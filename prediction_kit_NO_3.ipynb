{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_scale_prediction import large_scale_predictor, large_scale_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = 'NO_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:43:06,995]\u001b[0m A new study created in RDB with name: NO_3_2018\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:43:23,209]\u001b[0m Trial 0 finished with value: 4.572236647446062 and parameters: {'n_hidden': 4, 'learning_rate': 0.040701940762085866, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2417275027333778, 'dropout_rate_Layer_2': 0.345409513324411, 'dropout_rate_Layer_3': 0.017601324788472584, 'dropout_rate_Layer_4': 0.23852549869699763, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.1100496992069474e-05, 'l1_Layer_2': 0.05309413804754265, 'l1_Layer_3': 8.64089475564519e-05, 'l1_Layer_4': 3.554662799598669e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 145, 'n_units_Layer_3': 255, 'n_units_Layer_4': 140}. Best is trial 0 with value: 4.572236647446062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.57 | sMAPE for Validation Set is: 15.80% | rMAE for Validation Set is: 1.36\n",
      "MAE for Test Set is: 18.79 | sMAPE for Test Set is: 51.63% | rMAE for Test Set is: 3.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:43:23,339]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 15.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:43:29,140]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:43:38,130]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:43:46,550]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:43:49,447]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:43:52,538]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:43:52,690]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:43:57,699]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:43:58,165]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:43:58,182]\u001b[0m Trial 1 finished with value: 2.6581989224929385 and parameters: {'n_hidden': 4, 'learning_rate': 0.0456701096655866, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.253397618286808, 'dropout_rate_Layer_2': 0.36561523187835315, 'dropout_rate_Layer_3': 0.21585037410894892, 'dropout_rate_Layer_4': 0.21364681132303504, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.7880055382395925e-05, 'l1_Layer_2': 2.568587752610687e-05, 'l1_Layer_3': 0.0018361818892986786, 'l1_Layer_4': 0.004201002807729038, 'n_units_Layer_1': 50, 'n_units_Layer_2': 135, 'n_units_Layer_3': 240, 'n_units_Layer_4': 280}. Best is trial 1 with value: 2.6581989224929385.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.66 | sMAPE for Validation Set is: 8.84% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 11.40 | sMAPE for Test Set is: 28.23% | rMAE for Test Set is: 2.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:44:05,871]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:44:10,990]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:44:11,318]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:44:17,695]\u001b[0m Trial 5 finished with value: 2.199206823654459 and parameters: {'n_hidden': 3, 'learning_rate': 0.000605409369423605, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28829403017547034, 'dropout_rate_Layer_2': 0.22287659554295525, 'dropout_rate_Layer_3': 0.376908052758586, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011986045747343969, 'l1_Layer_2': 0.011241476261425527, 'l1_Layer_3': 0.00011287798985157053, 'n_units_Layer_1': 175, 'n_units_Layer_2': 175, 'n_units_Layer_3': 110}. Best is trial 5 with value: 2.199206823654459.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.20 | sMAPE for Validation Set is: 7.39% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.81 | sMAPE for Test Set is: 16.05% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:44:21,291]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:44:24,497]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:44:24,733]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.32 | sMAPE for Validation Set is: 7.78% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 3.95 | sMAPE for Test Set is: 9.74% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:44:27,318]\u001b[0m Trial 14 finished with value: 2.3208629921694706 and parameters: {'n_hidden': 4, 'learning_rate': 0.008266710348697475, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09259775684323485, 'dropout_rate_Layer_2': 0.12387642714254676, 'dropout_rate_Layer_3': 0.08119156685693629, 'dropout_rate_Layer_4': 0.10067656436566615, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012689389760578165, 'l1_Layer_2': 0.00034911639206336995, 'l1_Layer_3': 0.018954469851404827, 'l1_Layer_4': 0.0018838260083303814, 'n_units_Layer_1': 100, 'n_units_Layer_2': 195, 'n_units_Layer_3': 170, 'n_units_Layer_4': 180}. Best is trial 5 with value: 2.199206823654459.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:44:32,758]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:44:34,052]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:44:35,166]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:44:40,288]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:44:43,652]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:44:48,239]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:44:49,014]\u001b[0m Trial 16 finished with value: 2.205772678865401 and parameters: {'n_hidden': 3, 'learning_rate': 0.006041740389731892, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15956087478655634, 'dropout_rate_Layer_2': 0.3550708857539738, 'dropout_rate_Layer_3': 0.04487376965750359, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015446124990046394, 'l1_Layer_2': 0.00022232670487662488, 'l1_Layer_3': 0.0033181368186484222, 'n_units_Layer_1': 205, 'n_units_Layer_2': 270, 'n_units_Layer_3': 195}. Best is trial 5 with value: 2.199206823654459.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.21 | sMAPE for Validation Set is: 7.31% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.23 | sMAPE for Test Set is: 27.55% | rMAE for Test Set is: 2.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:44:53,031]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:44:54,249]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:00,241]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:02,143]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:02,684]\u001b[0m Trial 25 finished with value: 2.33143889277119 and parameters: {'n_hidden': 3, 'learning_rate': 0.008676200890585954, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14627437210056826, 'dropout_rate_Layer_2': 0.07978613456562406, 'dropout_rate_Layer_3': 0.2834481559154268, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002674120630686735, 'l1_Layer_2': 0.0002781897927610758, 'l1_Layer_3': 0.08682587131918655, 'n_units_Layer_1': 110, 'n_units_Layer_2': 210, 'n_units_Layer_3': 205}. Best is trial 5 with value: 2.199206823654459.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.33 | sMAPE for Validation Set is: 7.74% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 9.97 | sMAPE for Test Set is: 24.12% | rMAE for Test Set is: 1.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:45:08,462]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:10,277]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:12,765]\u001b[0m Trial 23 finished with value: 4.969532940356647 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035675886591808505, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38689324852420537, 'dropout_rate_Layer_2': 0.1147277351614589, 'dropout_rate_Layer_3': 0.045441744890481764, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.007603622459498653, 'l1_Layer_2': 0.017339800316040845, 'l1_Layer_3': 2.116743428987414e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 125, 'n_units_Layer_3': 75}. Best is trial 5 with value: 2.199206823654459.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 17.31% | rMAE for Validation Set is: 1.48\n",
      "MAE for Test Set is: 19.45 | sMAPE for Test Set is: 53.94% | rMAE for Test Set is: 3.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:45:17,580]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:20,325]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:21,949]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:25,319]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:26,914]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:29,278]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:29,620]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:33,225]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:33,578]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:34,907]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:38,415]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:40,176]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:45,336]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:46,004]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:46,804]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:49,606]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:49,701]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:52,644]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:54,801]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:57,087]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:45:58,986]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:46:05,090]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:46:05,254]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:46:05,784]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:46:13,867]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:46:16,035]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:46:17,506]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:46:22,899]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:46:23,364]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:46:28,567]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:46:29,684]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:46:37,673]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:46:47,707]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:46:55,070]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:47:02,721]\u001b[0m Trial 62 finished with value: 3.007560543285846 and parameters: {'n_hidden': 3, 'learning_rate': 0.020562572804794833, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1092608533079813, 'dropout_rate_Layer_2': 0.02583931663244026, 'dropout_rate_Layer_3': 0.3484214757373918, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.684857310234255e-05, 'l1_Layer_2': 0.0006463435407053041, 'l1_Layer_3': 0.018418304245927584, 'n_units_Layer_1': 105, 'n_units_Layer_2': 165, 'n_units_Layer_3': 195}. Best is trial 5 with value: 2.199206823654459.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.01 | sMAPE for Validation Set is: 10.33% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 10.92 | sMAPE for Test Set is: 27.05% | rMAE for Test Set is: 2.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:47:05,387]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.30 | sMAPE for Validation Set is: 7.75% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.75 | sMAPE for Test Set is: 16.13% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:47:08,025]\u001b[0m Trial 55 finished with value: 2.3009550769102645 and parameters: {'n_hidden': 3, 'learning_rate': 0.017054879767938305, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05803735327655701, 'dropout_rate_Layer_2': 0.39807637123186124, 'dropout_rate_Layer_3': 0.12227048246220527, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.421346288596388e-05, 'l1_Layer_2': 0.0006637193567132381, 'l1_Layer_3': 0.02452291765484629, 'n_units_Layer_1': 260, 'n_units_Layer_2': 210, 'n_units_Layer_3': 230}. Best is trial 5 with value: 2.199206823654459.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:47:13,705]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:47:15,497]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:47:16,102]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:47:21,711]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:47:27,720]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:47:30,558]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:47:35,022]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:47:37,290]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:47:42,129]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:47:43,834]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:47:47,523]\u001b[0m Trial 75 finished with value: 2.224314489790847 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018620216379792028, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21234190882795084, 'dropout_rate_Layer_2': 0.2863109326049481, 'dropout_rate_Layer_3': 0.07235406039449792, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005371433431515354, 'l1_Layer_2': 1.4537337784752561e-05, 'l1_Layer_3': 0.00010066622057117779, 'n_units_Layer_1': 205, 'n_units_Layer_2': 300, 'n_units_Layer_3': 180}. Best is trial 5 with value: 2.199206823654459.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.22 | sMAPE for Validation Set is: 7.38% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 15.45% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:47:48,505]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:47:49,244]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:47:52,377]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:47:56,609]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:47:58,794]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:01,173]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:01,334]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:01,720]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:16,316]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:16,488]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:21,985]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:23,556]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:27,609]\u001b[0m Trial 91 finished with value: 2.4446120808954794 and parameters: {'n_hidden': 3, 'learning_rate': 0.010682450508271038, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03435002336325846, 'dropout_rate_Layer_2': 0.04238975172968473, 'dropout_rate_Layer_3': 0.3118228278356049, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005103217802680376, 'l1_Layer_2': 0.0009762319609835203, 'l1_Layer_3': 0.05971417344774607, 'n_units_Layer_1': 90, 'n_units_Layer_2': 185, 'n_units_Layer_3': 145}. Best is trial 5 with value: 2.199206823654459.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.44 | sMAPE for Validation Set is: 8.20% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 10.08 | sMAPE for Test Set is: 24.44% | rMAE for Test Set is: 1.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:48:29,531]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:31,609]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:33,400]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:33,915]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:39,718]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:39,943]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:45,744]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:48,819]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:52,711]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:52,818]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:54,508]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:48:59,259]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:49:05,703]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:49:11,445]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:49:15,198]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:49:19,053]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:49:21,720]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:49:25,643]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:49:26,083]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:49:28,146]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:49:31,696]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:49:35,820]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:49:38,931]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:49:44,279]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:49:49,619]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:49:51,269]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:49:55,515]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:49:55,850]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:00,075]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:01,192]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:07,223]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:09,743]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:13,766]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:13,933]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:18,960]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:23,924]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:24,149]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:31,227]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:32,609]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:35,497]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:38,073]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:38,520]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:40,632]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:44,209]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:47,548]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:49,385]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:51,926]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:54,781]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:57,278]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:50:59,363]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:00,389]\u001b[0m Trial 139 finished with value: 2.1846919740556117 and parameters: {'n_hidden': 3, 'learning_rate': 0.00914312405313369, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0321492589924116, 'dropout_rate_Layer_2': 0.10323087825819466, 'dropout_rate_Layer_3': 0.20800545092948747, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.001685430875584449, 'l1_Layer_2': 0.005396229175250555, 'l1_Layer_3': 0.003730610137644195, 'n_units_Layer_1': 170, 'n_units_Layer_2': 235, 'n_units_Layer_3': 220}. Best is trial 139 with value: 2.1846919740556117.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.18 | sMAPE for Validation Set is: 7.35% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.89 | sMAPE for Test Set is: 21.29% | rMAE for Test Set is: 1.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:51:00,533]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:07,084]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:13,558]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:15,835]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:17,599]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:18,135]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:23,428]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:23,701]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:28,102]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:28,397]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:31,267]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:34,031]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:36,770]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:36,828]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:41,353]\u001b[0m Trial 146 finished with value: 2.2898828064795973 and parameters: {'n_hidden': 4, 'learning_rate': 0.005255632950441359, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2560030250911725, 'dropout_rate_Layer_2': 0.16986282437872186, 'dropout_rate_Layer_3': 0.3208670201360679, 'dropout_rate_Layer_4': 0.3856122265644149, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0025266855424263004, 'l1_Layer_2': 0.09124952920669258, 'l1_Layer_3': 0.00022608940354949103, 'l1_Layer_4': 0.0009379475064301196, 'n_units_Layer_1': 195, 'n_units_Layer_2': 225, 'n_units_Layer_3': 205, 'n_units_Layer_4': 145}. Best is trial 139 with value: 2.1846919740556117.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.29 | sMAPE for Validation Set is: 7.62% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.04 | sMAPE for Test Set is: 19.04% | rMAE for Test Set is: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:51:42,975]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:47,588]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:48,006]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:48,027]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:55,395]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:51:57,669]\u001b[0m Trial 163 finished with value: 2.292518425285261 and parameters: {'n_hidden': 3, 'learning_rate': 0.017660939837060022, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11603821270665339, 'dropout_rate_Layer_2': 0.1497916083747085, 'dropout_rate_Layer_3': 0.11172572886758123, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00013650351724687904, 'l1_Layer_2': 0.0004392870503309025, 'l1_Layer_3': 0.0024037303820765537, 'n_units_Layer_1': 100, 'n_units_Layer_2': 55, 'n_units_Layer_3': 235}. Best is trial 139 with value: 2.1846919740556117.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.29 | sMAPE for Validation Set is: 7.65% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.09 | sMAPE for Test Set is: 24.48% | rMAE for Test Set is: 1.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:52:01,098]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:05,647]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:06,150]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:10,615]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:14,320]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:17,828]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:18,038]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.17 | sMAPE for Validation Set is: 7.27% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.68 | sMAPE for Test Set is: 15.84% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:52:20,338]\u001b[0m Trial 166 finished with value: 2.173255493902849 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018861017085642388, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18987020531915233, 'dropout_rate_Layer_2': 0.27434341396409356, 'dropout_rate_Layer_3': 0.056746617804389506, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007246831316227252, 'l1_Layer_2': 1.9582414425334727e-05, 'l1_Layer_3': 0.00010203303984052933, 'n_units_Layer_1': 210, 'n_units_Layer_2': 295, 'n_units_Layer_3': 180}. Best is trial 166 with value: 2.173255493902849.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:23,540]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:26,635]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:27,312]\u001b[0m Trial 167 finished with value: 2.219777857782232 and parameters: {'n_hidden': 3, 'learning_rate': 0.001951363485626804, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18579825361099256, 'dropout_rate_Layer_2': 0.27284068173677894, 'dropout_rate_Layer_3': 0.06365933403608563, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007236188045908044, 'l1_Layer_2': 1.346436358936425e-05, 'l1_Layer_3': 5.5661480912697334e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 295, 'n_units_Layer_3': 175}. Best is trial 166 with value: 2.173255493902849.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.22 | sMAPE for Validation Set is: 7.35% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 15.54% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:52:31,425]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:33,744]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:34,609]\u001b[0m Trial 177 finished with value: 2.6699036215936673 and parameters: {'n_hidden': 3, 'learning_rate': 0.023324119574842605, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020570913734468524, 'dropout_rate_Layer_2': 0.3601257197869043, 'dropout_rate_Layer_3': 0.1511293076738461, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.6028628674899256e-05, 'l1_Layer_2': 0.0005323557996753981, 'l1_Layer_3': 0.003653236689871031, 'n_units_Layer_1': 90, 'n_units_Layer_2': 50, 'n_units_Layer_3': 230}. Best is trial 166 with value: 2.173255493902849.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:34,613]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.67 | sMAPE for Validation Set is: 8.88% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 13.61 | sMAPE for Test Set is: 34.50% | rMAE for Test Set is: 2.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:52:40,154]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:41,947]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:45,100]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:47,428]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:47,942]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:52,493]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:52:56,161]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:01,680]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:07,565]\u001b[0m Trial 178 finished with value: 2.141291222776559 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024985311790974253, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018337305287032105, 'dropout_rate_Layer_2': 0.14137448660631208, 'dropout_rate_Layer_3': 0.11866327370977989, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005558625471608458, 'l1_Layer_2': 0.0004936574670318693, 'l1_Layer_3': 0.003397034907116869, 'n_units_Layer_1': 105, 'n_units_Layer_2': 170, 'n_units_Layer_3': 230}. Best is trial 178 with value: 2.141291222776559.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.14% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.39 | sMAPE for Test Set is: 25.23% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:53:09,871]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:12,025]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:16,115]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:16,165]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:21,789]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:25,059]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:25,668]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:31,347]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:35,637]\u001b[0m Trial 200 finished with value: 2.798457158659646 and parameters: {'n_hidden': 3, 'learning_rate': 0.03769163246100043, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10675781651434291, 'dropout_rate_Layer_2': 0.3190426853208775, 'dropout_rate_Layer_3': 0.15088108491267233, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00020962863652986975, 'l1_Layer_2': 0.0014155033470209086, 'l1_Layer_3': 0.00019494120654343596, 'n_units_Layer_1': 55, 'n_units_Layer_2': 185, 'n_units_Layer_3': 245}. Best is trial 178 with value: 2.141291222776559.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.80 | sMAPE for Validation Set is: 9.52% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 12.70 | sMAPE for Test Set is: 31.83% | rMAE for Test Set is: 2.45\n",
      "MAE for Validation Set is: 2.17 | sMAPE for Validation Set is: 7.24% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 14.83% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:53:38,063]\u001b[0m Trial 196 finished with value: 2.173505061716119 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027617586242019683, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11186107736777978, 'dropout_rate_Layer_2': 0.31265162047421413, 'dropout_rate_Layer_3': 0.039985346353830165, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009154126137006875, 'l1_Layer_2': 5.5471811119080774e-05, 'l1_Layer_3': 3.473480530716151e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 275, 'n_units_Layer_3': 195}. Best is trial 178 with value: 2.141291222776559.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:40,410]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:42,345]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:46,141]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:48,416]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:50,431]\u001b[0m Trial 204 finished with value: 3.0275730308784907 and parameters: {'n_hidden': 3, 'learning_rate': 0.029848250874066503, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10218624577462529, 'dropout_rate_Layer_2': 0.31425702541640993, 'dropout_rate_Layer_3': 0.15390477750577228, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 5.537786488256053e-05, 'l1_Layer_2': 0.0013984346340503403, 'l1_Layer_3': 0.0001998027944885543, 'n_units_Layer_1': 55, 'n_units_Layer_2': 185, 'n_units_Layer_3': 210}. Best is trial 178 with value: 2.141291222776559.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.03 | sMAPE for Validation Set is: 10.10% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 15.87 | sMAPE for Test Set is: 41.57% | rMAE for Test Set is: 3.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:53:52,119]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:52,646]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:54,975]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:57,590]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:53:59,437]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:02,818]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:04,980]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:06,201]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:06,397]\u001b[0m Trial 211 finished with value: 3.413510798946218 and parameters: {'n_hidden': 3, 'learning_rate': 0.05165277826226532, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0782154332746924, 'dropout_rate_Layer_2': 0.35790835234424595, 'dropout_rate_Layer_3': 0.12240482857923139, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00019468468128605034, 'l1_Layer_2': 0.0017361124883056068, 'l1_Layer_3': 0.0001566876760620664, 'n_units_Layer_1': 70, 'n_units_Layer_2': 175, 'n_units_Layer_3': 245}. Best is trial 178 with value: 2.141291222776559.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.41 | sMAPE for Validation Set is: 11.72% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 13.42 | sMAPE for Test Set is: 33.88% | rMAE for Test Set is: 2.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:54:07,945]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:10,302]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:15,046]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:16,169]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:20,541]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:20,767]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:21,440]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:27,118]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:27,275]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:31,546]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:34,293]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:34,338]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:35,270]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:40,705]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:41,080]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:44,391]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:46,217]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:49,611]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:54:53,957]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:55:01,649]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:55:10,223]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:55:13,324]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:55:20,528]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:55:22,689]\u001b[0m Trial 217 finished with value: 2.3665601389279356 and parameters: {'n_hidden': 3, 'learning_rate': 0.0046422728264657485, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11656822065391839, 'dropout_rate_Layer_2': 0.03296632661985747, 'dropout_rate_Layer_3': 0.3764825530231438, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8726504466675324e-05, 'l1_Layer_2': 0.0006182672157028097, 'l1_Layer_3': 0.02652036673830091, 'n_units_Layer_1': 90, 'n_units_Layer_2': 155, 'n_units_Layer_3': 220}. Best is trial 178 with value: 2.141291222776559.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.37 | sMAPE for Validation Set is: 7.93% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 8.34 | sMAPE for Test Set is: 19.83% | rMAE for Test Set is: 1.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:55:25,067]\u001b[0m Trial 235 finished with value: 2.163367812105175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0041706550689949405, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15435112503292264, 'dropout_rate_Layer_2': 0.0631974094141936, 'dropout_rate_Layer_3': 0.02808755603533776, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.017311472197498734, 'l1_Layer_2': 0.0005330456743558582, 'l1_Layer_3': 0.014356302362237299, 'n_units_Layer_1': 50, 'n_units_Layer_2': 180, 'n_units_Layer_3': 180}. Best is trial 178 with value: 2.141291222776559.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 7.17% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.18 | sMAPE for Test Set is: 21.98% | rMAE for Test Set is: 1.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:55:25,394]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:55:27,841]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:55:31,855]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:55:33,316]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:55:35,293]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:55:35,551]\u001b[0m Trial 238 finished with value: 2.333656178630708 and parameters: {'n_hidden': 3, 'learning_rate': 0.006523212715465343, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04531415777958461, 'dropout_rate_Layer_2': 0.062332230001450564, 'dropout_rate_Layer_3': 0.015079749118321863, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01697872716351898, 'l1_Layer_2': 1.9274292789195275e-05, 'l1_Layer_3': 0.05382806631875554, 'n_units_Layer_1': 50, 'n_units_Layer_2': 125, 'n_units_Layer_3': 205}. Best is trial 178 with value: 2.141291222776559.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.33 | sMAPE for Validation Set is: 7.86% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 9.46 | sMAPE for Test Set is: 22.81% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:55:40,262]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:55:40,970]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:55:42,933]\u001b[0m Trial 247 finished with value: 2.9180920263997217 and parameters: {'n_hidden': 3, 'learning_rate': 0.04522501898461118, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19005960551844414, 'dropout_rate_Layer_2': 0.38381443023564155, 'dropout_rate_Layer_3': 0.21743281897448102, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 6.116111714096611e-05, 'l1_Layer_2': 0.0004545552424600734, 'l1_Layer_3': 0.00012708380802032968, 'n_units_Layer_1': 100, 'n_units_Layer_2': 205, 'n_units_Layer_3': 255}. Best is trial 178 with value: 2.141291222776559.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.92 | sMAPE for Validation Set is: 9.92% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 11.04 | sMAPE for Test Set is: 27.07% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:55:46,758]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:55:50,666]\u001b[0m Trial 250 finished with value: 3.8050212734726774 and parameters: {'n_hidden': 3, 'learning_rate': 0.04642344640182674, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08878969772784133, 'dropout_rate_Layer_2': 0.35823944530510804, 'dropout_rate_Layer_3': 0.12544719446131586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00018823205644781198, 'l1_Layer_2': 0.002056239541012258, 'l1_Layer_3': 0.00011770534536334705, 'n_units_Layer_1': 70, 'n_units_Layer_2': 150, 'n_units_Layer_3': 240}. Best is trial 178 with value: 2.141291222776559.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 12.54% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 10.88 | sMAPE for Test Set is: 26.66% | rMAE for Test Set is: 2.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:55:51,006]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.32 | sMAPE for Validation Set is: 7.73% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 8.12 | sMAPE for Test Set is: 19.40% | rMAE for Test Set is: 1.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:55:54,144]\u001b[0m Trial 246 finished with value: 2.3234253122331485 and parameters: {'n_hidden': 3, 'learning_rate': 0.021242536627366113, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01182218877706194, 'dropout_rate_Layer_2': 0.3991712073773109, 'dropout_rate_Layer_3': 0.22676520302031278, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00030958114006822857, 'l1_Layer_2': 0.0023869394990188317, 'l1_Layer_3': 0.0005427678359520852, 'n_units_Layer_1': 100, 'n_units_Layer_2': 170, 'n_units_Layer_3': 255}. Best is trial 178 with value: 2.141291222776559.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:55:56,307]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:55:59,331]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:55:59,820]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:03,929]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:05,369]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:07,234]\u001b[0m Trial 252 finished with value: 2.141209415332787 and parameters: {'n_hidden': 3, 'learning_rate': 0.008133345507873462, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.038151305680226025, 'dropout_rate_Layer_2': 0.32536078653883704, 'dropout_rate_Layer_3': 0.09487818339835609, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.030229877881950792, 'l1_Layer_2': 0.002860515934658796, 'l1_Layer_3': 2.8771501669020222e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 285, 'n_units_Layer_3': 195}. Best is trial 252 with value: 2.141209415332787.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.11% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.63 | sMAPE for Test Set is: 15.72% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:56:07,844]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:11,409]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:11,492]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:12,075]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:17,390]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:19,514]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:21,699]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:24,324]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:28,661]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:33,975]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:36,028]\u001b[0m Trial 266 finished with value: 2.579241048033233 and parameters: {'n_hidden': 3, 'learning_rate': 0.012929220329834708, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05446425596904182, 'dropout_rate_Layer_2': 0.39942218114301514, 'dropout_rate_Layer_3': 0.2112345438174903, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002942455011123906, 'l1_Layer_2': 0.00015531796960420246, 'l1_Layer_3': 0.0025051150406500953, 'n_units_Layer_1': 135, 'n_units_Layer_2': 255, 'n_units_Layer_3': 225}. Best is trial 252 with value: 2.141209415332787.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.58 | sMAPE for Validation Set is: 8.66% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 8.04 | sMAPE for Test Set is: 19.09% | rMAE for Test Set is: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:56:37,012]\u001b[0m Trial 255 finished with value: 2.240043495140928 and parameters: {'n_hidden': 3, 'learning_rate': 0.0056334164621022085, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12776544956009975, 'dropout_rate_Layer_2': 0.028862902572666993, 'dropout_rate_Layer_3': 0.006372285445715484, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012153823802894594, 'l1_Layer_2': 0.0004418240632959236, 'l1_Layer_3': 0.05835287575517547, 'n_units_Layer_1': 60, 'n_units_Layer_2': 120, 'n_units_Layer_3': 185}. Best is trial 252 with value: 2.141209415332787.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.24 | sMAPE for Validation Set is: 7.43% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.66 | sMAPE for Test Set is: 18.05% | rMAE for Test Set is: 1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:56:37,898]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:44,778]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:47,651]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:48,069]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:48,477]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:53,681]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:55,928]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:55,970]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:56:56,841]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:02,190]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:02,533]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:02,670]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:02,851]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:10,674]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:10,993]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:11,347]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:11,697]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:19,150]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:21,679]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:21,910]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:24,552]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:24,768]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:25,711]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:31,568]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:31,789]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:31,989]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:33,662]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:37,092]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:38,534]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:40,338]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:41,656]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:42,553]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:45,016]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:50,531]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:51,070]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:54,230]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:56,556]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:57:57,516]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:00,813]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:02,904]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:03,090]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:09,343]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:09,646]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:09,773]\u001b[0m Trial 313 finished with value: 2.5403744720391503 and parameters: {'n_hidden': 3, 'learning_rate': 0.026941163811568702, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09695136443751655, 'dropout_rate_Layer_2': 0.12022485629883606, 'dropout_rate_Layer_3': 0.10791747952187407, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00010834685282221519, 'l1_Layer_2': 0.0003165248595186308, 'l1_Layer_3': 0.0001905094210907971, 'n_units_Layer_1': 195, 'n_units_Layer_2': 185, 'n_units_Layer_3': 230}. Best is trial 252 with value: 2.141209415332787.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.54 | sMAPE for Validation Set is: 8.49% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 10.98 | sMAPE for Test Set is: 26.90% | rMAE for Test Set is: 2.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:58:10,489]\u001b[0m Trial 311 finished with value: 2.404385492424281 and parameters: {'n_hidden': 3, 'learning_rate': 0.014542590324213725, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10451100073492832, 'dropout_rate_Layer_2': 0.12043708482670411, 'dropout_rate_Layer_3': 0.10887586974220766, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.1718292900986388e-05, 'l1_Layer_2': 0.0028334131381222896, 'l1_Layer_3': 0.00021755733149919827, 'n_units_Layer_1': 60, 'n_units_Layer_2': 185, 'n_units_Layer_3': 230}. Best is trial 252 with value: 2.141209415332787.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.40 | sMAPE for Validation Set is: 7.97% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 7.76 | sMAPE for Test Set is: 18.48% | rMAE for Test Set is: 1.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 13:58:17,386]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:18,174]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:19,450]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:19,574]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:20,677]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:27,672]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:28,086]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:33,506]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:33,823]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:37,035]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:40,518]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:41,229]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:43,135]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:47,597]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:50,224]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:52,731]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:53,278]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:55,988]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:58:58,796]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:01,119]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:03,355]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:06,414]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:09,924]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:14,573]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:15,622]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:19,854]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:23,309]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:26,523]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:31,863]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:35,115]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:35,591]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:41,070]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:41,234]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:41,779]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:47,673]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:48,162]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:48,849]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:54,378]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:54,421]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:55,123]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 13:59:55,598]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:02,900]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:04,530]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:06,648]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:06,955]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:07,517]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:13,579]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:16,632]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:16,854]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:21,853]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:21,987]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:27,059]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:30,868]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:34,761]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:38,231]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:39,241]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:40,909]\u001b[0m Trial 372 finished with value: 2.488303798687969 and parameters: {'n_hidden': 3, 'learning_rate': 0.03051258781026426, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12063400037926295, 'dropout_rate_Layer_2': 0.3036336661433832, 'dropout_rate_Layer_3': 0.15188744800571716, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00011436259781318951, 'l1_Layer_2': 0.0008995930035854609, 'l1_Layer_3': 0.00042300084776269645, 'n_units_Layer_1': 50, 'n_units_Layer_2': 170, 'n_units_Layer_3': 205}. Best is trial 252 with value: 2.141209415332787.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.49 | sMAPE for Validation Set is: 8.31% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 10.51 | sMAPE for Test Set is: 25.74% | rMAE for Test Set is: 2.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:00:44,924]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:47,004]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:51,392]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:56,365]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:00:58,637]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:02,518]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:06,021]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:11,751]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:11,943]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:16,733]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:17,217]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:21,189]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:24,386]\u001b[0m Trial 365 finished with value: 2.2575886155151568 and parameters: {'n_hidden': 3, 'learning_rate': 0.003670477375075952, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14529519731956814, 'dropout_rate_Layer_2': 0.09280456581514376, 'dropout_rate_Layer_3': 0.013551257210521708, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.569984314281267e-05, 'l1_Layer_2': 0.00040798894828412437, 'l1_Layer_3': 0.041308452755267726, 'n_units_Layer_1': 55, 'n_units_Layer_2': 165, 'n_units_Layer_3': 215}. Best is trial 252 with value: 2.141209415332787.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.26 | sMAPE for Validation Set is: 7.50% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.51 | sMAPE for Test Set is: 20.23% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:01:24,880]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:30,288]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:30,525]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:30,927]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:35,441]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:37,158]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:39,610]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:39,715]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:43,405]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:43,459]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:46,490]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:48,675]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:49,401]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:51,112]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:54,997]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:58,663]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:58,931]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:59,042]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:01:59,275]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:05,458]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:06,324]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:09,378]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:09,835]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:13,843]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:14,658]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:15,121]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:19,984]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:22,044]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:23,159]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:25,467]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:29,364]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:31,988]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:36,250]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:38,446]\u001b[0m Trial 419 finished with value: 2.2378585529948967 and parameters: {'n_hidden': 3, 'learning_rate': 0.029714092066050045, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12241682850246209, 'dropout_rate_Layer_2': 0.30022480852748984, 'dropout_rate_Layer_3': 0.1494289419539618, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 6.071231415667933e-05, 'l1_Layer_2': 0.0015358310046956827, 'l1_Layer_3': 0.00019896811189169903, 'n_units_Layer_1': 55, 'n_units_Layer_2': 185, 'n_units_Layer_3': 205}. Best is trial 252 with value: 2.141209415332787.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.24 | sMAPE for Validation Set is: 7.41% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.81 | sMAPE for Test Set is: 21.22% | rMAE for Test Set is: 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:02:41,081]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:41,203]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:46,440]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:49,658]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:53,383]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:02:58,651]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:03:01,217]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:03:04,602]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:03:07,612]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:03:07,852]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:03:18,498]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:03:19,055]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:03:21,926]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:03:24,340]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:03:28,767]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:03:38,712]\u001b[0m Trial 422 finished with value: 2.289021584157393 and parameters: {'n_hidden': 3, 'learning_rate': 0.001422601107917336, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022623413067142092, 'dropout_rate_Layer_2': 0.0004704134041550337, 'dropout_rate_Layer_3': 0.015932823729677536, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8721350740271958e-05, 'l1_Layer_2': 0.0005578526430992783, 'l1_Layer_3': 0.02119287660443112, 'n_units_Layer_1': 95, 'n_units_Layer_2': 150, 'n_units_Layer_3': 215}. Best is trial 252 with value: 2.141209415332787.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.29 | sMAPE for Validation Set is: 7.64% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.29 | sMAPE for Test Set is: 19.81% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:03:45,146]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:03:48,569]\u001b[0m Trial 434 finished with value: 2.4066163027264333 and parameters: {'n_hidden': 3, 'learning_rate': 0.02323314082278976, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10667892745018412, 'dropout_rate_Layer_2': 0.12884973164703042, 'dropout_rate_Layer_3': 0.11650475395334806, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.417474483264506e-05, 'l1_Layer_2': 0.0017060816665613447, 'l1_Layer_3': 0.004714970680986486, 'n_units_Layer_1': 70, 'n_units_Layer_2': 155, 'n_units_Layer_3': 220}. Best is trial 252 with value: 2.141209415332787.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.41 | sMAPE for Validation Set is: 8.02% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 10.78 | sMAPE for Test Set is: 26.41% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:03:54,611]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:04:00,236]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:04:05,559]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:04:09,631]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:04:14,897]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:04:19,930]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:04:22,969]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:04:29,949]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:04:37,742]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:04:43,890]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:04:47,313]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:04:52,152]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:04:55,448]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:05:03,821]\u001b[0m Trial 439 finished with value: 2.157583484516463 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007711525098931523, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016462152733526057, 'dropout_rate_Layer_2': 0.0006239505459214936, 'dropout_rate_Layer_3': 0.019964093801136017, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8992390313111702e-05, 'l1_Layer_2': 0.0005179192280534787, 'l1_Layer_3': 0.01987932946574682, 'n_units_Layer_1': 95, 'n_units_Layer_2': 145, 'n_units_Layer_3': 210}. Best is trial 252 with value: 2.141209415332787.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 7.19% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.05 | sMAPE for Test Set is: 19.28% | rMAE for Test Set is: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:05:04,088]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.91% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 15.70% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:05:05,985]\u001b[0m Trial 436 finished with value: 2.0778716256765013 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007423102911260315, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07080813478102019, 'dropout_rate_Layer_2': 0.06162932042437941, 'dropout_rate_Layer_3': 0.02623443838761425, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001990216574142593, 'l1_Layer_2': 2.593166066854017e-05, 'l1_Layer_3': 0.0602084852398498, 'n_units_Layer_1': 100, 'n_units_Layer_2': 150, 'n_units_Layer_3': 215}. Best is trial 436 with value: 2.0778716256765013.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:05:08,953]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:05:10,352]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:05:11,326]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:05:17,326]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:05:49,991]\u001b[0m Trial 440 finished with value: 2.0832357257260514 and parameters: {'n_hidden': 3, 'learning_rate': 0.00095650702479129, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021708521610909224, 'dropout_rate_Layer_2': 0.0651881097995835, 'dropout_rate_Layer_3': 0.01985925536452937, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019007176302272152, 'l1_Layer_2': 0.0005049689401613987, 'l1_Layer_3': 0.02035343607987857, 'n_units_Layer_1': 95, 'n_units_Layer_2': 155, 'n_units_Layer_3': 210}. Best is trial 436 with value: 2.0778716256765013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.94% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.16 | sMAPE for Test Set is: 16.89% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:05:52,936]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:05:54,717]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:06:02,421]\u001b[0m Trial 464 finished with value: 2.8051998136829397 and parameters: {'n_hidden': 3, 'learning_rate': 0.03211320800954344, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.055469885000392356, 'dropout_rate_Layer_2': 0.3902170421919239, 'dropout_rate_Layer_3': 0.14144989773540076, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.8493707809473424e-05, 'l1_Layer_2': 0.002139780387569849, 'l1_Layer_3': 0.004167542177483089, 'n_units_Layer_1': 50, 'n_units_Layer_2': 265, 'n_units_Layer_3': 260}. Best is trial 436 with value: 2.0778716256765013.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.81 | sMAPE for Validation Set is: 9.40% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 14.41 | sMAPE for Test Set is: 36.97% | rMAE for Test Set is: 2.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:06:07,076]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:06:10,100]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:06:14,316]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:06:18,162]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:06:21,743]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:06:27,014]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:06:30,992]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:06:35,949]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:06:39,732]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:06:44,272]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:06:47,458]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:06:51,829]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:06:57,888]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:07:08,205]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:07:13,450]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:07:17,474]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:07:22,727]\u001b[0m Trial 461 finished with value: 2.076519387403236 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009670669514438899, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.003681661894093878, 'dropout_rate_Layer_2': 0.06345491448857293, 'dropout_rate_Layer_3': 0.016107413900238343, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002963332424145695, 'l1_Layer_2': 0.0005342809794986024, 'l1_Layer_3': 0.02260392883598516, 'n_units_Layer_1': 105, 'n_units_Layer_2': 140, 'n_units_Layer_3': 180}. Best is trial 461 with value: 2.076519387403236.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.88% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.43 | sMAPE for Test Set is: 17.55% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:07:25,020]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:07:28,433]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:07:31,444]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:07:34,538]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:07:37,018]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:07:40,836]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:07:43,453]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:07:45,648]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:07:48,914]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:00,969]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:04,853]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:05,152]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:09,305]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:11,655]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:15,294]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 6.98% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.48 | sMAPE for Test Set is: 12.86% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:08:16,727]\u001b[0m Trial 478 finished with value: 2.0977490731013777 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006679026948261697, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06896281858069575, 'dropout_rate_Layer_2': 0.0705941403427507, 'dropout_rate_Layer_3': 0.03286261201984373, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0033524943500215136, 'l1_Layer_2': 2.5275201460933105e-05, 'l1_Layer_3': 0.019543401749060375, 'n_units_Layer_1': 110, 'n_units_Layer_2': 140, 'n_units_Layer_3': 145}. Best is trial 461 with value: 2.076519387403236.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:20,813]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:20,933]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:21,034]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:34,113]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:34,321]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:40,003]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:40,327]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:44,592]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:47,430]\u001b[0m Trial 463 finished with value: 2.1076273985282 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005947007025919506, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0016610509870237378, 'dropout_rate_Layer_2': 0.06441585583445368, 'dropout_rate_Layer_3': 0.03286334710770983, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001793779255734508, 'l1_Layer_2': 2.4652723061989894e-05, 'l1_Layer_3': 0.024026390422588643, 'n_units_Layer_1': 100, 'n_units_Layer_2': 155, 'n_units_Layer_3': 175}. Best is trial 461 with value: 2.076519387403236.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 7.06% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.07 | sMAPE for Test Set is: 16.74% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:08:47,843]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:51,076]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:53,244]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:55,769]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:08:56,273]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:09:02,026]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:09:05,402]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:09:09,321]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:09:13,235]\u001b[0m Trial 514 finished with value: 3.9167567571980997 and parameters: {'n_hidden': 3, 'learning_rate': 0.023896805673927452, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22512047733454793, 'dropout_rate_Layer_2': 0.39549431552698366, 'dropout_rate_Layer_3': 0.14289370886805863, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00010723923843450774, 'l1_Layer_2': 0.001848914084085138, 'l1_Layer_3': 0.00015093242623463382, 'n_units_Layer_1': 270, 'n_units_Layer_2': 205, 'n_units_Layer_3': 230}. Best is trial 461 with value: 2.076519387403236.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.92 | sMAPE for Validation Set is: 13.07% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 14.47 | sMAPE for Test Set is: 37.50% | rMAE for Test Set is: 2.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:09:17,689]\u001b[0m Trial 513 finished with value: 2.2709796542828307 and parameters: {'n_hidden': 3, 'learning_rate': 0.007768698844636543, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09053491026072177, 'dropout_rate_Layer_2': 0.17298163174914477, 'dropout_rate_Layer_3': 0.18406021499889558, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00010868486452316414, 'l1_Layer_2': 0.0017718646339141845, 'l1_Layer_3': 0.002075149309507687, 'n_units_Layer_1': 155, 'n_units_Layer_2': 200, 'n_units_Layer_3': 230}. Best is trial 461 with value: 2.076519387403236.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.27 | sMAPE for Validation Set is: 7.56% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.69 | sMAPE for Test Set is: 26.11% | rMAE for Test Set is: 2.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:09:18,235]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:09:18,616]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:09:22,939]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:09:25,445]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:09:26,020]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:09:31,054]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:09:31,664]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:09:39,197]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:09:39,589]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:09:43,869]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:09:48,442]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:09:57,157]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:10:03,305]\u001b[0m Trial 511 finished with value: 2.0497693538576973 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005187393182109893, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005644116373785815, 'dropout_rate_Layer_2': 0.08764571926441114, 'dropout_rate_Layer_3': 0.0171133622293028, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002294475598022565, 'l1_Layer_2': 1.9994771524650643e-05, 'l1_Layer_3': 0.00378650366001803, 'n_units_Layer_1': 100, 'n_units_Layer_2': 165, 'n_units_Layer_3': 145}. Best is trial 511 with value: 2.0497693538576973.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 6.81% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.63 | sMAPE for Test Set is: 13.20% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:10:07,321]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:10:11,369]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:10:13,796]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:10:14,419]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:10:18,501]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:10:23,400]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:10:43,433]\u001b[0m Trial 529 finished with value: 2.1672609350889975 and parameters: {'n_hidden': 4, 'learning_rate': 0.002709674969916335, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.056566449328341095, 'dropout_rate_Layer_2': 0.122481086101379, 'dropout_rate_Layer_3': 0.2717603493426592, 'dropout_rate_Layer_4': 0.2375746627102337, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.013080210601535499, 'l1_Layer_2': 0.006412971660968931, 'l1_Layer_3': 0.0004349657794407738, 'l1_Layer_4': 0.0022255313718607095, 'n_units_Layer_1': 165, 'n_units_Layer_2': 225, 'n_units_Layer_3': 275, 'n_units_Layer_4': 180}. Best is trial 511 with value: 2.0497693538576973.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.17 | sMAPE for Validation Set is: 7.24% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 13.71% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:10:51,250]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:10:57,206]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:05,140]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:09,255]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:12,467]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:19,900]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:24,902]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:25,108]\u001b[0m Trial 540 finished with value: 2.1898187861273852 and parameters: {'n_hidden': 3, 'learning_rate': 0.005917564895168147, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11272800943134363, 'dropout_rate_Layer_2': 0.19305684531858286, 'dropout_rate_Layer_3': 0.20644686543870963, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.3538687373702964e-05, 'l1_Layer_2': 0.0019756801348694694, 'l1_Layer_3': 0.002583324248443185, 'n_units_Layer_1': 55, 'n_units_Layer_2': 210, 'n_units_Layer_3': 235}. Best is trial 511 with value: 2.0497693538576973.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.19 | sMAPE for Validation Set is: 7.29% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.05 | sMAPE for Test Set is: 27.08% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:11:29,376]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:32,278]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:36,386]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:37,013]\u001b[0m Trial 527 finished with value: 2.1380810984641703 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006096126884587867, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020047370008446773, 'dropout_rate_Layer_2': 0.07082143328389305, 'dropout_rate_Layer_3': 0.0011763915169612053, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022668228520658375, 'l1_Layer_2': 3.123738325415887e-05, 'l1_Layer_3': 0.02515303936172896, 'n_units_Layer_1': 100, 'n_units_Layer_2': 130, 'n_units_Layer_3': 180}. Best is trial 511 with value: 2.0497693538576973.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.13% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 14.62% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:11:39,965]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:41,943]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:42,966]\u001b[0m Trial 539 finished with value: 2.1493782775495305 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008242700086019447, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.060178206728527646, 'dropout_rate_Layer_2': 0.0362536683161878, 'dropout_rate_Layer_3': 0.032083683907275416, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.10828371450631e-05, 'l1_Layer_2': 1.6788524131364235e-05, 'l1_Layer_3': 0.007237997038971948, 'n_units_Layer_1': 50, 'n_units_Layer_2': 230, 'n_units_Layer_3': 175}. Best is trial 511 with value: 2.0497693538576973.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.15 | sMAPE for Validation Set is: 7.19% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.13 | sMAPE for Test Set is: 16.79% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:11:43,197]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:43,420]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:46,711]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:48,814]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:52,017]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:52,648]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:52,918]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:11:54,794]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:00,102]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:00,209]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:00,521]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:06,486]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:06,696]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:10,345]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:10,711]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:10,711]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:14,993]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:17,368]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:17,525]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:23,494]\u001b[0m Trial 557 finished with value: 2.132689907155667 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028987673198482625, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04530815100565656, 'dropout_rate_Layer_2': 0.31445355592212054, 'dropout_rate_Layer_3': 0.11856310682382018, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.8663728251563034e-05, 'l1_Layer_2': 0.0012716324985526611, 'l1_Layer_3': 0.002083538240674403, 'n_units_Layer_1': 65, 'n_units_Layer_2': 190, 'n_units_Layer_3': 245}. Best is trial 511 with value: 2.0497693538576973.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 7.08% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 15.09% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:12:29,960]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:32,579]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:35,230]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:41,407]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:46,820]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:48,892]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:50,787]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:53,274]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:54,050]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:12:57,933]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:13:01,066]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:13:17,045]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:13:19,824]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:13:23,384]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:13:23,609]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:13:24,238]\u001b[0m Trial 573 finished with value: 2.052836148081767 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029379291840899023, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04733543634191671, 'dropout_rate_Layer_2': 0.31082791737686133, 'dropout_rate_Layer_3': 0.09952458176189552, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.8408050823855233e-05, 'l1_Layer_2': 0.0013734861899282302, 'l1_Layer_3': 0.0008338414099426222, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 225}. Best is trial 511 with value: 2.0497693538576973.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 6.84% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 16.20% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:13:30,486]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:13:30,736]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:13:36,443]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 7.16% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.92 | sMAPE for Test Set is: 11.58% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:13:38,729]\u001b[0m Trial 580 finished with value: 2.129982271221097 and parameters: {'n_hidden': 4, 'learning_rate': 0.0029070782382998373, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14795695023440822, 'dropout_rate_Layer_2': 0.1543632339864117, 'dropout_rate_Layer_3': 0.32319647797718387, 'dropout_rate_Layer_4': 0.057097947211635164, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01033201014549659, 'l1_Layer_2': 0.004206160683728006, 'l1_Layer_3': 0.0005451210572411071, 'l1_Layer_4': 0.0025330199134233483, 'n_units_Layer_1': 50, 'n_units_Layer_2': 170, 'n_units_Layer_3': 300, 'n_units_Layer_4': 140}. Best is trial 511 with value: 2.0497693538576973.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:13:43,993]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:13:46,811]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:13:52,846]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:13:54,161]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:14:15,234]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:14:26,943]\u001b[0m Trial 590 finished with value: 2.135734453263451 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021419204452046217, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013257066376297418, 'dropout_rate_Layer_2': 0.3208374596891223, 'dropout_rate_Layer_3': 0.08664271114523117, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.14263554907327e-05, 'l1_Layer_2': 0.000707395110803549, 'l1_Layer_3': 0.0006645208616740096, 'n_units_Layer_1': 85, 'n_units_Layer_2': 195, 'n_units_Layer_3': 220}. Best is trial 511 with value: 2.0497693538576973.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.15% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 15.55% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:14:30,782]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:14:50,946]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:14:59,545]\u001b[0m Trial 592 finished with value: 2.1176389693769884 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009368848393606481, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0008154347640994635, 'dropout_rate_Layer_2': 0.07969594090937857, 'dropout_rate_Layer_3': 0.0003136840024711915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.022739877651119393, 'l1_Layer_2': 3.096537333770036e-05, 'l1_Layer_3': 0.005717602840674567, 'n_units_Layer_1': 95, 'n_units_Layer_2': 120, 'n_units_Layer_3': 260}. Best is trial 511 with value: 2.0497693538576973.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 7.08% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 3.09 | sMAPE for Test Set is: 7.67% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:14:59,931]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:15:01,623]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:15:06,978]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:15:09,720]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:15:15,503]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:15:20,129]\u001b[0m Trial 595 finished with value: 1.9827726508607633 and parameters: {'n_hidden': 3, 'learning_rate': 0.002261498367520464, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01126365672610332, 'dropout_rate_Layer_2': 0.30274798760694277, 'dropout_rate_Layer_3': 0.09014964290856071, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.1948667500927728e-05, 'l1_Layer_2': 0.000844466814658318, 'l1_Layer_3': 0.0009441676637714214, 'n_units_Layer_1': 85, 'n_units_Layer_2': 195, 'n_units_Layer_3': 220}. Best is trial 595 with value: 1.9827726508607633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 6.59% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.69 | sMAPE for Test Set is: 13.39% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:15:30,570]\u001b[0m Trial 605 finished with value: 2.127040947011951 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025240474687633773, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04208072960719549, 'dropout_rate_Layer_2': 0.31445264839111403, 'dropout_rate_Layer_3': 0.09769303608280958, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.0932428840112112e-05, 'l1_Layer_2': 0.0017010541089834978, 'l1_Layer_3': 0.0008783793307996714, 'n_units_Layer_1': 70, 'n_units_Layer_2': 180, 'n_units_Layer_3': 235}. Best is trial 595 with value: 1.9827726508607633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 7.08% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.15 | sMAPE for Test Set is: 16.84% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:15:33,139]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:15:33,714]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:15:37,294]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:15:39,364]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:15:40,222]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:15:43,232]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:15:46,079]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:15:50,547]\u001b[0m Trial 603 finished with value: 2.2463772102086015 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015098174722039666, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1102448210777861, 'dropout_rate_Layer_2': 0.22362666238353765, 'dropout_rate_Layer_3': 0.323274087670482, 'dropout_rate_Layer_4': 0.29263334580705724, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.005014146719995165, 'l1_Layer_2': 0.000415047441236861, 'l1_Layer_3': 0.0002490628032665994, 'l1_Layer_4': 0.0059512210049709685, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 275, 'n_units_Layer_4': 190}. Best is trial 595 with value: 1.9827726508607633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.25 | sMAPE for Validation Set is: 7.45% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.67 | sMAPE for Test Set is: 20.69% | rMAE for Test Set is: 1.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:15:55,448]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:16:06,801]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:16:15,402]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:17:14,778]\u001b[0m Trial 619 finished with value: 2.0698592059838705 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016182968557323248, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005646559822086807, 'dropout_rate_Layer_2': 0.32899180386045046, 'dropout_rate_Layer_3': 0.09575591673626006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.0747918734389129e-05, 'l1_Layer_2': 0.001226257360442982, 'l1_Layer_3': 0.0009705916063818113, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 225}. Best is trial 595 with value: 1.9827726508607633.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.89% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.05 | sMAPE for Test Set is: 16.57% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:17:18,097]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:17:21,440]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:17:23,395]\u001b[0m Trial 607 finished with value: 1.960364220457592 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016955258228562814, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005326206344781999, 'dropout_rate_Layer_2': 0.20524436764174825, 'dropout_rate_Layer_3': 0.08893841332358965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.1499369734725734e-05, 'l1_Layer_2': 0.0006651013425013387, 'l1_Layer_3': 0.0008117793952982733, 'n_units_Layer_1': 75, 'n_units_Layer_2': 180, 'n_units_Layer_3': 215}. Best is trial 607 with value: 1.960364220457592.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 6.50% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.63 | sMAPE for Test Set is: 13.16% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:17:26,051]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:17:31,744]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:17:36,394]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:17:36,577]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:18:01,617]\u001b[0m Trial 614 finished with value: 2.0206979303786206 and parameters: {'n_hidden': 3, 'learning_rate': 0.002289493728797962, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.038596145214503205, 'dropout_rate_Layer_2': 0.2819861412554144, 'dropout_rate_Layer_3': 0.0946320882099936, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.660564289651086e-05, 'l1_Layer_2': 0.001140648160516132, 'l1_Layer_3': 0.0007270988323205289, 'n_units_Layer_1': 75, 'n_units_Layer_2': 180, 'n_units_Layer_3': 215}. Best is trial 607 with value: 1.960364220457592.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 6.72% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.22 | sMAPE for Test Set is: 14.67% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:18:17,025]\u001b[0m Trial 615 finished with value: 1.979562837780077 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021638244192102563, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006807603632319947, 'dropout_rate_Layer_2': 0.292540102849237, 'dropout_rate_Layer_3': 0.08605938772100169, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.3156363844961016e-05, 'l1_Layer_2': 0.0011356815249494849, 'l1_Layer_3': 0.0009831854115872041, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 225}. Best is trial 607 with value: 1.960364220457592.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 6.55% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.94 | sMAPE for Test Set is: 16.38% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:18:18,605]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:18:21,290]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:18:24,175]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:18:27,881]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:18:28,295]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:18:32,374]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:18:35,041]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:18:39,184]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:18:39,451]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:18:44,063]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:18:47,222]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:18:51,271]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:18:51,483]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:19:13,588]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:19:16,723]\u001b[0m Trial 642 finished with value: 2.215949345780485 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019521640212778035, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17234241044562798, 'dropout_rate_Layer_2': 0.1219375639243333, 'dropout_rate_Layer_3': 0.040455027565596, 'dropout_rate_Layer_4': 0.28245428489357605, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.006420549647343371, 'l1_Layer_2': 0.0007387784549173741, 'l1_Layer_3': 0.000463135622530584, 'l1_Layer_4': 0.03376174762183454, 'n_units_Layer_1': 90, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285, 'n_units_Layer_4': 205}. Best is trial 607 with value: 1.960364220457592.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.22 | sMAPE for Validation Set is: 7.42% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.51 | sMAPE for Test Set is: 25.53% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:19:20,544]\u001b[0m Trial 626 finished with value: 2.093213010393707 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022227045338984804, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01217335648520089, 'dropout_rate_Layer_2': 0.33155666495925973, 'dropout_rate_Layer_3': 0.09491454300078572, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.457869720432984e-05, 'l1_Layer_2': 0.0011061891312019571, 'l1_Layer_3': 0.0009322323330212769, 'n_units_Layer_1': 80, 'n_units_Layer_2': 195, 'n_units_Layer_3': 210}. Best is trial 607 with value: 1.960364220457592.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.98% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.59 | sMAPE for Test Set is: 15.57% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:19:20,888]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:19:30,139]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:19:33,030]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:19:33,571]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:19:37,365]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:19:41,647]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:19:41,907]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:19:47,020]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:19:49,847]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:19:54,654]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:19:57,630]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:20:02,877]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:20:05,905]\u001b[0m Trial 641 finished with value: 2.123157852934725 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007395251670433502, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16917761408609305, 'dropout_rate_Layer_2': 0.19092698385882964, 'dropout_rate_Layer_3': 0.2709340409441766, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005709128263951513, 'l1_Layer_2': 0.0010707081765283148, 'l1_Layer_3': 0.00048180912362964285, 'n_units_Layer_1': 90, 'n_units_Layer_2': 180, 'n_units_Layer_3': 275}. Best is trial 607 with value: 1.960364220457592.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 7.10% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.95 | sMAPE for Test Set is: 11.67% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:20:07,540]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:20:11,159]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:20:16,133]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:20:16,659]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:20:20,159]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:20:23,778]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:20:24,340]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:20:28,636]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:20:37,190]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:20:40,471]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:20:46,823]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:20:53,251]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:20:58,965]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:21:02,555]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:21:07,037]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:21:10,836]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:21:25,081]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:21:32,373]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:21:36,368]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:21:41,798]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:21:48,291]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:21:54,176]\u001b[0m Trial 669 finished with value: 2.0373358681748033 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019222365833593753, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026429036890101502, 'dropout_rate_Layer_2': 0.29880522853173885, 'dropout_rate_Layer_3': 0.11441103782079914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.240523084234009e-05, 'l1_Layer_2': 0.0013952278998198785, 'l1_Layer_3': 0.0005274748014929477, 'n_units_Layer_1': 75, 'n_units_Layer_2': 175, 'n_units_Layer_3': 220}. Best is trial 607 with value: 1.960364220457592.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 6.83% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.88 | sMAPE for Test Set is: 13.87% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:22:00,516]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:22:02,948]\u001b[0m Trial 665 finished with value: 1.9686910825956687 and parameters: {'n_hidden': 3, 'learning_rate': 0.002111682857453015, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025852574944551766, 'dropout_rate_Layer_2': 0.31447376188541465, 'dropout_rate_Layer_3': 0.09165383668586194, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.266326498019969e-05, 'l1_Layer_2': 0.0016740376830160501, 'l1_Layer_3': 0.000497852341407636, 'n_units_Layer_1': 75, 'n_units_Layer_2': 175, 'n_units_Layer_3': 225}. Best is trial 607 with value: 1.960364220457592.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 6.54% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.38 | sMAPE for Test Set is: 12.62% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:22:04,875]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:22:07,884]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:22:14,558]\u001b[0m Trial 649 finished with value: 1.948583969412791 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014266242240277968, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022030130904153913, 'dropout_rate_Layer_2': 0.20642492516046773, 'dropout_rate_Layer_3': 0.1000312131882511, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.6630181238213143e-05, 'l1_Layer_2': 0.0007101801309001369, 'l1_Layer_3': 0.0012890356053828602, 'n_units_Layer_1': 85, 'n_units_Layer_2': 210, 'n_units_Layer_3': 210}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 6.47% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.88 | sMAPE for Test Set is: 13.73% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:22:17,736]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:22:20,955]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:23:00,472]\u001b[0m Trial 684 finished with value: 2.031260513362494 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022396079288684537, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024393980829018086, 'dropout_rate_Layer_2': 0.31198184450770206, 'dropout_rate_Layer_3': 0.08293338787810045, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.3703754001852351e-05, 'l1_Layer_2': 0.0014463737826800472, 'l1_Layer_3': 0.000525056099061213, 'n_units_Layer_1': 85, 'n_units_Layer_2': 190, 'n_units_Layer_3': 155}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 6.75% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.27 | sMAPE for Test Set is: 14.74% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:23:03,531]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:23:03,805]\u001b[0m Trial 681 finished with value: 2.061737384511994 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006061551805450474, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06224400244777327, 'dropout_rate_Layer_2': 0.03380303508386372, 'dropout_rate_Layer_3': 0.09321777034557113, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026741567962614244, 'l1_Layer_2': 0.00011551916101869438, 'l1_Layer_3': 0.0006324059808068232, 'n_units_Layer_1': 190, 'n_units_Layer_2': 140, 'n_units_Layer_3': 205}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.87% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.37 | sMAPE for Test Set is: 12.61% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:23:09,741]\u001b[0m Trial 683 finished with value: 2.009611655431531 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014255863168152222, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02795334460263152, 'dropout_rate_Layer_2': 0.2861219514910999, 'dropout_rate_Layer_3': 0.0824380188093661, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.6721569690654674e-05, 'l1_Layer_2': 0.0013871218393099684, 'l1_Layer_3': 0.000670867258641232, 'n_units_Layer_1': 75, 'n_units_Layer_2': 165, 'n_units_Layer_3': 210}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 6.68% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 13.63% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:23:10,370]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:23:15,808]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:23:22,183]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:23:22,538]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:23:23,528]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:23:28,652]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:23:30,877]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:23:35,129]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:23:38,735]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:23:46,398]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:23:53,253]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:23:55,590]\u001b[0m Trial 690 finished with value: 2.2404853290152946 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015196215733759382, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1580489023399042, 'dropout_rate_Layer_2': 0.19579038665410625, 'dropout_rate_Layer_3': 0.08475264747727629, 'dropout_rate_Layer_4': 0.2855220823060116, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.004820918163236912, 'l1_Layer_2': 0.00044894394603412174, 'l1_Layer_3': 0.0005043808148338045, 'l1_Layer_4': 0.03145059395513252, 'n_units_Layer_1': 120, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275, 'n_units_Layer_4': 225}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.24 | sMAPE for Validation Set is: 7.41% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.52 | sMAPE for Test Set is: 25.55% | rMAE for Test Set is: 2.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:23:59,450]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:24:07,251]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:24:14,643]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:24:17,435]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:24:20,089]\u001b[0m Trial 699 finished with value: 2.2886450426449767 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015266787467090011, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15703298855011927, 'dropout_rate_Layer_2': 0.3200552412885097, 'dropout_rate_Layer_3': 0.3352292170388961, 'dropout_rate_Layer_4': 0.19624982993732035, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0040958568197594905, 'l1_Layer_2': 0.0004062602934750429, 'l1_Layer_3': 0.0005564517185293638, 'l1_Layer_4': 0.031317367944122966, 'n_units_Layer_1': 80, 'n_units_Layer_2': 140, 'n_units_Layer_3': 275, 'n_units_Layer_4': 210}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.29 | sMAPE for Validation Set is: 7.78% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.96 | sMAPE for Test Set is: 21.44% | rMAE for Test Set is: 1.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:24:23,288]\u001b[0m Trial 703 finished with value: 2.170185922350963 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016056558703838998, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15675627328235348, 'dropout_rate_Layer_2': 0.1674961146611143, 'dropout_rate_Layer_3': 0.12799631156780453, 'dropout_rate_Layer_4': 0.1933708186988919, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.009476503402674297, 'l1_Layer_2': 0.0003496464966956002, 'l1_Layer_3': 0.0005652473605036422, 'l1_Layer_4': 0.02572024330024429, 'n_units_Layer_1': 130, 'n_units_Layer_2': 145, 'n_units_Layer_3': 60, 'n_units_Layer_4': 255}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.17 | sMAPE for Validation Set is: 7.19% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.34 | sMAPE for Test Set is: 25.07% | rMAE for Test Set is: 1.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:24:23,786]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:24:27,715]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:24:30,782]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:24:32,358]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:24:42,001]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:24:44,169]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:24:47,896]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:24:48,603]\u001b[0m Trial 696 finished with value: 2.092088767119182 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019042572068620623, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03910069899682144, 'dropout_rate_Layer_2': 0.2055747786410501, 'dropout_rate_Layer_3': 0.09239163474024194, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.4825676275873514e-05, 'l1_Layer_2': 0.0015465163828147401, 'l1_Layer_3': 0.0011921279697940438, 'n_units_Layer_1': 90, 'n_units_Layer_2': 195, 'n_units_Layer_3': 170}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.95% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.04 | sMAPE for Test Set is: 16.61% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:24:52,871]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:24:57,051]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:24:59,238]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:25:14,158]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:25:47,904]\u001b[0m Trial 713 finished with value: 2.1019410524954343 and parameters: {'n_hidden': 3, 'learning_rate': 0.002060285202569338, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01748450321325767, 'dropout_rate_Layer_2': 0.31711142726679165, 'dropout_rate_Layer_3': 0.09431999536307037, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.311294178111081e-05, 'l1_Layer_2': 0.001694664063770101, 'l1_Layer_3': 0.0009237287171094345, 'n_units_Layer_1': 85, 'n_units_Layer_2': 195, 'n_units_Layer_3': 115}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 6.98% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.03 | sMAPE for Test Set is: 16.55% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:25:50,823]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:25:54,698]\u001b[0m Trial 719 finished with value: 2.117551413603557 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021288235434489887, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018253073642841226, 'dropout_rate_Layer_2': 0.29672766635786224, 'dropout_rate_Layer_3': 0.07351123993046878, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.1123022811717245e-05, 'l1_Layer_2': 0.0017244751520244716, 'l1_Layer_3': 0.0009100792854842074, 'n_units_Layer_1': 85, 'n_units_Layer_2': 195, 'n_units_Layer_3': 175}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 7.05% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.15 | sMAPE for Test Set is: 16.87% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:25:58,253]\u001b[0m Trial 720 finished with value: 2.1143773014274614 and parameters: {'n_hidden': 3, 'learning_rate': 0.002082064624086916, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01887295832168744, 'dropout_rate_Layer_2': 0.31675138111308526, 'dropout_rate_Layer_3': 0.07389086541742197, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.412117948103463e-05, 'l1_Layer_2': 0.001904970994748513, 'l1_Layer_3': 0.0009119988652716749, 'n_units_Layer_1': 85, 'n_units_Layer_2': 195, 'n_units_Layer_3': 180}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 7.01% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 16.38% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:25:58,813]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:25:59,192]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:26:07,850]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:26:10,719]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:26:19,486]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:26:23,858]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:26:27,918]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:26:35,469]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:26:41,744]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:26:44,889]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:26:46,912]\u001b[0m Trial 724 finished with value: 2.1368793242825697 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020379093471673535, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020126594438154812, 'dropout_rate_Layer_2': 0.26310639252405793, 'dropout_rate_Layer_3': 0.06658364377849485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.272795378150182e-05, 'l1_Layer_2': 0.013427585004295615, 'l1_Layer_3': 0.0009422410200831512, 'n_units_Layer_1': 90, 'n_units_Layer_2': 175, 'n_units_Layer_3': 180}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.08% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.15 | sMAPE for Test Set is: 16.85% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:26:49,391]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:26:52,102]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:26:52,267]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:26:53,085]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:26:58,876]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:26:59,995]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:27:03,659]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:27:07,807]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:27:10,812]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:27:12,599]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:27:28,160]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:27:59,506]\u001b[0m Trial 729 finished with value: 2.0862911148533034 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026528466602332252, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005232655637562099, 'dropout_rate_Layer_2': 0.31828331743312765, 'dropout_rate_Layer_3': 0.033804937042950844, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.8912785946583363e-05, 'l1_Layer_2': 0.0012502925481202663, 'l1_Layer_3': 0.0012498362217920726, 'n_units_Layer_1': 95, 'n_units_Layer_2': 175, 'n_units_Layer_3': 175}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.93% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.32 | sMAPE for Test Set is: 14.83% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:28:06,544]\u001b[0m Trial 745 finished with value: 2.1086248943481585 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016053443046846342, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03902332370753287, 'dropout_rate_Layer_2': 0.308011976667872, 'dropout_rate_Layer_3': 0.09133511971820336, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.292882460707998e-05, 'l1_Layer_2': 0.008470798005435837, 'l1_Layer_3': 0.0008479308873682675, 'n_units_Layer_1': 95, 'n_units_Layer_2': 170, 'n_units_Layer_3': 175}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 6.98% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.21 | sMAPE for Test Set is: 17.01% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:28:10,427]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:28:10,814]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:28:15,857]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:28:18,697]\u001b[0m Trial 740 finished with value: 2.167671293146783 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018636467813177595, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03081586961240912, 'dropout_rate_Layer_2': 0.29253636117139703, 'dropout_rate_Layer_3': 0.040282896374856964, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.2449179815706546e-05, 'l1_Layer_2': 0.015662469121817308, 'l1_Layer_3': 0.0006735908415102973, 'n_units_Layer_1': 95, 'n_units_Layer_2': 170, 'n_units_Layer_3': 125}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.17 | sMAPE for Validation Set is: 7.22% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.22 | sMAPE for Test Set is: 14.67% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:28:21,623]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:28:24,039]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:28:24,266]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:28:29,335]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:28:32,028]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:28:33,635]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:28:40,470]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:28:47,820]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:28:48,095]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:28:53,992]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:28:56,618]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:28:59,874]\u001b[0m Trial 750 finished with value: 2.2233048335311576 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019503110230549084, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20487026983560475, 'dropout_rate_Layer_2': 0.19519165961469429, 'dropout_rate_Layer_3': 0.09349534551299657, 'dropout_rate_Layer_4': 0.2735851336174354, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.007588341916022268, 'l1_Layer_2': 0.0007253783618254123, 'l1_Layer_3': 1.878978906545323e-05, 'l1_Layer_4': 0.023256752631733935, 'n_units_Layer_1': 120, 'n_units_Layer_2': 170, 'n_units_Layer_3': 175, 'n_units_Layer_4': 225}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.22 | sMAPE for Validation Set is: 7.42% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.63 | sMAPE for Test Set is: 28.72% | rMAE for Test Set is: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:29:00,417]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:29:05,319]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:29:05,751]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:29:11,170]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:29:12,689]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:29:17,015]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:29:22,485]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:29:35,791]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:29:36,094]\u001b[0m Trial 763 finished with value: 2.1562701851029638 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020374096750567492, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04302996615479218, 'dropout_rate_Layer_2': 0.31220023589685947, 'dropout_rate_Layer_3': 0.09052683292918431, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.0060494156058698e-05, 'l1_Layer_2': 0.008878467592603169, 'l1_Layer_3': 0.00083255794241747, 'n_units_Layer_1': 90, 'n_units_Layer_2': 195, 'n_units_Layer_3': 170}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 7.18% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 15.50% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:29:42,549]\u001b[0m Trial 755 finished with value: 2.0934142985690234 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014836975180714225, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006170816763478554, 'dropout_rate_Layer_2': 0.3272698208446056, 'dropout_rate_Layer_3': 0.09248420203125829, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.8946505195633754e-05, 'l1_Layer_2': 0.01181396434386158, 'l1_Layer_3': 0.0004999775399962901, 'n_units_Layer_1': 85, 'n_units_Layer_2': 160, 'n_units_Layer_3': 175}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.93% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 15.98% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:29:51,041]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:29:55,830]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:29:58,656]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:30:03,346]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:30:06,859]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:30:10,743]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:30:12,090]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:30:17,199]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:30:17,793]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:30:21,600]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:30:24,668]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:30:27,341]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:30:28,043]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:30:39,834]\u001b[0m Trial 774 finished with value: 2.1257769021242026 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017158922291381296, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005317827221600578, 'dropout_rate_Layer_2': 0.3228478627694629, 'dropout_rate_Layer_3': 0.0769034705322179, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.74012315240231e-05, 'l1_Layer_2': 0.0011618308374528022, 'l1_Layer_3': 0.0011573374158235534, 'n_units_Layer_1': 75, 'n_units_Layer_2': 165, 'n_units_Layer_3': 180}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 7.05% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.23 | sMAPE for Test Set is: 17.07% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:30:42,999]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:30:44,767]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:30:47,421]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:30:51,998]\u001b[0m Trial 784 finished with value: 2.2206492365671937 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018399015005542622, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1421588493698363, 'dropout_rate_Layer_2': 0.1919662345221498, 'dropout_rate_Layer_3': 0.08454749302529496, 'dropout_rate_Layer_4': 0.3123516964355696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.005747120008641302, 'l1_Layer_2': 2.3609364360089592e-05, 'l1_Layer_3': 0.0004657580808731839, 'l1_Layer_4': 0.0034052669881455212, 'n_units_Layer_1': 110, 'n_units_Layer_2': 145, 'n_units_Layer_3': 50, 'n_units_Layer_4': 250}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.22 | sMAPE for Validation Set is: 7.44% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.18 | sMAPE for Test Set is: 16.87% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:31:06,882]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:31:20,780]\u001b[0m Trial 792 finished with value: 2.179499440930187 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019184972305611944, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16094575930131, 'dropout_rate_Layer_2': 0.28457445145225724, 'dropout_rate_Layer_3': 0.08345189031439806, 'dropout_rate_Layer_4': 0.3027608799030809, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.004129919151744876, 'l1_Layer_2': 0.00033351881919364737, 'l1_Layer_3': 5.3136330262721746e-05, 'l1_Layer_4': 0.0017675697714788809, 'n_units_Layer_1': 180, 'n_units_Layer_2': 130, 'n_units_Layer_3': 200, 'n_units_Layer_4': 250}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.18 | sMAPE for Validation Set is: 7.28% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.71 | sMAPE for Test Set is: 15.73% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:31:25,933]\u001b[0m Trial 791 finished with value: 2.1887835545424417 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012019767765682492, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1599915147211622, 'dropout_rate_Layer_2': 0.28373829245312826, 'dropout_rate_Layer_3': 0.10993049569102703, 'dropout_rate_Layer_4': 0.35495168420263035, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00829299614643262, 'l1_Layer_2': 0.00033045377692815964, 'l1_Layer_3': 0.00043241909308843336, 'l1_Layer_4': 0.0013360787493872195, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 50, 'n_units_Layer_4': 235}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.19 | sMAPE for Validation Set is: 7.29% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.18 | sMAPE for Test Set is: 16.87% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:31:44,969]\u001b[0m Trial 795 finished with value: 2.194877915453423 and parameters: {'n_hidden': 4, 'learning_rate': 0.001936794191926519, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14148041601099384, 'dropout_rate_Layer_2': 0.05818074850877669, 'dropout_rate_Layer_3': 0.10667316440961827, 'dropout_rate_Layer_4': 0.34726805161449487, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0073112769396690945, 'l1_Layer_2': 0.00015899217025336249, 'l1_Layer_3': 5.42486257752235e-05, 'l1_Layer_4': 0.0013897698863133906, 'n_units_Layer_1': 180, 'n_units_Layer_2': 125, 'n_units_Layer_3': 50, 'n_units_Layer_4': 250}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.19 | sMAPE for Validation Set is: 7.40% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.43 | sMAPE for Test Set is: 22.68% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:31:49,711]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:31:56,597]\u001b[0m Trial 796 finished with value: 2.1707130652788185 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009336734014900398, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13044133758554832, 'dropout_rate_Layer_2': 0.29625223321997557, 'dropout_rate_Layer_3': 0.10890624162295284, 'dropout_rate_Layer_4': 0.34365495176490957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0035731006668173445, 'l1_Layer_2': 0.00023998346067179664, 'l1_Layer_3': 5.505472550814191e-05, 'l1_Layer_4': 0.0014310932963194807, 'n_units_Layer_1': 90, 'n_units_Layer_2': 130, 'n_units_Layer_3': 55, 'n_units_Layer_4': 245}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.17 | sMAPE for Validation Set is: 7.29% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.38 | sMAPE for Test Set is: 22.53% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:31:57,092]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:32:05,679]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:32:09,353]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:32:15,326]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:32:15,580]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:32:19,579]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:32:23,344]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:32:23,624]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:32:27,989]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:32:28,501]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:32:33,359]\u001b[0m Trial 788 finished with value: 2.081926374888287 and parameters: {'n_hidden': 3, 'learning_rate': 0.001549385524863152, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007422629018069849, 'dropout_rate_Layer_2': 0.28868008084887775, 'dropout_rate_Layer_3': 0.07572150715339462, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.8332890763219732e-05, 'l1_Layer_2': 0.011262798485319653, 'l1_Layer_3': 0.001142971127069105, 'n_units_Layer_1': 75, 'n_units_Layer_2': 185, 'n_units_Layer_3': 180}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.91% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.48 | sMAPE for Test Set is: 12.87% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:32:36,427]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:32:46,248]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:32:46,390]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:32:50,803]\u001b[0m Trial 797 finished with value: 2.1724228977935054 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012320187987591344, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012754320886957087, 'dropout_rate_Layer_2': 0.33107257881789853, 'dropout_rate_Layer_3': 0.09692981968009695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.538232484460771e-05, 'l1_Layer_2': 0.0011799772445469947, 'l1_Layer_3': 0.0011673783949157216, 'n_units_Layer_1': 70, 'n_units_Layer_2': 165, 'n_units_Layer_3': 175}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.17 | sMAPE for Validation Set is: 7.23% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.27 | sMAPE for Test Set is: 14.71% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:32:52,969]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:32:55,244]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:32:55,751]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:32:57,540]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:33:02,345]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:33:02,559]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:33:10,600]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:33:11,264]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:33:14,490]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:33:15,880]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:33:19,410]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:33:27,786]\u001b[0m Trial 818 finished with value: 2.158266726028542 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011860179323538243, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1259725715642517, 'dropout_rate_Layer_2': 0.0026758812322623393, 'dropout_rate_Layer_3': 0.15709929319723212, 'dropout_rate_Layer_4': 0.3760851316062218, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.003514261775441741, 'l1_Layer_2': 0.00015373495185765765, 'l1_Layer_3': 5.4207214678933e-05, 'l1_Layer_4': 0.0014244693668392238, 'n_units_Layer_1': 90, 'n_units_Layer_2': 130, 'n_units_Layer_3': 50, 'n_units_Layer_4': 250}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 7.22% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.35 | sMAPE for Test Set is: 22.44% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:33:34,380]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:33:38,331]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:33:41,736]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:33:42,090]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:33:47,241]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:33:59,022]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:34:03,333]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:34:13,607]\u001b[0m Trial 811 finished with value: 2.1346596099810893 and parameters: {'n_hidden': 3, 'learning_rate': 0.001337595810519736, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.003459445387392496, 'dropout_rate_Layer_2': 0.3188064514875209, 'dropout_rate_Layer_3': 0.09619643484378491, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.420537035786511e-05, 'l1_Layer_2': 0.0011985438189095388, 'l1_Layer_3': 0.0016019082545473962, 'n_units_Layer_1': 70, 'n_units_Layer_2': 185, 'n_units_Layer_3': 185}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 7.12% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.86 | sMAPE for Test Set is: 16.24% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:34:15,769]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:34:22,058]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:34:26,912]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:34:34,228]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:34:41,289]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:34:50,808]\u001b[0m Trial 833 finished with value: 2.148682674375992 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020295447736347542, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020008373302013355, 'dropout_rate_Layer_2': 0.2728479280256941, 'dropout_rate_Layer_3': 0.06464956277325688, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.839058680247096e-05, 'l1_Layer_2': 0.0013283162616889886, 'l1_Layer_3': 0.0009725613246757004, 'n_units_Layer_1': 85, 'n_units_Layer_2': 180, 'n_units_Layer_3': 175}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.15 | sMAPE for Validation Set is: 7.15% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.01 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 1.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:34:53,937]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:34:59,620]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:35:04,826]\u001b[0m Trial 835 finished with value: 2.1236208903634126 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008746961820319098, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16429036426701896, 'dropout_rate_Layer_2': 0.008631760114674277, 'dropout_rate_Layer_3': 0.1574449156165692, 'dropout_rate_Layer_4': 0.3793943449970011, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.004183650420680535, 'l1_Layer_2': 0.0002701119015412327, 'l1_Layer_3': 7.848985168922449e-05, 'l1_Layer_4': 0.0017335466943412335, 'n_units_Layer_1': 85, 'n_units_Layer_2': 125, 'n_units_Layer_3': 55, 'n_units_Layer_4': 240}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 7.10% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.86 | sMAPE for Test Set is: 21.17% | rMAE for Test Set is: 1.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:35:17,107]\u001b[0m Trial 839 finished with value: 2.121355571427159 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009979577523585447, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1167533650238069, 'dropout_rate_Layer_2': 0.2922900028896738, 'dropout_rate_Layer_3': 0.10072414661121315, 'dropout_rate_Layer_4': 0.3312748227276673, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.007209442412078621, 'l1_Layer_2': 0.0003030333825704704, 'l1_Layer_3': 9.158234019461902e-05, 'l1_Layer_4': 0.0009431348785290914, 'n_units_Layer_1': 75, 'n_units_Layer_2': 135, 'n_units_Layer_3': 50, 'n_units_Layer_4': 265}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 7.11% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.28 | sMAPE for Test Set is: 22.25% | rMAE for Test Set is: 1.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:35:29,479]\u001b[0m Trial 831 finished with value: 2.136499869614784 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019281620526760566, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02897523326966509, 'dropout_rate_Layer_2': 0.31589418206779324, 'dropout_rate_Layer_3': 0.10517472095740024, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.4070390913309767e-05, 'l1_Layer_2': 0.00693581055978487, 'l1_Layer_3': 0.0007237179130461105, 'n_units_Layer_1': 85, 'n_units_Layer_2': 200, 'n_units_Layer_3': 170}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.12% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 16.07% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:35:31,812]\u001b[0m Trial 843 finished with value: 2.173290578950495 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010046799167669292, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12284797650987672, 'dropout_rate_Layer_2': 0.019964547715167053, 'dropout_rate_Layer_3': 0.141001850214717, 'dropout_rate_Layer_4': 0.3315083970314025, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0037767064956895995, 'l1_Layer_2': 0.00016584117028076368, 'l1_Layer_3': 6.0994366225987625e-05, 'l1_Layer_4': 0.0009451519067611578, 'n_units_Layer_1': 85, 'n_units_Layer_2': 110, 'n_units_Layer_3': 50, 'n_units_Layer_4': 265}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.17 | sMAPE for Validation Set is: 7.28% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.51 | sMAPE for Test Set is: 22.87% | rMAE for Test Set is: 1.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:35:34,118]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:35:37,184]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:35:40,596]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:35:43,845]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:35:51,213]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:35:54,712]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:35:55,428]\u001b[0m Trial 846 finished with value: 2.144645298064532 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010226643934550285, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11866768915651514, 'dropout_rate_Layer_2': 0.027006734715092236, 'dropout_rate_Layer_3': 0.1407376382540492, 'dropout_rate_Layer_4': 0.33656767004342597, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0034276965589591546, 'l1_Layer_2': 0.00017331538842064515, 'l1_Layer_3': 6.212769755472208e-05, 'l1_Layer_4': 0.0010433541464870636, 'n_units_Layer_1': 75, 'n_units_Layer_2': 105, 'n_units_Layer_3': 50, 'n_units_Layer_4': 265}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.16% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.64 | sMAPE for Test Set is: 25.93% | rMAE for Test Set is: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:36:01,972]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:36:02,211]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:36:03,407]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:36:08,409]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:36:11,062]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:36:11,459]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:36:11,691]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:36:17,823]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:36:21,486]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:36:22,475]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:36:25,879]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:36:26,630]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:36:30,831]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:36:34,555]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:36:37,821]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:36:42,581]\u001b[0m Trial 860 finished with value: 2.1184070312421857 and parameters: {'n_hidden': 4, 'learning_rate': 0.001037741509522928, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0983502529371314, 'dropout_rate_Layer_2': 0.007730837798288502, 'dropout_rate_Layer_3': 0.13881438319816092, 'dropout_rate_Layer_4': 0.32953302693569675, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0020560225410638368, 'l1_Layer_2': 0.00036476428503661346, 'l1_Layer_3': 9.707101139657611e-05, 'l1_Layer_4': 0.001049487615476359, 'n_units_Layer_1': 75, 'n_units_Layer_2': 105, 'n_units_Layer_3': 65, 'n_units_Layer_4': 290}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 7.09% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.39 | sMAPE for Test Set is: 25.25% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:36:55,687]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.20% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.95 | sMAPE for Test Set is: 21.39% | rMAE for Test Set is: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:36:59,558]\u001b[0m Trial 863 finished with value: 2.1437469615883002 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010093969279070974, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09860937397067565, 'dropout_rate_Layer_2': 0.00018219676294996268, 'dropout_rate_Layer_3': 0.1411904433266669, 'dropout_rate_Layer_4': 0.3311814440063396, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0035428049548957724, 'l1_Layer_2': 0.0003341850784294173, 'l1_Layer_3': 6.230312089745056e-05, 'l1_Layer_4': 0.0009859140403722475, 'n_units_Layer_1': 75, 'n_units_Layer_2': 90, 'n_units_Layer_3': 65, 'n_units_Layer_4': 290}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:37:04,702]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:37:06,401]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:37:09,660]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:37:09,754]\u001b[0m Trial 868 finished with value: 2.1814859338579233 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010132466769751164, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10087759555495451, 'dropout_rate_Layer_2': 0.010750171220751345, 'dropout_rate_Layer_3': 0.14470888360769235, 'dropout_rate_Layer_4': 0.3287036870076776, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0034922079601945478, 'l1_Layer_2': 0.00033244538390365274, 'l1_Layer_3': 9.740110535338036e-05, 'l1_Layer_4': 0.0009482755878028311, 'n_units_Layer_1': 75, 'n_units_Layer_2': 85, 'n_units_Layer_3': 65, 'n_units_Layer_4': 265}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.18 | sMAPE for Validation Set is: 7.37% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.59 | sMAPE for Test Set is: 20.46% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:37:10,916]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:37:12,099]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:37:18,427]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:37:18,634]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:37:23,917]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:37:27,253]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:37:29,075]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:37:33,811]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:37:37,887]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:37:41,493]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:37:41,966]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:37:49,622]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:37:53,528]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:38:00,039]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:38:01,752]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:38:03,520]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:38:06,594]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:38:08,452]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:38:11,971]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:38:15,215]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:38:15,702]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:38:20,876]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:38:23,818]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:38:26,565]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:38:29,932]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:38:30,215]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:38:38,465]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:38:41,991]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:38:50,833]\u001b[0m Trial 881 finished with value: 2.127781736846299 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007688776238103168, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08219708990019058, 'dropout_rate_Layer_2': 0.02917661685221118, 'dropout_rate_Layer_3': 0.1906198702918369, 'dropout_rate_Layer_4': 0.30182917490393957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003197318793896403, 'l1_Layer_2': 0.0002146014491517726, 'l1_Layer_3': 8.18357014168408e-05, 'l1_Layer_4': 0.000769542888383867, 'n_units_Layer_1': 90, 'n_units_Layer_2': 100, 'n_units_Layer_3': 55, 'n_units_Layer_4': 265}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 7.16% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.54 | sMAPE for Test Set is: 13.03% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:38:55,705]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:38:57,508]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:01,079]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:05,423]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:08,011]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:08,978]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:12,214]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:14,707]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:15,986]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:20,151]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:20,389]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:20,607]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:27,154]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:33,275]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:36,240]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:36,594]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:37,432]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:42,445]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:45,066]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:45,376]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:46,259]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:53,164]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:39:54,617]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:40:00,135]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:40:01,879]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:40:05,494]\u001b[0m Trial 908 finished with value: 2.0392915276086976 and parameters: {'n_hidden': 3, 'learning_rate': 0.002188972292053457, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014404602859430425, 'dropout_rate_Layer_2': 0.2957775837090348, 'dropout_rate_Layer_3': 0.08780517927892922, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.503156153018274e-05, 'l1_Layer_2': 0.000998532103920785, 'l1_Layer_3': 0.0004581766347985055, 'n_units_Layer_1': 90, 'n_units_Layer_2': 160, 'n_units_Layer_3': 210}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 6.84% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 14.22% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:40:23,366]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:40:26,901]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:40:34,584]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:40:42,277]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:40:45,359]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:40:46,769]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:40:49,832]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:40:54,294]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:40:55,161]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:41:00,089]\u001b[0m Trial 929 finished with value: 2.0860010956208357 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024778479608323065, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016809836884557252, 'dropout_rate_Layer_2': 0.2322407671611892, 'dropout_rate_Layer_3': 0.09360686141548079, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0615594541324039, 'l1_Layer_2': 0.0009871772214735007, 'l1_Layer_3': 0.001133855450172883, 'n_units_Layer_1': 85, 'n_units_Layer_2': 185, 'n_units_Layer_3': 180}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.88% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.55 | sMAPE for Test Set is: 12.99% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:41:02,312]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:41:07,224]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:41:07,452]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:41:14,219]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:41:19,558]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:41:20,293]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:41:24,456]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:41:24,826]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:41:29,245]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:41:29,530]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:41:34,203]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:41:34,698]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:41:39,069]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:41:39,218]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:41:45,283]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:41:52,587]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:41:56,893]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:42:02,666]\u001b[0m Trial 926 finished with value: 2.018542436279176 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019848021912141365, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013018098695595962, 'dropout_rate_Layer_2': 0.21301049623715299, 'dropout_rate_Layer_3': 0.0997914700630774, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.6052712248263384e-05, 'l1_Layer_2': 0.0017275528362471365, 'l1_Layer_3': 0.0011269421794400946, 'n_units_Layer_1': 85, 'n_units_Layer_2': 185, 'n_units_Layer_3': 180}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 6.72% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 13.88% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:42:10,588]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:42:19,863]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:42:25,457]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:42:25,876]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:42:32,615]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:42:38,572]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:42:42,014]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:42:48,041]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:42:55,924]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:42:59,803]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:43:07,736]\u001b[0m Trial 938 finished with value: 2.1207795786280426 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018047653804831557, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0549907102213433, 'dropout_rate_Layer_2': 0.2929678668575106, 'dropout_rate_Layer_3': 0.08225694438863085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.8072529386010774e-05, 'l1_Layer_2': 0.001324514408019816, 'l1_Layer_3': 0.0014091900602508155, 'n_units_Layer_1': 65, 'n_units_Layer_2': 150, 'n_units_Layer_3': 210}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 7.00% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.50 | sMAPE for Test Set is: 12.94% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:43:11,198]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:43:13,463]\u001b[0m Trial 965 finished with value: 2.1380653017193247 and parameters: {'n_hidden': 4, 'learning_rate': 0.001036510234355834, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12603749423874525, 'dropout_rate_Layer_2': 0.00926540388054462, 'dropout_rate_Layer_3': 0.1776580662215512, 'dropout_rate_Layer_4': 0.30746447804406357, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.004422031294570138, 'l1_Layer_2': 0.0005055804586767979, 'l1_Layer_3': 5.3076583763066395e-05, 'l1_Layer_4': 0.0005813735565005118, 'n_units_Layer_1': 105, 'n_units_Layer_2': 85, 'n_units_Layer_3': 50, 'n_units_Layer_4': 245}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.17% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.29 | sMAPE for Test Set is: 22.29% | rMAE for Test Set is: 1.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:43:13,600]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:43:16,769]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:43:19,472]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:43:26,397]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:43:31,514]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:43:34,611]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:43:34,774]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:43:42,475]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:43:46,260]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:43:49,522]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:43:51,305]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:43:54,895]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:43:58,668]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:43:58,955]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:00,604]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:10,017]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:10,482]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:14,989]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:18,684]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:18,936]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:22,711]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:24,254]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:26,771]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:30,265]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:30,491]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:35,165]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:36,835]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:40,433]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:41,554]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:44,377]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:49,054]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:51,154]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:54,162]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:54,728]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:44:56,787]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:45:01,172]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:45:01,692]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:45:08,560]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:45:10,237]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:45:14,379]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:45:16,477]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:45:20,517]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:45:21,098]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:45:25,135]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:45:27,903]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:45:28,450]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:45:35,521]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:45:36,346]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:45:40,343]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:45:42,721]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:45:45,482]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:46:00,515]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:46:07,767]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:46:11,803]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:46:22,796]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:46:32,622]\u001b[0m Trial 993 finished with value: 2.027531872035405 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011474586638089502, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04852881904724764, 'dropout_rate_Layer_2': 0.05472064400826517, 'dropout_rate_Layer_3': 0.00022609894514432401, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004884447746614751, 'l1_Layer_2': 0.029514923452583663, 'l1_Layer_3': 0.02703769218963486, 'n_units_Layer_1': 170, 'n_units_Layer_2': 145, 'n_units_Layer_3': 240}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 6.72% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 3.33 | sMAPE for Test Set is: 8.18% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:46:36,961]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:46:40,908]\u001b[0m Trial 1021 finished with value: 2.1358912086575614 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015313565210026906, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0005099930739268762, 'dropout_rate_Layer_2': 0.27030552416724085, 'dropout_rate_Layer_3': 0.07864998755624389, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.1671123408357096e-05, 'l1_Layer_2': 0.00980966310963043, 'l1_Layer_3': 0.000567343072170052, 'n_units_Layer_1': 75, 'n_units_Layer_2': 170, 'n_units_Layer_3': 225}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.08% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.34 | sMAPE for Test Set is: 14.91% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:46:46,699]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:46:50,633]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:46:54,503]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:47:01,607]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:47:31,508]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:47:34,940]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:47:37,790]\u001b[0m Trial 1033 finished with value: 2.155868532413433 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009462665465175426, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14287661906867688, 'dropout_rate_Layer_2': 0.2945000668136861, 'dropout_rate_Layer_3': 0.14887029509589425, 'dropout_rate_Layer_4': 0.3522308199425911, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.002978874349334618, 'l1_Layer_2': 0.0004355165523158806, 'l1_Layer_3': 2.488644033368076e-05, 'l1_Layer_4': 0.0009329144903888559, 'n_units_Layer_1': 95, 'n_units_Layer_2': 105, 'n_units_Layer_3': 60, 'n_units_Layer_4': 295}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 7.25% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.63 | sMAPE for Test Set is: 20.54% | rMAE for Test Set is: 1.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:47:40,392]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:47:43,173]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:47:48,623]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:47:51,769]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:47:54,723]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:47:57,838]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:48:01,169]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:48:01,679]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:48:06,499]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:48:08,382]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:48:12,164]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:48:15,252]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:48:15,650]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:48:15,882]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:48:24,254]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:48:26,440]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:48:32,005]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:48:39,492]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:48:41,762]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:48:46,119]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:48:47,872]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:48:53,714]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:48:56,078]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:00,159]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:05,802]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:07,768]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:09,819]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:14,214]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:14,742]\u001b[0m Trial 1039 finished with value: 2.099493119956395 and parameters: {'n_hidden': 3, 'learning_rate': 0.002161535157143487, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014496437618486185, 'dropout_rate_Layer_2': 0.25145797619144944, 'dropout_rate_Layer_3': 0.08607008811512622, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.22882412602757e-05, 'l1_Layer_2': 0.000729613927881862, 'l1_Layer_3': 0.0008238830049759477, 'n_units_Layer_1': 80, 'n_units_Layer_2': 185, 'n_units_Layer_3': 210}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:14,861]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 7.00% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.13 | sMAPE for Test Set is: 16.89% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:49:15,400]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:21,720]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:23,006]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:24,365]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:29,513]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:32,233]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:34,896]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:35,740]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:37,903]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:41,400]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:43,910]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:47,544]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:50,666]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:49:56,029]\u001b[0m Trial 1068 finished with value: 2.1203080037008672 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016062544041617378, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04370667596053315, 'dropout_rate_Layer_2': 0.30250438582443034, 'dropout_rate_Layer_3': 0.19624721745002222, 'dropout_rate_Layer_4': 0.3452812518057568, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.005276859606057113, 'l1_Layer_2': 0.00023072932595564238, 'l1_Layer_3': 0.0006683497347215925, 'l1_Layer_4': 0.000624876522000781, 'n_units_Layer_1': 90, 'n_units_Layer_2': 125, 'n_units_Layer_3': 60, 'n_units_Layer_4': 280}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 7.08% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.91 | sMAPE for Test Set is: 21.26% | rMAE for Test Set is: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:50:04,705]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:50:07,763]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:50:07,973]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:50:22,408]\u001b[0m Trial 1077 finished with value: 2.1469794464111325 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015472961617890128, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16207080077976174, 'dropout_rate_Layer_2': 0.3009891632986891, 'dropout_rate_Layer_3': 0.10604646326510636, 'dropout_rate_Layer_4': 0.3474794282417676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.005109256767566093, 'l1_Layer_2': 0.00019630564123241506, 'l1_Layer_3': 1.5512216391935312e-05, 'l1_Layer_4': 0.0006882331629006869, 'n_units_Layer_1': 90, 'n_units_Layer_2': 110, 'n_units_Layer_3': 70, 'n_units_Layer_4': 280}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.15 | sMAPE for Validation Set is: 7.10% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.35 | sMAPE for Test Set is: 17.27% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:50:25,691]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:50:26,064]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:50:31,812]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.15 | sMAPE for Validation Set is: 7.14% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 16.31% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:50:34,162]\u001b[0m Trial 1080 finished with value: 2.147718703049743 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011442701344261987, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04140229331647375, 'dropout_rate_Layer_2': 0.30309141805678985, 'dropout_rate_Layer_3': 0.19414833307061904, 'dropout_rate_Layer_4': 0.34522008769954476, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.005215894845593921, 'l1_Layer_2': 0.000196546915081609, 'l1_Layer_3': 0.000657489157441086, 'l1_Layer_4': 0.00021490058954275464, 'n_units_Layer_1': 90, 'n_units_Layer_2': 125, 'n_units_Layer_3': 70, 'n_units_Layer_4': 280}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:50:36,895]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:50:42,654]\u001b[0m Trial 1083 finished with value: 2.1310939198676877 and parameters: {'n_hidden': 4, 'learning_rate': 0.001129195719480069, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02985051331853304, 'dropout_rate_Layer_2': 0.2983827366441295, 'dropout_rate_Layer_3': 0.19586312252063637, 'dropout_rate_Layer_4': 0.3466738815963547, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0056576163211173435, 'l1_Layer_2': 0.00019037270884159101, 'l1_Layer_3': 0.0006288908864853706, 'l1_Layer_4': 0.00011393232321976782, 'n_units_Layer_1': 95, 'n_units_Layer_2': 120, 'n_units_Layer_3': 70, 'n_units_Layer_4': 280}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 7.13% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.40 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:50:44,878]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:50:49,627]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:50:51,069]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:50:54,229]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:50:55,344]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:50:59,618]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:51:00,010]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:51:00,770]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:51:07,232]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:51:11,484]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:51:15,320]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:51:17,785]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:51:21,047]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:51:21,437]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:51:30,561]\u001b[0m Trial 1097 finished with value: 2.131093336137313 and parameters: {'n_hidden': 4, 'learning_rate': 0.00128662617812464, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03837679407254756, 'dropout_rate_Layer_2': 0.30602296141902424, 'dropout_rate_Layer_3': 0.2161181183491519, 'dropout_rate_Layer_4': 0.3758730019055417, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.005695630982733276, 'l1_Layer_2': 0.00023884948807637642, 'l1_Layer_3': 0.000587749076686322, 'l1_Layer_4': 2.4928178752212626e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 120, 'n_units_Layer_3': 75, 'n_units_Layer_4': 280}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 7.07% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.06 | sMAPE for Test Set is: 19.05% | rMAE for Test Set is: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:51:39,834]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:51:42,710]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:51:46,338]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:51:59,661]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:52:03,060]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:52:05,639]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:52:09,926]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:52:15,605]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:52:18,426]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:52:22,161]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:52:26,342]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:52:30,448]\u001b[0m Trial 1096 finished with value: 2.1381234232762227 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015673953398955207, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014970554718640032, 'dropout_rate_Layer_2': 0.25398710903706007, 'dropout_rate_Layer_3': 0.09299406092283652, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.9648675457064336e-05, 'l1_Layer_2': 0.006790554885624722, 'l1_Layer_3': 0.0005200337108760179, 'n_units_Layer_1': 60, 'n_units_Layer_2': 180, 'n_units_Layer_3': 215}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.14% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.16 | sMAPE for Test Set is: 14.53% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:52:30,880]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:52:33,148]\u001b[0m Trial 1105 finished with value: 2.1250651538394236 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011364262806176982, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025803577642190854, 'dropout_rate_Layer_2': 0.3215854980635799, 'dropout_rate_Layer_3': 0.21514687386735226, 'dropout_rate_Layer_4': 0.37444649586780326, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.005087790658016034, 'l1_Layer_2': 0.00023869740773739293, 'l1_Layer_3': 0.0006132088276232787, 'l1_Layer_4': 3.634580718077876e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 120, 'n_units_Layer_3': 70, 'n_units_Layer_4': 290}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 7.03% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 15.25% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:52:39,970]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:52:42,477]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:52:43,168]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:52:46,896]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:52:51,517]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:52:55,550]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:53:00,612]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:53:04,001]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:53:11,582]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:53:15,576]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:53:27,074]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:53:31,131]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:53:35,232]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:53:40,209]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:53:45,798]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:53:53,441]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:53:57,628]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:54:02,620]\u001b[0m Trial 1131 finished with value: 2.1091662030957044 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011814163769372698, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02493450225349092, 'dropout_rate_Layer_2': 0.3228767411858298, 'dropout_rate_Layer_3': 0.2473941056294354, 'dropout_rate_Layer_4': 0.39905423216878805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.008540230741301938, 'l1_Layer_2': 0.0001736334816643672, 'l1_Layer_3': 0.0005532223068995744, 'l1_Layer_4': 4.877002750407554e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 135, 'n_units_Layer_3': 70, 'n_units_Layer_4': 285}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 7.01% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.33 | sMAPE for Test Set is: 19.76% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:54:02,821]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:54:07,415]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:54:14,423]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:54:18,852]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:54:23,026]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:54:25,419]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:54:29,536]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:54:29,679]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:54:35,645]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:54:38,241]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:54:42,993]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:54:45,188]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:54:47,610]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:54:51,406]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:54:51,887]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:55:00,537]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:55:01,060]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:55:05,647]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:55:06,459]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:55:12,597]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:55:16,114]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:55:20,680]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:55:23,982]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:55:29,276]\u001b[0m Trial 1145 finished with value: 2.1024197441062 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014019444845159246, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.039001540484669764, 'dropout_rate_Layer_2': 0.32853782558909417, 'dropout_rate_Layer_3': 0.20593385999613287, 'dropout_rate_Layer_4': 0.39712925956510525, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.010085157183793598, 'l1_Layer_2': 0.0002940626880893889, 'l1_Layer_3': 0.00041327812698823134, 'l1_Layer_4': 6.393410721423363e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 110, 'n_units_Layer_3': 60, 'n_units_Layer_4': 275}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 6.98% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 15.94% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:55:32,113]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:55:35,725]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:55:49,622]\u001b[0m Trial 1155 finished with value: 2.164208760510166 and parameters: {'n_hidden': 4, 'learning_rate': 0.001006814477836446, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01323365734816116, 'dropout_rate_Layer_2': 0.30955075196422654, 'dropout_rate_Layer_3': 0.20481950805918395, 'dropout_rate_Layer_4': 0.3321927142066056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.006148004462081883, 'l1_Layer_2': 0.00015523433143008292, 'l1_Layer_3': 0.0011559672121470334, 'l1_Layer_4': 6.094335592817284e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 125, 'n_units_Layer_3': 60, 'n_units_Layer_4': 285}. Best is trial 649 with value: 1.948583969412791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 7.23% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 16.14% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:55:53,394]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:55:57,629]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:56:00,853]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:56:04,319]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:56:07,091]\u001b[0m Trial 1110 finished with value: 1.87042595845139 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008922922088202823, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14433065598891512, 'dropout_rate_Layer_2': 0.05022211327109383, 'dropout_rate_Layer_3': 0.006804155706018319, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021270382319922465, 'l1_Layer_2': 0.0007614781362097887, 'l1_Layer_3': 0.006816934730620624, 'n_units_Layer_1': 110, 'n_units_Layer_2': 155, 'n_units_Layer_3': 200}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 6.16% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 3.37 | sMAPE for Test Set is: 8.20% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:56:08,126]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:56:12,154]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:56:17,775]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:56:18,347]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:56:25,095]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:56:29,109]\u001b[0m Trial 1163 finished with value: 2.0874553870355617 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021254111102948165, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06166364638328998, 'dropout_rate_Layer_2': 0.3009842673886475, 'dropout_rate_Layer_3': 0.09931976442243053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03498445962739668, 'l1_Layer_2': 0.050263438711869654, 'l1_Layer_3': 0.000844071422238889, 'n_units_Layer_1': 65, 'n_units_Layer_2': 205, 'n_units_Layer_3': 170}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.95% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.48 | sMAPE for Test Set is: 12.89% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:56:34,291]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:56:34,649]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:56:35,184]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:56:42,227]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:56:46,462]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:56:50,118]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:56:53,638]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:56:59,688]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:57:18,032]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:57:23,427]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:57:31,705]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:57:32,402]\u001b[0m Trial 1182 finished with value: 2.17255010033897 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010419575935908649, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011698304037104366, 'dropout_rate_Layer_2': 0.3344943150373483, 'dropout_rate_Layer_3': 0.19305575593304616, 'dropout_rate_Layer_4': 0.3984141083660871, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.006034192393933673, 'l1_Layer_2': 0.000155951122713735, 'l1_Layer_3': 0.0016290108787680147, 'l1_Layer_4': 4.286794747767946e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 125, 'n_units_Layer_3': 65, 'n_units_Layer_4': 275}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.17 | sMAPE for Validation Set is: 7.20% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 15.04% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:57:38,812]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:57:39,413]\u001b[0m Trial 1176 finished with value: 2.057086357786225 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026317026574184635, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015822639375284216, 'dropout_rate_Layer_2': 0.3161248148275921, 'dropout_rate_Layer_3': 0.11995319523165757, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07322047687585378, 'l1_Layer_2': 0.039710164226476496, 'l1_Layer_3': 0.0010327127325453515, 'n_units_Layer_1': 80, 'n_units_Layer_2': 200, 'n_units_Layer_3': 155}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.82% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.69 | sMAPE for Test Set is: 11.07% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:57:41,637]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:57:46,749]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:57:53,073]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:57:53,772]\u001b[0m Trial 1172 finished with value: 1.9989329904328954 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021554078233021025, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026844448033295023, 'dropout_rate_Layer_2': 0.20071331836337278, 'dropout_rate_Layer_3': 0.09373994846972844, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.633954686036907e-05, 'l1_Layer_2': 0.0009058308982239315, 'l1_Layer_3': 0.0008253035105917984, 'n_units_Layer_1': 85, 'n_units_Layer_2': 180, 'n_units_Layer_3': 220}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 6.61% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 14.56% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:57:58,212]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:58:00,957]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:58:06,102]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:58:08,982]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:58:12,081]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:58:12,774]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:58:17,644]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:58:20,881]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:58:25,589]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:58:30,600]\u001b[0m Trial 1189 finished with value: 2.1182458248617926 and parameters: {'n_hidden': 3, 'learning_rate': 0.002579489138336141, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06260569107733888, 'dropout_rate_Layer_2': 0.3172867310523207, 'dropout_rate_Layer_3': 0.11800656956275288, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04469266261167954, 'l1_Layer_2': 0.03746574475400955, 'l1_Layer_3': 0.0005922998511135383, 'n_units_Layer_1': 75, 'n_units_Layer_2': 205, 'n_units_Layer_3': 135}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 7.06% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 13.54% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:58:34,422]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:58:38,316]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:58:45,432]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:58:55,270]\u001b[0m Trial 1198 finished with value: 2.0874041772377114 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023459483476072295, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06056126864465607, 'dropout_rate_Layer_2': 0.20321050620242534, 'dropout_rate_Layer_3': 0.10932257767474693, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.023094021463330817, 'l1_Layer_2': 0.06123805609533259, 'l1_Layer_3': 0.001111043577301543, 'n_units_Layer_1': 75, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.96% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.56 | sMAPE for Test Set is: 13.08% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:59:00,564]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:59:04,369]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:59:04,596]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:59:06,706]\u001b[0m Trial 1196 finished with value: 2.113045371355735 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023413746143580486, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.060803388046815975, 'dropout_rate_Layer_2': 0.22209085867485961, 'dropout_rate_Layer_3': 0.11373396570183927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.05875492108081128, 'l1_Layer_2': 0.0445211199339471, 'l1_Layer_3': 0.0005450691497752819, 'n_units_Layer_1': 75, 'n_units_Layer_2': 205, 'n_units_Layer_3': 155}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 7.04% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.49 | sMAPE for Test Set is: 12.94% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:59:13,154]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:59:15,324]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:59:18,210]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:59:20,285]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:59:21,360]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:59:25,060]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:59:26,277]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:59:30,763]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:59:31,791]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:59:35,144]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:59:39,328]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:59:46,660]\u001b[0m Trial 1208 finished with value: 2.106989872477796 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025289205560007967, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05740918926249749, 'dropout_rate_Layer_2': 0.18729037375389349, 'dropout_rate_Layer_3': 0.11041463445800095, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03463619693704133, 'l1_Layer_2': 0.060790551213891, 'l1_Layer_3': 0.0010995886705879277, 'n_units_Layer_1': 70, 'n_units_Layer_2': 180, 'n_units_Layer_3': 155}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 7.02% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 13.71% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 14:59:49,981]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 14:59:53,240]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:00:00,438]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:00:05,815]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:00:09,168]\u001b[0m Trial 1222 finished with value: 2.126819995475215 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016296604727547405, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023712844400183782, 'dropout_rate_Layer_2': 0.3228889382247692, 'dropout_rate_Layer_3': 0.2255468216453205, 'dropout_rate_Layer_4': 0.24504540126952198, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.011254552622040859, 'l1_Layer_2': 0.0001974288313129016, 'l1_Layer_3': 0.0005247917956509746, 'l1_Layer_4': 0.0007962305485576421, 'n_units_Layer_1': 80, 'n_units_Layer_2': 135, 'n_units_Layer_3': 55, 'n_units_Layer_4': 270}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 7.12% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.32 | sMAPE for Test Set is: 25.07% | rMAE for Test Set is: 1.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:00:09,916]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:00:17,959]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:00:19,927]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:00:22,897]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:00:27,293]\u001b[0m Trial 1215 finished with value: 2.1260630422819484 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019847019277654788, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.049486766922316516, 'dropout_rate_Layer_2': 0.18078763314333618, 'dropout_rate_Layer_3': 0.10411393018577782, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.023899771055738313, 'l1_Layer_2': 0.06827331145698401, 'l1_Layer_3': 0.0007381914830440874, 'n_units_Layer_1': 70, 'n_units_Layer_2': 185, 'n_units_Layer_3': 145}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 7.16% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.19 | sMAPE for Test Set is: 12.22% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:00:27,484]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:00:32,134]\u001b[0m Trial 1220 finished with value: 2.0712539923080073 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019726487530496413, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04797963216161055, 'dropout_rate_Layer_2': 0.20976828076672774, 'dropout_rate_Layer_3': 0.09987127801236843, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0501817843961283, 'l1_Layer_2': 0.07259877312672419, 'l1_Layer_3': 0.0009864846451328143, 'n_units_Layer_1': 80, 'n_units_Layer_2': 190, 'n_units_Layer_3': 160}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.88% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.19 | sMAPE for Test Set is: 12.21% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:00:45,158]\u001b[0m Trial 1231 finished with value: 2.108923039347544 and parameters: {'n_hidden': 4, 'learning_rate': 0.001629266680569856, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019299615078532017, 'dropout_rate_Layer_2': 0.3379776391090378, 'dropout_rate_Layer_3': 0.21283180371450736, 'dropout_rate_Layer_4': 0.31458010946970266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0069121122993202, 'l1_Layer_2': 0.0002229612779931412, 'l1_Layer_3': 0.00048402306541407995, 'l1_Layer_4': 0.0008793071078931935, 'n_units_Layer_1': 75, 'n_units_Layer_2': 125, 'n_units_Layer_3': 65, 'n_units_Layer_4': 280}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 7.04% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.09 | sMAPE for Test Set is: 24.42% | rMAE for Test Set is: 1.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:00:46,744]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:00:51,200]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:00:54,316]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:00:56,368]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:00:59,991]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:01:00,488]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:01:06,047]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:01:13,471]\u001b[0m Trial 1233 finished with value: 2.095306485751488 and parameters: {'n_hidden': 3, 'learning_rate': 0.001960167921306059, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03024387053146682, 'dropout_rate_Layer_2': 0.2104246441035461, 'dropout_rate_Layer_3': 0.12249551725856521, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.01692245505102233, 'l1_Layer_2': 0.06138532396343354, 'l1_Layer_3': 0.000960418808414539, 'n_units_Layer_1': 80, 'n_units_Layer_2': 190, 'n_units_Layer_3': 160}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 6.96% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.50 | sMAPE for Test Set is: 12.94% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:01:21,945]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:01:29,938]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:01:32,199]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:01:36,615]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:01:36,915]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:01:40,438]\u001b[0m Trial 1234 finished with value: 2.0729968354599877 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028800572255195615, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03042169642770056, 'dropout_rate_Layer_2': 0.2094623622589343, 'dropout_rate_Layer_3': 0.12419446942507387, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.09683358037154284, 'l1_Layer_2': 0.05207984843871958, 'l1_Layer_3': 0.0009400658691039703, 'n_units_Layer_1': 80, 'n_units_Layer_2': 175, 'n_units_Layer_3': 160}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.89% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.51 | sMAPE for Test Set is: 10.68% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:01:43,009]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:01:48,534]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:01:51,307]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:01:54,220]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:01:55,807]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:02:00,338]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:02:04,827]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:02:09,864]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:02:15,208]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:02:26,854]\u001b[0m Trial 1249 finished with value: 2.0893418541078908 and parameters: {'n_hidden': 4, 'learning_rate': 0.001202822365200036, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024583642050691183, 'dropout_rate_Layer_2': 0.3482787676359462, 'dropout_rate_Layer_3': 0.20569364863098355, 'dropout_rate_Layer_4': 0.31618330421652124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.011233884754503888, 'l1_Layer_2': 0.0002494657416964766, 'l1_Layer_3': 0.0004795715165153715, 'l1_Layer_4': 0.0012333436259252177, 'n_units_Layer_1': 90, 'n_units_Layer_2': 130, 'n_units_Layer_3': 60, 'n_units_Layer_4': 280}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.96% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.77 | sMAPE for Test Set is: 20.93% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:02:29,931]\u001b[0m Trial 1255 finished with value: 2.129145817294911 and parameters: {'n_hidden': 4, 'learning_rate': 0.001222035226367752, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027678992993824758, 'dropout_rate_Layer_2': 0.3311979598014442, 'dropout_rate_Layer_3': 0.23590576050207898, 'dropout_rate_Layer_4': 0.24780546053571434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00485915176518128, 'l1_Layer_2': 0.0002800911161990534, 'l1_Layer_3': 0.0003591057044201067, 'l1_Layer_4': 0.001216050034656244, 'n_units_Layer_1': 85, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50, 'n_units_Layer_4': 280}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 7.10% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.99 | sMAPE for Test Set is: 24.15% | rMAE for Test Set is: 1.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:02:30,698]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:02:34,753]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:02:36,889]\u001b[0m Trial 1251 finished with value: 2.0600235246324448 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033773487452882027, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03918828559444793, 'dropout_rate_Layer_2': 0.20132553052383123, 'dropout_rate_Layer_3': 0.00898016610044891, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0725240495078861, 'l1_Layer_2': 0.04683488669694826, 'l1_Layer_3': 0.0004958610640341466, 'n_units_Layer_1': 90, 'n_units_Layer_2': 175, 'n_units_Layer_3': 150}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.83% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 12.72% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:02:37,213]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:02:41,269]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:02:46,468]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:02:47,133]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:02:48,603]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:02:52,758]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:02:57,643]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:03:00,808]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:03:04,465]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:03:15,489]\u001b[0m Trial 1268 finished with value: 2.1401763841426575 and parameters: {'n_hidden': 4, 'learning_rate': 0.001230458720868577, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031073317630300808, 'dropout_rate_Layer_2': 0.3521197020879209, 'dropout_rate_Layer_3': 0.22734633069879037, 'dropout_rate_Layer_4': 0.31342829137362554, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.004995197042676101, 'l1_Layer_2': 0.0002738310120634818, 'l1_Layer_3': 0.0003568088364392514, 'l1_Layer_4': 0.0012063957360698265, 'n_units_Layer_1': 75, 'n_units_Layer_2': 135, 'n_units_Layer_3': 50, 'n_units_Layer_4': 280}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.15% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.14 | sMAPE for Test Set is: 24.56% | rMAE for Test Set is: 1.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:03:16,326]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:03:22,268]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:03:26,876]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:03:28,786]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:03:32,101]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:03:36,379]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:03:38,079]\u001b[0m Trial 1259 finished with value: 2.073019327700027 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022912633953073953, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04137825154855486, 'dropout_rate_Layer_2': 0.2218060017279998, 'dropout_rate_Layer_3': 0.1093685003216598, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.036959026900721614, 'l1_Layer_2': 0.09998028020780847, 'l1_Layer_3': 0.000995459852769449, 'n_units_Layer_1': 60, 'n_units_Layer_2': 170, 'n_units_Layer_3': 160}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.89% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.73 | sMAPE for Test Set is: 11.19% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:03:42,369]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:03:42,560]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:03:42,797]\u001b[0m Trial 1273 finished with value: 2.0337085749627932 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033026054814152953, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04610397500070225, 'dropout_rate_Layer_2': 0.18299941082643598, 'dropout_rate_Layer_3': 0.10713405940745342, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03382003629972463, 'l1_Layer_2': 0.048073822099543626, 'l1_Layer_3': 0.0009927275510846487, 'n_units_Layer_1': 60, 'n_units_Layer_2': 170, 'n_units_Layer_3': 150}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 6.72% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 12.66% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:03:50,190]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:03:50,461]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:03:56,486]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:03:59,959]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:04:03,406]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:04:08,944]\u001b[0m Trial 1284 finished with value: 2.0855916907756247 and parameters: {'n_hidden': 3, 'learning_rate': 0.004387437984426206, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.051091075544186834, 'dropout_rate_Layer_2': 0.22305328244755362, 'dropout_rate_Layer_3': 0.03701194382979531, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03331369531820314, 'l1_Layer_2': 0.08393125371111805, 'l1_Layer_3': 0.0007717999297015913, 'n_units_Layer_1': 55, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.91% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 13.91% | rMAE for Test Set is: 1.14\n",
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.94% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.11 | sMAPE for Test Set is: 14.39% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:04:30,018]\u001b[0m Trial 1289 finished with value: 2.0829893555721086 and parameters: {'n_hidden': 3, 'learning_rate': 0.003109004107238932, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04625424416046319, 'dropout_rate_Layer_2': 0.2235118907539361, 'dropout_rate_Layer_3': 0.12606100087590877, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.037726259220133215, 'l1_Layer_2': 0.05387717821103999, 'l1_Layer_3': 0.0007693403611056846, 'n_units_Layer_1': 60, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:04:34,391]\u001b[0m Trial 1278 finished with value: 2.10413520036019 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027003461967425634, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0613779708382014, 'dropout_rate_Layer_2': 0.18306151168306, 'dropout_rate_Layer_3': 0.13112628708328866, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.040433685711115754, 'l1_Layer_2': 0.05395084587466915, 'l1_Layer_3': 0.000632781429285182, 'n_units_Layer_1': 65, 'n_units_Layer_2': 180, 'n_units_Layer_3': 150}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 6.98% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 12.28% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:04:36,437]\u001b[0m Trial 1285 finished with value: 2.0801398563917792 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035424838591865374, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.050316151233412515, 'dropout_rate_Layer_2': 0.22574420699895317, 'dropout_rate_Layer_3': 0.11472123991959406, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03858974349324911, 'l1_Layer_2': 0.05530368750682124, 'l1_Layer_3': 0.0007098327881260471, 'n_units_Layer_1': 60, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.93% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.31 | sMAPE for Test Set is: 12.51% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:04:41,064]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:04:41,593]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:04:48,293]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:04:48,766]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:04:52,921]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:04:57,248]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:05:15,684]\u001b[0m Trial 1297 finished with value: 2.1038889443186184 and parameters: {'n_hidden': 3, 'learning_rate': 0.004126821796217642, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04379224888601867, 'dropout_rate_Layer_2': 0.23642059456921122, 'dropout_rate_Layer_3': 0.12655632040266698, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.028461997195108727, 'l1_Layer_2': 0.08631702196809594, 'l1_Layer_3': 0.0005360784081771952, 'n_units_Layer_1': 60, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 6.96% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.75 | sMAPE for Test Set is: 13.48% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:05:19,138]\u001b[0m Trial 1290 finished with value: 2.0459944016351823 and parameters: {'n_hidden': 3, 'learning_rate': 0.0043711888648850965, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04566554271432254, 'dropout_rate_Layer_2': 0.23010514204168858, 'dropout_rate_Layer_3': 0.12657743836605734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03982513226716735, 'l1_Layer_2': 0.0868220170433216, 'l1_Layer_3': 0.0006797674409451123, 'n_units_Layer_1': 65, 'n_units_Layer_2': 170, 'n_units_Layer_3': 145}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 6.79% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.62 | sMAPE for Test Set is: 10.91% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:05:23,194]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:05:28,161]\u001b[0m Trial 1292 finished with value: 2.1375212162255792 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013953250294404436, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027515552992932017, 'dropout_rate_Layer_2': 0.3437190134991819, 'dropout_rate_Layer_3': 0.2362815798908909, 'dropout_rate_Layer_4': 0.31088156414794244, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.004984560992600648, 'l1_Layer_2': 0.0003104028114083401, 'l1_Layer_3': 0.0003360639403128062, 'l1_Layer_4': 0.001150395983655414, 'n_units_Layer_1': 70, 'n_units_Layer_2': 135, 'n_units_Layer_3': 50, 'n_units_Layer_4': 275}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.11% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.93 | sMAPE for Test Set is: 18.80% | rMAE for Test Set is: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:05:31,060]\u001b[0m Trial 1299 finished with value: 2.1397751571967834 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013718534319020015, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02774969812005321, 'dropout_rate_Layer_2': 0.3611275476001258, 'dropout_rate_Layer_3': 0.2328619191532021, 'dropout_rate_Layer_4': 0.3172600507960163, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0049298711852953205, 'l1_Layer_2': 0.0002931919744895958, 'l1_Layer_3': 0.0003715430314349522, 'l1_Layer_4': 0.0011051157715437194, 'n_units_Layer_1': 70, 'n_units_Layer_2': 135, 'n_units_Layer_3': 50, 'n_units_Layer_4': 275}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.11% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.38 | sMAPE for Test Set is: 22.54% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:05:42,225]\u001b[0m Trial 1300 finished with value: 2.1566768594560677 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013854247565427674, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02737930494832131, 'dropout_rate_Layer_2': 0.35960618210142203, 'dropout_rate_Layer_3': 0.23555387330664834, 'dropout_rate_Layer_4': 0.24459943073327223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.004922127116283198, 'l1_Layer_2': 0.00028860445091244706, 'l1_Layer_3': 0.0003857511281760149, 'l1_Layer_4': 0.001079412459359766, 'n_units_Layer_1': 70, 'n_units_Layer_2': 135, 'n_units_Layer_3': 50, 'n_units_Layer_4': 280}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 7.14% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.37 | sMAPE for Test Set is: 25.19% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:05:45,595]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:05:47,794]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:05:50,440]\u001b[0m Trial 1302 finished with value: 2.127880178812052 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013645721604843028, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03126078744762583, 'dropout_rate_Layer_2': 0.3492172864742407, 'dropout_rate_Layer_3': 0.2324124355948869, 'dropout_rate_Layer_4': 0.3108100408387991, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.005143560987860088, 'l1_Layer_2': 0.0002872721983934088, 'l1_Layer_3': 0.00033261988071208614, 'l1_Layer_4': 0.0011147623764760474, 'n_units_Layer_1': 70, 'n_units_Layer_2': 135, 'n_units_Layer_3': 50, 'n_units_Layer_4': 275}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 7.06% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.33 | sMAPE for Test Set is: 25.05% | rMAE for Test Set is: 1.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:05:51,441]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:05:53,818]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:05:58,121]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.15 | sMAPE for Validation Set is: 7.13% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.77 | sMAPE for Test Set is: 26.30% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:05:58,686]\u001b[0m Trial 1304 finished with value: 2.1472841827651865 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014690742212659768, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02662586959751467, 'dropout_rate_Layer_2': 0.3487916653604526, 'dropout_rate_Layer_3': 0.23703749913869993, 'dropout_rate_Layer_4': 0.3116716523457721, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.004944965093849574, 'l1_Layer_2': 0.000287568122885697, 'l1_Layer_3': 0.00034546101044462697, 'l1_Layer_4': 0.0011147003487838375, 'n_units_Layer_1': 70, 'n_units_Layer_2': 145, 'n_units_Layer_3': 50, 'n_units_Layer_4': 270}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:05:59,406]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:06:05,631]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:06:06,547]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:06:08,729]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:06:13,957]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:06:15,779]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:06:20,171]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:06:24,921]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:06:28,937]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:06:35,810]\u001b[0m Trial 1312 finished with value: 2.108592898681399 and parameters: {'n_hidden': 3, 'learning_rate': 0.0054415311470116115, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.042491998709736384, 'dropout_rate_Layer_2': 0.21676090835021627, 'dropout_rate_Layer_3': 0.11991915787901022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04099518473511786, 'l1_Layer_2': 0.09891786141397847, 'l1_Layer_3': 0.0004360541298906091, 'n_units_Layer_1': 55, 'n_units_Layer_2': 165, 'n_units_Layer_3': 140}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 7.02% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.23 | sMAPE for Test Set is: 12.31% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:06:50,320]\u001b[0m Trial 1317 finished with value: 2.09339015995324 and parameters: {'n_hidden': 3, 'learning_rate': 0.0054088897097164, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04325727146475491, 'dropout_rate_Layer_2': 0.22575026157324393, 'dropout_rate_Layer_3': 0.12869832541918141, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03277365463877709, 'l1_Layer_2': 0.07010392322883917, 'l1_Layer_3': 0.0004913351641932574, 'n_units_Layer_1': 55, 'n_units_Layer_2': 165, 'n_units_Layer_3': 140}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.96% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 11.94% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:06:54,395]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.87% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.14 | sMAPE for Test Set is: 12.04% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:06:56,488]\u001b[0m Trial 1319 finished with value: 2.0652613188301387 and parameters: {'n_hidden': 3, 'learning_rate': 0.00443906308329203, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.047362194844906016, 'dropout_rate_Layer_2': 0.22676082319492893, 'dropout_rate_Layer_3': 0.12418854724646859, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03591141700458045, 'l1_Layer_2': 0.03992635555759275, 'l1_Layer_3': 0.0004335567085627683, 'n_units_Layer_1': 55, 'n_units_Layer_2': 165, 'n_units_Layer_3': 140}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:06:57,558]\u001b[0m Trial 1321 finished with value: 2.0361785585698247 and parameters: {'n_hidden': 3, 'learning_rate': 0.004871899215857702, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0448503810706335, 'dropout_rate_Layer_2': 0.22296604051980265, 'dropout_rate_Layer_3': 0.12401740206292237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03614996328347871, 'l1_Layer_2': 0.06824632061067457, 'l1_Layer_3': 0.0004265774048385714, 'n_units_Layer_1': 55, 'n_units_Layer_2': 165, 'n_units_Layer_3': 160}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 6.73% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 13.68% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:06:58,701]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:07:02,804]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:07:04,832]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:07:05,556]\u001b[0m Trial 1322 finished with value: 2.0497392497959526 and parameters: {'n_hidden': 3, 'learning_rate': 0.004624548137526757, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04759549323497273, 'dropout_rate_Layer_2': 0.23821976084553656, 'dropout_rate_Layer_3': 0.12768324589452432, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03668020773280346, 'l1_Layer_2': 0.04024521574959459, 'l1_Layer_3': 0.000731394857688808, 'n_units_Layer_1': 55, 'n_units_Layer_2': 170, 'n_units_Layer_3': 160}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 6.78% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 13.63% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:07:06,034]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:07:13,006]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:07:16,315]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:07:18,760]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:07:22,403]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:07:25,290]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:07:26,254]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:07:34,336]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:07:34,748]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:07:51,268]\u001b[0m Trial 1332 finished with value: 2.1328017824499743 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012900997555893722, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03527087421364939, 'dropout_rate_Layer_2': 0.35718958414810986, 'dropout_rate_Layer_3': 0.21769905273756698, 'dropout_rate_Layer_4': 0.3242906744883672, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.007310605885472378, 'l1_Layer_2': 0.00032671593075686757, 'l1_Layer_3': 0.00034505492978640105, 'l1_Layer_4': 0.001518735503122032, 'n_units_Layer_1': 60, 'n_units_Layer_2': 135, 'n_units_Layer_3': 50, 'n_units_Layer_4': 265}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 7.12% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.37 | sMAPE for Test Set is: 22.50% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:07:56,461]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:08:09,858]\u001b[0m Trial 1339 finished with value: 2.123074064237001 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036521139330009857, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05707208555307885, 'dropout_rate_Layer_2': 0.23128519245113527, 'dropout_rate_Layer_3': 0.11953358985590679, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.040395928567058544, 'l1_Layer_2': 0.03152939709047372, 'l1_Layer_3': 0.00037402503716782724, 'n_units_Layer_1': 50, 'n_units_Layer_2': 155, 'n_units_Layer_3': 145}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 7.04% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.29 | sMAPE for Test Set is: 19.69% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:08:13,308]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:08:17,034]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:08:19,084]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:08:21,350]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:08:25,699]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:08:31,437]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:08:48,456]\u001b[0m Trial 1345 finished with value: 2.0653471436047686 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038628378430791976, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.046025689080551324, 'dropout_rate_Layer_2': 0.2280603601496176, 'dropout_rate_Layer_3': 0.13215413815116628, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03648449909511788, 'l1_Layer_2': 0.036048732178863875, 'l1_Layer_3': 0.0004948664051161951, 'n_units_Layer_1': 60, 'n_units_Layer_2': 165, 'n_units_Layer_3': 160}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.84% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 12.41% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:09:06,682]\u001b[0m Trial 1330 finished with value: 1.9247738609322844 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007995365111530612, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12120771592407234, 'dropout_rate_Layer_2': 0.07771644362999211, 'dropout_rate_Layer_3': 0.024990225623651507, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.836823933578402e-05, 'l1_Layer_2': 0.00023433359623960278, 'l1_Layer_3': 0.003459054743265483, 'n_units_Layer_1': 100, 'n_units_Layer_2': 180, 'n_units_Layer_3': 170}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 6.37% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.83 | sMAPE for Test Set is: 7.03% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:09:11,827]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:09:14,590]\u001b[0m Trial 1348 finished with value: 2.1365626219353415 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012521005537438309, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04679059574963922, 'dropout_rate_Layer_2': 0.345094133357494, 'dropout_rate_Layer_3': 0.21653339087297904, 'dropout_rate_Layer_4': 0.3251019962957119, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00854596854127547, 'l1_Layer_2': 0.000387090521811956, 'l1_Layer_3': 0.00036891154466538097, 'l1_Layer_4': 0.001979569359339173, 'n_units_Layer_1': 60, 'n_units_Layer_2': 130, 'n_units_Layer_3': 55, 'n_units_Layer_4': 270}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.11% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.02 | sMAPE for Test Set is: 21.57% | rMAE for Test Set is: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:09:15,604]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:09:20,941]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:09:23,397]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:09:23,497]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:09:27,100]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:09:27,823]\u001b[0m Trial 1349 finished with value: 2.1114633004048238 and parameters: {'n_hidden': 4, 'learning_rate': 0.001190164278462889, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015214092994602217, 'dropout_rate_Layer_2': 0.3415958468683084, 'dropout_rate_Layer_3': 0.21593647952626593, 'dropout_rate_Layer_4': 0.32457688635848087, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.008491686516641289, 'l1_Layer_2': 0.0003838075222018131, 'l1_Layer_3': 0.00037046955835387703, 'l1_Layer_4': 0.001947313184576276, 'n_units_Layer_1': 60, 'n_units_Layer_2': 130, 'n_units_Layer_3': 55, 'n_units_Layer_4': 270}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 7.04% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.82 | sMAPE for Test Set is: 23.72% | rMAE for Test Set is: 1.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:09:33,395]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:09:38,347]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:09:42,424]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:09:44,814]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:09:47,804]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:09:50,032]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:09:55,052]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:09:55,507]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:09:59,915]\u001b[0m Trial 1356 finished with value: 2.0948048812095457 and parameters: {'n_hidden': 3, 'learning_rate': 0.004561270865954412, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03403461425088766, 'dropout_rate_Layer_2': 0.2426005188573671, 'dropout_rate_Layer_3': 0.13038057745295895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.027884627132872212, 'l1_Layer_2': 0.035116560192368224, 'l1_Layer_3': 0.00038817556025718596, 'n_units_Layer_1': 60, 'n_units_Layer_2': 160, 'n_units_Layer_3': 160}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.96% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.69 | sMAPE for Test Set is: 13.40% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:10:05,723]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:10:17,124]\u001b[0m Trial 1362 finished with value: 2.087254878617754 and parameters: {'n_hidden': 3, 'learning_rate': 0.0045220184570079576, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07079459156657447, 'dropout_rate_Layer_2': 0.23159522319124443, 'dropout_rate_Layer_3': 0.13540018909878215, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.030978711486856866, 'l1_Layer_2': 0.038878450404325596, 'l1_Layer_3': 0.000491084979555059, 'n_units_Layer_1': 60, 'n_units_Layer_2': 160, 'n_units_Layer_3': 140}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.92% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 13.60% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:10:21,471]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:10:25,667]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:10:26,251]\u001b[0m Trial 1365 finished with value: 2.0813719457043836 and parameters: {'n_hidden': 3, 'learning_rate': 0.0051697311532509635, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.034823391936123334, 'dropout_rate_Layer_2': 0.24614547367269315, 'dropout_rate_Layer_3': 0.13216109189458936, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.02850190675013399, 'l1_Layer_2': 0.037253826957050276, 'l1_Layer_3': 0.00038185423461550714, 'n_units_Layer_1': 60, 'n_units_Layer_2': 160, 'n_units_Layer_3': 140}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.91% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 14.02% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:10:31,959]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:10:32,461]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:10:32,775]\u001b[0m Trial 1368 finished with value: 2.1458120917918744 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014288262334886696, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01611338797369056, 'dropout_rate_Layer_2': 0.33770458595762726, 'dropout_rate_Layer_3': 0.22697695281012892, 'dropout_rate_Layer_4': 0.2889004340638677, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.007272170090124254, 'l1_Layer_2': 0.0002885137124018194, 'l1_Layer_3': 0.00032929854489904944, 'l1_Layer_4': 0.002564759299763506, 'n_units_Layer_1': 55, 'n_units_Layer_2': 150, 'n_units_Layer_3': 55, 'n_units_Layer_4': 265}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.15 | sMAPE for Validation Set is: 7.20% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.46 | sMAPE for Test Set is: 25.41% | rMAE for Test Set is: 2.01\n",
      "MAE for Validation Set is: 2.17 | sMAPE for Validation Set is: 7.28% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.76 | sMAPE for Test Set is: 23.55% | rMAE for Test Set is: 1.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:10:37,229]\u001b[0m Trial 1367 finished with value: 2.167847892354543 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014437020022750409, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029842185798421815, 'dropout_rate_Layer_2': 0.3366709616144646, 'dropout_rate_Layer_3': 0.229210494040455, 'dropout_rate_Layer_4': 0.32453343436193055, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0069541624550991605, 'l1_Layer_2': 0.0004774931646475467, 'l1_Layer_3': 0.00035330224233494345, 'l1_Layer_4': 0.0027753914091635844, 'n_units_Layer_1': 55, 'n_units_Layer_2': 120, 'n_units_Layer_3': 55, 'n_units_Layer_4': 260}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:10:42,347]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:10:43,010]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:10:48,214]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:10:52,955]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:10:56,095]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:10:59,351]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:11:02,330]\u001b[0m Trial 1373 finished with value: 2.0618792683141414 and parameters: {'n_hidden': 3, 'learning_rate': 0.003764121338942889, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04113527714662622, 'dropout_rate_Layer_2': 0.21791732840905628, 'dropout_rate_Layer_3': 0.14277806961841555, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.06984747931607174, 'l1_Layer_2': 0.047728962860781245, 'l1_Layer_3': 0.0005442579289162438, 'n_units_Layer_1': 55, 'n_units_Layer_2': 170, 'n_units_Layer_3': 160}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.83% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.48 | sMAPE for Test Set is: 12.85% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:11:03,184]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:11:04,722]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:11:19,101]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:11:20,685]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:11:25,515]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.92% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 13.51% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:11:26,965]\u001b[0m Trial 1383 finished with value: 2.081915914111075 and parameters: {'n_hidden': 3, 'learning_rate': 0.003692939488885818, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031090844479346676, 'dropout_rate_Layer_2': 0.20854895759713407, 'dropout_rate_Layer_3': 0.12530238775479116, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.05917781265303878, 'l1_Layer_2': 0.045223439834111444, 'l1_Layer_3': 0.00047364885777419533, 'n_units_Layer_1': 55, 'n_units_Layer_2': 165, 'n_units_Layer_3': 150}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:11:31,878]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:11:36,307]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:11:46,694]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:11:50,790]\u001b[0m Trial 1386 finished with value: 2.0805771520728285 and parameters: {'n_hidden': 3, 'learning_rate': 0.003985238916946978, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04726012996816462, 'dropout_rate_Layer_2': 0.21518560203163611, 'dropout_rate_Layer_3': 0.1358665006885283, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.05511170873642548, 'l1_Layer_2': 0.061366951999851205, 'l1_Layer_3': 0.00044625961825488653, 'n_units_Layer_1': 50, 'n_units_Layer_2': 170, 'n_units_Layer_3': 165}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.88% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 12.41% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:11:52,899]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:11:56,895]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:11:58,679]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:12:21,895]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:13:04,841]\u001b[0m Trial 1397 finished with value: 2.092833176680339 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014987006706511396, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06677221066471417, 'dropout_rate_Layer_2': 0.34794413608690145, 'dropout_rate_Layer_3': 0.20241532643809101, 'dropout_rate_Layer_4': 0.09485214871968833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.014582340029504936, 'l1_Layer_2': 0.000245899723572649, 'l1_Layer_3': 0.0003781588393980425, 'l1_Layer_4': 0.003761247308913821, 'n_units_Layer_1': 80, 'n_units_Layer_2': 125, 'n_units_Layer_3': 60, 'n_units_Layer_4': 285}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.96% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.36 | sMAPE for Test Set is: 17.40% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:13:09,338]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:13:14,255]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:13:38,031]\u001b[0m Trial 1388 finished with value: 2.0852422704643376 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012315231616969785, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012574424840486579, 'dropout_rate_Layer_2': 0.061188105330313554, 'dropout_rate_Layer_3': 0.007734252932288829, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001926073018085553, 'l1_Layer_2': 0.0007637652828899626, 'l1_Layer_3': 0.03740693866537366, 'n_units_Layer_1': 55, 'n_units_Layer_2': 130, 'n_units_Layer_3': 200}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.96% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.00 | sMAPE for Test Set is: 16.47% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:13:41,553]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:13:49,496]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:13:54,688]\u001b[0m Trial 1400 finished with value: 2.0736854669812446 and parameters: {'n_hidden': 3, 'learning_rate': 0.003412202012069233, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03748592429266155, 'dropout_rate_Layer_2': 0.21761674196110015, 'dropout_rate_Layer_3': 0.11646781524409666, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07172436963843891, 'l1_Layer_2': 0.060510573878626496, 'l1_Layer_3': 0.00035409504140724196, 'n_units_Layer_1': 55, 'n_units_Layer_2': 155, 'n_units_Layer_3': 230}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.87% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.93 | sMAPE for Test Set is: 11.59% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:14:01,057]\u001b[0m Trial 1391 finished with value: 1.9690987375506255 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005521491589735604, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07904530528524241, 'dropout_rate_Layer_2': 0.09476416885596811, 'dropout_rate_Layer_3': 0.014397747469394822, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2597461872347477e-05, 'l1_Layer_2': 0.0007986652691036842, 'l1_Layer_3': 0.00047093130270770944, 'n_units_Layer_1': 110, 'n_units_Layer_2': 115, 'n_units_Layer_3': 215}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 6.54% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.10 | sMAPE for Test Set is: 19.31% | rMAE for Test Set is: 1.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:14:10,016]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:14:20,225]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:14:20,465]\u001b[0m Trial 1395 finished with value: 2.121142113763749 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009567360147951789, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03991518453762075, 'dropout_rate_Layer_2': 0.027942493700311703, 'dropout_rate_Layer_3': 0.01414482252079069, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002151651691886561, 'l1_Layer_2': 0.0007655452053766654, 'l1_Layer_3': 0.03736322050362464, 'n_units_Layer_1': 110, 'n_units_Layer_2': 115, 'n_units_Layer_3': 215}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 7.07% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.44 | sMAPE for Test Set is: 17.54% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:14:28,493]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:14:31,021]\u001b[0m Trial 1403 finished with value: 2.059517342888887 and parameters: {'n_hidden': 3, 'learning_rate': 0.004987044918234267, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0381428451977588, 'dropout_rate_Layer_2': 0.23662754966646005, 'dropout_rate_Layer_3': 0.11714709985315586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.06920481949041167, 'l1_Layer_2': 0.06248956273828069, 'l1_Layer_3': 0.00039605255121004607, 'n_units_Layer_1': 55, 'n_units_Layer_2': 155, 'n_units_Layer_3': 230}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.83% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.64 | sMAPE for Test Set is: 10.93% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:14:34,483]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:14:35,333]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:14:42,792]\u001b[0m Trial 1404 finished with value: 2.1213346458502547 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015614430854435334, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0097295574626645, 'dropout_rate_Layer_2': 0.3439739321861413, 'dropout_rate_Layer_3': 0.20471933858514757, 'dropout_rate_Layer_4': 0.09110699177245576, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.013897909281384166, 'l1_Layer_2': 0.0002437922820520791, 'l1_Layer_3': 0.0003932666443557848, 'l1_Layer_4': 0.0014770235024464675, 'n_units_Layer_1': 80, 'n_units_Layer_2': 125, 'n_units_Layer_3': 65, 'n_units_Layer_4': 285}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 7.12% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 15.42% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:14:46,270]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:14:51,154]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:14:56,254]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:15:02,082]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:15:25,951]\u001b[0m Trial 1415 finished with value: 2.0741712448894423 and parameters: {'n_hidden': 3, 'learning_rate': 0.005015444125315534, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0659406371787517, 'dropout_rate_Layer_2': 0.23276604673813378, 'dropout_rate_Layer_3': 0.11549806936872808, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04574580614271308, 'l1_Layer_2': 0.0688778483152325, 'l1_Layer_3': 0.0003189811921149234, 'n_units_Layer_1': 55, 'n_units_Layer_2': 160, 'n_units_Layer_3': 225}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.88% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 11.56% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:15:32,530]\u001b[0m Trial 1414 finished with value: 2.065957768349674 and parameters: {'n_hidden': 3, 'learning_rate': 0.0042614212492401125, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04032896777292094, 'dropout_rate_Layer_2': 0.2375312495080593, 'dropout_rate_Layer_3': 0.27258056333416797, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04457088722618863, 'l1_Layer_2': 0.07572091538281726, 'l1_Layer_3': 0.00032740184261191536, 'n_units_Layer_1': 55, 'n_units_Layer_2': 155, 'n_units_Layer_3': 225}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.85% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.25 | sMAPE for Test Set is: 12.39% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:15:38,194]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:15:38,352]\u001b[0m Trial 1417 finished with value: 2.066201294494075 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017256092033856802, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008499685179516393, 'dropout_rate_Layer_2': 0.3433925955364984, 'dropout_rate_Layer_3': 0.20603878929327143, 'dropout_rate_Layer_4': 0.08245182770474363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.01271277576489266, 'l1_Layer_2': 0.00021909414702343713, 'l1_Layer_3': 0.0005743547556733321, 'l1_Layer_4': 0.0033636597153648873, 'n_units_Layer_1': 70, 'n_units_Layer_2': 125, 'n_units_Layer_3': 60, 'n_units_Layer_4': 290}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.81% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.19 | sMAPE for Test Set is: 19.47% | rMAE for Test Set is: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:15:43,764]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:16:01,852]\u001b[0m Trial 1416 finished with value: 2.1461822934346046 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010695175562452494, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06644471136031238, 'dropout_rate_Layer_2': 0.1039571106764598, 'dropout_rate_Layer_3': 0.021820711476291804, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017415757764746142, 'l1_Layer_2': 0.0005584573426700404, 'l1_Layer_3': 0.031757536095331156, 'n_units_Layer_1': 120, 'n_units_Layer_2': 105, 'n_units_Layer_3': 210}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.15 | sMAPE for Validation Set is: 7.20% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 15.36% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:16:05,884]\u001b[0m Trial 1418 finished with value: 2.1044751493180485 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017139348466266235, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007684635381494401, 'dropout_rate_Layer_2': 0.34358855924103243, 'dropout_rate_Layer_3': 0.2066911552533769, 'dropout_rate_Layer_4': 0.06394478797215994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.01735665429360683, 'l1_Layer_2': 0.00023405413984309493, 'l1_Layer_3': 0.0004460798106932783, 'l1_Layer_4': 0.003659551913904717, 'n_units_Layer_1': 70, 'n_units_Layer_2': 125, 'n_units_Layer_3': 60, 'n_units_Layer_4': 290}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 7.00% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.00 | sMAPE for Test Set is: 19.03% | rMAE for Test Set is: 1.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:16:08,451]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 6.93% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 15.43% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:16:10,314]\u001b[0m Trial 1422 finished with value: 2.0981828702450684 and parameters: {'n_hidden': 3, 'learning_rate': 0.0054618774395746115, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.040676424370578106, 'dropout_rate_Layer_2': 0.24293214620108552, 'dropout_rate_Layer_3': 0.12648649186139718, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03473943862120656, 'l1_Layer_2': 5.533643551540237e-05, 'l1_Layer_3': 0.0002547030282313433, 'n_units_Layer_1': 50, 'n_units_Layer_2': 150, 'n_units_Layer_3': 230}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:16:15,018]\u001b[0m Trial 1421 finished with value: 2.1004418379057275 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017296785921522455, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0001260272548781593, 'dropout_rate_Layer_2': 0.3420781668481394, 'dropout_rate_Layer_3': 0.20614204544597328, 'dropout_rate_Layer_4': 0.08952710362852181, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.01713655138963929, 'l1_Layer_2': 0.0002240135087121924, 'l1_Layer_3': 0.0005796821368917157, 'l1_Layer_4': 0.0024966882673429685, 'n_units_Layer_1': 80, 'n_units_Layer_2': 125, 'n_units_Layer_3': 65, 'n_units_Layer_4': 290}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 7.00% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.29 | sMAPE for Test Set is: 19.69% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:16:27,315]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:16:35,992]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:16:45,752]\u001b[0m Trial 1426 finished with value: 2.0743263219144317 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016467783099562816, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.003681783605103791, 'dropout_rate_Layer_2': 0.34210594221532464, 'dropout_rate_Layer_3': 0.20358689447853057, 'dropout_rate_Layer_4': 0.0652502733595302, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0180846186098665, 'l1_Layer_2': 0.00022072435109513321, 'l1_Layer_3': 0.0005926125491728683, 'l1_Layer_4': 0.007078454535432065, 'n_units_Layer_1': 80, 'n_units_Layer_2': 125, 'n_units_Layer_3': 65, 'n_units_Layer_4': 290}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.91% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.62 | sMAPE for Test Set is: 20.51% | rMAE for Test Set is: 1.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:16:51,483]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:16:52,151]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:17:05,755]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:17:18,013]\u001b[0m Trial 1427 finished with value: 2.080951265223199 and parameters: {'n_hidden': 3, 'learning_rate': 0.004571458395772407, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02772588694890799, 'dropout_rate_Layer_2': 0.24720997048230164, 'dropout_rate_Layer_3': 0.32559542616876913, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.040542488090270126, 'l1_Layer_2': 0.043359862918162635, 'l1_Layer_3': 0.0003198569167413802, 'n_units_Layer_1': 50, 'n_units_Layer_2': 145, 'n_units_Layer_3': 220}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.93% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 12.24% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:17:28,216]\u001b[0m Trial 1429 finished with value: 2.0664207551732408 and parameters: {'n_hidden': 3, 'learning_rate': 0.004399173939984502, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02784859864333488, 'dropout_rate_Layer_2': 0.23843359383145413, 'dropout_rate_Layer_3': 0.14645071163617646, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.041134806435837515, 'l1_Layer_2': 0.03356093856548114, 'l1_Layer_3': 0.0003071132535008701, 'n_units_Layer_1': 50, 'n_units_Layer_2': 155, 'n_units_Layer_3': 220}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:17:28,364]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.84% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.98 | sMAPE for Test Set is: 11.72% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:17:34,711]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:17:40,115]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:17:40,608]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:17:54,241]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:18:00,188]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:18:00,873]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:18:06,492]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:18:06,956]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:18:12,659]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:18:20,452]\u001b[0m Trial 1440 finished with value: 2.0686322265941115 and parameters: {'n_hidden': 3, 'learning_rate': 0.003848436482488934, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03628273485933935, 'dropout_rate_Layer_2': 0.2361199700738547, 'dropout_rate_Layer_3': 0.1576961263984415, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.019972632593554328, 'l1_Layer_2': 0.03376418258791129, 'l1_Layer_3': 0.00025158421493633545, 'n_units_Layer_1': 60, 'n_units_Layer_2': 160, 'n_units_Layer_3': 230}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.86% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 14.55% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:18:43,542]\u001b[0m Trial 1445 finished with value: 2.0873682560290256 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019890683699188396, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008637188923041696, 'dropout_rate_Layer_2': 0.3291061698090698, 'dropout_rate_Layer_3': 0.20993440449032272, 'dropout_rate_Layer_4': 0.08205479511258529, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.023346337918596038, 'l1_Layer_2': 0.0002004081914175802, 'l1_Layer_3': 0.0007162317103266545, 'l1_Layer_4': 0.007297827083704953, 'n_units_Layer_1': 85, 'n_units_Layer_2': 120, 'n_units_Layer_3': 60, 'n_units_Layer_4': 290}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.93% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.22 | sMAPE for Test Set is: 22.05% | rMAE for Test Set is: 1.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:18:48,770]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 7.06% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.83 | sMAPE for Test Set is: 11.34% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:18:50,464]\u001b[0m Trial 1443 finished with value: 2.131283705851663 and parameters: {'n_hidden': 3, 'learning_rate': 0.006302438061964036, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04339649904340824, 'dropout_rate_Layer_2': 0.23823617151900228, 'dropout_rate_Layer_3': 0.3459482328344079, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.031735120012275624, 'l1_Layer_2': 0.03474358763921441, 'l1_Layer_3': 0.0004120913046984842, 'n_units_Layer_1': 60, 'n_units_Layer_2': 160, 'n_units_Layer_3': 220}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:18:53,314]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:18:56,152]\u001b[0m Trial 1446 finished with value: 2.0433316613664396 and parameters: {'n_hidden': 3, 'learning_rate': 0.003389708482351447, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.045317259606878234, 'dropout_rate_Layer_2': 0.2580790578856049, 'dropout_rate_Layer_3': 0.3432940611952686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07413423710387242, 'l1_Layer_2': 0.05058037321283911, 'l1_Layer_3': 0.0004117570474543397, 'n_units_Layer_1': 60, 'n_units_Layer_2': 155, 'n_units_Layer_3': 215}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 6.76% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.75 | sMAPE for Test Set is: 13.49% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:18:57,846]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:18:59,982]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:19:04,241]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:19:05,988]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:19:10,219]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:19:17,835]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:19:27,438]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:19:31,152]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:19:42,164]\u001b[0m Trial 1455 finished with value: 2.0790459975006415 and parameters: {'n_hidden': 4, 'learning_rate': 0.002019605490090032, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011008508304598506, 'dropout_rate_Layer_2': 0.3304983321047436, 'dropout_rate_Layer_3': 0.2083388377367854, 'dropout_rate_Layer_4': 0.07495858930813452, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.023765063118913833, 'l1_Layer_2': 0.00017536792849469812, 'l1_Layer_3': 0.0007486544613713472, 'l1_Layer_4': 0.007985048534098108, 'n_units_Layer_1': 85, 'n_units_Layer_2': 115, 'n_units_Layer_3': 70, 'n_units_Layer_4': 290}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.91% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.67 | sMAPE for Test Set is: 20.68% | rMAE for Test Set is: 1.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:19:48,505]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:19:52,528]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:19:59,169]\u001b[0m Trial 1457 finished with value: 2.1443924350045913 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020639483550790837, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009016057787260445, 'dropout_rate_Layer_2': 0.3252914786162621, 'dropout_rate_Layer_3': 0.20742791347073125, 'dropout_rate_Layer_4': 0.09436497792749321, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.02302200476518355, 'l1_Layer_2': 0.00017538332847218615, 'l1_Layer_3': 0.0008271574325815064, 'l1_Layer_4': 0.006395912203124023, 'n_units_Layer_1': 85, 'n_units_Layer_2': 115, 'n_units_Layer_3': 70, 'n_units_Layer_4': 290}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.12% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.75 | sMAPE for Test Set is: 18.42% | rMAE for Test Set is: 1.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:20:02,025]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:20:06,365]\u001b[0m Trial 1451 finished with value: 2.066604773638635 and parameters: {'n_hidden': 3, 'learning_rate': 0.00326065800651637, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05420343074227771, 'dropout_rate_Layer_2': 0.2473566426904557, 'dropout_rate_Layer_3': 0.13193296037695196, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003519035344261468, 'l1_Layer_2': 0.055042495893353686, 'l1_Layer_3': 0.0004790409602938324, 'n_units_Layer_1': 65, 'n_units_Layer_2': 165, 'n_units_Layer_3': 215}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.86% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.99 | sMAPE for Test Set is: 11.74% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:20:12,042]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:20:14,564]\u001b[0m Trial 1459 finished with value: 2.09177764516081 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020413911538412874, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012416833753238056, 'dropout_rate_Layer_2': 0.3273705906814658, 'dropout_rate_Layer_3': 0.20975317703800903, 'dropout_rate_Layer_4': 0.08395787121262947, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.026740501749878857, 'l1_Layer_2': 0.00017398565263229224, 'l1_Layer_3': 0.0008217803020585192, 'l1_Layer_4': 0.0034449290607423792, 'n_units_Layer_1': 85, 'n_units_Layer_2': 120, 'n_units_Layer_3': 70, 'n_units_Layer_4': 290}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.95% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.01 | sMAPE for Test Set is: 16.53% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:20:22,992]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:20:26,098]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:20:30,301]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:20:30,962]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:20:37,398]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:20:41,658]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:20:46,399]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:20:47,763]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:20:52,147]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.12% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.17 | sMAPE for Test Set is: 21.95% | rMAE for Test Set is: 1.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:20:53,832]\u001b[0m Trial 1467 finished with value: 2.140066131781821 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018808818004726305, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012085846711280332, 'dropout_rate_Layer_2': 0.32937823566285673, 'dropout_rate_Layer_3': 0.2095710401908326, 'dropout_rate_Layer_4': 0.1068281449612834, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.030041190326919046, 'l1_Layer_2': 0.0001936163736202515, 'l1_Layer_3': 0.0008279174522578234, 'l1_Layer_4': 0.007652360437116076, 'n_units_Layer_1': 85, 'n_units_Layer_2': 125, 'n_units_Layer_3': 60, 'n_units_Layer_4': 300}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:21:05,716]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:21:07,920]\u001b[0m Trial 1468 finished with value: 2.140308152639222 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019010080426943468, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008917387586290959, 'dropout_rate_Layer_2': 0.34101868826060927, 'dropout_rate_Layer_3': 0.20099523313395654, 'dropout_rate_Layer_4': 0.07006645375871438, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.02900694030680076, 'l1_Layer_2': 0.00018788099743124277, 'l1_Layer_3': 0.0009126246467002028, 'l1_Layer_4': 0.003353435909575226, 'n_units_Layer_1': 75, 'n_units_Layer_2': 125, 'n_units_Layer_3': 65, 'n_units_Layer_4': 290}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 7.15% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.95 | sMAPE for Test Set is: 18.90% | rMAE for Test Set is: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:21:13,672]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:21:24,222]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:21:31,926]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:21:37,104]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:21:45,438]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:21:49,304]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:21:55,842]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:21:58,713]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:22:03,233]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:22:10,065]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:22:14,038]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:22:15,136]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:22:26,034]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:22:33,117]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:22:36,797]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:22:40,739]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:22:41,525]\u001b[0m Trial 1477 finished with value: 1.926089363630923 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008632824294601824, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015752283207715587, 'dropout_rate_Layer_2': 0.06533872847708215, 'dropout_rate_Layer_3': 0.011933022842037993, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014582601220094983, 'l1_Layer_2': 0.0005813311971313076, 'l1_Layer_3': 0.0008499474198441015, 'n_units_Layer_1': 120, 'n_units_Layer_2': 85, 'n_units_Layer_3': 195}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 6.40% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.25 | sMAPE for Test Set is: 14.66% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:22:45,209]\u001b[0m Trial 1488 finished with value: 2.1014939118585994 and parameters: {'n_hidden': 3, 'learning_rate': 0.005160511466436397, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03236538019395735, 'dropout_rate_Layer_2': 0.2171079533411712, 'dropout_rate_Layer_3': 0.12137832895018488, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.035462271114086195, 'l1_Layer_2': 0.07417763380644081, 'l1_Layer_3': 0.00042144678995000343, 'n_units_Layer_1': 65, 'n_units_Layer_2': 175, 'n_units_Layer_3': 135}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 6.95% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.16 | sMAPE for Test Set is: 14.48% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:23:02,916]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:23:07,957]\u001b[0m Trial 1492 finished with value: 2.100338621858778 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023227079482797588, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005833217498041807, 'dropout_rate_Layer_2': 0.34403146164528503, 'dropout_rate_Layer_3': 0.18634359310635218, 'dropout_rate_Layer_4': 0.08829911817264634, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.021286913042320298, 'l1_Layer_2': 0.00024153243996970073, 'l1_Layer_3': 0.000471912113936582, 'l1_Layer_4': 0.004794658954095713, 'n_units_Layer_1': 85, 'n_units_Layer_2': 120, 'n_units_Layer_3': 70, 'n_units_Layer_4': 285}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 6.95% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.73 | sMAPE for Test Set is: 18.36% | rMAE for Test Set is: 1.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:23:18,058]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:23:24,147]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 15:23:25,631]\u001b[0m Trial 1495 finished with value: 2.0918546128406206 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017550985561420032, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018155923108837714, 'dropout_rate_Layer_2': 0.34458110624070515, 'dropout_rate_Layer_3': 0.18637950225345729, 'dropout_rate_Layer_4': 0.09300648762516915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.020131854779387014, 'l1_Layer_2': 0.00013650282795587046, 'l1_Layer_3': 0.0005181614134284953, 'l1_Layer_4': 0.004873595326847511, 'n_units_Layer_1': 75, 'n_units_Layer_2': 185, 'n_units_Layer_3': 60, 'n_units_Layer_4': 285}. Best is trial 1110 with value: 1.87042595845139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.96% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.46 | sMAPE for Test Set is: 17.70% | rMAE for Test Set is: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 15:23:26,011]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-01-01, MAE is:0.52 & sMAPE is:2.00% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :0.52 & 2.00% & 1.51\n",
      "for 2018-01-02, MAE is:4.85 & sMAPE is:15.30% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :2.69 & 8.65% & 1.16\n",
      "for 2018-01-03, MAE is:0.91 & sMAPE is:3.12% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 6.81% & 0.89\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EE45C3A040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-04, MAE is:3.10 & sMAPE is:9.45% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :2.35 & 7.47% & 1.16\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EF003B34C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-05, MAE is:1.20 & sMAPE is:3.77% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 6.73% & 1.03\n",
      "for 2018-01-06, MAE is:1.09 & sMAPE is:3.38% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :1.95 & 6.17% & 0.90\n",
      "for 2018-01-07, MAE is:1.81 & sMAPE is:6.21% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :1.93 & 6.18% & 0.92\n",
      "for 2018-01-08, MAE is:2.35 & sMAPE is:7.79% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :1.98 & 6.38% & 0.87\n",
      "for 2018-01-09, MAE is:1.01 & sMAPE is:3.42% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :1.87 & 6.05% & 0.82\n",
      "for 2018-01-10, MAE is:9.91 & sMAPE is:25.79% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.68 & 8.02% & 0.83\n",
      "for 2018-01-11, MAE is:9.29 & sMAPE is:21.47% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 9.25% & 0.83\n",
      "for 2018-01-12, MAE is:3.82 & sMAPE is:10.46% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 9.35% & 0.83\n",
      "for 2018-01-13, MAE is:1.60 & sMAPE is:5.18% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :3.19 & 9.03% & 0.93\n",
      "for 2018-01-14, MAE is:1.00 & sMAPE is:3.25% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.03 & 8.61% & 0.91\n",
      "for 2018-01-15, MAE is:1.93 & sMAPE is:6.43% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.96 & 8.47% & 0.93\n",
      "for 2018-01-16, MAE is:2.49 & sMAPE is:7.91% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :2.93 & 8.43% & 1.00\n",
      "for 2018-01-17, MAE is:3.14 & sMAPE is:8.99% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 8.47% & 0.97\n",
      "for 2018-01-18, MAE is:4.48 & sMAPE is:12.67% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.03 & 8.70% & 0.95\n",
      "for 2018-01-19, MAE is:5.79 & sMAPE is:14.48% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.17 & 9.00% & 0.98\n",
      "for 2018-01-20, MAE is:2.27 & sMAPE is:6.80% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.13 & 8.89% & 1.02\n",
      "for 2018-01-21, MAE is:0.99 & sMAPE is:3.03% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.03 & 8.61% & 0.99\n",
      "for 2018-01-22, MAE is:7.85 & sMAPE is:19.89% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 9.13% & 0.98\n",
      "for 2018-01-23, MAE is:4.08 & sMAPE is:10.80% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 9.20% & 0.97\n",
      "for 2018-01-24, MAE is:1.35 & sMAPE is:4.55% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.20 & 9.01% & 0.94\n",
      "for 2018-01-25, MAE is:0.79 & sMAPE is:2.58% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 8.75% & 0.91\n",
      "for 2018-01-26, MAE is:1.30 & sMAPE is:4.09% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :3.04 & 8.57% & 0.88\n",
      "for 2018-01-27, MAE is:1.44 & sMAPE is:4.70% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :2.98 & 8.43% & 0.89\n",
      "for 2018-01-28, MAE is:0.88 & sMAPE is:3.08% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.90 & 8.24% & 0.86\n",
      "for 2018-01-29, MAE is:1.28 & sMAPE is:4.42% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :2.85 & 8.10% & 0.84\n",
      "for 2018-01-30, MAE is:2.04 & sMAPE is:5.99% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :2.82 & 8.03% & 0.82\n",
      "for 2018-01-31, MAE is:2.32 & sMAPE is:7.31% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :2.80 & 8.01% & 0.86\n",
      "for 2018-02-01, MAE is:1.35 & sMAPE is:4.43% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.76 & 7.90% & 0.87\n",
      "for 2018-02-02, MAE is:3.08 & sMAPE is:9.17% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.77 & 7.94% & 0.89\n",
      "for 2018-02-03, MAE is:1.53 & sMAPE is:4.34% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.73 & 7.83% & 0.88\n",
      "for 2018-02-04, MAE is:1.75 & sMAPE is:5.00% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :2.70 & 7.75% & 0.87\n",
      "for 2018-02-05, MAE is:10.58 & sMAPE is:24.09% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.92 & 8.20% & 0.86\n",
      "for 2018-02-06, MAE is:9.29 & sMAPE is:19.70% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :3.09 & 8.51% & 0.85\n",
      "for 2018-02-07, MAE is:7.40 & sMAPE is:15.69% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.21 & 8.70% & 0.84\n",
      "for 2018-02-08, MAE is:4.24 & sMAPE is:10.60% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.23 & 8.75% & 0.84\n",
      "for 2018-02-09, MAE is:0.76 & sMAPE is:2.39% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.17 & 8.59% & 0.83\n",
      "for 2018-02-10, MAE is:1.31 & sMAPE is:4.13% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.13 & 8.48% & 0.82\n",
      "for 2018-02-11, MAE is:0.81 & sMAPE is:2.69% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 8.35% & 0.81\n",
      "for 2018-02-12, MAE is:1.03 & sMAPE is:3.19% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :3.02 & 8.23% & 0.79\n",
      "for 2018-02-13, MAE is:4.11 & sMAPE is:10.50% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.05 & 8.28% & 0.78\n",
      "for 2018-02-14, MAE is:2.35 & sMAPE is:6.75% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :3.03 & 8.24% & 0.77\n",
      "for 2018-02-15, MAE is:1.11 & sMAPE is:3.33% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 8.14% & 0.76\n",
      "for 2018-02-16, MAE is:3.17 & sMAPE is:8.71% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :2.99 & 8.15% & 0.76\n",
      "for 2018-02-17, MAE is:4.57 & sMAPE is:12.21% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :3.03 & 8.23% & 0.76\n",
      "for 2018-02-18, MAE is:2.56 & sMAPE is:6.87% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.02 & 8.21% & 0.75\n",
      "for 2018-02-19, MAE is:11.60 & sMAPE is:24.94% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :3.19 & 8.54% & 0.75\n",
      "for 2018-02-20, MAE is:8.72 & sMAPE is:18.30% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :3.30 & 8.73% & 0.75\n",
      "for 2018-02-21, MAE is:5.96 & sMAPE is:12.44% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 8.80% & 0.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-02-22, MAE is:7.92 & sMAPE is:16.52% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 8.95% & 0.74\n",
      "for 2018-02-23, MAE is:4.94 & sMAPE is:10.51% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.46 & 8.98% & 0.74\n",
      "for 2018-02-24, MAE is:1.71 & sMAPE is:4.56% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :3.43 & 8.90% & 0.74\n",
      "for 2018-02-25, MAE is:2.13 & sMAPE is:5.65% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.41 & 8.84% & 0.74\n",
      "for 2018-02-26, MAE is:5.57 & sMAPE is:11.58% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :3.45 & 8.89% & 0.74\n",
      "for 2018-02-27, MAE is:4.59 & sMAPE is:9.49% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.47 & 8.90% & 0.74\n",
      "for 2018-02-28, MAE is:6.78 & sMAPE is:12.76% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :3.52 & 8.96% & 0.76\n",
      "for 2018-03-01, MAE is:50.66 & sMAPE is:52.90% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 9.70% & 0.77\n",
      "for 2018-03-02, MAE is:14.67 & sMAPE is:22.02% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 9.90% & 0.77\n",
      "for 2018-03-03, MAE is:3.59 & sMAPE is:8.32% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 9.87% & 0.77\n",
      "for 2018-03-04, MAE is:2.05 & sMAPE is:5.15% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 9.80% & 0.78\n",
      "for 2018-03-05, MAE is:10.40 & sMAPE is:19.40% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 9.95% & 0.78\n",
      "for 2018-03-06, MAE is:5.90 & sMAPE is:11.98% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 9.98% & 0.79\n",
      "for 2018-03-07, MAE is:6.17 & sMAPE is:12.81% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 10.02% & 0.80\n",
      "for 2018-03-08, MAE is:8.69 & sMAPE is:19.70% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 10.17% & 0.79\n",
      "for 2018-03-09, MAE is:2.69 & sMAPE is:6.52% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 10.11% & 0.78\n",
      "for 2018-03-10, MAE is:2.81 & sMAPE is:7.15% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 10.07% & 0.77\n",
      "for 2018-03-11, MAE is:0.85 & sMAPE is:2.35% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 9.96% & 0.77\n",
      "for 2018-03-12, MAE is:4.43 & sMAPE is:10.39% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 9.97% & 0.76\n",
      "for 2018-03-13, MAE is:2.35 & sMAPE is:5.47% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 9.90% & 0.76\n",
      "for 2018-03-14, MAE is:7.30 & sMAPE is:14.93% & rMAE is:5.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 9.97% & 0.82\n",
      "for 2018-03-15, MAE is:5.33 & sMAPE is:10.64% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 9.98% & 0.82\n",
      "for 2018-03-16, MAE is:2.60 & sMAPE is:6.37% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 9.93% & 0.82\n",
      "for 2018-03-17, MAE is:1.41 & sMAPE is:3.69% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.47 & 9.85% & 0.83\n",
      "for 2018-03-18, MAE is:2.17 & sMAPE is:5.82% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 9.80% & 0.84\n",
      "for 2018-03-19, MAE is:3.26 & sMAPE is:7.36% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 9.77% & 0.85\n",
      "for 2018-03-20, MAE is:4.05 & sMAPE is:8.95% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 9.76% & 0.86\n",
      "for 2018-03-21, MAE is:2.50 & sMAPE is:5.75% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 9.71% & 0.85\n",
      "for 2018-03-22, MAE is:1.63 & sMAPE is:3.93% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 9.64% & 0.85\n",
      "for 2018-03-23, MAE is:5.58 & sMAPE is:11.02% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.38 & 9.65% & 0.85\n",
      "for 2018-03-24, MAE is:1.75 & sMAPE is:4.48% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.35 & 9.59% & 0.85\n",
      "for 2018-03-25, MAE is:1.51 & sMAPE is:3.88% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 9.52% & 0.85\n",
      "for 2018-03-26, MAE is:5.88 & sMAPE is:12.09% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 9.55% & 0.85\n",
      "for 2018-03-27, MAE is:3.45 & sMAPE is:6.89% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 9.52% & 0.85\n",
      "for 2018-03-28, MAE is:5.57 & sMAPE is:12.10% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 9.55% & 0.85\n",
      "for 2018-03-29, MAE is:1.62 & sMAPE is:4.04% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 9.49% & 0.86\n",
      "for 2018-03-30, MAE is:2.53 & sMAPE is:5.89% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 9.45% & 0.85\n",
      "for 2018-03-31, MAE is:2.11 & sMAPE is:5.29% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.26 & 9.40% & 0.86\n",
      "for 2018-04-01, MAE is:2.62 & sMAPE is:6.63% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 9.37% & 0.87\n",
      "for 2018-04-02, MAE is:2.08 & sMAPE is:5.05% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 9.32% & 0.87\n",
      "for 2018-04-03, MAE is:2.75 & sMAPE is:6.32% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 9.29% & 0.87\n",
      "for 2018-04-04, MAE is:2.10 & sMAPE is:4.78% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 9.24% & 0.86\n",
      "for 2018-04-05, MAE is:2.63 & sMAPE is:6.12% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 9.21% & 0.87\n",
      "for 2018-04-06, MAE is:2.09 & sMAPE is:5.12% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 9.17% & 0.88\n",
      "for 2018-04-07, MAE is:1.32 & sMAPE is:3.49% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 9.11% & 0.88\n",
      "for 2018-04-08, MAE is:1.99 & sMAPE is:5.17% & rMAE is:3.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 9.07% & 0.91\n",
      "for 2018-04-09, MAE is:3.71 & sMAPE is:8.50% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 9.06% & 0.91\n",
      "for 2018-04-10, MAE is:1.17 & sMAPE is:2.94% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 9.00% & 0.90\n",
      "for 2018-04-11, MAE is:1.19 & sMAPE is:2.96% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 8.94% & 0.90\n",
      "for 2018-04-12, MAE is:2.23 & sMAPE is:5.51% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 8.91% & 0.90\n",
      "for 2018-04-13, MAE is:2.03 & sMAPE is:5.07% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 8.87% & 0.91\n",
      "for 2018-04-14, MAE is:1.45 & sMAPE is:3.87% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 8.82% & 0.92\n",
      "for 2018-04-15, MAE is:1.72 & sMAPE is:4.49% & rMAE is:4.87 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 8.78% & 0.95\n",
      "for 2018-04-16, MAE is:6.67 & sMAPE is:14.07% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 8.83% & 0.96\n",
      "for 2018-04-17, MAE is:2.73 & sMAPE is:5.95% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :3.96 & 8.81% & 0.96\n",
      "for 2018-04-18, MAE is:2.19 & sMAPE is:5.04% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 8.77% & 0.96\n",
      "for 2018-04-19, MAE is:2.25 & sMAPE is:5.57% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 8.74% & 0.96\n",
      "for 2018-04-20, MAE is:1.48 & sMAPE is:4.05% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 8.70% & 0.96\n",
      "for 2018-04-21, MAE is:2.82 & sMAPE is:8.91% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 8.70% & 0.95\n",
      "for 2018-04-22, MAE is:1.09 & sMAPE is:3.21% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :3.87 & 8.65% & 0.94\n",
      "for 2018-04-23, MAE is:2.20 & sMAPE is:6.97% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :3.86 & 8.64% & 0.94\n",
      "for 2018-04-24, MAE is:1.89 & sMAPE is:5.65% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 8.61% & 0.93\n",
      "for 2018-04-25, MAE is:1.05 & sMAPE is:2.87% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :3.82 & 8.56% & 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-04-26, MAE is:1.43 & sMAPE is:3.84% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 8.52% & 0.92\n",
      "for 2018-04-27, MAE is:1.39 & sMAPE is:3.76% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 8.48% & 0.93\n",
      "for 2018-04-28, MAE is:0.96 & sMAPE is:2.71% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 8.43% & 0.92\n",
      "for 2018-04-29, MAE is:1.84 & sMAPE is:5.21% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :3.73 & 8.40% & 0.93\n",
      "for 2018-04-30, MAE is:1.03 & sMAPE is:3.08% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.71 & 8.36% & 0.92\n",
      "for 2018-05-01, MAE is:1.45 & sMAPE is:4.27% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :3.69 & 8.33% & 0.92\n",
      "for 2018-05-02, MAE is:2.30 & sMAPE is:6.39% & rMAE is:2.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 8.31% & 0.93\n",
      "for 2018-05-03, MAE is:1.06 & sMAPE is:2.94% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :3.66 & 8.27% & 0.93\n",
      "for 2018-05-04, MAE is:0.99 & sMAPE is:2.76% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 8.22% & 0.94\n",
      "for 2018-05-05, MAE is:2.63 & sMAPE is:8.11% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 8.22% & 0.93\n",
      "for 2018-05-06, MAE is:3.07 & sMAPE is:10.99% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 8.24% & 0.93\n",
      "for 2018-05-07, MAE is:3.65 & sMAPE is:13.90% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 8.29% & 0.93\n",
      "for 2018-05-08, MAE is:3.09 & sMAPE is:10.57% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.62 & 8.30% & 0.93\n",
      "for 2018-05-09, MAE is:6.39 & sMAPE is:29.73% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 8.47% & 0.92\n",
      "for 2018-05-10, MAE is:6.60 & sMAPE is:53.81% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 8.82% & 0.92\n",
      "for 2018-05-11, MAE is:13.96 & sMAPE is:67.62% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 9.27% & 0.92\n",
      "for 2018-05-12, MAE is:4.40 & sMAPE is:16.45% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 9.32% & 0.93\n",
      "for 2018-05-13, MAE is:7.86 & sMAPE is:37.67% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :3.78 & 9.54% & 0.93\n",
      "for 2018-05-14, MAE is:11.57 & sMAPE is:40.14% & rMAE is:4.10 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 9.76% & 0.96\n",
      "for 2018-05-15, MAE is:2.64 & sMAPE is:7.47% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 9.75% & 0.95\n",
      "for 2018-05-16, MAE is:3.01 & sMAPE is:8.80% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.82 & 9.74% & 0.95\n",
      "for 2018-05-17, MAE is:5.09 & sMAPE is:18.04% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 9.80% & 0.94\n",
      "for 2018-05-18, MAE is:4.66 & sMAPE is:13.56% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 9.83% & 0.94\n",
      "for 2018-05-19, MAE is:2.38 & sMAPE is:7.06% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 9.81% & 0.94\n",
      "for 2018-05-20, MAE is:6.95 & sMAPE is:25.83% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 9.92% & 0.94\n",
      "for 2018-05-21, MAE is:11.79 & sMAPE is:49.77% & rMAE is:3.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 10.21% & 0.95\n",
      "for 2018-05-22, MAE is:7.89 & sMAPE is:22.67% & rMAE is:3.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 10.29% & 0.97\n",
      "for 2018-05-23, MAE is:1.98 & sMAPE is:5.16% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 10.26% & 0.97\n",
      "for 2018-05-24, MAE is:3.43 & sMAPE is:8.64% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 10.25% & 0.96\n",
      "for 2018-05-25, MAE is:2.78 & sMAPE is:7.00% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.91 & 10.22% & 0.96\n",
      "for 2018-05-26, MAE is:1.76 & sMAPE is:4.56% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 10.18% & 0.96\n",
      "for 2018-05-27, MAE is:1.82 & sMAPE is:4.76% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 10.15% & 0.95\n",
      "for 2018-05-28, MAE is:4.26 & sMAPE is:10.77% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 10.15% & 0.95\n",
      "for 2018-05-29, MAE is:2.20 & sMAPE is:5.22% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.87 & 10.12% & 0.94\n",
      "for 2018-05-30, MAE is:3.52 & sMAPE is:8.36% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.87 & 10.11% & 0.94\n",
      "for 2018-05-31, MAE is:1.27 & sMAPE is:2.88% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 10.06% & 0.94\n",
      "for 2018-06-01, MAE is:3.34 & sMAPE is:7.56% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :3.85 & 10.04% & 0.94\n",
      "for 2018-06-02, MAE is:0.96 & sMAPE is:2.24% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 9.99% & 0.93\n",
      "for 2018-06-03, MAE is:1.30 & sMAPE is:3.12% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 9.95% & 0.93\n",
      "for 2018-06-04, MAE is:1.43 & sMAPE is:3.31% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 9.90% & 0.93\n",
      "for 2018-06-05, MAE is:1.65 & sMAPE is:3.70% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 9.86% & 0.93\n",
      "for 2018-06-06, MAE is:1.75 & sMAPE is:3.90% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 9.83% & 0.92\n",
      "for 2018-06-07, MAE is:2.35 & sMAPE is:5.14% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :3.76 & 9.80% & 0.92\n",
      "for 2018-06-08, MAE is:1.60 & sMAPE is:3.40% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.75 & 9.76% & 0.92\n",
      "for 2018-06-09, MAE is:1.22 & sMAPE is:2.70% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.73 & 9.71% & 0.91\n",
      "for 2018-06-10, MAE is:1.44 & sMAPE is:3.23% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :3.72 & 9.67% & 0.91\n",
      "for 2018-06-11, MAE is:0.98 & sMAPE is:2.13% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 9.63% & 0.91\n",
      "for 2018-06-12, MAE is:1.61 & sMAPE is:3.48% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.69 & 9.59% & 0.91\n",
      "for 2018-06-13, MAE is:1.54 & sMAPE is:3.31% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 9.55% & 0.91\n",
      "for 2018-06-14, MAE is:1.78 & sMAPE is:3.83% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 9.52% & 0.91\n",
      "for 2018-06-15, MAE is:1.32 & sMAPE is:3.09% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.65 & 9.48% & 0.91\n",
      "for 2018-06-16, MAE is:1.02 & sMAPE is:2.39% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.64 & 9.43% & 0.91\n",
      "for 2018-06-17, MAE is:1.18 & sMAPE is:2.75% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.62 & 9.39% & 0.91\n",
      "for 2018-06-18, MAE is:0.98 & sMAPE is:2.27% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.61 & 9.35% & 0.90\n",
      "for 2018-06-19, MAE is:1.80 & sMAPE is:4.29% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.59 & 9.32% & 0.90\n",
      "for 2018-06-20, MAE is:1.62 & sMAPE is:3.88% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 9.29% & 0.90\n",
      "for 2018-06-21, MAE is:2.22 & sMAPE is:5.35% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 9.27% & 0.90\n",
      "for 2018-06-22, MAE is:2.26 & sMAPE is:5.34% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :3.57 & 9.25% & 0.89\n",
      "for 2018-06-23, MAE is:1.88 & sMAPE is:4.71% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.56 & 9.22% & 0.89\n",
      "for 2018-06-24, MAE is:2.55 & sMAPE is:6.20% & rMAE is:3.56 ||| daily mean of MAE & sMAPE & rMAE till now are :3.55 & 9.20% & 0.91\n",
      "for 2018-06-25, MAE is:1.97 & sMAPE is:4.53% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.54 & 9.18% & 0.91\n",
      "for 2018-06-26, MAE is:3.07 & sMAPE is:6.81% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :3.54 & 9.16% & 0.91\n",
      "for 2018-06-27, MAE is:2.56 & sMAPE is:5.67% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.54 & 9.14% & 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-06-28, MAE is:1.28 & sMAPE is:2.78% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.52 & 9.11% & 0.91\n",
      "for 2018-06-29, MAE is:2.74 & sMAPE is:6.15% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :3.52 & 9.09% & 0.91\n",
      "for 2018-06-30, MAE is:2.17 & sMAPE is:4.96% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.51 & 9.07% & 0.91\n",
      "for 2018-07-01, MAE is:1.98 & sMAPE is:4.46% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.50 & 9.04% & 0.90\n",
      "for 2018-07-02, MAE is:4.52 & sMAPE is:9.44% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.51 & 9.04% & 0.90\n",
      "for 2018-07-03, MAE is:2.35 & sMAPE is:4.65% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.50 & 9.02% & 0.90\n",
      "for 2018-07-04, MAE is:4.18 & sMAPE is:7.99% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.51 & 9.01% & 0.90\n",
      "for 2018-07-05, MAE is:3.43 & sMAPE is:6.22% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.50 & 9.00% & 0.90\n",
      "for 2018-07-06, MAE is:1.91 & sMAPE is:3.74% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.50 & 8.97% & 0.90\n",
      "for 2018-07-07, MAE is:1.48 & sMAPE is:3.25% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :3.49 & 8.94% & 0.90\n",
      "for 2018-07-08, MAE is:3.28 & sMAPE is:7.05% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.48 & 8.93% & 0.90\n",
      "for 2018-07-09, MAE is:2.03 & sMAPE is:4.10% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.48 & 8.91% & 0.90\n",
      "for 2018-07-10, MAE is:3.03 & sMAPE is:5.72% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.47 & 8.89% & 0.90\n",
      "for 2018-07-11, MAE is:1.13 & sMAPE is:2.13% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :3.46 & 8.85% & 0.90\n",
      "for 2018-07-12, MAE is:1.93 & sMAPE is:3.74% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.45 & 8.83% & 0.90\n",
      "for 2018-07-13, MAE is:1.52 & sMAPE is:2.97% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 8.80% & 0.90\n",
      "for 2018-07-14, MAE is:2.33 & sMAPE is:4.44% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 8.77% & 0.90\n",
      "for 2018-07-15, MAE is:1.94 & sMAPE is:3.77% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :3.43 & 8.75% & 0.90\n",
      "for 2018-07-16, MAE is:1.36 & sMAPE is:2.60% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 8.72% & 0.89\n",
      "for 2018-07-17, MAE is:1.22 & sMAPE is:2.31% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.41 & 8.69% & 0.89\n",
      "for 2018-07-18, MAE is:1.21 & sMAPE is:2.42% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :3.40 & 8.65% & 0.89\n",
      "for 2018-07-19, MAE is:1.65 & sMAPE is:3.27% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :3.39 & 8.63% & 0.89\n",
      "for 2018-07-20, MAE is:1.20 & sMAPE is:2.32% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.38 & 8.60% & 0.90\n",
      "for 2018-07-21, MAE is:1.45 & sMAPE is:2.88% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.37 & 8.57% & 0.90\n",
      "for 2018-07-22, MAE is:2.35 & sMAPE is:4.53% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 8.55% & 0.90\n",
      "for 2018-07-23, MAE is:1.13 & sMAPE is:2.11% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 8.52% & 0.90\n",
      "for 2018-07-24, MAE is:1.42 & sMAPE is:2.67% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 8.49% & 0.90\n",
      "for 2018-07-25, MAE is:2.02 & sMAPE is:3.87% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 8.47% & 0.90\n",
      "for 2018-07-26, MAE is:1.43 & sMAPE is:2.70% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.44% & 0.90\n",
      "for 2018-07-27, MAE is:1.04 & sMAPE is:2.02% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.41% & 0.90\n",
      "for 2018-07-28, MAE is:1.84 & sMAPE is:3.65% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 8.38% & 0.90\n",
      "for 2018-07-29, MAE is:1.82 & sMAPE is:3.56% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :3.30 & 8.36% & 0.90\n",
      "for 2018-07-30, MAE is:1.63 & sMAPE is:3.13% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.29 & 8.34% & 0.90\n",
      "for 2018-07-31, MAE is:1.36 & sMAPE is:2.62% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.29 & 8.31% & 0.90\n",
      "for 2018-08-01, MAE is:1.71 & sMAPE is:3.26% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 8.29% & 0.91\n",
      "for 2018-08-02, MAE is:2.02 & sMAPE is:3.84% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.27 & 8.26% & 0.91\n",
      "for 2018-08-03, MAE is:2.02 & sMAPE is:3.89% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :3.27 & 8.24% & 0.92\n",
      "for 2018-08-04, MAE is:2.06 & sMAPE is:4.11% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :3.26 & 8.23% & 0.92\n",
      "for 2018-08-05, MAE is:2.69 & sMAPE is:5.46% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.26 & 8.21% & 0.92\n",
      "for 2018-08-06, MAE is:2.23 & sMAPE is:4.43% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 8.20% & 0.92\n",
      "for 2018-08-07, MAE is:4.86 & sMAPE is:8.98% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :3.26 & 8.20% & 0.93\n",
      "for 2018-08-08, MAE is:1.92 & sMAPE is:3.61% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.26 & 8.18% & 0.92\n",
      "for 2018-08-09, MAE is:2.58 & sMAPE is:5.18% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 8.16% & 0.92\n",
      "for 2018-08-10, MAE is:2.08 & sMAPE is:4.32% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 8.15% & 0.92\n",
      "for 2018-08-11, MAE is:2.06 & sMAPE is:4.34% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.24 & 8.13% & 0.92\n",
      "for 2018-08-12, MAE is:3.17 & sMAPE is:6.79% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :3.24 & 8.12% & 0.92\n",
      "for 2018-08-13, MAE is:1.25 & sMAPE is:2.58% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.23 & 8.10% & 0.92\n",
      "for 2018-08-14, MAE is:3.22 & sMAPE is:6.41% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.23 & 8.09% & 0.92\n",
      "for 2018-08-15, MAE is:1.81 & sMAPE is:3.44% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :3.23 & 8.07% & 0.92\n",
      "for 2018-08-16, MAE is:1.48 & sMAPE is:2.97% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.22 & 8.05% & 0.92\n",
      "for 2018-08-17, MAE is:2.56 & sMAPE is:5.33% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :3.22 & 8.04% & 0.92\n",
      "for 2018-08-18, MAE is:2.46 & sMAPE is:5.44% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :3.21 & 8.03% & 0.92\n",
      "for 2018-08-19, MAE is:2.76 & sMAPE is:6.20% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :3.21 & 8.02% & 0.92\n",
      "for 2018-08-20, MAE is:1.86 & sMAPE is:3.92% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.20 & 8.00% & 0.92\n",
      "for 2018-08-21, MAE is:2.26 & sMAPE is:4.84% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.20 & 7.99% & 0.92\n",
      "for 2018-08-22, MAE is:2.66 & sMAPE is:5.65% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.20 & 7.98% & 0.92\n",
      "for 2018-08-23, MAE is:2.61 & sMAPE is:5.54% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :3.20 & 7.97% & 0.92\n",
      "for 2018-08-24, MAE is:2.43 & sMAPE is:5.05% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.19 & 7.95% & 0.93\n",
      "for 2018-08-25, MAE is:3.01 & sMAPE is:6.36% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.19 & 7.95% & 0.93\n",
      "for 2018-08-26, MAE is:2.06 & sMAPE is:4.32% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.19 & 7.93% & 0.92\n",
      "for 2018-08-27, MAE is:1.49 & sMAPE is:2.98% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.18 & 7.91% & 0.92\n",
      "for 2018-08-28, MAE is:5.42 & sMAPE is:10.35% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :3.19 & 7.92% & 0.92\n",
      "for 2018-08-29, MAE is:3.20 & sMAPE is:6.12% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.19 & 7.91% & 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-08-30, MAE is:2.05 & sMAPE is:3.86% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.18 & 7.90% & 0.92\n",
      "for 2018-08-31, MAE is:5.66 & sMAPE is:9.92% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :3.19 & 7.91% & 0.92\n",
      "for 2018-09-01, MAE is:2.42 & sMAPE is:4.20% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.19 & 7.89% & 0.91\n",
      "for 2018-09-02, MAE is:3.01 & sMAPE is:5.26% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.19 & 7.88% & 0.91\n",
      "for 2018-09-03, MAE is:7.52 & sMAPE is:12.59% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :3.21 & 7.90% & 0.91\n",
      "for 2018-09-04, MAE is:7.56 & sMAPE is:12.38% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :3.23 & 7.92% & 0.91\n",
      "for 2018-09-05, MAE is:5.64 & sMAPE is:8.94% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.24 & 7.92% & 0.91\n",
      "for 2018-09-06, MAE is:3.96 & sMAPE is:6.15% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.24 & 7.91% & 0.91\n",
      "for 2018-09-07, MAE is:2.38 & sMAPE is:4.07% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :3.23 & 7.90% & 0.91\n",
      "for 2018-09-08, MAE is:2.04 & sMAPE is:3.90% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.23 & 7.88% & 0.91\n",
      "for 2018-09-09, MAE is:2.27 & sMAPE is:4.29% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :3.23 & 7.87% & 0.91\n",
      "for 2018-09-10, MAE is:1.36 & sMAPE is:2.48% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :3.22 & 7.85% & 0.90\n",
      "for 2018-09-11, MAE is:1.74 & sMAPE is:3.14% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :3.21 & 7.83% & 0.90\n",
      "for 2018-09-12, MAE is:1.17 & sMAPE is:2.25% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :3.21 & 7.81% & 0.90\n",
      "for 2018-09-13, MAE is:3.13 & sMAPE is:6.03% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.20 & 7.80% & 0.90\n",
      "for 2018-09-14, MAE is:1.95 & sMAPE is:3.67% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.20 & 7.78% & 0.89\n",
      "for 2018-09-15, MAE is:2.86 & sMAPE is:5.57% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.20 & 7.78% & 0.89\n",
      "for 2018-09-16, MAE is:2.15 & sMAPE is:4.32% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.19 & 7.76% & 0.89\n",
      "for 2018-09-17, MAE is:2.33 & sMAPE is:4.67% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.19 & 7.75% & 0.89\n",
      "for 2018-09-18, MAE is:1.60 & sMAPE is:3.27% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :3.19 & 7.73% & 0.89\n",
      "for 2018-09-19, MAE is:1.91 & sMAPE is:4.09% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :3.18 & 7.72% & 0.89\n",
      "for 2018-09-20, MAE is:2.87 & sMAPE is:7.20% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.18 & 7.72% & 0.88\n",
      "for 2018-09-21, MAE is:6.05 & sMAPE is:19.43% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.19 & 7.76% & 0.88\n",
      "for 2018-09-22, MAE is:8.82 & sMAPE is:52.09% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :3.21 & 7.93% & 0.88\n",
      "for 2018-09-23, MAE is:14.71 & sMAPE is:46.56% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 8.07% & 0.88\n",
      "for 2018-09-24, MAE is:8.67 & sMAPE is:29.35% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :3.27 & 8.15% & 0.88\n",
      "for 2018-09-25, MAE is:3.87 & sMAPE is:8.84% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 8.16% & 0.88\n",
      "for 2018-09-26, MAE is:10.01 & sMAPE is:36.56% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.30 & 8.26% & 0.88\n",
      "for 2018-09-27, MAE is:9.92 & sMAPE is:31.11% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.35% & 0.88\n",
      "for 2018-09-28, MAE is:5.80 & sMAPE is:15.15% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 8.37% & 0.88\n",
      "for 2018-09-29, MAE is:5.10 & sMAPE is:14.16% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 8.39% & 0.88\n",
      "for 2018-09-30, MAE is:6.09 & sMAPE is:18.19% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 8.43% & 0.88\n",
      "for 2018-10-01, MAE is:5.77 & sMAPE is:13.45% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 8.45% & 0.88\n",
      "for 2018-10-02, MAE is:3.40 & sMAPE is:7.74% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 8.44% & 0.88\n",
      "for 2018-10-03, MAE is:2.57 & sMAPE is:5.77% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 8.43% & 0.88\n",
      "for 2018-10-04, MAE is:2.08 & sMAPE is:4.56% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 8.42% & 0.88\n",
      "for 2018-10-05, MAE is:2.18 & sMAPE is:4.81% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 8.41% & 0.87\n",
      "for 2018-10-06, MAE is:2.59 & sMAPE is:5.68% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 8.40% & 0.87\n",
      "for 2018-10-07, MAE is:3.53 & sMAPE is:7.84% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 8.40% & 0.87\n",
      "for 2018-10-08, MAE is:1.19 & sMAPE is:2.57% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 8.37% & 0.87\n",
      "for 2018-10-09, MAE is:1.76 & sMAPE is:3.95% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.36% & 0.87\n",
      "for 2018-10-10, MAE is:4.66 & sMAPE is:10.38% & rMAE is:2.82 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 8.37% & 0.88\n",
      "for 2018-10-11, MAE is:3.14 & sMAPE is:7.74% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 8.36% & 0.88\n",
      "for 2018-10-12, MAE is:2.02 & sMAPE is:4.61% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.35% & 0.88\n",
      "for 2018-10-13, MAE is:5.78 & sMAPE is:17.55% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 8.38% & 0.87\n",
      "for 2018-10-14, MAE is:11.31 & sMAPE is:67.52% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.37 & 8.59% & 0.87\n",
      "for 2018-10-15, MAE is:23.25 & sMAPE is:83.54% & rMAE is:2.68 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 8.85% & 0.88\n",
      "for 2018-10-16, MAE is:3.51 & sMAPE is:8.20% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 8.85% & 0.88\n",
      "for 2018-10-17, MAE is:1.95 & sMAPE is:4.51% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.43 & 8.83% & 0.88\n",
      "for 2018-10-18, MAE is:1.98 & sMAPE is:4.79% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.43 & 8.82% & 0.88\n",
      "for 2018-10-19, MAE is:2.48 & sMAPE is:6.09% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :3.43 & 8.81% & 0.88\n",
      "for 2018-10-20, MAE is:2.52 & sMAPE is:6.26% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 8.80% & 0.88\n",
      "for 2018-10-21, MAE is:2.38 & sMAPE is:6.21% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 8.79% & 0.88\n",
      "for 2018-10-22, MAE is:4.68 & sMAPE is:14.29% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 8.81% & 0.87\n",
      "for 2018-10-23, MAE is:4.92 & sMAPE is:17.30% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.43 & 8.84% & 0.87\n",
      "for 2018-10-24, MAE is:7.48 & sMAPE is:18.96% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 8.87% & 0.88\n",
      "for 2018-10-25, MAE is:2.25 & sMAPE is:5.32% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 8.86% & 0.88\n",
      "for 2018-10-26, MAE is:1.87 & sMAPE is:4.21% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.43 & 8.85% & 0.88\n",
      "for 2018-10-27, MAE is:1.09 & sMAPE is:2.41% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 8.82% & 0.87\n",
      "for 2018-10-28, MAE is:1.60 & sMAPE is:3.63% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 8.81% & 0.87\n",
      "for 2018-10-29, MAE is:1.94 & sMAPE is:4.45% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.41 & 8.79% & 0.87\n",
      "for 2018-10-30, MAE is:1.89 & sMAPE is:4.42% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.41 & 8.78% & 0.87\n",
      "for 2018-10-31, MAE is:1.48 & sMAPE is:3.48% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.40 & 8.76% & 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-11-01, MAE is:2.28 & sMAPE is:5.20% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :3.40 & 8.75% & 0.87\n",
      "for 2018-11-02, MAE is:1.97 & sMAPE is:4.58% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.39 & 8.74% & 0.87\n",
      "for 2018-11-03, MAE is:1.68 & sMAPE is:4.02% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :3.39 & 8.72% & 0.87\n",
      "for 2018-11-04, MAE is:2.07 & sMAPE is:5.04% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :3.38 & 8.71% & 0.87\n",
      "for 2018-11-05, MAE is:3.02 & sMAPE is:7.04% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.38 & 8.70% & 0.88\n",
      "for 2018-11-06, MAE is:2.57 & sMAPE is:5.65% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.38 & 8.69% & 0.88\n",
      "for 2018-11-07, MAE is:1.81 & sMAPE is:3.85% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.38 & 8.68% & 0.88\n",
      "for 2018-11-08, MAE is:2.30 & sMAPE is:5.20% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :3.37 & 8.67% & 0.88\n",
      "for 2018-11-09, MAE is:2.21 & sMAPE is:4.96% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :3.37 & 8.65% & 0.88\n",
      "for 2018-11-10, MAE is:2.37 & sMAPE is:5.36% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :3.37 & 8.64% & 0.88\n",
      "for 2018-11-11, MAE is:1.50 & sMAPE is:3.66% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 8.63% & 0.88\n",
      "for 2018-11-12, MAE is:4.37 & sMAPE is:10.08% & rMAE is:3.17 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 8.63% & 0.89\n",
      "for 2018-11-13, MAE is:3.59 & sMAPE is:7.80% & rMAE is:3.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 8.63% & 0.90\n",
      "for 2018-11-14, MAE is:2.26 & sMAPE is:4.74% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 8.62% & 0.90\n",
      "for 2018-11-15, MAE is:1.82 & sMAPE is:3.81% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 8.60% & 0.90\n",
      "for 2018-11-16, MAE is:1.98 & sMAPE is:4.32% & rMAE is:2.91 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 8.59% & 0.91\n",
      "for 2018-11-17, MAE is:1.80 & sMAPE is:4.05% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 8.57% & 0.91\n",
      "for 2018-11-18, MAE is:2.13 & sMAPE is:4.60% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 8.56% & 0.90\n",
      "for 2018-11-19, MAE is:3.34 & sMAPE is:6.84% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 8.56% & 0.90\n",
      "for 2018-11-20, MAE is:1.87 & sMAPE is:3.75% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 8.54% & 0.91\n",
      "for 2018-11-21, MAE is:4.06 & sMAPE is:8.20% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 8.54% & 0.91\n",
      "for 2018-11-22, MAE is:1.33 & sMAPE is:2.56% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.52% & 0.91\n",
      "for 2018-11-23, MAE is:2.57 & sMAPE is:4.98% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.51% & 0.91\n",
      "for 2018-11-24, MAE is:2.45 & sMAPE is:5.12% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.50% & 0.91\n",
      "for 2018-11-25, MAE is:2.07 & sMAPE is:4.29% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.49% & 0.91\n",
      "for 2018-11-26, MAE is:1.67 & sMAPE is:3.28% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.47% & 0.90\n",
      "for 2018-11-27, MAE is:5.97 & sMAPE is:10.49% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.48% & 0.90\n",
      "for 2018-11-28, MAE is:3.54 & sMAPE is:6.85% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.47% & 0.91\n",
      "for 2018-11-29, MAE is:1.24 & sMAPE is:2.64% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.46% & 0.90\n",
      "for 2018-11-30, MAE is:1.24 & sMAPE is:2.73% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.44% & 0.90\n",
      "for 2018-12-01, MAE is:2.54 & sMAPE is:5.81% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 8.43% & 0.90\n",
      "for 2018-12-02, MAE is:1.80 & sMAPE is:4.10% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 8.42% & 0.90\n",
      "for 2018-12-03, MAE is:2.43 & sMAPE is:5.24% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 8.41% & 0.90\n",
      "for 2018-12-04, MAE is:1.31 & sMAPE is:2.77% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :3.30 & 8.39% & 0.90\n",
      "for 2018-12-05, MAE is:2.79 & sMAPE is:5.78% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.30 & 8.39% & 0.90\n",
      "for 2018-12-06, MAE is:3.66 & sMAPE is:7.04% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :3.30 & 8.38% & 0.90\n",
      "for 2018-12-07, MAE is:2.21 & sMAPE is:4.46% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :3.30 & 8.37% & 0.90\n",
      "for 2018-12-08, MAE is:2.36 & sMAPE is:5.11% & rMAE is:2.40 ||| daily mean of MAE & sMAPE & rMAE till now are :3.29 & 8.36% & 0.90\n",
      "for 2018-12-09, MAE is:2.19 & sMAPE is:5.02% & rMAE is:2.52 ||| daily mean of MAE & sMAPE & rMAE till now are :3.29 & 8.35% & 0.91\n",
      "for 2018-12-10, MAE is:1.79 & sMAPE is:3.85% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :3.29 & 8.34% & 0.91\n",
      "for 2018-12-11, MAE is:4.21 & sMAPE is:8.61% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :3.29 & 8.34% & 0.91\n",
      "for 2018-12-12, MAE is:5.65 & sMAPE is:9.77% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :3.30 & 8.34% & 0.91\n",
      "for 2018-12-13, MAE is:5.47 & sMAPE is:9.20% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :3.30 & 8.34% & 0.91\n",
      "for 2018-12-14, MAE is:6.29 & sMAPE is:10.44% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 8.35% & 0.91\n",
      "for 2018-12-15, MAE is:3.61 & sMAPE is:6.80% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 8.35% & 0.91\n",
      "for 2018-12-16, MAE is:2.65 & sMAPE is:5.40% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 8.34% & 0.91\n",
      "for 2018-12-17, MAE is:10.43 & sMAPE is:16.99% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.36% & 0.91\n",
      "for 2018-12-18, MAE is:6.59 & sMAPE is:10.95% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :3.34 & 8.37% & 0.91\n",
      "for 2018-12-19, MAE is:1.48 & sMAPE is:2.83% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.35% & 0.91\n",
      "for 2018-12-20, MAE is:2.01 & sMAPE is:3.74% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.34% & 0.90\n",
      "for 2018-12-21, MAE is:1.47 & sMAPE is:2.77% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 8.33% & 0.90\n",
      "for 2018-12-22, MAE is:1.87 & sMAPE is:3.65% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.31% & 0.90\n",
      "for 2018-12-23, MAE is:2.80 & sMAPE is:5.24% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.30% & 0.90\n",
      "for 2018-12-24, MAE is:5.08 & sMAPE is:9.27% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.31% & 0.90\n",
      "for 2018-12-25, MAE is:3.37 & sMAPE is:6.87% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.30% & 0.90\n",
      "for 2018-12-26, MAE is:2.26 & sMAPE is:4.78% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.29% & 0.90\n",
      "for 2018-12-27, MAE is:2.09 & sMAPE is:4.26% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.28% & 0.90\n",
      "for 2018-12-28, MAE is:1.94 & sMAPE is:3.91% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 8.27% & 0.90\n",
      "for 2018-12-29, MAE is:2.43 & sMAPE is:4.91% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 8.26% & 0.90\n",
      "for 2018-12-30, MAE is:5.03 & sMAPE is:10.50% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.27% & 0.90\n",
      "for 2018-12-31, MAE is:4.06 & sMAPE is:8.04% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 8.27% & 0.91\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:32:07,113]\u001b[0m A new study created in RDB with name: NO_3_2019\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:32:33,691]\u001b[0m Trial 3 finished with value: 4.187106435205684 and parameters: {'n_hidden': 4, 'learning_rate': 0.00604739088981927, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15868019886275864, 'dropout_rate_Layer_2': 0.20244630157250532, 'dropout_rate_Layer_3': 0.24068674365582804, 'dropout_rate_Layer_4': 0.1921135248063699, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002793866026691908, 'l1_Layer_2': 3.905222780800942e-05, 'l1_Layer_3': 0.03893459010866584, 'l1_Layer_4': 0.00029507414586252756, 'n_units_Layer_1': 125, 'n_units_Layer_2': 255, 'n_units_Layer_3': 140, 'n_units_Layer_4': 115}. Best is trial 3 with value: 4.187106435205684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 10.02% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 3.06 | sMAPE for Test Set is: 8.63% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:32:33,863]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 65.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:32:39,246]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:32:42,383]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:32:44,988]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:32:46,250]\u001b[0m Trial 1 finished with value: 5.695742185626394 and parameters: {'n_hidden': 4, 'learning_rate': 0.0037587961850530796, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1226414082324133, 'dropout_rate_Layer_2': 0.2572669605521654, 'dropout_rate_Layer_3': 0.13756135913469691, 'dropout_rate_Layer_4': 0.032155994882854165, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010433443036522209, 'l1_Layer_2': 0.0033761434796483786, 'l1_Layer_3': 1.4850697341544342e-05, 'l1_Layer_4': 0.00011030027876122231, 'n_units_Layer_1': 160, 'n_units_Layer_2': 135, 'n_units_Layer_3': 70, 'n_units_Layer_4': 80}. Best is trial 3 with value: 4.187106435205684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 13.41% | rMAE for Validation Set is: 1.10\n",
      "MAE for Test Set is: 2.98 | sMAPE for Test Set is: 8.41% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:32:49,500]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:32:52,089]\u001b[0m Trial 0 finished with value: 10.48391295745608 and parameters: {'n_hidden': 4, 'learning_rate': 0.0030615397962145767, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24615458908613164, 'dropout_rate_Layer_2': 0.2817451536528223, 'dropout_rate_Layer_3': 0.3793436655254791, 'dropout_rate_Layer_4': 0.27369180649218355, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.029632093100691e-05, 'l1_Layer_2': 0.03308749101598465, 'l1_Layer_3': 0.06765428108102729, 'l1_Layer_4': 0.02269190352021159, 'n_units_Layer_1': 275, 'n_units_Layer_2': 270, 'n_units_Layer_3': 55, 'n_units_Layer_4': 215}. Best is trial 3 with value: 4.187106435205684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.48 | sMAPE for Validation Set is: 25.50% | rMAE for Validation Set is: 2.02\n",
      "MAE for Test Set is: 5.29 | sMAPE for Test Set is: 14.49% | rMAE for Test Set is: 1.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:32:55,909]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:32:59,125]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:00,600]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:03,187]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:05,596]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 10.83% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 3.17 | sMAPE for Test Set is: 9.01% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:33:06,964]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:06,973]\u001b[0m Trial 8 finished with value: 4.587912366643299 and parameters: {'n_hidden': 3, 'learning_rate': 0.003480447363164857, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35289884407763206, 'dropout_rate_Layer_2': 0.07778207977867942, 'dropout_rate_Layer_3': 0.30804740557706767, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06672299156815559, 'l1_Layer_2': 0.0015910119486885086, 'l1_Layer_3': 0.0005562840799245096, 'n_units_Layer_1': 275, 'n_units_Layer_2': 220, 'n_units_Layer_3': 125}. Best is trial 3 with value: 4.187106435205684.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:15,069]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:19,263]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:20,285]\u001b[0m Trial 16 finished with value: 7.138129483201649 and parameters: {'n_hidden': 3, 'learning_rate': 0.022895985184112587, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3838777702218974, 'dropout_rate_Layer_2': 0.21156325358728464, 'dropout_rate_Layer_3': 0.010142034450944372, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.1170508695583891e-05, 'l1_Layer_2': 1.7371495038395456e-05, 'l1_Layer_3': 0.0015270241212251674, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 300}. Best is trial 3 with value: 4.187106435205684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.14 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 1.38\n",
      "MAE for Test Set is: 4.03 | sMAPE for Test Set is: 11.18% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:33:25,046]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:25,378]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:30,468]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:34,524]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:34,969]\u001b[0m Trial 5 finished with value: 4.704760257376417 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023959175537949765, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05786171854978073, 'dropout_rate_Layer_2': 0.060841712108509464, 'dropout_rate_Layer_3': 0.07574705054770244, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007877191915630768, 'l1_Layer_2': 0.000603122238296559, 'l1_Layer_3': 0.00034745628263325805, 'n_units_Layer_1': 225, 'n_units_Layer_2': 275, 'n_units_Layer_3': 205}. Best is trial 3 with value: 4.187106435205684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 11.12% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 3.78 | sMAPE for Test Set is: 10.07% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:33:38,064]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:40,549]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:41,649]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:44,868]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:45,274]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:48,083]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:55,121]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:55,988]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:33:57,591]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:01,726]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:01,966]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:02,147]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.32 | sMAPE for Validation Set is: 8.19% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 2.38 | sMAPE for Test Set is: 7.10% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:34:03,769]\u001b[0m Trial 18 finished with value: 3.319740368338715 and parameters: {'n_hidden': 4, 'learning_rate': 0.004066300383859234, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3231265655119462, 'dropout_rate_Layer_2': 0.35823409619997554, 'dropout_rate_Layer_3': 0.05735472874641654, 'dropout_rate_Layer_4': 0.08911644060544886, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0019057841376491592, 'l1_Layer_2': 0.00029466512107775687, 'l1_Layer_3': 9.885044200629324e-05, 'l1_Layer_4': 0.0010211555896512447, 'n_units_Layer_1': 105, 'n_units_Layer_2': 195, 'n_units_Layer_3': 240, 'n_units_Layer_4': 300}. Best is trial 18 with value: 3.319740368338715.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:10,924]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:13,839]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:15,924]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:18,794]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:19,333]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:21,057]\u001b[0m Trial 36 finished with value: 3.2048659383695663 and parameters: {'n_hidden': 3, 'learning_rate': 0.009978559867611663, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2880231773529217, 'dropout_rate_Layer_2': 0.06304954974192817, 'dropout_rate_Layer_3': 0.3838403157980873, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.020306904328017576, 'l1_Layer_2': 1.0765255769082018e-05, 'l1_Layer_3': 0.0038415083890438587, 'n_units_Layer_1': 220, 'n_units_Layer_2': 275, 'n_units_Layer_3': 90}. Best is trial 36 with value: 3.2048659383695663.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.20 | sMAPE for Validation Set is: 7.91% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.35 | sMAPE for Test Set is: 7.02% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:34:24,543]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:25,267]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:27,339]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:31,993]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:34,260]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:34,393]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:37,107]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:41,202]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:42,696]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:42,739]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:43,197]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:45,073]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:48,207]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:49,697]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:51,890]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:54,589]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:34:57,218]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:00,550]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:02,466]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:08,177]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:10,280]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:11,174]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:13,933]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:15,620]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:17,317]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:19,916]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:21,662]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:23,701]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:23,991]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:30,717]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:32,688]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:34,753]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:36,872]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:40,016]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:44,175]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:35:50,375]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:36:00,112]\u001b[0m Trial 79 finished with value: 5.102856748135174 and parameters: {'n_hidden': 3, 'learning_rate': 0.01200029079809999, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06098327325393882, 'dropout_rate_Layer_2': 0.24828752363466947, 'dropout_rate_Layer_3': 0.2566359027309983, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003740827086484065, 'l1_Layer_2': 0.011711002390490777, 'l1_Layer_3': 0.005605451984985637, 'n_units_Layer_1': 75, 'n_units_Layer_2': 125, 'n_units_Layer_3': 225}. Best is trial 36 with value: 3.2048659383695663.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 12.13% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 4.30 | sMAPE for Test Set is: 11.70% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:36:03,177]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:36:08,161]\u001b[0m Trial 72 finished with value: 4.0782578304670825 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017119701362146224, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13351307916487262, 'dropout_rate_Layer_2': 0.3047954249333748, 'dropout_rate_Layer_3': 0.15351381686692425, 'dropout_rate_Layer_4': 0.04401251310810688, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.4736486699926013e-05, 'l1_Layer_2': 0.0002546997010124904, 'l1_Layer_3': 0.0005515456618006337, 'l1_Layer_4': 0.00873244411631882, 'n_units_Layer_1': 245, 'n_units_Layer_2': 160, 'n_units_Layer_3': 240, 'n_units_Layer_4': 100}. Best is trial 36 with value: 3.2048659383695663.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 9.82% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 4.85 | sMAPE for Test Set is: 12.65% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:36:11,871]\u001b[0m Trial 73 finished with value: 3.429329223375303 and parameters: {'n_hidden': 4, 'learning_rate': 0.0055080476858184535, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008735895261814008, 'dropout_rate_Layer_2': 0.23953370972342836, 'dropout_rate_Layer_3': 0.11246266065064665, 'dropout_rate_Layer_4': 0.0799389761221199, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.008924221215571354, 'l1_Layer_2': 2.603269836514705e-05, 'l1_Layer_3': 0.014125071769487517, 'l1_Layer_4': 0.0016013685124965978, 'n_units_Layer_1': 65, 'n_units_Layer_2': 210, 'n_units_Layer_3': 300, 'n_units_Layer_4': 140}. Best is trial 36 with value: 3.2048659383695663.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.43 | sMAPE for Validation Set is: 8.40% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 2.67 | sMAPE for Test Set is: 7.77% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:36:22,905]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:36:26,916]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:36:27,518]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:36:28,409]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:36:32,832]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:36:34,603]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:36:36,334]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:36:43,426]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:36:49,051]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:36:49,308]\u001b[0m Trial 92 finished with value: 9.54587991020089 and parameters: {'n_hidden': 4, 'learning_rate': 0.07601156954056627, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2584332724142775, 'dropout_rate_Layer_2': 0.18490773872410507, 'dropout_rate_Layer_3': 0.24701421298283607, 'dropout_rate_Layer_4': 0.16131548278617192, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 3.7580365862614506e-05, 'l1_Layer_2': 0.0001526616698204854, 'l1_Layer_3': 3.672262739215152e-05, 'l1_Layer_4': 3.960075991060261e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 85, 'n_units_Layer_3': 210, 'n_units_Layer_4': 125}. Best is trial 36 with value: 3.2048659383695663.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.55 | sMAPE for Validation Set is: 22.89% | rMAE for Validation Set is: 1.84\n",
      "MAE for Test Set is: 5.51 | sMAPE for Test Set is: 15.06% | rMAE for Test Set is: 1.58\n",
      "MAE for Validation Set is: 3.39 | sMAPE for Validation Set is: 8.33% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 2.53 | sMAPE for Test Set is: 7.43% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:36:51,832]\u001b[0m Trial 81 finished with value: 3.392052787580082 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013380878455259337, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28797984877537897, 'dropout_rate_Layer_2': 0.21929519506264455, 'dropout_rate_Layer_3': 0.06801649809592006, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014886970353550136, 'l1_Layer_2': 0.027178903857198955, 'l1_Layer_3': 2.2759379533745892e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 90, 'n_units_Layer_3': 215}. Best is trial 36 with value: 3.2048659383695663.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:36:55,658]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:36:57,863]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:36:59,684]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:00,821]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:06,520]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:07,961]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:11,909]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:12,411]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:17,532]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:18,103]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:18,804]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:20,656]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:25,046]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:25,318]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:28,555]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:32,554]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:33,098]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:33,846]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:39,380]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:39,473]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:40,183]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:45,793]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:49,101]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:52,381]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:54,149]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:37:54,261]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:38:00,894]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:38:06,346]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:38:10,805]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:38:14,472]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:38:18,069]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:38:21,294]\u001b[0m Trial 118 finished with value: 2.9075503099608473 and parameters: {'n_hidden': 3, 'learning_rate': 0.002510529776558522, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27271906950330776, 'dropout_rate_Layer_2': 0.18167136502158648, 'dropout_rate_Layer_3': 0.3093084403772079, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.9485972689530766e-05, 'l1_Layer_2': 3.779448123586639e-05, 'l1_Layer_3': 0.002116156481718198, 'n_units_Layer_1': 165, 'n_units_Layer_2': 255, 'n_units_Layer_3': 115}. Best is trial 118 with value: 2.9075503099608473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.91 | sMAPE for Validation Set is: 7.20% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 2.43 | sMAPE for Test Set is: 6.98% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:38:25,171]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:38:25,788]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:38:30,852]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:38:35,228]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:38:41,082]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:38:46,761]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:38:58,448]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:39:03,232]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:39:09,401]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:39:39,552]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:39:48,824]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:39:59,314]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:40:04,855]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:40:09,004]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:40:18,090]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:40:25,419]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:40:28,549]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:40:32,547]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:40:37,435]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:40:50,144]\u001b[0m Trial 134 finished with value: 2.954130540178254 and parameters: {'n_hidden': 4, 'learning_rate': 0.001083988621311619, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0023434448251452855, 'dropout_rate_Layer_2': 0.38811260102093653, 'dropout_rate_Layer_3': 0.005399006632365394, 'dropout_rate_Layer_4': 0.001040851833881501, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.42400560202151e-05, 'l1_Layer_2': 0.001427030423422628, 'l1_Layer_3': 0.00013974940225941777, 'l1_Layer_4': 0.08299683284159824, 'n_units_Layer_1': 275, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300, 'n_units_Layer_4': 60}. Best is trial 118 with value: 2.9075503099608473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.95 | sMAPE for Validation Set is: 7.32% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.21 | sMAPE for Test Set is: 6.66% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:40:53,331]\u001b[0m Trial 120 finished with value: 3.1026333317943124 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009489635481511855, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0029859440612091948, 'dropout_rate_Layer_2': 0.3877141955802328, 'dropout_rate_Layer_3': 0.00971765427836968, 'dropout_rate_Layer_4': 0.028311196142651245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.259909032272422e-05, 'l1_Layer_2': 0.0019230273479371534, 'l1_Layer_3': 0.00019215397859997273, 'l1_Layer_4': 0.08789924218107421, 'n_units_Layer_1': 275, 'n_units_Layer_2': 195, 'n_units_Layer_3': 295, 'n_units_Layer_4': 50}. Best is trial 118 with value: 2.9075503099608473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.10 | sMAPE for Validation Set is: 7.68% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.33 | sMAPE for Test Set is: 6.88% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:40:56,324]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.17 | sMAPE for Validation Set is: 7.77% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.36 | sMAPE for Test Set is: 7.01% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:40:57,567]\u001b[0m Trial 147 finished with value: 3.1713016961184746 and parameters: {'n_hidden': 4, 'learning_rate': 0.003974666480589907, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19082808954541944, 'dropout_rate_Layer_2': 0.11086557336085878, 'dropout_rate_Layer_3': 0.3935203953231712, 'dropout_rate_Layer_4': 0.23294251464942814, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0027924383953222675, 'l1_Layer_2': 0.03304191517491124, 'l1_Layer_3': 0.0002519520084588354, 'l1_Layer_4': 0.08390426854754532, 'n_units_Layer_1': 230, 'n_units_Layer_2': 245, 'n_units_Layer_3': 60, 'n_units_Layer_4': 180}. Best is trial 118 with value: 2.9075503099608473.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:41:02,287]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:41:02,564]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:41:06,753]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:41:09,712]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:41:13,075]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:41:17,504]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:41:17,658]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:41:29,986]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:41:30,160]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:41:37,453]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:41:42,899]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:41:57,579]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:42:00,293]\u001b[0m Trial 161 finished with value: 2.8987039480706613 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017645859024918655, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18448963170348176, 'dropout_rate_Layer_2': 0.027641734228537135, 'dropout_rate_Layer_3': 0.09408085842350686, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010040068144286623, 'l1_Layer_2': 3.714659188145832e-05, 'l1_Layer_3': 0.0006716104895267271, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 110}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.90 | sMAPE for Validation Set is: 7.25% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 2.20 | sMAPE for Test Set is: 6.42% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:42:02,315]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.00 | sMAPE for Validation Set is: 7.45% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.45 | sMAPE for Test Set is: 7.19% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:42:04,042]\u001b[0m Trial 137 finished with value: 3.0045051797053453 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007647703937482081, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0017449231006866628, 'dropout_rate_Layer_2': 0.3920672848509362, 'dropout_rate_Layer_3': 0.006646347688829712, 'dropout_rate_Layer_4': 0.025256230193259076, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.073254341014685e-05, 'l1_Layer_2': 0.0013659933739437607, 'l1_Layer_3': 0.00014143101840981363, 'l1_Layer_4': 0.06232006496523771, 'n_units_Layer_1': 280, 'n_units_Layer_2': 185, 'n_units_Layer_3': 275, 'n_units_Layer_4': 60}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:42:09,171]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:42:15,557]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:42:21,321]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:42:25,034]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:42:27,764]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:42:35,623]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:42:38,840]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:42:39,261]\u001b[0m Trial 170 finished with value: 5.051374186084257 and parameters: {'n_hidden': 4, 'learning_rate': 0.005587622184833244, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08992512338505426, 'dropout_rate_Layer_2': 0.08754050821819857, 'dropout_rate_Layer_3': 0.22083766027970086, 'dropout_rate_Layer_4': 0.0022810159970138577, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003809785299622474, 'l1_Layer_2': 0.00030891046235208156, 'l1_Layer_3': 9.57256818288717e-05, 'l1_Layer_4': 0.0007387025990180038, 'n_units_Layer_1': 300, 'n_units_Layer_2': 240, 'n_units_Layer_3': 190, 'n_units_Layer_4': 155}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 4.06 | sMAPE for Test Set is: 11.12% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:42:47,834]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:42:53,290]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:42:59,163]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:43:16,073]\u001b[0m Trial 173 finished with value: 2.99944275528359 and parameters: {'n_hidden': 4, 'learning_rate': 0.003962037588669569, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08344566732337912, 'dropout_rate_Layer_2': 0.1328192894715142, 'dropout_rate_Layer_3': 6.929707398635465e-05, 'dropout_rate_Layer_4': 0.21541512783814282, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0014992111799693895, 'l1_Layer_2': 0.012316854141778862, 'l1_Layer_3': 0.0013112885987500713, 'l1_Layer_4': 0.00719354544503041, 'n_units_Layer_1': 210, 'n_units_Layer_2': 240, 'n_units_Layer_3': 255, 'n_units_Layer_4': 70}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.00 | sMAPE for Validation Set is: 7.48% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.17 | sMAPE for Test Set is: 6.54% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:43:21,050]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:43:32,715]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:43:48,144]\u001b[0m Trial 179 finished with value: 3.4227908436723706 and parameters: {'n_hidden': 4, 'learning_rate': 0.006548610971598925, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18456277041738772, 'dropout_rate_Layer_2': 0.1835186112069247, 'dropout_rate_Layer_3': 0.3110698955263012, 'dropout_rate_Layer_4': 0.21385139512997373, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002322306279977388, 'l1_Layer_2': 0.08324897734773205, 'l1_Layer_3': 1.0538762268477105e-05, 'l1_Layer_4': 0.012287348373057548, 'n_units_Layer_1': 100, 'n_units_Layer_2': 170, 'n_units_Layer_3': 255, 'n_units_Layer_4': 55}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.42 | sMAPE for Validation Set is: 8.49% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 2.30 | sMAPE for Test Set is: 6.91% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:43:52,316]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:43:52,753]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:43:57,136]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:00,964]\u001b[0m Trial 180 finished with value: 3.13084287508462 and parameters: {'n_hidden': 4, 'learning_rate': 0.005812272555180449, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18853917665175016, 'dropout_rate_Layer_2': 0.005315985070481866, 'dropout_rate_Layer_3': 0.3303554126764774, 'dropout_rate_Layer_4': 0.2134346168802997, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002608438700955225, 'l1_Layer_2': 0.03913213449384663, 'l1_Layer_3': 0.0028534925474267793, 'l1_Layer_4': 0.009288552567186246, 'n_units_Layer_1': 55, 'n_units_Layer_2': 235, 'n_units_Layer_3': 255, 'n_units_Layer_4': 75}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.13 | sMAPE for Validation Set is: 7.77% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.39 | sMAPE for Test Set is: 7.11% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:44:03,543]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:06,169]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:10,324]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:13,263]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:16,291]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:20,096]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:22,215]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:22,414]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:24,429]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:29,269]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:30,818]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:34,768]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:39,566]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:42,658]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:43,358]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:46,316]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:47,431]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:49,397]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:51,977]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:53,691]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:44:57,555]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:45:02,871]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:45:15,015]\u001b[0m Trial 206 finished with value: 3.3743903286275025 and parameters: {'n_hidden': 4, 'learning_rate': 0.011695965821149274, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2107816152882319, 'dropout_rate_Layer_2': 0.13944707041588852, 'dropout_rate_Layer_3': 0.35562813736012333, 'dropout_rate_Layer_4': 0.26438021170251147, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0015318432072640715, 'l1_Layer_2': 0.03865872328387763, 'l1_Layer_3': 0.0009830539527422666, 'l1_Layer_4': 0.006020437562515893, 'n_units_Layer_1': 115, 'n_units_Layer_2': 245, 'n_units_Layer_3': 300, 'n_units_Layer_4': 135}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.37 | sMAPE for Validation Set is: 8.34% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 2.57 | sMAPE for Test Set is: 7.54% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:45:19,815]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:45:20,192]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:45:21,647]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:45:27,918]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:45:29,239]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:45:31,630]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:45:33,710]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:45:36,305]\u001b[0m Trial 210 finished with value: 3.1445776912175964 and parameters: {'n_hidden': 3, 'learning_rate': 0.0055846904325310195, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25183664741706224, 'dropout_rate_Layer_2': 0.11268905950525054, 'dropout_rate_Layer_3': 0.2167813011703691, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010823901322323428, 'l1_Layer_2': 1.4407807728988845e-05, 'l1_Layer_3': 0.0016553614135306517, 'n_units_Layer_1': 100, 'n_units_Layer_2': 270, 'n_units_Layer_3': 60}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.14 | sMAPE for Validation Set is: 7.83% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.33 | sMAPE for Test Set is: 6.87% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:45:38,784]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:45:43,943]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:45:47,213]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:45:47,861]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:46:00,172]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:46:08,281]\u001b[0m Trial 216 finished with value: 3.3094044643895812 and parameters: {'n_hidden': 4, 'learning_rate': 0.005248243821511564, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1908251203731145, 'dropout_rate_Layer_2': 0.05490317717187075, 'dropout_rate_Layer_3': 0.357354814576079, 'dropout_rate_Layer_4': 0.23066093483248026, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004700656247027498, 'l1_Layer_2': 0.03222949194802473, 'l1_Layer_3': 0.0005031374744351771, 'l1_Layer_4': 0.030652831581055657, 'n_units_Layer_1': 245, 'n_units_Layer_2': 255, 'n_units_Layer_3': 185, 'n_units_Layer_4': 85}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.31 | sMAPE for Validation Set is: 8.18% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 2.57 | sMAPE for Test Set is: 7.52% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:46:12,331]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:46:15,582]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:46:20,558]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:46:23,516]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:46:34,154]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:46:39,474]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:46:44,978]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:46:51,148]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:46:57,941]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:47:01,032]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:47:04,418]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:47:12,928]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:47:18,233]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:47:21,939]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:47:26,000]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:47:30,437]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:47:35,391]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:47:40,591]\u001b[0m Trial 214 finished with value: 3.0427899100838207 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008537347889932196, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03621793678769771, 'dropout_rate_Layer_2': 0.3541903906329872, 'dropout_rate_Layer_3': 0.03886374408485097, 'dropout_rate_Layer_4': 0.0671858456392628, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.8664494600118795e-05, 'l1_Layer_2': 0.0017067551710879204, 'l1_Layer_3': 0.0002572809858635014, 'l1_Layer_4': 0.02893948904834811, 'n_units_Layer_1': 265, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265, 'n_units_Layer_4': 85}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.04 | sMAPE for Validation Set is: 7.52% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.30 | sMAPE for Test Set is: 6.88% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:47:40,917]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:47:47,610]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:47:51,317]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:47:51,583]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:47:54,993]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:47:59,815]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:01,820]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:10,563]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:15,236]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:18,369]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:24,534]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:30,081]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:33,006]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:37,126]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:40,635]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:41,669]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:44,402]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:45,697]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:46,855]\u001b[0m Trial 220 finished with value: 3.118635883855198 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009998757275850663, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.034422525074903294, 'dropout_rate_Layer_2': 0.3630164611442616, 'dropout_rate_Layer_3': 0.034207339911262805, 'dropout_rate_Layer_4': 0.06749723575538516, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.595465546980364e-05, 'l1_Layer_2': 0.0021410309774975507, 'l1_Layer_3': 0.00024537498865226723, 'l1_Layer_4': 0.03084170887965778, 'n_units_Layer_1': 220, 'n_units_Layer_2': 175, 'n_units_Layer_3': 280, 'n_units_Layer_4': 80}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.12 | sMAPE for Validation Set is: 7.66% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.47 | sMAPE for Test Set is: 7.21% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:48:50,291]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:53,380]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:53,741]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:54,236]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:58,366]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:48:59,860]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:01,241]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:03,590]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:03,856]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:11,170]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:15,021]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:17,021]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:20,046]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:21,752]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:24,335]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:26,852]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:29,034]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:29,467]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:34,216]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:34,588]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:39,339]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:40,745]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:43,917]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:46,926]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:48,437]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:50,827]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:54,194]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:57,760]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:57,838]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:49:58,864]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:05,110]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:08,119]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:09,942]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:11,722]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:12,383]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:13,350]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:20,634]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:25,638]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:28,375]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:31,850]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:31,963]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:32,112]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:32,494]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:39,599]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:43,109]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:45,513]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:45,861]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:53,516]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:54,157]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:50:57,657]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:51:00,697]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:51:03,566]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:51:12,999]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:51:23,429]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:51:23,875]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:51:29,231]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:51:29,909]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:51:35,285]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:51:48,079]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:51:53,579]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:51:59,841]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:52:04,363]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:52:06,222]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:52:12,392]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:52:16,009]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:52:18,820]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:52:22,270]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:52:27,999]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:52:31,658]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:52:32,109]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:52:35,605]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:52:38,778]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:52:42,954]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:52:46,038]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:52:53,390]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:52:56,388]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:53:06,173]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:53:08,423]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:53:12,332]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:53:12,559]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:53:16,844]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:53:18,103]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:53:21,502]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:53:23,716]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:53:26,685]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:53:27,178]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:53:32,167]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:53:35,033]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:53:35,501]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:53:37,351]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:53:44,580]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:53:48,907]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:53:51,981]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:53:56,536]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:54:03,009]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:54:08,014]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:54:11,760]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:54:16,339]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:54:20,755]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:54:26,746]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:54:30,957]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:54:35,385]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:54:38,076]\u001b[0m Trial 309 finished with value: 3.1788726213302474 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007761023067616741, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00183639543278327, 'dropout_rate_Layer_2': 0.37978692613809956, 'dropout_rate_Layer_3': 0.006055795969163804, 'dropout_rate_Layer_4': 0.031033090696084696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.656472759418832e-05, 'l1_Layer_2': 0.001398639422991624, 'l1_Layer_3': 0.0009641814297177486, 'l1_Layer_4': 0.0471274016646042, 'n_units_Layer_1': 280, 'n_units_Layer_2': 200, 'n_units_Layer_3': 300, 'n_units_Layer_4': 50}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.18 | sMAPE for Validation Set is: 7.85% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.27 | sMAPE for Test Set is: 6.78% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:54:43,302]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:54:44,870]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:54:51,444]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:54:51,590]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:01,308]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:05,525]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:05,752]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:10,781]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:11,459]\u001b[0m Trial 363 finished with value: 3.289377662260883 and parameters: {'n_hidden': 4, 'learning_rate': 0.010716697201607176, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20767451119897212, 'dropout_rate_Layer_2': 0.13879594827323943, 'dropout_rate_Layer_3': 0.37099138193813674, 'dropout_rate_Layer_4': 0.2513270513306195, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0013992579815711177, 'l1_Layer_2': 0.03809760525302056, 'l1_Layer_3': 0.0009021054441963977, 'l1_Layer_4': 0.0067931133821031425, 'n_units_Layer_1': 120, 'n_units_Layer_2': 245, 'n_units_Layer_3': 290, 'n_units_Layer_4': 140}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.29 | sMAPE for Validation Set is: 8.10% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 2.35 | sMAPE for Test Set is: 6.98% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:55:16,673]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:16,816]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:19,418]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:25,489]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:25,711]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:26,060]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:31,874]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:34,001]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:37,272]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:40,664]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:45,411]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:45,709]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:47,830]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:52,283]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:55:52,652]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:02,403]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:07,551]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:08,274]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:14,046]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:14,326]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:18,189]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:18,778]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:23,675]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:24,189]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:29,351]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:29,556]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:34,692]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:37,427]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:38,198]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:41,498]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:45,314]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:47,460]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:50,171]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:50,604]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:50,714]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:55,312]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:55,781]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:59,468]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:56:59,580]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:04,172]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:04,365]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:04,943]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:05,203]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:10,936]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:12,999]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:16,402]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:16,545]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:17,424]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:24,809]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:25,201]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:25,806]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:32,606]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:39,482]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:41,886]\u001b[0m Trial 416 finished with value: 3.0760398363534307 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022317349918279964, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11524486265056219, 'dropout_rate_Layer_2': 0.19011497963157392, 'dropout_rate_Layer_3': 0.33691338874104226, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014302582173199695, 'l1_Layer_2': 4.958990711270417e-05, 'l1_Layer_3': 0.010913012031473553, 'n_units_Layer_1': 270, 'n_units_Layer_2': 220, 'n_units_Layer_3': 90}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.08 | sMAPE for Validation Set is: 7.61% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.97 | sMAPE for Test Set is: 8.30% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:57:44,205]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:49,810]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:50,335]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:50,773]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:52,867]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:57:56,318]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:00,811]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:03,169]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:05,953]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:05,987]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:10,808]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:13,691]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:14,598]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:15,306]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:15,715]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:21,544]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:24,145]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:24,582]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:26,368]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:29,910]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:31,796]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:31,817]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:32,825]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:40,492]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:41,041]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:47,099]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:58:47,366]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:59:10,563]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:59:14,336]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:59:17,711]\u001b[0m Trial 452 finished with value: 3.2320652373187815 and parameters: {'n_hidden': 4, 'learning_rate': 0.004577512865640433, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2223395990365135, 'dropout_rate_Layer_2': 0.15019060398400985, 'dropout_rate_Layer_3': 0.3354027775170167, 'dropout_rate_Layer_4': 0.26801654411313586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0017308099505779643, 'l1_Layer_2': 0.03645126365039188, 'l1_Layer_3': 0.0013690849976933754, 'l1_Layer_4': 0.005870727189269714, 'n_units_Layer_1': 85, 'n_units_Layer_2': 245, 'n_units_Layer_3': 285, 'n_units_Layer_4': 135}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.23 | sMAPE for Validation Set is: 8.03% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.36 | sMAPE for Test Set is: 7.00% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 19:59:19,490]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:59:24,076]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:59:24,305]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:59:25,866]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:59:30,383]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:59:32,972]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:59:37,700]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:59:42,468]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:59:44,859]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 19:59:57,757]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:00:03,194]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:00:08,476]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:00:13,027]\u001b[0m Trial 464 finished with value: 3.125382563868049 and parameters: {'n_hidden': 4, 'learning_rate': 0.0038169408961005076, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22699822932867916, 'dropout_rate_Layer_2': 0.17735816622832318, 'dropout_rate_Layer_3': 0.29243291635806745, 'dropout_rate_Layer_4': 0.3069576019900486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002077216656931231, 'l1_Layer_2': 0.06267657689129019, 'l1_Layer_3': 0.0002274178536481458, 'l1_Layer_4': 0.014032231337699862, 'n_units_Layer_1': 60, 'n_units_Layer_2': 240, 'n_units_Layer_3': 250, 'n_units_Layer_4': 180}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.13 | sMAPE for Validation Set is: 7.77% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.36 | sMAPE for Test Set is: 6.96% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:00:16,724]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:00:20,291]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:00:22,897]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:00:25,816]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:00:30,987]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:00:31,564]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:00:35,251]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:00:36,810]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:00:39,538]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:00:50,771]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:00:56,404]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:00:58,795]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:07,355]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:11,411]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:13,666]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:21,155]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:27,281]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:30,115]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:30,131]\u001b[0m Trial 460 finished with value: 3.4861938790902074 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010619452452755754, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23534197320674669, 'dropout_rate_Layer_2': 0.2247908830923448, 'dropout_rate_Layer_3': 0.18762515378424555, 'dropout_rate_Layer_4': 0.10630621612529421, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002190638471321303, 'l1_Layer_2': 3.658177030605803e-05, 'l1_Layer_3': 3.392591109237407e-05, 'l1_Layer_4': 0.000568201155138106, 'n_units_Layer_1': 65, 'n_units_Layer_2': 115, 'n_units_Layer_3': 145, 'n_units_Layer_4': 140}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.49 | sMAPE for Validation Set is: 8.71% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 2.76 | sMAPE for Test Set is: 7.99% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:01:30,791]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:34,662]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:39,171]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:39,843]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:40,785]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:41,447]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:49,404]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:51,707]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:52,323]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:56,263]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:56,489]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:01:57,255]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:02:05,541]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:02:08,459]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:02:12,192]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:02:15,257]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:02:17,484]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:02:19,591]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:02:21,059]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:02:22,062]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:02:27,801]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:02:29,801]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:02:35,533]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:02:39,190]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:02:41,879]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:02:46,364]\u001b[0m Trial 497 finished with value: 3.2218974292566878 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022947036529298507, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.088084996927212, 'dropout_rate_Layer_2': 0.22389168877730056, 'dropout_rate_Layer_3': 0.24214579326579067, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011120544029659306, 'l1_Layer_2': 5.0596711944059345e-05, 'l1_Layer_3': 0.0037687641632240115, 'n_units_Layer_1': 295, 'n_units_Layer_2': 295, 'n_units_Layer_3': 265}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.22 | sMAPE for Validation Set is: 7.99% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.40 | sMAPE for Test Set is: 7.04% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:02:51,146]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:02:55,311]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:02:58,527]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:03:14,262]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:03:47,074]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:03:52,493]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:04:23,076]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:04:29,370]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:04:56,728]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:04:57,395]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:04:59,004]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:05:01,952]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:05:03,044]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:05:20,787]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:05:26,219]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:05:30,050]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:05:35,155]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:05:41,452]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:05:45,817]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:05:51,523]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:05:59,689]\u001b[0m Trial 519 finished with value: 3.2693537483712602 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006546021512764282, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05117468160865506, 'dropout_rate_Layer_2': 0.3740450860727833, 'dropout_rate_Layer_3': 0.025061980415660545, 'dropout_rate_Layer_4': 0.030676607461851902, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.619488702161763e-05, 'l1_Layer_2': 0.005238580258820612, 'l1_Layer_3': 0.00041058909046878225, 'l1_Layer_4': 0.06829145975929167, 'n_units_Layer_1': 250, 'n_units_Layer_2': 160, 'n_units_Layer_3': 270, 'n_units_Layer_4': 125}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.27 | sMAPE for Validation Set is: 8.01% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 2.43 | sMAPE for Test Set is: 7.15% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:06:02,495]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:06:03,026]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:06:15,911]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:06:16,321]\u001b[0m Trial 526 finished with value: 3.200296535127878 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008397408118803444, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2762076030559206, 'dropout_rate_Layer_2': 0.12500405213388552, 'dropout_rate_Layer_3': 0.06457642283420312, 'dropout_rate_Layer_4': 0.06306549845626085, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0031071729893594724, 'l1_Layer_2': 1.6881279023440322e-05, 'l1_Layer_3': 0.042878183826642186, 'l1_Layer_4': 0.006809832270487699, 'n_units_Layer_1': 65, 'n_units_Layer_2': 110, 'n_units_Layer_3': 110, 'n_units_Layer_4': 145}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.20 | sMAPE for Validation Set is: 7.87% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.48 | sMAPE for Test Set is: 7.24% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:06:18,552]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:06:21,397]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:06:29,714]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:06:33,770]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:06:38,274]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:06:45,244]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:06:49,310]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:06:51,698]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:06:53,620]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:06:56,325]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:06:58,991]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:06:59,800]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:07:05,164]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:07:27,822]\u001b[0m Trial 539 finished with value: 3.164847160548915 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008741772931003554, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10755889844995618, 'dropout_rate_Layer_2': 0.1223198384280467, 'dropout_rate_Layer_3': 0.30538640758079505, 'dropout_rate_Layer_4': 0.06765010228844802, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00447238761733761, 'l1_Layer_2': 1.5692328534996745e-05, 'l1_Layer_3': 0.025164919408349595, 'l1_Layer_4': 0.021556126819388743, 'n_units_Layer_1': 70, 'n_units_Layer_2': 130, 'n_units_Layer_3': 125, 'n_units_Layer_4': 145}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.16 | sMAPE for Validation Set is: 7.80% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.40 | sMAPE for Test Set is: 7.11% | rMAE for Test Set is: 0.69\n",
      "MAE for Validation Set is: 3.03 | sMAPE for Validation Set is: 7.53% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.84 | sMAPE for Test Set is: 8.10% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:07:27,925]\u001b[0m Trial 551 finished with value: 3.032816600755163 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008200479299147659, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24204211348176255, 'dropout_rate_Layer_2': 0.026900511885482238, 'dropout_rate_Layer_3': 0.3735243908481647, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004720587503818938, 'l1_Layer_2': 5.517219867869863e-05, 'l1_Layer_3': 0.00397743050838381, 'n_units_Layer_1': 300, 'n_units_Layer_2': 290, 'n_units_Layer_3': 260}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:07:33,625]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:07:35,145]\u001b[0m Trial 542 finished with value: 3.293288741964202 and parameters: {'n_hidden': 4, 'learning_rate': 0.000904847011886725, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1542100196933394, 'dropout_rate_Layer_2': 0.1366031245527021, 'dropout_rate_Layer_3': 0.06507761908582868, 'dropout_rate_Layer_4': 0.04554632036838773, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005757409781010296, 'l1_Layer_2': 1.5063806099414632e-05, 'l1_Layer_3': 0.03027068231050956, 'l1_Layer_4': 0.03354201431577209, 'n_units_Layer_1': 75, 'n_units_Layer_2': 130, 'n_units_Layer_3': 115, 'n_units_Layer_4': 150}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.29 | sMAPE for Validation Set is: 8.13% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 2.37 | sMAPE for Test Set is: 7.06% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:07:39,179]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:07:42,674]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:07:43,417]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.04 | sMAPE for Validation Set is: 7.55% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.30 | sMAPE for Test Set is: 6.87% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:07:46,630]\u001b[0m Trial 549 finished with value: 3.039907238851935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016969709834554895, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0923996004394089, 'dropout_rate_Layer_2': 0.024638643103280126, 'dropout_rate_Layer_3': 0.3362667845761736, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00515482658958791, 'l1_Layer_2': 5.360057693481827e-05, 'l1_Layer_3': 0.005072218664395253, 'n_units_Layer_1': 290, 'n_units_Layer_2': 290, 'n_units_Layer_3': 260}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:07:47,776]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:07:48,588]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:07:52,104]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:07:56,742]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:07:58,575]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:08:01,402]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:08:03,609]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:08:06,447]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:08:09,536]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:08:18,918]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:08:23,548]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:08:28,682]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:08:32,908]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:08:39,062]\u001b[0m Trial 561 finished with value: 2.9877515714350587 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007198576472903938, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21755876190202222, 'dropout_rate_Layer_2': 0.0005455379720235194, 'dropout_rate_Layer_3': 0.37883040461973466, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005211347840545627, 'l1_Layer_2': 8.10690561385698e-05, 'l1_Layer_3': 0.002227025016355954, 'n_units_Layer_1': 285, 'n_units_Layer_2': 285, 'n_units_Layer_3': 260}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.99 | sMAPE for Validation Set is: 7.43% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.20 | sMAPE for Test Set is: 6.58% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:08:41,359]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:08:45,642]\u001b[0m Trial 560 finished with value: 3.0362461732264117 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009141892690651348, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27745586769330643, 'dropout_rate_Layer_2': 0.005134957423999841, 'dropout_rate_Layer_3': 0.3702755039987201, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0036396151517692882, 'l1_Layer_2': 0.00019067507554129773, 'l1_Layer_3': 0.00513157910518408, 'n_units_Layer_1': 290, 'n_units_Layer_2': 285, 'n_units_Layer_3': 240}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.04 | sMAPE for Validation Set is: 7.52% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.42 | sMAPE for Test Set is: 7.13% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:08:45,822]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:08:46,237]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:08:51,330]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:08:53,407]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:08:55,515]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:08:59,185]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:09:02,734]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:09:06,196]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:09:09,668]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:09:13,781]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:09:33,322]\u001b[0m Trial 580 finished with value: 3.023669334638941 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006858874919896741, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24397140373460435, 'dropout_rate_Layer_2': 0.010847803197084966, 'dropout_rate_Layer_3': 0.38038535881978414, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005068256702240277, 'l1_Layer_2': 0.00022216259195821688, 'l1_Layer_3': 0.005400180758107613, 'n_units_Layer_1': 300, 'n_units_Layer_2': 285, 'n_units_Layer_3': 275}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.02 | sMAPE for Validation Set is: 7.51% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.39 | sMAPE for Test Set is: 7.03% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:09:37,914]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:09:44,490]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:09:48,844]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:09:54,067]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:09:54,804]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:09:59,915]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:10:03,128]\u001b[0m Trial 575 finished with value: 3.1621570292087466 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008852715182254003, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04563288479628347, 'dropout_rate_Layer_2': 0.11782653039653447, 'dropout_rate_Layer_3': 0.09395701061622205, 'dropout_rate_Layer_4': 0.2842133222519403, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0028025808925087005, 'l1_Layer_2': 3.261541492332734e-05, 'l1_Layer_3': 0.028325776196514798, 'l1_Layer_4': 0.029831529080616953, 'n_units_Layer_1': 60, 'n_units_Layer_2': 135, 'n_units_Layer_3': 125, 'n_units_Layer_4': 160}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:10:03,151]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.16 | sMAPE for Validation Set is: 7.78% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.48 | sMAPE for Test Set is: 7.23% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:10:14,127]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:10:18,906]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:10:22,035]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:10:29,345]\u001b[0m Trial 587 finished with value: 3.04448782679311 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005865978547635526, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2398916595685284, 'dropout_rate_Layer_2': 0.010148521914382817, 'dropout_rate_Layer_3': 0.39526996517809776, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005119033328046603, 'l1_Layer_2': 0.0002738048204194415, 'l1_Layer_3': 0.00344826141686473, 'n_units_Layer_1': 300, 'n_units_Layer_2': 285, 'n_units_Layer_3': 275}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.04 | sMAPE for Validation Set is: 7.55% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.57 | sMAPE for Test Set is: 7.49% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:10:29,706]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:10:34,637]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:10:34,842]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:10:39,471]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:10:39,958]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:10:40,604]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:10:46,763]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:10:48,142]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:10:50,940]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:10:54,294]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:10:59,773]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:01,488]\u001b[0m Trial 595 finished with value: 2.9940997278490555 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005412354102048053, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22448999324875724, 'dropout_rate_Layer_2': 0.01203090894025905, 'dropout_rate_Layer_3': 0.3689317268605239, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003479281709723322, 'l1_Layer_2': 0.00010298761076129846, 'l1_Layer_3': 0.003719554363924443, 'n_units_Layer_1': 285, 'n_units_Layer_2': 280, 'n_units_Layer_3': 275}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.99 | sMAPE for Validation Set is: 7.43% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.31 | sMAPE for Test Set is: 6.81% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:11:03,993]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:07,524]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:08,098]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:11,999]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:13,173]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:16,842]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:19,115]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:20,789]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:21,756]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:23,859]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:30,137]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:34,500]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:38,763]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:43,246]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:45,098]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:45,453]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:49,143]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:51,974]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:11:57,922]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:00,270]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:01,061]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:04,606]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:06,257]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:06,538]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:11,948]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:14,870]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:15,540]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:15,821]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:18,057]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:21,165]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:23,424]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:24,951]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:26,998]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:29,314]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:30,949]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:31,715]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:33,308]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:40,083]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:40,355]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:43,872]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:49,630]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:51,610]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:52,576]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:56,061]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:12:57,974]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:13:01,271]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:13:12,448]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:13:19,098]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:13:19,726]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:13:29,893]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:13:34,156]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:13:40,301]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:13:48,683]\u001b[0m Trial 655 finished with value: 3.0193727054720267 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008345831086771449, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24917032468844144, 'dropout_rate_Layer_2': 5.479940085355989e-05, 'dropout_rate_Layer_3': 0.09445893049015086, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007868488820734314, 'l1_Layer_2': 0.0001590031966345394, 'l1_Layer_3': 0.0015077732508826476, 'n_units_Layer_1': 300, 'n_units_Layer_2': 290, 'n_units_Layer_3': 280}. Best is trial 161 with value: 2.8987039480706613.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.02 | sMAPE for Validation Set is: 7.50% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.49 | sMAPE for Test Set is: 7.33% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:13:51,944]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:13:55,102]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:14:03,702]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:14:07,435]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:14:10,408]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:14:14,658]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:14:15,111]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:14:17,873]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:14:20,671]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:14:25,423]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:14:34,774]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:14:40,342]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:14:43,532]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:14:46,564]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:14:49,214]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:14:52,359]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:15:00,004]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:15:11,286]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:15:20,488]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:15:26,596]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:15:31,698]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:15:39,601]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:15:51,729]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:15:55,601]\u001b[0m Trial 671 finished with value: 2.7148771157211438 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006401013909318948, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.050862008019832775, 'dropout_rate_Layer_2': 0.2302500293648961, 'dropout_rate_Layer_3': 0.16150766698856292, 'dropout_rate_Layer_4': 0.09566491536484878, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0033390552452214318, 'l1_Layer_2': 1.681873900486363e-05, 'l1_Layer_3': 0.004588144733269839, 'l1_Layer_4': 1.1468034535661571e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 215, 'n_units_Layer_3': 145, 'n_units_Layer_4': 145}. Best is trial 671 with value: 2.7148771157211438.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.71 | sMAPE for Validation Set is: 6.73% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 2.13 | sMAPE for Test Set is: 6.35% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:15:55,952]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:16:02,327]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:16:02,905]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:16:08,674]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:16:16,277]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:16:58,496]\u001b[0m Trial 673 finished with value: 3.047249534614038 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007553565959054012, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0001203181731373286, 'dropout_rate_Layer_2': 0.3795222481886829, 'dropout_rate_Layer_3': 0.019287285962686574, 'dropout_rate_Layer_4': 0.0271609416653518, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.7833936820377026e-05, 'l1_Layer_2': 0.0012274503872352989, 'l1_Layer_3': 0.0022626926497638085, 'l1_Layer_4': 0.05002190463673009, 'n_units_Layer_1': 270, 'n_units_Layer_2': 205, 'n_units_Layer_3': 295, 'n_units_Layer_4': 50}. Best is trial 671 with value: 2.7148771157211438.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.05 | sMAPE for Validation Set is: 7.53% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.23 | sMAPE for Test Set is: 6.69% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:17:02,170]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:17:11,892]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:17:15,480]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:17:18,986]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:17:22,597]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:17:29,139]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:17:55,477]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:18:04,147]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:18:07,222]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:18:10,132]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:18:12,770]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:18:17,465]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:18:20,700]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:18:25,763]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:18:26,367]\u001b[0m Trial 692 finished with value: 3.0188434600297303 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008893212089004063, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002802131036076372, 'dropout_rate_Layer_2': 0.3797087919707111, 'dropout_rate_Layer_3': 0.016383158731023136, 'dropout_rate_Layer_4': 0.02430273978634303, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.457458265583962e-05, 'l1_Layer_2': 0.0005121927593258303, 'l1_Layer_3': 0.0024873915808253993, 'l1_Layer_4': 0.047379782112856976, 'n_units_Layer_1': 275, 'n_units_Layer_2': 205, 'n_units_Layer_3': 300, 'n_units_Layer_4': 50}. Best is trial 671 with value: 2.7148771157211438.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.02 | sMAPE for Validation Set is: 7.44% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.39 | sMAPE for Test Set is: 7.05% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:18:31,952]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:18:38,891]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:18:41,155]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:18:51,882]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:19:07,834]\u001b[0m Trial 690 finished with value: 3.0045821845908853 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008083659885592817, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0013054937907087463, 'dropout_rate_Layer_2': 0.37815824398732606, 'dropout_rate_Layer_3': 0.0174029567052908, 'dropout_rate_Layer_4': 0.026133613192865272, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.491964805099194e-05, 'l1_Layer_2': 0.0011687135805828394, 'l1_Layer_3': 0.0001977239955970244, 'l1_Layer_4': 0.05824170026897446, 'n_units_Layer_1': 270, 'n_units_Layer_2': 205, 'n_units_Layer_3': 300, 'n_units_Layer_4': 50}. Best is trial 671 with value: 2.7148771157211438.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.00 | sMAPE for Validation Set is: 7.43% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.41 | sMAPE for Test Set is: 7.14% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:19:11,876]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:19:15,096]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:19:24,143]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:19:27,223]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:19:34,409]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:19:35,057]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:19:39,605]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:19:41,423]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:19:44,413]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:19:49,780]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:19:56,675]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:20:03,072]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:20:05,824]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:20:11,729]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:20:29,452]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:20:46,598]\u001b[0m Trial 710 finished with value: 2.69086373472569 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012288687634270505, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013265833323603251, 'dropout_rate_Layer_2': 0.16983738309244648, 'dropout_rate_Layer_3': 0.057523704995250446, 'dropout_rate_Layer_4': 0.020681417430075528, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.76258306527257e-05, 'l1_Layer_2': 0.0008197435487026681, 'l1_Layer_3': 0.012143845614402762, 'l1_Layer_4': 1.0620563473824796e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 235, 'n_units_Layer_3': 295, 'n_units_Layer_4': 60}. Best is trial 710 with value: 2.69086373472569.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.69 | sMAPE for Validation Set is: 6.72% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.92 | sMAPE for Test Set is: 5.83% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:20:51,248]\u001b[0m Trial 727 finished with value: 3.050835257615457 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020974656901879, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15196178986722386, 'dropout_rate_Layer_2': 0.15417920471523247, 'dropout_rate_Layer_3': 0.11857195477718074, 'dropout_rate_Layer_4': 0.2215151059658941, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003866680779556602, 'l1_Layer_2': 0.029865712983979126, 'l1_Layer_3': 1.0236296284175948e-05, 'l1_Layer_4': 0.005452228726568321, 'n_units_Layer_1': 125, 'n_units_Layer_2': 130, 'n_units_Layer_3': 230, 'n_units_Layer_4': 185}. Best is trial 710 with value: 2.69086373472569.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.05 | sMAPE for Validation Set is: 7.56% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.25 | sMAPE for Test Set is: 6.71% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:21:06,125]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:21:13,110]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:21:21,962]\u001b[0m Trial 726 finished with value: 2.9047509494440518 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005867619524672704, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21056599748127636, 'dropout_rate_Layer_2': 0.011888537625262825, 'dropout_rate_Layer_3': 0.028489824259979604, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005548202005074465, 'l1_Layer_2': 7.331528677055562e-05, 'l1_Layer_3': 0.002392789580443675, 'n_units_Layer_1': 290, 'n_units_Layer_2': 290, 'n_units_Layer_3': 255}. Best is trial 710 with value: 2.69086373472569.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.90 | sMAPE for Validation Set is: 7.23% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 2.01 | sMAPE for Test Set is: 6.07% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:21:22,417]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:21:27,598]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:21:30,539]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:21:34,363]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:21:36,217]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:21:44,255]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:21:46,321]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:22:36,407]\u001b[0m Trial 739 finished with value: 2.816263212225291 and parameters: {'n_hidden': 4, 'learning_rate': 0.001562839004508883, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1283273278606859, 'dropout_rate_Layer_2': 0.12745857791016282, 'dropout_rate_Layer_3': 0.04094141826602002, 'dropout_rate_Layer_4': 0.2526730509815072, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0024555896379120394, 'l1_Layer_2': 0.02067982593068819, 'l1_Layer_3': 0.0012966249904812475, 'l1_Layer_4': 0.0005364358391943035, 'n_units_Layer_1': 60, 'n_units_Layer_2': 70, 'n_units_Layer_3': 235, 'n_units_Layer_4': 205}. Best is trial 710 with value: 2.69086373472569.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.82 | sMAPE for Validation Set is: 6.96% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 2.38 | sMAPE for Test Set is: 6.88% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:22:43,280]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:22:43,613]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:22:48,479]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:22:58,221]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:23:07,828]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:23:32,893]\u001b[0m Trial 740 finished with value: 3.124863096748651 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016226481444912915, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.055273975135973735, 'dropout_rate_Layer_2': 0.18402382552194502, 'dropout_rate_Layer_3': 0.04243263765279752, 'dropout_rate_Layer_4': 0.05052247911946431, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.8587762112502506e-05, 'l1_Layer_2': 0.0010820098561121177, 'l1_Layer_3': 0.018296972475602948, 'l1_Layer_4': 7.312669439967789e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 285, 'n_units_Layer_3': 265, 'n_units_Layer_4': 80}. Best is trial 710 with value: 2.69086373472569.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.12 | sMAPE for Validation Set is: 7.69% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.71 | sMAPE for Test Set is: 7.75% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:23:36,488]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:23:41,672]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:23:41,834]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:23:47,245]\u001b[0m Trial 746 finished with value: 3.067800986789015 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019283113189228246, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1299661500856443, 'dropout_rate_Layer_2': 0.12666810589818484, 'dropout_rate_Layer_3': 0.018443125770198847, 'dropout_rate_Layer_4': 0.2525400629797029, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006921612207868406, 'l1_Layer_2': 0.019042379494042503, 'l1_Layer_3': 0.0012716946588235902, 'l1_Layer_4': 0.00028526108272429733, 'n_units_Layer_1': 60, 'n_units_Layer_2': 50, 'n_units_Layer_3': 235, 'n_units_Layer_4': 265}. Best is trial 710 with value: 2.69086373472569.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.07 | sMAPE for Validation Set is: 7.48% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.24 | sMAPE for Test Set is: 6.64% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:23:50,150]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:23:53,325]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:23:58,787]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:24:01,977]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:24:05,770]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:24:08,971]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:24:18,737]\u001b[0m Trial 730 finished with value: 3.254123510524104 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006120053322093215, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1260715324934212, 'dropout_rate_Layer_2': 0.10893800114190062, 'dropout_rate_Layer_3': 0.09825554933147418, 'dropout_rate_Layer_4': 0.04230624148082022, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003183352370477012, 'l1_Layer_2': 0.006430356266043803, 'l1_Layer_3': 0.0008841405215528245, 'l1_Layer_4': 0.012086622846230232, 'n_units_Layer_1': 60, 'n_units_Layer_2': 145, 'n_units_Layer_3': 290, 'n_units_Layer_4': 145}. Best is trial 710 with value: 2.69086373472569.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.25 | sMAPE for Validation Set is: 7.97% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 2.60 | sMAPE for Test Set is: 7.53% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:24:23,906]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:24:24,533]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:24:28,668]\u001b[0m Trial 749 finished with value: 2.997515130673485 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011190280625437677, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12499459335938129, 'dropout_rate_Layer_2': 0.12228541257442194, 'dropout_rate_Layer_3': 0.01953151535066515, 'dropout_rate_Layer_4': 0.2844139617700092, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0032702886826147925, 'l1_Layer_2': 0.019113960102925636, 'l1_Layer_3': 1.0353307932461779e-05, 'l1_Layer_4': 0.0004833160547814239, 'n_units_Layer_1': 65, 'n_units_Layer_2': 65, 'n_units_Layer_3': 235, 'n_units_Layer_4': 205}. Best is trial 710 with value: 2.69086373472569.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.00 | sMAPE for Validation Set is: 7.39% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.21 | sMAPE for Test Set is: 6.57% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:24:31,314]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:24:32,296]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:24:32,412]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:24:40,493]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:24:44,945]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:24:45,038]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:25:05,254]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:25:13,960]\u001b[0m Trial 765 finished with value: 2.7516507399814762 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007972700816231057, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10951220925433269, 'dropout_rate_Layer_2': 0.06787082457893434, 'dropout_rate_Layer_3': 0.03687496177128122, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00298328850139145, 'l1_Layer_2': 2.9489745950265775e-05, 'l1_Layer_3': 0.0025162606643880183, 'n_units_Layer_1': 290, 'n_units_Layer_2': 285, 'n_units_Layer_3': 255}. Best is trial 710 with value: 2.69086373472569.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.75 | sMAPE for Validation Set is: 6.84% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 2.42 | sMAPE for Test Set is: 7.05% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:25:19,717]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:25:22,444]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:25:25,163]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:26:02,080]\u001b[0m Trial 769 finished with value: 2.807421261340768 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012930023485671794, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11191777207912162, 'dropout_rate_Layer_2': 0.1469508276825765, 'dropout_rate_Layer_3': 0.044341412447959284, 'dropout_rate_Layer_4': 0.28579673285089596, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003585117138257325, 'l1_Layer_2': 0.01641651893414494, 'l1_Layer_3': 2.189755279392996e-05, 'l1_Layer_4': 0.00018576378593560891, 'n_units_Layer_1': 65, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225, 'n_units_Layer_4': 205}. Best is trial 710 with value: 2.69086373472569.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.81 | sMAPE for Validation Set is: 6.99% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 2.23 | sMAPE for Test Set is: 6.50% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:26:10,235]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:26:12,122]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:26:14,941]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:26:16,730]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:26:19,748]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:26:20,658]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:26:45,318]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:26:50,825]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:26:57,976]\u001b[0m Trial 779 finished with value: 2.77850870670553 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012863696195655667, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1031614826357142, 'dropout_rate_Layer_2': 0.1467909134214016, 'dropout_rate_Layer_3': 0.04301629684972063, 'dropout_rate_Layer_4': 0.2846382080669844, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0032974933581693486, 'l1_Layer_2': 0.006978560931634753, 'l1_Layer_3': 1.4041881984577952e-05, 'l1_Layer_4': 0.0002460658644380328, 'n_units_Layer_1': 60, 'n_units_Layer_2': 50, 'n_units_Layer_3': 225, 'n_units_Layer_4': 265}. Best is trial 710 with value: 2.69086373472569.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.78 | sMAPE for Validation Set is: 6.91% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 2.18 | sMAPE for Test Set is: 6.43% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:26:58,510]\u001b[0m Trial 768 finished with value: 2.981428040286017 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006981657566769833, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04360188821112294, 'dropout_rate_Layer_2': 0.14660611314082733, 'dropout_rate_Layer_3': 0.07037686955983466, 'dropout_rate_Layer_4': 0.016429541094085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4172307296011475e-05, 'l1_Layer_2': 0.002741167536463138, 'l1_Layer_3': 0.00335196841687463, 'l1_Layer_4': 0.0003908490171583249, 'n_units_Layer_1': 275, 'n_units_Layer_2': 260, 'n_units_Layer_3': 285, 'n_units_Layer_4': 60}. Best is trial 710 with value: 2.69086373472569.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.98 | sMAPE for Validation Set is: 7.40% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.19 | sMAPE for Test Set is: 6.62% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:26:58,737]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:27:03,113]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:27:05,062]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:27:11,909]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:27:13,846]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:27:16,720]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:27:18,783]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:27:20,945]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:27:21,004]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:27:21,716]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:27:26,981]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:27:30,099]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:27:33,371]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:27:34,431]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:27:37,197]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:27:41,004]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:27:47,177]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:28:03,583]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:28:08,189]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:28:09,896]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:28:10,560]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:28:15,830]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:28:16,063]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:28:18,108]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:28:22,955]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:28:24,348]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:28:27,987]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:28:28,831]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:28:32,980]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:28:35,052]\u001b[0m Trial 766 finished with value: 2.661968137214526 and parameters: {'n_hidden': 4, 'learning_rate': 0.000696650647061295, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.041624445384008946, 'dropout_rate_Layer_2': 0.1534182379700909, 'dropout_rate_Layer_3': 0.02035722706691242, 'dropout_rate_Layer_4': 0.01482044829583762, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.2450064924757446e-05, 'l1_Layer_2': 0.0004503766960311792, 'l1_Layer_3': 0.0031944683883818803, 'l1_Layer_4': 0.0005077938074374401, 'n_units_Layer_1': 265, 'n_units_Layer_2': 260, 'n_units_Layer_3': 285, 'n_units_Layer_4': 60}. Best is trial 766 with value: 2.661968137214526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.66 | sMAPE for Validation Set is: 6.63% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 2.08 | sMAPE for Test Set is: 6.22% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:28:38,587]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:28:39,246]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:28:39,470]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:28:45,157]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:29:05,479]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:29:12,940]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:29:20,287]\u001b[0m Trial 810 finished with value: 3.0255202110652823 and parameters: {'n_hidden': 3, 'learning_rate': 0.000633945886253489, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2519597849967644, 'dropout_rate_Layer_2': 0.013569148540080771, 'dropout_rate_Layer_3': 0.36428971591308423, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008177424672591653, 'l1_Layer_2': 8.326034668285283e-05, 'l1_Layer_3': 0.007035245408769263, 'n_units_Layer_1': 300, 'n_units_Layer_2': 285, 'n_units_Layer_3': 270}. Best is trial 766 with value: 2.661968137214526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.03 | sMAPE for Validation Set is: 7.51% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.33 | sMAPE for Test Set is: 6.96% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:29:30,355]\u001b[0m Trial 816 finished with value: 2.802007609013073 and parameters: {'n_hidden': 4, 'learning_rate': 0.001503469779824544, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08658374285694972, 'dropout_rate_Layer_2': 0.12939574520561115, 'dropout_rate_Layer_3': 0.041727588412381375, 'dropout_rate_Layer_4': 0.28939597073844514, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006609585443720116, 'l1_Layer_2': 0.012490822259286395, 'l1_Layer_3': 1.856972911029603e-05, 'l1_Layer_4': 0.0001931407081934142, 'n_units_Layer_1': 60, 'n_units_Layer_2': 50, 'n_units_Layer_3': 225, 'n_units_Layer_4': 270}. Best is trial 766 with value: 2.661968137214526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.80 | sMAPE for Validation Set is: 6.98% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 2.09 | sMAPE for Test Set is: 6.21% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:29:33,341]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:30:01,954]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:30:06,410]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:30:17,565]\u001b[0m Trial 815 finished with value: 3.0123787233949373 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006874828953238938, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04513239913617403, 'dropout_rate_Layer_2': 0.178939693017677, 'dropout_rate_Layer_3': 0.05001423663492628, 'dropout_rate_Layer_4': 0.03975249304667849, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0659397226047278e-05, 'l1_Layer_2': 0.00020817578446166715, 'l1_Layer_3': 0.03569147646052808, 'l1_Layer_4': 0.0004912167868514366, 'n_units_Layer_1': 280, 'n_units_Layer_2': 260, 'n_units_Layer_3': 295, 'n_units_Layer_4': 75}. Best is trial 766 with value: 2.661968137214526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.01 | sMAPE for Validation Set is: 7.48% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.21 | sMAPE for Test Set is: 6.68% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:30:39,336]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:30:55,210]\u001b[0m Trial 824 finished with value: 2.933258366504861 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008032512067639154, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07145661356941045, 'dropout_rate_Layer_2': 0.1293403220855867, 'dropout_rate_Layer_3': 0.04824523316284706, 'dropout_rate_Layer_4': 0.3108337538384418, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.017498029063313852, 'l1_Layer_2': 0.008577828269191507, 'l1_Layer_3': 1.3181981931111506e-05, 'l1_Layer_4': 0.00020812050051426467, 'n_units_Layer_1': 60, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225, 'n_units_Layer_4': 270}. Best is trial 766 with value: 2.661968137214526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.93 | sMAPE for Validation Set is: 7.26% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.01 | sMAPE for Test Set is: 6.08% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:30:58,389]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:31:02,965]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:31:09,723]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:31:19,758]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:31:24,360]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:31:37,872]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:31:42,519]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:31:45,325]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:31:47,771]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:31:55,685]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:31:59,232]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:32:01,873]\u001b[0m Trial 822 finished with value: 2.6938060945860727 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006264408550569833, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025384365343098, 'dropout_rate_Layer_2': 0.17686669460180887, 'dropout_rate_Layer_3': 0.047329833784212946, 'dropout_rate_Layer_4': 0.03918445203080737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0238160673901004e-05, 'l1_Layer_2': 2.045714827200553e-05, 'l1_Layer_3': 0.001565132373829532, 'l1_Layer_4': 0.000512417941369723, 'n_units_Layer_1': 280, 'n_units_Layer_2': 260, 'n_units_Layer_3': 295, 'n_units_Layer_4': 75}. Best is trial 766 with value: 2.661968137214526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.69 | sMAPE for Validation Set is: 6.67% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 2.19 | sMAPE for Test Set is: 6.42% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:32:05,076]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:32:07,871]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:32:12,962]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:32:16,999]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:32:32,506]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:32:35,807]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:32:40,585]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:32:44,341]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:32:51,433]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:32:55,506]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:33:05,470]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:33:07,259]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:33:13,393]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:33:16,351]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:33:30,393]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:33:30,703]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:33:31,365]\u001b[0m Trial 839 finished with value: 3.073440646912133 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008230888589371809, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12580519157165374, 'dropout_rate_Layer_2': 0.22703410045441244, 'dropout_rate_Layer_3': 0.19356967109608253, 'dropout_rate_Layer_4': 0.06267320586003783, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0035589177033466496, 'l1_Layer_2': 4.101851682783219e-05, 'l1_Layer_3': 0.0001211941188355487, 'l1_Layer_4': 0.02212784997383221, 'n_units_Layer_1': 55, 'n_units_Layer_2': 210, 'n_units_Layer_3': 105, 'n_units_Layer_4': 140}. Best is trial 766 with value: 2.661968137214526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.07 | sMAPE for Validation Set is: 7.63% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.24 | sMAPE for Test Set is: 6.71% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:33:37,171]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:33:39,538]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:33:40,093]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:33:45,749]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:33:46,461]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:33:51,812]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:33:52,033]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:33:57,109]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:33:57,268]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:34:02,937]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:34:03,280]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:34:03,389]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:34:06,869]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:34:14,767]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:34:14,971]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:34:21,719]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:34:24,794]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:34:29,814]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:34:38,870]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:34:42,330]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:34:45,035]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:34:53,660]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:34:57,290]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:35:00,666]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:35:05,337]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:35:08,826]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:35:11,596]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:35:14,665]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:35:14,893]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:35:21,870]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:35:25,000]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:35:32,764]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:35:33,826]\u001b[0m Trial 869 finished with value: 3.239295608806433 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009788063870166054, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11378497853548708, 'dropout_rate_Layer_2': 0.23233379753075523, 'dropout_rate_Layer_3': 0.09696216233693447, 'dropout_rate_Layer_4': 0.0487973444676668, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004271767374783373, 'l1_Layer_2': 0.030222716787026174, 'l1_Layer_3': 0.03071508242085361, 'l1_Layer_4': 0.005478870117144633, 'n_units_Layer_1': 65, 'n_units_Layer_2': 200, 'n_units_Layer_3': 110, 'n_units_Layer_4': 140}. Best is trial 766 with value: 2.661968137214526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.24 | sMAPE for Validation Set is: 7.95% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.44 | sMAPE for Test Set is: 7.15% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:35:36,868]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:35:44,577]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:35:48,962]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:35:53,382]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:35:54,212]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:35:58,730]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:00,658]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:05,524]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:10,055]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:15,827]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:21,579]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:21,746]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:25,989]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:27,357]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:29,984]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:32,244]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:36,405]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:36,947]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:41,978]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:46,496]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:48,278]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:50,281]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:52,305]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:56,229]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:36:58,066]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:37:02,004]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:37:02,248]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:37:07,467]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:37:09,179]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:37:13,882]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:37:17,138]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:37:25,071]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:37:28,717]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:37:31,475]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:37:36,280]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:38:35,073]\u001b[0m Trial 888 finished with value: 2.7171608260312787 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011041781892565472, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009662120585189657, 'dropout_rate_Layer_2': 0.22390577107654558, 'dropout_rate_Layer_3': 0.013264263893680402, 'dropout_rate_Layer_4': 0.02657743339442881, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.09169350166627e-05, 'l1_Layer_2': 0.00011008641173778586, 'l1_Layer_3': 0.004964681538266803, 'l1_Layer_4': 0.0014448012984343186, 'n_units_Layer_1': 275, 'n_units_Layer_2': 245, 'n_units_Layer_3': 295, 'n_units_Layer_4': 65}. Best is trial 766 with value: 2.661968137214526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.72 | sMAPE for Validation Set is: 6.76% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 2.19 | sMAPE for Test Set is: 6.44% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:38:41,317]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:38:46,650]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:38:50,071]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:38:54,009]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:38:58,134]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:39:05,546]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:39:12,997]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:39:16,724]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:39:27,460]\u001b[0m Trial 924 finished with value: 2.7519060598316583 and parameters: {'n_hidden': 4, 'learning_rate': 0.001185215430636058, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01949503213839814, 'dropout_rate_Layer_2': 0.20388844077429902, 'dropout_rate_Layer_3': 0.013832520766728465, 'dropout_rate_Layer_4': 0.02787994242658135, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.445468549527419e-05, 'l1_Layer_2': 8.806697996497712e-05, 'l1_Layer_3': 0.0049295477006933855, 'l1_Layer_4': 0.0003689379952940829, 'n_units_Layer_1': 285, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300, 'n_units_Layer_4': 65}. Best is trial 766 with value: 2.661968137214526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.75 | sMAPE for Validation Set is: 6.83% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 2.12 | sMAPE for Test Set is: 6.36% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:39:30,775]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:39:32,362]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:39:35,518]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:39:36,179]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:39:40,940]\u001b[0m Trial 922 finished with value: 2.7125939284356613 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010723823996428871, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021414186481999074, 'dropout_rate_Layer_2': 0.18094965485449982, 'dropout_rate_Layer_3': 0.016265595316055165, 'dropout_rate_Layer_4': 0.030508818233555977, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4027680225374659e-05, 'l1_Layer_2': 9.375428913678636e-05, 'l1_Layer_3': 0.004881824939401245, 'l1_Layer_4': 0.00036862364398344475, 'n_units_Layer_1': 285, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300, 'n_units_Layer_4': 65}. Best is trial 766 with value: 2.661968137214526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.71 | sMAPE for Validation Set is: 6.78% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.97 | sMAPE for Test Set is: 5.97% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:39:41,239]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:39:47,268]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:39:48,697]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:39:51,281]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:39:52,120]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:39:56,995]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:40:01,325]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:40:05,576]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:40:08,341]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:40:09,000]\u001b[0m Trial 920 finished with value: 2.7014032367576655 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011690022693783195, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01982919337039365, 'dropout_rate_Layer_2': 0.23101013567823603, 'dropout_rate_Layer_3': 0.009221641788038852, 'dropout_rate_Layer_4': 0.012757692165144982, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.3683043751472987e-05, 'l1_Layer_2': 0.0001102260472212657, 'l1_Layer_3': 0.0006652709059456956, 'l1_Layer_4': 0.00022196042249163073, 'n_units_Layer_1': 285, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300, 'n_units_Layer_4': 70}. Best is trial 766 with value: 2.661968137214526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.70 | sMAPE for Validation Set is: 6.69% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 2.09 | sMAPE for Test Set is: 6.24% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:40:13,761]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:40:21,826]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:40:36,545]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:40:41,480]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:40:44,719]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:40:50,895]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:40:53,920]\u001b[0m Trial 943 finished with value: 2.729173177638311 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010835685036751784, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020450934038007157, 'dropout_rate_Layer_2': 0.20579537258395025, 'dropout_rate_Layer_3': 0.007526113830315451, 'dropout_rate_Layer_4': 0.05619009117197857, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.339875414541287e-05, 'l1_Layer_2': 9.163402106835032e-05, 'l1_Layer_3': 0.005122984669732794, 'l1_Layer_4': 0.0002278441501787692, 'n_units_Layer_1': 295, 'n_units_Layer_2': 235, 'n_units_Layer_3': 285, 'n_units_Layer_4': 65}. Best is trial 766 with value: 2.661968137214526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.73 | sMAPE for Validation Set is: 6.80% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 2.15 | sMAPE for Test Set is: 6.38% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:40:56,013]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:40:58,992]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:01,872]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:05,439]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:09,952]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:12,906]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:14,052]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:17,281]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:18,485]\u001b[0m Trial 938 finished with value: 2.7798277740061175 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006121803574058097, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13552683946613833, 'dropout_rate_Layer_2': 0.16421318860375853, 'dropout_rate_Layer_3': 0.017494158567776873, 'dropout_rate_Layer_4': 0.28885303362283726, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00485156613864784, 'l1_Layer_2': 0.006477579475543872, 'l1_Layer_3': 3.766774582890454e-05, 'l1_Layer_4': 0.0008573384557642348, 'n_units_Layer_1': 90, 'n_units_Layer_2': 65, 'n_units_Layer_3': 250, 'n_units_Layer_4': 235}. Best is trial 766 with value: 2.661968137214526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.78 | sMAPE for Validation Set is: 6.87% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 2.12 | sMAPE for Test Set is: 6.29% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:41:21,904]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:22,353]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:26,943]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:29,515]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:30,049]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:32,889]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:34,632]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:39,130]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:42,466]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:42,840]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:43,277]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:49,677]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:50,161]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:50,638]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:56,918]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:41:58,290]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:42:02,241]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:42:04,524]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:42:05,832]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:42:09,013]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:42:14,376]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:42:22,147]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:42:24,941]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:42:33,454]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:42:37,504]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:43:07,491]\u001b[0m Trial 969 finished with value: 2.6788959417884803 and parameters: {'n_hidden': 4, 'learning_rate': 0.000629819740438347, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11615409017710579, 'dropout_rate_Layer_2': 0.1880153610551262, 'dropout_rate_Layer_3': 0.022029496294567134, 'dropout_rate_Layer_4': 0.28395605385456074, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0028617781570258894, 'l1_Layer_2': 0.00671122512184481, 'l1_Layer_3': 2.7315190570388373e-05, 'l1_Layer_4': 0.00023973621187612225, 'n_units_Layer_1': 75, 'n_units_Layer_2': 80, 'n_units_Layer_3': 250, 'n_units_Layer_4': 250}. Best is trial 766 with value: 2.661968137214526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.68 | sMAPE for Validation Set is: 6.69% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 2.17 | sMAPE for Test Set is: 6.36% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:43:07,654]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:43:15,053]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:43:19,655]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:43:20,647]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:43:25,384]\u001b[0m Trial 990 finished with value: 3.067135775262417 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008884555561423361, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23792311682571582, 'dropout_rate_Layer_2': 0.01907154382739433, 'dropout_rate_Layer_3': 0.08229778269888871, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028653468094782756, 'l1_Layer_2': 0.0001018930327385342, 'l1_Layer_3': 0.007172599799581028, 'n_units_Layer_1': 295, 'n_units_Layer_2': 205, 'n_units_Layer_3': 290}. Best is trial 766 with value: 2.661968137214526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.07 | sMAPE for Validation Set is: 7.62% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.60 | sMAPE for Test Set is: 7.53% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:43:26,221]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:43:26,831]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:43:34,176]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:43:34,834]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:43:40,858]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:43:51,191]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:43:53,052]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:43:57,167]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:44:01,230]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:44:06,851]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:44:13,065]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:44:14,387]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:44:19,295]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:44:24,417]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:44:29,325]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:44:37,060]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:44:41,135]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:44:49,768]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:44:53,510]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:44:53,872]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:45:00,670]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:45:01,678]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:45:14,794]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:45:19,343]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:45:24,079]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:45:31,044]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:45:35,688]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:45:40,260]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:45:45,954]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:45:47,969]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:45:50,201]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:45:50,870]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:45:52,416]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:45:56,077]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:45:57,710]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:01,108]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:03,986]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:04,246]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:05,378]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:12,252]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:18,910]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:24,051]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:28,390]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:28,708]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:29,411]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:37,186]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:39,484]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:41,179]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:47,665]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:49,433]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:51,394]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:53,325]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:55,953]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:46:58,756]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:01,788]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:05,339]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:05,528]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:11,855]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:14,487]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:18,497]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:19,240]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:24,864]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:25,243]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:25,396]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:32,358]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:32,567]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:33,461]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:33,510]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:40,176]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:41,221]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:42,978]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:44,283]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:48,342]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:52,778]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:53,098]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:47:53,616]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:48:00,191]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:48:00,292]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:48:04,492]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:48:06,480]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:48:09,134]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:48:09,965]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:48:10,801]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:48:18,314]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:48:21,233]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:48:21,700]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:48:27,050]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:48:30,892]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:48:35,600]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:48:37,264]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:48:43,476]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:48:51,570]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:49:36,957]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:49:42,993]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:49:46,699]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:49:56,305]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:50:00,278]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:50:03,144]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:50:08,289]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:50:11,602]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:50:17,261]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:50:20,757]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:50:25,107]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:50:28,150]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:50:33,713]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:50:39,154]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:50:46,453]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:50:49,395]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:50:52,318]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:50:54,553]\u001b[0m Trial 1085 finished with value: 2.7077741171616636 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007436415709132153, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2524377074423518, 'dropout_rate_Layer_2': 0.018211442071840833, 'dropout_rate_Layer_3': 0.0012979537794598041, 'dropout_rate_Layer_4': 0.02346304764556743, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.8556576782912935e-05, 'l1_Layer_2': 1.0360149479208385e-05, 'l1_Layer_3': 0.003185430091986806, 'l1_Layer_4': 0.000284068230055761, 'n_units_Layer_1': 275, 'n_units_Layer_2': 220, 'n_units_Layer_3': 270, 'n_units_Layer_4': 65}. Best is trial 766 with value: 2.661968137214526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.71 | sMAPE for Validation Set is: 6.72% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 5.76% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:51:01,951]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:51:02,427]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:51:14,670]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:51:15,479]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:51:18,986]\u001b[0m Trial 1086 finished with value: 2.5921985426517393 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007497441379210405, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006277986588049983, 'dropout_rate_Layer_2': 0.00283862491827247, 'dropout_rate_Layer_3': 0.019590336474706947, 'dropout_rate_Layer_4': 0.025989686088654124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.939062773184065e-05, 'l1_Layer_2': 2.49845592169184e-05, 'l1_Layer_3': 0.0026473270037209607, 'l1_Layer_4': 0.0006896399317874452, 'n_units_Layer_1': 275, 'n_units_Layer_2': 220, 'n_units_Layer_3': 270, 'n_units_Layer_4': 65}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.59 | sMAPE for Validation Set is: 6.41% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 1.93 | sMAPE for Test Set is: 5.79% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:51:22,547]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:51:24,828]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:51:28,222]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:51:28,299]\u001b[0m Trial 1066 finished with value: 2.6668700361251836 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007723439426843865, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025125042903559824, 'dropout_rate_Layer_2': 0.20169590206828664, 'dropout_rate_Layer_3': 0.0013486322366193784, 'dropout_rate_Layer_4': 0.025834734033886957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.727937697583647e-05, 'l1_Layer_2': 2.719854634430552e-05, 'l1_Layer_3': 0.010206160638475273, 'l1_Layer_4': 0.0006666784395039373, 'n_units_Layer_1': 275, 'n_units_Layer_2': 220, 'n_units_Layer_3': 270, 'n_units_Layer_4': 65}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.67 | sMAPE for Validation Set is: 6.61% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 2.15 | sMAPE for Test Set is: 6.38% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:51:29,166]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:51:36,468]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:51:37,506]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:51:43,146]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:51:46,094]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:51:50,269]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:51:53,157]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:51:55,469]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:51:57,585]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:51:59,049]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:52:00,520]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:52:07,155]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:52:08,093]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:52:13,531]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:52:15,493]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:52:17,866]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:52:21,442]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:52:21,945]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:52:25,211]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:52:51,114]\u001b[0m Trial 1124 finished with value: 2.7999882094109747 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011052199570880767, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15063012864860392, 'dropout_rate_Layer_2': 0.10904238826337505, 'dropout_rate_Layer_3': 0.14098208934722778, 'dropout_rate_Layer_4': 0.2726653852164397, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006617733875558137, 'l1_Layer_2': 0.02134674531328704, 'l1_Layer_3': 2.088718264370228e-05, 'l1_Layer_4': 0.0005187711038707559, 'n_units_Layer_1': 80, 'n_units_Layer_2': 65, 'n_units_Layer_3': 260, 'n_units_Layer_4': 230}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.80 | sMAPE for Validation Set is: 7.01% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 2.05 | sMAPE for Test Set is: 6.15% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:53:00,365]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:53:03,741]\u001b[0m Trial 1133 finished with value: 3.0460413124130654 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005883201688276504, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23299227843568848, 'dropout_rate_Layer_2': 0.023002930133480242, 'dropout_rate_Layer_3': 0.09308415496631374, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0059640309261174765, 'l1_Layer_2': 1.766761487271688e-05, 'l1_Layer_3': 0.003771456239478967, 'n_units_Layer_1': 290, 'n_units_Layer_2': 240, 'n_units_Layer_3': 270}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.05 | sMAPE for Validation Set is: 7.55% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.26 | sMAPE for Test Set is: 6.75% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:53:05,847]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:53:09,400]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:53:09,584]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:53:16,946]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:53:20,575]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:53:23,346]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:53:24,384]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:53:30,345]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:53:32,807]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:53:39,040]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:53:39,429]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:53:39,673]\u001b[0m Trial 1112 finished with value: 3.4011514371378246 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005599282596308538, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29606537311135117, 'dropout_rate_Layer_2': 0.010622278258172607, 'dropout_rate_Layer_3': 0.017929525361884163, 'dropout_rate_Layer_4': 0.008595334024123089, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.191649923953766e-05, 'l1_Layer_2': 1.0834775090182732e-05, 'l1_Layer_3': 0.0026015373316330957, 'l1_Layer_4': 0.00032849606629276854, 'n_units_Layer_1': 290, 'n_units_Layer_2': 215, 'n_units_Layer_3': 130, 'n_units_Layer_4': 300}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.40 | sMAPE for Validation Set is: 8.19% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 2.74 | sMAPE for Test Set is: 7.78% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:53:44,336]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:53:45,282]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:53:45,465]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:53:52,872]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:53:56,028]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:54:06,724]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:54:11,112]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:54:15,022]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:54:20,671]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:54:54,447]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:55:06,431]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:55:11,161]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:55:14,928]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:55:19,342]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:55:20,438]\u001b[0m Trial 1156 finished with value: 2.732052589142123 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008562950764294541, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2512048913832103, 'dropout_rate_Layer_2': 0.04036493398190589, 'dropout_rate_Layer_3': 0.008127311847659292, 'dropout_rate_Layer_4': 0.03530120880511095, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.356851742332731e-05, 'l1_Layer_2': 2.0771318558763517e-05, 'l1_Layer_3': 0.0020586992622196416, 'l1_Layer_4': 0.0005515046376480542, 'n_units_Layer_1': 250, 'n_units_Layer_2': 230, 'n_units_Layer_3': 245, 'n_units_Layer_4': 80}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.73 | sMAPE for Validation Set is: 6.80% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 2.28 | sMAPE for Test Set is: 6.59% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:55:27,492]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:55:32,852]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:55:36,813]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:55:37,801]\u001b[0m Trial 1139 finished with value: 2.619241596751151 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008649325242752758, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027002145351082904, 'dropout_rate_Layer_2': 0.000724709507122584, 'dropout_rate_Layer_3': 0.011521955221145928, 'dropout_rate_Layer_4': 0.06310541505598065, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.725911864743205e-05, 'l1_Layer_2': 2.6452017281298717e-05, 'l1_Layer_3': 0.007350221356612295, 'l1_Layer_4': 0.0003127552218067362, 'n_units_Layer_1': 255, 'n_units_Layer_2': 230, 'n_units_Layer_3': 135, 'n_units_Layer_4': 80}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.62 | sMAPE for Validation Set is: 6.54% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 2.13 | sMAPE for Test Set is: 6.31% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:55:44,347]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:55:45,006]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:55:52,298]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:55:56,318]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:55:56,902]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:55:57,484]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:03,132]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:03,549]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:09,526]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:18,717]\u001b[0m Trial 1167 finished with value: 2.760089816030399 and parameters: {'n_hidden': 4, 'learning_rate': 0.001004402836440823, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2686727933757213, 'dropout_rate_Layer_2': 0.006860677527844233, 'dropout_rate_Layer_3': 0.03598476418543671, 'dropout_rate_Layer_4': 0.01632483950018959, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.0987515474736604e-05, 'l1_Layer_2': 1.542048094852001e-05, 'l1_Layer_3': 0.0012900403045762452, 'l1_Layer_4': 0.0007306630084769949, 'n_units_Layer_1': 255, 'n_units_Layer_2': 240, 'n_units_Layer_3': 95, 'n_units_Layer_4': 90}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.76 | sMAPE for Validation Set is: 6.84% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 2.10 | sMAPE for Test Set is: 6.26% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:56:21,452]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:23,111]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:24,518]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:26,196]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:30,658]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:34,083]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:36,875]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:37,245]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:40,384]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:44,997]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:48,500]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:51,267]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:52,130]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:52,443]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:56:59,700]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:00,961]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:01,114]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:06,481]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:09,977]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:13,913]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:17,021]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:17,332]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:21,702]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:21,968]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:25,858]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:28,856]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:30,037]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:31,295]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:35,234]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:40,170]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:43,028]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:45,940]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:48,920]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:51,585]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:54,350]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:57,323]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:57:59,662]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:58:02,071]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:58:05,461]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:58:07,922]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:58:08,106]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:58:15,015]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:58:19,729]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:58:44,088]\u001b[0m Trial 1218 finished with value: 2.9762139994338903 and parameters: {'n_hidden': 4, 'learning_rate': 0.000814425227737668, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09025832793038235, 'dropout_rate_Layer_2': 0.13575869137564828, 'dropout_rate_Layer_3': 0.021787306977860726, 'dropout_rate_Layer_4': 0.19865957986155225, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.012027787763255667, 'l1_Layer_2': 0.022487937713658385, 'l1_Layer_3': 1.6032745902792963e-05, 'l1_Layer_4': 0.00023433598639896277, 'n_units_Layer_1': 65, 'n_units_Layer_2': 65, 'n_units_Layer_3': 270, 'n_units_Layer_4': 205}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.98 | sMAPE for Validation Set is: 7.40% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.17 | sMAPE for Test Set is: 6.46% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:58:47,785]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:59:05,912]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:59:09,312]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:59:14,241]\u001b[0m Trial 1211 finished with value: 3.2494346042007933 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006645567209496845, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08974174405872681, 'dropout_rate_Layer_2': 0.18272489548772136, 'dropout_rate_Layer_3': 0.10344375121295568, 'dropout_rate_Layer_4': 0.04310761201281305, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005910401069102722, 'l1_Layer_2': 1.581343784076034e-05, 'l1_Layer_3': 0.018118024443097097, 'l1_Layer_4': 0.03537736293403746, 'n_units_Layer_1': 50, 'n_units_Layer_2': 205, 'n_units_Layer_3': 105, 'n_units_Layer_4': 140}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.25 | sMAPE for Validation Set is: 7.95% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 2.42 | sMAPE for Test Set is: 7.08% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 20:59:14,593]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:59:21,773]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:59:25,876]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:59:29,495]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:59:29,688]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:59:38,085]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:59:38,559]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 20:59:43,740]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:00:22,958]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:00:23,161]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:00:28,468]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:00:28,531]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:00:32,434]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:00:37,858]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:00:41,999]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:00:42,134]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:00:42,575]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:00:46,301]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:00:51,889]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:00:52,877]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:00:53,870]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:00:59,629]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:01:01,769]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:01:03,184]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:01:08,370]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:01:12,007]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:01:18,029]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:01:30,483]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:01:33,525]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:01:36,285]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:01:38,624]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:01:39,540]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:01:45,719]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:01:46,052]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:08,319]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:08,957]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:13,806]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:15,516]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:18,703]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:24,184]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:26,918]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:27,928]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:31,534]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:33,824]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:36,417]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:40,685]\u001b[0m Trial 1253 finished with value: 2.774138838010572 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011999722679632517, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027716717821469516, 'dropout_rate_Layer_2': 0.17951872655628567, 'dropout_rate_Layer_3': 0.017621652307117337, 'dropout_rate_Layer_4': 0.026565718748449, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.3644963789367385e-05, 'l1_Layer_2': 3.343838636101213e-05, 'l1_Layer_3': 0.005698335952793309, 'l1_Layer_4': 0.0003092433171078614, 'n_units_Layer_1': 270, 'n_units_Layer_2': 235, 'n_units_Layer_3': 290, 'n_units_Layer_4': 65}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.77 | sMAPE for Validation Set is: 6.96% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.99 | sMAPE for Test Set is: 6.13% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:02:42,886]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:43,590]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:45,132]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:49,419]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:51,909]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:53,744]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:58,449]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:02:58,703]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:03:00,507]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:03:01,064]\u001b[0m Trial 1256 finished with value: 2.9887389133140814 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010170116163549544, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05194055204104793, 'dropout_rate_Layer_2': 0.1533640682509622, 'dropout_rate_Layer_3': 0.01926880703985145, 'dropout_rate_Layer_4': 0.28873971881505833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.012526558961314068, 'l1_Layer_2': 0.02272340596720377, 'l1_Layer_3': 0.0012251569542642653, 'l1_Layer_4': 0.0003264982596862816, 'n_units_Layer_1': 60, 'n_units_Layer_2': 75, 'n_units_Layer_3': 260, 'n_units_Layer_4': 210}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.99 | sMAPE for Validation Set is: 7.43% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.27 | sMAPE for Test Set is: 6.76% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:03:06,208]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:03:08,873]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:03:11,310]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:03:14,596]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:03:16,155]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:03:16,400]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:03:17,061]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:03:22,605]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:03:26,194]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:03:27,634]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:03:28,792]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:03:32,581]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:03:33,752]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:03:39,963]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:03:54,352]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:03:58,815]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:04:46,555]\u001b[0m Trial 1296 finished with value: 2.7474392013754034 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010181443476108922, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017288324624350614, 'dropout_rate_Layer_2': 0.0005217117045807598, 'dropout_rate_Layer_3': 0.013867328818572876, 'dropout_rate_Layer_4': 0.03953261576146129, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.10584672979443e-05, 'l1_Layer_2': 5.8960156840501156e-05, 'l1_Layer_3': 0.015060073251102878, 'l1_Layer_4': 0.0005707011524234877, 'n_units_Layer_1': 280, 'n_units_Layer_2': 220, 'n_units_Layer_3': 140, 'n_units_Layer_4': 70}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.75 | sMAPE for Validation Set is: 6.85% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 2.05 | sMAPE for Test Set is: 6.18% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:04:53,397]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:04:56,207]\u001b[0m Trial 1292 finished with value: 2.7279271641479084 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009273060836578565, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018432532627672044, 'dropout_rate_Layer_2': 0.0019102726138395352, 'dropout_rate_Layer_3': 0.015902277043948265, 'dropout_rate_Layer_4': 0.04062198123307818, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.4568984855784733e-05, 'l1_Layer_2': 0.00010185443617265246, 'l1_Layer_3': 0.015037163604891718, 'l1_Layer_4': 0.000572946441321448, 'n_units_Layer_1': 295, 'n_units_Layer_2': 220, 'n_units_Layer_3': 200, 'n_units_Layer_4': 70}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.73 | sMAPE for Validation Set is: 6.78% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 2.23 | sMAPE for Test Set is: 6.65% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:06:12,702]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:06:17,965]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:06:22,418]\u001b[0m Trial 1288 finished with value: 2.654074986371693 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013832469751526837, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0187689798263398, 'dropout_rate_Layer_2': 0.19728627766803608, 'dropout_rate_Layer_3': 0.014610574913132376, 'dropout_rate_Layer_4': 0.039246600722647434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.767907981292148e-05, 'l1_Layer_2': 6.214638203368893e-05, 'l1_Layer_3': 0.014525277220784049, 'l1_Layer_4': 0.0006244503364421874, 'n_units_Layer_1': 280, 'n_units_Layer_2': 220, 'n_units_Layer_3': 200, 'n_units_Layer_4': 65}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.65 | sMAPE for Validation Set is: 6.65% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 1.94 | sMAPE for Test Set is: 5.87% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:06:29,799]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:06:34,529]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:06:37,048]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:06:42,349]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:06:44,978]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:06:46,583]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:06:50,108]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:06:51,209]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:06:57,641]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:06:59,291]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:07:03,375]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:07:13,793]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:07:17,593]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:07:20,658]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.76 | sMAPE for Validation Set is: 6.92% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.86% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:07:22,338]\u001b[0m Trial 1301 finished with value: 2.7596299770912864 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008522372479797069, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006773711599640495, 'dropout_rate_Layer_2': 0.020205751722138916, 'dropout_rate_Layer_3': 0.043886581569060105, 'dropout_rate_Layer_4': 0.019155397874983847, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.5184898092946814e-05, 'l1_Layer_2': 0.0003384771384599269, 'l1_Layer_3': 0.024369840888267286, 'l1_Layer_4': 0.0004541787661027208, 'n_units_Layer_1': 300, 'n_units_Layer_2': 230, 'n_units_Layer_3': 205, 'n_units_Layer_4': 60}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:07:25,310]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:07:27,312]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:07:31,052]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:07:35,148]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:07:40,714]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:07:46,827]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:07:56,622]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:08:01,202]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:08:06,988]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:08:09,247]\u001b[0m Trial 1300 finished with value: 2.60258866427331 and parameters: {'n_hidden': 4, 'learning_rate': 0.001032179567915186, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016478749014996665, 'dropout_rate_Layer_2': 0.0016040319337801631, 'dropout_rate_Layer_3': 0.04264076942654622, 'dropout_rate_Layer_4': 0.04097051079109561, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.9969976637128713e-05, 'l1_Layer_2': 5.765873462353646e-05, 'l1_Layer_3': 0.02045724300725039, 'l1_Layer_4': 0.0004434667729242369, 'n_units_Layer_1': 280, 'n_units_Layer_2': 220, 'n_units_Layer_3': 140, 'n_units_Layer_4': 185}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.60 | sMAPE for Validation Set is: 6.46% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 2.06 | sMAPE for Test Set is: 6.09% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:08:11,779]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:08:18,123]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:08:39,372]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:08:43,070]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:08:47,848]\u001b[0m Trial 1329 finished with value: 2.8100247677566847 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014918300654644138, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05960973588065169, 'dropout_rate_Layer_2': 0.1226054201894052, 'dropout_rate_Layer_3': 0.07684404298524611, 'dropout_rate_Layer_4': 0.2997892594053802, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0050263507334523515, 'l1_Layer_2': 0.0292201441161503, 'l1_Layer_3': 1.5107711528764876e-05, 'l1_Layer_4': 0.00021123265504598035, 'n_units_Layer_1': 65, 'n_units_Layer_2': 75, 'n_units_Layer_3': 230, 'n_units_Layer_4': 270}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.81 | sMAPE for Validation Set is: 7.04% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.96 | sMAPE for Test Set is: 6.02% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:08:50,891]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:08:54,957]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:09:01,350]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:09:05,117]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:09:09,219]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:09:09,852]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:09:16,618]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:09:24,996]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:09:29,125]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:09:33,603]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:09:36,724]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:09:39,377]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:09:42,422]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:09:43,754]\u001b[0m Trial 1313 finished with value: 2.794098996121568 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005100688867627155, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007693296118946178, 'dropout_rate_Layer_2': 0.19884192853823038, 'dropout_rate_Layer_3': 0.04039339862994499, 'dropout_rate_Layer_4': 0.019720588375386927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.4917361939033105e-05, 'l1_Layer_2': 6.492153306034609e-05, 'l1_Layer_3': 0.022313714898620947, 'l1_Layer_4': 0.0011994103437683158, 'n_units_Layer_1': 300, 'n_units_Layer_2': 250, 'n_units_Layer_3': 205, 'n_units_Layer_4': 60}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.79 | sMAPE for Validation Set is: 6.97% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 2.05 | sMAPE for Test Set is: 6.23% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:09:43,916]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:09:50,115]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:09:53,617]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:09:54,459]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:09:59,040]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:10:04,054]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:10:10,588]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:10:15,098]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:10:37,121]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:10:45,939]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:10:48,831]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:10:49,554]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:10:54,317]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:02,362]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:03,009]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:03,964]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:11,505]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:11,617]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:12,117]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:21,532]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:24,224]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:24,503]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:30,334]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:30,552]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:36,953]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:37,718]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:43,564]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:46,588]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:46,860]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:52,041]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:52,874]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:56,354]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:11:56,549]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:12:00,096]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:12:08,944]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:12:19,746]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:12:26,357]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:12:29,608]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:12:34,952]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:12:37,507]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:12:40,199]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:12:42,305]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:12:45,549]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:12:46,001]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:12:49,951]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:12:50,741]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:12:56,133]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:12:58,779]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:13:01,567]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:13:04,561]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:13:07,504]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:13:11,719]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:13:14,394]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:13:18,981]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:13:24,332]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:13:24,641]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:13:24,689]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:13:28,816]\u001b[0m Trial 1380 finished with value: 2.7235259323590744 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006660942158804993, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017088732588257216, 'dropout_rate_Layer_2': 0.24059613623318485, 'dropout_rate_Layer_3': 0.06283030106813195, 'dropout_rate_Layer_4': 0.04273949379897947, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.095603486059426e-05, 'l1_Layer_2': 0.0001338200958581888, 'l1_Layer_3': 0.007892554618779383, 'l1_Layer_4': 0.00016351880199855784, 'n_units_Layer_1': 285, 'n_units_Layer_2': 215, 'n_units_Layer_3': 165, 'n_units_Layer_4': 55}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.72 | sMAPE for Validation Set is: 6.88% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 2.01 | sMAPE for Test Set is: 6.10% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:13:29,835]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:13:34,278]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:13:39,145]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:13:41,117]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:13:53,360]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:13:57,572]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:14:04,700]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:14:08,601]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:14:08,722]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:14:20,651]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:14:21,961]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:14:27,496]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:14:29,573]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:14:39,643]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:14:50,951]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:14:54,250]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:14:58,279]\u001b[0m Trial 1418 finished with value: 3.0246608814402887 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007937458088730534, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25488128011130845, 'dropout_rate_Layer_2': 0.1344276430761832, 'dropout_rate_Layer_3': 0.12332647859203423, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004946693225938924, 'l1_Layer_2': 9.403707435850332e-05, 'l1_Layer_3': 0.004441378915538593, 'n_units_Layer_1': 290, 'n_units_Layer_2': 300, 'n_units_Layer_3': 255}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.02 | sMAPE for Validation Set is: 7.55% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.42 | sMAPE for Test Set is: 7.10% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:15:01,784]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:15:02,992]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:15:22,797]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:15:26,228]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:15:46,389]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:15:51,384]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:15:54,478]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:15:56,431]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:16:00,396]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:16:04,783]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:16:05,351]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:16:12,615]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:16:18,811]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:16:22,746]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:16:27,602]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:16:35,617]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:16:45,190]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:16:49,439]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:17:06,353]\u001b[0m Trial 1435 finished with value: 2.7811243561615053 and parameters: {'n_hidden': 4, 'learning_rate': 0.002025443482313217, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019489448763338267, 'dropout_rate_Layer_2': 0.1227894536760188, 'dropout_rate_Layer_3': 0.03809287700015711, 'dropout_rate_Layer_4': 0.30449993643623974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0019760166174326186, 'l1_Layer_2': 0.009058869128121826, 'l1_Layer_3': 0.0009017354446619836, 'l1_Layer_4': 0.00011796334050974979, 'n_units_Layer_1': 75, 'n_units_Layer_2': 105, 'n_units_Layer_3': 255, 'n_units_Layer_4': 260}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.78 | sMAPE for Validation Set is: 6.90% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 2.19 | sMAPE for Test Set is: 6.52% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:17:07,351]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:17:14,595]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:17:14,742]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:17:19,911]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:17:21,499]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:17:25,602]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:17:25,822]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:17:26,969]\u001b[0m Trial 1425 finished with value: 2.7288497037061767 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007025745411268576, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05716738063076279, 'dropout_rate_Layer_2': 0.23975783474128862, 'dropout_rate_Layer_3': 0.06273955040480268, 'dropout_rate_Layer_4': 0.031399039144260996, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.892722956948758e-05, 'l1_Layer_2': 0.00013581884069327916, 'l1_Layer_3': 0.010170287488006285, 'l1_Layer_4': 0.00017490574186217477, 'n_units_Layer_1': 275, 'n_units_Layer_2': 215, 'n_units_Layer_3': 140, 'n_units_Layer_4': 55}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.73 | sMAPE for Validation Set is: 6.79% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 2.09 | sMAPE for Test Set is: 6.24% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:17:30,971]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:17:35,823]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:17:35,932]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:17:36,164]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:17:42,320]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:17:46,374]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:17:49,599]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:17:55,222]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:17:57,711]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:18:02,831]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:18:03,929]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:18:07,418]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:18:11,604]\u001b[0m Trial 1414 finished with value: 2.7258278794084405 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006868125466522729, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.051689670210249665, 'dropout_rate_Layer_2': 0.24197889732516267, 'dropout_rate_Layer_3': 0.05966251093307993, 'dropout_rate_Layer_4': 0.033661559268166066, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006319206308472812, 'l1_Layer_2': 0.00013712167241737607, 'l1_Layer_3': 0.010250280771063457, 'l1_Layer_4': 0.0001912327694825902, 'n_units_Layer_1': 275, 'n_units_Layer_2': 220, 'n_units_Layer_3': 135, 'n_units_Layer_4': 50}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.73 | sMAPE for Validation Set is: 6.79% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 2.00 | sMAPE for Test Set is: 6.00% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:18:12,297]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:18:14,307]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:18:15,635]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:18:22,123]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:18:25,259]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:18:29,729]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:18:33,896]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:18:36,612]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:18:37,738]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:18:43,531]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:18:45,636]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:18:49,477]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:18:54,455]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:18:57,772]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:19:01,981]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:19:05,681]\u001b[0m Trial 1465 finished with value: 3.0296719121666604 and parameters: {'n_hidden': 3, 'learning_rate': 0.00149291008156864, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19332779030421243, 'dropout_rate_Layer_2': 0.014265289504519916, 'dropout_rate_Layer_3': 0.37166975180771816, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.802102183323691e-05, 'l1_Layer_2': 5.431878063445044e-05, 'l1_Layer_3': 0.010048477408848427, 'n_units_Layer_1': 215, 'n_units_Layer_2': 290, 'n_units_Layer_3': 295}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.03 | sMAPE for Validation Set is: 7.49% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.42 | sMAPE for Test Set is: 7.06% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:19:16,642]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:19:19,504]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:19:36,954]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:19:50,778]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:19:57,094]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:20:05,188]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:20:10,483]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:20:18,168]\u001b[0m Trial 1482 finished with value: 2.808706610162831 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026324644571381305, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006858908992876743, 'dropout_rate_Layer_2': 0.11778718906570522, 'dropout_rate_Layer_3': 0.12447207934334885, 'dropout_rate_Layer_4': 0.277200077321633, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0037682883511041504, 'l1_Layer_2': 0.005463187259042442, 'l1_Layer_3': 1.0112689373207914e-05, 'l1_Layer_4': 0.00012897804167075186, 'n_units_Layer_1': 70, 'n_units_Layer_2': 80, 'n_units_Layer_3': 255, 'n_units_Layer_4': 240}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.81 | sMAPE for Validation Set is: 6.93% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 2.54 | sMAPE for Test Set is: 7.18% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:20:40,897]\u001b[0m Trial 1481 finished with value: 3.156126891425646 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007945531917033223, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08272418210896955, 'dropout_rate_Layer_2': 0.15099916602208463, 'dropout_rate_Layer_3': 0.11072922282573468, 'dropout_rate_Layer_4': 0.09611833563906835, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004253805109964994, 'l1_Layer_2': 0.02663490895567462, 'l1_Layer_3': 0.01837884404068208, 'l1_Layer_4': 0.0020209879428550927, 'n_units_Layer_1': 85, 'n_units_Layer_2': 125, 'n_units_Layer_3': 130, 'n_units_Layer_4': 135}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.16 | sMAPE for Validation Set is: 7.79% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.31 | sMAPE for Test Set is: 6.85% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:20:44,737]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:20:51,203]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:20:57,549]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:21:02,011]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:21:35,014]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:21:41,067]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:21:44,632]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:21:49,890]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:21:54,970]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:21:59,564]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:22:04,034]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:22:07,697]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:22:11,908]\u001b[0m Trial 1487 finished with value: 2.709391673965383 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006500426173219795, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015256379642989941, 'dropout_rate_Layer_2': 0.21409703513387338, 'dropout_rate_Layer_3': 0.03202111187926468, 'dropout_rate_Layer_4': 0.0661048484824276, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.438375018070918e-05, 'l1_Layer_2': 0.00012462409307129377, 'l1_Layer_3': 0.011817666887119415, 'l1_Layer_4': 5.34770535980537e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 205, 'n_units_Layer_3': 195, 'n_units_Layer_4': 60}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.71 | sMAPE for Validation Set is: 6.77% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 2.09 | sMAPE for Test Set is: 6.32% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 21:22:21,218]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 21:22:21,544]\u001b[0m Trial 1492 finished with value: 3.047727228631743 and parameters: {'n_hidden': 4, 'learning_rate': 0.000572658358048095, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07625473367998095, 'dropout_rate_Layer_2': 0.1517095508521837, 'dropout_rate_Layer_3': 0.1203521968985394, 'dropout_rate_Layer_4': 0.10861581852078338, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004008814270396706, 'l1_Layer_2': 0.017919225477690426, 'l1_Layer_3': 0.010949288108065582, 'l1_Layer_4': 0.0016446018798880737, 'n_units_Layer_1': 90, 'n_units_Layer_2': 125, 'n_units_Layer_3': 135, 'n_units_Layer_4': 135}. Best is trial 1086 with value: 2.5921985426517393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.05 | sMAPE for Validation Set is: 7.52% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.29 | sMAPE for Test Set is: 6.80% | rMAE for Test Set is: 0.66\n",
      "for 2019-01-01, MAE is:0.91 & sMAPE is:1.96% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :0.91 & 1.96% & 1.10\n",
      "for 2019-01-02, MAE is:3.26 & sMAPE is:6.63% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 4.30% & 1.35\n",
      "for 2019-01-03, MAE is:1.42 & sMAPE is:2.68% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :1.86 & 3.76% & 1.26\n",
      "for 2019-01-04, MAE is:1.03 & sMAPE is:2.05% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :1.66 & 3.33% & 1.16\n",
      "for 2019-01-05, MAE is:1.86 & sMAPE is:3.64% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :1.70 & 3.39% & 1.11\n",
      "for 2019-01-06, MAE is:1.69 & sMAPE is:3.40% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :1.70 & 3.40% & 1.14\n",
      "for 2019-01-07, MAE is:1.92 & sMAPE is:3.76% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :1.73 & 3.45% & 1.07\n",
      "for 2019-01-08, MAE is:0.92 & sMAPE is:1.83% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :1.63 & 3.25% & 0.98\n",
      "for 2019-01-09, MAE is:2.28 & sMAPE is:4.59% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :1.70 & 3.40% & 1.08\n",
      "for 2019-01-10, MAE is:2.20 & sMAPE is:4.41% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :1.75 & 3.50% & 1.07\n",
      "for 2019-01-11, MAE is:1.64 & sMAPE is:3.33% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :1.74 & 3.48% & 1.03\n",
      "for 2019-01-12, MAE is:2.81 & sMAPE is:5.89% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :1.83 & 3.68% & 1.07\n",
      "for 2019-01-13, MAE is:1.73 & sMAPE is:3.66% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :1.82 & 3.68% & 1.04\n",
      "for 2019-01-14, MAE is:0.91 & sMAPE is:1.86% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :1.76 & 3.55% & 1.00\n",
      "for 2019-01-15, MAE is:4.63 & sMAPE is:9.25% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :1.95 & 3.93% & 1.06\n",
      "for 2019-01-16, MAE is:3.15 & sMAPE is:6.18% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :2.02 & 4.07% & 1.05\n",
      "for 2019-01-17, MAE is:3.82 & sMAPE is:7.45% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 4.27% & 1.06\n",
      "for 2019-01-18, MAE is:1.89 & sMAPE is:3.57% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 4.23% & 1.02\n",
      "for 2019-01-19, MAE is:2.12 & sMAPE is:3.84% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 4.21% & 0.98\n",
      "for 2019-01-20, MAE is:2.45 & sMAPE is:4.46% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 4.22% & 0.95\n",
      "for 2019-01-21, MAE is:2.22 & sMAPE is:3.90% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 4.21% & 0.92\n",
      "for 2019-01-22, MAE is:1.64 & sMAPE is:2.87% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 4.15% & 0.90\n",
      "for 2019-01-23, MAE is:1.91 & sMAPE is:3.52% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 4.12% & 0.88\n",
      "for 2019-01-24, MAE is:3.38 & sMAPE is:6.20% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :2.16 & 4.21% & 0.89\n",
      "for 2019-01-25, MAE is:3.06 & sMAPE is:5.47% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.19 & 4.26% & 0.92\n",
      "for 2019-01-26, MAE is:1.76 & sMAPE is:3.25% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 4.22% & 0.92\n",
      "for 2019-01-27, MAE is:0.99 & sMAPE is:1.89% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 4.13% & 0.90\n",
      "for 2019-01-28, MAE is:1.80 & sMAPE is:3.35% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 4.10% & 0.89\n",
      "for 2019-01-29, MAE is:2.27 & sMAPE is:4.09% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 4.10% & 0.91\n",
      "for 2019-01-30, MAE is:2.96 & sMAPE is:5.43% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.16 & 4.15% & 0.92\n",
      "for 2019-01-31, MAE is:5.36 & sMAPE is:9.55% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 4.32% & 0.93\n",
      "for 2019-02-01, MAE is:1.20 & sMAPE is:2.22% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 4.26% & 0.92\n",
      "for 2019-02-02, MAE is:0.77 & sMAPE is:1.51% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 4.17% & 0.90\n",
      "for 2019-02-03, MAE is:1.31 & sMAPE is:2.57% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.16 & 4.13% & 0.89\n",
      "for 2019-02-04, MAE is:2.95 & sMAPE is:5.65% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 4.17% & 0.90\n",
      "for 2019-02-05, MAE is:1.63 & sMAPE is:3.12% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.16 & 4.14% & 0.89\n",
      "for 2019-02-06, MAE is:2.01 & sMAPE is:3.92% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :2.16 & 4.13% & 0.88\n",
      "for 2019-02-07, MAE is:2.83 & sMAPE is:5.49% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 4.17% & 0.87\n",
      "for 2019-02-08, MAE is:1.51 & sMAPE is:3.14% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :2.16 & 4.14% & 0.86\n",
      "for 2019-02-09, MAE is:1.60 & sMAPE is:3.50% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.15 & 4.13% & 0.84\n",
      "for 2019-02-10, MAE is:1.16 & sMAPE is:2.48% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 4.09% & 0.83\n",
      "for 2019-02-11, MAE is:1.32 & sMAPE is:2.84% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 4.06% & 0.82\n",
      "for 2019-02-12, MAE is:3.02 & sMAPE is:6.66% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 4.12% & 0.81\n",
      "for 2019-02-13, MAE is:1.26 & sMAPE is:2.81% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 4.09% & 0.79\n",
      "for 2019-02-14, MAE is:2.20 & sMAPE is:4.89% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 4.11% & 0.78\n",
      "for 2019-02-15, MAE is:1.34 & sMAPE is:3.06% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.08% & 0.77\n",
      "for 2019-02-16, MAE is:1.93 & sMAPE is:4.83% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.10% & 0.76\n",
      "for 2019-02-17, MAE is:2.49 & sMAPE is:6.00% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.14% & 0.76\n",
      "for 2019-02-18, MAE is:1.38 & sMAPE is:3.21% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 4.12% & 0.75\n",
      "for 2019-02-19, MAE is:1.85 & sMAPE is:4.49% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 4.13% & 0.75\n",
      "for 2019-02-20, MAE is:3.01 & sMAPE is:7.21% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.19% & 0.77\n",
      "for 2019-02-21, MAE is:1.91 & sMAPE is:4.49% & rMAE is:3.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.19% & 0.81\n",
      "for 2019-02-22, MAE is:1.07 & sMAPE is:2.52% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 4.16% & 0.82\n",
      "for 2019-02-23, MAE is:1.27 & sMAPE is:3.24% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :2.06 & 4.14% & 0.83\n",
      "for 2019-02-24, MAE is:1.32 & sMAPE is:3.45% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.04 & 4.13% & 0.83\n",
      "for 2019-02-25, MAE is:1.19 & sMAPE is:2.98% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.03 & 4.11% & 0.82\n",
      "for 2019-02-26, MAE is:1.74 & sMAPE is:4.27% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :2.02 & 4.11% & 0.82\n",
      "for 2019-02-27, MAE is:1.01 & sMAPE is:2.54% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.01 & 4.09% & 0.81\n",
      "for 2019-02-28, MAE is:3.04 & sMAPE is:7.89% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :2.02 & 4.15% & 0.81\n",
      "for 2019-03-01, MAE is:3.01 & sMAPE is:7.39% & rMAE is:2.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.04 & 4.21% & 0.84\n",
      "for 2019-03-02, MAE is:1.90 & sMAPE is:4.55% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :2.04 & 4.21% & 0.85\n",
      "for 2019-03-03, MAE is:1.34 & sMAPE is:3.35% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :2.03 & 4.20% & 0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-03-04, MAE is:1.84 & sMAPE is:4.62% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.02 & 4.20% & 0.85\n",
      "for 2019-03-05, MAE is:4.71 & sMAPE is:10.96% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.06 & 4.31% & 0.86\n",
      "for 2019-03-06, MAE is:2.12 & sMAPE is:4.80% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 4.32% & 0.85\n",
      "for 2019-03-07, MAE is:1.80 & sMAPE is:4.11% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.06 & 4.31% & 0.85\n",
      "for 2019-03-08, MAE is:1.17 & sMAPE is:2.81% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :2.05 & 4.29% & 0.85\n",
      "for 2019-03-09, MAE is:1.15 & sMAPE is:2.71% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.03 & 4.27% & 0.84\n",
      "for 2019-03-10, MAE is:0.94 & sMAPE is:2.21% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.02 & 4.24% & 0.84\n",
      "for 2019-03-11, MAE is:2.26 & sMAPE is:5.07% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :2.02 & 4.25% & 0.83\n",
      "for 2019-03-12, MAE is:1.95 & sMAPE is:4.33% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.02 & 4.25% & 0.83\n",
      "for 2019-03-13, MAE is:0.98 & sMAPE is:2.27% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.01 & 4.22% & 0.82\n",
      "for 2019-03-14, MAE is:0.82 & sMAPE is:1.99% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :1.99 & 4.19% & 0.82\n",
      "for 2019-03-15, MAE is:1.00 & sMAPE is:2.38% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :1.98 & 4.17% & 0.82\n",
      "for 2019-03-16, MAE is:1.14 & sMAPE is:2.75% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :1.97 & 4.15% & 0.82\n",
      "for 2019-03-17, MAE is:0.94 & sMAPE is:2.34% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :1.95 & 4.13% & 0.81\n",
      "for 2019-03-18, MAE is:2.66 & sMAPE is:6.49% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :1.96 & 4.16% & 0.81\n",
      "for 2019-03-19, MAE is:4.46 & sMAPE is:9.75% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :1.99 & 4.23% & 0.82\n",
      "for 2019-03-20, MAE is:2.05 & sMAPE is:4.90% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :1.99 & 4.24% & 0.83\n",
      "for 2019-03-21, MAE is:1.57 & sMAPE is:4.00% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :1.99 & 4.23% & 0.82\n",
      "for 2019-03-22, MAE is:2.00 & sMAPE is:4.94% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :1.99 & 4.24% & 0.82\n",
      "for 2019-03-23, MAE is:0.71 & sMAPE is:1.94% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :1.97 & 4.21% & 0.81\n",
      "for 2019-03-24, MAE is:1.54 & sMAPE is:4.25% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :1.97 & 4.21% & 0.81\n",
      "for 2019-03-25, MAE is:1.36 & sMAPE is:3.52% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :1.96 & 4.21% & 0.81\n",
      "for 2019-03-26, MAE is:1.97 & sMAPE is:4.79% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :1.96 & 4.21% & 0.80\n",
      "for 2019-03-27, MAE is:1.29 & sMAPE is:3.18% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :1.95 & 4.20% & 0.80\n",
      "for 2019-03-28, MAE is:1.27 & sMAPE is:3.45% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :1.95 & 4.19% & 0.80\n",
      "for 2019-03-29, MAE is:1.40 & sMAPE is:3.83% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :1.94 & 4.19% & 0.79\n",
      "for 2019-03-30, MAE is:1.56 & sMAPE is:4.50% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :1.94 & 4.19% & 0.80\n",
      "for 2019-03-31, MAE is:1.26 & sMAPE is:3.60% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :1.93 & 4.19% & 0.80\n",
      "for 2019-04-01, MAE is:1.75 & sMAPE is:4.50% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :1.93 & 4.19% & 0.80\n",
      "for 2019-04-02, MAE is:1.63 & sMAPE is:4.40% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :1.92 & 4.19% & 0.80\n",
      "for 2019-04-03, MAE is:3.88 & sMAPE is:9.76% & rMAE is:2.77 ||| daily mean of MAE & sMAPE & rMAE till now are :1.94 & 4.25% & 0.82\n",
      "for 2019-04-04, MAE is:3.89 & sMAPE is:10.00% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :1.96 & 4.31% & 0.83\n",
      "for 2019-04-05, MAE is:4.17 & sMAPE is:10.98% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :1.99 & 4.38% & 0.83\n",
      "for 2019-04-06, MAE is:2.02 & sMAPE is:5.32% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :1.99 & 4.39% & 0.83\n",
      "for 2019-04-07, MAE is:1.85 & sMAPE is:4.85% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :1.99 & 4.40% & 0.82\n",
      "for 2019-04-08, MAE is:1.56 & sMAPE is:3.82% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :1.98 & 4.39% & 0.82\n",
      "for 2019-04-09, MAE is:4.13 & sMAPE is:10.01% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.00 & 4.45% & 0.82\n",
      "for 2019-04-10, MAE is:5.13 & sMAPE is:12.04% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.04 & 4.52% & 0.83\n",
      "for 2019-04-11, MAE is:6.18 & sMAPE is:13.42% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 4.61% & 0.83\n",
      "for 2019-04-12, MAE is:3.65 & sMAPE is:7.81% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.64% & 0.82\n",
      "for 2019-04-13, MAE is:2.12 & sMAPE is:4.95% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.65% & 0.82\n",
      "for 2019-04-14, MAE is:0.84 & sMAPE is:1.97% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 4.62% & 0.81\n",
      "for 2019-04-15, MAE is:2.41 & sMAPE is:5.20% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 4.63% & 0.81\n",
      "for 2019-04-16, MAE is:2.17 & sMAPE is:4.85% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 4.63% & 0.81\n",
      "for 2019-04-17, MAE is:1.23 & sMAPE is:2.83% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 4.61% & 0.81\n",
      "for 2019-04-18, MAE is:1.90 & sMAPE is:4.43% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 4.61% & 0.81\n",
      "for 2019-04-19, MAE is:1.17 & sMAPE is:2.78% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 4.59% & 0.81\n",
      "for 2019-04-20, MAE is:0.99 & sMAPE is:2.39% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.06 & 4.57% & 0.80\n",
      "for 2019-04-21, MAE is:1.20 & sMAPE is:2.94% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :2.05 & 4.56% & 0.80\n",
      "for 2019-04-22, MAE is:2.26 & sMAPE is:5.46% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.05 & 4.57% & 0.80\n",
      "for 2019-04-23, MAE is:1.54 & sMAPE is:3.71% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.05 & 4.56% & 0.79\n",
      "for 2019-04-24, MAE is:1.92 & sMAPE is:4.89% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.04 & 4.56% & 0.79\n",
      "for 2019-04-25, MAE is:2.70 & sMAPE is:6.74% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :2.05 & 4.58% & 0.79\n",
      "for 2019-04-26, MAE is:1.87 & sMAPE is:4.61% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :2.05 & 4.58% & 0.79\n",
      "for 2019-04-27, MAE is:3.67 & sMAPE is:10.61% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.06 & 4.63% & 0.79\n",
      "for 2019-04-28, MAE is:2.54 & sMAPE is:7.26% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 4.65% & 0.79\n",
      "for 2019-04-29, MAE is:2.68 & sMAPE is:7.15% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 4.68% & 0.79\n",
      "for 2019-04-30, MAE is:3.22 & sMAPE is:8.28% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 4.71% & 0.80\n",
      "for 2019-05-01, MAE is:1.50 & sMAPE is:4.25% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 4.70% & 0.80\n",
      "for 2019-05-02, MAE is:2.03 & sMAPE is:5.68% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 4.71% & 0.80\n",
      "for 2019-05-03, MAE is:1.58 & sMAPE is:4.12% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 4.70% & 0.80\n",
      "for 2019-05-04, MAE is:3.27 & sMAPE is:8.36% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 4.73% & 0.79\n",
      "for 2019-05-05, MAE is:0.85 & sMAPE is:2.13% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 4.71% & 0.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-05-06, MAE is:3.32 & sMAPE is:7.90% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 4.74% & 0.79\n",
      "for 2019-05-07, MAE is:2.73 & sMAPE is:6.37% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.75% & 0.79\n",
      "for 2019-05-08, MAE is:1.54 & sMAPE is:3.61% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 4.74% & 0.78\n",
      "for 2019-05-09, MAE is:2.51 & sMAPE is:6.09% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.75% & 0.78\n",
      "for 2019-05-10, MAE is:2.27 & sMAPE is:5.41% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.76% & 0.78\n",
      "for 2019-05-11, MAE is:1.48 & sMAPE is:3.68% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 4.75% & 0.79\n",
      "for 2019-05-12, MAE is:0.46 & sMAPE is:1.22% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 4.72% & 0.78\n",
      "for 2019-05-13, MAE is:1.80 & sMAPE is:4.63% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 4.72% & 0.78\n",
      "for 2019-05-14, MAE is:2.27 & sMAPE is:5.48% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 4.73% & 0.79\n",
      "for 2019-05-15, MAE is:2.36 & sMAPE is:5.56% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 4.73% & 0.79\n",
      "for 2019-05-16, MAE is:1.17 & sMAPE is:2.93% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 4.72% & 0.79\n",
      "for 2019-05-17, MAE is:2.94 & sMAPE is:8.55% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 4.75% & 0.79\n",
      "for 2019-05-18, MAE is:2.20 & sMAPE is:7.40% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 4.77% & 0.79\n",
      "for 2019-05-19, MAE is:4.40 & sMAPE is:12.89% & rMAE is:2.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.83% & 0.80\n",
      "for 2019-05-20, MAE is:2.53 & sMAPE is:6.57% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.84% & 0.81\n",
      "for 2019-05-21, MAE is:2.27 & sMAPE is:5.89% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.85% & 0.81\n",
      "for 2019-05-22, MAE is:2.80 & sMAPE is:7.65% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 4.87% & 0.81\n",
      "for 2019-05-23, MAE is:1.75 & sMAPE is:4.77% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 4.87% & 0.81\n",
      "for 2019-05-24, MAE is:1.25 & sMAPE is:3.35% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.86% & 0.80\n",
      "for 2019-05-25, MAE is:1.73 & sMAPE is:4.86% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.86% & 0.80\n",
      "for 2019-05-26, MAE is:3.90 & sMAPE is:13.90% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 4.92% & 0.80\n",
      "for 2019-05-27, MAE is:2.53 & sMAPE is:7.39% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 4.93% & 0.80\n",
      "for 2019-05-28, MAE is:1.09 & sMAPE is:2.97% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 4.92% & 0.80\n",
      "for 2019-05-29, MAE is:2.87 & sMAPE is:7.89% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 4.94% & 0.81\n",
      "for 2019-05-30, MAE is:0.98 & sMAPE is:2.91% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.93% & 0.80\n",
      "for 2019-05-31, MAE is:1.63 & sMAPE is:4.88% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.93% & 0.80\n",
      "for 2019-06-01, MAE is:1.69 & sMAPE is:5.44% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.93% & 0.80\n",
      "for 2019-06-02, MAE is:1.27 & sMAPE is:3.90% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 4.92% & 0.79\n",
      "for 2019-06-03, MAE is:2.73 & sMAPE is:9.53% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 4.95% & 0.79\n",
      "for 2019-06-04, MAE is:5.05 & sMAPE is:19.65% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 5.05% & 0.79\n",
      "for 2019-06-05, MAE is:4.06 & sMAPE is:15.70% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.12% & 0.79\n",
      "for 2019-06-06, MAE is:5.85 & sMAPE is:28.10% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 5.26% & 0.79\n",
      "for 2019-06-07, MAE is:11.81 & sMAPE is:58.42% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.20 & 5.60% & 0.79\n",
      "for 2019-06-08, MAE is:10.42 & sMAPE is:78.70% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 6.06% & 0.79\n",
      "for 2019-06-09, MAE is:4.01 & sMAPE is:48.65% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :2.27 & 6.33% & 0.78\n",
      "for 2019-06-10, MAE is:7.55 & sMAPE is:56.96% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :2.30 & 6.64% & 0.78\n",
      "for 2019-06-11, MAE is:7.40 & sMAPE is:40.99% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :2.33 & 6.85% & 0.79\n",
      "for 2019-06-12, MAE is:10.73 & sMAPE is:44.93% & rMAE is:3.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.38 & 7.09% & 0.80\n",
      "for 2019-06-13, MAE is:7.40 & sMAPE is:29.88% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 7.22% & 0.80\n",
      "for 2019-06-14, MAE is:3.16 & sMAPE is:11.18% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 7.25% & 0.80\n",
      "for 2019-06-15, MAE is:4.27 & sMAPE is:17.25% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 7.31% & 0.80\n",
      "for 2019-06-16, MAE is:8.99 & sMAPE is:44.72% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 7.53% & 0.80\n",
      "for 2019-06-17, MAE is:4.49 & sMAPE is:17.30% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 7.59% & 0.80\n",
      "for 2019-06-18, MAE is:5.81 & sMAPE is:22.04% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 7.68% & 0.80\n",
      "for 2019-06-19, MAE is:7.01 & sMAPE is:25.33% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.78% & 0.80\n",
      "for 2019-06-20, MAE is:2.40 & sMAPE is:9.20% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.79% & 0.80\n",
      "for 2019-06-21, MAE is:3.78 & sMAPE is:14.79% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.83% & 0.80\n",
      "for 2019-06-22, MAE is:1.17 & sMAPE is:5.38% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.81% & 0.80\n",
      "for 2019-06-23, MAE is:3.43 & sMAPE is:15.00% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.86% & 0.81\n",
      "for 2019-06-24, MAE is:2.48 & sMAPE is:8.52% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.86% & 0.80\n",
      "for 2019-06-25, MAE is:2.38 & sMAPE is:7.67% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.86% & 0.80\n",
      "for 2019-06-26, MAE is:2.34 & sMAPE is:7.69% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.86% & 0.80\n",
      "for 2019-06-27, MAE is:3.62 & sMAPE is:13.02% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.89% & 0.81\n",
      "for 2019-06-28, MAE is:1.40 & sMAPE is:5.22% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.87% & 0.81\n",
      "for 2019-06-29, MAE is:2.71 & sMAPE is:11.89% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.89% & 0.81\n",
      "for 2019-06-30, MAE is:1.81 & sMAPE is:8.60% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.90% & 0.81\n",
      "for 2019-07-01, MAE is:4.64 & sMAPE is:18.87% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 7.96% & 0.81\n",
      "for 2019-07-02, MAE is:3.13 & sMAPE is:12.70% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 7.98% & 0.81\n",
      "for 2019-07-03, MAE is:1.24 & sMAPE is:4.92% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.97% & 0.81\n",
      "for 2019-07-04, MAE is:4.09 & sMAPE is:15.75% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 8.01% & 0.81\n",
      "for 2019-07-05, MAE is:2.72 & sMAPE is:10.07% & rMAE is:2.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 8.02% & 0.82\n",
      "for 2019-07-06, MAE is:1.39 & sMAPE is:4.99% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 8.00% & 0.82\n",
      "for 2019-07-07, MAE is:1.29 & sMAPE is:4.65% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.99% & 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-07-08, MAE is:2.24 & sMAPE is:7.95% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.99% & 0.82\n",
      "for 2019-07-09, MAE is:1.79 & sMAPE is:6.02% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.98% & 0.81\n",
      "for 2019-07-10, MAE is:4.40 & sMAPE is:14.23% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 8.01% & 0.81\n",
      "for 2019-07-11, MAE is:2.89 & sMAPE is:8.77% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 8.01% & 0.81\n",
      "for 2019-07-12, MAE is:3.41 & sMAPE is:10.12% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 8.02% & 0.81\n",
      "for 2019-07-13, MAE is:3.71 & sMAPE is:10.79% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 8.04% & 0.81\n",
      "for 2019-07-14, MAE is:1.21 & sMAPE is:3.35% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 8.01% & 0.80\n",
      "for 2019-07-15, MAE is:2.73 & sMAPE is:7.48% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 8.01% & 0.80\n",
      "for 2019-07-16, MAE is:1.40 & sMAPE is:3.88% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.99% & 0.80\n",
      "for 2019-07-17, MAE is:1.63 & sMAPE is:4.66% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.97% & 0.80\n",
      "for 2019-07-18, MAE is:2.35 & sMAPE is:6.65% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.97% & 0.80\n",
      "for 2019-07-19, MAE is:2.60 & sMAPE is:7.10% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 7.96% & 0.80\n",
      "for 2019-07-20, MAE is:1.06 & sMAPE is:2.90% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.94% & 0.80\n",
      "for 2019-07-21, MAE is:1.41 & sMAPE is:4.00% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.92% & 0.80\n",
      "for 2019-07-22, MAE is:1.84 & sMAPE is:5.13% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.90% & 0.81\n",
      "for 2019-07-23, MAE is:1.63 & sMAPE is:4.47% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.89% & 0.81\n",
      "for 2019-07-24, MAE is:3.58 & sMAPE is:9.74% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.90% & 0.82\n",
      "for 2019-07-25, MAE is:2.97 & sMAPE is:7.87% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.90% & 0.82\n",
      "for 2019-07-26, MAE is:2.38 & sMAPE is:6.30% & rMAE is:2.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.89% & 0.82\n",
      "for 2019-07-27, MAE is:0.95 & sMAPE is:2.59% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.86% & 0.82\n",
      "for 2019-07-28, MAE is:3.64 & sMAPE is:10.57% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.88% & 0.83\n",
      "for 2019-07-29, MAE is:3.21 & sMAPE is:8.59% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.88% & 0.83\n",
      "for 2019-07-30, MAE is:2.17 & sMAPE is:5.66% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.87% & 0.83\n",
      "for 2019-07-31, MAE is:2.67 & sMAPE is:6.90% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.86% & 0.84\n",
      "for 2019-08-01, MAE is:1.18 & sMAPE is:3.03% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.84% & 0.84\n",
      "for 2019-08-02, MAE is:1.71 & sMAPE is:4.39% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.83% & 0.84\n",
      "for 2019-08-03, MAE is:1.15 & sMAPE is:2.99% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 7.80% & 0.84\n",
      "for 2019-08-04, MAE is:1.91 & sMAPE is:5.01% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 7.79% & 0.84\n",
      "for 2019-08-05, MAE is:1.87 & sMAPE is:4.81% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.78% & 0.85\n",
      "for 2019-08-06, MAE is:1.56 & sMAPE is:3.99% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.76% & 0.85\n",
      "for 2019-08-07, MAE is:1.66 & sMAPE is:4.27% & rMAE is:2.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.74% & 0.86\n",
      "for 2019-08-08, MAE is:1.35 & sMAPE is:3.60% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 7.72% & 0.86\n",
      "for 2019-08-09, MAE is:1.57 & sMAPE is:4.20% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 7.71% & 0.86\n",
      "for 2019-08-10, MAE is:0.90 & sMAPE is:2.66% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 7.69% & 0.86\n",
      "for 2019-08-11, MAE is:3.76 & sMAPE is:14.54% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 7.72% & 0.86\n",
      "for 2019-08-12, MAE is:3.13 & sMAPE is:9.02% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 7.72% & 0.86\n",
      "for 2019-08-13, MAE is:1.82 & sMAPE is:5.05% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 7.71% & 0.85\n",
      "for 2019-08-14, MAE is:1.80 & sMAPE is:5.27% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 7.70% & 0.85\n",
      "for 2019-08-15, MAE is:1.45 & sMAPE is:4.30% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 7.68% & 0.85\n",
      "for 2019-08-16, MAE is:1.96 & sMAPE is:5.70% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 7.68% & 0.85\n",
      "for 2019-08-17, MAE is:1.76 & sMAPE is:5.77% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 7.67% & 0.85\n",
      "for 2019-08-18, MAE is:2.81 & sMAPE is:8.69% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 7.67% & 0.85\n",
      "for 2019-08-19, MAE is:1.55 & sMAPE is:4.54% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 7.66% & 0.85\n",
      "for 2019-08-20, MAE is:3.56 & sMAPE is:10.38% & rMAE is:3.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 7.67% & 0.86\n",
      "for 2019-08-21, MAE is:2.40 & sMAPE is:6.80% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 7.67% & 0.86\n",
      "for 2019-08-22, MAE is:1.71 & sMAPE is:4.82% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 7.65% & 0.86\n",
      "for 2019-08-23, MAE is:1.96 & sMAPE is:5.69% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 7.65% & 0.87\n",
      "for 2019-08-24, MAE is:1.54 & sMAPE is:4.46% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 7.63% & 0.86\n",
      "for 2019-08-25, MAE is:1.69 & sMAPE is:5.04% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 7.62% & 0.87\n",
      "for 2019-08-26, MAE is:4.08 & sMAPE is:11.24% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 7.64% & 0.87\n",
      "for 2019-08-27, MAE is:3.90 & sMAPE is:9.90% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 7.65% & 0.87\n",
      "for 2019-08-28, MAE is:7.63 & sMAPE is:17.68% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.69% & 0.87\n",
      "for 2019-08-29, MAE is:4.11 & sMAPE is:11.22% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.70% & 0.88\n",
      "for 2019-08-30, MAE is:1.31 & sMAPE is:3.74% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.69% & 0.88\n",
      "for 2019-08-31, MAE is:1.16 & sMAPE is:3.40% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 7.67% & 0.88\n",
      "for 2019-09-01, MAE is:2.03 & sMAPE is:6.55% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 7.66% & 0.88\n",
      "for 2019-09-02, MAE is:4.27 & sMAPE is:12.21% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.68% & 0.89\n",
      "for 2019-09-03, MAE is:3.35 & sMAPE is:9.53% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.69% & 0.89\n",
      "for 2019-09-04, MAE is:2.98 & sMAPE is:7.96% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.69% & 0.89\n",
      "for 2019-09-05, MAE is:1.70 & sMAPE is:5.00% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.68% & 0.88\n",
      "for 2019-09-06, MAE is:2.49 & sMAPE is:7.73% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.68% & 0.88\n",
      "for 2019-09-07, MAE is:2.30 & sMAPE is:6.81% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.68% & 0.89\n",
      "for 2019-09-08, MAE is:2.19 & sMAPE is:6.50% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.67% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-09-09, MAE is:3.40 & sMAPE is:9.60% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.68% & 0.89\n",
      "for 2019-09-10, MAE is:1.28 & sMAPE is:3.63% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.66% & 0.89\n",
      "for 2019-09-11, MAE is:2.17 & sMAPE is:6.40% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.66% & 0.89\n",
      "for 2019-09-12, MAE is:2.20 & sMAPE is:6.91% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.66% & 0.89\n",
      "for 2019-09-13, MAE is:1.79 & sMAPE is:5.63% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 7.65% & 0.89\n",
      "for 2019-09-14, MAE is:1.97 & sMAPE is:6.34% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 7.64% & 0.89\n",
      "for 2019-09-15, MAE is:5.25 & sMAPE is:21.80% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 7.70% & 0.89\n",
      "for 2019-09-16, MAE is:6.92 & sMAPE is:29.71% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.78% & 0.89\n",
      "for 2019-09-17, MAE is:4.13 & sMAPE is:12.86% & rMAE is:3.94 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.80% & 0.90\n",
      "for 2019-09-18, MAE is:4.71 & sMAPE is:14.14% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.83% & 0.90\n",
      "for 2019-09-19, MAE is:3.03 & sMAPE is:8.88% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.83% & 0.90\n",
      "for 2019-09-20, MAE is:1.25 & sMAPE is:3.91% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.82% & 0.90\n",
      "for 2019-09-21, MAE is:3.26 & sMAPE is:10.76% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.83% & 0.91\n",
      "for 2019-09-22, MAE is:1.72 & sMAPE is:5.44% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.82% & 0.90\n",
      "for 2019-09-23, MAE is:2.93 & sMAPE is:9.41% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.82% & 0.90\n",
      "for 2019-09-24, MAE is:3.36 & sMAPE is:10.41% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.83% & 0.91\n",
      "for 2019-09-25, MAE is:1.87 & sMAPE is:5.72% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.83% & 0.91\n",
      "for 2019-09-26, MAE is:1.65 & sMAPE is:4.97% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.82% & 0.91\n",
      "for 2019-09-27, MAE is:0.92 & sMAPE is:2.88% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.80% & 0.91\n",
      "for 2019-09-28, MAE is:1.07 & sMAPE is:3.49% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.78% & 0.91\n",
      "for 2019-09-29, MAE is:2.79 & sMAPE is:9.30% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.79% & 0.91\n",
      "for 2019-09-30, MAE is:2.66 & sMAPE is:8.46% & rMAE is:4.07 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.79% & 0.92\n",
      "for 2019-10-01, MAE is:2.66 & sMAPE is:8.16% & rMAE is:4.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.79% & 0.93\n",
      "for 2019-10-02, MAE is:3.06 & sMAPE is:9.18% & rMAE is:2.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.80% & 0.94\n",
      "for 2019-10-03, MAE is:3.62 & sMAPE is:10.59% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.81% & 0.94\n",
      "for 2019-10-04, MAE is:2.51 & sMAPE is:7.16% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.80% & 0.94\n",
      "for 2019-10-05, MAE is:1.68 & sMAPE is:4.68% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.79% & 0.94\n",
      "for 2019-10-06, MAE is:0.82 & sMAPE is:2.33% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.77% & 0.94\n",
      "for 2019-10-07, MAE is:4.26 & sMAPE is:11.46% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.79% & 0.94\n",
      "for 2019-10-08, MAE is:1.92 & sMAPE is:5.29% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.78% & 0.94\n",
      "for 2019-10-09, MAE is:3.06 & sMAPE is:8.63% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.78% & 0.94\n",
      "for 2019-10-10, MAE is:1.90 & sMAPE is:5.49% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.77% & 0.94\n",
      "for 2019-10-11, MAE is:1.43 & sMAPE is:4.34% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.76% & 0.94\n",
      "for 2019-10-12, MAE is:2.51 & sMAPE is:7.58% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.76% & 0.94\n",
      "for 2019-10-13, MAE is:2.80 & sMAPE is:8.33% & rMAE is:5.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.76% & 0.96\n",
      "for 2019-10-14, MAE is:3.08 & sMAPE is:8.49% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.76% & 0.96\n",
      "for 2019-10-15, MAE is:2.54 & sMAPE is:6.86% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.76% & 0.96\n",
      "for 2019-10-16, MAE is:3.11 & sMAPE is:8.54% & rMAE is:3.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.76% & 0.97\n",
      "for 2019-10-17, MAE is:3.58 & sMAPE is:9.91% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.77% & 0.98\n",
      "for 2019-10-18, MAE is:1.65 & sMAPE is:4.60% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.76% & 0.97\n",
      "for 2019-10-19, MAE is:1.03 & sMAPE is:2.95% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.74% & 0.97\n",
      "for 2019-10-20, MAE is:2.85 & sMAPE is:8.05% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.74% & 0.98\n",
      "for 2019-10-21, MAE is:4.30 & sMAPE is:10.69% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.75% & 0.98\n",
      "for 2019-10-22, MAE is:0.82 & sMAPE is:2.32% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.74% & 0.98\n",
      "for 2019-10-23, MAE is:3.47 & sMAPE is:9.63% & rMAE is:3.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.74% & 0.98\n",
      "for 2019-10-24, MAE is:2.00 & sMAPE is:5.38% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.73% & 0.99\n",
      "for 2019-10-25, MAE is:2.31 & sMAPE is:6.81% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.73% & 0.99\n",
      "for 2019-10-26, MAE is:3.47 & sMAPE is:10.77% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.74% & 0.99\n",
      "for 2019-10-27, MAE is:2.98 & sMAPE is:8.52% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.74% & 0.99\n",
      "for 2019-10-28, MAE is:4.06 & sMAPE is:10.97% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.75% & 1.00\n",
      "for 2019-10-29, MAE is:2.39 & sMAPE is:6.15% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.75% & 0.99\n",
      "for 2019-10-30, MAE is:1.37 & sMAPE is:3.60% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.74% & 0.99\n",
      "for 2019-10-31, MAE is:2.16 & sMAPE is:5.66% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.73% & 1.00\n",
      "for 2019-11-01, MAE is:1.25 & sMAPE is:3.36% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.71% & 0.99\n",
      "for 2019-11-02, MAE is:1.72 & sMAPE is:4.76% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.70% & 0.99\n",
      "for 2019-11-03, MAE is:2.35 & sMAPE is:6.51% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.70% & 0.99\n",
      "for 2019-11-04, MAE is:4.93 & sMAPE is:12.88% & rMAE is:3.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 7.72% & 1.00\n",
      "for 2019-11-05, MAE is:4.13 & sMAPE is:10.06% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 7.73% & 1.00\n",
      "for 2019-11-06, MAE is:12.23 & sMAPE is:24.20% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.78% & 1.00\n",
      "for 2019-11-07, MAE is:2.43 & sMAPE is:5.21% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.77% & 1.00\n",
      "for 2019-11-08, MAE is:5.21 & sMAPE is:11.15% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 7.78% & 1.00\n",
      "for 2019-11-09, MAE is:1.50 & sMAPE is:3.62% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 7.77% & 1.00\n",
      "for 2019-11-10, MAE is:2.96 & sMAPE is:6.91% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 7.76% & 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-11-11, MAE is:2.81 & sMAPE is:6.45% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 7.76% & 0.99\n",
      "for 2019-11-12, MAE is:2.13 & sMAPE is:5.24% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 7.75% & 1.00\n",
      "for 2019-11-13, MAE is:2.18 & sMAPE is:5.43% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 7.75% & 0.99\n",
      "for 2019-11-14, MAE is:1.74 & sMAPE is:4.24% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.73% & 0.99\n",
      "for 2019-11-15, MAE is:1.48 & sMAPE is:3.65% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.72% & 0.99\n",
      "for 2019-11-16, MAE is:1.33 & sMAPE is:3.42% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.71% & 0.99\n",
      "for 2019-11-17, MAE is:2.54 & sMAPE is:6.59% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.70% & 0.99\n",
      "for 2019-11-18, MAE is:3.56 & sMAPE is:9.02% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.71% & 0.99\n",
      "for 2019-11-19, MAE is:2.51 & sMAPE is:6.32% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.70% & 0.99\n",
      "for 2019-11-20, MAE is:5.29 & sMAPE is:12.91% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 7.72% & 1.00\n",
      "for 2019-11-21, MAE is:2.10 & sMAPE is:5.18% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 7.71% & 1.00\n",
      "for 2019-11-22, MAE is:2.66 & sMAPE is:6.75% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 7.71% & 1.00\n",
      "for 2019-11-23, MAE is:1.04 & sMAPE is:2.75% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.69% & 1.00\n",
      "for 2019-11-24, MAE is:2.68 & sMAPE is:7.08% & rMAE is:3.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.69% & 1.01\n",
      "for 2019-11-25, MAE is:3.24 & sMAPE is:7.78% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.69% & 1.01\n",
      "for 2019-11-26, MAE is:4.89 & sMAPE is:11.40% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 7.70% & 1.01\n",
      "for 2019-11-27, MAE is:2.29 & sMAPE is:5.54% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 7.70% & 1.01\n",
      "for 2019-11-28, MAE is:1.96 & sMAPE is:4.91% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 7.69% & 1.01\n",
      "for 2019-11-29, MAE is:2.98 & sMAPE is:7.51% & rMAE is:3.15 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 7.69% & 1.02\n",
      "for 2019-11-30, MAE is:0.66 & sMAPE is:1.72% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.67% & 1.02\n",
      "for 2019-12-01, MAE is:1.13 & sMAPE is:2.93% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.66% & 1.02\n",
      "for 2019-12-02, MAE is:2.74 & sMAPE is:6.94% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.65% & 1.02\n",
      "for 2019-12-03, MAE is:1.51 & sMAPE is:3.90% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.64% & 1.02\n",
      "for 2019-12-04, MAE is:1.03 & sMAPE is:2.77% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 7.63% & 1.01\n",
      "for 2019-12-05, MAE is:1.49 & sMAPE is:4.27% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 7.62% & 1.01\n",
      "for 2019-12-06, MAE is:3.13 & sMAPE is:8.92% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 7.62% & 1.01\n",
      "for 2019-12-07, MAE is:1.91 & sMAPE is:5.45% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 7.62% & 1.01\n",
      "for 2019-12-08, MAE is:1.31 & sMAPE is:3.82% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 7.61% & 1.01\n",
      "for 2019-12-09, MAE is:2.66 & sMAPE is:7.30% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 7.60% & 1.01\n",
      "for 2019-12-10, MAE is:5.93 & sMAPE is:15.46% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.63% & 1.01\n",
      "for 2019-12-11, MAE is:4.69 & sMAPE is:15.13% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.65% & 1.01\n",
      "for 2019-12-12, MAE is:3.66 & sMAPE is:10.72% & rMAE is:3.07 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 7.66% & 1.02\n",
      "for 2019-12-13, MAE is:1.04 & sMAPE is:2.97% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.64% & 1.02\n",
      "for 2019-12-14, MAE is:1.67 & sMAPE is:5.02% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.64% & 1.02\n",
      "for 2019-12-15, MAE is:2.42 & sMAPE is:7.44% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.64% & 1.02\n",
      "for 2019-12-16, MAE is:5.79 & sMAPE is:16.00% & rMAE is:2.81 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 7.66% & 1.02\n",
      "for 2019-12-17, MAE is:1.85 & sMAPE is:4.94% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 7.65% & 1.02\n",
      "for 2019-12-18, MAE is:2.19 & sMAPE is:5.98% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.65% & 1.02\n",
      "for 2019-12-19, MAE is:2.34 & sMAPE is:6.52% & rMAE is:2.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.64% & 1.03\n",
      "for 2019-12-20, MAE is:1.97 & sMAPE is:5.60% & rMAE is:3.05 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.64% & 1.03\n",
      "for 2019-12-21, MAE is:1.95 & sMAPE is:5.61% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.63% & 1.03\n",
      "for 2019-12-22, MAE is:1.89 & sMAPE is:5.42% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.63% & 1.03\n",
      "for 2019-12-23, MAE is:1.83 & sMAPE is:5.24% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.62% & 1.03\n",
      "for 2019-12-24, MAE is:1.48 & sMAPE is:4.19% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 7.61% & 1.03\n",
      "for 2019-12-25, MAE is:1.06 & sMAPE is:3.04% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 7.60% & 1.03\n",
      "for 2019-12-26, MAE is:2.17 & sMAPE is:6.11% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 7.59% & 1.03\n",
      "for 2019-12-27, MAE is:3.75 & sMAPE is:9.64% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 7.60% & 1.03\n",
      "for 2019-12-28, MAE is:1.83 & sMAPE is:5.29% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 7.59% & 1.03\n",
      "for 2019-12-29, MAE is:3.65 & sMAPE is:12.98% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 7.61% & 1.03\n",
      "for 2019-12-30, MAE is:5.18 & sMAPE is:28.86% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 7.67% & 1.03\n",
      "for 2019-12-31, MAE is:4.25 & sMAPE is:19.51% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 7.70% & 1.03\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 01:58:56,595]\u001b[0m A new study created in RDB with name: NO_3_2020\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 01:59:21,325]\u001b[0m Trial 3 finished with value: 2.7530693917212314 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014108399262510684, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1619626855845779, 'dropout_rate_Layer_2': 0.025333962370388454, 'dropout_rate_Layer_3': 0.2269276463307371, 'dropout_rate_Layer_4': 0.301606592402423, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001990927477969652, 'l1_Layer_2': 9.56549974579806e-05, 'l1_Layer_3': 5.061525328092584e-05, 'l1_Layer_4': 8.307764496444003e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 130, 'n_units_Layer_3': 280, 'n_units_Layer_4': 240}. Best is trial 3 with value: 2.7530693917212314.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.75 | sMAPE for Validation Set is: 8.19% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 18.07 | sMAPE for Test Set is: 109.14% | rMAE for Test Set is: 5.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 01:59:21,859]\u001b[0m Trial 0 pruned. Trial was pruned at epoch 22.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 01:59:23,039]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 14.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 01:59:33,420]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 01:59:36,451]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 01:59:41,620]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 01:59:45,835]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 01:59:58,543]\u001b[0m Trial 5 finished with value: 2.499846782160427 and parameters: {'n_hidden': 3, 'learning_rate': 0.0039812264919438815, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2524281445016277, 'dropout_rate_Layer_2': 0.12610230282073576, 'dropout_rate_Layer_3': 0.09331178839805028, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.129012821415652e-05, 'l1_Layer_2': 2.317416195538836e-05, 'l1_Layer_3': 0.0002895571057376025, 'n_units_Layer_1': 300, 'n_units_Layer_2': 145, 'n_units_Layer_3': 265}. Best is trial 5 with value: 2.499846782160427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.50 | sMAPE for Validation Set is: 7.48% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 17.02 | sMAPE for Test Set is: 106.25% | rMAE for Test Set is: 5.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:00:01,023]\u001b[0m Trial 10 finished with value: 3.6405197485154797 and parameters: {'n_hidden': 4, 'learning_rate': 0.0662912446104116, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2786706515157806, 'dropout_rate_Layer_2': 0.15071460125123495, 'dropout_rate_Layer_3': 0.39085916048544467, 'dropout_rate_Layer_4': 0.26216271377902756, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.30140427548449e-05, 'l1_Layer_2': 0.001620726712302231, 'l1_Layer_3': 0.0011814739334385866, 'l1_Layer_4': 0.0026166554284563883, 'n_units_Layer_1': 285, 'n_units_Layer_2': 105, 'n_units_Layer_3': 145, 'n_units_Layer_4': 300}. Best is trial 5 with value: 2.499846782160427.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 10.16% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 20.85 | sMAPE for Test Set is: 114.80% | rMAE for Test Set is: 6.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:00:02,329]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:06,082]\u001b[0m Trial 4 finished with value: 2.1414003725336026 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006547167675943381, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00943887707569342, 'dropout_rate_Layer_2': 0.3116507332085711, 'dropout_rate_Layer_3': 0.0046981152643629015, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.04339434707870797, 'l1_Layer_2': 0.056540147837212576, 'l1_Layer_3': 0.0003544995760699219, 'n_units_Layer_1': 205, 'n_units_Layer_2': 55, 'n_units_Layer_3': 85}. Best is trial 4 with value: 2.1414003725336026.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 6.52% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.22 | sMAPE for Test Set is: 95.72% | rMAE for Test Set is: 3.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:00:07,540]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:08,633]\u001b[0m Trial 1 finished with value: 2.302077122338435 and parameters: {'n_hidden': 3, 'learning_rate': 0.009618585965700404, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03957705218891956, 'dropout_rate_Layer_2': 0.27395924657294557, 'dropout_rate_Layer_3': 0.1497194757310003, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.013528904920150802, 'l1_Layer_2': 0.0001110415102936575, 'l1_Layer_3': 0.0009479451550084233, 'n_units_Layer_1': 255, 'n_units_Layer_2': 150, 'n_units_Layer_3': 170}. Best is trial 4 with value: 2.1414003725336026.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.30 | sMAPE for Validation Set is: 6.88% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 14.04 | sMAPE for Test Set is: 98.59% | rMAE for Test Set is: 4.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:00:08,772]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:12,815]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:14,848]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:15,956]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:16,389]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:19,636]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:21,900]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:23,952]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:26,620]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:26,833]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:32,624]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:37,343]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:37,494]\u001b[0m Trial 24 finished with value: 5.074050980093759 and parameters: {'n_hidden': 4, 'learning_rate': 0.03156217272268861, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05577063631056509, 'dropout_rate_Layer_2': 0.19267979777008223, 'dropout_rate_Layer_3': 0.014864663501210318, 'dropout_rate_Layer_4': 0.0834351474878309, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.5984902579663455e-05, 'l1_Layer_2': 0.0004477087830153337, 'l1_Layer_3': 9.172515435256814e-05, 'l1_Layer_4': 6.552571850675073e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 220, 'n_units_Layer_3': 295, 'n_units_Layer_4': 240}. Best is trial 4 with value: 2.1414003725336026.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 14.15% | rMAE for Validation Set is: 1.45\n",
      "MAE for Test Set is: 20.79 | sMAPE for Test Set is: 114.38% | rMAE for Test Set is: 6.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:00:41,481]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:42,508]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:47,698]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:51,422]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:00:58,741]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:01:02,149]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:01:28,299]\u001b[0m Trial 30 finished with value: 2.30112441195234 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012477721926685316, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14974862396546926, 'dropout_rate_Layer_2': 0.18562703031579716, 'dropout_rate_Layer_3': 0.393558365354467, 'dropout_rate_Layer_4': 0.3804434681455918, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.019135496473323015, 'l1_Layer_2': 0.014941583668717057, 'l1_Layer_3': 0.030286675417686235, 'l1_Layer_4': 3.251519544710668e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 270, 'n_units_Layer_3': 55, 'n_units_Layer_4': 65}. Best is trial 4 with value: 2.1414003725336026.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.30 | sMAPE for Validation Set is: 6.91% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 18.72 | sMAPE for Test Set is: 109.87% | rMAE for Test Set is: 5.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:01:30,849]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:01:34,104]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:01:38,677]\u001b[0m Trial 31 finished with value: 2.165039142550037 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008128292380857782, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10711703188974027, 'dropout_rate_Layer_2': 0.03916404872957879, 'dropout_rate_Layer_3': 0.20371172924619213, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06489014399799872, 'l1_Layer_2': 0.01724247862790677, 'l1_Layer_3': 0.050228394451745324, 'n_units_Layer_1': 295, 'n_units_Layer_2': 295, 'n_units_Layer_3': 270}. Best is trial 4 with value: 2.1414003725336026.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.17 | sMAPE for Validation Set is: 6.51% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.58 | sMAPE for Test Set is: 88.13% | rMAE for Test Set is: 3.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:01:41,699]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:01:44,914]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:01:48,882]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:01:55,203]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:02:00,935]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:02:12,193]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:02:14,393]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:02:26,446]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:02:28,877]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:02:33,500]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:02:40,213]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:02:49,268]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:02:50,825]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:02:57,212]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:03:01,698]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:03:07,839]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:03:09,972]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:03:15,542]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:03:17,683]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:03:20,252]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:03:21,652]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:03:23,240]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:03:25,946]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:03:34,072]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:03:36,937]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:03:41,342]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:03:44,530]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:03:50,886]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:03:55,903]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:03:57,378]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:04:08,899]\u001b[0m Trial 60 finished with value: 2.244505744983808 and parameters: {'n_hidden': 4, 'learning_rate': 0.001585811416069036, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2335104759490228, 'dropout_rate_Layer_2': 0.3137490960453499, 'dropout_rate_Layer_3': 0.18010612009742297, 'dropout_rate_Layer_4': 0.26336795844418137, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005423579088124177, 'l1_Layer_2': 1.2826220606896327e-05, 'l1_Layer_3': 0.007360692327206846, 'l1_Layer_4': 1.2718674274250343e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 90, 'n_units_Layer_3': 90, 'n_units_Layer_4': 120}. Best is trial 4 with value: 2.1414003725336026.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.24 | sMAPE for Validation Set is: 6.72% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 15.20 | sMAPE for Test Set is: 101.29% | rMAE for Test Set is: 4.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:04:10,883]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:04:13,441]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:04:16,135]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:04:18,208]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:04:20,993]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:04:25,917]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:04:30,188]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:04:36,682]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:04:39,788]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:04:51,239]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:04:55,920]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:05:02,652]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:05:09,047]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:05:13,425]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:05:13,592]\u001b[0m Trial 73 finished with value: 2.370307755532433 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009573123696983511, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2446015040850838, 'dropout_rate_Layer_2': 0.29015405287090745, 'dropout_rate_Layer_3': 0.26235392615270375, 'dropout_rate_Layer_4': 0.3221917840194579, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009685898009341302, 'l1_Layer_2': 1.4437294501773832e-05, 'l1_Layer_3': 0.03168278784609986, 'l1_Layer_4': 0.00040250271605120347, 'n_units_Layer_1': 240, 'n_units_Layer_2': 55, 'n_units_Layer_3': 95, 'n_units_Layer_4': 50}. Best is trial 4 with value: 2.1414003725336026.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.37 | sMAPE for Validation Set is: 6.97% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 16.75 | sMAPE for Test Set is: 105.52% | rMAE for Test Set is: 5.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:05:20,666]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:05:21,274]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:05:23,136]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:05:28,012]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:05:39,335]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:05:41,173]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:05:47,547]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:05:48,141]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:05:56,825]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:05:59,766]\u001b[0m Trial 89 finished with value: 2.2243031652457663 and parameters: {'n_hidden': 4, 'learning_rate': 0.013956497064466557, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0002311795184327892, 'dropout_rate_Layer_2': 0.11018465059933864, 'dropout_rate_Layer_3': 0.1573294293268994, 'dropout_rate_Layer_4': 0.2584698414461957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005176021096140593, 'l1_Layer_2': 0.01354412378984851, 'l1_Layer_3': 0.0015438234556516368, 'l1_Layer_4': 0.0001917368550960552, 'n_units_Layer_1': 100, 'n_units_Layer_2': 150, 'n_units_Layer_3': 255, 'n_units_Layer_4': 240}. Best is trial 4 with value: 2.1414003725336026.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.22 | sMAPE for Validation Set is: 6.72% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 15.02 | sMAPE for Test Set is: 101.14% | rMAE for Test Set is: 4.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:06:01,485]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:06:06,673]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:06:08,197]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:06:11,250]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:06:12,681]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:06:18,148]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:06:21,355]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:06:23,633]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:06:28,877]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:06:30,477]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:06:34,094]\u001b[0m Trial 97 finished with value: 2.096283034381476 and parameters: {'n_hidden': 3, 'learning_rate': 0.00513028511253685, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16251502814692118, 'dropout_rate_Layer_2': 0.27495561656629874, 'dropout_rate_Layer_3': 0.23446658467684311, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.006451639444992983, 'l1_Layer_2': 0.019521562674959355, 'l1_Layer_3': 5.221129304515424e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 130, 'n_units_Layer_3': 275}. Best is trial 97 with value: 2.096283034381476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 6.36% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 10.72 | sMAPE for Test Set is: 87.94% | rMAE for Test Set is: 3.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:06:36,244]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:06:37,238]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:06:48,075]\u001b[0m Trial 99 finished with value: 2.3471888306598196 and parameters: {'n_hidden': 3, 'learning_rate': 0.002694631347807178, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3882139864036361, 'dropout_rate_Layer_2': 0.004318025862199162, 'dropout_rate_Layer_3': 0.2798187517553645, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09428686216141609, 'l1_Layer_2': 0.0015468709225834115, 'l1_Layer_3': 1.464826635607626e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 300, 'n_units_Layer_3': 290}. Best is trial 97 with value: 2.096283034381476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.35 | sMAPE for Validation Set is: 7.02% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 12.11 | sMAPE for Test Set is: 92.89% | rMAE for Test Set is: 3.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:06:51,003]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:06:51,521]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:06:55,317]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:07:14,224]\u001b[0m Trial 110 finished with value: 2.368648211516481 and parameters: {'n_hidden': 4, 'learning_rate': 0.011283389009743473, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36414677958198116, 'dropout_rate_Layer_2': 0.1506953204682852, 'dropout_rate_Layer_3': 0.011155236750186232, 'dropout_rate_Layer_4': 0.3697502913590617, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00019971985477991485, 'l1_Layer_2': 8.212846033155336e-05, 'l1_Layer_3': 0.00019392942183292153, 'l1_Layer_4': 0.04440892722957742, 'n_units_Layer_1': 295, 'n_units_Layer_2': 120, 'n_units_Layer_3': 230, 'n_units_Layer_4': 300}. Best is trial 97 with value: 2.096283034381476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.37 | sMAPE for Validation Set is: 7.05% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 17.88 | sMAPE for Test Set is: 108.37% | rMAE for Test Set is: 5.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:07:19,001]\u001b[0m Trial 108 finished with value: 2.362158709700103 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007089600251421969, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2275746339982848, 'dropout_rate_Layer_2': 0.29266137933826547, 'dropout_rate_Layer_3': 0.29512306945049466, 'dropout_rate_Layer_4': 0.2878019193190703, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.013516520046810875, 'l1_Layer_2': 2.5764288447434228e-05, 'l1_Layer_3': 0.03709804219063892, 'l1_Layer_4': 0.0008657141730372445, 'n_units_Layer_1': 245, 'n_units_Layer_2': 60, 'n_units_Layer_3': 100, 'n_units_Layer_4': 50}. Best is trial 97 with value: 2.096283034381476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.36 | sMAPE for Validation Set is: 7.00% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 17.06 | sMAPE for Test Set is: 106.06% | rMAE for Test Set is: 5.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:07:20,723]\u001b[0m Trial 112 finished with value: 2.1262181720698123 and parameters: {'n_hidden': 3, 'learning_rate': 0.004633159515376712, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024200149978147192, 'dropout_rate_Layer_2': 0.23470777625180708, 'dropout_rate_Layer_3': 0.28351499007188785, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003401829823636124, 'l1_Layer_2': 0.013228896959113222, 'l1_Layer_3': 0.0001331800564174414, 'n_units_Layer_1': 260, 'n_units_Layer_2': 130, 'n_units_Layer_3': 300}. Best is trial 97 with value: 2.096283034381476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 6.43% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.75 | sMAPE for Test Set is: 88.02% | rMAE for Test Set is: 3.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:07:30,238]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:07:35,708]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:07:36,769]\u001b[0m Trial 115 finished with value: 2.1050453582911075 and parameters: {'n_hidden': 3, 'learning_rate': 0.004737934634914095, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01994507521671337, 'dropout_rate_Layer_2': 0.23704014715229904, 'dropout_rate_Layer_3': 0.2467574788379442, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.01463883534461579, 'l1_Layer_2': 0.010921766484384275, 'l1_Layer_3': 0.00025854625346330873, 'n_units_Layer_1': 265, 'n_units_Layer_2': 130, 'n_units_Layer_3': 300}. Best is trial 97 with value: 2.096283034381476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 6.40% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.92 | sMAPE for Test Set is: 76.57% | rMAE for Test Set is: 2.38\n",
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 6.51% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.70 | sMAPE for Test Set is: 94.64% | rMAE for Test Set is: 3.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:07:36,970]\u001b[0m Trial 114 finished with value: 2.1613712081607273 and parameters: {'n_hidden': 3, 'learning_rate': 0.004566459753313117, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3656712913220017, 'dropout_rate_Layer_2': 0.23170544802402537, 'dropout_rate_Layer_3': 0.2516305669970032, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.01546256164856921, 'l1_Layer_2': 0.010274578184131258, 'l1_Layer_3': 0.0001058051607885409, 'n_units_Layer_1': 260, 'n_units_Layer_2': 130, 'n_units_Layer_3': 295}. Best is trial 97 with value: 2.096283034381476.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:07:42,043]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:07:45,558]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:07:51,088]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:03,537]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:03,899]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:11,335]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:13,951]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:17,780]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:19,621]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:23,201]\u001b[0m Trial 120 finished with value: 2.0269138334871895 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028979311983834436, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026595901926577677, 'dropout_rate_Layer_2': 0.22335993500828694, 'dropout_rate_Layer_3': 0.2511482889734789, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01566093322005301, 'l1_Layer_2': 0.009285801083944905, 'l1_Layer_3': 0.0002851594535617214, 'n_units_Layer_1': 265, 'n_units_Layer_2': 130, 'n_units_Layer_3': 300}. Best is trial 120 with value: 2.0269138334871895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 6.28% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.89 | sMAPE for Test Set is: 29.01% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:08:25,451]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:26,359]\u001b[0m Trial 123 finished with value: 2.6070963732667924 and parameters: {'n_hidden': 4, 'learning_rate': 0.011940818612786556, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3938469318158905, 'dropout_rate_Layer_2': 0.13542602973665097, 'dropout_rate_Layer_3': 0.006526606177444775, 'dropout_rate_Layer_4': 0.391546391284469, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00024258506059347544, 'l1_Layer_2': 8.321472215317677e-05, 'l1_Layer_3': 0.00019154288929870006, 'l1_Layer_4': 0.07583344408755824, 'n_units_Layer_1': 290, 'n_units_Layer_2': 115, 'n_units_Layer_3': 225, 'n_units_Layer_4': 295}. Best is trial 120 with value: 2.0269138334871895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.61 | sMAPE for Validation Set is: 7.68% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 18.01 | sMAPE for Test Set is: 108.81% | rMAE for Test Set is: 5.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:08:29,332]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:31,245]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:33,036]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:34,394]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:36,487]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:39,875]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:40,192]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:48,443]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:50,890]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:54,435]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:55,380]\u001b[0m Trial 137 finished with value: 2.9820625182015057 and parameters: {'n_hidden': 4, 'learning_rate': 0.011454704191469486, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31728989547520386, 'dropout_rate_Layer_2': 0.16740409590325633, 'dropout_rate_Layer_3': 0.001469874254594489, 'dropout_rate_Layer_4': 0.3990800615195529, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0002081241808319858, 'l1_Layer_2': 6.344366825451436e-05, 'l1_Layer_3': 0.0002457380744859231, 'l1_Layer_4': 0.060173128883066355, 'n_units_Layer_1': 260, 'n_units_Layer_2': 125, 'n_units_Layer_3': 300, 'n_units_Layer_4': 290}. Best is trial 120 with value: 2.0269138334871895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.98 | sMAPE for Validation Set is: 8.73% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 18.77 | sMAPE for Test Set is: 110.42% | rMAE for Test Set is: 5.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:08:58,293]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:08:58,458]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:09:01,529]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:09:03,230]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:09:05,691]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:09:05,916]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:09:06,317]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:09:10,910]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:09:12,485]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:09:13,136]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:09:17,849]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:09:18,230]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:09:23,825]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:09:30,146]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:09:39,366]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:09:43,807]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:09:51,029]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:09:57,168]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:10:03,598]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:10:18,561]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:10:37,778]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:10:43,297]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:10:46,626]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:11:11,004]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:11:14,980]\u001b[0m Trial 151 finished with value: 2.677901314463695 and parameters: {'n_hidden': 4, 'learning_rate': 0.0073345802040320615, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1598016991952369, 'dropout_rate_Layer_2': 0.103988823947737, 'dropout_rate_Layer_3': 0.24502376979181428, 'dropout_rate_Layer_4': 0.0020940799590389303, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00828000651418222, 'l1_Layer_2': 0.00026870402208068844, 'l1_Layer_3': 0.002815120091496015, 'l1_Layer_4': 0.00326632370623718, 'n_units_Layer_1': 240, 'n_units_Layer_2': 245, 'n_units_Layer_3': 260, 'n_units_Layer_4': 285}. Best is trial 120 with value: 2.0269138334871895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.68 | sMAPE for Validation Set is: 7.71% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 17.94 | sMAPE for Test Set is: 108.37% | rMAE for Test Set is: 5.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:11:19,599]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:11:20,320]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.61 | sMAPE for Validation Set is: 7.65% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 13.06 | sMAPE for Test Set is: 95.61% | rMAE for Test Set is: 3.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:11:22,922]\u001b[0m Trial 153 finished with value: 2.606801356043896 and parameters: {'n_hidden': 4, 'learning_rate': 0.006211180766255962, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16144546759172076, 'dropout_rate_Layer_2': 0.10517736928548059, 'dropout_rate_Layer_3': 0.11265301704606315, 'dropout_rate_Layer_4': 0.0009528051807815019, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007848535327997865, 'l1_Layer_2': 0.01191707286924159, 'l1_Layer_3': 0.0030253805358183695, 'l1_Layer_4': 0.003456704880126684, 'n_units_Layer_1': 245, 'n_units_Layer_2': 50, 'n_units_Layer_3': 260, 'n_units_Layer_4': 300}. Best is trial 120 with value: 2.0269138334871895.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:11:26,076]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:11:27,950]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:11:30,788]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:11:37,831]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:11:40,883]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:11:41,264]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:11:41,309]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:11:45,974]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:11:56,038]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:12:10,243]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:12:13,187]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:12:15,990]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:12:20,209]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:12:24,810]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:12:24,981]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:12:31,862]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:12:37,614]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.19 | sMAPE for Validation Set is: 6.58% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.53 | sMAPE for Test Set is: 94.63% | rMAE for Test Set is: 3.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:12:38,807]\u001b[0m Trial 176 finished with value: 2.191568755712811 and parameters: {'n_hidden': 3, 'learning_rate': 0.018423098733406265, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2799223677156507, 'dropout_rate_Layer_2': 0.11477381450137103, 'dropout_rate_Layer_3': 0.06151811039438793, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007959710855158647, 'l1_Layer_2': 2.8994060432031406e-05, 'l1_Layer_3': 0.000686146291740441, 'n_units_Layer_1': 300, 'n_units_Layer_2': 90, 'n_units_Layer_3': 205}. Best is trial 120 with value: 2.0269138334871895.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:12:41,211]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:12:44,217]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:12:49,021]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:12:49,810]\u001b[0m Trial 178 finished with value: 2.1555532367358214 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016377984052675747, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008956745800061967, 'dropout_rate_Layer_2': 0.16710143274046782, 'dropout_rate_Layer_3': 0.22912599760941438, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.026381184102865773, 'l1_Layer_2': 0.0001745638248205223, 'l1_Layer_3': 0.0004940453939580307, 'n_units_Layer_1': 285, 'n_units_Layer_2': 130, 'n_units_Layer_3': 90}. Best is trial 120 with value: 2.0269138334871895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 6.49% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.40 | sMAPE for Test Set is: 79.04% | rMAE for Test Set is: 2.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:12:53,921]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:12:56,255]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:12:58,245]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:13:03,557]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:13:03,893]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:13:09,489]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:13:12,287]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:13:15,585]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:13:19,110]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:13:19,536]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:13:25,250]\u001b[0m Trial 185 finished with value: 2.2565418332382285 and parameters: {'n_hidden': 3, 'learning_rate': 0.001519023639031508, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3189927526484903, 'dropout_rate_Layer_2': 0.04911613321362771, 'dropout_rate_Layer_3': 0.2961386751073681, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.031238271440389886, 'l1_Layer_2': 0.00142001520448115, 'l1_Layer_3': 1.683805584789733e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 300, 'n_units_Layer_3': 280}. Best is trial 120 with value: 2.0269138334871895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.26 | sMAPE for Validation Set is: 6.73% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.60 | sMAPE for Test Set is: 94.64% | rMAE for Test Set is: 3.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:13:28,711]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:13:29,133]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:13:33,361]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:13:37,848]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:13:40,803]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:13:43,343]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:13:46,241]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:13:55,892]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:14:00,695]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:14:08,065]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:14:15,490]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:14:19,321]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:14:25,426]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:14:29,175]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:14:42,167]\u001b[0m Trial 205 finished with value: 2.123898775071405 and parameters: {'n_hidden': 3, 'learning_rate': 0.006264764713773219, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3491307988410678, 'dropout_rate_Layer_2': 0.1375188190201471, 'dropout_rate_Layer_3': 0.0496366843882145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000542952046514316, 'l1_Layer_2': 2.9540384232417346e-05, 'l1_Layer_3': 0.0005184985861348708, 'n_units_Layer_1': 265, 'n_units_Layer_2': 100, 'n_units_Layer_3': 145}. Best is trial 120 with value: 2.0269138334871895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 6.42% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.35 | sMAPE for Test Set is: 86.72% | rMAE for Test Set is: 3.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:14:46,371]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:14:47,609]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:14:51,560]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:14:56,025]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:02,692]\u001b[0m Trial 188 finished with value: 2.061729632742578 and parameters: {'n_hidden': 3, 'learning_rate': 0.006506934874087191, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34973451273073763, 'dropout_rate_Layer_2': 0.1380704114088317, 'dropout_rate_Layer_3': 0.04618741762695312, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006995737339036065, 'l1_Layer_2': 3.086749188749863e-05, 'l1_Layer_3': 0.0005923010524125719, 'n_units_Layer_1': 265, 'n_units_Layer_2': 110, 'n_units_Layer_3': 160}. Best is trial 120 with value: 2.0269138334871895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.17% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 12.98 | sMAPE for Test Set is: 96.25% | rMAE for Test Set is: 3.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:15:07,382]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:10,066]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:13,924]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:15,494]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:17,460]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:19,112]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:21,744]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:25,329]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:28,359]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:29,489]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:32,743]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:33,236]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:38,698]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:38,978]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:45,681]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:50,901]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:53,474]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:56,625]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:15:59,658]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:16:03,657]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:16:08,375]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:16:09,419]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:16:13,374]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:16:15,080]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:16:18,505]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:16:19,047]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:16:25,234]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:16:29,392]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:16:36,287]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:16:39,199]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:16:43,336]\u001b[0m Trial 222 finished with value: 2.2092245610555015 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006145311641880667, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2887193906569714, 'dropout_rate_Layer_2': 0.27138854702304477, 'dropout_rate_Layer_3': 0.10313771117397014, 'dropout_rate_Layer_4': 0.2340665841601819, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09902957297262661, 'l1_Layer_2': 0.026331331307748618, 'l1_Layer_3': 0.00031299860826706696, 'l1_Layer_4': 0.001844802246615891, 'n_units_Layer_1': 135, 'n_units_Layer_2': 275, 'n_units_Layer_3': 195, 'n_units_Layer_4': 255}. Best is trial 120 with value: 2.0269138334871895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.21 | sMAPE for Validation Set is: 6.62% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 15.33 | sMAPE for Test Set is: 101.51% | rMAE for Test Set is: 4.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:16:46,713]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:16:51,306]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:16:55,688]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:16:55,832]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:16:56,210]\u001b[0m Trial 237 finished with value: 2.006841571413161 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014783354267239699, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0020023977449724582, 'dropout_rate_Layer_2': 0.20776692988722079, 'dropout_rate_Layer_3': 0.1902276055381431, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015316008412360636, 'l1_Layer_2': 0.011358873762211322, 'l1_Layer_3': 0.00020380698610280253, 'n_units_Layer_1': 210, 'n_units_Layer_2': 105, 'n_units_Layer_3': 275}. Best is trial 237 with value: 2.006841571413161.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 6.22% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.12 | sMAPE for Test Set is: 32.72% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:17:00,225]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:17:01,667]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:17:02,522]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:17:02,887]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:17:06,400]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:17:17,325]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:17:18,897]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:17:22,585]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:17:28,343]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:17:31,627]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:17:34,018]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:17:45,348]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:17:48,338]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:17:49,926]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:17:53,071]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:17:54,367]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:17:54,801]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:17:59,803]\u001b[0m Trial 270 finished with value: 2.4420893643199837 and parameters: {'n_hidden': 3, 'learning_rate': 0.0039672326308724725, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36736168188823215, 'dropout_rate_Layer_2': 0.0393374397123125, 'dropout_rate_Layer_3': 0.07981861413228931, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.474319840206484e-05, 'l1_Layer_2': 1.7685200106672363e-05, 'l1_Layer_3': 3.647293219220087e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 90, 'n_units_Layer_3': 180}. Best is trial 237 with value: 2.006841571413161.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.44 | sMAPE for Validation Set is: 7.28% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 14.37 | sMAPE for Test Set is: 100.38% | rMAE for Test Set is: 4.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:18:03,119]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:18:07,775]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:18:11,912]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:18:15,988]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:18:34,014]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:18:38,314]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:18:51,240]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:18:57,907]\u001b[0m Trial 274 finished with value: 2.204387712869342 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018906593103031899, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3708855159892587, 'dropout_rate_Layer_2': 0.04390741159943269, 'dropout_rate_Layer_3': 0.09250731469062787, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004660386516009083, 'l1_Layer_2': 2.0658782067859316e-05, 'l1_Layer_3': 0.0003301736010177431, 'n_units_Layer_1': 255, 'n_units_Layer_2': 165, 'n_units_Layer_3': 175}. Best is trial 237 with value: 2.006841571413161.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.20 | sMAPE for Validation Set is: 6.69% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 15.00 | sMAPE for Test Set is: 101.19% | rMAE for Test Set is: 4.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:19:00,799]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:19:05,541]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:19:09,822]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:19:17,621]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:19:26,487]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:19:56,841]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:20:00,480]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:20:09,890]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:20:27,834]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:20:30,511]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:20:33,955]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:20:36,665]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:20:38,834]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:20:39,758]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:20:46,468]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:20:47,940]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:20:51,221]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:20:55,823]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:20:57,930]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:21:00,257]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:21:04,453]\u001b[0m Trial 285 finished with value: 2.2334513529630122 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018373589472566662, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21284607936869818, 'dropout_rate_Layer_2': 0.07003753612198577, 'dropout_rate_Layer_3': 0.10178271475596554, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003743834427645748, 'l1_Layer_2': 1.5105485993384766e-05, 'l1_Layer_3': 0.00040871725266919916, 'n_units_Layer_1': 245, 'n_units_Layer_2': 240, 'n_units_Layer_3': 125}. Best is trial 237 with value: 2.006841571413161.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.23 | sMAPE for Validation Set is: 6.78% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.65 | sMAPE for Test Set is: 91.81% | rMAE for Test Set is: 3.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:21:09,947]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:21:15,703]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:21:28,334]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:22:01,244]\u001b[0m Trial 305 finished with value: 2.145375459624846 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029372247836454675, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36525601967279053, 'dropout_rate_Layer_2': 0.12315049328264886, 'dropout_rate_Layer_3': 0.050053611964482166, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012723638075718303, 'l1_Layer_2': 3.935563817371835e-05, 'l1_Layer_3': 0.0007875852106985329, 'n_units_Layer_1': 245, 'n_units_Layer_2': 165, 'n_units_Layer_3': 175}. Best is trial 237 with value: 2.006841571413161.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.15 | sMAPE for Validation Set is: 6.51% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 15.38 | sMAPE for Test Set is: 102.30% | rMAE for Test Set is: 4.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:22:04,870]\u001b[0m Trial 290 finished with value: 2.224219588349873 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015117598985037396, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21991333798732818, 'dropout_rate_Layer_2': 0.07177445428700584, 'dropout_rate_Layer_3': 0.11027536040944119, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00035867474239279087, 'l1_Layer_2': 1.7873805036265948e-05, 'l1_Layer_3': 0.000336378296522677, 'n_units_Layer_1': 195, 'n_units_Layer_2': 225, 'n_units_Layer_3': 125}. Best is trial 237 with value: 2.006841571413161.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.22 | sMAPE for Validation Set is: 6.66% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.72 | sMAPE for Test Set is: 75.03% | rMAE for Test Set is: 2.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:22:08,703]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:22:16,290]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:22:20,332]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:22:20,998]\u001b[0m Trial 303 finished with value: 1.9929276590151934 and parameters: {'n_hidden': 3, 'learning_rate': 0.001613305904717953, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0076228079219246014, 'dropout_rate_Layer_2': 0.21972569561375882, 'dropout_rate_Layer_3': 0.1749451165497656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01055686608243162, 'l1_Layer_2': 0.006622300541334894, 'l1_Layer_3': 0.0010770517912951415, 'n_units_Layer_1': 255, 'n_units_Layer_2': 110, 'n_units_Layer_3': 295}. Best is trial 303 with value: 1.9929276590151934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.99 | sMAPE for Validation Set is: 6.12% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.43 | sMAPE for Test Set is: 69.17% | rMAE for Test Set is: 1.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:22:26,929]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:22:32,847]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:22:37,580]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:22:37,920]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:22:41,708]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:22:42,689]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:22:46,284]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:22:49,728]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:22:52,473]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:22:53,970]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:23:00,882]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:23:14,340]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:23:17,119]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:23:20,428]\u001b[0m Trial 309 finished with value: 2.168555026453966 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007396452501664576, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3407373704292744, 'dropout_rate_Layer_2': 0.31271047007227376, 'dropout_rate_Layer_3': 0.03776176139544388, 'dropout_rate_Layer_4': 0.2620512984270941, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0054278920652971, 'l1_Layer_2': 0.05310378475213768, 'l1_Layer_3': 0.00022391188664091464, 'l1_Layer_4': 0.012015165352073568, 'n_units_Layer_1': 95, 'n_units_Layer_2': 225, 'n_units_Layer_3': 170, 'n_units_Layer_4': 285}. Best is trial 303 with value: 1.9929276590151934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.17 | sMAPE for Validation Set is: 6.51% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 17.07 | sMAPE for Test Set is: 106.09% | rMAE for Test Set is: 5.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:23:23,478]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:23:24,005]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:23:33,469]\u001b[0m Trial 326 finished with value: 2.569063543944829 and parameters: {'n_hidden': 3, 'learning_rate': 0.014806568042851303, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00591802211078637, 'dropout_rate_Layer_2': 0.2290692905809707, 'dropout_rate_Layer_3': 0.19125422279108792, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.012653287393696689, 'l1_Layer_2': 0.00012119991413370939, 'l1_Layer_3': 0.04032857185133008, 'n_units_Layer_1': 160, 'n_units_Layer_2': 235, 'n_units_Layer_3': 170}. Best is trial 303 with value: 1.9929276590151934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.57 | sMAPE for Validation Set is: 7.45% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 15.24 | sMAPE for Test Set is: 102.48% | rMAE for Test Set is: 4.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:23:36,499]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:23:37,018]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:23:38,493]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:23:40,447]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:23:43,566]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:23:46,376]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:23:50,292]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:23:50,826]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:23:51,128]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:23:55,035]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:23:55,588]\u001b[0m Trial 321 finished with value: 2.1988587731444853 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032385368385064958, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32635429712658104, 'dropout_rate_Layer_2': 0.12304654975420747, 'dropout_rate_Layer_3': 0.051977501951770054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018365535259719408, 'l1_Layer_2': 4.111873099959321e-05, 'l1_Layer_3': 0.0007822391011486993, 'n_units_Layer_1': 220, 'n_units_Layer_2': 195, 'n_units_Layer_3': 150}. Best is trial 303 with value: 1.9929276590151934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.20 | sMAPE for Validation Set is: 6.66% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 14.96 | sMAPE for Test Set is: 100.79% | rMAE for Test Set is: 4.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:23:56,337]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:23:57,795]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:01,171]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:01,839]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:04,698]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:06,643]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:08,376]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:08,642]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:17,260]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:21,978]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:23,919]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:25,679]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:28,200]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:38,073]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:40,917]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:44,664]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:45,106]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:50,112]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:53,373]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:55,443]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:58,913]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:24:59,693]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:25:03,083]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:25:04,083]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:25:09,320]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:25:09,446]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:25:10,145]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:25:14,430]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:25:18,074]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:25:23,761]\u001b[0m Trial 352 finished with value: 2.097496832797869 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006848616976733769, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2227927985458028, 'dropout_rate_Layer_2': 0.30069899376942, 'dropout_rate_Layer_3': 0.033632594584718095, 'dropout_rate_Layer_4': 0.288165794564457, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.027803891333396943, 'l1_Layer_2': 2.0415187709643612e-05, 'l1_Layer_3': 0.00010581867619262314, 'l1_Layer_4': 0.008102586110151102, 'n_units_Layer_1': 75, 'n_units_Layer_2': 265, 'n_units_Layer_3': 260, 'n_units_Layer_4': 295}. Best is trial 303 with value: 1.9929276590151934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 6.38% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 10.93 | sMAPE for Test Set is: 88.78% | rMAE for Test Set is: 3.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:25:28,650]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:25:32,974]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:25:37,773]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:25:41,615]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:25:44,232]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:25:49,434]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:25:55,271]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.45 | sMAPE for Validation Set is: 7.21% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 16.42 | sMAPE for Test Set is: 104.73% | rMAE for Test Set is: 4.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:25:56,678]\u001b[0m Trial 369 finished with value: 2.4538098009027802 and parameters: {'n_hidden': 3, 'learning_rate': 0.0051815236856824496, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31027908478975824, 'dropout_rate_Layer_2': 0.10457893720026315, 'dropout_rate_Layer_3': 0.05395299436225266, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012045783956122439, 'l1_Layer_2': 0.002010801960361451, 'l1_Layer_3': 0.0008208057901244416, 'n_units_Layer_1': 225, 'n_units_Layer_2': 295, 'n_units_Layer_3': 150}. Best is trial 303 with value: 1.9929276590151934.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:25:58,872]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:01,357]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:02,956]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:06,545]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:06,799]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:07,266]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:07,373]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:16,220]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:18,511]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:20,248]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:20,323]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:21,228]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:22,257]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:28,683]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:28,739]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:33,482]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:34,206]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:37,346]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:37,551]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:41,789]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:42,302]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:44,749]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:45,478]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:49,915]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:51,418]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:53,194]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:26:56,614]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:27:00,236]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:27:01,779]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:27:04,602]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:27:07,864]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:27:11,884]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:27:16,351]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:27:26,689]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:27:30,553]\u001b[0m Trial 395 finished with value: 2.216966944886319 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008649209338922358, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23480910414443765, 'dropout_rate_Layer_2': 0.34859124868812363, 'dropout_rate_Layer_3': 0.023520903562049573, 'dropout_rate_Layer_4': 0.2852906860237999, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.09321756887145874, 'l1_Layer_2': 0.021853467562748488, 'l1_Layer_3': 0.00013716914486734392, 'l1_Layer_4': 0.0024026436891016107, 'n_units_Layer_1': 60, 'n_units_Layer_2': 270, 'n_units_Layer_3': 75, 'n_units_Layer_4': 285}. Best is trial 303 with value: 1.9929276590151934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.22 | sMAPE for Validation Set is: 6.65% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 16.53 | sMAPE for Test Set is: 105.04% | rMAE for Test Set is: 4.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:27:34,596]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:27:36,169]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:27:40,076]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:27:44,289]\u001b[0m Trial 407 finished with value: 2.073906399613208 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023337540395186084, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3576947910248782, 'dropout_rate_Layer_2': 0.03307489402648872, 'dropout_rate_Layer_3': 0.27863020354770024, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.005797200558468e-05, 'l1_Layer_2': 0.0013732669469801962, 'l1_Layer_3': 1.0570692379895934e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 275, 'n_units_Layer_3': 50}. Best is trial 303 with value: 1.9929276590151934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.31% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 12.06 | sMAPE for Test Set is: 92.88% | rMAE for Test Set is: 3.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:27:44,795]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:27:48,796]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:27:52,830]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:27:56,697]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:28:05,099]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:28:08,727]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:28:16,583]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:28:20,788]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:28:21,118]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:28:21,907]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:28:27,832]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:28:30,543]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:28:32,085]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:28:35,663]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:28:40,337]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:28:45,722]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:28:53,976]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:28:57,499]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:05,216]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:05,644]\u001b[0m Trial 433 finished with value: 2.1611206369115874 and parameters: {'n_hidden': 3, 'learning_rate': 0.002142856105777929, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35024214545493737, 'dropout_rate_Layer_2': 0.045394020184130836, 'dropout_rate_Layer_3': 0.33617697431969085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0831849222497596e-05, 'l1_Layer_2': 0.0008480623454006596, 'l1_Layer_3': 3.0957612821755576e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 275, 'n_units_Layer_3': 100}. Best is trial 303 with value: 1.9929276590151934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 6.52% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.18 | sMAPE for Test Set is: 89.80% | rMAE for Test Set is: 3.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:29:10,768]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:16,365]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:18,652]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:21,678]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:22,516]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:27,215]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:31,745]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:33,709]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:38,874]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:41,391]\u001b[0m Trial 422 finished with value: 2.155529548202813 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008588062174063639, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20386542970570776, 'dropout_rate_Layer_2': 0.34830385461303404, 'dropout_rate_Layer_3': 0.048904307875191504, 'dropout_rate_Layer_4': 0.3022160445004716, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.08398000096219803, 'l1_Layer_2': 0.020321376429272814, 'l1_Layer_3': 0.05264964481399001, 'l1_Layer_4': 0.002226152710095327, 'n_units_Layer_1': 60, 'n_units_Layer_2': 270, 'n_units_Layer_3': 75, 'n_units_Layer_4': 270}. Best is trial 303 with value: 1.9929276590151934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 6.53% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 18.57 | sMAPE for Test Set is: 109.60% | rMAE for Test Set is: 5.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:29:42,245]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:44,733]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:48,079]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:48,415]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:48,762]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:55,328]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:55,719]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:29:55,816]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:30:02,083]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:30:02,443]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:30:04,579]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:30:09,686]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:30:14,059]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:30:15,364]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:30:18,489]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:30:19,166]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:30:19,477]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:30:23,176]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:30:25,291]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:30:25,901]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:30:28,914]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:30:41,052]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:30:44,304]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:30:53,364]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:30:57,781]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:31:01,067]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:31:05,422]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:31:09,569]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:31:12,595]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:31:40,122]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:31:45,914]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:31:49,031]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:31:53,488]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:31:59,085]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:32:03,404]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:32:05,110]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:32:09,247]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:32:11,595]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:32:17,048]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:32:19,896]\u001b[0m Trial 468 finished with value: 2.0939747887083935 and parameters: {'n_hidden': 3, 'learning_rate': 0.001379953918230155, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1748151060966525, 'dropout_rate_Layer_2': 0.05345007111435558, 'dropout_rate_Layer_3': 0.043042538572980266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005597472054632165, 'l1_Layer_2': 1.4188725261235195e-05, 'l1_Layer_3': 0.00029840552507166585, 'n_units_Layer_1': 200, 'n_units_Layer_2': 230, 'n_units_Layer_3': 130}. Best is trial 303 with value: 1.9929276590151934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.27% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.77 | sMAPE for Test Set is: 57.05% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:32:20,336]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:32:26,144]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:32:31,432]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:32:33,199]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:32:36,712]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:32:39,164]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:32:41,334]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:32:42,046]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:32:46,623]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:32:51,870]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:32:55,959]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:00,199]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:03,558]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:07,557]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:11,350]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:17,037]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:21,092]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:21,896]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:25,701]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:29,074]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:33,717]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:37,777]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:38,576]\u001b[0m Trial 498 finished with value: 2.0589303036464215 and parameters: {'n_hidden': 3, 'learning_rate': 0.007021217744105661, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07914849665727668, 'dropout_rate_Layer_2': 0.01316052542675671, 'dropout_rate_Layer_3': 0.0873658428681333, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010054828354498196, 'l1_Layer_2': 3.103701775812499e-05, 'l1_Layer_3': 0.0012640516179701568, 'n_units_Layer_1': 285, 'n_units_Layer_2': 185, 'n_units_Layer_3': 95}. Best is trial 303 with value: 1.9929276590151934.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.32% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.49 | sMAPE for Test Set is: 79.56% | rMAE for Test Set is: 2.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:33:42,569]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:43,133]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:47,427]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:47,984]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:51,165]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:55,031]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:55,422]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:33:55,506]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:00,318]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:01,667]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:03,475]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:04,513]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:06,290]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:08,496]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:10,499]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:12,285]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:15,512]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:16,129]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:27,750]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:30,661]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:30,814]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:39,266]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:42,467]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:43,007]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:46,209]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:50,025]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:53,469]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:34:59,580]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:35:09,980]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 6.55% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 13.49 | sMAPE for Test Set is: 97.36% | rMAE for Test Set is: 4.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:35:11,760]\u001b[0m Trial 531 finished with value: 2.1603599187071314 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006127194480837028, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23261831050144977, 'dropout_rate_Layer_2': 0.25608792077543163, 'dropout_rate_Layer_3': 0.027016450708434066, 'dropout_rate_Layer_4': 0.26420973623244537, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.3481609227688547e-05, 'l1_Layer_2': 0.0007427249341454388, 'l1_Layer_3': 0.0001571059694567742, 'l1_Layer_4': 0.0036596855162510256, 'n_units_Layer_1': 240, 'n_units_Layer_2': 220, 'n_units_Layer_3': 75, 'n_units_Layer_4': 270}. Best is trial 303 with value: 1.9929276590151934.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:35:15,692]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:35:17,598]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:35:19,878]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:35:36,093]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:35:38,872]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:35:42,407]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:35:45,542]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:35:47,968]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:35:51,614]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.92% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 11.71 | sMAPE for Test Set is: 91.76% | rMAE for Test Set is: 3.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:35:53,534]\u001b[0m Trial 529 finished with value: 1.9382710741796083 and parameters: {'n_hidden': 3, 'learning_rate': 0.005697745998712617, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0871823187919968, 'dropout_rate_Layer_2': 0.028996202248366718, 'dropout_rate_Layer_3': 0.06499963524488543, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009295498602928255, 'l1_Layer_2': 2.3472528020938295e-05, 'l1_Layer_3': 0.0014660546941409097, 'n_units_Layer_1': 280, 'n_units_Layer_2': 180, 'n_units_Layer_3': 100}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:35:57,851]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:35:59,295]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:01,474]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:05,095]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:05,497]\u001b[0m Trial 538 finished with value: 2.0783436769124957 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006834201165260431, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3352683529304186, 'dropout_rate_Layer_2': 0.047313422013128936, 'dropout_rate_Layer_3': 0.27672249006858485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2972341139637164e-05, 'l1_Layer_2': 0.0013242473269196326, 'l1_Layer_3': 1.986469532442958e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 285, 'n_units_Layer_3': 165}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.26% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.38 | sMAPE for Test Set is: 78.80% | rMAE for Test Set is: 2.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:36:07,591]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:12,459]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:14,032]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:15,998]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:16,840]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:17,979]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:18,413]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:19,036]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:24,107]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:26,376]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:28,593]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:29,019]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:29,523]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:31,060]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:34,758]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:37,025]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:37,055]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:36:39,916]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:37:14,019]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:37:28,295]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:37:35,505]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:37:40,919]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:37:44,498]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:37:48,485]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:37:49,150]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:37:56,474]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:00,351]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:02,359]\u001b[0m Trial 574 finished with value: 2.1950529843557702 and parameters: {'n_hidden': 3, 'learning_rate': 0.004334517491080687, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04443091357296072, 'dropout_rate_Layer_2': 0.00019335665637025892, 'dropout_rate_Layer_3': 0.05257724551965105, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0075085767529612804, 'l1_Layer_2': 6.797992526397176e-05, 'l1_Layer_3': 0.0011045074021869398, 'n_units_Layer_1': 280, 'n_units_Layer_2': 110, 'n_units_Layer_3': 80}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.20 | sMAPE for Validation Set is: 6.70% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.43 | sMAPE for Test Set is: 79.03% | rMAE for Test Set is: 2.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:38:07,974]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:13,308]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:13,542]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:15,534]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:21,456]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:21,802]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:22,018]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:22,844]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:28,723]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:29,194]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:29,885]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:35,910]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:36,128]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:36,350]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:37,000]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:46,088]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:46,328]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:46,992]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:48,805]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:56,631]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:38:57,205]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:00,190]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:02,735]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:04,345]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:07,776]\u001b[0m Trial 602 finished with value: 4.379762117867141 and parameters: {'n_hidden': 3, 'learning_rate': 0.003183149788418646, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23681849984987546, 'dropout_rate_Layer_2': 0.01737441126319531, 'dropout_rate_Layer_3': 0.27769416533467384, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.4008293377100876e-05, 'l1_Layer_2': 0.0038766692726471996, 'l1_Layer_3': 0.0411315941560042, 'n_units_Layer_1': 285, 'n_units_Layer_2': 240, 'n_units_Layer_3': 180}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.38 | sMAPE for Validation Set is: 12.06% | rMAE for Validation Set is: 1.25\n",
      "MAE for Test Set is: 24.97 | sMAPE for Test Set is: 122.24% | rMAE for Test Set is: 7.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:39:10,670]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:12,567]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:13,563]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:17,149]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:17,482]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:24,512]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:28,415]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:28,606]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:35,017]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:40,447]\u001b[0m Trial 609 finished with value: 2.1059398506873146 and parameters: {'n_hidden': 3, 'learning_rate': 0.007956417227995762, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026307409415851066, 'dropout_rate_Layer_2': 0.025260857864104303, 'dropout_rate_Layer_3': 0.28938556998480225, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.427198050074955e-05, 'l1_Layer_2': 1.2185482479040831e-05, 'l1_Layer_3': 0.0021479706961453765, 'n_units_Layer_1': 135, 'n_units_Layer_2': 85, 'n_units_Layer_3': 70}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 6.42% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.15 | sMAPE for Test Set is: 72.87% | rMAE for Test Set is: 2.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:39:43,876]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:47,920]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:49,781]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:49,846]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:55,655]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:39:58,518]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:02,005]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:06,043]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:07,912]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:12,146]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:12,972]\u001b[0m Trial 611 finished with value: 2.1025549111153157 and parameters: {'n_hidden': 3, 'learning_rate': 0.00746566806769584, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028135342521151283, 'dropout_rate_Layer_2': 0.03417011669346759, 'dropout_rate_Layer_3': 0.2806123704776905, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003352669408974591, 'l1_Layer_2': 0.00012221278847764704, 'l1_Layer_3': 0.002142512147536239, 'n_units_Layer_1': 265, 'n_units_Layer_2': 85, 'n_units_Layer_3': 85}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:13,091]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 6.39% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.74 | sMAPE for Test Set is: 80.78% | rMAE for Test Set is: 2.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:40:18,496]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:19,955]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:22,636]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:25,459]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:28,915]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:31,594]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:34,487]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:39,996]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:42,997]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:47,572]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:50,708]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:52,048]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:55,715]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:40:57,350]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:41:01,388]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:41:03,325]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:41:07,256]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:41:08,960]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:41:13,139]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:41:17,942]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:41:21,529]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:41:25,409]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:41:26,837]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:41:29,964]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:41:35,575]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:41:40,351]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:41:54,185]\u001b[0m Trial 635 finished with value: 2.0898825236450134 and parameters: {'n_hidden': 3, 'learning_rate': 0.009817562981855208, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00018756507770127315, 'dropout_rate_Layer_2': 0.0243226222360889, 'dropout_rate_Layer_3': 0.2716301079859739, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.1525975533204477e-05, 'l1_Layer_2': 0.0001420922737477186, 'l1_Layer_3': 0.006763888544348763, 'n_units_Layer_1': 160, 'n_units_Layer_2': 65, 'n_units_Layer_3': 110}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.40% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 10.50 | sMAPE for Test Set is: 87.60% | rMAE for Test Set is: 3.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:41:57,108]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:41:58,913]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:42:02,680]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.40 | sMAPE for Validation Set is: 7.13% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 15.46 | sMAPE for Test Set is: 101.83% | rMAE for Test Set is: 4.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:42:04,311]\u001b[0m Trial 656 finished with value: 2.400692278783859 and parameters: {'n_hidden': 4, 'learning_rate': 0.05452282931880245, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.348033573414209, 'dropout_rate_Layer_2': 0.11839164800657492, 'dropout_rate_Layer_3': 0.34536263457110583, 'dropout_rate_Layer_4': 0.3146764998544014, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.5494261541243974e-05, 'l1_Layer_2': 0.06251775623823397, 'l1_Layer_3': 1.0784020447434241e-05, 'l1_Layer_4': 0.00019294915298496293, 'n_units_Layer_1': 240, 'n_units_Layer_2': 260, 'n_units_Layer_3': 90, 'n_units_Layer_4': 130}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:42:04,983]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:42:09,854]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:42:12,846]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:42:16,689]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:42:19,545]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:42:22,422]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:42:24,249]\u001b[0m Trial 662 finished with value: 2.0134424725102753 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019261100688209938, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03098734746712708, 'dropout_rate_Layer_2': 0.20650865350742692, 'dropout_rate_Layer_3': 0.22172254749688808, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007803115852738672, 'l1_Layer_2': 0.00027392421919065585, 'l1_Layer_3': 9.225614219841497e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 115, 'n_units_Layer_3': 285}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 6.20% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 61.68% | rMAE for Test Set is: 1.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:42:26,204]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:42:27,914]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:42:30,122]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:42:32,002]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:42:36,047]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:42:39,671]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:42:41,646]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:42:54,948]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:42:57,719]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:43:02,255]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:43:07,093]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:43:17,610]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:43:21,175]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:43:23,883]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:43:26,005]\u001b[0m Trial 663 finished with value: 2.2132068458482537 and parameters: {'n_hidden': 3, 'learning_rate': 0.009665278178540156, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06297704722247967, 'dropout_rate_Layer_2': 0.023012950463376272, 'dropout_rate_Layer_3': 0.28809992673580653, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 3.0673238739476955e-05, 'l1_Layer_2': 0.0001224322070459944, 'l1_Layer_3': 0.009305668670320583, 'n_units_Layer_1': 150, 'n_units_Layer_2': 65, 'n_units_Layer_3': 90}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.21 | sMAPE for Validation Set is: 6.67% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.14 | sMAPE for Test Set is: 86.21% | rMAE for Test Set is: 3.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:43:28,077]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:43:32,122]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:43:37,457]\u001b[0m Trial 680 finished with value: 2.1766892672117857 and parameters: {'n_hidden': 3, 'learning_rate': 0.015458290925023712, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0912298708913522, 'dropout_rate_Layer_2': 0.026484730602567202, 'dropout_rate_Layer_3': 0.3350080812865782, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.0780199576523656e-05, 'l1_Layer_2': 2.808717485616502e-05, 'l1_Layer_3': 0.013753653917124409, 'n_units_Layer_1': 165, 'n_units_Layer_2': 65, 'n_units_Layer_3': 115}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.18 | sMAPE for Validation Set is: 6.63% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.87 | sMAPE for Test Set is: 65.57% | rMAE for Test Set is: 1.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:43:38,554]\u001b[0m Trial 665 finished with value: 2.144759361655131 and parameters: {'n_hidden': 4, 'learning_rate': 0.011068479652431835, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06030873465147267, 'dropout_rate_Layer_2': 0.01635027070441399, 'dropout_rate_Layer_3': 0.2506240642720991, 'dropout_rate_Layer_4': 0.013612932912495601, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.436000502616693e-05, 'l1_Layer_2': 0.0006074426203023667, 'l1_Layer_3': 0.012869787283853797, 'l1_Layer_4': 0.00021382378539501384, 'n_units_Layer_1': 155, 'n_units_Layer_2': 60, 'n_units_Layer_3': 90, 'n_units_Layer_4': 70}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 6.53% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.43 | sMAPE for Test Set is: 87.22% | rMAE for Test Set is: 3.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:43:43,087]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:43:46,190]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:43:49,427]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:43:53,509]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:43:57,992]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:43:59,829]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:44:02,162]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:44:05,960]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:44:14,734]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:44:20,158]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:44:23,719]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:44:26,647]\u001b[0m Trial 686 finished with value: 2.1946124418443365 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009284809760007105, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24533979942848758, 'dropout_rate_Layer_2': 0.1630028369563729, 'dropout_rate_Layer_3': 0.11370839687744323, 'dropout_rate_Layer_4': 0.3578293587759007, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.06417395912544249, 'l1_Layer_2': 0.058981946935962946, 'l1_Layer_3': 0.026996859862356535, 'l1_Layer_4': 1.1112238319343004e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 290, 'n_units_Layer_3': 70, 'n_units_Layer_4': 190}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.19 | sMAPE for Validation Set is: 6.60% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 18.06 | sMAPE for Test Set is: 108.34% | rMAE for Test Set is: 5.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:44:31,360]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:44:34,766]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:44:37,718]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:44:38,474]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:44:40,571]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:44:44,336]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:44:44,508]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:44:47,299]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:44:57,203]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:44:57,817]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:45:00,970]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:45:04,251]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:45:04,826]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:45:12,786]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:45:15,232]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:45:17,017]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:45:19,031]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:45:24,498]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:45:28,865]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:45:29,876]\u001b[0m Trial 709 finished with value: 2.030379363580345 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007668387083448031, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22159898482920262, 'dropout_rate_Layer_2': 0.35631073703135757, 'dropout_rate_Layer_3': 0.08974144116222797, 'dropout_rate_Layer_4': 0.36819445402689255, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0817533943445475, 'l1_Layer_2': 0.0590711872443565, 'l1_Layer_3': 1.5149989079590094e-05, 'l1_Layer_4': 3.157248204851244e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 285, 'n_units_Layer_3': 80, 'n_units_Layer_4': 130}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 6.21% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.03 | sMAPE for Test Set is: 72.47% | rMAE for Test Set is: 2.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:45:34,580]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:45:36,680]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:45:42,841]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:45:44,506]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:45:48,984]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:45:53,073]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:45:59,016]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:02,087]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:05,791]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:11,737]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:14,434]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:15,717]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:20,498]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:25,428]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:28,892]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:29,199]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:34,132]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:34,159]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:34,531]\u001b[0m Trial 725 finished with value: 2.0575193673449967 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009263912573141883, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3160880256306139, 'dropout_rate_Layer_2': 0.04931539408883957, 'dropout_rate_Layer_3': 0.291705349478393, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.016042140755299937, 'l1_Layer_2': 0.0013109619305908574, 'l1_Layer_3': 1.808928319276086e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 290, 'n_units_Layer_3': 255}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.79 | sMAPE for Test Set is: 84.73% | rMAE for Test Set is: 2.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:46:34,752]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:40,832]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:42,490]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:45,467]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:45,651]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:45,864]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:47,162]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:52,444]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:55,818]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:57,083]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:46:58,704]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:00,335]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:02,463]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:04,343]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:10,854]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:11,624]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:17,346]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:17,906]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:18,475]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:22,873]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:23,437]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:27,448]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:27,928]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:28,143]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:33,703]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:37,267]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:37,401]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:41,600]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:48,325]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:51,792]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:54,603]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:56,156]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:57,949]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:47:58,596]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:02,606]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:02,912]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:03,869]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:09,915]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:10,077]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:10,410]\u001b[0m Trial 769 finished with value: 2.061720761309345 and parameters: {'n_hidden': 3, 'learning_rate': 0.0040659616908684465, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01991883066344984, 'dropout_rate_Layer_2': 0.21715767010660642, 'dropout_rate_Layer_3': 0.23340070439298746, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.029360871753204534, 'l1_Layer_2': 0.01887468167645564, 'l1_Layer_3': 0.00013165855047716048, 'n_units_Layer_1': 255, 'n_units_Layer_2': 125, 'n_units_Layer_3': 265}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.33% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.31 | sMAPE for Test Set is: 33.78% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:48:16,510]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:16,917]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:20,835]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:20,975]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:22,325]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:27,597]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:28,602]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:32,375]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:36,231]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:38,452]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:41,053]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:43,548]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:47,182]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:49,702]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:49,832]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:51,947]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.27 | sMAPE for Validation Set is: 6.90% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 16.29 | sMAPE for Test Set is: 105.32% | rMAE for Test Set is: 4.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:48:53,513]\u001b[0m Trial 779 finished with value: 2.27256866938131 and parameters: {'n_hidden': 3, 'learning_rate': 0.016838481060501672, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11467705515537471, 'dropout_rate_Layer_2': 0.027562613329837317, 'dropout_rate_Layer_3': 0.3400717023838363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.692473083645503e-05, 'l1_Layer_2': 2.5922933658285288e-05, 'l1_Layer_3': 0.015546699632096407, 'n_units_Layer_1': 155, 'n_units_Layer_2': 85, 'n_units_Layer_3': 115}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:48:58,222]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:49:00,911]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:49:01,381]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:49:02,369]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:49:05,341]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:49:09,864]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:49:14,044]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:49:17,979]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:49:27,537]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:49:32,060]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:49:35,030]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:49:43,519]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:49:46,563]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:49:46,629]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:49:51,762]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:49:53,412]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:49:56,223]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:00,209]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:03,064]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:07,201]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:11,954]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:12,183]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:17,676]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:18,370]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:21,105]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:22,822]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:26,837]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:27,011]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:29,924]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:32,923]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:35,428]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:37,960]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:40,866]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:45,508]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:45,715]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:50:49,121]\u001b[0m Trial 804 finished with value: 1.953481367167148 and parameters: {'n_hidden': 3, 'learning_rate': 0.003293619971336664, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06930890706500123, 'dropout_rate_Layer_2': 0.11535197810123676, 'dropout_rate_Layer_3': 0.3131725752400093, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003213109784815767, 'l1_Layer_2': 0.008804283015502087, 'l1_Layer_3': 1.4714554660148208e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 275, 'n_units_Layer_3': 265}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.97% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 10.32 | sMAPE for Test Set is: 85.86% | rMAE for Test Set is: 3.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:50:54,206]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:51:01,230]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:51:04,256]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:51:15,201]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:51:19,120]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:51:19,873]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:51:36,515]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:51:41,269]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:51:50,299]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:51:56,692]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:52:05,260]\u001b[0m Trial 839 finished with value: 2.1190112431400094 and parameters: {'n_hidden': 3, 'learning_rate': 0.022132796450153393, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04964084237314262, 'dropout_rate_Layer_2': 0.010424869665169718, 'dropout_rate_Layer_3': 0.33067513257831416, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002297249895285943, 'l1_Layer_2': 1.9635206350236656e-05, 'l1_Layer_3': 0.003941239467030235, 'n_units_Layer_1': 120, 'n_units_Layer_2': 60, 'n_units_Layer_3': 100}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 6.43% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 14.85 | sMAPE for Test Set is: 101.49% | rMAE for Test Set is: 4.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:52:08,120]\u001b[0m Trial 828 finished with value: 2.0905865670049657 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006263178785387032, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17510996001146933, 'dropout_rate_Layer_2': 0.0016008833574083711, 'dropout_rate_Layer_3': 0.2484139655705338, 'dropout_rate_Layer_4': 0.1731612013245648, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00035755257561660144, 'l1_Layer_2': 0.0009176665393995761, 'l1_Layer_3': 2.466351191411094e-05, 'l1_Layer_4': 0.0015132835311308813, 'n_units_Layer_1': 275, 'n_units_Layer_2': 125, 'n_units_Layer_3': 210, 'n_units_Layer_4': 255}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 6.38% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.01 | sMAPE for Test Set is: 96.72% | rMAE for Test Set is: 3.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:52:08,940]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:52:15,494]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:52:15,999]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:52:31,683]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:52:47,922]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:52:50,066]\u001b[0m Trial 837 finished with value: 2.0380738853609093 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023264803286213703, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07064709231854983, 'dropout_rate_Layer_2': 0.10449783144571298, 'dropout_rate_Layer_3': 0.31110755188686057, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002840568210414179, 'l1_Layer_2': 0.006264318351159765, 'l1_Layer_3': 1.5396185154974387e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 125, 'n_units_Layer_3': 265}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 6.13% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.17 | sMAPE for Test Set is: 77.79% | rMAE for Test Set is: 2.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:52:53,157]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:53:13,257]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:53:15,066]\u001b[0m Trial 850 finished with value: 2.115619566800208 and parameters: {'n_hidden': 4, 'learning_rate': 0.000717767053631504, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23626088870348275, 'dropout_rate_Layer_2': 0.30897745262356935, 'dropout_rate_Layer_3': 0.3639146561517359, 'dropout_rate_Layer_4': 0.3899917519067143, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.07926789883554491, 'l1_Layer_2': 0.000882806159169085, 'l1_Layer_3': 2.5312497794109685e-05, 'l1_Layer_4': 9.673982976253674e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 285, 'n_units_Layer_3': 65, 'n_units_Layer_4': 170}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 6.41% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.73 | sMAPE for Test Set is: 84.49% | rMAE for Test Set is: 2.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:53:21,701]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:53:27,875]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:53:28,207]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:53:34,992]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:53:36,805]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:53:38,725]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:53:41,437]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:53:45,877]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:53:50,139]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:53:53,075]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:53:56,307]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:54:01,412]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:54:03,850]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:54:05,920]\u001b[0m Trial 848 finished with value: 2.010967199114226 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006090866636684695, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09602512141863562, 'dropout_rate_Layer_2': 0.03327405889973292, 'dropout_rate_Layer_3': 0.24281951527461337, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003377651159274005, 'l1_Layer_2': 0.0009340283541230798, 'l1_Layer_3': 2.0439765899946585e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 290, 'n_units_Layer_3': 265}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 6.09% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.94 | sMAPE for Test Set is: 88.68% | rMAE for Test Set is: 3.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:54:09,439]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:54:10,473]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:54:14,195]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:54:14,718]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:54:15,450]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:54:27,420]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:54:30,452]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:54:32,609]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:54:36,051]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:54:37,952]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:54:40,423]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:54:43,877]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:54:46,490]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:54:53,381]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:54:56,781]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:55:00,002]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:55:05,935]\u001b[0m Trial 851 finished with value: 2.0369569692576177 and parameters: {'n_hidden': 3, 'learning_rate': 0.001192925535141742, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10355868921727848, 'dropout_rate_Layer_2': 0.03492489457848072, 'dropout_rate_Layer_3': 0.2682928106057322, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000730926732060855, 'l1_Layer_2': 0.0009006256377172788, 'l1_Layer_3': 2.3710321744687325e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 290, 'n_units_Layer_3': 265}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 6.17% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.35 | sMAPE for Test Set is: 86.51% | rMAE for Test Set is: 3.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:55:15,586]\u001b[0m Trial 872 finished with value: 2.1071480190687333 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007472015438455731, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22117783167510735, 'dropout_rate_Layer_2': 0.33791744815984087, 'dropout_rate_Layer_3': 0.3658050914554183, 'dropout_rate_Layer_4': 0.39076929453982195, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.07133688007391306, 'l1_Layer_2': 0.001232648207398673, 'l1_Layer_3': 1.709480234212489e-05, 'l1_Layer_4': 0.0011333817854454072, 'n_units_Layer_1': 280, 'n_units_Layer_2': 285, 'n_units_Layer_3': 60, 'n_units_Layer_4': 165}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 6.41% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.82 | sMAPE for Test Set is: 76.20% | rMAE for Test Set is: 2.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:55:20,497]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:55:20,624]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:55:23,412]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:55:25,755]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:55:25,976]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:55:26,126]\u001b[0m Trial 879 finished with value: 2.0257828351061664 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007539102077251004, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22239908153457377, 'dropout_rate_Layer_2': 0.3192650056370128, 'dropout_rate_Layer_3': 0.365280025519941, 'dropout_rate_Layer_4': 0.39413592773603, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.07490942979467746, 'l1_Layer_2': 0.0011513102354681845, 'l1_Layer_3': 2.0879791129241658e-05, 'l1_Layer_4': 0.00012085778542218554, 'n_units_Layer_1': 240, 'n_units_Layer_2': 285, 'n_units_Layer_3': 70, 'n_units_Layer_4': 165}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 6.18% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.61 | sMAPE for Test Set is: 84.01% | rMAE for Test Set is: 2.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:55:26,779]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:55:33,149]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:55:34,935]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:55:37,650]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:55:42,699]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:55:45,125]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:55:49,607]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:55:52,680]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:56:07,840]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:56:13,427]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:56:17,205]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:56:20,287]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:56:20,325]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:56:26,844]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:56:30,363]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:56:32,012]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:56:35,352]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:56:37,686]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:56:41,505]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:56:44,759]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:56:47,433]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:56:52,657]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:56:55,094]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:56:55,623]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:57:01,047]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:57:04,272]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:57:07,758]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:57:08,346]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:57:21,541]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:57:25,756]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:57:30,850]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:57:36,225]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:57:39,409]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:57:43,704]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:57:44,130]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:57:49,891]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:57:52,831]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:57:55,081]\u001b[0m Trial 912 finished with value: 1.9970790250030532 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038855383520664463, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05300637404007702, 'dropout_rate_Layer_2': 0.09702851943566998, 'dropout_rate_Layer_3': 0.2881072278986925, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006995329070785534, 'l1_Layer_2': 0.001569880410195759, 'l1_Layer_3': 1.3818198352182241e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 250, 'n_units_Layer_3': 245}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 6.10% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.58 | sMAPE for Test Set is: 87.87% | rMAE for Test Set is: 3.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:57:56,571]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:57:58,759]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:00,741]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:10,481]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:15,565]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:17,559]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:18,160]\u001b[0m Trial 920 finished with value: 1.9984171423654538 and parameters: {'n_hidden': 3, 'learning_rate': 0.004526795043298733, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04256389680990948, 'dropout_rate_Layer_2': 0.18811888812045255, 'dropout_rate_Layer_3': 0.23552542438646928, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006395066951528091, 'l1_Layer_2': 0.0016074608555991248, 'l1_Layer_3': 1.3835130986190753e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 250, 'n_units_Layer_3': 245}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 6.06% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.75 | sMAPE for Test Set is: 84.63% | rMAE for Test Set is: 2.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:58:21,711]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:22,987]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:28,458]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:30,383]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:31,435]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:35,134]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:37,749]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:41,885]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:42,706]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:43,433]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:48,945]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:50,323]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:51,380]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:53,188]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:57,212]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:58:59,605]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:59:09,272]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:59:11,575]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:59:15,767]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:59:16,124]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:59:23,716]\u001b[0m Trial 940 finished with value: 2.0834829801864903 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008762443650690387, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3617047196330916, 'dropout_rate_Layer_2': 0.34813848233524525, 'dropout_rate_Layer_3': 0.37320858448647004, 'dropout_rate_Layer_4': 0.25701231690438736, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.06965523692123346, 'l1_Layer_2': 0.0024260350329524906, 'l1_Layer_3': 0.03598067618452617, 'l1_Layer_4': 0.0008860040194457365, 'n_units_Layer_1': 260, 'n_units_Layer_2': 295, 'n_units_Layer_3': 70, 'n_units_Layer_4': 170}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.31% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 12.64 | sMAPE for Test Set is: 94.52% | rMAE for Test Set is: 3.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 02:59:28,867]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:59:34,093]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:59:38,315]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:59:42,584]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:59:48,030]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 02:59:52,105]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:00:02,413]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:00:04,815]\u001b[0m Trial 955 finished with value: 2.0322649589730375 and parameters: {'n_hidden': 4, 'learning_rate': 0.00072043987048561, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.234848493892113, 'dropout_rate_Layer_2': 0.3240258990565194, 'dropout_rate_Layer_3': 0.3597994016984158, 'dropout_rate_Layer_4': 0.38974720520469247, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009490496122213062, 'l1_Layer_2': 0.001984807889632856, 'l1_Layer_3': 0.004801857813861151, 'l1_Layer_4': 4.015504459847922e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 175, 'n_units_Layer_3': 65, 'n_units_Layer_4': 260}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 6.21% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.89 | sMAPE for Test Set is: 76.60% | rMAE for Test Set is: 2.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:00:08,888]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:00:10,246]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:00:15,095]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:00:24,350]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:00:27,794]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:00:32,763]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:00:38,271]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:00:38,383]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:00:44,979]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:00:48,158]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:00:48,794]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:01:00,065]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:01:04,023]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:01:04,219]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:01:13,323]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:01:15,021]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:01:19,752]\u001b[0m Trial 957 finished with value: 1.9457688307495757 and parameters: {'n_hidden': 3, 'learning_rate': 0.003905043478997409, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06223993644927577, 'dropout_rate_Layer_2': 0.14039222946250296, 'dropout_rate_Layer_3': 0.2396140959680418, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001230407605222544, 'l1_Layer_2': 0.0017065071602428857, 'l1_Layer_3': 3.8442061209113186e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 250, 'n_units_Layer_3': 255}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.94% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 9.47 | sMAPE for Test Set is: 83.39% | rMAE for Test Set is: 2.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:01:29,236]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:01:32,772]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:01:43,256]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:01:49,725]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:01:55,298]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:01:58,921]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:02:01,865]\u001b[0m Trial 970 finished with value: 1.9827800706156584 and parameters: {'n_hidden': 3, 'learning_rate': 0.003999232000063084, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015834829611509074, 'dropout_rate_Layer_2': 0.13844025084579928, 'dropout_rate_Layer_3': 0.2391878560647951, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011391882242949214, 'l1_Layer_2': 0.003349105660302889, 'l1_Layer_3': 1.2866686532541066e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 255, 'n_units_Layer_3': 250}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 6.03% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.52 | sMAPE for Test Set is: 83.94% | rMAE for Test Set is: 2.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:02:06,548]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:02:09,412]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:02:12,676]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:02:16,899]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:02:17,758]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:02:22,128]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:02:25,036]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:02:28,366]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:02:31,103]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:02:32,165]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:02:32,353]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:02:37,191]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:02:40,710]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:02:41,841]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:02:46,057]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:06,072]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:10,765]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:13,693]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:13,998]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:19,624]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:20,090]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:20,515]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:27,843]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:29,812]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:33,259]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:33,964]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:35,521]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:39,546]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:40,911]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:42,044]\u001b[0m Trial 993 finished with value: 2.0039757036740995 and parameters: {'n_hidden': 3, 'learning_rate': 0.004136532642583192, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015656837299078102, 'dropout_rate_Layer_2': 0.14533128073493531, 'dropout_rate_Layer_3': 0.2329490539603601, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001133934135444135, 'l1_Layer_2': 0.0028100947331336505, 'l1_Layer_3': 3.9920730838273394e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 225, 'n_units_Layer_3': 230}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 6.08% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.11 | sMAPE for Test Set is: 71.99% | rMAE for Test Set is: 2.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:03:44,661]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:47,889]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:53,569]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:03:56,083]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:01,380]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:04,274]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:05,407]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:10,444]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:10,827]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:15,365]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:17,453]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:18,046]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:21,040]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:24,509]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:25,511]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:26,028]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:29,068]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:37,349]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:39,079]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:40,373]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:42,590]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:46,197]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:46,821]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:54,429]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:54,527]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:04:54,831]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:05:09,312]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:05:13,435]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:05:13,994]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:05:18,770]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:05:30,638]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:05:33,593]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:05:36,659]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:05:39,529]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:05:44,070]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:05:48,688]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:06:00,615]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:06:09,103]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:06:11,650]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:06:16,766]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:06:21,682]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:06:24,857]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:06:29,663]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:06:33,732]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:06:35,577]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:06:37,799]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:06:40,114]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:06:43,873]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:06:43,945]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:06:50,370]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:06:54,266]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:07:01,390]\u001b[0m Trial 1056 finished with value: 2.0762497650888823 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005993540987536353, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23741396634860257, 'dropout_rate_Layer_2': 0.32648160868517706, 'dropout_rate_Layer_3': 0.3577412465523477, 'dropout_rate_Layer_4': 0.3743216940497746, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.08715109990058074, 'l1_Layer_2': 0.0016956020158315755, 'l1_Layer_3': 0.008296915145280017, 'l1_Layer_4': 1.3073115073830605e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 290, 'n_units_Layer_3': 75, 'n_units_Layer_4': 165}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.32% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.28 | sMAPE for Test Set is: 86.53% | rMAE for Test Set is: 3.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:07:01,787]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:07:02,732]\u001b[0m Trial 1057 finished with value: 2.1531946895553187 and parameters: {'n_hidden': 3, 'learning_rate': 0.004464667535517834, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04689128781836838, 'dropout_rate_Layer_2': 0.002592731727222871, 'dropout_rate_Layer_3': 0.05849363186146951, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009940647789155224, 'l1_Layer_2': 5.662030562777352e-05, 'l1_Layer_3': 0.0010731897794978406, 'n_units_Layer_1': 280, 'n_units_Layer_2': 120, 'n_units_Layer_3': 85}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.15 | sMAPE for Validation Set is: 6.54% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.91 | sMAPE for Test Set is: 92.91% | rMAE for Test Set is: 3.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:07:12,093]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:07:13,680]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:07:14,794]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:07:15,193]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:07:21,918]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:07:22,515]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:07:23,361]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:07:28,067]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:07:51,507]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:07:54,725]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:08:01,929]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:08:06,042]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:08:06,746]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:08:06,816]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:08:13,897]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:08:20,322]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:08:20,912]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:08:24,497]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:08:28,202]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:08:44,660]\u001b[0m Trial 1087 finished with value: 2.02693795573112 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006136792362023241, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2328104134441833, 'dropout_rate_Layer_2': 0.32128059292629935, 'dropout_rate_Layer_3': 0.024482956522437718, 'dropout_rate_Layer_4': 0.1924603303307422, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02282884539349082, 'l1_Layer_2': 0.0013381240690980218, 'l1_Layer_3': 0.005911494375764631, 'l1_Layer_4': 1.674122183758874e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 280, 'n_units_Layer_3': 80, 'n_units_Layer_4': 130}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 6.19% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.62 | sMAPE for Test Set is: 75.42% | rMAE for Test Set is: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:08:49,067]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:09:01,998]\u001b[0m Trial 1088 finished with value: 2.018617706538579 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005922905162380506, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22536669206541873, 'dropout_rate_Layer_2': 0.32179848458608823, 'dropout_rate_Layer_3': 0.024898125299796327, 'dropout_rate_Layer_4': 0.2764681235933647, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.022797894326960177, 'l1_Layer_2': 0.0012037710476994013, 'l1_Layer_3': 1.901956664142823e-05, 'l1_Layer_4': 1.3625271465017672e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 270, 'n_units_Layer_3': 75, 'n_units_Layer_4': 165}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 6.19% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.06 | sMAPE for Test Set is: 85.67% | rMAE for Test Set is: 3.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:09:06,403]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:09:21,635]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:09:27,047]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:09:31,368]\u001b[0m Trial 1094 finished with value: 2.068614375471403 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005690382158270255, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24862736540889985, 'dropout_rate_Layer_2': 0.03914327787340188, 'dropout_rate_Layer_3': 0.020176644128881236, 'dropout_rate_Layer_4': 0.3621631925548933, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02384471604592354, 'l1_Layer_2': 0.001244249178639056, 'l1_Layer_3': 0.05588144178094092, 'l1_Layer_4': 1.6367482877742614e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 285, 'n_units_Layer_3': 95, 'n_units_Layer_4': 160}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 11.24 | sMAPE for Test Set is: 89.95% | rMAE for Test Set is: 3.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:09:32,036]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:09:40,482]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:09:52,284]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:09:57,052]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:10:00,254]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:10:02,466]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:10:07,300]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:10:13,886]\u001b[0m Trial 1096 finished with value: 2.0506089367946427 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005797957570034383, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24880226445296347, 'dropout_rate_Layer_2': 0.3315356934483359, 'dropout_rate_Layer_3': 0.025500920727011194, 'dropout_rate_Layer_4': 0.18063685566313714, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.023749699823249027, 'l1_Layer_2': 0.0013575945390528123, 'l1_Layer_3': 0.0037941082889340495, 'l1_Layer_4': 1.6213537785067474e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 270, 'n_units_Layer_3': 90, 'n_units_Layer_4': 160}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 6.26% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 11.61 | sMAPE for Test Set is: 91.13% | rMAE for Test Set is: 3.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:10:16,157]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:10:22,004]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:10:27,762]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:10:45,809]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:10:48,740]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.29% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 10.36 | sMAPE for Test Set is: 87.08% | rMAE for Test Set is: 3.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:10:52,871]\u001b[0m Trial 1107 finished with value: 2.0789401318019105 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005678952453657714, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2341470488373748, 'dropout_rate_Layer_2': 0.02505460124484378, 'dropout_rate_Layer_3': 0.03641332366704964, 'dropout_rate_Layer_4': 0.3518770082661904, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03203959164632933, 'l1_Layer_2': 0.0011510038735724364, 'l1_Layer_3': 1.961078967726205e-05, 'l1_Layer_4': 1.4506294386084032e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 280, 'n_units_Layer_3': 75, 'n_units_Layer_4': 160}. Best is trial 529 with value: 1.9382710741796083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:10:56,701]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:10:57,176]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:03,289]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:07,101]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:09,946]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:11,671]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:13,609]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:16,628]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:19,341]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:20,184]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:20,606]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:28,431]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:32,027]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:33,775]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:37,915]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:38,658]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:39,581]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:44,878]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:48,180]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:49,566]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:51,892]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:57,152]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:11:58,686]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:12:00,374]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:12:01,974]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:12:15,453]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:12:20,539]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:12:32,569]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:12:52,879]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:13:19,736]\u001b[0m Trial 1118 finished with value: 1.9112447146241671 and parameters: {'n_hidden': 3, 'learning_rate': 0.004313618887289619, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.056994589015069985, 'dropout_rate_Layer_2': 0.14181452000031056, 'dropout_rate_Layer_3': 0.2856344595951192, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013052173537835762, 'l1_Layer_2': 0.0010337746173240477, 'l1_Layer_3': 1.6289826250013174e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.85% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 11.04 | sMAPE for Test Set is: 89.72% | rMAE for Test Set is: 3.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:13:24,264]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:13:28,148]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:13:31,885]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:13:33,226]\u001b[0m Trial 1142 finished with value: 2.0148234299041703 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005137555405384549, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24976072932066276, 'dropout_rate_Layer_2': 0.008661824268896588, 'dropout_rate_Layer_3': 0.02611475279978197, 'dropout_rate_Layer_4': 0.17647853830057003, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.020661097349704723, 'l1_Layer_2': 0.0014374827489022522, 'l1_Layer_3': 0.004204912223489972, 'l1_Layer_4': 1.056192363549046e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 285, 'n_units_Layer_3': 70, 'n_units_Layer_4': 150}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 6.16% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.99 | sMAPE for Test Set is: 77.14% | rMAE for Test Set is: 2.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:13:36,641]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:13:38,552]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:13:42,106]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:13:44,881]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:13:45,719]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:13:52,879]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:14:05,662]\u001b[0m Trial 1139 finished with value: 2.0689461168896552 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005063865189047205, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2504104737125455, 'dropout_rate_Layer_2': 0.004022924556746816, 'dropout_rate_Layer_3': 0.02473025505882957, 'dropout_rate_Layer_4': 0.3518809387397826, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01795278928707398, 'l1_Layer_2': 0.0014392811183421472, 'l1_Layer_3': 0.004039101098067824, 'l1_Layer_4': 1.1665442643939912e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 285, 'n_units_Layer_3': 70, 'n_units_Layer_4': 150}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.30% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.77 | sMAPE for Test Set is: 84.80% | rMAE for Test Set is: 2.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:14:31,370]\u001b[0m Trial 1144 finished with value: 2.059822521982246 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005010423626852254, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2467122857979631, 'dropout_rate_Layer_2': 0.030597506452400572, 'dropout_rate_Layer_3': 0.02701224284172528, 'dropout_rate_Layer_4': 0.350029900624795, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.034532823139875775, 'l1_Layer_2': 0.001414729480699921, 'l1_Layer_3': 0.004021069094363511, 'l1_Layer_4': 1.0763861164064616e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 285, 'n_units_Layer_3': 70, 'n_units_Layer_4': 150}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.07 | sMAPE for Test Set is: 85.74% | rMAE for Test Set is: 3.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:14:34,395]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:14:46,347]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:14:57,081]\u001b[0m Trial 1155 finished with value: 2.076073746414824 and parameters: {'n_hidden': 3, 'learning_rate': 0.004435733936375889, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06666863863081826, 'dropout_rate_Layer_2': 3.14753660683835e-05, 'dropout_rate_Layer_3': 0.050740467717195675, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011819522235124006, 'l1_Layer_2': 6.713427530195277e-05, 'l1_Layer_3': 0.0018203192928265648, 'n_units_Layer_1': 280, 'n_units_Layer_2': 105, 'n_units_Layer_3': 60}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.35% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.55 | sMAPE for Test Set is: 84.23% | rMAE for Test Set is: 2.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:15:03,134]\u001b[0m Trial 1153 finished with value: 1.9903845297158098 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005142897679519771, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25283746264166956, 'dropout_rate_Layer_2': 0.0075870931408972345, 'dropout_rate_Layer_3': 0.024548460197561937, 'dropout_rate_Layer_4': 0.18498466550331213, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01890153159045244, 'l1_Layer_2': 0.0013850464506044902, 'l1_Layer_3': 1.7595499980411463e-05, 'l1_Layer_4': 1.0173508228726043e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 285, 'n_units_Layer_3': 75, 'n_units_Layer_4': 145}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.99 | sMAPE for Validation Set is: 6.11% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.99 | sMAPE for Test Set is: 85.56% | rMAE for Test Set is: 3.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:15:28,420]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:15:29,042]\u001b[0m Trial 1158 finished with value: 2.016882649284945 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005044083725318871, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24934811506132876, 'dropout_rate_Layer_2': 0.03901390170696216, 'dropout_rate_Layer_3': 0.025469104500816908, 'dropout_rate_Layer_4': 0.35105636968412796, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03234823833752597, 'l1_Layer_2': 0.0014372062511348032, 'l1_Layer_3': 0.003587571519936918, 'l1_Layer_4': 1.1287038374260984e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 280, 'n_units_Layer_3': 70, 'n_units_Layer_4': 145}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 6.17% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.85 | sMAPE for Test Set is: 76.56% | rMAE for Test Set is: 2.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:15:34,738]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:15:38,171]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:15:52,909]\u001b[0m Trial 1160 finished with value: 2.0348277733357034 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005018546901277536, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2506231152565432, 'dropout_rate_Layer_2': 0.009524417115002829, 'dropout_rate_Layer_3': 0.02411059463438524, 'dropout_rate_Layer_4': 0.16002204531845204, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03225170381284608, 'l1_Layer_2': 0.0014494187135520528, 'l1_Layer_3': 0.004274792101317621, 'l1_Layer_4': 1.0556900560798248e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 285, 'n_units_Layer_3': 70, 'n_units_Layer_4': 145}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 6.23% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.90 | sMAPE for Test Set is: 71.82% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:16:03,418]\u001b[0m Trial 1159 finished with value: 2.0262829649470593 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005285224935272061, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25308698784207057, 'dropout_rate_Layer_2': 0.03727358699296108, 'dropout_rate_Layer_3': 0.02434051827137293, 'dropout_rate_Layer_4': 0.1628393971933717, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.019798699211458236, 'l1_Layer_2': 0.0014412199638217712, 'l1_Layer_3': 0.0030126241436727458, 'l1_Layer_4': 1.1084752782533079e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 285, 'n_units_Layer_3': 70, 'n_units_Layer_4': 145}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 6.19% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.15 | sMAPE for Test Set is: 82.29% | rMAE for Test Set is: 2.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:16:31,205]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:16:35,997]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:16:43,148]\u001b[0m Trial 1163 finished with value: 2.0491278583777017 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005134570049715825, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25377593650885905, 'dropout_rate_Layer_2': 0.043489219357025384, 'dropout_rate_Layer_3': 0.0265160031406415, 'dropout_rate_Layer_4': 0.3444129342399617, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.036501952315185306, 'l1_Layer_2': 0.0013668461483843065, 'l1_Layer_3': 0.003704657336468469, 'l1_Layer_4': 1.0234632440023654e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 285, 'n_units_Layer_3': 70, 'n_units_Layer_4': 150}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 6.25% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.99 | sMAPE for Test Set is: 81.47% | rMAE for Test Set is: 2.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:16:50,823]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:16:51,516]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:16:57,225]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:17:01,703]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:17:01,876]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:17:08,498]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:17:08,911]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:17:15,036]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:17:15,066]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:17:21,994]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:17:25,136]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:17:30,550]\u001b[0m Trial 1166 finished with value: 2.022232367619456 and parameters: {'n_hidden': 3, 'learning_rate': 0.003706297415905945, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026573201888631326, 'dropout_rate_Layer_2': 0.18551337584210925, 'dropout_rate_Layer_3': 0.30139893924681066, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002320344569639689, 'l1_Layer_2': 0.002917454127769764, 'l1_Layer_3': 1.6546874626604462e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 255, 'n_units_Layer_3': 265}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 6.15% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.93 | sMAPE for Test Set is: 71.77% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:17:34,189]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:17:37,013]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:17:40,469]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:17:40,731]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:17:46,611]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:17:50,713]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:17:59,190]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:18:02,227]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:18:09,389]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:18:14,861]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:18:18,124]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:18:31,513]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:18:35,792]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:18:39,155]\u001b[0m Trial 1176 finished with value: 2.069912578540141 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005043200602047142, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25264010914368834, 'dropout_rate_Layer_2': 0.019624423930980885, 'dropout_rate_Layer_3': 0.008315500402013294, 'dropout_rate_Layer_4': 0.150241022637418, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.024038960843849436, 'l1_Layer_2': 0.0012745895749733066, 'l1_Layer_3': 0.003219413447267909, 'l1_Layer_4': 1.36338505417569e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 280, 'n_units_Layer_3': 80, 'n_units_Layer_4': 140}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.29% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.68 | sMAPE for Test Set is: 80.13% | rMAE for Test Set is: 2.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:18:39,766]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:18:45,955]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:18:55,827]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:18:58,736]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:19:02,583]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:19:06,634]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:19:13,432]\u001b[0m Trial 1190 finished with value: 2.079711814299642 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005166504168029329, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25386976617323137, 'dropout_rate_Layer_2': 0.019131547467393584, 'dropout_rate_Layer_3': 0.008820078844406495, 'dropout_rate_Layer_4': 0.34856480503730247, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.023470287036239993, 'l1_Layer_2': 0.0012666887701297525, 'l1_Layer_3': 0.0045034591406409585, 'l1_Layer_4': 1.3142790331961107e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 280, 'n_units_Layer_3': 80, 'n_units_Layer_4': 140}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.31% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.82 | sMAPE for Test Set is: 84.99% | rMAE for Test Set is: 2.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:19:13,719]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:19:19,137]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:19:20,067]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:19:20,069]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:19:26,362]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:19:33,391]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:19:36,967]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:19:40,839]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:19:44,814]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:19:56,630]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:20:19,221]\u001b[0m Trial 1202 finished with value: 2.036515490631373 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005012615799197071, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2642688227375065, 'dropout_rate_Layer_2': 0.047301675873304194, 'dropout_rate_Layer_3': 0.01735782626005951, 'dropout_rate_Layer_4': 0.16522176928896265, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.022496027786313662, 'l1_Layer_2': 0.0010414781826028577, 'l1_Layer_3': 0.0029849565370410626, 'l1_Layer_4': 1.5756085394023426e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 295, 'n_units_Layer_3': 75, 'n_units_Layer_4': 135}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 6.22% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.08 | sMAPE for Test Set is: 81.98% | rMAE for Test Set is: 2.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:20:23,904]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:20:27,791]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:20:33,468]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:20:40,086]\u001b[0m Trial 1206 finished with value: 2.0058575639600416 and parameters: {'n_hidden': 3, 'learning_rate': 0.003557733858969649, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011884784424517389, 'dropout_rate_Layer_2': 0.2620162498565534, 'dropout_rate_Layer_3': 0.262362060054678, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005919355607064811, 'l1_Layer_2': 0.002926104957281155, 'l1_Layer_3': 1.7256929323239038e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 240, 'n_units_Layer_3': 255}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 6.10% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.63 | sMAPE for Test Set is: 80.10% | rMAE for Test Set is: 2.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:20:41,101]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:20:53,346]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:21:00,352]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:21:14,318]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:21:15,467]\u001b[0m Trial 1213 finished with value: 2.0417847517970773 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005071541127471222, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26082866099493396, 'dropout_rate_Layer_2': 0.047421571442842265, 'dropout_rate_Layer_3': 0.006140845451957717, 'dropout_rate_Layer_4': 0.34498653276042635, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02281318582470443, 'l1_Layer_2': 0.0017254476637940345, 'l1_Layer_3': 0.0029710940403908735, 'l1_Layer_4': 1.5289555438681023e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 295, 'n_units_Layer_3': 65, 'n_units_Layer_4': 135}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 6.23% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.81 | sMAPE for Test Set is: 80.75% | rMAE for Test Set is: 2.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:21:18,596]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:21:22,066]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:21:22,431]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:21:23,329]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:21:31,716]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:21:31,758]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:21:39,532]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:21:53,948]\u001b[0m Trial 1219 finished with value: 2.052212566836586 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005009538806450735, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26298946989189925, 'dropout_rate_Layer_2': 0.01325046077366646, 'dropout_rate_Layer_3': 0.0170155356367366, 'dropout_rate_Layer_4': 0.1637790656634016, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.018794582518546148, 'l1_Layer_2': 0.0010381865766013367, 'l1_Layer_3': 0.003093470888192985, 'l1_Layer_4': 1.537075734244663e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 300, 'n_units_Layer_3': 75, 'n_units_Layer_4': 140}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 6.26% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.93 | sMAPE for Test Set is: 76.90% | rMAE for Test Set is: 2.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:21:56,741]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:22:06,387]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:22:58,623]\u001b[0m Trial 1231 finished with value: 2.071360952441253 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005034801647880403, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26844128582568383, 'dropout_rate_Layer_2': 0.0008526880101866405, 'dropout_rate_Layer_3': 0.01736993177647559, 'dropout_rate_Layer_4': 0.16036113590217507, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.026779836812748474, 'l1_Layer_2': 0.002214107332653554, 'l1_Layer_3': 0.002848062143460756, 'l1_Layer_4': 1.6619556323709706e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 300, 'n_units_Layer_3': 75, 'n_units_Layer_4': 135}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.30% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.37 | sMAPE for Test Set is: 83.12% | rMAE for Test Set is: 2.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:23:05,258]\u001b[0m Trial 1230 finished with value: 2.0241315415984427 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005028567897120017, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2644764217282282, 'dropout_rate_Layer_2': 0.013986417720788211, 'dropout_rate_Layer_3': 0.016908533795972364, 'dropout_rate_Layer_4': 0.3440483543879768, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.027196424509183876, 'l1_Layer_2': 0.0023114358854582386, 'l1_Layer_3': 0.002878638792057954, 'l1_Layer_4': 1.2968029230035603e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 295, 'n_units_Layer_3': 65, 'n_units_Layer_4': 125}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 6.18% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.55 | sMAPE for Test Set is: 75.07% | rMAE for Test Set is: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:23:11,175]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:23:16,615]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:23:19,738]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:23:24,563]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:23:28,103]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:23:31,646]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:23:34,738]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:23:52,027]\u001b[0m Trial 1228 finished with value: 2.0519844256921407 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005009197206692153, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25764589313105324, 'dropout_rate_Layer_2': 0.00042188646493131546, 'dropout_rate_Layer_3': 0.018482269208991195, 'dropout_rate_Layer_4': 0.3504968071067087, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02812764384982209, 'l1_Layer_2': 0.002345966897514758, 'l1_Layer_3': 0.002736315305089805, 'l1_Layer_4': 1.2591972951555343e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 295, 'n_units_Layer_3': 65, 'n_units_Layer_4': 135}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 6.26% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.73 | sMAPE for Test Set is: 84.63% | rMAE for Test Set is: 2.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:23:55,166]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:24:13,625]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:24:27,236]\u001b[0m Trial 1233 finished with value: 2.0238929837420443 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005071751968158294, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.263822348280245, 'dropout_rate_Layer_2': 0.0017811340900923977, 'dropout_rate_Layer_3': 0.018379027095097263, 'dropout_rate_Layer_4': 0.156267897470216, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.026853481361193053, 'l1_Layer_2': 0.001500966767544115, 'l1_Layer_3': 0.00293452958146555, 'l1_Layer_4': 1.703642936928629e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 300, 'n_units_Layer_3': 75, 'n_units_Layer_4': 135}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 6.19% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.82 | sMAPE for Test Set is: 84.87% | rMAE for Test Set is: 2.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:24:31,552]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:25:18,479]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:25:23,091]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:25:27,115]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.05 | sMAPE for Test Set is: 77.49% | rMAE for Test Set is: 2.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:25:28,713]\u001b[0m Trial 1244 finished with value: 2.0599667514502666 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005140679819550319, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2678263936228632, 'dropout_rate_Layer_2': 0.0004959787189411091, 'dropout_rate_Layer_3': 0.015233709626652605, 'dropout_rate_Layer_4': 0.1315749751328511, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02666502853612775, 'l1_Layer_2': 0.002125278820748082, 'l1_Layer_3': 0.003150532091306741, 'l1_Layer_4': 1.5749572083347137e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 300, 'n_units_Layer_3': 75, 'n_units_Layer_4': 125}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:25:31,753]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:25:42,489]\u001b[0m Trial 1245 finished with value: 2.077279061081245 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005036780562935182, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27810293437971195, 'dropout_rate_Layer_2': 0.0010628819992039434, 'dropout_rate_Layer_3': 0.00046502351556707185, 'dropout_rate_Layer_4': 0.3449375730977964, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02713665721489672, 'l1_Layer_2': 0.001982794895269161, 'l1_Layer_3': 0.003485768499117141, 'l1_Layer_4': 1.3143960457697376e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 300, 'n_units_Layer_3': 80, 'n_units_Layer_4': 135}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.29% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.22 | sMAPE for Test Set is: 82.56% | rMAE for Test Set is: 2.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:26:15,091]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:26:17,007]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:26:18,283]\u001b[0m Trial 1242 finished with value: 2.046169453715035 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005100298929592855, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2654647071728637, 'dropout_rate_Layer_2': 0.0010827650065271099, 'dropout_rate_Layer_3': 0.01564574523946907, 'dropout_rate_Layer_4': 0.12420040923314751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.018681794360872663, 'l1_Layer_2': 0.0026274757903175998, 'l1_Layer_3': 0.0027909442771978437, 'l1_Layer_4': 1.6968099059126493e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 300, 'n_units_Layer_3': 75, 'n_units_Layer_4': 135}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 6.23% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.63 | sMAPE for Test Set is: 88.00% | rMAE for Test Set is: 3.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:26:18,824]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:26:22,988]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:26:37,188]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:26:41,650]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:26:46,080]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:26:50,884]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:26:55,403]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:26:58,699]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:27:16,425]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:27:20,929]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:27:24,063]\u001b[0m Trial 1253 finished with value: 2.0237901483434535 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005777825886172119, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26501764789672216, 'dropout_rate_Layer_2': 0.010975028103739091, 'dropout_rate_Layer_3': 0.015166424923465744, 'dropout_rate_Layer_4': 0.1376335078635114, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.019459959997788982, 'l1_Layer_2': 0.0016075010474415703, 'l1_Layer_3': 0.002357916920262589, 'l1_Layer_4': 1.6756950624758734e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 295, 'n_units_Layer_3': 70, 'n_units_Layer_4': 120}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 6.18% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.34 | sMAPE for Test Set is: 78.76% | rMAE for Test Set is: 2.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:27:36,387]\u001b[0m Trial 1256 finished with value: 2.032572075215132 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005672123145144401, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2786463297624724, 'dropout_rate_Layer_2': 0.011295682311911128, 'dropout_rate_Layer_3': 0.01179821540823784, 'dropout_rate_Layer_4': 0.12808164267579702, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.016967466748260676, 'l1_Layer_2': 0.002139630649849212, 'l1_Layer_3': 0.0026248552245059418, 'l1_Layer_4': 2.3455531603507906e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 295, 'n_units_Layer_3': 70, 'n_units_Layer_4': 135}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 6.22% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 69.86% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:27:44,748]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:27:48,501]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:27:49,347]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:28:42,695]\u001b[0m Trial 1264 finished with value: 2.044418778352897 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005648134732496438, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28048985088217493, 'dropout_rate_Layer_2': 0.012162903116571307, 'dropout_rate_Layer_3': 0.012968115611790808, 'dropout_rate_Layer_4': 0.1281665106675768, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.016706568345957958, 'l1_Layer_2': 0.0023637897420203282, 'l1_Layer_3': 0.0023522571108699646, 'l1_Layer_4': 2.3914761922200227e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 295, 'n_units_Layer_3': 70, 'n_units_Layer_4': 130}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 6.25% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.28 | sMAPE for Test Set is: 78.45% | rMAE for Test Set is: 2.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:28:46,247]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:28:50,063]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:28:59,711]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:29:37,540]\u001b[0m Trial 1268 finished with value: 2.061917821632861 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033015127657531817, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04457928532610424, 'dropout_rate_Layer_2': 0.0015896146251272447, 'dropout_rate_Layer_3': 0.05997694765854837, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011199049904005816, 'l1_Layer_2': 6.543522782529414e-05, 'l1_Layer_3': 0.0011740698409670974, 'n_units_Layer_1': 280, 'n_units_Layer_2': 110, 'n_units_Layer_3': 80}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.23% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.92 | sMAPE for Test Set is: 85.52% | rMAE for Test Set is: 2.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:29:38,259]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:29:49,946]\u001b[0m Trial 1271 finished with value: 2.052324576923967 and parameters: {'n_hidden': 4, 'learning_rate': 0.000579307993203122, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2754689133899102, 'dropout_rate_Layer_2': 0.011454011815927211, 'dropout_rate_Layer_3': 0.026123243789811946, 'dropout_rate_Layer_4': 0.12636639257032525, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.015839385401519763, 'l1_Layer_2': 0.0024966672473412453, 'l1_Layer_3': 0.0037492565854206636, 'l1_Layer_4': 2.2984955045154728e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 295, 'n_units_Layer_3': 65, 'n_units_Layer_4': 120}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 6.26% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.95 | sMAPE for Test Set is: 81.32% | rMAE for Test Set is: 2.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:29:55,841]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:30:18,230]\u001b[0m Trial 1275 finished with value: 2.214430991044923 and parameters: {'n_hidden': 3, 'learning_rate': 0.005788609129446713, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012482494654290955, 'dropout_rate_Layer_2': 0.18820546521184692, 'dropout_rate_Layer_3': 0.2604847964734209, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000239702241608096, 'l1_Layer_2': 0.004680944713917208, 'l1_Layer_3': 1.2083597642662031e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 255, 'n_units_Layer_3': 240}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.21 | sMAPE for Validation Set is: 6.62% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.77 | sMAPE for Test Set is: 95.38% | rMAE for Test Set is: 3.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:31:15,489]\u001b[0m Trial 1280 finished with value: 2.053068371240875 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005872733192233119, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28938783918181943, 'dropout_rate_Layer_2': 0.013847200499379209, 'dropout_rate_Layer_3': 0.00039119078331129736, 'dropout_rate_Layer_4': 0.12575590512794593, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01633022241797334, 'l1_Layer_2': 0.0028212461339634522, 'l1_Layer_3': 0.002680753036231972, 'l1_Layer_4': 2.1233830484323995e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 295, 'n_units_Layer_3': 60, 'n_units_Layer_4': 120}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 6.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.56 | sMAPE for Test Set is: 64.27% | rMAE for Test Set is: 1.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:31:18,797]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:31:22,842]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:31:34,750]\u001b[0m Trial 1279 finished with value: 2.0393131048541715 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005830230984046132, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.288518680848903, 'dropout_rate_Layer_2': 0.011698718164374143, 'dropout_rate_Layer_3': 0.00013673065126978967, 'dropout_rate_Layer_4': 0.12251375661969108, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01525968929770654, 'l1_Layer_2': 0.0024241022901704424, 'l1_Layer_3': 0.0023919771378596143, 'l1_Layer_4': 2.1603003288984434e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 295, 'n_units_Layer_3': 60, 'n_units_Layer_4': 120}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 6.21% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.65 | sMAPE for Test Set is: 80.12% | rMAE for Test Set is: 2.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:31:38,565]\u001b[0m Trial 1277 finished with value: 2.057366289808319 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005796353927201395, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2736368602171243, 'dropout_rate_Layer_2': 0.040621470709579444, 'dropout_rate_Layer_3': 0.014838606963290098, 'dropout_rate_Layer_4': 0.125863681759188, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01603345974821532, 'l1_Layer_2': 0.002676090343977426, 'l1_Layer_3': 0.0022726744536152406, 'l1_Layer_4': 2.0394809561528974e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 295, 'n_units_Layer_3': 65, 'n_units_Layer_4': 120}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.26% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.70 | sMAPE for Test Set is: 80.26% | rMAE for Test Set is: 2.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:31:41,943]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:31:45,151]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:31:50,372]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:31:54,107]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:32:15,718]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:32:19,656]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:32:24,196]\u001b[0m Trial 1276 finished with value: 2.033288406491058 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005796115304532087, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2787395468231972, 'dropout_rate_Layer_2': 0.012251996697055071, 'dropout_rate_Layer_3': 0.023040257895617443, 'dropout_rate_Layer_4': 0.12773677100449732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01640210470673695, 'l1_Layer_2': 0.0025078352941718647, 'l1_Layer_3': 0.0024188604803496855, 'l1_Layer_4': 2.123395970318876e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 295, 'n_units_Layer_3': 65, 'n_units_Layer_4': 120}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 6.21% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.15 | sMAPE for Test Set is: 86.19% | rMAE for Test Set is: 3.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:32:47,761]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:33:08,108]\u001b[0m Trial 1283 finished with value: 1.996892153821622 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005957845201330414, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28477565038645786, 'dropout_rate_Layer_2': 0.011702422029988464, 'dropout_rate_Layer_3': 0.0006551273430638362, 'dropout_rate_Layer_4': 0.12560906507889255, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.015096313120718638, 'l1_Layer_2': 0.0028515289980245166, 'l1_Layer_3': 0.0024852441938419275, 'l1_Layer_4': 2.2472327825760205e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 295, 'n_units_Layer_3': 60, 'n_units_Layer_4': 120}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 6.10% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.08 | sMAPE for Test Set is: 82.01% | rMAE for Test Set is: 2.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:33:13,256]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:33:16,833]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:33:37,730]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:33:41,480]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:33:48,292]\u001b[0m Trial 1291 finished with value: 2.0277507998157476 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006013727726055499, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.293309473060718, 'dropout_rate_Layer_2': 0.013711749127925055, 'dropout_rate_Layer_3': 0.0013804660069688945, 'dropout_rate_Layer_4': 0.11607196225910486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.014841622531467855, 'l1_Layer_2': 0.003174145079956501, 'l1_Layer_3': 0.0025026027700092894, 'l1_Layer_4': 2.239989952359349e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 295, 'n_units_Layer_3': 60, 'n_units_Layer_4': 130}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 6.18% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.91 | sMAPE for Test Set is: 76.83% | rMAE for Test Set is: 2.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:33:52,928]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:34:47,656]\u001b[0m Trial 1289 finished with value: 2.0566284452470325 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006033683657612396, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2913266714189051, 'dropout_rate_Layer_2': 0.012201041386487428, 'dropout_rate_Layer_3': 0.00044285404725721497, 'dropout_rate_Layer_4': 0.10989720333419088, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.013838619389992814, 'l1_Layer_2': 0.004147742883363537, 'l1_Layer_3': 0.0025401482520359202, 'l1_Layer_4': 3.111975906313694e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 295, 'n_units_Layer_3': 60, 'n_units_Layer_4': 110}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.29% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.32 | sMAPE for Test Set is: 86.66% | rMAE for Test Set is: 3.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:34:58,629]\u001b[0m Trial 1296 finished with value: 2.0266548192345675 and parameters: {'n_hidden': 4, 'learning_rate': 0.00062113507299935, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2944899519535033, 'dropout_rate_Layer_2': 0.02466472806367639, 'dropout_rate_Layer_3': 0.005401305192686616, 'dropout_rate_Layer_4': 0.11236804991744076, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.014233306250542832, 'l1_Layer_2': 0.0037546639575293827, 'l1_Layer_3': 0.0017223997156913412, 'l1_Layer_4': 2.994670227675061e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 290, 'n_units_Layer_3': 55, 'n_units_Layer_4': 130}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 6.20% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.62 | sMAPE for Test Set is: 75.37% | rMAE for Test Set is: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:35:03,243]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:35:17,449]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:35:26,728]\u001b[0m Trial 1299 finished with value: 2.0786135309102147 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006294035114984014, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2824248072491729, 'dropout_rate_Layer_2': 0.025146599970050074, 'dropout_rate_Layer_3': 0.0008204271048692438, 'dropout_rate_Layer_4': 0.11600181619746995, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.013434955893307711, 'l1_Layer_2': 0.0033658782973438606, 'l1_Layer_3': 0.002181155819237654, 'l1_Layer_4': 2.8917168653691677e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 290, 'n_units_Layer_3': 55, 'n_units_Layer_4': 130}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.33% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.08 | sMAPE for Test Set is: 77.60% | rMAE for Test Set is: 2.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:35:35,634]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:35:47,101]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:35:49,563]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:35:53,708]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:35:54,260]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:35:54,794]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:36:02,306]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:36:02,769]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:36:11,536]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:36:19,388]\u001b[0m Trial 1301 finished with value: 2.098159893424817 and parameters: {'n_hidden': 4, 'learning_rate': 0.000637479124635442, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2823246917558946, 'dropout_rate_Layer_2': 0.02587454333924603, 'dropout_rate_Layer_3': 0.0063362775197639155, 'dropout_rate_Layer_4': 0.12085150887891519, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012714642547293459, 'l1_Layer_2': 0.002141407350582517, 'l1_Layer_3': 0.002043256930224655, 'l1_Layer_4': 2.8672735374925734e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 290, 'n_units_Layer_3': 50, 'n_units_Layer_4': 110}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 6.38% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.80 | sMAPE for Test Set is: 76.30% | rMAE for Test Set is: 2.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:36:23,964]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:36:33,032]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:36:36,474]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:36:40,636]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:36:50,299]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:36:51,699]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:36:52,522]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:36:58,253]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:37:02,253]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:37:06,262]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:37:08,704]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:37:12,088]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:37:21,108]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:37:27,060]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:37:30,881]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:37:34,374]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:37:37,433]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:37:40,470]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:37:52,884]\u001b[0m Trial 1312 finished with value: 2.0407804323041905 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005692026506303743, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27915894246056505, 'dropout_rate_Layer_2': 0.02407587900057062, 'dropout_rate_Layer_3': 0.012088860301006893, 'dropout_rate_Layer_4': 0.13508430497271115, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.018151377327874533, 'l1_Layer_2': 0.0028298200413823227, 'l1_Layer_3': 0.0024145062081929723, 'l1_Layer_4': 2.5838407376807054e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 300, 'n_units_Layer_3': 60, 'n_units_Layer_4': 135}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 6.23% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.58 | sMAPE for Test Set is: 75.24% | rMAE for Test Set is: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:38:01,443]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:38:15,005]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:38:22,620]\u001b[0m Trial 1320 finished with value: 2.071722062406593 and parameters: {'n_hidden': 3, 'learning_rate': 0.003666537499531391, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024486079555683146, 'dropout_rate_Layer_2': 0.23000928928914494, 'dropout_rate_Layer_3': 0.24179475284300286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007419552115103985, 'l1_Layer_2': 0.0019969389536570684, 'l1_Layer_3': 2.461281071519488e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 260, 'n_units_Layer_3': 265}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.42 | sMAPE for Test Set is: 83.18% | rMAE for Test Set is: 2.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:38:24,199]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:38:27,954]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:38:30,799]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:38:34,028]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:39:07,582]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:39:09,412]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:39:34,051]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:39:34,872]\u001b[0m Trial 1335 finished with value: 2.00657700620328 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005673750016383827, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3097116051339171, 'dropout_rate_Layer_2': 0.01669546436413098, 'dropout_rate_Layer_3': 0.021624223232273587, 'dropout_rate_Layer_4': 0.1363385714953355, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.015389550980068587, 'l1_Layer_2': 0.002383088055598656, 'l1_Layer_3': 0.0026317504425808417, 'l1_Layer_4': 2.5244382565577833e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 300, 'n_units_Layer_3': 65, 'n_units_Layer_4': 135}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 6.13% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.58 | sMAPE for Test Set is: 79.88% | rMAE for Test Set is: 2.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:39:41,713]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:39:46,858]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:39:50,886]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:39:54,739]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:39:58,278]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:40:16,889]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:40:24,526]\u001b[0m Trial 1334 finished with value: 2.0099460037060957 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005537149102091358, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29498487396495454, 'dropout_rate_Layer_2': 0.03433419107481955, 'dropout_rate_Layer_3': 0.01322814775681926, 'dropout_rate_Layer_4': 0.14295820366210515, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.010758752898060995, 'l1_Layer_2': 0.004680287564181396, 'l1_Layer_3': 0.002764333847391482, 'l1_Layer_4': 2.5952836259837824e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 300, 'n_units_Layer_3': 60, 'n_units_Layer_4': 115}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 6.15% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.34 | sMAPE for Test Set is: 83.00% | rMAE for Test Set is: 2.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:40:29,511]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:40:35,108]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:40:38,002]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:40:45,260]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:40:50,277]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:40:59,381]\u001b[0m Trial 1342 finished with value: 2.011064610694374 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007441969766758767, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3394415058059555, 'dropout_rate_Layer_2': 0.03474591831888365, 'dropout_rate_Layer_3': 0.10196964738419946, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008490163352683537, 'l1_Layer_2': 5.495463041279232e-05, 'l1_Layer_3': 0.028320757701194167, 'n_units_Layer_1': 250, 'n_units_Layer_2': 195, 'n_units_Layer_3': 210}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 6.15% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 16.61 | sMAPE for Test Set is: 104.79% | rMAE for Test Set is: 4.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:41:02,642]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:41:07,161]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:41:10,580]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:41:10,939]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:41:12,455]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:41:15,800]\u001b[0m Trial 1346 finished with value: 2.048040515413053 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006478734179328563, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30522333986381606, 'dropout_rate_Layer_2': 0.018178312788462977, 'dropout_rate_Layer_3': 0.01325266173680227, 'dropout_rate_Layer_4': 0.12985375368618818, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01584410338657183, 'l1_Layer_2': 0.0029561992824965752, 'l1_Layer_3': 0.0019905101079780406, 'l1_Layer_4': 2.5603934934290033e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 300, 'n_units_Layer_3': 55, 'n_units_Layer_4': 125}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 6.26% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.87 | sMAPE for Test Set is: 76.62% | rMAE for Test Set is: 2.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:41:16,042]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:41:23,093]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:41:27,291]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:41:31,071]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:41:35,716]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:41:39,973]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:41:47,187]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:41:52,473]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:41:57,949]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:42:07,002]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:42:10,308]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:42:27,960]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:42:36,790]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:42:39,829]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:43:20,263]\u001b[0m Trial 1369 finished with value: 2.0575260494718783 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005999051136938496, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2960482224156593, 'dropout_rate_Layer_2': 0.02813450571109241, 'dropout_rate_Layer_3': 0.03607811125118471, 'dropout_rate_Layer_4': 0.1436801995975476, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011478435164600244, 'l1_Layer_2': 0.00549454089200228, 'l1_Layer_3': 0.0029514417246786673, 'l1_Layer_4': 3.123737724643514e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 290, 'n_units_Layer_3': 65, 'n_units_Layer_4': 145}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.25% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.79 | sMAPE for Test Set is: 84.91% | rMAE for Test Set is: 2.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:43:23,827]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:43:27,487]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:43:27,957]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:43:34,161]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:43:37,257]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:43:40,341]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:43:44,007]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:43:46,997]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:43:49,092]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:43:51,364]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:43:53,767]\u001b[0m Trial 1365 finished with value: 2.0280372353861007 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006048422114238133, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29468670181897705, 'dropout_rate_Layer_2': 0.027502778290781155, 'dropout_rate_Layer_3': 0.00016992222197404275, 'dropout_rate_Layer_4': 0.14551454787539936, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.020993367754210495, 'l1_Layer_2': 0.0021634312632035713, 'l1_Layer_3': 0.0029625541548442373, 'l1_Layer_4': 3.38614259836946e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 65, 'n_units_Layer_4': 145}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 6.20% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.41 | sMAPE for Test Set is: 90.65% | rMAE for Test Set is: 3.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:43:58,191]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:44:16,497]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:44:19,737]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:44:23,625]\u001b[0m Trial 1373 finished with value: 2.0604253188724626 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006017873460768889, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2952762110015981, 'dropout_rate_Layer_2': 0.026880358982744428, 'dropout_rate_Layer_3': 0.03525903845994573, 'dropout_rate_Layer_4': 0.14871284349806813, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0210889709005208, 'l1_Layer_2': 0.005192404933659866, 'l1_Layer_3': 0.0029095905478478323, 'l1_Layer_4': 3.323455662234489e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 290, 'n_units_Layer_3': 65, 'n_units_Layer_4': 145}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.29% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.71 | sMAPE for Test Set is: 88.24% | rMAE for Test Set is: 3.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:44:25,703]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:44:28,876]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:44:29,866]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:44:34,851]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:44:42,511]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:44:42,795]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:44:52,201]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:44:55,757]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:45:13,030]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:45:15,787]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:45:19,200]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:45:39,720]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:45:42,377]\u001b[0m Trial 1400 finished with value: 2.2238734154372684 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034768833323198705, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10711627928388483, 'dropout_rate_Layer_2': 0.32728416825638673, 'dropout_rate_Layer_3': 0.25754007645840105, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013262215227126568, 'l1_Layer_2': 0.0012122331648334143, 'l1_Layer_3': 3.348011777232293e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 265, 'n_units_Layer_3': 255}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.22 | sMAPE for Validation Set is: 6.65% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.84 | sMAPE for Test Set is: 95.34% | rMAE for Test Set is: 3.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:45:45,054]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:45:52,632]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:45:57,000]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:46:03,582]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:46:17,816]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:46:22,365]\u001b[0m Trial 1393 finished with value: 1.9947692811866489 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005214307727335499, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3293223061852274, 'dropout_rate_Layer_2': 0.04839979549282696, 'dropout_rate_Layer_3': 0.1034739972550805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011021678056840165, 'l1_Layer_2': 6.72147046778193e-05, 'l1_Layer_3': 0.0411204217131615, 'n_units_Layer_1': 165, 'n_units_Layer_2': 190, 'n_units_Layer_3': 225}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.99 | sMAPE for Validation Set is: 6.11% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 16.70 | sMAPE for Test Set is: 105.02% | rMAE for Test Set is: 5.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:46:26,168]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:46:40,784]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:46:48,201]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:46:52,422]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:47:04,267]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:47:07,591]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:47:20,580]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:47:27,068]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:47:33,227]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:47:36,644]\u001b[0m Trial 1404 finished with value: 2.056732669054241 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006895997559905277, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28386557371966104, 'dropout_rate_Layer_2': 0.007917521071838914, 'dropout_rate_Layer_3': 0.028729995697609433, 'dropout_rate_Layer_4': 0.11778813924791132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.014274528734832414, 'l1_Layer_2': 0.0015749809740788516, 'l1_Layer_3': 0.0033768097881480847, 'l1_Layer_4': 1.547134249910945e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 285, 'n_units_Layer_3': 70, 'n_units_Layer_4': 105}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.79 | sMAPE for Test Set is: 88.54% | rMAE for Test Set is: 3.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:47:39,964]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:47:44,792]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:47:52,376]\u001b[0m Trial 1419 finished with value: 2.036621105417859 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028609282681422124, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03830137527969528, 'dropout_rate_Layer_2': 0.21328340867001763, 'dropout_rate_Layer_3': 0.2331953771313749, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015271308699279064, 'l1_Layer_2': 0.01407053142366106, 'l1_Layer_3': 0.0005859286989216962, 'n_units_Layer_1': 255, 'n_units_Layer_2': 130, 'n_units_Layer_3': 295}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 6.25% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 3.66 | sMAPE for Test Set is: 48.13% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:48:02,520]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:48:13,430]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:48:13,609]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:48:20,913]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:48:25,394]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:48:28,032]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:48:33,985]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:48:43,678]\u001b[0m Trial 1418 finished with value: 2.071767981687294 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005479681029951485, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26169186343774864, 'dropout_rate_Layer_2': 0.007483081749462238, 'dropout_rate_Layer_3': 0.0166779546503376, 'dropout_rate_Layer_4': 0.17010272938618948, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.013398456983623247, 'l1_Layer_2': 0.0026795180787715484, 'l1_Layer_3': 0.0033147725386742195, 'l1_Layer_4': 2.7645815568995558e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 60, 'n_units_Layer_4': 105}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 6.33% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.09 | sMAPE for Test Set is: 82.06% | rMAE for Test Set is: 2.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:48:49,175]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:48:54,746]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:49:08,835]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:49:13,595]\u001b[0m Trial 1422 finished with value: 2.0491079018102676 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006125135636176801, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2734898550901581, 'dropout_rate_Layer_2': 0.0004513307153120802, 'dropout_rate_Layer_3': 0.030345704151408786, 'dropout_rate_Layer_4': 0.10739051620011637, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01826960828229761, 'l1_Layer_2': 0.0020464833034227014, 'l1_Layer_3': 0.0020304374240395257, 'l1_Layer_4': 1.776014197005503e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 290, 'n_units_Layer_3': 60, 'n_units_Layer_4': 115}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 6.23% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.21 | sMAPE for Test Set is: 78.17% | rMAE for Test Set is: 2.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:49:18,045]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:49:20,996]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:49:27,540]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:49:32,015]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:49:44,045]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:49:49,499]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:49:55,593]\u001b[0m Trial 1433 finished with value: 2.0444719295217557 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005416114057008601, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2907554350585975, 'dropout_rate_Layer_2': 0.055543536775969495, 'dropout_rate_Layer_3': 0.01141601694795961, 'dropout_rate_Layer_4': 0.33063653693995537, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012540092761191772, 'l1_Layer_2': 0.0041875831593388485, 'l1_Layer_3': 0.0017861408776332585, 'l1_Layer_4': 2.862593418012514e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 275, 'n_units_Layer_3': 75, 'n_units_Layer_4': 120}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 6.23% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.09 | sMAPE for Test Set is: 72.79% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:50:01,178]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:50:05,340]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:50:08,887]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:50:19,892]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:50:21,067]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:50:24,698]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:50:28,573]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:50:32,392]\u001b[0m Trial 1436 finished with value: 2.0188473929861623 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005528318736639644, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2939201795603542, 'dropout_rate_Layer_2': 0.0003385752791260875, 'dropout_rate_Layer_3': 0.02922484955339923, 'dropout_rate_Layer_4': 0.11078153223879035, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.028652904269445226, 'l1_Layer_2': 0.007953616075310145, 'l1_Layer_3': 0.004222417794756882, 'l1_Layer_4': 2.2187985452327504e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 280, 'n_units_Layer_3': 75, 'n_units_Layer_4': 115}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 6.19% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.97 | sMAPE for Test Set is: 72.19% | rMAE for Test Set is: 2.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:50:32,805]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:50:40,001]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:50:42,009]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:50:45,674]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:50:49,746]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:50:50,139]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:50:53,744]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:51:00,823]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:51:04,878]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:51:09,152]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:51:18,885]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:51:20,506]\u001b[0m Trial 1448 finished with value: 2.003241325809969 and parameters: {'n_hidden': 3, 'learning_rate': 0.004139862276584415, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08874677158544772, 'dropout_rate_Layer_2': 0.1062500033323207, 'dropout_rate_Layer_3': 0.32577383450793745, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002467132243397507, 'l1_Layer_2': 0.0038533144658721343, 'l1_Layer_3': 1.5096915581193527e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 255, 'n_units_Layer_3': 270}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 6.14% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 12.74 | sMAPE for Test Set is: 95.44% | rMAE for Test Set is: 3.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:51:26,033]\u001b[0m Trial 1459 finished with value: 2.056473660975195 and parameters: {'n_hidden': 3, 'learning_rate': 0.008664379148339405, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33906003599769213, 'dropout_rate_Layer_2': 0.010400006296191897, 'dropout_rate_Layer_3': 0.10381202062105793, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007692110208982638, 'l1_Layer_2': 4.297323529534181e-05, 'l1_Layer_3': 0.05174511311676617, 'n_units_Layer_1': 155, 'n_units_Layer_2': 50, 'n_units_Layer_3': 245}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 6.26% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 16.97 | sMAPE for Test Set is: 105.77% | rMAE for Test Set is: 5.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:51:29,729]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:51:30,160]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:51:36,149]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:51:42,946]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:51:49,201]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:51:56,810]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:52:02,909]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:52:06,105]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:52:09,232]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:52:11,807]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:52:17,081]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:53:16,288]\u001b[0m Trial 1467 finished with value: 2.0169797177998494 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006366534670526848, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28504542997353854, 'dropout_rate_Layer_2': 0.012063145860420912, 'dropout_rate_Layer_3': 0.052511104090009614, 'dropout_rate_Layer_4': 0.15155427245947772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009552250599376439, 'l1_Layer_2': 0.0032521465902368126, 'l1_Layer_3': 0.005365677749207245, 'l1_Layer_4': 2.1954603109813064e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 300, 'n_units_Layer_3': 70, 'n_units_Layer_4': 130}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 6.15% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.61 | sMAPE for Test Set is: 84.05% | rMAE for Test Set is: 2.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:53:19,658]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:53:21,919]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:53:27,365]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:53:31,655]\u001b[0m Trial 1477 finished with value: 2.009071760364085 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009861631416338292, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.325357661308876, 'dropout_rate_Layer_2': 0.009768380769665535, 'dropout_rate_Layer_3': 0.12814897930168878, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010634475904187526, 'l1_Layer_2': 0.00029289950089433415, 'l1_Layer_3': 0.04996818534678827, 'n_units_Layer_1': 165, 'n_units_Layer_2': 120, 'n_units_Layer_3': 275}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 6.15% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 17.11 | sMAPE for Test Set is: 106.04% | rMAE for Test Set is: 5.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:53:31,872]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:53:37,664]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:53:56,119]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:53:59,782]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:54:02,941]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:54:11,134]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:54:15,434]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:54:19,091]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:54:37,604]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:54:40,781]\u001b[0m Trial 1464 finished with value: 2.043072254191564 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006357179852108902, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28252434210829236, 'dropout_rate_Layer_2': 0.012108595145426646, 'dropout_rate_Layer_3': 0.023503341459589315, 'dropout_rate_Layer_4': 0.12274475584106061, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01976951564759403, 'l1_Layer_2': 0.006823166864703992, 'l1_Layer_3': 0.005346852860547064, 'l1_Layer_4': 2.0708816291451885e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 280, 'n_units_Layer_3': 70, 'n_units_Layer_4': 130}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 6.25% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 11.23 | sMAPE for Test Set is: 89.97% | rMAE for Test Set is: 3.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:54:41,153]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:54:47,063]\u001b[0m Trial 1483 finished with value: 2.010336770074549 and parameters: {'n_hidden': 3, 'learning_rate': 0.0040069881656088924, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03440356024060438, 'dropout_rate_Layer_2': 0.08827209081914698, 'dropout_rate_Layer_3': 0.35366541191500545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006281417911467119, 'l1_Layer_2': 0.0031317858226743147, 'l1_Layer_3': 1.582004941561619e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 235, 'n_units_Layer_3': 240}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 6.12% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.31 | sMAPE for Test Set is: 78.14% | rMAE for Test Set is: 2.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:54:52,134]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:54:56,557]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:55:02,139]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:55:06,057]\u001b[0m Trial 1479 finished with value: 2.082332715535297 and parameters: {'n_hidden': 3, 'learning_rate': 0.003977168039526324, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009470972919057848, 'dropout_rate_Layer_2': 0.08781903431631069, 'dropout_rate_Layer_3': 0.3090356112199546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006198917829100101, 'l1_Layer_2': 0.007707886324131025, 'l1_Layer_3': 1.0251967126870972e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 235, 'n_units_Layer_3': 240}. Best is trial 1118 with value: 1.9112447146241671.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 6.24% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.35 | sMAPE for Test Set is: 73.84% | rMAE for Test Set is: 2.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 03:55:08,435]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:55:10,577]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:55:11,275]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:55:11,600]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 03:55:14,040]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-01-01, MAE is:3.44 & sMAPE is:11.73% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 11.73% & 0.47\n",
      "for 2020-01-02, MAE is:2.88 & sMAPE is:12.38% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.16 & 12.05% & 0.39\n",
      "for 2020-01-03, MAE is:6.42 & sMAPE is:37.38% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 20.50% & 0.40\n",
      "for 2020-01-04, MAE is:2.50 & sMAPE is:10.35% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 17.96% & 0.36\n",
      "for 2020-01-05, MAE is:1.60 & sMAPE is:5.55% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.37 & 15.48% & 0.41\n",
      "for 2020-01-06, MAE is:0.63 & sMAPE is:2.15% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :2.91 & 13.26% & 0.36\n",
      "for 2020-01-07, MAE is:1.72 & sMAPE is:5.86% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.74 & 12.20% & 0.35\n",
      "for 2020-01-08, MAE is:3.69 & sMAPE is:15.24% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :2.86 & 12.58% & 0.44\n",
      "for 2020-01-09, MAE is:1.47 & sMAPE is:5.91% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :2.70 & 11.84% & 0.45\n",
      "for 2020-01-10, MAE is:3.52 & sMAPE is:12.29% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :2.79 & 11.88% & 0.46\n",
      "for 2020-01-11, MAE is:3.04 & sMAPE is:11.67% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :2.81 & 11.87% & 0.50\n",
      "for 2020-01-12, MAE is:2.61 & sMAPE is:11.67% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.79 & 11.85% & 0.49\n",
      "for 2020-01-13, MAE is:1.88 & sMAPE is:7.20% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.72 & 11.49% & 0.48\n",
      "for 2020-01-14, MAE is:4.09 & sMAPE is:16.56% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :2.82 & 11.85% & 0.50\n",
      "for 2020-01-15, MAE is:2.78 & sMAPE is:11.48% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.82 & 11.83% & 0.57\n",
      "for 2020-01-16, MAE is:1.46 & sMAPE is:5.89% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.73 & 11.46% & 0.59\n",
      "for 2020-01-17, MAE is:1.26 & sMAPE is:5.01% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.65 & 11.08% & 0.59\n",
      "for 2020-01-18, MAE is:2.51 & sMAPE is:10.21% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :2.64 & 11.03% & 0.62\n",
      "for 2020-01-19, MAE is:2.03 & sMAPE is:8.50% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :2.61 & 10.90% & 0.64\n",
      "for 2020-01-20, MAE is:2.99 & sMAPE is:12.39% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :2.62 & 10.97% & 0.66\n",
      "for 2020-01-21, MAE is:2.92 & sMAPE is:13.33% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :2.64 & 11.08% & 0.68\n",
      "for 2020-01-22, MAE is:3.46 & sMAPE is:16.55% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.68 & 11.33% & 0.69\n",
      "for 2020-01-23, MAE is:2.66 & sMAPE is:12.18% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.68 & 11.37% & 0.69\n",
      "for 2020-01-24, MAE is:3.36 & sMAPE is:16.02% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.70 & 11.56% & 0.69\n",
      "for 2020-01-25, MAE is:0.85 & sMAPE is:4.42% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :2.63 & 11.28% & 0.68\n",
      "for 2020-01-26, MAE is:1.71 & sMAPE is:8.20% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :2.59 & 11.16% & 0.67\n",
      "for 2020-01-27, MAE is:2.18 & sMAPE is:9.88% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.58 & 11.11% & 0.69\n",
      "for 2020-01-28, MAE is:1.09 & sMAPE is:5.00% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 10.89% & 0.70\n",
      "for 2020-01-29, MAE is:2.65 & sMAPE is:11.60% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 10.92% & 0.75\n",
      "for 2020-01-30, MAE is:1.66 & sMAPE is:7.45% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 10.80% & 0.76\n",
      "for 2020-01-31, MAE is:3.33 & sMAPE is:16.17% & rMAE is:4.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 10.98% & 0.89\n",
      "for 2020-02-01, MAE is:5.38 & sMAPE is:29.11% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :2.62 & 11.54% & 0.89\n",
      "for 2020-02-02, MAE is:2.80 & sMAPE is:16.31% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.62 & 11.69% & 0.89\n",
      "for 2020-02-03, MAE is:2.86 & sMAPE is:13.92% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.63 & 11.75% & 0.91\n",
      "for 2020-02-04, MAE is:3.51 & sMAPE is:16.50% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.65 & 11.89% & 0.93\n",
      "for 2020-02-05, MAE is:4.40 & sMAPE is:22.39% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :2.70 & 12.18% & 0.94\n",
      "for 2020-02-06, MAE is:5.13 & sMAPE is:26.15% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.77 & 12.56% & 0.95\n",
      "for 2020-02-07, MAE is:4.89 & sMAPE is:26.43% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.82 & 12.92% & 0.97\n",
      "for 2020-02-08, MAE is:5.00 & sMAPE is:30.80% & rMAE is:2.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.88 & 13.38% & 1.00\n",
      "for 2020-02-09, MAE is:9.05 & sMAPE is:68.15% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :3.03 & 14.75% & 1.01\n",
      "for 2020-02-10, MAE is:6.93 & sMAPE is:48.14% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :3.13 & 15.56% & 1.01\n",
      "for 2020-02-11, MAE is:7.25 & sMAPE is:45.82% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :3.23 & 16.28% & 1.01\n",
      "for 2020-02-12, MAE is:6.45 & sMAPE is:39.39% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :3.30 & 16.82% & 1.02\n",
      "for 2020-02-13, MAE is:4.28 & sMAPE is:25.03% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.32 & 17.01% & 1.04\n",
      "for 2020-02-14, MAE is:2.34 & sMAPE is:13.97% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :3.30 & 16.94% & 1.06\n",
      "for 2020-02-15, MAE is:6.02 & sMAPE is:40.89% & rMAE is:3.08 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 17.46% & 1.11\n",
      "for 2020-02-16, MAE is:6.56 & sMAPE is:51.89% & rMAE is:4.19 ||| daily mean of MAE & sMAPE & rMAE till now are :3.43 & 18.19% & 1.17\n",
      "for 2020-02-17, MAE is:4.89 & sMAPE is:37.01% & rMAE is:4.00 ||| daily mean of MAE & sMAPE & rMAE till now are :3.46 & 18.59% & 1.23\n",
      "for 2020-02-18, MAE is:6.50 & sMAPE is:46.12% & rMAE is:3.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.52 & 19.15% & 1.29\n",
      "for 2020-02-19, MAE is:2.91 & sMAPE is:19.69% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.51 & 19.16% & 1.30\n",
      "for 2020-02-20, MAE is:8.54 & sMAPE is:55.79% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :3.61 & 19.88% & 1.31\n",
      "for 2020-02-21, MAE is:7.38 & sMAPE is:57.77% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 20.61% & 1.31\n",
      "for 2020-02-22, MAE is:8.07 & sMAPE is:70.22% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :3.76 & 21.54% & 1.32\n",
      "for 2020-02-23, MAE is:6.16 & sMAPE is:54.64% & rMAE is:5.70 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 22.16% & 1.40\n",
      "for 2020-02-24, MAE is:5.69 & sMAPE is:40.86% & rMAE is:5.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 22.50% & 1.47\n",
      "for 2020-02-25, MAE is:3.90 & sMAPE is:25.49% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 22.55% & 1.47\n",
      "for 2020-02-26, MAE is:1.97 & sMAPE is:11.37% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 22.35% & 1.45\n",
      "for 2020-02-27, MAE is:1.02 & sMAPE is:5.24% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :3.76 & 22.06% & 1.43\n",
      "for 2020-02-28, MAE is:2.05 & sMAPE is:10.85% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :3.73 & 21.87% & 1.41\n",
      "for 2020-02-29, MAE is:8.44 & sMAPE is:52.45% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 22.38% & 1.41\n",
      "for 2020-03-01, MAE is:5.12 & sMAPE is:38.57% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 22.64% & 1.42\n",
      "for 2020-03-02, MAE is:2.23 & sMAPE is:13.87% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 22.50% & 1.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-03-03, MAE is:4.75 & sMAPE is:27.36% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :3.82 & 22.58% & 1.42\n",
      "for 2020-03-04, MAE is:4.21 & sMAPE is:25.62% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 22.63% & 1.41\n",
      "for 2020-03-05, MAE is:3.76 & sMAPE is:22.77% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :3.83 & 22.63% & 1.40\n",
      "for 2020-03-06, MAE is:3.22 & sMAPE is:19.13% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :3.82 & 22.58% & 1.39\n",
      "for 2020-03-07, MAE is:2.96 & sMAPE is:19.71% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 22.53% & 1.40\n",
      "for 2020-03-08, MAE is:9.05 & sMAPE is:64.69% & rMAE is:6.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 23.15% & 1.47\n",
      "for 2020-03-09, MAE is:6.62 & sMAPE is:47.47% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :3.92 & 23.50% & 1.47\n",
      "for 2020-03-10, MAE is:5.42 & sMAPE is:40.29% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 23.74% & 1.47\n",
      "for 2020-03-11, MAE is:6.62 & sMAPE is:52.53% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.98 & 24.15% & 1.47\n",
      "for 2020-03-12, MAE is:6.71 & sMAPE is:56.15% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 24.59% & 1.47\n",
      "for 2020-03-13, MAE is:8.28 & sMAPE is:65.71% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 25.16% & 1.46\n",
      "for 2020-03-14, MAE is:6.16 & sMAPE is:49.81% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 25.49% & 1.46\n",
      "for 2020-03-15, MAE is:7.99 & sMAPE is:74.12% & rMAE is:3.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 26.14% & 1.48\n",
      "for 2020-03-16, MAE is:7.73 & sMAPE is:60.87% & rMAE is:5.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 26.60% & 1.54\n",
      "for 2020-03-17, MAE is:7.59 & sMAPE is:67.24% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.25 & 27.12% & 1.55\n",
      "for 2020-03-18, MAE is:7.66 & sMAPE is:67.30% & rMAE is:4.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 27.64% & 1.59\n",
      "for 2020-03-19, MAE is:7.27 & sMAPE is:68.05% & rMAE is:4.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 28.15% & 1.62\n",
      "for 2020-03-20, MAE is:4.50 & sMAPE is:42.80% & rMAE is:4.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 28.33% & 1.65\n",
      "for 2020-03-21, MAE is:7.18 & sMAPE is:63.68% & rMAE is:4.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 28.77% & 1.68\n",
      "for 2020-03-22, MAE is:6.96 & sMAPE is:69.37% & rMAE is:9.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 29.27% & 1.78\n",
      "for 2020-03-23, MAE is:7.92 & sMAPE is:68.60% & rMAE is:5.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 29.74% & 1.82\n",
      "for 2020-03-24, MAE is:9.51 & sMAPE is:83.30% & rMAE is:11.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 30.38% & 1.93\n",
      "for 2020-03-25, MAE is:9.86 & sMAPE is:88.40% & rMAE is:6.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 31.06% & 1.98\n",
      "for 2020-03-26, MAE is:8.10 & sMAPE is:76.76% & rMAE is:12.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 31.59% & 2.11\n",
      "for 2020-03-27, MAE is:8.22 & sMAPE is:80.47% & rMAE is:3.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 32.15% & 2.12\n",
      "for 2020-03-28, MAE is:4.11 & sMAPE is:56.27% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 32.43% & 2.12\n",
      "for 2020-03-29, MAE is:7.38 & sMAPE is:86.10% & rMAE is:4.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 33.03% & 2.14\n",
      "for 2020-03-30, MAE is:8.37 & sMAPE is:77.59% & rMAE is:8.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 33.52% & 2.22\n",
      "for 2020-03-31, MAE is:7.23 & sMAPE is:80.84% & rMAE is:4.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 34.04% & 2.24\n",
      "for 2020-04-01, MAE is:8.27 & sMAPE is:89.37% & rMAE is:8.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 34.65% & 2.31\n",
      "for 2020-04-02, MAE is:8.97 & sMAPE is:98.48% & rMAE is:5.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 35.33% & 2.34\n",
      "for 2020-04-03, MAE is:9.01 & sMAPE is:104.39% & rMAE is:4.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 36.07% & 2.36\n",
      "for 2020-04-04, MAE is:9.92 & sMAPE is:105.56% & rMAE is:11.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 36.80% & 2.46\n",
      "for 2020-04-05, MAE is:8.30 & sMAPE is:95.57% & rMAE is:9.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 37.41% & 2.53\n",
      "for 2020-04-06, MAE is:10.37 & sMAPE is:106.48% & rMAE is:4.99 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 38.12% & 2.56\n",
      "for 2020-04-07, MAE is:10.41 & sMAPE is:110.68% & rMAE is:11.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 38.86% & 2.65\n",
      "for 2020-04-08, MAE is:7.84 & sMAPE is:103.65% & rMAE is:5.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 39.52% & 2.67\n",
      "for 2020-04-09, MAE is:6.53 & sMAPE is:91.95% & rMAE is:8.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 40.04% & 2.73\n",
      "for 2020-04-10, MAE is:6.89 & sMAPE is:91.05% & rMAE is:15.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 40.55% & 2.85\n",
      "for 2020-04-11, MAE is:8.38 & sMAPE is:91.66% & rMAE is:16.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 41.05% & 2.98\n",
      "for 2020-04-12, MAE is:9.22 & sMAPE is:110.25% & rMAE is:10.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 41.72% & 3.06\n",
      "for 2020-04-13, MAE is:9.83 & sMAPE is:137.05% & rMAE is:4.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 42.64% & 3.07\n",
      "for 2020-04-14, MAE is:6.41 & sMAPE is:87.65% & rMAE is:16.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 43.07% & 3.20\n",
      "for 2020-04-15, MAE is:8.71 & sMAPE is:103.36% & rMAE is:18.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 43.63% & 3.34\n",
      "for 2020-04-16, MAE is:9.43 & sMAPE is:113.86% & rMAE is:32.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 44.29% & 3.61\n",
      "for 2020-04-17, MAE is:9.83 & sMAPE is:115.04% & rMAE is:19.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 44.95% & 3.76\n",
      "for 2020-04-18, MAE is:7.89 & sMAPE is:94.91% & rMAE is:12.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 45.40% & 3.84\n",
      "for 2020-04-19, MAE is:8.42 & sMAPE is:92.58% & rMAE is:7.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 45.83% & 3.88\n",
      "for 2020-04-20, MAE is:7.19 & sMAPE is:87.34% & rMAE is:3.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 46.21% & 3.87\n",
      "for 2020-04-21, MAE is:9.33 & sMAPE is:97.06% & rMAE is:10.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 46.66% & 3.93\n",
      "for 2020-04-22, MAE is:7.30 & sMAPE is:82.49% & rMAE is:6.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 46.98% & 3.95\n",
      "for 2020-04-23, MAE is:8.04 & sMAPE is:89.02% & rMAE is:5.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 47.35% & 3.97\n",
      "for 2020-04-24, MAE is:9.40 & sMAPE is:96.94% & rMAE is:6.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 47.78% & 3.99\n",
      "for 2020-04-25, MAE is:10.57 & sMAPE is:104.02% & rMAE is:20.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 48.26% & 4.14\n",
      "for 2020-04-26, MAE is:6.53 & sMAPE is:75.67% & rMAE is:11.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 48.50% & 4.21\n",
      "for 2020-04-27, MAE is:7.49 & sMAPE is:76.67% & rMAE is:5.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 48.74% & 4.22\n",
      "for 2020-04-28, MAE is:5.57 & sMAPE is:55.94% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 48.80% & 4.20\n",
      "for 2020-04-29, MAE is:5.78 & sMAPE is:58.20% & rMAE is:3.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 48.87% & 4.19\n",
      "for 2020-04-30, MAE is:7.02 & sMAPE is:70.75% & rMAE is:4.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 49.06% & 4.20\n",
      "for 2020-05-01, MAE is:7.07 & sMAPE is:77.78% & rMAE is:8.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 49.29% & 4.23\n",
      "for 2020-05-02, MAE is:6.52 & sMAPE is:60.06% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 49.38% & 4.22\n",
      "for 2020-05-03, MAE is:4.08 & sMAPE is:43.84% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 49.33% & 4.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-05-04, MAE is:5.52 & sMAPE is:51.30% & rMAE is:2.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 49.35% & 4.19\n",
      "for 2020-05-05, MAE is:5.37 & sMAPE is:52.31% & rMAE is:5.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 49.37% & 4.21\n",
      "for 2020-05-06, MAE is:5.59 & sMAPE is:57.69% & rMAE is:10.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 49.44% & 4.25\n",
      "for 2020-05-07, MAE is:5.12 & sMAPE is:51.41% & rMAE is:3.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 49.45% & 4.25\n",
      "for 2020-05-08, MAE is:5.72 & sMAPE is:52.06% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 49.47% & 4.23\n",
      "for 2020-05-09, MAE is:6.18 & sMAPE is:54.89% & rMAE is:11.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 49.52% & 4.29\n",
      "for 2020-05-10, MAE is:4.41 & sMAPE is:44.04% & rMAE is:10.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 49.47% & 4.33\n",
      "for 2020-05-11, MAE is:6.91 & sMAPE is:61.55% & rMAE is:13.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 49.57% & 4.40\n",
      "for 2020-05-12, MAE is:2.94 & sMAPE is:24.50% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 49.38% & 4.37\n",
      "for 2020-05-13, MAE is:0.91 & sMAPE is:6.62% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 49.06% & 4.34\n",
      "for 2020-05-14, MAE is:2.32 & sMAPE is:15.89% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 48.81% & 4.31\n",
      "for 2020-05-15, MAE is:2.49 & sMAPE is:18.28% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 48.59% & 4.29\n",
      "for 2020-05-16, MAE is:5.19 & sMAPE is:43.13% & rMAE is:3.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 48.55% & 4.28\n",
      "for 2020-05-17, MAE is:8.13 & sMAPE is:58.24% & rMAE is:3.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 48.62% & 4.27\n",
      "for 2020-05-18, MAE is:2.46 & sMAPE is:16.25% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 48.39% & 4.25\n",
      "for 2020-05-19, MAE is:2.87 & sMAPE is:21.48% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 48.19% & 4.22\n",
      "for 2020-05-20, MAE is:10.43 & sMAPE is:35.11% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 48.10% & 4.20\n",
      "for 2020-05-21, MAE is:1.58 & sMAPE is:11.18% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 47.84% & 4.18\n",
      "for 2020-05-22, MAE is:7.00 & sMAPE is:54.80% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 47.89% & 4.16\n",
      "for 2020-05-23, MAE is:10.30 & sMAPE is:113.50% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 48.34% & 4.15\n",
      "for 2020-05-24, MAE is:5.79 & sMAPE is:94.17% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 48.66% & 4.13\n",
      "for 2020-05-25, MAE is:6.70 & sMAPE is:63.40% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 48.76% & 4.11\n",
      "for 2020-05-26, MAE is:12.01 & sMAPE is:114.64% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 49.21% & 4.09\n",
      "for 2020-05-27, MAE is:6.55 & sMAPE is:85.12% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 49.45% & 4.06\n",
      "for 2020-05-28, MAE is:7.03 & sMAPE is:94.52% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 49.75% & 4.04\n",
      "for 2020-05-29, MAE is:10.45 & sMAPE is:109.90% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 50.16% & 4.02\n",
      "for 2020-05-30, MAE is:8.17 & sMAPE is:102.25% & rMAE is:9.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 50.50% & 4.06\n",
      "for 2020-05-31, MAE is:9.81 & sMAPE is:138.44% & rMAE is:3.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 51.08% & 4.06\n",
      "for 2020-06-01, MAE is:5.29 & sMAPE is:71.64% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 51.21% & 4.04\n",
      "for 2020-06-02, MAE is:5.30 & sMAPE is:59.69% & rMAE is:3.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 51.27% & 4.04\n",
      "for 2020-06-03, MAE is:2.81 & sMAPE is:32.80% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 51.15% & 4.02\n",
      "for 2020-06-04, MAE is:7.08 & sMAPE is:84.21% & rMAE is:5.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 51.36% & 4.02\n",
      "for 2020-06-05, MAE is:8.31 & sMAPE is:115.30% & rMAE is:7.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 51.77% & 4.04\n",
      "for 2020-06-06, MAE is:7.13 & sMAPE is:114.08% & rMAE is:5.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 52.16% & 4.05\n",
      "for 2020-06-07, MAE is:6.98 & sMAPE is:114.42% & rMAE is:5.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 52.55% & 4.06\n",
      "for 2020-06-08, MAE is:5.90 & sMAPE is:77.87% & rMAE is:2.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 52.71% & 4.05\n",
      "for 2020-06-09, MAE is:5.66 & sMAPE is:65.02% & rMAE is:3.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 52.79% & 4.04\n",
      "for 2020-06-10, MAE is:8.50 & sMAPE is:99.08% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 53.08% & 4.03\n",
      "for 2020-06-11, MAE is:6.18 & sMAPE is:103.31% & rMAE is:3.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 53.38% & 4.03\n",
      "for 2020-06-12, MAE is:8.83 & sMAPE is:131.10% & rMAE is:13.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 53.86% & 4.08\n",
      "for 2020-06-13, MAE is:11.21 & sMAPE is:155.22% & rMAE is:9.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 54.47% & 4.11\n",
      "for 2020-06-14, MAE is:8.51 & sMAPE is:131.10% & rMAE is:15.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 54.93% & 4.18\n",
      "for 2020-06-15, MAE is:8.20 & sMAPE is:112.34% & rMAE is:3.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 55.28% & 4.18\n",
      "for 2020-06-16, MAE is:12.05 & sMAPE is:134.05% & rMAE is:3.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 55.75% & 4.17\n",
      "for 2020-06-17, MAE is:9.59 & sMAPE is:132.67% & rMAE is:4.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 56.20% & 4.18\n",
      "for 2020-06-18, MAE is:10.67 & sMAPE is:142.99% & rMAE is:10.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 56.71% & 4.22\n",
      "for 2020-06-19, MAE is:10.36 & sMAPE is:140.91% & rMAE is:13.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 57.20% & 4.27\n",
      "for 2020-06-20, MAE is:10.80 & sMAPE is:153.96% & rMAE is:35.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 57.77% & 4.45\n",
      "for 2020-06-21, MAE is:9.93 & sMAPE is:151.39% & rMAE is:8.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 58.31% & 4.47\n",
      "for 2020-06-22, MAE is:9.41 & sMAPE is:131.74% & rMAE is:8.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 58.73% & 4.49\n",
      "for 2020-06-23, MAE is:11.32 & sMAPE is:152.41% & rMAE is:8.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 59.27% & 4.52\n",
      "for 2020-06-24, MAE is:14.71 & sMAPE is:163.83% & rMAE is:17.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 59.86% & 4.59\n",
      "for 2020-06-25, MAE is:14.45 & sMAPE is:163.20% & rMAE is:26.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 60.44% & 4.72\n",
      "for 2020-06-26, MAE is:12.53 & sMAPE is:140.22% & rMAE is:24.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 60.89% & 4.83\n",
      "for 2020-06-27, MAE is:10.41 & sMAPE is:132.85% & rMAE is:10.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 61.29% & 4.86\n",
      "for 2020-06-28, MAE is:14.12 & sMAPE is:154.92% & rMAE is:26.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 61.81% & 4.98\n",
      "for 2020-06-29, MAE is:11.42 & sMAPE is:139.30% & rMAE is:11.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 62.24% & 5.02\n",
      "for 2020-06-30, MAE is:12.65 & sMAPE is:158.92% & rMAE is:66.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 62.77% & 5.36\n",
      "for 2020-07-01, MAE is:8.51 & sMAPE is:141.53% & rMAE is:14.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 63.20% & 5.41\n",
      "for 2020-07-02, MAE is:11.37 & sMAPE is:138.90% & rMAE is:12.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 63.61% & 5.45\n",
      "for 2020-07-03, MAE is:12.72 & sMAPE is:142.32% & rMAE is:28.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 64.04% & 5.57\n",
      "for 2020-07-04, MAE is:10.23 & sMAPE is:141.66% & rMAE is:9.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 64.46% & 5.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-07-05, MAE is:13.75 & sMAPE is:172.26% & rMAE is:13.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 65.03% & 5.63\n",
      "for 2020-07-06, MAE is:14.85 & sMAPE is:171.08% & rMAE is:13.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 65.60% & 5.67\n",
      "for 2020-07-07, MAE is:15.75 & sMAPE is:158.84% & rMAE is:33.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 66.09% & 5.82\n",
      "for 2020-07-08, MAE is:10.47 & sMAPE is:145.60% & rMAE is:20.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 66.51% & 5.90\n",
      "for 2020-07-09, MAE is:3.33 & sMAPE is:87.72% & rMAE is:6.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 66.62% & 5.91\n",
      "for 2020-07-10, MAE is:1.31 & sMAPE is:37.74% & rMAE is:2.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 66.47% & 5.89\n",
      "for 2020-07-11, MAE is:2.44 & sMAPE is:79.87% & rMAE is:2.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 66.54% & 5.87\n",
      "for 2020-07-12, MAE is:10.45 & sMAPE is:138.63% & rMAE is:7.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 66.91% & 5.88\n",
      "for 2020-07-13, MAE is:1.01 & sMAPE is:24.92% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 66.70% & 5.85\n",
      "for 2020-07-14, MAE is:1.37 & sMAPE is:35.33% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 66.54% & 5.83\n",
      "for 2020-07-15, MAE is:0.73 & sMAPE is:19.60% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 66.30% & 5.80\n",
      "for 2020-07-16, MAE is:1.84 & sMAPE is:38.98% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 66.16% & 5.78\n",
      "for 2020-07-17, MAE is:0.68 & sMAPE is:17.15% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 65.91% & 5.75\n",
      "for 2020-07-18, MAE is:7.51 & sMAPE is:103.00% & rMAE is:4.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 66.10% & 5.75\n",
      "for 2020-07-19, MAE is:0.71 & sMAPE is:17.90% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 65.86% & 5.72\n",
      "for 2020-07-20, MAE is:0.76 & sMAPE is:20.45% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 65.63% & 5.70\n",
      "for 2020-07-21, MAE is:1.07 & sMAPE is:26.82% & rMAE is:3.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 65.44% & 5.69\n",
      "for 2020-07-22, MAE is:2.33 & sMAPE is:56.93% & rMAE is:5.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 65.40% & 5.69\n",
      "for 2020-07-23, MAE is:2.15 & sMAPE is:59.23% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 65.37% & 5.67\n",
      "for 2020-07-24, MAE is:2.89 & sMAPE is:68.29% & rMAE is:3.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 65.39% & 5.66\n",
      "for 2020-07-25, MAE is:1.69 & sMAPE is:45.65% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 65.29% & 5.64\n",
      "for 2020-07-26, MAE is:2.26 & sMAPE is:70.79% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 65.32% & 5.62\n",
      "for 2020-07-27, MAE is:0.86 & sMAPE is:31.07% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 65.15% & 5.60\n",
      "for 2020-07-28, MAE is:2.88 & sMAPE is:91.69% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 65.28% & 5.58\n",
      "for 2020-07-29, MAE is:2.80 & sMAPE is:85.93% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 65.38% & 5.57\n",
      "for 2020-07-30, MAE is:3.55 & sMAPE is:105.70% & rMAE is:3.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 65.57% & 5.56\n",
      "for 2020-07-31, MAE is:3.29 & sMAPE is:93.65% & rMAE is:3.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 65.70% & 5.55\n",
      "for 2020-08-01, MAE is:2.36 & sMAPE is:71.83% & rMAE is:3.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 65.73% & 5.54\n",
      "for 2020-08-02, MAE is:1.45 & sMAPE is:51.67% & rMAE is:3.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 65.66% & 5.53\n",
      "for 2020-08-03, MAE is:2.11 & sMAPE is:66.19% & rMAE is:7.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 65.66% & 5.54\n",
      "for 2020-08-04, MAE is:1.91 & sMAPE is:58.13% & rMAE is:2.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 65.63% & 5.53\n",
      "for 2020-08-05, MAE is:2.46 & sMAPE is:66.25% & rMAE is:4.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 65.63% & 5.52\n",
      "for 2020-08-06, MAE is:3.32 & sMAPE is:75.88% & rMAE is:3.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 65.68% & 5.51\n",
      "for 2020-08-07, MAE is:1.23 & sMAPE is:35.38% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 65.54% & 5.49\n",
      "for 2020-08-08, MAE is:1.87 & sMAPE is:49.78% & rMAE is:2.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 65.47% & 5.48\n",
      "for 2020-08-09, MAE is:2.32 & sMAPE is:54.36% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 65.42% & 5.46\n",
      "for 2020-08-10, MAE is:0.82 & sMAPE is:24.72% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 65.24% & 5.44\n",
      "for 2020-08-11, MAE is:0.80 & sMAPE is:16.42% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 65.02% & 5.42\n",
      "for 2020-08-12, MAE is:0.61 & sMAPE is:11.06% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 64.78% & 5.39\n",
      "for 2020-08-13, MAE is:1.29 & sMAPE is:24.33% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 64.60% & 5.37\n",
      "for 2020-08-14, MAE is:1.40 & sMAPE is:26.80% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 64.43% & 5.35\n",
      "for 2020-08-15, MAE is:1.70 & sMAPE is:36.14% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 64.31% & 5.33\n",
      "for 2020-08-16, MAE is:2.67 & sMAPE is:50.86% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 64.25% & 5.31\n",
      "for 2020-08-17, MAE is:1.44 & sMAPE is:23.14% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 64.07% & 5.29\n",
      "for 2020-08-18, MAE is:2.40 & sMAPE is:41.24% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 63.97% & 5.27\n",
      "for 2020-08-19, MAE is:3.39 & sMAPE is:63.44% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 63.97% & 5.25\n",
      "for 2020-08-20, MAE is:2.99 & sMAPE is:52.46% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 63.92% & 5.24\n",
      "for 2020-08-21, MAE is:3.26 & sMAPE is:63.30% & rMAE is:4.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 63.92% & 5.24\n",
      "for 2020-08-22, MAE is:1.25 & sMAPE is:22.05% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 63.74% & 5.23\n",
      "for 2020-08-23, MAE is:1.13 & sMAPE is:23.53% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 63.57% & 5.21\n",
      "for 2020-08-24, MAE is:1.70 & sMAPE is:34.29% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 63.45% & 5.19\n",
      "for 2020-08-25, MAE is:2.55 & sMAPE is:45.88% & rMAE is:3.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 63.37% & 5.18\n",
      "for 2020-08-26, MAE is:4.06 & sMAPE is:65.73% & rMAE is:3.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 63.38% & 5.17\n",
      "for 2020-08-27, MAE is:5.36 & sMAPE is:72.43% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 63.42% & 5.16\n",
      "for 2020-08-28, MAE is:8.61 & sMAPE is:125.86% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 63.68% & 5.15\n",
      "for 2020-08-29, MAE is:8.96 & sMAPE is:100.31% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 63.83% & 5.13\n",
      "for 2020-08-30, MAE is:11.07 & sMAPE is:110.62% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 64.02% & 5.11\n",
      "for 2020-08-31, MAE is:16.76 & sMAPE is:119.66% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 64.25% & 5.10\n",
      "for 2020-09-01, MAE is:14.46 & sMAPE is:127.25% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 64.51% & 5.08\n",
      "for 2020-09-02, MAE is:14.89 & sMAPE is:122.15% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 64.74% & 5.07\n",
      "for 2020-09-03, MAE is:12.84 & sMAPE is:112.15% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 64.94% & 5.05\n",
      "for 2020-09-04, MAE is:12.39 & sMAPE is:106.06% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 65.10% & 5.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-09-05, MAE is:12.42 & sMAPE is:114.94% & rMAE is:3.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 65.30% & 5.03\n",
      "for 2020-09-06, MAE is:12.96 & sMAPE is:114.75% & rMAE is:5.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 65.50% & 5.04\n",
      "for 2020-09-07, MAE is:12.31 & sMAPE is:111.62% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 65.68% & 5.03\n",
      "for 2020-09-08, MAE is:6.87 & sMAPE is:89.11% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 65.78% & 5.01\n",
      "for 2020-09-09, MAE is:9.00 & sMAPE is:86.14% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 65.86% & 5.00\n",
      "for 2020-09-10, MAE is:7.97 & sMAPE is:95.39% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 65.97% & 4.98\n",
      "for 2020-09-11, MAE is:9.12 & sMAPE is:95.51% & rMAE is:2.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 66.09% & 4.97\n",
      "for 2020-09-12, MAE is:6.98 & sMAPE is:93.63% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 66.20% & 4.96\n",
      "for 2020-09-13, MAE is:5.31 & sMAPE is:75.45% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 66.23% & 4.94\n",
      "for 2020-09-14, MAE is:11.90 & sMAPE is:114.81% & rMAE is:4.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 66.42% & 4.94\n",
      "for 2020-09-15, MAE is:10.99 & sMAPE is:118.72% & rMAE is:2.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 66.62% & 4.93\n",
      "for 2020-09-16, MAE is:4.40 & sMAPE is:55.58% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 66.58% & 4.92\n",
      "for 2020-09-17, MAE is:6.10 & sMAPE is:79.04% & rMAE is:3.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 66.63% & 4.91\n",
      "for 2020-09-18, MAE is:3.10 & sMAPE is:61.59% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 66.61% & 4.89\n",
      "for 2020-09-19, MAE is:2.33 & sMAPE is:46.50% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 66.53% & 4.88\n",
      "for 2020-09-20, MAE is:1.78 & sMAPE is:63.84% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 66.52% & 4.86\n",
      "for 2020-09-21, MAE is:2.15 & sMAPE is:50.15% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 66.46% & 4.84\n",
      "for 2020-09-22, MAE is:3.60 & sMAPE is:69.61% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 66.47% & 4.83\n",
      "for 2020-09-23, MAE is:0.90 & sMAPE is:16.50% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 66.29% & 4.81\n",
      "for 2020-09-24, MAE is:1.23 & sMAPE is:33.26% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 66.16% & 4.79\n",
      "for 2020-09-25, MAE is:1.46 & sMAPE is:46.63% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 66.09% & 4.78\n",
      "for 2020-09-26, MAE is:1.88 & sMAPE is:49.09% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 66.03% & 4.76\n",
      "for 2020-09-27, MAE is:2.10 & sMAPE is:63.15% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 66.02% & 4.75\n",
      "for 2020-09-28, MAE is:1.96 & sMAPE is:52.23% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 65.96% & 4.74\n",
      "for 2020-09-29, MAE is:2.85 & sMAPE is:69.30% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 65.98% & 4.72\n",
      "for 2020-09-30, MAE is:5.57 & sMAPE is:83.12% & rMAE is:3.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 66.04% & 4.72\n",
      "for 2020-10-01, MAE is:1.33 & sMAPE is:33.90% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 65.92% & 4.70\n",
      "for 2020-10-02, MAE is:1.56 & sMAPE is:37.34% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 65.82% & 4.69\n",
      "for 2020-10-03, MAE is:1.03 & sMAPE is:33.49% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 65.70% & 4.68\n",
      "for 2020-10-04, MAE is:1.64 & sMAPE is:40.34% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 65.61% & 4.67\n",
      "for 2020-10-05, MAE is:0.89 & sMAPE is:19.03% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 65.44% & 4.65\n",
      "for 2020-10-06, MAE is:0.67 & sMAPE is:13.92% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 65.26% & 4.64\n",
      "for 2020-10-07, MAE is:1.45 & sMAPE is:27.60% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 65.13% & 4.62\n",
      "for 2020-10-08, MAE is:3.37 & sMAPE is:54.35% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 65.09% & 4.61\n",
      "for 2020-10-09, MAE is:5.50 & sMAPE is:73.98% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 65.12% & 4.59\n",
      "for 2020-10-10, MAE is:7.92 & sMAPE is:93.11% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 65.22% & 4.58\n",
      "for 2020-10-11, MAE is:11.45 & sMAPE is:112.19% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 65.38% & 4.57\n",
      "for 2020-10-12, MAE is:12.71 & sMAPE is:126.30% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 65.60% & 4.56\n",
      "for 2020-10-13, MAE is:12.49 & sMAPE is:112.69% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 65.76% & 4.54\n",
      "for 2020-10-14, MAE is:0.99 & sMAPE is:6.24% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 65.55% & 4.53\n",
      "for 2020-10-15, MAE is:4.55 & sMAPE is:30.67% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 65.43% & 4.51\n",
      "for 2020-10-16, MAE is:11.88 & sMAPE is:102.67% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 65.56% & 4.50\n",
      "for 2020-10-17, MAE is:6.81 & sMAPE is:76.38% & rMAE is:23.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 65.60% & 4.57\n",
      "for 2020-10-18, MAE is:10.31 & sMAPE is:101.97% & rMAE is:5.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 65.72% & 4.57\n",
      "for 2020-10-19, MAE is:17.12 & sMAPE is:130.03% & rMAE is:3.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 65.94% & 4.57\n",
      "for 2020-10-20, MAE is:2.34 & sMAPE is:11.94% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 65.76% & 4.56\n",
      "for 2020-10-21, MAE is:13.92 & sMAPE is:110.18% & rMAE is:5.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 65.91% & 4.56\n",
      "for 2020-10-22, MAE is:2.94 & sMAPE is:19.58% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 65.75% & 4.54\n",
      "for 2020-10-23, MAE is:2.70 & sMAPE is:16.69% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 65.59% & 4.53\n",
      "for 2020-10-24, MAE is:1.71 & sMAPE is:13.55% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 65.41% & 4.52\n",
      "for 2020-10-25, MAE is:4.30 & sMAPE is:55.08% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 65.38% & 4.51\n",
      "for 2020-10-26, MAE is:3.20 & sMAPE is:27.34% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 65.25% & 4.49\n",
      "for 2020-10-27, MAE is:1.78 & sMAPE is:13.56% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 65.08% & 4.48\n",
      "for 2020-10-28, MAE is:1.23 & sMAPE is:12.01% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 64.90% & 4.47\n",
      "for 2020-10-29, MAE is:6.14 & sMAPE is:76.97% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 64.94% & 4.46\n",
      "for 2020-10-30, MAE is:5.16 & sMAPE is:70.83% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 64.96% & 4.44\n",
      "for 2020-10-31, MAE is:1.99 & sMAPE is:24.83% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 64.83% & 4.43\n",
      "for 2020-11-01, MAE is:2.03 & sMAPE is:39.46% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 64.75% & 4.42\n",
      "for 2020-11-02, MAE is:1.36 & sMAPE is:36.44% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 64.66% & 4.40\n",
      "for 2020-11-03, MAE is:1.53 & sMAPE is:34.27% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 64.56% & 4.39\n",
      "for 2020-11-04, MAE is:2.30 & sMAPE is:52.12% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 64.52% & 4.38\n",
      "for 2020-11-05, MAE is:1.20 & sMAPE is:48.09% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 64.46% & 4.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-11-06, MAE is:1.35 & sMAPE is:49.45% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 64.42% & 4.35\n",
      "for 2020-11-07, MAE is:1.09 & sMAPE is:33.25% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 64.32% & 4.34\n",
      "for 2020-11-08, MAE is:1.04 & sMAPE is:19.46% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 64.17% & 4.33\n",
      "for 2020-11-09, MAE is:1.64 & sMAPE is:25.26% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 64.05% & 4.32\n",
      "for 2020-11-10, MAE is:0.69 & sMAPE is:7.59% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 63.87% & 4.30\n",
      "for 2020-11-11, MAE is:2.76 & sMAPE is:36.92% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 63.78% & 4.29\n",
      "for 2020-11-12, MAE is:0.89 & sMAPE is:15.40% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 63.63% & 4.28\n",
      "for 2020-11-13, MAE is:0.91 & sMAPE is:21.37% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 63.50% & 4.27\n",
      "for 2020-11-14, MAE is:0.75 & sMAPE is:21.01% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 63.37% & 4.26\n",
      "for 2020-11-15, MAE is:1.63 & sMAPE is:47.07% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 63.32% & 4.24\n",
      "for 2020-11-16, MAE is:1.19 & sMAPE is:40.80% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 63.24% & 4.23\n",
      "for 2020-11-17, MAE is:2.57 & sMAPE is:59.96% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 63.23% & 4.22\n",
      "for 2020-11-18, MAE is:1.58 & sMAPE is:47.17% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 63.18% & 4.21\n",
      "for 2020-11-19, MAE is:0.81 & sMAPE is:36.48% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 63.10% & 4.19\n",
      "for 2020-11-20, MAE is:0.65 & sMAPE is:21.73% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 62.98% & 4.18\n",
      "for 2020-11-21, MAE is:1.20 & sMAPE is:40.88% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 62.91% & 4.17\n",
      "for 2020-11-22, MAE is:0.80 & sMAPE is:68.42% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 62.92% & 4.16\n",
      "for 2020-11-23, MAE is:1.97 & sMAPE is:68.62% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 62.94% & 4.16\n",
      "for 2020-11-24, MAE is:1.63 & sMAPE is:30.09% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 62.84% & 4.15\n",
      "for 2020-11-25, MAE is:0.88 & sMAPE is:17.97% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 62.71% & 4.13\n",
      "for 2020-11-26, MAE is:2.31 & sMAPE is:39.62% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 62.64% & 4.12\n",
      "for 2020-11-27, MAE is:1.88 & sMAPE is:24.01% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 62.52% & 4.11\n",
      "for 2020-11-28, MAE is:3.55 & sMAPE is:44.21% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 62.46% & 4.10\n",
      "for 2020-11-29, MAE is:4.62 & sMAPE is:54.11% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 62.44% & 4.09\n",
      "for 2020-11-30, MAE is:1.44 & sMAPE is:12.56% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 62.29% & 4.08\n",
      "for 2020-12-01, MAE is:3.60 & sMAPE is:38.25% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 62.22% & 4.07\n",
      "for 2020-12-02, MAE is:0.48 & sMAPE is:4.76% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 62.05% & 4.06\n",
      "for 2020-12-03, MAE is:1.52 & sMAPE is:16.57% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 61.91% & 4.05\n",
      "for 2020-12-04, MAE is:3.81 & sMAPE is:38.07% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 61.84% & 4.04\n",
      "for 2020-12-05, MAE is:2.51 & sMAPE is:19.06% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 61.72% & 4.03\n",
      "for 2020-12-06, MAE is:1.23 & sMAPE is:8.86% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 61.56% & 4.02\n",
      "for 2020-12-07, MAE is:4.20 & sMAPE is:27.77% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 61.46% & 4.01\n",
      "for 2020-12-08, MAE is:1.63 & sMAPE is:13.70% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 61.33% & 4.00\n",
      "for 2020-12-09, MAE is:1.65 & sMAPE is:12.39% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 61.18% & 3.99\n",
      "for 2020-12-10, MAE is:1.41 & sMAPE is:10.07% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 61.03% & 3.98\n",
      "for 2020-12-11, MAE is:0.76 & sMAPE is:5.84% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 60.88% & 3.97\n",
      "for 2020-12-12, MAE is:3.47 & sMAPE is:27.92% & rMAE is:3.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 60.78% & 3.97\n",
      "for 2020-12-13, MAE is:2.33 & sMAPE is:15.74% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 60.65% & 3.96\n",
      "for 2020-12-14, MAE is:1.07 & sMAPE is:7.69% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 60.50% & 3.95\n",
      "for 2020-12-15, MAE is:4.61 & sMAPE is:28.48% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 60.41% & 3.94\n",
      "for 2020-12-16, MAE is:1.88 & sMAPE is:9.11% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 60.26% & 3.93\n",
      "for 2020-12-17, MAE is:4.94 & sMAPE is:26.22% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 60.16% & 3.93\n",
      "for 2020-12-18, MAE is:1.72 & sMAPE is:10.67% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 60.02% & 3.92\n",
      "for 2020-12-19, MAE is:1.90 & sMAPE is:12.35% & rMAE is:2.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 59.89% & 3.91\n",
      "for 2020-12-20, MAE is:1.10 & sMAPE is:8.84% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 59.75% & 3.90\n",
      "for 2020-12-21, MAE is:1.57 & sMAPE is:11.16% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 59.61% & 3.90\n",
      "for 2020-12-22, MAE is:2.85 & sMAPE is:24.11% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 59.51% & 3.89\n",
      "for 2020-12-23, MAE is:0.70 & sMAPE is:5.74% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 59.36% & 3.88\n",
      "for 2020-12-24, MAE is:3.03 & sMAPE is:25.87% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 59.27% & 3.87\n",
      "for 2020-12-25, MAE is:2.53 & sMAPE is:18.96% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 59.15% & 3.86\n",
      "for 2020-12-26, MAE is:1.48 & sMAPE is:11.26% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 59.02% & 3.86\n",
      "for 2020-12-27, MAE is:2.65 & sMAPE is:36.43% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 58.96% & 3.85\n",
      "for 2020-12-28, MAE is:4.69 & sMAPE is:43.91% & rMAE is:3.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 58.92% & 3.84\n",
      "for 2020-12-29, MAE is:1.30 & sMAPE is:8.86% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 58.78% & 3.83\n",
      "for 2020-12-30, MAE is:5.06 & sMAPE is:30.31% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 58.70% & 3.83\n",
      "for 2020-12-31, MAE is:4.89 & sMAPE is:22.04% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 58.60% & 3.82\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 05:57:41,096]\u001b[0m A new study created in RDB with name: NO_3_2021\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:57:53,899]\u001b[0m Trial 0 finished with value: 4.264999181076455 and parameters: {'n_hidden': 3, 'learning_rate': 0.007147959397127361, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2786551337740168, 'dropout_rate_Layer_2': 0.3883031915691393, 'dropout_rate_Layer_3': 0.016138375167498786, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0903443018761487, 'l1_Layer_2': 0.005162379622926509, 'l1_Layer_3': 0.02273640007851674, 'n_units_Layer_1': 295, 'n_units_Layer_2': 145, 'n_units_Layer_3': 115}. Best is trial 0 with value: 4.264999181076455.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 53.63% | rMAE for Validation Set is: 1.28\n",
      "MAE for Test Set is: 12.09 | sMAPE for Test Set is: 35.79% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 05:58:05,679]\u001b[0m Trial 1 finished with value: 3.716315928464038 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012127121183456019, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2459497350894286, 'dropout_rate_Layer_2': 0.21899177412405427, 'dropout_rate_Layer_3': 0.3729163950821329, 'dropout_rate_Layer_4': 0.0153748211631636, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.3170999453530912e-05, 'l1_Layer_2': 0.003157765283070633, 'l1_Layer_3': 4.1095542929019694e-05, 'l1_Layer_4': 0.032872591052016384, 'n_units_Layer_1': 205, 'n_units_Layer_2': 60, 'n_units_Layer_3': 175, 'n_units_Layer_4': 150}. Best is trial 1 with value: 3.716315928464038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 47.93% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 13.59 | sMAPE for Test Set is: 37.39% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 05:58:13,571]\u001b[0m Trial 2 finished with value: 13.98571806869135 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008646503410685363, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05897902027996454, 'dropout_rate_Layer_2': 0.37648306516405067, 'dropout_rate_Layer_3': 0.16437749478997554, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.458434426224544e-05, 'l1_Layer_2': 0.00018031917186891143, 'l1_Layer_3': 0.02192411134687026, 'n_units_Layer_1': 185, 'n_units_Layer_2': 265, 'n_units_Layer_3': 60}. Best is trial 1 with value: 3.716315928464038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.99 | sMAPE for Validation Set is: 98.80% | rMAE for Validation Set is: 4.20\n",
      "MAE for Test Set is: 10.20 | sMAPE for Test Set is: 24.74% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 05:58:15,799]\u001b[0m Trial 4 finished with value: 3.4172566158404027 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006913762798026255, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06090577418255046, 'dropout_rate_Layer_2': 0.33501530029822935, 'dropout_rate_Layer_3': 0.37977112944181424, 'dropout_rate_Layer_4': 0.13132634683413588, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00015516333930137155, 'l1_Layer_2': 0.023401140505209687, 'l1_Layer_3': 0.00293535824106484, 'l1_Layer_4': 0.00016037260768601188, 'n_units_Layer_1': 185, 'n_units_Layer_2': 205, 'n_units_Layer_3': 235, 'n_units_Layer_4': 245}. Best is trial 4 with value: 3.4172566158404027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.42 | sMAPE for Validation Set is: 43.68% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 24.79 | sMAPE for Test Set is: 77.81% | rMAE for Test Set is: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 05:58:17,501]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:58:20,986]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:58:23,676]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:58:27,237]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:58:29,604]\u001b[0m Trial 5 finished with value: 5.575036798930323 and parameters: {'n_hidden': 3, 'learning_rate': 0.006676955557878902, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38054853334862243, 'dropout_rate_Layer_2': 0.3012640063359684, 'dropout_rate_Layer_3': 0.046229190048197435, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.06135994777181022, 'l1_Layer_2': 0.0027147319387116455, 'l1_Layer_3': 0.019305320077624512, 'n_units_Layer_1': 185, 'n_units_Layer_2': 95, 'n_units_Layer_3': 95}. Best is trial 4 with value: 3.4172566158404027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 67.82% | rMAE for Validation Set is: 1.68\n",
      "MAE for Test Set is: 36.12 | sMAPE for Test Set is: 145.40% | rMAE for Test Set is: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 05:58:33,970]\u001b[0m Trial 3 finished with value: 10.033609018007029 and parameters: {'n_hidden': 4, 'learning_rate': 0.049224050948129566, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3697991163482328, 'dropout_rate_Layer_2': 0.38820486587233527, 'dropout_rate_Layer_3': 0.02389933498614072, 'dropout_rate_Layer_4': 0.33903011083578766, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00040365265511077206, 'l1_Layer_2': 1.584953558912273e-05, 'l1_Layer_3': 0.027606441917524076, 'l1_Layer_4': 0.05682918627887609, 'n_units_Layer_1': 275, 'n_units_Layer_2': 225, 'n_units_Layer_3': 125, 'n_units_Layer_4': 65}. Best is trial 4 with value: 3.4172566158404027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.03 | sMAPE for Validation Set is: 84.74% | rMAE for Validation Set is: 3.02\n",
      "MAE for Test Set is: 11.61 | sMAPE for Test Set is: 29.39% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 05:58:35,762]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:58:38,672]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:58:41,569]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:58:41,820]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:58:47,725]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:58:49,303]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:58:52,277]\u001b[0m Trial 9 finished with value: 3.880192876345406 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007654944436739499, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2617498000152638, 'dropout_rate_Layer_2': 0.0674468719708886, 'dropout_rate_Layer_3': 0.11373855237660041, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3438562427743202e-05, 'l1_Layer_2': 0.00024019517366596682, 'l1_Layer_3': 0.004906539220706214, 'n_units_Layer_1': 245, 'n_units_Layer_2': 220, 'n_units_Layer_3': 80}. Best is trial 4 with value: 3.4172566158404027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 50.60% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 22.51 | sMAPE for Test Set is: 65.86% | rMAE for Test Set is: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 05:58:56,303]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:58:58,594]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:59:01,303]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:59:01,384]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:59:02,141]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:59:07,255]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:59:07,570]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:59:07,780]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:59:22,139]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:59:27,862]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:59:31,724]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:59:34,426]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:59:38,151]\u001b[0m Trial 22 finished with value: 6.0867017943790485 and parameters: {'n_hidden': 4, 'learning_rate': 0.0029277852175639786, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10841580502187238, 'dropout_rate_Layer_2': 0.15317791929830596, 'dropout_rate_Layer_3': 0.2360957340097853, 'dropout_rate_Layer_4': 0.15181538376384537, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.000621739723247607, 'l1_Layer_2': 7.388795238893995e-05, 'l1_Layer_3': 2.6911665314289847e-05, 'l1_Layer_4': 0.008529641431051362, 'n_units_Layer_1': 80, 'n_units_Layer_2': 95, 'n_units_Layer_3': 95, 'n_units_Layer_4': 245}. Best is trial 4 with value: 3.4172566158404027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 77.02% | rMAE for Validation Set is: 1.83\n",
      "MAE for Test Set is: 37.44 | sMAPE for Test Set is: 157.49% | rMAE for Test Set is: 2.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 05:59:41,370]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:59:44,223]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:59:52,996]\u001b[0m Trial 32 finished with value: 5.316036694826853 and parameters: {'n_hidden': 4, 'learning_rate': 0.002606761828777264, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.050058910177670016, 'dropout_rate_Layer_2': 0.3055493113350943, 'dropout_rate_Layer_3': 0.2690449184624874, 'dropout_rate_Layer_4': 0.12374663554150951, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0035163578536126523, 'l1_Layer_2': 0.004304894963283737, 'l1_Layer_3': 2.0828027118542666e-05, 'l1_Layer_4': 0.00034264612652357476, 'n_units_Layer_1': 240, 'n_units_Layer_2': 235, 'n_units_Layer_3': 260, 'n_units_Layer_4': 65}. Best is trial 4 with value: 3.4172566158404027.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 05:59:53,038]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 63.94% | rMAE for Validation Set is: 1.60\n",
      "MAE for Test Set is: 34.83 | sMAPE for Test Set is: 134.22% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:00:00,461]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:03,441]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:05,465]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:08,729]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:08,991]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:14,201]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:17,123]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:18,484]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:22,029]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:22,260]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:27,007]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:30,274]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:32,145]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:37,155]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:41,170]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:41,397]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:41,836]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:42,438]\u001b[0m Trial 38 finished with value: 3.883673546406109 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014970373936523502, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.059964821603026054, 'dropout_rate_Layer_2': 0.20791651548515186, 'dropout_rate_Layer_3': 0.22559037749304942, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05102764073322676, 'l1_Layer_2': 0.000527002966191463, 'l1_Layer_3': 0.006157291866400278, 'n_units_Layer_1': 250, 'n_units_Layer_2': 70, 'n_units_Layer_3': 75}. Best is trial 4 with value: 3.4172566158404027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 65.06% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 8.64 | sMAPE for Test Set is: 22.51% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:00:47,480]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:49,633]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:50,303]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:55,497]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:00:57,049]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:01:02,440]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:01:06,866]\u001b[0m Trial 53 finished with value: 1.6931535896934922 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032836107680208125, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1334872061981399, 'dropout_rate_Layer_2': 0.3937899305058893, 'dropout_rate_Layer_3': 0.17425217122401074, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06975947848067154, 'l1_Layer_2': 0.0915007525478255, 'l1_Layer_3': 0.002169392648263578, 'n_units_Layer_1': 160, 'n_units_Layer_2': 125, 'n_units_Layer_3': 50}. Best is trial 53 with value: 1.6931535896934922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.69 | sMAPE for Validation Set is: 25.90% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 7.35 | sMAPE for Test Set is: 18.19% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:01:10,708]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:01:11,510]\u001b[0m Trial 56 finished with value: 2.878404623667676 and parameters: {'n_hidden': 3, 'learning_rate': 0.016171652918048757, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029369793610446164, 'dropout_rate_Layer_2': 0.37568216799974224, 'dropout_rate_Layer_3': 0.0776268038224037, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.825570372832589e-05, 'l1_Layer_2': 0.04742449454501979, 'l1_Layer_3': 0.0021484392792170725, 'n_units_Layer_1': 190, 'n_units_Layer_2': 205, 'n_units_Layer_3': 265}. Best is trial 53 with value: 1.6931535896934922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.88 | sMAPE for Validation Set is: 41.70% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 7.96 | sMAPE for Test Set is: 18.78% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:01:13,051]\u001b[0m Trial 60 finished with value: 2.182537087960274 and parameters: {'n_hidden': 3, 'learning_rate': 0.004347709659600837, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07017982885675632, 'dropout_rate_Layer_2': 0.3720216179656576, 'dropout_rate_Layer_3': 0.13171973157134043, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.0970211348743574e-05, 'l1_Layer_2': 0.043859999086438374, 'l1_Layer_3': 0.006505225126866291, 'n_units_Layer_1': 190, 'n_units_Layer_2': 205, 'n_units_Layer_3': 250}. Best is trial 53 with value: 1.6931535896934922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.18 | sMAPE for Validation Set is: 33.31% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.68 | sMAPE for Test Set is: 18.68% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:01:15,136]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:01:17,597]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:01:19,124]\u001b[0m Trial 61 finished with value: 2.5496660593448133 and parameters: {'n_hidden': 3, 'learning_rate': 0.005099742987389016, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023720004873471194, 'dropout_rate_Layer_2': 0.374640513404651, 'dropout_rate_Layer_3': 0.1206122054477394, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.767775132544052e-05, 'l1_Layer_2': 0.052706699119335905, 'l1_Layer_3': 0.005548220840924356, 'n_units_Layer_1': 195, 'n_units_Layer_2': 240, 'n_units_Layer_3': 250}. Best is trial 53 with value: 1.6931535896934922.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:01:19,145]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.55 | sMAPE for Validation Set is: 36.85% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 7.99 | sMAPE for Test Set is: 19.00% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:01:22,275]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:01:26,557]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:01:27,043]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:01:32,647]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:01:35,497]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.55 | sMAPE for Validation Set is: 37.33% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 8.35 | sMAPE for Test Set is: 21.45% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:01:37,564]\u001b[0m Trial 68 finished with value: 2.5478511295278756 and parameters: {'n_hidden': 3, 'learning_rate': 0.01868924663427946, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07417815807201603, 'dropout_rate_Layer_2': 0.13192333737649567, 'dropout_rate_Layer_3': 0.08273100818192235, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9802258281356583e-05, 'l1_Layer_2': 0.01523357327170781, 'l1_Layer_3': 0.011101873158193908, 'n_units_Layer_1': 215, 'n_units_Layer_2': 190, 'n_units_Layer_3': 210}. Best is trial 53 with value: 1.6931535896934922.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:01:40,426]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:01:42,490]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:01:46,188]\u001b[0m Trial 72 finished with value: 2.1418863786097027 and parameters: {'n_hidden': 3, 'learning_rate': 0.012006223249495152, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05332877087546728, 'dropout_rate_Layer_2': 0.3870157199323296, 'dropout_rate_Layer_3': 0.032515150100798515, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003291968471072998, 'l1_Layer_2': 0.01490726389383102, 'l1_Layer_3': 0.002502582117579209, 'n_units_Layer_1': 215, 'n_units_Layer_2': 210, 'n_units_Layer_3': 210}. Best is trial 53 with value: 1.6931535896934922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.14 | sMAPE for Validation Set is: 32.28% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.18 | sMAPE for Test Set is: 19.61% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:01:48,341]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:01:51,644]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:01:52,910]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:02:00,134]\u001b[0m Trial 77 finished with value: 1.8370376729674656 and parameters: {'n_hidden': 3, 'learning_rate': 0.022080760410396555, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011241539788538436, 'dropout_rate_Layer_2': 0.11431218678925703, 'dropout_rate_Layer_3': 0.17336134401787198, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1117371850397704e-05, 'l1_Layer_2': 0.08008882001502321, 'l1_Layer_3': 0.011599285361846736, 'n_units_Layer_1': 210, 'n_units_Layer_2': 215, 'n_units_Layer_3': 245}. Best is trial 53 with value: 1.6931535896934922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.84 | sMAPE for Validation Set is: 36.71% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 8.08 | sMAPE for Test Set is: 19.25% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:02:07,088]\u001b[0m Trial 80 finished with value: 2.042220160115507 and parameters: {'n_hidden': 3, 'learning_rate': 0.007276167992946902, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.114571978648173, 'dropout_rate_Layer_2': 0.0739366813980219, 'dropout_rate_Layer_3': 0.03998077413247504, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002728747077609982, 'l1_Layer_2': 0.032756965134066944, 'l1_Layer_3': 0.00239032208303426, 'n_units_Layer_1': 210, 'n_units_Layer_2': 215, 'n_units_Layer_3': 245}. Best is trial 53 with value: 1.6931535896934922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 31.98% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.93 | sMAPE for Test Set is: 19.43% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:02:07,452]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:02:13,359]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:02:16,163]\u001b[0m Trial 82 finished with value: 1.9520640814193666 and parameters: {'n_hidden': 3, 'learning_rate': 0.005725042361350091, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00030187645337590926, 'dropout_rate_Layer_2': 0.09193597709550898, 'dropout_rate_Layer_3': 0.13278519393600083, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.58420200879742e-05, 'l1_Layer_2': 0.016732695280464692, 'l1_Layer_3': 0.012621786858013637, 'n_units_Layer_1': 230, 'n_units_Layer_2': 235, 'n_units_Layer_3': 240}. Best is trial 53 with value: 1.6931535896934922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 29.50% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.13 | sMAPE for Test Set is: 19.86% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:02:25,730]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:02:26,219]\u001b[0m Trial 83 finished with value: 2.0072930025500946 and parameters: {'n_hidden': 3, 'learning_rate': 0.006836929055880774, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11496850319307077, 'dropout_rate_Layer_2': 0.07484122531063182, 'dropout_rate_Layer_3': 0.03619909162761479, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010785248491738242, 'l1_Layer_2': 0.017278328823515564, 'l1_Layer_3': 0.012551966562296686, 'n_units_Layer_1': 245, 'n_units_Layer_2': 190, 'n_units_Layer_3': 220}. Best is trial 53 with value: 1.6931535896934922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 30.21% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.96 | sMAPE for Test Set is: 19.86% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:02:31,408]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:02:35,188]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:02:36,539]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:02:40,465]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:02:44,368]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:02:44,595]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:02:49,499]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:02:52,390]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:02:53,412]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:02:57,306]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:02:58,890]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:03:02,851]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:03:06,762]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:03:11,248]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:03:15,105]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:03:17,753]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:03:22,222]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:03:26,369]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:03:30,725]\u001b[0m Trial 70 finished with value: 7.2551503229362595 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005752477680189339, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3775638620767605, 'dropout_rate_Layer_2': 0.07056986586092369, 'dropout_rate_Layer_3': 0.062461719895291305, 'dropout_rate_Layer_4': 0.04678897220480893, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.312755132067654e-05, 'l1_Layer_2': 0.00013370979794746925, 'l1_Layer_3': 0.0017888282298988375, 'l1_Layer_4': 2.4279509321063425e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 300, 'n_units_Layer_3': 160, 'n_units_Layer_4': 70}. Best is trial 53 with value: 1.6931535896934922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.26 | sMAPE for Validation Set is: 73.28% | rMAE for Validation Set is: 2.18\n",
      "MAE for Test Set is: 8.86 | sMAPE for Test Set is: 20.80% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:03:32,829]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:03:37,434]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:03:40,007]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:03:44,168]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:03:45,917]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:03:49,426]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:03:53,212]\u001b[0m Trial 106 finished with value: 1.5219031293244691 and parameters: {'n_hidden': 3, 'learning_rate': 0.005849623386067223, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1322183230667133, 'dropout_rate_Layer_2': 0.10327751160269863, 'dropout_rate_Layer_3': 0.053681461113363124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018129912369709625, 'l1_Layer_2': 0.004808873400460344, 'l1_Layer_3': 0.02032368484521323, 'n_units_Layer_1': 265, 'n_units_Layer_2': 210, 'n_units_Layer_3': 230}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 26.20% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 7.35 | sMAPE for Test Set is: 17.54% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:03:58,355]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:04:05,793]\u001b[0m Trial 109 finished with value: 1.677568949224806 and parameters: {'n_hidden': 3, 'learning_rate': 0.0059661108095639065, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13940766036755178, 'dropout_rate_Layer_2': 0.10320289157143434, 'dropout_rate_Layer_3': 0.05596758265310507, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013982977060199547, 'l1_Layer_2': 0.007602107752234694, 'l1_Layer_3': 0.009031625938000727, 'n_units_Layer_1': 265, 'n_units_Layer_2': 115, 'n_units_Layer_3': 190}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.68 | sMAPE for Validation Set is: 31.31% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 7.74 | sMAPE for Test Set is: 18.79% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:04:10,989]\u001b[0m Trial 112 finished with value: 8.066497234557321 and parameters: {'n_hidden': 4, 'learning_rate': 0.0062349937740425725, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25074100752570977, 'dropout_rate_Layer_2': 0.027116373573159172, 'dropout_rate_Layer_3': 0.3983032359437368, 'dropout_rate_Layer_4': 0.14839846202250295, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.826624562830165e-05, 'l1_Layer_2': 0.0010855696884958447, 'l1_Layer_3': 0.01800211252437783, 'l1_Layer_4': 0.006149951807118131, 'n_units_Layer_1': 250, 'n_units_Layer_2': 125, 'n_units_Layer_3': 300, 'n_units_Layer_4': 50}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.07 | sMAPE for Validation Set is: 141.72% | rMAE for Validation Set is: 2.42\n",
      "MAE for Test Set is: 39.36 | sMAPE for Test Set is: 179.40% | rMAE for Test Set is: 2.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:04:11,883]\u001b[0m Trial 113 finished with value: 2.379235307497345 and parameters: {'n_hidden': 3, 'learning_rate': 0.00597958779130927, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03412139948114119, 'dropout_rate_Layer_2': 0.1419398395195099, 'dropout_rate_Layer_3': 0.11055553784547331, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002489623518576744, 'l1_Layer_2': 0.0049211161319037125, 'l1_Layer_3': 0.019834288665517227, 'n_units_Layer_1': 285, 'n_units_Layer_2': 230, 'n_units_Layer_3': 250}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.38 | sMAPE for Validation Set is: 36.57% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 7.76 | sMAPE for Test Set is: 18.73% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:04:14,717]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:04:19,676]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:04:21,923]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:04:24,628]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:04:28,191]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:04:29,501]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:04:30,813]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:04:33,571]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:04:36,930]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:04:37,345]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:04:39,578]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 35.23% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.27 | sMAPE for Test Set is: 17.27% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:04:41,883]\u001b[0m Trial 115 finished with value: 1.862731963407141 and parameters: {'n_hidden': 3, 'learning_rate': 0.005956557850101801, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14678920952248922, 'dropout_rate_Layer_2': 0.1441494006276337, 'dropout_rate_Layer_3': 0.05231206918957474, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0024088975068923125, 'l1_Layer_2': 0.0363063638302452, 'l1_Layer_3': 0.018096555860726705, 'n_units_Layer_1': 285, 'n_units_Layer_2': 225, 'n_units_Layer_3': 240}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:04:48,965]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:04:50,597]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:04:55,245]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:04:55,342]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:04:56,029]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:02,698]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:02,857]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:03,214]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:04,058]\u001b[0m Trial 129 finished with value: 5.311730044344119 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016820026870570206, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10900306636688598, 'dropout_rate_Layer_2': 0.3210834123190258, 'dropout_rate_Layer_3': 0.28862685781841235, 'dropout_rate_Layer_4': 0.2984233452125802, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.03528678458285765, 'l1_Layer_2': 0.0023532656277853842, 'l1_Layer_3': 0.003101270463317956, 'l1_Layer_4': 0.008692527430778446, 'n_units_Layer_1': 265, 'n_units_Layer_2': 145, 'n_units_Layer_3': 215, 'n_units_Layer_4': 100}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 63.03% | rMAE for Validation Set is: 1.60\n",
      "MAE for Test Set is: 32.97 | sMAPE for Test Set is: 120.09% | rMAE for Test Set is: 2.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:05:10,514]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:12,692]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:16,572]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:16,914]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:21,294]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:21,658]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:21,735]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:27,665]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:28,653]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:32,708]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:36,009]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:36,147]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:43,521]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:46,733]\u001b[0m Trial 151 finished with value: 9.54985935623378 and parameters: {'n_hidden': 3, 'learning_rate': 0.0181216495426067, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28099762645170157, 'dropout_rate_Layer_2': 0.11917400596308388, 'dropout_rate_Layer_3': 0.36536404484188895, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.013765951444471443, 'l1_Layer_2': 0.004233733777763855, 'l1_Layer_3': 9.710046208355923e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 255, 'n_units_Layer_3': 115}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.55 | sMAPE for Validation Set is: 82.51% | rMAE for Validation Set is: 2.87\n",
      "MAE for Test Set is: 24.64 | sMAPE for Test Set is: 70.73% | rMAE for Test Set is: 1.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:05:47,595]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:51,669]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:53,298]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:55,015]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:05:56,176]\u001b[0m Trial 142 finished with value: 10.477427576442723 and parameters: {'n_hidden': 3, 'learning_rate': 0.033331849300959726, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.180848524768442, 'dropout_rate_Layer_2': 0.08747118121528108, 'dropout_rate_Layer_3': 0.20960369082756802, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008297827081250406, 'l1_Layer_2': 0.0005352595259366623, 'l1_Layer_3': 1.1660475585501946e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 230, 'n_units_Layer_3': 165}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.48 | sMAPE for Validation Set is: 73.93% | rMAE for Validation Set is: 3.15\n",
      "MAE for Test Set is: 34.03 | sMAPE for Test Set is: 85.65% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:05:59,052]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:02,539]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:03,036]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:03,638]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:06,833]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:11,447]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:12,987]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:14,721]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:17,040]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:20,605]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:24,595]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:25,135]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:29,570]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:36,792]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:38,744]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:42,549]\u001b[0m Trial 167 finished with value: 4.230752179701238 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018738657095479522, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07256389031681859, 'dropout_rate_Layer_2': 0.20244837695563725, 'dropout_rate_Layer_3': 0.2716290558768343, 'dropout_rate_Layer_4': 0.24590327232235767, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013889769841471584, 'l1_Layer_2': 1.0555112495877522e-05, 'l1_Layer_3': 1.0124522210610332e-05, 'l1_Layer_4': 0.0009223721050995386, 'n_units_Layer_1': 55, 'n_units_Layer_2': 50, 'n_units_Layer_3': 50, 'n_units_Layer_4': 125}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 52.53% | rMAE for Validation Set is: 1.27\n",
      "MAE for Test Set is: 28.34 | sMAPE for Test Set is: 92.22% | rMAE for Test Set is: 1.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:06:44,970]\u001b[0m Trial 170 finished with value: 2.134604306242039 and parameters: {'n_hidden': 3, 'learning_rate': 0.005012598705050355, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07610825789735451, 'dropout_rate_Layer_2': 0.13290220489488777, 'dropout_rate_Layer_3': 0.08444779308435049, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.139720427932866e-05, 'l1_Layer_2': 0.015177489107196443, 'l1_Layer_3': 0.009326561356572966, 'n_units_Layer_1': 195, 'n_units_Layer_2': 215, 'n_units_Layer_3': 225}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 31.24% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.48 | sMAPE for Test Set is: 24.50% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:06:46,712]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:47,988]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:48,328]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:50,224]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:51,342]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:57,031]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:06:57,192]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:00,219]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:03,024]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:07,722]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:09,312]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:13,328]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:16,598]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:18,215]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:21,083]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:22,138]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:24,394]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:30,031]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:30,304]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:31,673]\u001b[0m Trial 186 finished with value: 4.560648835846529 and parameters: {'n_hidden': 4, 'learning_rate': 0.002010753763096036, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01592377401010267, 'dropout_rate_Layer_2': 0.23316121954403607, 'dropout_rate_Layer_3': 0.2914684845412916, 'dropout_rate_Layer_4': 0.25732828719180934, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.395571365895922e-05, 'l1_Layer_2': 1.0297713658235277e-05, 'l1_Layer_3': 8.001141163411074e-05, 'l1_Layer_4': 0.0005267916887559567, 'n_units_Layer_1': 55, 'n_units_Layer_2': 50, 'n_units_Layer_3': 55, 'n_units_Layer_4': 120}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 55.04% | rMAE for Validation Set is: 1.37\n",
      "MAE for Test Set is: 30.40 | sMAPE for Test Set is: 104.92% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:07:37,279]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:37,626]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:40,088]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:44,312]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:44,405]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:45,418]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:50,571]\u001b[0m Trial 192 finished with value: 4.514056042947337 and parameters: {'n_hidden': 4, 'learning_rate': 0.002034604876684259, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021544652405014512, 'dropout_rate_Layer_2': 0.24483043645436586, 'dropout_rate_Layer_3': 0.27949478592448745, 'dropout_rate_Layer_4': 0.2450809204792039, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.50334928025994e-05, 'l1_Layer_2': 1.9242224295410583e-05, 'l1_Layer_3': 8.475729287055576e-05, 'l1_Layer_4': 0.0005574543240900419, 'n_units_Layer_1': 50, 'n_units_Layer_2': 55, 'n_units_Layer_3': 215, 'n_units_Layer_4': 120}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.51 | sMAPE for Validation Set is: 55.42% | rMAE for Validation Set is: 1.36\n",
      "MAE for Test Set is: 28.76 | sMAPE for Test Set is: 96.29% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:07:52,514]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:56,179]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:07:57,446]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:00,659]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:01,291]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:02,888]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:05,437]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:05,583]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:11,972]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:14,492]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:17,642]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:20,022]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:23,410]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:26,537]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:28,930]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:32,058]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:32,657]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:32,825]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:37,680]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:39,583]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:40,396]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:41,744]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:43,595]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:43,702]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:45,542]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:49,209]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:53,905]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:56,396]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:08:57,672]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:01,155]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:03,974]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:04,465]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:05,194]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:07,281]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:11,823]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:16,042]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:16,190]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:18,266]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:25,346]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:25,470]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:25,986]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 69.74% | rMAE for Validation Set is: 1.98\n",
      "MAE for Test Set is: 28.30 | sMAPE for Test Set is: 89.47% | rMAE for Test Set is: 1.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:09:30,817]\u001b[0m Trial 234 finished with value: 6.580751185426031 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012171351636241895, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31343024995987123, 'dropout_rate_Layer_2': 0.19005158538399894, 'dropout_rate_Layer_3': 0.3160961341753889, 'dropout_rate_Layer_4': 0.013588509020339534, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.766824618098747e-05, 'l1_Layer_2': 0.04173445421182452, 'l1_Layer_3': 4.590695173824538e-05, 'l1_Layer_4': 0.0015339170201275894, 'n_units_Layer_1': 220, 'n_units_Layer_2': 95, 'n_units_Layer_3': 205, 'n_units_Layer_4': 295}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:31,858]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:32,751]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:34,194]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:36,791]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:42,669]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:43,119]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:44,889]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:48,227]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:52,343]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:09:55,448]\u001b[0m Trial 249 finished with value: 5.266917259026813 and parameters: {'n_hidden': 3, 'learning_rate': 0.004390476731711891, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08123116225029398, 'dropout_rate_Layer_2': 0.35608767012225334, 'dropout_rate_Layer_3': 0.09634849461705691, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02341550732847587, 'l1_Layer_2': 9.066477792153765e-05, 'l1_Layer_3': 1.324616779458299e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 150, 'n_units_Layer_3': 150}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 62.28% | rMAE for Validation Set is: 1.58\n",
      "MAE for Test Set is: 8.38 | sMAPE for Test Set is: 19.14% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:09:55,684]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:00,105]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:03,371]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:05,055]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:05,602]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:07,561]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:09,322]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:10,666]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 47.98% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 21.48 | sMAPE for Test Set is: 65.46% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:10:14,764]\u001b[0m Trial 245 finished with value: 3.7917118563058203 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005812405858636411, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11815626011728625, 'dropout_rate_Layer_2': 0.33509082684976405, 'dropout_rate_Layer_3': 0.23127705214641525, 'dropout_rate_Layer_4': 0.28882760821526743, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002781386847776538, 'l1_Layer_2': 0.0018540077611982502, 'l1_Layer_3': 0.00040837111276267516, 'l1_Layer_4': 0.00013901180443325026, 'n_units_Layer_1': 275, 'n_units_Layer_2': 80, 'n_units_Layer_3': 200, 'n_units_Layer_4': 130}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:15,075]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:16,254]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:16,420]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:21,701]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:22,986]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:25,654]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:27,641]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:29,333]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:30,972]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:33,004]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:35,082]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:36,986]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:40,973]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:41,265]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:41,890]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:48,558]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:49,111]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:56,465]\u001b[0m Trial 266 finished with value: 3.4805417370181893 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005072572884454798, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1486225435341576, 'dropout_rate_Layer_2': 0.3992218719221783, 'dropout_rate_Layer_3': 0.16268350265608794, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026676932078231377, 'l1_Layer_2': 0.001488087500693427, 'l1_Layer_3': 0.0017461475694282612, 'n_units_Layer_1': 300, 'n_units_Layer_2': 170, 'n_units_Layer_3': 200}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.48 | sMAPE for Validation Set is: 46.56% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 13.32 | sMAPE for Test Set is: 34.81% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:10:57,499]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:10:59,776]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:11:02,698]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:11:06,529]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:11:11,112]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:11:16,625]\u001b[0m Trial 279 finished with value: 3.486122135206323 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006086526134202101, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14129763274275361, 'dropout_rate_Layer_2': 0.37048906886152105, 'dropout_rate_Layer_3': 0.025419402420699372, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00210861628752395, 'l1_Layer_2': 0.0016367814860251532, 'l1_Layer_3': 0.0015757632573835613, 'n_units_Layer_1': 290, 'n_units_Layer_2': 180, 'n_units_Layer_3': 200}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.49 | sMAPE for Validation Set is: 48.19% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 11.41 | sMAPE for Test Set is: 30.81% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:11:19,573]\u001b[0m Trial 284 finished with value: 1.8830965122040935 and parameters: {'n_hidden': 3, 'learning_rate': 0.004292022104421519, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17326680825482332, 'dropout_rate_Layer_2': 0.11036246196241827, 'dropout_rate_Layer_3': 0.14751708412205838, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017631641035535642, 'l1_Layer_2': 0.004963314582201207, 'l1_Layer_3': 0.05417592768841418, 'n_units_Layer_1': 215, 'n_units_Layer_2': 250, 'n_units_Layer_3': 190}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 27.82% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.85 | sMAPE for Test Set is: 18.95% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:11:21,767]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:11:25,564]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:11:25,966]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:11:30,546]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:11:31,505]\u001b[0m Trial 282 finished with value: 3.893305268312009 and parameters: {'n_hidden': 3, 'learning_rate': 0.000601689119250263, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23056114365058378, 'dropout_rate_Layer_2': 0.1342938233401037, 'dropout_rate_Layer_3': 0.027069463717515174, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0100579537609808e-05, 'l1_Layer_2': 0.0007072342099459805, 'l1_Layer_3': 0.02654629854848373, 'n_units_Layer_1': 160, 'n_units_Layer_2': 260, 'n_units_Layer_3': 75}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 54.71% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 24.11 | sMAPE for Test Set is: 74.55% | rMAE for Test Set is: 1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:11:35,376]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:11:37,013]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:11:41,326]\u001b[0m Trial 286 finished with value: 4.463957679651352 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008077407218935779, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36821938338379223, 'dropout_rate_Layer_2': 0.0759072743810207, 'dropout_rate_Layer_3': 0.1415176848931702, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013691932906187857, 'l1_Layer_2': 0.0035476528065749822, 'l1_Layer_3': 0.0023382811135375485, 'n_units_Layer_1': 95, 'n_units_Layer_2': 155, 'n_units_Layer_3': 75}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 54.42% | rMAE for Validation Set is: 1.34\n",
      "MAE for Test Set is: 23.13 | sMAPE for Test Set is: 67.79% | rMAE for Test Set is: 1.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:11:41,989]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:11:47,382]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:11:49,509]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:11:49,777]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:11:52,788]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:11:57,200]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:11:57,663]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:12:03,264]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:12:03,700]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:12:08,317]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:12:12,577]\u001b[0m Trial 299 finished with value: 1.9773657034576881 and parameters: {'n_hidden': 3, 'learning_rate': 0.003741686123960056, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15919982538944188, 'dropout_rate_Layer_2': 0.12829021390904674, 'dropout_rate_Layer_3': 0.07485728031423036, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002745427359108174, 'l1_Layer_2': 0.005130359839287602, 'l1_Layer_3': 0.04718467504317139, 'n_units_Layer_1': 225, 'n_units_Layer_2': 255, 'n_units_Layer_3': 180}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 31.47% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.34 | sMAPE for Test Set is: 17.57% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:12:15,057]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:12:16,061]\u001b[0m Trial 301 finished with value: 2.0964693928716795 and parameters: {'n_hidden': 3, 'learning_rate': 0.002869774762894638, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1637058136602695, 'dropout_rate_Layer_2': 0.10719031014823105, 'dropout_rate_Layer_3': 0.1530767879447199, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018545060108633169, 'l1_Layer_2': 0.004497606547659072, 'l1_Layer_3': 0.04462618489774851, 'n_units_Layer_1': 205, 'n_units_Layer_2': 210, 'n_units_Layer_3': 180}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 33.33% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.73 | sMAPE for Test Set is: 18.64% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:12:25,396]\u001b[0m Trial 305 finished with value: 5.48357680095382 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005139067341658021, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14831266035194615, 'dropout_rate_Layer_2': 0.3793479647107042, 'dropout_rate_Layer_3': 0.012908797816843927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0033947699827936075, 'l1_Layer_2': 0.01569154799183841, 'l1_Layer_3': 0.002776611119175337, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 225}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 63.89% | rMAE for Validation Set is: 1.65\n",
      "MAE for Test Set is: 31.55 | sMAPE for Test Set is: 109.71% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:12:29,707]\u001b[0m Trial 309 finished with value: 1.7523726900508532 and parameters: {'n_hidden': 3, 'learning_rate': 0.006347892929971852, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1479473014135954, 'dropout_rate_Layer_2': 0.39074841604502475, 'dropout_rate_Layer_3': 0.2532788921636728, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.048064340922428e-05, 'l1_Layer_2': 0.06663410967515312, 'l1_Layer_3': 0.00023705541524377625, 'n_units_Layer_1': 135, 'n_units_Layer_2': 170, 'n_units_Layer_3': 65}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.75 | sMAPE for Validation Set is: 32.43% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 7.52 | sMAPE for Test Set is: 18.47% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:12:30,413]\u001b[0m Trial 307 finished with value: 2.079845875822623 and parameters: {'n_hidden': 3, 'learning_rate': 0.005929096289121082, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15446694911732073, 'dropout_rate_Layer_2': 0.13010943089600432, 'dropout_rate_Layer_3': 0.10213868875000937, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.449455620686997e-05, 'l1_Layer_2': 0.0045703326917450725, 'l1_Layer_3': 0.040090422145949225, 'n_units_Layer_1': 240, 'n_units_Layer_2': 245, 'n_units_Layer_3': 180}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 32.24% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.54 | sMAPE for Test Set is: 18.52% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:12:36,734]\u001b[0m Trial 308 finished with value: 1.8881817500206088 and parameters: {'n_hidden': 3, 'learning_rate': 0.00290278360567662, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15893243431516185, 'dropout_rate_Layer_2': 0.12836303315064088, 'dropout_rate_Layer_3': 0.08212000848172685, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4119414239814195e-05, 'l1_Layer_2': 0.004116708130347711, 'l1_Layer_3': 0.04664443305105233, 'n_units_Layer_1': 230, 'n_units_Layer_2': 205, 'n_units_Layer_3': 170}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 29.21% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.58 | sMAPE for Test Set is: 18.85% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:12:39,835]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:12:43,448]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:12:44,250]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:12:45,590]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:12:46,219]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:12:53,819]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:12:57,591]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:12:59,400]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:03,504]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:06,971]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:07,509]\u001b[0m Trial 319 finished with value: 5.624163781255068 and parameters: {'n_hidden': 3, 'learning_rate': 0.010583495261930675, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06688448222523191, 'dropout_rate_Layer_2': 0.34049114811077286, 'dropout_rate_Layer_3': 0.0011454550301361506, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002735589452219949, 'l1_Layer_2': 0.00032649762303399335, 'l1_Layer_3': 0.004518021559370393, 'n_units_Layer_1': 260, 'n_units_Layer_2': 190, 'n_units_Layer_3': 135}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 65.45% | rMAE for Validation Set is: 1.69\n",
      "MAE for Test Set is: 28.48 | sMAPE for Test Set is: 99.51% | rMAE for Test Set is: 1.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:13:13,587]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:13,763]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:14,656]\u001b[0m Trial 317 finished with value: 1.6375716267876195 and parameters: {'n_hidden': 3, 'learning_rate': 0.002343761345870549, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18346181045601423, 'dropout_rate_Layer_2': 0.11287499022978283, 'dropout_rate_Layer_3': 0.11012431654358792, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3144174655986603e-05, 'l1_Layer_2': 0.0027007004818299907, 'l1_Layer_3': 0.06262646467679725, 'n_units_Layer_1': 240, 'n_units_Layer_2': 215, 'n_units_Layer_3': 180}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.64 | sMAPE for Validation Set is: 24.34% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 7.52 | sMAPE for Test Set is: 18.33% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:13:15,362]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:22,154]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:22,620]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:24,070]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:26,698]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:29,272]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:30,409]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:36,355]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:36,835]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:37,313]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:45,229]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:46,689]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:50,827]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:52,377]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:13:56,016]\u001b[0m Trial 332 finished with value: 3.6583869469793946 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008812575784968566, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21776911365583507, 'dropout_rate_Layer_2': 0.39464326385203835, 'dropout_rate_Layer_3': 0.15582378680754394, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002880804248074633, 'l1_Layer_2': 0.0023850100487654634, 'l1_Layer_3': 0.0009841378989599399, 'n_units_Layer_1': 215, 'n_units_Layer_2': 155, 'n_units_Layer_3': 185}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 46.42% | rMAE for Validation Set is: 1.10\n",
      "MAE for Test Set is: 12.45 | sMAPE for Test Set is: 31.31% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:13:59,609]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:00,303]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:04,545]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:05,167]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:05,333]\u001b[0m Trial 336 finished with value: 3.9955198387957993 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008957834421414036, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21808404233908657, 'dropout_rate_Layer_2': 0.38658690486858227, 'dropout_rate_Layer_3': 0.16150998625275995, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025782791396935863, 'l1_Layer_2': 0.002082120800363994, 'l1_Layer_3': 0.0011168287564795566, 'n_units_Layer_1': 215, 'n_units_Layer_2': 150, 'n_units_Layer_3': 185}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 56.17% | rMAE for Validation Set is: 1.20\n",
      "MAE for Test Set is: 18.96 | sMAPE for Test Set is: 55.85% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:14:08,722]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:10,854]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:14,217]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:14,491]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:16,881]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:20,914]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:26,202]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:28,405]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:30,669]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:31,630]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:36,658]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:36,671]\u001b[0m Trial 351 finished with value: 5.21213430389167 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031501751942145913, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1627995393359309, 'dropout_rate_Layer_2': 0.399666695470143, 'dropout_rate_Layer_3': 0.15963828941110356, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006083206501816221, 'l1_Layer_2': 0.015308322782182523, 'l1_Layer_3': 0.007595525282717397, 'n_units_Layer_1': 300, 'n_units_Layer_2': 170, 'n_units_Layer_3': 235}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 62.61% | rMAE for Validation Set is: 1.57\n",
      "MAE for Test Set is: 34.28 | sMAPE for Test Set is: 130.01% | rMAE for Test Set is: 2.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:14:40,958]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:44,442]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:44,753]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:44,805]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:14:52,272]\u001b[0m Trial 357 finished with value: 1.7177082754642516 and parameters: {'n_hidden': 3, 'learning_rate': 0.005356427425139205, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12376494636522355, 'dropout_rate_Layer_2': 0.11619506629908519, 'dropout_rate_Layer_3': 0.03806166073063211, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.888734012792435e-05, 'l1_Layer_2': 0.005686788891804582, 'l1_Layer_3': 0.04427049190910188, 'n_units_Layer_1': 190, 'n_units_Layer_2': 180, 'n_units_Layer_3': 245}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.72 | sMAPE for Validation Set is: 25.18% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 7.61 | sMAPE for Test Set is: 18.67% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:14:57,081]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:02,372]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:02,770]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:07,123]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:10,236]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:12,821]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:17,287]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:18,213]\u001b[0m Trial 363 finished with value: 3.9719556812511736 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010689971771665593, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29132813212707553, 'dropout_rate_Layer_2': 0.03790373940612987, 'dropout_rate_Layer_3': 0.16956709157148245, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.1782778131303844e-05, 'l1_Layer_2': 0.0029380676362611518, 'l1_Layer_3': 0.011918166935975137, 'n_units_Layer_1': 250, 'n_units_Layer_2': 160, 'n_units_Layer_3': 95}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 50.36% | rMAE for Validation Set is: 1.19\n",
      "MAE for Test Set is: 11.30 | sMAPE for Test Set is: 30.86% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:15:22,230]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:22,468]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:22,873]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:26,922]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:29,502]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:29,961]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:38,205]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:38,597]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:38,703]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:39,880]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:44,970]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:47,637]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:50,193]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:15:56,406]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:00,436]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:04,128]\u001b[0m Trial 380 finished with value: 2.2815890173881055 and parameters: {'n_hidden': 3, 'learning_rate': 0.007814252117968792, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12139842605086268, 'dropout_rate_Layer_2': 0.13639764086747966, 'dropout_rate_Layer_3': 0.045266267348757355, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017842713065479638, 'l1_Layer_2': 0.012819156345754047, 'l1_Layer_3': 0.02850661518126994, 'n_units_Layer_1': 190, 'n_units_Layer_2': 210, 'n_units_Layer_3': 250}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.28 | sMAPE for Validation Set is: 34.83% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.77 | sMAPE for Test Set is: 19.03% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:16:06,211]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:07,657]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:11,306]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:13,354]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:18,398]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:18,425]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:19,762]\u001b[0m Trial 384 finished with value: 2.2324104607215944 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007328308245410839, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3133521186217269, 'dropout_rate_Layer_2': 0.31309281254109683, 'dropout_rate_Layer_3': 0.04764088346941722, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006113342167699999, 'l1_Layer_2': 0.011208694598578324, 'l1_Layer_3': 0.00021465474717401208, 'n_units_Layer_1': 285, 'n_units_Layer_2': 160, 'n_units_Layer_3': 240}. Best is trial 106 with value: 1.5219031293244691.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.23 | sMAPE for Validation Set is: 33.62% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.35 | sMAPE for Test Set is: 19.05% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:16:25,902]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:28,226]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:30,109]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:33,457]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:36,134]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:40,375]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:41,036]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:44,494]\u001b[0m Trial 388 finished with value: 1.3954766486132708 and parameters: {'n_hidden': 3, 'learning_rate': 0.001504299048173123, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02520667858927221, 'dropout_rate_Layer_2': 0.3713912204370706, 'dropout_rate_Layer_3': 0.24502627372596697, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002295544108108326, 'l1_Layer_2': 0.010450242923725444, 'l1_Layer_3': 0.0015554951499930263, 'n_units_Layer_1': 230, 'n_units_Layer_2': 180, 'n_units_Layer_3': 90}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.40 | sMAPE for Validation Set is: 20.28% | rMAE for Validation Set is: 0.42\n",
      "MAE for Test Set is: 7.22 | sMAPE for Test Set is: 17.42% | rMAE for Test Set is: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:16:44,825]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:46,444]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:51,441]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:54,321]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:55,813]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:16:59,988]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:03,391]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:03,588]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:08,542]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:08,687]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:09,115]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 50.36% | rMAE for Validation Set is: 1.15\n",
      "MAE for Test Set is: 11.41 | sMAPE for Test Set is: 27.83% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:17:14,641]\u001b[0m Trial 408 finished with value: 3.8133975532725657 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014341447179186144, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06277302715405819, 'dropout_rate_Layer_2': 0.35956137916280617, 'dropout_rate_Layer_3': 0.0816933738119224, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00651297636295865, 'l1_Layer_2': 0.0356073209223603, 'l1_Layer_3': 0.09823868818620794, 'n_units_Layer_1': 230, 'n_units_Layer_2': 160, 'n_units_Layer_3': 235}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:17,186]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:17,727]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:23,838]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:27,227]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:27,742]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:32,284]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:32,555]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:32,781]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:39,875]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:40,160]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:43,159]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:44,201]\u001b[0m Trial 416 finished with value: 3.909247607990006 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007217947816544744, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1919477499623817, 'dropout_rate_Layer_2': 0.39964350216202593, 'dropout_rate_Layer_3': 0.13653794248446519, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016288452772969238, 'l1_Layer_2': 0.004161258470052147, 'l1_Layer_3': 0.0007223912324352365, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 180}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 47.67% | rMAE for Validation Set is: 1.18\n",
      "MAE for Test Set is: 18.28 | sMAPE for Test Set is: 49.75% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:17:49,347]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:49,914]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:50,479]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:50,746]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:54,818]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:17:59,724]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:01,815]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:03,717]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:03,868]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:05,553]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:08,038]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:13,736]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:14,457]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:19,058]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:21,345]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:22,524]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:23,873]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:24,314]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:25,300]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:29,801]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:32,688]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:34,461]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:35,792]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:37,386]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:45,196]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:47,225]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:50,480]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:50,973]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:56,347]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:56,441]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:56,812]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:18:59,840]\u001b[0m Trial 448 finished with value: 1.8874180493044115 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009375760580940162, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13835262242000276, 'dropout_rate_Layer_2': 0.35717410082242035, 'dropout_rate_Layer_3': 0.1711534299912217, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012871444194167666, 'l1_Layer_2': 0.0023875676909629706, 'l1_Layer_3': 0.001966775593415111, 'n_units_Layer_1': 260, 'n_units_Layer_2': 155, 'n_units_Layer_3': 215}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 28.64% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.01 | sMAPE for Test Set is: 20.99% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:19:05,046]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:19:07,446]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:19:09,309]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:19:10,011]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:19:12,219]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:19:17,139]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:19:21,613]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:19:25,075]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:19:27,087]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:19:30,494]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:19:30,709]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:19:30,936]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:19:38,311]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:19:43,308]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:19:47,995]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:19:52,778]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:19:58,611]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:19:58,942]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:20:04,113]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:20:07,925]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:20:11,238]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:20:14,275]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:20:19,356]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:20:23,005]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:20:33,157]\u001b[0m Trial 471 finished with value: 2.055873961684155 and parameters: {'n_hidden': 3, 'learning_rate': 0.005236134760482264, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08035125419954642, 'dropout_rate_Layer_2': 0.3996692173169087, 'dropout_rate_Layer_3': 0.146448325774512, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04412007443163355, 'l1_Layer_2': 4.746306512656429e-05, 'l1_Layer_3': 0.006517490890466908, 'n_units_Layer_1': 250, 'n_units_Layer_2': 175, 'n_units_Layer_3': 115}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 36.88% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.30 | sMAPE for Test Set is: 17.73% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:20:35,690]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:20:38,123]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:20:45,880]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:20:46,484]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:20:50,733]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:20:53,009]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:20:56,378]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:20:59,653]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:21:07,445]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:21:24,878]\u001b[0m Trial 483 finished with value: 1.7818108397451067 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018145925637326717, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025044116890387755, 'dropout_rate_Layer_2': 0.38171597211921654, 'dropout_rate_Layer_3': 0.18056576852415315, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001938157258373618, 'l1_Layer_2': 1.769508683779999e-05, 'l1_Layer_3': 0.06762872758240927, 'n_units_Layer_1': 120, 'n_units_Layer_2': 175, 'n_units_Layer_3': 220}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.78 | sMAPE for Validation Set is: 26.84% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.45 | sMAPE for Test Set is: 18.42% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:21:33,078]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:21:38,039]\u001b[0m Trial 477 finished with value: 1.4546762550859509 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017349890309702933, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026787969869776523, 'dropout_rate_Layer_2': 0.22975567848517925, 'dropout_rate_Layer_3': 0.1915706918651692, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018386177935621952, 'l1_Layer_2': 1.6762256161520875e-05, 'l1_Layer_3': 0.0428826259761233, 'n_units_Layer_1': 120, 'n_units_Layer_2': 170, 'n_units_Layer_3': 70}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 21.16% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 7.06 | sMAPE for Test Set is: 16.86% | rMAE for Test Set is: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:21:42,363]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:21:46,292]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:21:56,733]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:21:57,439]\u001b[0m Trial 492 finished with value: 1.7135385144955049 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021686675205325537, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06782427374755355, 'dropout_rate_Layer_2': 0.3813641058725415, 'dropout_rate_Layer_3': 0.18770055876324526, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04370223243242942, 'l1_Layer_2': 1.446024554980013e-05, 'l1_Layer_3': 0.06457274609864357, 'n_units_Layer_1': 250, 'n_units_Layer_2': 175, 'n_units_Layer_3': 115}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.71 | sMAPE for Validation Set is: 28.31% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 7.10 | sMAPE for Test Set is: 17.07% | rMAE for Test Set is: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:22:02,203]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:22:05,445]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:22:09,331]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:22:11,237]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:22:12,505]\u001b[0m Trial 498 finished with value: 3.772555338891436 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008742103345378113, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0025323464231138404, 'dropout_rate_Layer_2': 0.26935689063763185, 'dropout_rate_Layer_3': 0.18136256655716526, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.03453499630194382, 'l1_Layer_2': 0.0038331135159996883, 'l1_Layer_3': 0.001532390148000547, 'n_units_Layer_1': 80, 'n_units_Layer_2': 75, 'n_units_Layer_3': 85}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 46.62% | rMAE for Validation Set is: 1.13\n",
      "MAE for Test Set is: 22.36 | sMAPE for Test Set is: 66.44% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:22:14,677]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:22:19,118]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:22:19,597]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:22:20,364]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:22:22,237]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:22:27,126]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:22:32,426]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:22:35,569]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:22:36,467]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:22:45,040]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:22:58,767]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:23:02,444]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:23:14,151]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:23:18,294]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:23:21,284]\u001b[0m Trial 513 finished with value: 1.7048413574645778 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015103583451678592, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05130143837589771, 'dropout_rate_Layer_2': 0.36863582913740145, 'dropout_rate_Layer_3': 0.15589502710590397, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018982999671582383, 'l1_Layer_2': 4.173522763984935e-05, 'l1_Layer_3': 0.02392410650868919, 'n_units_Layer_1': 255, 'n_units_Layer_2': 190, 'n_units_Layer_3': 115}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.70 | sMAPE for Validation Set is: 25.39% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 9.43 | sMAPE for Test Set is: 23.90% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:23:23,680]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:23:26,814]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:23:39,420]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:23:42,414]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:23:45,277]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:23:49,082]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:23:51,892]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:23:55,537]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:23:57,625]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:24:02,110]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:24:06,267]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:24:11,024]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:24:13,174]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:24:15,560]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:24:21,681]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:24:23,998]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:24:26,076]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:24:29,415]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:24:32,434]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:24:39,452]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:24:44,273]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:24:49,619]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:24:55,182]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:24:55,543]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:25:00,218]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:25:04,508]\u001b[0m Trial 521 finished with value: 1.6625584092180044 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014544182080891443, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05311933191687049, 'dropout_rate_Layer_2': 0.3664413546932542, 'dropout_rate_Layer_3': 0.15571657104103953, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019424934608875803, 'l1_Layer_2': 4.5095034788137677e-05, 'l1_Layer_3': 0.0355732046835946, 'n_units_Layer_1': 240, 'n_units_Layer_2': 165, 'n_units_Layer_3': 240}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.66 | sMAPE for Validation Set is: 24.42% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 7.37 | sMAPE for Test Set is: 17.70% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:25:22,107]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:25:45,845]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:25:56,533]\u001b[0m Trial 531 finished with value: 2.270813823218908 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012051230500855464, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012979456150214315, 'dropout_rate_Layer_2': 0.34693283970690775, 'dropout_rate_Layer_3': 0.1412147928816892, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0407988904475728, 'l1_Layer_2': 2.195260063674927e-05, 'l1_Layer_3': 0.03219215730153187, 'n_units_Layer_1': 115, 'n_units_Layer_2': 235, 'n_units_Layer_3': 140}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.27 | sMAPE for Validation Set is: 34.03% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.14 | sMAPE for Test Set is: 20.49% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:25:59,260]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:26:02,234]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:26:04,878]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:26:05,100]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:26:11,043]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:26:11,349]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:26:15,886]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:26:16,477]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:26:20,686]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:26:24,576]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:26:28,646]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:26:29,295]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:26:34,814]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:26:40,470]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:26:43,527]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:26:45,847]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:26:52,429]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:26:59,245]\u001b[0m Trial 565 finished with value: 4.4602690502041 and parameters: {'n_hidden': 3, 'learning_rate': 0.004468476475850622, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23153972718835136, 'dropout_rate_Layer_2': 0.337795356484095, 'dropout_rate_Layer_3': 0.11022199379386509, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0040494722571293535, 'l1_Layer_2': 0.00035912145391748797, 'l1_Layer_3': 0.004113995968366052, 'n_units_Layer_1': 170, 'n_units_Layer_2': 155, 'n_units_Layer_3': 195}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.46 | sMAPE for Validation Set is: 54.50% | rMAE for Validation Set is: 1.34\n",
      "MAE for Test Set is: 30.06 | sMAPE for Test Set is: 102.00% | rMAE for Test Set is: 1.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:27:01,691]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:27:05,998]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:27:08,779]\u001b[0m Trial 562 finished with value: 4.430652189134112 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011043834726218952, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14882004028514464, 'dropout_rate_Layer_2': 0.3308327897523456, 'dropout_rate_Layer_3': 0.33552843728801773, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01116411484056125, 'l1_Layer_2': 0.04073184177606723, 'l1_Layer_3': 0.006953778741656999, 'n_units_Layer_1': 235, 'n_units_Layer_2': 80, 'n_units_Layer_3': 60}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 54.43% | rMAE for Validation Set is: 1.33\n",
      "MAE for Test Set is: 19.77 | sMAPE for Test Set is: 53.78% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:27:11,943]\u001b[0m Trial 547 finished with value: 1.922612654314953 and parameters: {'n_hidden': 3, 'learning_rate': 0.001794374587830136, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03813574137379422, 'dropout_rate_Layer_2': 0.3564443374199855, 'dropout_rate_Layer_3': 0.18198365754723325, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006937915140065818, 'l1_Layer_2': 4.0084661393332996e-05, 'l1_Layer_3': 0.04046957673564156, 'n_units_Layer_1': 125, 'n_units_Layer_2': 220, 'n_units_Layer_3': 255}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 28.51% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.90 | sMAPE for Test Set is: 19.63% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:27:15,862]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:27:20,092]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:27:24,650]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:27:24,807]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:27:31,771]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:27:32,392]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:27:37,084]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:27:40,455]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:27:46,057]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:27:50,211]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:27:50,436]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:27:51,688]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:27:58,289]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:28:00,179]\u001b[0m Trial 568 finished with value: 1.5964783281890351 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013292910685027055, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0006163209443214267, 'dropout_rate_Layer_2': 0.3998711997025027, 'dropout_rate_Layer_3': 0.16775907204790574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04804340753475109, 'l1_Layer_2': 2.7681976036075555e-05, 'l1_Layer_3': 0.03763358373400402, 'n_units_Layer_1': 235, 'n_units_Layer_2': 165, 'n_units_Layer_3': 155}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.60 | sMAPE for Validation Set is: 23.96% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 7.30 | sMAPE for Test Set is: 17.54% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:28:01,594]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:28:03,988]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:28:13,066]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:28:17,000]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:28:20,576]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:28:22,075]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:28:28,255]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:28:28,727]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:28:30,867]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:28:34,035]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:28:39,853]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:28:42,914]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:28:43,445]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:28:48,404]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:28:52,578]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:28:58,380]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:02,819]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:05,515]\u001b[0m Trial 594 finished with value: 5.498438070783376 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024442168342752794, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3816219630147829, 'dropout_rate_Layer_2': 0.1666170182497032, 'dropout_rate_Layer_3': 0.22444263588211266, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00036391358496259886, 'l1_Layer_2': 0.00782058594581498, 'l1_Layer_3': 0.00015475188841039932, 'n_units_Layer_1': 230, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 66.67% | rMAE for Validation Set is: 1.65\n",
      "MAE for Test Set is: 36.05 | sMAPE for Test Set is: 144.62% | rMAE for Test Set is: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:29:10,112]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:10,524]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:16,219]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:16,877]\u001b[0m Trial 601 finished with value: 5.293514397593705 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022917316545225165, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10918912809403136, 'dropout_rate_Layer_2': 0.19122694151213937, 'dropout_rate_Layer_3': 0.2172906127943944, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0025972882249407163, 'l1_Layer_2': 0.008233744668975024, 'l1_Layer_3': 0.00013447896825330934, 'n_units_Layer_1': 230, 'n_units_Layer_2': 195, 'n_units_Layer_3': 270}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 62.82% | rMAE for Validation Set is: 1.59\n",
      "MAE for Test Set is: 32.77 | sMAPE for Test Set is: 118.47% | rMAE for Test Set is: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:29:17,371]\u001b[0m Trial 598 finished with value: 5.209534626111125 and parameters: {'n_hidden': 3, 'learning_rate': 0.002513584153558301, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3827325917630137, 'dropout_rate_Layer_2': 0.1769895893819839, 'dropout_rate_Layer_3': 0.09884691954029909, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0023562179949488367, 'l1_Layer_2': 0.02562426281573617, 'l1_Layer_3': 0.0026713935458742228, 'n_units_Layer_1': 230, 'n_units_Layer_2': 195, 'n_units_Layer_3': 265}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 62.40% | rMAE for Validation Set is: 1.57\n",
      "MAE for Test Set is: 33.84 | sMAPE for Test Set is: 126.28% | rMAE for Test Set is: 2.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:29:24,187]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:24,617]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:24,669]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:24,766]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:37,580]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:37,928]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:43,004]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:45,267]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:45,886]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:48,645]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:51,600]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:57,494]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:57,554]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:29:58,276]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:30:07,202]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:30:07,252]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:30:08,411]\u001b[0m Trial 616 finished with value: 6.002078869612878 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015042235927511763, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14450507690850617, 'dropout_rate_Layer_2': 0.27425975642994416, 'dropout_rate_Layer_3': 0.16180305792898128, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03038147938637276, 'l1_Layer_2': 0.007607415980824337, 'l1_Layer_3': 0.042791783285589524, 'n_units_Layer_1': 265, 'n_units_Layer_2': 300, 'n_units_Layer_3': 60}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 75.10% | rMAE for Validation Set is: 1.80\n",
      "MAE for Test Set is: 37.29 | sMAPE for Test Set is: 155.89% | rMAE for Test Set is: 2.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:30:16,762]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:30:19,413]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:30:23,167]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:30:23,696]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:30:29,001]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:30:29,271]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:30:35,673]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:30:38,417]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:30:38,490]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:30:42,021]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:30:48,491]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:30:53,528]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:30:58,823]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:31:03,427]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:31:07,547]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:31:17,777]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:31:21,613]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:31:27,720]\u001b[0m Trial 636 finished with value: 3.582942231848296 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005991759083299492, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15994952662127282, 'dropout_rate_Layer_2': 0.344315991409515, 'dropout_rate_Layer_3': 0.09601448210925699, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.018319277665845367, 'l1_Layer_2': 0.00017657538421629387, 'l1_Layer_3': 0.008895296809188897, 'n_units_Layer_1': 230, 'n_units_Layer_2': 140, 'n_units_Layer_3': 120}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.58 | sMAPE for Validation Set is: 50.75% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 19.13 | sMAPE for Test Set is: 54.56% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:31:28,071]\u001b[0m Trial 633 finished with value: 4.345553710674703 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005362650726067986, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16342348624861086, 'dropout_rate_Layer_2': 0.21025164145113628, 'dropout_rate_Layer_3': 0.11249288101988206, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.005906536277555416, 'l1_Layer_2': 0.00018044246620292048, 'l1_Layer_3': 0.008675076939572623, 'n_units_Layer_1': 175, 'n_units_Layer_2': 165, 'n_units_Layer_3': 120}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.35 | sMAPE for Validation Set is: 65.25% | rMAE for Validation Set is: 1.31\n",
      "MAE for Test Set is: 15.23 | sMAPE for Test Set is: 45.73% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:31:30,114]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:31:32,377]\u001b[0m Trial 624 finished with value: 3.4346930197786154 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006273025760757992, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2800274404412676, 'dropout_rate_Layer_2': 0.21176840710077593, 'dropout_rate_Layer_3': 0.3771491308422385, 'dropout_rate_Layer_4': 0.06774074941236628, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.004801752156594403, 'l1_Layer_2': 0.0032515292173227977, 'l1_Layer_3': 2.3198333249503192e-05, 'l1_Layer_4': 0.0914516404103949, 'n_units_Layer_1': 135, 'n_units_Layer_2': 245, 'n_units_Layer_3': 205, 'n_units_Layer_4': 185}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.43 | sMAPE for Validation Set is: 46.18% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 9.18 | sMAPE for Test Set is: 23.19% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:31:36,814]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:31:40,684]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:31:40,822]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:31:48,153]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:31:53,756]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:31:53,916]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:32:00,700]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:32:01,020]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:32:07,142]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:32:07,523]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:32:08,288]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:32:08,399]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:32:17,736]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:32:18,164]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:32:28,569]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:32:32,461]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:32:33,701]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:32:37,641]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:32:39,808]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:32:43,604]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:32:48,544]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:32:57,685]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:33:12,263]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:33:19,245]\u001b[0m Trial 668 finished with value: 5.164226243723955 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011930338705697476, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2999368843897883, 'dropout_rate_Layer_2': 0.22152958517096386, 'dropout_rate_Layer_3': 0.1616607368932271, 'dropout_rate_Layer_4': 0.18373609213312211, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.009056737851578305, 'l1_Layer_2': 0.0035139477095302673, 'l1_Layer_3': 2.130909828613486e-05, 'l1_Layer_4': 0.0029585246340251095, 'n_units_Layer_1': 95, 'n_units_Layer_2': 235, 'n_units_Layer_3': 185, 'n_units_Layer_4': 260}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 62.08% | rMAE for Validation Set is: 1.55\n",
      "MAE for Test Set is: 34.58 | sMAPE for Test Set is: 132.38% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:33:23,002]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:33:25,507]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:33:29,222]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:33:32,767]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:33:34,929]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:33:39,528]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:33:46,876]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:33:47,395]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:33:53,690]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:33:53,959]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:33:59,641]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:33:59,904]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:00,588]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:07,022]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:07,339]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:08,118]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:14,812]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:17,615]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:17,835]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:19,015]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:19,510]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:27,339]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:29,400]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:29,595]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:30,463]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:30,547]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:35,319]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:37,187]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:42,311]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:42,844]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:44,254]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:51,593]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:51,706]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:56,328]\u001b[0m Trial 697 finished with value: 9.146782430189011 and parameters: {'n_hidden': 3, 'learning_rate': 0.04048634075786284, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32653665953200567, 'dropout_rate_Layer_2': 0.24830303171357718, 'dropout_rate_Layer_3': 0.19421197783017183, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006625125487849342, 'l1_Layer_2': 0.0006922867357939823, 'l1_Layer_3': 0.0014200231681739768, 'n_units_Layer_1': 145, 'n_units_Layer_2': 70, 'n_units_Layer_3': 245}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.15 | sMAPE for Validation Set is: 79.22% | rMAE for Validation Set is: 2.75\n",
      "MAE for Test Set is: 12.08 | sMAPE for Test Set is: 29.77% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:34:58,776]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:34:59,887]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:04,368]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:07,366]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:11,083]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:11,548]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:17,072]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:17,616]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:18,421]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:24,498]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:25,121]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:30,451]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:30,889]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:31,083]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:39,305]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:39,492]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:42,298]\u001b[0m Trial 713 finished with value: 5.37562999045063 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008392311104510174, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18519168360695232, 'dropout_rate_Layer_2': 0.14005498701295435, 'dropout_rate_Layer_3': 0.3300906968676052, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.017950426349246706, 'l1_Layer_2': 0.09763428637952119, 'l1_Layer_3': 0.0006249963386338679, 'n_units_Layer_1': 295, 'n_units_Layer_2': 280, 'n_units_Layer_3': 155}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 64.86% | rMAE for Validation Set is: 1.62\n",
      "MAE for Test Set is: 35.32 | sMAPE for Test Set is: 138.49% | rMAE for Test Set is: 2.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:35:48,064]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:48,818]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:49,380]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:35:54,833]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:00,149]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:02,217]\u001b[0m Trial 717 finished with value: 3.2038064004540323 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008203771545988696, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1886451850705592, 'dropout_rate_Layer_2': 0.3471198578255371, 'dropout_rate_Layer_3': 0.2976087370393714, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01897024316057493, 'l1_Layer_2': 0.0053752924709097065, 'l1_Layer_3': 0.0026909708134219825, 'n_units_Layer_1': 185, 'n_units_Layer_2': 285, 'n_units_Layer_3': 205}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.20 | sMAPE for Validation Set is: 43.79% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 8.82 | sMAPE for Test Set is: 21.44% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:36:04,417]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:05,032]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:07,336]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:09,492]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:14,111]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:14,568]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:14,993]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:21,392]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:21,431]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:22,057]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:27,767]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:28,268]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:28,809]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:32,685]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:34,925]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:40,018]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:45,073]\u001b[0m Trial 742 finished with value: 13.365085471152375 and parameters: {'n_hidden': 4, 'learning_rate': 0.012987313280094054, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15849682070530424, 'dropout_rate_Layer_2': 0.32984786089409784, 'dropout_rate_Layer_3': 0.3018974553671688, 'dropout_rate_Layer_4': 0.20912336123059055, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.04190726245143142, 'l1_Layer_2': 0.011282545778442378, 'l1_Layer_3': 0.002412128889591357, 'l1_Layer_4': 1.376198784822159e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 275, 'n_units_Layer_3': 210, 'n_units_Layer_4': 165}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.37 | sMAPE for Validation Set is: 95.68% | rMAE for Validation Set is: 4.02\n",
      "MAE for Test Set is: 21.46 | sMAPE for Test Set is: 57.23% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:36:49,020]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:53,680]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:36:54,236]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:37:00,929]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:37:09,693]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:37:14,733]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:37:19,751]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:37:23,928]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:37:26,404]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:37:31,461]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:37:32,119]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:37:36,616]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:37:37,009]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:37:37,835]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:37:46,281]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:37:49,993]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:37:53,826]\u001b[0m Trial 740 finished with value: 1.647235459391453 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013810095022946018, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07688271013201824, 'dropout_rate_Layer_2': 0.3771161500527912, 'dropout_rate_Layer_3': 0.08163944462294234, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0020986036355431495, 'l1_Layer_2': 0.0007501872257794337, 'l1_Layer_3': 0.018894638301814832, 'n_units_Layer_1': 125, 'n_units_Layer_2': 225, 'n_units_Layer_3': 105}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.65 | sMAPE for Validation Set is: 24.58% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 7.67 | sMAPE for Test Set is: 18.69% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:37:56,837]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:38:00,330]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:38:00,513]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:38:06,693]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:38:11,009]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:38:11,498]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:38:16,926]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:38:21,915]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:38:26,048]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:38:30,287]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:38:36,740]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:38:40,107]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:38:44,051]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:38:44,909]\u001b[0m Trial 761 finished with value: 1.5852961446913503 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014238557051953814, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08003512556978246, 'dropout_rate_Layer_2': 0.38999312680337833, 'dropout_rate_Layer_3': 0.2771266153088565, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002587921773919032, 'l1_Layer_2': 0.0008050837956658055, 'l1_Layer_3': 0.00830542462395858, 'n_units_Layer_1': 110, 'n_units_Layer_2': 225, 'n_units_Layer_3': 75}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.59 | sMAPE for Validation Set is: 22.76% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 7.42 | sMAPE for Test Set is: 17.91% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:38:49,761]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:38:50,231]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:38:55,347]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:38:56,548]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:39:02,406]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:39:02,573]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:39:07,678]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:39:08,118]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:39:13,607]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:39:20,517]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:39:22,112]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:39:29,313]\u001b[0m Trial 757 finished with value: 1.7413652313419703 and parameters: {'n_hidden': 3, 'learning_rate': 0.001404957967769758, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01971812518390327, 'dropout_rate_Layer_2': 0.39036266246416046, 'dropout_rate_Layer_3': 0.14411738748270414, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003439262316516887, 'l1_Layer_2': 1.2519886289674565e-05, 'l1_Layer_3': 0.02355488190655868, 'n_units_Layer_1': 115, 'n_units_Layer_2': 230, 'n_units_Layer_3': 250}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.74 | sMAPE for Validation Set is: 25.93% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 7.61 | sMAPE for Test Set is: 18.85% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:39:29,874]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:39:35,281]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:39:35,705]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:39:40,955]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:39:44,484]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:39:48,928]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:39:52,086]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:39:56,104]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:39:57,570]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:40:02,527]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:40:04,833]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:40:04,877]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:40:05,018]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:40:12,857]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:40:16,613]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:40:17,142]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:40:17,357]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:40:21,904]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:40:27,064]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:40:29,968]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:40:33,249]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:40:39,772]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:40:40,001]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 48.86% | rMAE for Validation Set is: 1.19\n",
      "MAE for Test Set is: 27.19 | sMAPE for Test Set is: 87.02% | rMAE for Test Set is: 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:40:43,915]\u001b[0m Trial 804 finished with value: 3.944680331648364 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010400550503826009, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14586112174147664, 'dropout_rate_Layer_2': 0.30336401484101483, 'dropout_rate_Layer_3': 0.35028868738644614, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018593047304493759, 'l1_Layer_2': 0.003531922911607616, 'l1_Layer_3': 0.0029233635654236758, 'n_units_Layer_1': 155, 'n_units_Layer_2': 135, 'n_units_Layer_3': 70}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:40:47,124]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:41:04,185]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:41:11,784]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:41:15,140]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:41:22,966]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:41:23,496]\u001b[0m Trial 811 finished with value: 3.908944276008572 and parameters: {'n_hidden': 3, 'learning_rate': 0.000805872635077503, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17166004859933315, 'dropout_rate_Layer_2': 0.3503330096724281, 'dropout_rate_Layer_3': 0.1356588692565364, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013228621693233543, 'l1_Layer_2': 3.9461119096521376e-05, 'l1_Layer_3': 0.00021729397600383493, 'n_units_Layer_1': 275, 'n_units_Layer_2': 270, 'n_units_Layer_3': 175}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 54.34% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 16.74 | sMAPE for Test Set is: 47.01% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:41:29,322]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:41:29,356]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:41:36,194]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:41:36,369]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:41:42,430]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:41:42,913]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:41:48,029]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:41:51,908]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:41:56,137]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:41:58,851]\u001b[0m Trial 823 finished with value: 2.167163983536962 and parameters: {'n_hidden': 3, 'learning_rate': 0.015520609900671249, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07763828285312506, 'dropout_rate_Layer_2': 0.1636937283004064, 'dropout_rate_Layer_3': 0.031786302432961405, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.608058886167772e-05, 'l1_Layer_2': 0.05146282367544731, 'l1_Layer_3': 0.017084006488682874, 'n_units_Layer_1': 215, 'n_units_Layer_2': 210, 'n_units_Layer_3': 250}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.17 | sMAPE for Validation Set is: 31.36% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.46 | sMAPE for Test Set is: 21.50% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:42:00,281]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:42:03,496]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:42:07,337]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:42:10,679]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:42:13,412]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:42:18,270]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:42:22,606]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:42:27,498]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:42:31,398]\u001b[0m Trial 821 finished with value: 2.258887932658085 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005337707830687158, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29815830379062347, 'dropout_rate_Layer_2': 0.38367201159511255, 'dropout_rate_Layer_3': 0.17538329558535684, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007445595147321467, 'l1_Layer_2': 0.0010214586760177783, 'l1_Layer_3': 0.004868564196857031, 'n_units_Layer_1': 165, 'n_units_Layer_2': 245, 'n_units_Layer_3': 225}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.26 | sMAPE for Validation Set is: 43.29% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.57 | sMAPE for Test Set is: 18.18% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:42:32,203]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:42:37,231]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:42:40,375]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:42:51,491]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:43:20,547]\u001b[0m Trial 814 finished with value: 1.5464267675153838 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014386890778651923, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09475032867679441, 'dropout_rate_Layer_2': 0.2957787712359515, 'dropout_rate_Layer_3': 0.27489616169611614, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003859255145405124, 'l1_Layer_2': 0.000461907775579072, 'l1_Layer_3': 0.005435921360973796, 'n_units_Layer_1': 105, 'n_units_Layer_2': 220, 'n_units_Layer_3': 70}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 22.29% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 7.67 | sMAPE for Test Set is: 19.04% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:43:28,888]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:43:42,824]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:43:46,923]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:43:54,361]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:43:54,742]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:44:00,439]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:44:00,983]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:44:06,861]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 23.02% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 7.05 | sMAPE for Test Set is: 17.13% | rMAE for Test Set is: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:44:09,111]\u001b[0m Trial 834 finished with value: 1.5478142702363655 and parameters: {'n_hidden': 3, 'learning_rate': 0.001190971716796754, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008889612642613925, 'dropout_rate_Layer_2': 0.3892720319262493, 'dropout_rate_Layer_3': 0.1584422145582016, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017571222491349731, 'l1_Layer_2': 0.00180339397037663, 'l1_Layer_3': 0.011219870388382961, 'n_units_Layer_1': 110, 'n_units_Layer_2': 230, 'n_units_Layer_3': 50}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:44:13,218]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:44:15,384]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:44:19,221]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:44:23,549]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:44:30,427]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:44:38,121]\u001b[0m Trial 839 finished with value: 1.4826252698344884 and parameters: {'n_hidden': 3, 'learning_rate': 0.001046225166826854, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008241988862362515, 'dropout_rate_Layer_2': 0.16284995241058742, 'dropout_rate_Layer_3': 0.24375251977135948, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016578561402837682, 'l1_Layer_2': 0.0006123857901829341, 'l1_Layer_3': 0.037205266674722966, 'n_units_Layer_1': 105, 'n_units_Layer_2': 230, 'n_units_Layer_3': 55}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 21.20% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 7.32 | sMAPE for Test Set is: 18.13% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:44:40,559]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:44:48,629]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:45:02,192]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:45:02,336]\u001b[0m Trial 857 finished with value: 3.554458593436505 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008342524873894632, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21658973750518265, 'dropout_rate_Layer_2': 0.3407827634229497, 'dropout_rate_Layer_3': 0.14105573890346687, 'dropout_rate_Layer_4': 0.0940268527099396, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0379078845127955e-05, 'l1_Layer_2': 0.002274991873273194, 'l1_Layer_3': 0.024299732631400138, 'l1_Layer_4': 0.00010953595492470383, 'n_units_Layer_1': 150, 'n_units_Layer_2': 80, 'n_units_Layer_3': 105, 'n_units_Layer_4': 230}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 44.39% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 26.91 | sMAPE for Test Set is: 85.67% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:45:06,928]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:45:08,827]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:45:12,505]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:45:15,811]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:45:16,143]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:45:21,165]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:45:26,172]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:45:40,843]\u001b[0m Trial 860 finished with value: 4.057636097115061 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008685606031797634, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21514049300967122, 'dropout_rate_Layer_2': 0.3839571799913071, 'dropout_rate_Layer_3': 0.014653178626319513, 'dropout_rate_Layer_4': 0.08113707540592743, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.099256935327424e-05, 'l1_Layer_2': 0.0022078404727102607, 'l1_Layer_3': 0.0037724961874873245, 'l1_Layer_4': 0.0001329818308330348, 'n_units_Layer_1': 145, 'n_units_Layer_2': 80, 'n_units_Layer_3': 125, 'n_units_Layer_4': 230}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 53.19% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 9.21 | sMAPE for Test Set is: 23.00% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:45:57,584]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:46:02,463]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:46:07,222]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:46:14,530]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:46:18,511]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:46:21,059]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:46:25,471]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:46:27,199]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:46:31,779]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:46:36,500]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:46:40,856]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:46:43,494]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:46:46,255]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:46:48,978]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:46:49,566]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:46:56,386]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:00,013]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:01,605]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:02,847]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:08,835]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:09,544]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:18,095]\u001b[0m Trial 886 finished with value: 1.993811945647361 and parameters: {'n_hidden': 3, 'learning_rate': 0.007764777652625482, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04245233200397333, 'dropout_rate_Layer_2': 0.1187327769617412, 'dropout_rate_Layer_3': 0.13592627311802252, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002802239453644455, 'l1_Layer_2': 0.006089983388167261, 'l1_Layer_3': 0.025325592406548924, 'n_units_Layer_1': 215, 'n_units_Layer_2': 220, 'n_units_Layer_3': 260}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.99 | sMAPE for Validation Set is: 31.84% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.56 | sMAPE for Test Set is: 18.37% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:47:20,094]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:22,633]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:23,836]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:28,663]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:32,834]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:35,312]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:38,362]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:38,527]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:43,834]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:44,222]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:45,685]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:52,150]\u001b[0m Trial 891 finished with value: 3.78351772760144 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005506875271882913, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2926983740430538, 'dropout_rate_Layer_2': 0.005765375873540091, 'dropout_rate_Layer_3': 0.155958763829008, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003188237250182738, 'l1_Layer_2': 0.0012276503881704776, 'l1_Layer_3': 0.004878997783925283, 'n_units_Layer_1': 295, 'n_units_Layer_2': 145, 'n_units_Layer_3': 220}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 51.64% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 17.60 | sMAPE for Test Set is: 48.55% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:47:52,513]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:47:53,213]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:48:00,620]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:48:02,812]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:48:07,188]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:48:08,862]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:48:11,082]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:48:15,348]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:48:21,423]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:48:25,461]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:48:25,487]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:48:31,083]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:48:33,934]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:48:35,670]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:48:41,080]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:48:45,276]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:48:49,626]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:48:51,422]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:48:54,659]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:49:09,362]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:50:13,082]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:50:16,870]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:50:19,862]\u001b[0m Trial 914 finished with value: 1.4944732049735698 and parameters: {'n_hidden': 3, 'learning_rate': 0.000977193710540932, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02763611793045118, 'dropout_rate_Layer_2': 0.16352222899128122, 'dropout_rate_Layer_3': 0.2541304294599283, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015857001680151712, 'l1_Layer_2': 0.0006601565640413608, 'l1_Layer_3': 0.006810744852944556, 'n_units_Layer_1': 115, 'n_units_Layer_2': 220, 'n_units_Layer_3': 250}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 21.58% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 7.59 | sMAPE for Test Set is: 19.24% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:50:21,758]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:50:24,714]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:50:28,105]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:50:28,335]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:50:35,966]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:50:38,962]\u001b[0m Trial 916 finished with value: 1.6611539984950339 and parameters: {'n_hidden': 3, 'learning_rate': 0.00101638587228406, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02614473222965821, 'dropout_rate_Layer_2': 0.13576358141726108, 'dropout_rate_Layer_3': 0.25249475862937815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009659253833496699, 'l1_Layer_2': 0.0007091767531511626, 'l1_Layer_3': 0.006880507006750194, 'n_units_Layer_1': 115, 'n_units_Layer_2': 220, 'n_units_Layer_3': 250}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.66 | sMAPE for Validation Set is: 22.46% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 7.44 | sMAPE for Test Set is: 18.16% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:50:43,584]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:50:46,298]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:50:49,138]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:50:51,418]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:50:55,523]\u001b[0m Trial 921 finished with value: 1.6542746788492995 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010485128678178368, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09014747382219573, 'dropout_rate_Layer_2': 0.12636213774495206, 'dropout_rate_Layer_3': 0.14835402321608096, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009350082625694811, 'l1_Layer_2': 0.0005274650657337578, 'l1_Layer_3': 0.007462570189479089, 'n_units_Layer_1': 150, 'n_units_Layer_2': 140, 'n_units_Layer_3': 250}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.65 | sMAPE for Validation Set is: 23.14% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 7.35 | sMAPE for Test Set is: 17.65% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:50:57,541]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:51:02,624]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:51:02,803]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.98 | sMAPE for Validation Set is: 44.66% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 10.00 | sMAPE for Test Set is: 24.22% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:51:07,118]\u001b[0m Trial 930 finished with value: 2.975419833374693 and parameters: {'n_hidden': 3, 'learning_rate': 0.000836242967214471, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26670998650756145, 'dropout_rate_Layer_2': 0.3836787610916394, 'dropout_rate_Layer_3': 0.20395753996835428, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006717222398904328, 'l1_Layer_2': 0.01010845268485664, 'l1_Layer_3': 0.002051586383238055, 'n_units_Layer_1': 150, 'n_units_Layer_2': 180, 'n_units_Layer_3': 190}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:51:09,104]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:51:10,561]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:51:43,709]\u001b[0m Trial 942 finished with value: 2.6322031411922904 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006403333730684478, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2666042968030761, 'dropout_rate_Layer_2': 0.3434157284038792, 'dropout_rate_Layer_3': 0.2363209327530861, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01086461564005828, 'l1_Layer_2': 0.018966789121398056, 'l1_Layer_3': 0.0018740768335594828, 'n_units_Layer_1': 130, 'n_units_Layer_2': 185, 'n_units_Layer_3': 210}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.63 | sMAPE for Validation Set is: 38.15% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 8.39 | sMAPE for Test Set is: 21.26% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:51:49,571]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:51:52,441]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:51:54,976]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:52:09,225]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:52:13,667]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:52:31,187]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:52:34,000]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:52:37,875]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:52:38,623]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:52:47,603]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:52:50,178]\u001b[0m Trial 947 finished with value: 3.5394622436965513 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009119113992665306, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2653999544827291, 'dropout_rate_Layer_2': 0.15077398165605177, 'dropout_rate_Layer_3': 0.048988149320745786, 'dropout_rate_Layer_4': 0.12555711233947783, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.285998394753846e-05, 'l1_Layer_2': 0.005645294478989213, 'l1_Layer_3': 0.034950911945881624, 'l1_Layer_4': 0.00038698440370688394, 'n_units_Layer_1': 150, 'n_units_Layer_2': 100, 'n_units_Layer_3': 90, 'n_units_Layer_4': 160}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 53.51% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 8.69 | sMAPE for Test Set is: 20.54% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:52:53,840]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:52:57,589]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:53:02,017]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:53:06,385]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:53:10,192]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:53:15,495]\u001b[0m Trial 952 finished with value: 2.172626328403156 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008035255652338831, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26583312034446926, 'dropout_rate_Layer_2': 0.20586416543556546, 'dropout_rate_Layer_3': 0.20052868108726862, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0114423226128385, 'l1_Layer_2': 0.01021160443121065, 'l1_Layer_3': 0.008925639365049351, 'n_units_Layer_1': 135, 'n_units_Layer_2': 185, 'n_units_Layer_3': 210}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.17 | sMAPE for Validation Set is: 40.25% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.46 | sMAPE for Test Set is: 18.02% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:53:34,142]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:53:41,729]\u001b[0m Trial 959 finished with value: 2.8934470439560456 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008310246551466487, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23336477374948147, 'dropout_rate_Layer_2': 0.15034764513555987, 'dropout_rate_Layer_3': 0.0647179595585177, 'dropout_rate_Layer_4': 0.054711786527187216, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.763040989671745e-05, 'l1_Layer_2': 0.002688832449834833, 'l1_Layer_3': 0.024117051491821643, 'l1_Layer_4': 9.638380396146648e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 90, 'n_units_Layer_3': 85, 'n_units_Layer_4': 120}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.89 | sMAPE for Validation Set is: 55.06% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 8.07 | sMAPE for Test Set is: 19.74% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:53:46,133]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:53:48,185]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:53:52,690]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:53:56,221]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:53:59,705]\u001b[0m Trial 935 finished with value: 1.7727908312128775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007298912919347499, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03690325785286862, 'dropout_rate_Layer_2': 0.10935838896066155, 'dropout_rate_Layer_3': 0.23359707521187012, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000918597056342061, 'l1_Layer_2': 0.0005976121019123285, 'l1_Layer_3': 0.009918306544041742, 'n_units_Layer_1': 120, 'n_units_Layer_2': 215, 'n_units_Layer_3': 255}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.77 | sMAPE for Validation Set is: 27.26% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 7.24 | sMAPE for Test Set is: 17.48% | rMAE for Test Set is: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:54:03,640]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:54:05,543]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:54:09,624]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:54:13,833]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:54:22,192]\u001b[0m Trial 964 finished with value: 3.99127571616263 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008383049702423018, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2820519713937622, 'dropout_rate_Layer_2': 0.15259038759427743, 'dropout_rate_Layer_3': 0.06750119492703023, 'dropout_rate_Layer_4': 0.04855853432361973, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.857011015024538e-05, 'l1_Layer_2': 0.001726670974489384, 'l1_Layer_3': 0.02035850484604664, 'l1_Layer_4': 0.0001082102275666097, 'n_units_Layer_1': 135, 'n_units_Layer_2': 90, 'n_units_Layer_3': 85, 'n_units_Layer_4': 125}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 57.21% | rMAE for Validation Set is: 1.20\n",
      "MAE for Test Set is: 10.52 | sMAPE for Test Set is: 26.82% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:54:28,169]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:54:34,962]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:54:41,611]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:54:44,308]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:54:49,262]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:54:53,442]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:54:58,730]\u001b[0m Trial 971 finished with value: 3.2811967339814263 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008402250656081465, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22667635898660793, 'dropout_rate_Layer_2': 0.16147567622670345, 'dropout_rate_Layer_3': 0.04861271886597786, 'dropout_rate_Layer_4': 0.04097928280186069, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.514028354851189e-05, 'l1_Layer_2': 0.0035569840922727958, 'l1_Layer_3': 0.033397830832389466, 'l1_Layer_4': 0.00010545183010868453, 'n_units_Layer_1': 150, 'n_units_Layer_2': 90, 'n_units_Layer_3': 125, 'n_units_Layer_4': 120}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.28 | sMAPE for Validation Set is: 57.33% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 7.53 | sMAPE for Test Set is: 18.81% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:55:01,219]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:55:03,769]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:55:04,703]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:55:07,248]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:55:09,261]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:55:16,328]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:55:18,901]\u001b[0m Trial 960 finished with value: 1.714122143023636 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012428177224811333, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07718372450759722, 'dropout_rate_Layer_2': 0.11484547625285516, 'dropout_rate_Layer_3': 0.23189827238745017, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012035122767792088, 'l1_Layer_2': 0.0004316636107684195, 'l1_Layer_3': 0.005257755815738634, 'n_units_Layer_1': 145, 'n_units_Layer_2': 180, 'n_units_Layer_3': 245}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.71 | sMAPE for Validation Set is: 25.15% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 7.50 | sMAPE for Test Set is: 18.26% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:55:21,319]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:55:24,485]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:55:37,705]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:55:48,865]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:55:52,822]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:56:01,015]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:56:04,602]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:56:11,792]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:56:49,284]\u001b[0m Trial 982 finished with value: 1.6528373043107676 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008144419292114198, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006102756571363242, 'dropout_rate_Layer_2': 0.3731204307129022, 'dropout_rate_Layer_3': 0.15281598319305342, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017724471263705726, 'l1_Layer_2': 0.000647823240503499, 'l1_Layer_3': 0.004633921481490626, 'n_units_Layer_1': 130, 'n_units_Layer_2': 180, 'n_units_Layer_3': 255}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.65 | sMAPE for Validation Set is: 25.19% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 7.19 | sMAPE for Test Set is: 17.46% | rMAE for Test Set is: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:56:59,150]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:57:03,196]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:57:06,964]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:57:10,986]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:57:20,756]\u001b[0m Trial 994 finished with value: 1.6091398592612869 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011303059565555326, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.061573128211618845, 'dropout_rate_Layer_2': 0.1140308612863595, 'dropout_rate_Layer_3': 0.21432445462100969, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015970413436900389, 'l1_Layer_2': 0.000614221222020913, 'l1_Layer_3': 0.006181165214929645, 'n_units_Layer_1': 130, 'n_units_Layer_2': 185, 'n_units_Layer_3': 245}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.61 | sMAPE for Validation Set is: 23.88% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 7.55 | sMAPE for Test Set is: 18.10% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:57:23,268]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:57:29,523]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:57:29,711]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:57:33,479]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:57:37,908]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:57:41,186]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:57:44,311]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:57:49,387]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:57:53,241]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:57:59,043]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:58:03,076]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:58:08,245]\u001b[0m Trial 1002 finished with value: 2.6732942976582605 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008659125739757617, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28271204844923437, 'dropout_rate_Layer_2': 0.16787769521593082, 'dropout_rate_Layer_3': 0.07201786690735633, 'dropout_rate_Layer_4': 0.043581139400747246, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.791345447952481e-05, 'l1_Layer_2': 0.0016253267964326142, 'l1_Layer_3': 0.03103517002990572, 'l1_Layer_4': 0.00010265392249837754, 'n_units_Layer_1': 145, 'n_units_Layer_2': 90, 'n_units_Layer_3': 120, 'n_units_Layer_4': 120}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.67 | sMAPE for Validation Set is: 52.25% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 14.18 | sMAPE for Test Set is: 36.60% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:58:12,321]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:58:14,396]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:58:14,941]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:58:21,573]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:58:22,760]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:58:27,793]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:58:32,119]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:58:44,878]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:58:49,109]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:58:56,588]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:58:57,670]\u001b[0m Trial 1013 finished with value: 2.1331413649118054 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008842781940691074, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015284148361531521, 'dropout_rate_Layer_2': 0.1265258156655846, 'dropout_rate_Layer_3': 0.20013440488068163, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010391807655619834, 'l1_Layer_2': 0.03138814201364248, 'l1_Layer_3': 0.044866427551864506, 'n_units_Layer_1': 130, 'n_units_Layer_2': 180, 'n_units_Layer_3': 260}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 33.36% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.95 | sMAPE for Test Set is: 19.45% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:59:02,829]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:59:08,291]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:59:12,399]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:59:13,298]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:59:15,644]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:59:19,237]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:59:24,499]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:59:25,248]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:59:27,102]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.64 | sMAPE for Validation Set is: 24.59% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 7.45 | sMAPE for Test Set is: 18.07% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 06:59:31,545]\u001b[0m Trial 1010 finished with value: 1.6386148808792769 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009864010374623388, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007220985583222345, 'dropout_rate_Layer_2': 0.12531298485165634, 'dropout_rate_Layer_3': 0.2127709032354616, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023174297500974366, 'l1_Layer_2': 0.0007568536688076028, 'l1_Layer_3': 0.039292880882243066, 'n_units_Layer_1': 140, 'n_units_Layer_2': 190, 'n_units_Layer_3': 260}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:59:35,060]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:59:36,444]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:59:39,400]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:59:43,287]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:59:52,460]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:59:54,249]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 06:59:59,429]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:00:00,177]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:00:03,438]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:00:05,015]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:00:09,197]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:00:10,440]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:00:15,492]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:00:20,348]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:00:23,898]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:00:23,931]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:00:30,564]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:00:38,357]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:00:56,251]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:00:59,443]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:01:01,639]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:01:02,824]\u001b[0m Trial 1047 finished with value: 3.3447117062264446 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008500203241550231, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2735603675516069, 'dropout_rate_Layer_2': 0.19645785189676698, 'dropout_rate_Layer_3': 0.09020418156816806, 'dropout_rate_Layer_4': 0.10992505878881055, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.767536345049889e-05, 'l1_Layer_2': 0.004235521259123016, 'l1_Layer_3': 0.02190978350832618, 'l1_Layer_4': 0.00037043985365471877, 'n_units_Layer_1': 165, 'n_units_Layer_2': 95, 'n_units_Layer_3': 300, 'n_units_Layer_4': 105}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.34 | sMAPE for Validation Set is: 56.09% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 7.99 | sMAPE for Test Set is: 19.40% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:01:05,335]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:01:08,529]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:01:14,036]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:01:18,415]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:01:22,946]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:01:23,500]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:01:33,324]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:01:36,127]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:01:44,198]\u001b[0m Trial 1055 finished with value: 2.855176923000353 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010872595981508654, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23949089276794405, 'dropout_rate_Layer_2': 0.1980860092904978, 'dropout_rate_Layer_3': 0.04787779620182429, 'dropout_rate_Layer_4': 0.11395517637962874, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.357380799187733e-05, 'l1_Layer_2': 0.0061322715951038454, 'l1_Layer_3': 0.02194979616253383, 'l1_Layer_4': 0.00020611882405717773, 'n_units_Layer_1': 155, 'n_units_Layer_2': 100, 'n_units_Layer_3': 85, 'n_units_Layer_4': 100}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.86 | sMAPE for Validation Set is: 62.11% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 8.17 | sMAPE for Test Set is: 19.39% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:01:48,772]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:01:52,616]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:01:58,588]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:02:03,986]\u001b[0m Trial 1062 finished with value: 2.9649329087330485 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006577376724682323, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2892578167494016, 'dropout_rate_Layer_2': 0.3418942516035733, 'dropout_rate_Layer_3': 0.1995290305303411, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006629768542051166, 'l1_Layer_2': 0.01193626561812436, 'l1_Layer_3': 0.001341847463661019, 'n_units_Layer_1': 160, 'n_units_Layer_2': 205, 'n_units_Layer_3': 200}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.96 | sMAPE for Validation Set is: 45.16% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 9.38 | sMAPE for Test Set is: 24.81% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:02:07,652]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:02:11,610]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:02:16,318]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:02:25,944]\u001b[0m Trial 1056 finished with value: 1.7412133400674872 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008010742537951751, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 1.0683031797315695e-05, 'dropout_rate_Layer_2': 0.3815704260108124, 'dropout_rate_Layer_3': 0.2552693425614503, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002408089359478605, 'l1_Layer_2': 0.08733022926162919, 'l1_Layer_3': 0.0012824217115016267, 'n_units_Layer_1': 125, 'n_units_Layer_2': 200, 'n_units_Layer_3': 245}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.74 | sMAPE for Validation Set is: 27.29% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 7.40 | sMAPE for Test Set is: 17.91% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:02:26,591]\u001b[0m Trial 1066 finished with value: 2.9287832972141694 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010604302974790195, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2619790499339374, 'dropout_rate_Layer_2': 0.19507525937843298, 'dropout_rate_Layer_3': 0.07271806638203761, 'dropout_rate_Layer_4': 0.16064919112066006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.135718691846964e-05, 'l1_Layer_2': 0.006324760634050847, 'l1_Layer_3': 0.02172205258288336, 'l1_Layer_4': 0.0003074849145138107, 'n_units_Layer_1': 155, 'n_units_Layer_2': 105, 'n_units_Layer_3': 275, 'n_units_Layer_4': 105}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.93 | sMAPE for Validation Set is: 54.80% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 8.50 | sMAPE for Test Set is: 20.46% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:02:31,815]\u001b[0m Trial 1068 finished with value: 1.9424239600667716 and parameters: {'n_hidden': 3, 'learning_rate': 0.002591775562795224, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06143408053422492, 'dropout_rate_Layer_2': 0.12190350846236797, 'dropout_rate_Layer_3': 0.054649601996321726, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.4470864763995865e-05, 'l1_Layer_2': 0.0200287983620039, 'l1_Layer_3': 0.01999295883916372, 'n_units_Layer_1': 225, 'n_units_Layer_2': 230, 'n_units_Layer_3': 185}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 30.55% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.54 | sMAPE for Test Set is: 18.24% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:02:36,259]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:02:41,422]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:02:53,026]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:02:59,371]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:03:05,288]\u001b[0m Trial 1071 finished with value: 2.990894098846084 and parameters: {'n_hidden': 4, 'learning_rate': 0.00105211627181378, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24036399155353985, 'dropout_rate_Layer_2': 0.19776997982548383, 'dropout_rate_Layer_3': 0.07960027397510851, 'dropout_rate_Layer_4': 0.1671435474989985, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00011939368581104137, 'l1_Layer_2': 0.009136772697209826, 'l1_Layer_3': 0.08074869927025263, 'l1_Layer_4': 0.0005250879592467956, 'n_units_Layer_1': 155, 'n_units_Layer_2': 105, 'n_units_Layer_3': 265, 'n_units_Layer_4': 80}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.99 | sMAPE for Validation Set is: 45.52% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 8.76 | sMAPE for Test Set is: 20.46% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:03:10,446]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:03:15,764]\u001b[0m Trial 1077 finished with value: 1.754538504703242 and parameters: {'n_hidden': 3, 'learning_rate': 0.002679568749411792, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16480948466045173, 'dropout_rate_Layer_2': 0.11063294130986953, 'dropout_rate_Layer_3': 0.04528899344664712, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.995803046646809e-05, 'l1_Layer_2': 0.009259980598315619, 'l1_Layer_3': 0.014082022853912288, 'n_units_Layer_1': 220, 'n_units_Layer_2': 235, 'n_units_Layer_3': 190}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:03:15,834]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.75 | sMAPE for Validation Set is: 27.16% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 7.63 | sMAPE for Test Set is: 18.35% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:03:21,301]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:03:24,955]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:03:25,520]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:03:26,411]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:03:27,218]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:03:38,363]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:03:41,714]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:03:45,014]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:03:48,815]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:03:53,113]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:04:02,310]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:04:07,741]\u001b[0m Trial 1089 finished with value: 3.1943173017054654 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007942068435573577, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2886767518836681, 'dropout_rate_Layer_2': 0.34239251073494864, 'dropout_rate_Layer_3': 0.2032085700989837, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007462645740198108, 'l1_Layer_2': 0.010812084391501038, 'l1_Layer_3': 0.0012256040867799805, 'n_units_Layer_1': 165, 'n_units_Layer_2': 175, 'n_units_Layer_3': 230}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.19 | sMAPE for Validation Set is: 44.25% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 8.76 | sMAPE for Test Set is: 21.12% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:04:12,964]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:04:18,501]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:04:20,886]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:04:26,903]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:04:32,059]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:04:39,818]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:04:40,063]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:04:52,568]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:04:56,604]\u001b[0m Trial 1099 finished with value: 2.7760754650070254 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008254678649881747, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34135082548387197, 'dropout_rate_Layer_2': 0.3368715366329545, 'dropout_rate_Layer_3': 0.2232480295449178, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01070099738955162, 'l1_Layer_2': 0.01079901853230683, 'l1_Layer_3': 0.0005610019327520808, 'n_units_Layer_1': 160, 'n_units_Layer_2': 205, 'n_units_Layer_3': 245}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.78 | sMAPE for Validation Set is: 41.62% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 8.34 | sMAPE for Test Set is: 19.76% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:05:03,937]\u001b[0m Trial 1093 finished with value: 1.5473555014467173 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008356755173243384, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019678214699045873, 'dropout_rate_Layer_2': 0.12068802645105389, 'dropout_rate_Layer_3': 0.17426116332260175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0020743793489110614, 'l1_Layer_2': 0.0007086322682275478, 'l1_Layer_3': 0.028518020115470857, 'n_units_Layer_1': 110, 'n_units_Layer_2': 225, 'n_units_Layer_3': 70}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 26.06% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 7.22 | sMAPE for Test Set is: 17.67% | rMAE for Test Set is: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:05:10,051]\u001b[0m Trial 1101 finished with value: 1.9306828436247152 and parameters: {'n_hidden': 3, 'learning_rate': 0.002346383813037644, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15514956701971014, 'dropout_rate_Layer_2': 0.11801661418435658, 'dropout_rate_Layer_3': 0.03804104192296923, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017679552708528086, 'l1_Layer_2': 0.006642305832851382, 'l1_Layer_3': 0.022154470246462388, 'n_units_Layer_1': 235, 'n_units_Layer_2': 230, 'n_units_Layer_3': 175}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 30.29% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.89 | sMAPE for Test Set is: 19.00% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:05:10,609]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:05:12,721]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:05:20,878]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:05:25,653]\u001b[0m Trial 1103 finished with value: 1.7847049379437303 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024094340415349094, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17857349256959257, 'dropout_rate_Layer_2': 0.10363365431133753, 'dropout_rate_Layer_3': 0.04588969820384897, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.816518414121593e-05, 'l1_Layer_2': 0.006842049261941283, 'l1_Layer_3': 0.020398954967041926, 'n_units_Layer_1': 215, 'n_units_Layer_2': 230, 'n_units_Layer_3': 175}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.78 | sMAPE for Validation Set is: 27.77% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.64 | sMAPE for Test Set is: 18.63% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:05:36,710]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:05:37,296]\u001b[0m Trial 1106 finished with value: 1.752157824358236 and parameters: {'n_hidden': 3, 'learning_rate': 0.002327748542263263, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15454902953442318, 'dropout_rate_Layer_2': 0.11809937906176789, 'dropout_rate_Layer_3': 0.038575639757561786, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001731956997421849, 'l1_Layer_2': 0.006818114040063001, 'l1_Layer_3': 0.02014413582128295, 'n_units_Layer_1': 240, 'n_units_Layer_2': 230, 'n_units_Layer_3': 175}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.75 | sMAPE for Validation Set is: 26.90% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 7.67 | sMAPE for Test Set is: 18.68% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:05:44,363]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:05:50,490]\u001b[0m Trial 1109 finished with value: 2.0512969575773927 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024007079014001296, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19834613695109374, 'dropout_rate_Layer_2': 0.1021029964459986, 'dropout_rate_Layer_3': 0.04975464828669533, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00184524181007212, 'l1_Layer_2': 0.007641620421664277, 'l1_Layer_3': 0.026235911550520165, 'n_units_Layer_1': 230, 'n_units_Layer_2': 225, 'n_units_Layer_3': 170}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 31.95% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.82 | sMAPE for Test Set is: 18.76% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:05:50,686]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:05:52,301]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:06:03,496]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:06:08,103]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:06:18,084]\u001b[0m Trial 1114 finished with value: 1.8237066049628936 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022835760873142585, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19959941139736198, 'dropout_rate_Layer_2': 0.1006989567639047, 'dropout_rate_Layer_3': 0.0475777778011733, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014547318770616344, 'l1_Layer_2': 0.006573146514565666, 'l1_Layer_3': 0.024752911640081008, 'n_units_Layer_1': 250, 'n_units_Layer_2': 225, 'n_units_Layer_3': 170}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.82 | sMAPE for Validation Set is: 29.22% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.55 | sMAPE for Test Set is: 18.14% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:06:21,666]\u001b[0m Trial 1115 finished with value: 1.846978367962213 and parameters: {'n_hidden': 3, 'learning_rate': 0.00208951275637178, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20148337623456808, 'dropout_rate_Layer_2': 0.08591605193282453, 'dropout_rate_Layer_3': 0.047489323356995294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00167960653721831, 'l1_Layer_2': 0.00680645126255046, 'l1_Layer_3': 0.02374348460015507, 'n_units_Layer_1': 240, 'n_units_Layer_2': 225, 'n_units_Layer_3': 165}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.85 | sMAPE for Validation Set is: 28.05% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.41 | sMAPE for Test Set is: 17.93% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:06:26,379]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:06:42,606]\u001b[0m Trial 1118 finished with value: 1.6416033704610697 and parameters: {'n_hidden': 3, 'learning_rate': 0.002282536827240193, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2168888274037816, 'dropout_rate_Layer_2': 0.09712451162074634, 'dropout_rate_Layer_3': 0.05089189810783125, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014691680056043413, 'l1_Layer_2': 0.006487942756227043, 'l1_Layer_3': 0.025749727590695368, 'n_units_Layer_1': 245, 'n_units_Layer_2': 230, 'n_units_Layer_3': 160}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.64 | sMAPE for Validation Set is: 25.32% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 7.56 | sMAPE for Test Set is: 18.29% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:06:46,927]\u001b[0m Trial 1119 finished with value: 1.875332709798795 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023461201884866292, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2049543540169962, 'dropout_rate_Layer_2': 0.08261369260521496, 'dropout_rate_Layer_3': 0.05564684379555962, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001476710576446402, 'l1_Layer_2': 0.007510117327209167, 'l1_Layer_3': 0.02699130286574376, 'n_units_Layer_1': 250, 'n_units_Layer_2': 230, 'n_units_Layer_3': 155}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 29.92% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.43 | sMAPE for Test Set is: 17.98% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:06:52,706]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:06:52,914]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:07:00,386]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:07:05,731]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:07:12,532]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:07:16,877]\u001b[0m Trial 1108 finished with value: 1.4440258177519951 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006294119721688317, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01646779424092794, 'dropout_rate_Layer_2': 0.11747181633491054, 'dropout_rate_Layer_3': 0.16387212238402754, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0033189304753549176, 'l1_Layer_2': 0.021315040422995212, 'l1_Layer_3': 0.0225725370226275, 'n_units_Layer_1': 105, 'n_units_Layer_2': 170, 'n_units_Layer_3': 75}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 21.06% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 7.35 | sMAPE for Test Set is: 17.74% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:07:20,692]\u001b[0m Trial 1124 finished with value: 3.3731815219533545 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006952706902109674, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30613511226410417, 'dropout_rate_Layer_2': 0.3159241585454011, 'dropout_rate_Layer_3': 0.21773335308087544, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015324857790016442, 'l1_Layer_2': 0.051833022768732896, 'l1_Layer_3': 0.0008286751425460849, 'n_units_Layer_1': 145, 'n_units_Layer_2': 190, 'n_units_Layer_3': 250}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.37 | sMAPE for Validation Set is: 43.70% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 21.53 | sMAPE for Test Set is: 63.01% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:07:22,969]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:07:23,169]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:07:32,358]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:07:32,492]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:07:41,246]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:07:41,465]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:07:45,739]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:07:49,950]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:07:50,492]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:08:07,467]\u001b[0m Trial 1126 finished with value: 1.5720317925090797 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011393349961289739, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009020800349084855, 'dropout_rate_Layer_2': 0.2579438190920222, 'dropout_rate_Layer_3': 0.18809461065537098, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018533312849728708, 'l1_Layer_2': 0.0007765572885166676, 'l1_Layer_3': 0.050820402831515045, 'n_units_Layer_1': 100, 'n_units_Layer_2': 130, 'n_units_Layer_3': 55}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 23.05% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 7.61 | sMAPE for Test Set is: 18.48% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:08:11,553]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:08:18,880]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:08:18,962]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:08:29,690]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:08:37,149]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:08:37,555]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:08:45,573]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:08:53,769]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:08:57,014]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:09:01,723]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:09:03,779]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:09:07,308]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:09:11,175]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:09:16,969]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:09:20,373]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:09:24,675]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:09:29,074]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:09:40,687]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:09:49,400]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:09:50,559]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:09:52,730]\u001b[0m Trial 1136 finished with value: 1.644009865796887 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005340409630620999, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22730053634060454, 'dropout_rate_Layer_2': 0.12102474047268971, 'dropout_rate_Layer_3': 0.15599595338791927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0038648688730490923, 'l1_Layer_2': 0.03736554510341406, 'l1_Layer_3': 0.019989353795414843, 'n_units_Layer_1': 100, 'n_units_Layer_2': 165, 'n_units_Layer_3': 60}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.64 | sMAPE for Validation Set is: 26.21% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 7.22 | sMAPE for Test Set is: 17.49% | rMAE for Test Set is: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:10:00,762]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:10:06,241]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:10:11,241]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:10:14,561]\u001b[0m Trial 1159 finished with value: 6.798601684822676 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005592936218798635, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3361710982048981, 'dropout_rate_Layer_2': 0.30547064744029134, 'dropout_rate_Layer_3': 0.16998091649252453, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.020383159880907567, 'l1_Layer_2': 0.01686014418268262, 'l1_Layer_3': 0.0003834288934696463, 'n_units_Layer_1': 155, 'n_units_Layer_2': 210, 'n_units_Layer_3': 255}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.80 | sMAPE for Validation Set is: 71.05% | rMAE for Validation Set is: 2.04\n",
      "MAE for Test Set is: 8.44 | sMAPE for Test Set is: 20.51% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:10:16,032]\u001b[0m Trial 1158 finished with value: 1.745314887865008 and parameters: {'n_hidden': 3, 'learning_rate': 0.002837699544657701, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20950001704078056, 'dropout_rate_Layer_2': 0.10480052304934784, 'dropout_rate_Layer_3': 0.05385196009853308, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014148496230028795, 'l1_Layer_2': 0.008022849387185603, 'l1_Layer_3': 0.01812954706158306, 'n_units_Layer_1': 230, 'n_units_Layer_2': 230, 'n_units_Layer_3': 165}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.75 | sMAPE for Validation Set is: 27.70% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 7.56 | sMAPE for Test Set is: 18.07% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:10:19,036]\u001b[0m Trial 1137 finished with value: 1.4445667716730715 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006627746937255865, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009558669269027905, 'dropout_rate_Layer_2': 0.09639549248563609, 'dropout_rate_Layer_3': 0.16612876868771934, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004453224513848082, 'l1_Layer_2': 0.0123750391807156, 'l1_Layer_3': 0.02190534417546857, 'n_units_Layer_1': 150, 'n_units_Layer_2': 165, 'n_units_Layer_3': 60}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 21.97% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 7.23 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:10:26,421]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:10:28,008]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:10:33,954]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:10:37,643]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:10:37,800]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 27.72% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.00 | sMAPE for Test Set is: 19.16% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:10:41,953]\u001b[0m Trial 1163 finished with value: 1.8661067522158756 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026470272145780013, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21876030990450757, 'dropout_rate_Layer_2': 0.10023932224666121, 'dropout_rate_Layer_3': 0.04323997279157862, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013291746391784162, 'l1_Layer_2': 0.005342578378191943, 'l1_Layer_3': 0.03799655105111486, 'n_units_Layer_1': 230, 'n_units_Layer_2': 235, 'n_units_Layer_3': 180}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:10:47,380]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:10:48,317]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:10:54,551]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:10:57,299]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:11:00,709]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:11:05,845]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:11:07,873]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:11:15,990]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:11:20,394]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:11:27,714]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:11:30,302]\u001b[0m Trial 1176 finished with value: 2.123868343929727 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019906887841182968, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20474932644038932, 'dropout_rate_Layer_2': 0.09174535438711975, 'dropout_rate_Layer_3': 0.050928185966221895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011675292567244057, 'l1_Layer_2': 0.006060218049542248, 'l1_Layer_3': 0.022596851109393554, 'n_units_Layer_1': 150, 'n_units_Layer_2': 230, 'n_units_Layer_3': 175}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 33.00% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.57 | sMAPE for Test Set is: 18.25% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:11:35,798]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:11:50,202]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:11:54,263]\u001b[0m Trial 1182 finished with value: 3.6012009560031077 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006698329041542027, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31712347700209303, 'dropout_rate_Layer_2': 0.38068003056513283, 'dropout_rate_Layer_3': 0.2329663309705159, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03276146459826855, 'l1_Layer_2': 0.012221886739109483, 'l1_Layer_3': 0.0018860050439691144, 'n_units_Layer_1': 195, 'n_units_Layer_2': 160, 'n_units_Layer_3': 235}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 53.61% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 8.72 | sMAPE for Test Set is: 21.71% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:11:55,105]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:12:01,381]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:12:02,245]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:12:04,812]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:12:07,645]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:12:10,285]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:12:12,998]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:12:17,054]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:12:19,962]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:12:22,515]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:12:30,565]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:12:35,982]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:12:39,242]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:12:50,172]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:12:54,484]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:13:02,086]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:13:03,597]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:13:12,383]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:13:19,646]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:13:26,621]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:13:31,484]\u001b[0m Trial 1203 finished with value: 2.042293997915564 and parameters: {'n_hidden': 3, 'learning_rate': 0.003066784130924217, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20153504258936134, 'dropout_rate_Layer_2': 0.09337122831084627, 'dropout_rate_Layer_3': 0.01957421461574899, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015216067580811439, 'l1_Layer_2': 0.008457909540873967, 'l1_Layer_3': 0.019091608493471263, 'n_units_Layer_1': 230, 'n_units_Layer_2': 240, 'n_units_Layer_3': 165}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 32.36% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.61 | sMAPE for Test Set is: 18.15% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:13:32,343]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:13:44,211]\u001b[0m Trial 1183 finished with value: 1.4325182156902614 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006746480905733377, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006253899153534224, 'dropout_rate_Layer_2': 0.0887160926521057, 'dropout_rate_Layer_3': 0.15775542195580755, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015513534284743846, 'l1_Layer_2': 0.026342331598549557, 'l1_Layer_3': 0.025787764552152904, 'n_units_Layer_1': 100, 'n_units_Layer_2': 160, 'n_units_Layer_3': 55}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 21.17% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 7.33 | sMAPE for Test Set is: 17.95% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:14:02,754]\u001b[0m Trial 1207 finished with value: 3.445755083381078 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008207896179708451, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34268406484412484, 'dropout_rate_Layer_2': 0.34140432196228454, 'dropout_rate_Layer_3': 0.2627785827436241, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0062714453486963345, 'l1_Layer_2': 0.009888304663416442, 'l1_Layer_3': 0.007516034516470187, 'n_units_Layer_1': 170, 'n_units_Layer_2': 225, 'n_units_Layer_3': 190}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.45 | sMAPE for Validation Set is: 60.41% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 7.74 | sMAPE for Test Set is: 21.18% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:14:07,597]\u001b[0m Trial 1208 finished with value: 4.103530345599659 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008446099871939434, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2801730662270699, 'dropout_rate_Layer_2': 0.17954875688411634, 'dropout_rate_Layer_3': 0.07093399991752683, 'dropout_rate_Layer_4': 0.025621747579527607, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.883925127483423e-05, 'l1_Layer_2': 0.0049950882880201615, 'l1_Layer_3': 0.020153966921507598, 'l1_Layer_4': 0.00011122061019946934, 'n_units_Layer_1': 150, 'n_units_Layer_2': 95, 'n_units_Layer_3': 285, 'n_units_Layer_4': 115}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.10 | sMAPE for Validation Set is: 64.71% | rMAE for Validation Set is: 1.23\n",
      "MAE for Test Set is: 8.04 | sMAPE for Test Set is: 20.17% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:14:25,966]\u001b[0m Trial 1210 finished with value: 1.8914485802856327 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030843425460127896, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21087200202439585, 'dropout_rate_Layer_2': 0.08643246757728909, 'dropout_rate_Layer_3': 0.021275951835726642, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013059330789799044, 'l1_Layer_2': 0.010341768428653501, 'l1_Layer_3': 0.015282197086709139, 'n_units_Layer_1': 240, 'n_units_Layer_2': 245, 'n_units_Layer_3': 160}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 28.56% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.19 | sMAPE for Test Set is: 20.22% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:14:34,273]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:14:34,783]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 21.69% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 7.50 | sMAPE for Test Set is: 18.02% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:14:38,754]\u001b[0m Trial 1198 finished with value: 1.505878862634564 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005011709754845443, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006065002720560455, 'dropout_rate_Layer_2': 0.11874254555180336, 'dropout_rate_Layer_3': 0.3612076607382896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002904581191642239, 'l1_Layer_2': 0.024289114617911497, 'l1_Layer_3': 0.02140648167061509, 'n_units_Layer_1': 150, 'n_units_Layer_2': 130, 'n_units_Layer_3': 65}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:14:44,794]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:14:49,874]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:14:51,036]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:15:00,626]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:15:04,589]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:15:05,151]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:15:22,194]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:15:25,075]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:15:43,013]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:15:47,628]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:16:12,366]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:16:22,441]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:16:31,319]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:16:59,780]\u001b[0m Trial 1218 finished with value: 1.510505415462684 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005524461713653147, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0068456248129731626, 'dropout_rate_Layer_2': 0.09233154748311338, 'dropout_rate_Layer_3': 0.16719545769325816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003981780544792329, 'l1_Layer_2': 0.018465666036711115, 'l1_Layer_3': 0.02797833364146002, 'n_units_Layer_1': 95, 'n_units_Layer_2': 165, 'n_units_Layer_3': 55}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 21.84% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 7.46 | sMAPE for Test Set is: 18.62% | rMAE for Test Set is: 0.47\n",
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 19.51% | rMAE for Validation Set is: 0.42\n",
      "MAE for Test Set is: 7.28 | sMAPE for Test Set is: 17.45% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:17:02,364]\u001b[0m Trial 1222 finished with value: 1.412506030200805 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007209248810996214, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00786099906922817, 'dropout_rate_Layer_2': 0.12260979828331753, 'dropout_rate_Layer_3': 0.3428015610616253, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003402938839825251, 'l1_Layer_2': 0.022616256897837774, 'l1_Layer_3': 0.023011349747577306, 'n_units_Layer_1': 95, 'n_units_Layer_2': 130, 'n_units_Layer_3': 55}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:17:06,432]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:17:13,940]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:17:18,466]\u001b[0m Trial 1221 finished with value: 1.489210912951077 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006298805701873366, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007462241808099452, 'dropout_rate_Layer_2': 0.12966165018273412, 'dropout_rate_Layer_3': 0.3793161558775646, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004135818160051841, 'l1_Layer_2': 0.023108121067131743, 'l1_Layer_3': 0.02912689100736355, 'n_units_Layer_1': 95, 'n_units_Layer_2': 275, 'n_units_Layer_3': 55}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:17:18,536]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 21.39% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 7.52 | sMAPE for Test Set is: 18.67% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:17:26,982]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:17:32,213]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:17:37,277]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:17:37,672]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:17:37,854]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:17:48,536]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:17:49,936]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:17:51,015]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:18:01,613]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:18:03,659]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:18:08,199]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:18:14,083]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:18:18,911]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:18:22,746]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:18:24,883]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:18:29,374]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:18:33,107]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:18:40,901]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:18:56,916]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:19:00,397]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:19:05,779]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:19:10,986]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:19:12,103]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:19:16,884]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:19:17,436]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:19:19,749]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:19:27,100]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:19:31,832]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:19:34,860]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:19:38,021]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:19:41,155]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:19:41,425]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:19:48,814]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:19:49,390]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:19:49,478]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:19:57,262]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:20:02,301]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:20:07,172]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:20:08,087]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:20:10,158]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:20:17,132]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:20:18,417]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:20:18,907]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:20:24,535]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:20:28,959]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:20:33,665]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:20:38,149]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:20:41,067]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:20:45,283]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:20:46,018]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:20:54,209]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:20:58,982]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:21:00,317]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:21:06,533]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:21:11,717]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:21:18,840]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:21:23,076]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:21:27,433]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:21:29,472]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:21:34,213]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:21:40,614]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:21:44,220]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:21:46,457]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:21:49,905]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:21:57,888]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:21:58,269]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:22:04,137]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:22:08,421]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:22:12,850]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:22:13,379]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:22:19,428]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:22:26,432]\u001b[0m Trial 1279 finished with value: 1.5126758605214103 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007238667633039323, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01513499947440593, 'dropout_rate_Layer_2': 0.10953363659146616, 'dropout_rate_Layer_3': 0.17019603548762235, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004763312524119939, 'l1_Layer_2': 0.01912000341128396, 'l1_Layer_3': 0.014079444502742173, 'n_units_Layer_1': 110, 'n_units_Layer_2': 170, 'n_units_Layer_3': 80}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 23.41% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 7.11 | sMAPE for Test Set is: 17.08% | rMAE for Test Set is: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:22:36,887]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:22:41,400]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:22:46,989]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:22:49,436]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:22:57,827]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:23:01,207]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:23:03,639]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:23:13,599]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:23:22,638]\u001b[0m Trial 1312 finished with value: 2.465216323164955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026646710651020357, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2325972416150354, 'dropout_rate_Layer_2': 0.08065350682388066, 'dropout_rate_Layer_3': 0.028010323387672183, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0048724535982048855, 'l1_Layer_2': 0.008882375704832392, 'l1_Layer_3': 0.025691156804205542, 'n_units_Layer_1': 240, 'n_units_Layer_2': 155, 'n_units_Layer_3': 165}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.47 | sMAPE for Validation Set is: 37.61% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 7.77 | sMAPE for Test Set is: 18.86% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:23:23,022]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:23:30,324]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:23:35,793]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:23:38,166]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:23:41,829]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:23:46,251]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:23:46,632]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:23:55,757]\u001b[0m Trial 1310 finished with value: 1.7986460095962222 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008578975860372637, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2314394334268805, 'dropout_rate_Layer_2': 0.15673420856111767, 'dropout_rate_Layer_3': 0.03904209606793384, 'dropout_rate_Layer_4': 0.11733671472548847, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.082485752118404e-05, 'l1_Layer_2': 0.0021776188430423344, 'l1_Layer_3': 0.01026615120490928, 'l1_Layer_4': 0.00020972567443556777, 'n_units_Layer_1': 145, 'n_units_Layer_2': 100, 'n_units_Layer_3': 115, 'n_units_Layer_4': 265}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.80 | sMAPE for Validation Set is: 32.61% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.02 | sMAPE for Test Set is: 16.93% | rMAE for Test Set is: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:23:59,883]\u001b[0m Trial 1305 finished with value: 1.5462731293007084 and parameters: {'n_hidden': 3, 'learning_rate': 0.000905297656889812, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25378719863279725, 'dropout_rate_Layer_2': 0.08711421769514752, 'dropout_rate_Layer_3': 0.15180071023445024, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001457704178609403, 'l1_Layer_2': 0.03752563830552762, 'l1_Layer_3': 0.014215241250863967, 'n_units_Layer_1': 100, 'n_units_Layer_2': 170, 'n_units_Layer_3': 65}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 23.28% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 7.35 | sMAPE for Test Set is: 17.69% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:24:00,572]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:24:02,639]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:24:10,784]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:24:14,266]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:24:15,577]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:24:17,279]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:24:25,380]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:24:30,627]\u001b[0m Trial 1329 finished with value: 7.370553193784275 and parameters: {'n_hidden': 3, 'learning_rate': 0.01870283579268565, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29574463184952254, 'dropout_rate_Layer_2': 0.3001354202469312, 'dropout_rate_Layer_3': 0.1882016254405765, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0374141202233628, 'l1_Layer_2': 0.004007306757977991, 'l1_Layer_3': 0.00010179108249976562, 'n_units_Layer_1': 145, 'n_units_Layer_2': 155, 'n_units_Layer_3': 275}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.37 | sMAPE for Validation Set is: 75.89% | rMAE for Validation Set is: 2.22\n",
      "MAE for Test Set is: 15.39 | sMAPE for Test Set is: 46.49% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:24:31,156]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:24:37,850]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:24:44,477]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:24:56,567]\u001b[0m Trial 1334 finished with value: 1.9255071824373973 and parameters: {'n_hidden': 3, 'learning_rate': 0.003017842093851861, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2053593170367601, 'dropout_rate_Layer_2': 0.12269093002603845, 'dropout_rate_Layer_3': 0.049887814633125485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002697731433182782, 'l1_Layer_2': 0.006067815897285182, 'l1_Layer_3': 0.02752240925325461, 'n_units_Layer_1': 225, 'n_units_Layer_2': 250, 'n_units_Layer_3': 180}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 30.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.23 | sMAPE for Test Set is: 17.37% | rMAE for Test Set is: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:25:00,421]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:25:03,543]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:25:07,961]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:25:09,199]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:25:11,075]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:25:17,441]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:25:19,257]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:25:23,580]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:25:36,246]\u001b[0m Trial 1342 finished with value: 5.257879478924785 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006463353121047269, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27021758647188227, 'dropout_rate_Layer_2': 0.3903211543230932, 'dropout_rate_Layer_3': 0.20254678972418189, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.025026438184513243, 'l1_Layer_2': 0.031426347639738644, 'l1_Layer_3': 0.0016778726055303235, 'n_units_Layer_1': 175, 'n_units_Layer_2': 290, 'n_units_Layer_3': 205}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 62.49% | rMAE for Validation Set is: 1.58\n",
      "MAE for Test Set is: 32.87 | sMAPE for Test Set is: 118.96% | rMAE for Test Set is: 2.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:25:36,451]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:25:37,551]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 61.30% | rMAE for Validation Set is: 1.54\n",
      "MAE for Test Set is: 32.51 | sMAPE for Test Set is: 116.83% | rMAE for Test Set is: 2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:25:42,898]\u001b[0m Trial 1344 finished with value: 5.128464273489949 and parameters: {'n_hidden': 3, 'learning_rate': 0.000667430837291256, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22446784347174392, 'dropout_rate_Layer_2': 0.39109711721357054, 'dropout_rate_Layer_3': 0.25995016302607127, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02351272396405591, 'l1_Layer_2': 0.006878178432257399, 'l1_Layer_3': 0.005852929143843277, 'n_units_Layer_1': 175, 'n_units_Layer_2': 170, 'n_units_Layer_3': 205}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:25:46,351]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:25:52,588]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:25:53,044]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:26:00,907]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:26:05,009]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:26:11,277]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:26:12,639]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:26:19,936]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:26:24,104]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:26:24,325]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:26:32,106]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:26:32,391]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:26:39,381]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:26:39,835]\u001b[0m Trial 1345 finished with value: 1.550797898941496 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009664547436902022, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23128786181074468, 'dropout_rate_Layer_2': 0.1706915953447815, 'dropout_rate_Layer_3': 0.06087604446675212, 'dropout_rate_Layer_4': 0.09866665419171078, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.8216129769137153e-05, 'l1_Layer_2': 0.004914906951044947, 'l1_Layer_3': 0.05730649316407299, 'l1_Layer_4': 0.0011794254023267641, 'n_units_Layer_1': 160, 'n_units_Layer_2': 105, 'n_units_Layer_3': 85, 'n_units_Layer_4': 300}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 23.20% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 7.51 | sMAPE for Test Set is: 18.04% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:26:40,688]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:26:49,482]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:26:54,386]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:26:58,880]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:27:02,915]\u001b[0m Trial 1352 finished with value: 1.424854240077881 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008190201923740909, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2592655227946035, 'dropout_rate_Layer_2': 0.3200730572652703, 'dropout_rate_Layer_3': 0.18164105739008732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010416284881695888, 'l1_Layer_2': 0.005528395074216282, 'l1_Layer_3': 0.0011413757306713889, 'n_units_Layer_1': 130, 'n_units_Layer_2': 300, 'n_units_Layer_3': 220}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 21.18% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 7.14 | sMAPE for Test Set is: 17.05% | rMAE for Test Set is: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:27:07,071]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:27:10,368]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:27:14,677]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:27:17,743]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:27:18,257]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:27:25,196]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:27:25,228]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:27:29,721]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:27:33,522]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:27:37,623]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:27:39,657]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:27:44,151]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:27:47,438]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:27:50,564]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:27:53,385]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:27:54,349]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:28:01,008]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:28:12,966]\u001b[0m Trial 1374 finished with value: 1.4641791440238663 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012642355431969285, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24206917985302567, 'dropout_rate_Layer_2': 0.319857093168326, 'dropout_rate_Layer_3': 0.1322611544963384, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004778958637191692, 'l1_Layer_2': 0.005452155383344998, 'l1_Layer_3': 0.0006477515697601507, 'n_units_Layer_1': 160, 'n_units_Layer_2': 295, 'n_units_Layer_3': 230}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 25.28% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 7.23 | sMAPE for Test Set is: 17.26% | rMAE for Test Set is: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:28:17,610]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:28:21,106]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:28:28,220]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:28:31,504]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:28:46,110]\u001b[0m Trial 1383 finished with value: 1.7612299223115517 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007405760860613578, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03057641940473296, 'dropout_rate_Layer_2': 0.10690029931104143, 'dropout_rate_Layer_3': 0.15992312165490946, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0029879566775865844, 'l1_Layer_2': 0.025675799611641573, 'l1_Layer_3': 0.021979057794564258, 'n_units_Layer_1': 180, 'n_units_Layer_2': 160, 'n_units_Layer_3': 200}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.76 | sMAPE for Validation Set is: 27.46% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 7.40 | sMAPE for Test Set is: 18.53% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:28:51,039]\u001b[0m Trial 1389 finished with value: 1.9415540439980719 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029555252501157264, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17589780686579629, 'dropout_rate_Layer_2': 0.1285232773267352, 'dropout_rate_Layer_3': 0.01958791110186494, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002353856349357741, 'l1_Layer_2': 0.008532421794872026, 'l1_Layer_3': 0.023976012242881373, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 165}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 30.65% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.33 | sMAPE for Test Set is: 17.71% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:28:57,990]\u001b[0m Trial 1381 finished with value: 1.4915068847959312 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008115546045475564, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23547020271298494, 'dropout_rate_Layer_2': 0.19089880395559872, 'dropout_rate_Layer_3': 0.05715631027240697, 'dropout_rate_Layer_4': 0.10308350027084318, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.657940393969418e-05, 'l1_Layer_2': 0.00127474870921959, 'l1_Layer_3': 0.08461776071061848, 'l1_Layer_4': 0.0009026862461308121, 'n_units_Layer_1': 150, 'n_units_Layer_2': 125, 'n_units_Layer_3': 80, 'n_units_Layer_4': 290}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 22.03% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 7.28 | sMAPE for Test Set is: 17.56% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:29:03,390]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:29:07,070]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:29:08,126]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:29:09,795]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:29:16,718]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:29:17,874]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:29:22,985]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:29:29,801]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:29:38,219]\u001b[0m Trial 1388 finished with value: 1.575715605155007 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008216834492733954, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22422605769815845, 'dropout_rate_Layer_2': 0.15730719636680315, 'dropout_rate_Layer_3': 0.07033405433944151, 'dropout_rate_Layer_4': 0.17234186853216027, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.035530911386433e-05, 'l1_Layer_2': 0.005116670180184172, 'l1_Layer_3': 0.03233794409673061, 'l1_Layer_4': 0.0003967987086708535, 'n_units_Layer_1': 160, 'n_units_Layer_2': 105, 'n_units_Layer_3': 95, 'n_units_Layer_4': 300}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.58 | sMAPE for Validation Set is: 23.70% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 7.32 | sMAPE for Test Set is: 17.61% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:29:58,263]\u001b[0m Trial 1395 finished with value: 1.4707606655689254 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009312074680490483, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2464659607146752, 'dropout_rate_Layer_2': 0.2765547418607831, 'dropout_rate_Layer_3': 0.12813623201047983, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0047155945547912945, 'l1_Layer_2': 0.011432019016525801, 'l1_Layer_3': 0.0010399384597756225, 'n_units_Layer_1': 120, 'n_units_Layer_2': 270, 'n_units_Layer_3': 230}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 22.52% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 7.20 | sMAPE for Test Set is: 17.17% | rMAE for Test Set is: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:30:03,732]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:30:07,422]\u001b[0m Trial 1400 finished with value: 1.434866747687897 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008724003616593151, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2063123626989769, 'dropout_rate_Layer_2': 0.3724811039087285, 'dropout_rate_Layer_3': 0.18252350706387468, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006054787714050996, 'l1_Layer_2': 0.011205694131110952, 'l1_Layer_3': 0.002344462560457827, 'n_units_Layer_1': 120, 'n_units_Layer_2': 295, 'n_units_Layer_3': 225}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 21.14% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 7.32 | sMAPE for Test Set is: 17.51% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:30:16,724]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:30:20,260]\u001b[0m Trial 1401 finished with value: 1.471494816056934 and parameters: {'n_hidden': 3, 'learning_rate': 0.000888551837572383, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23804438879067807, 'dropout_rate_Layer_2': 0.34772098275413005, 'dropout_rate_Layer_3': 0.1343723606344036, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004639706299260578, 'l1_Layer_2': 0.005264508650285224, 'l1_Layer_3': 0.0004535050498582643, 'n_units_Layer_1': 115, 'n_units_Layer_2': 295, 'n_units_Layer_3': 230}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 23.76% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 7.16 | sMAPE for Test Set is: 17.13% | rMAE for Test Set is: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:30:23,030]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:30:28,212]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:30:28,313]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:30:34,656]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:30:38,280]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:30:43,469]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:30:48,475]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:30:54,993]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:31:01,967]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:31:06,200]\u001b[0m Trial 1408 finished with value: 1.5436881965719778 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007514384379790576, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22269767698443252, 'dropout_rate_Layer_2': 0.18103106107810432, 'dropout_rate_Layer_3': 0.10390657995085056, 'dropout_rate_Layer_4': 0.17259140205916743, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.9383396476273172e-05, 'l1_Layer_2': 0.008649928107429686, 'l1_Layer_3': 0.09627927943289206, 'l1_Layer_4': 0.0009075707003475898, 'n_units_Layer_1': 175, 'n_units_Layer_2': 120, 'n_units_Layer_3': 95, 'n_units_Layer_4': 295}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 21.58% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 7.55 | sMAPE for Test Set is: 18.12% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:31:10,707]\u001b[0m Trial 1403 finished with value: 1.5668160051851083 and parameters: {'n_hidden': 3, 'learning_rate': 0.000928292380437422, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24056695231031314, 'dropout_rate_Layer_2': 0.27101661164339935, 'dropout_rate_Layer_3': 0.10133850726686239, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0032925059068581747, 'l1_Layer_2': 0.011214708505350827, 'l1_Layer_3': 0.0004092697484712724, 'n_units_Layer_1': 120, 'n_units_Layer_2': 295, 'n_units_Layer_3': 230}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 27.79% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 7.15 | sMAPE for Test Set is: 17.10% | rMAE for Test Set is: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:31:21,307]\u001b[0m Trial 1413 finished with value: 1.6426199071261485 and parameters: {'n_hidden': 3, 'learning_rate': 0.001201233716994381, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21106434767761667, 'dropout_rate_Layer_2': 0.2577417311674623, 'dropout_rate_Layer_3': 0.12621167142073839, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0037818596840499654, 'l1_Layer_2': 0.002877650916866684, 'l1_Layer_3': 0.00030183884556530215, 'n_units_Layer_1': 95, 'n_units_Layer_2': 295, 'n_units_Layer_3': 225}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.64 | sMAPE for Validation Set is: 29.40% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 7.32 | sMAPE for Test Set is: 17.48% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:31:26,195]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:31:30,040]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:31:33,892]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:31:35,338]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:31:39,919]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:31:40,075]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:31:48,331]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:31:52,877]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:31:53,273]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:31:59,986]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:32:02,882]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:32:07,099]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:32:11,790]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:32:14,082]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:32:14,836]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:32:16,561]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:32:25,611]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:32:25,800]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:32:32,273]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:32:36,411]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:32:38,592]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:32:49,344]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:32:56,230]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:33:03,993]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:33:09,418]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:33:14,662]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:33:19,449]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:33:22,845]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:33:28,375]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:33:28,611]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:33:37,334]\u001b[0m Trial 1438 finished with value: 1.5623903944072837 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008266036156830803, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23606701263635135, 'dropout_rate_Layer_2': 0.19218993106289353, 'dropout_rate_Layer_3': 0.07909488911582906, 'dropout_rate_Layer_4': 0.17326340854556319, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.444583477556903e-05, 'l1_Layer_2': 0.0070116061635376314, 'l1_Layer_3': 0.07312442376808422, 'l1_Layer_4': 0.0007514793033060448, 'n_units_Layer_1': 180, 'n_units_Layer_2': 110, 'n_units_Layer_3': 115, 'n_units_Layer_4': 290}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 22.73% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 7.56 | sMAPE for Test Set is: 18.31% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:33:37,850]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:33:45,283]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:33:51,963]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:33:54,231]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:33:58,410]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:34:05,425]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:34:10,725]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:34:10,896]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:34:17,057]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:34:20,209]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:34:20,762]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:34:26,935]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:34:35,113]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:34:48,089]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:34:55,631]\u001b[0m Trial 1453 finished with value: 1.6057298030363898 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007890155668998985, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02052732951115209, 'dropout_rate_Layer_2': 0.2064588291742587, 'dropout_rate_Layer_3': 0.14545171342939653, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00464310535913671, 'l1_Layer_2': 0.00019574206633702455, 'l1_Layer_3': 0.01641833541344442, 'n_units_Layer_1': 150, 'n_units_Layer_2': 175, 'n_units_Layer_3': 85}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.61 | sMAPE for Validation Set is: 25.79% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 7.74 | sMAPE for Test Set is: 19.77% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:35:00,024]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:35:00,708]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:35:07,388]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:35:10,579]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:35:11,805]\u001b[0m Trial 1458 finished with value: 1.4940296537135083 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007068387794144192, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23996663786474992, 'dropout_rate_Layer_2': 0.2096746486676636, 'dropout_rate_Layer_3': 0.09968588490782679, 'dropout_rate_Layer_4': 0.10136693621192765, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.769134570370577e-05, 'l1_Layer_2': 0.005344044676229862, 'l1_Layer_3': 0.048121372826058585, 'l1_Layer_4': 0.0004335116018986375, 'n_units_Layer_1': 175, 'n_units_Layer_2': 100, 'n_units_Layer_3': 135, 'n_units_Layer_4': 295}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 21.56% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 7.75 | sMAPE for Test Set is: 18.62% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:35:18,389]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:35:21,034]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:35:27,220]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:35:32,033]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:35:38,467]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:35:42,694]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:35:44,912]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:35:50,357]\u001b[0m Trial 1462 finished with value: 1.6389538762330345 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011336745514855225, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2131041186512046, 'dropout_rate_Layer_2': 0.2557880972868488, 'dropout_rate_Layer_3': 0.12880449060126728, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003340410035751112, 'l1_Layer_2': 0.003040369797745366, 'l1_Layer_3': 0.0002167380837809847, 'n_units_Layer_1': 100, 'n_units_Layer_2': 295, 'n_units_Layer_3': 235}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.64 | sMAPE for Validation Set is: 30.07% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 16.69% | rMAE for Test Set is: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:35:50,750]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:35:58,539]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:36:03,178]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:36:03,276]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:36:12,156]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:36:12,661]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:36:21,092]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:36:27,084]\u001b[0m Trial 1470 finished with value: 1.523629779396518 and parameters: {'n_hidden': 3, 'learning_rate': 0.001158312038835514, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21436656898413725, 'dropout_rate_Layer_2': 0.25171274436213803, 'dropout_rate_Layer_3': 0.1310046253693885, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0034730372567363227, 'l1_Layer_2': 0.002977747361922855, 'l1_Layer_3': 0.00043611909539630913, 'n_units_Layer_1': 100, 'n_units_Layer_2': 290, 'n_units_Layer_3': 235}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 28.83% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 7.08 | sMAPE for Test Set is: 16.96% | rMAE for Test Set is: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:36:32,061]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:36:37,512]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:36:40,917]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:36:43,938]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:36:47,254]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:36:50,520]\u001b[0m Trial 1475 finished with value: 1.439981004201713 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011744926068767466, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2047407346963027, 'dropout_rate_Layer_2': 0.27598504065853247, 'dropout_rate_Layer_3': 0.13032571165637996, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0034919717033946164, 'l1_Layer_2': 0.0036528317674154086, 'l1_Layer_3': 0.00032298249630828687, 'n_units_Layer_1': 100, 'n_units_Layer_2': 295, 'n_units_Layer_3': 235}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 20.52% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 6.92 | sMAPE for Test Set is: 16.59% | rMAE for Test Set is: 0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 07:36:50,943]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:36:51,190]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:37:01,552]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:37:06,252]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:37:10,703]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:37:14,974]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:37:20,954]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:37:26,933]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:37:30,654]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:37:33,941]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:37:43,120]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 07:37:45,148]\u001b[0m Trial 1497 finished with value: 1.5639087168513317 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014750760072732639, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22572550595684301, 'dropout_rate_Layer_2': 0.2743286151594767, 'dropout_rate_Layer_3': 0.10848133024521482, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021353983814095486, 'l1_Layer_2': 0.003707089264255346, 'l1_Layer_3': 0.00024046723729891228, 'n_units_Layer_1': 90, 'n_units_Layer_2': 300, 'n_units_Layer_3': 235}. Best is trial 388 with value: 1.3954766486132708.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 23.56% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 7.04 | sMAPE for Test Set is: 16.81% | rMAE for Test Set is: 0.44\n",
      "for 2021-01-01, MAE is:3.73 & sMAPE is:15.42% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.73 & 15.42% & 0.33\n",
      "for 2021-01-02, MAE is:8.10 & sMAPE is:24.65% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 20.03% & 0.40\n",
      "for 2021-01-03, MAE is:2.88 & sMAPE is:10.58% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 16.88% & 0.32\n",
      "for 2021-01-04, MAE is:16.88 & sMAPE is:42.82% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 23.37% & 0.38\n",
      "for 2021-01-05, MAE is:14.78 & sMAPE is:32.32% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :9.27 & 25.16% & 0.40\n",
      "for 2021-01-06, MAE is:7.31 & sMAPE is:17.85% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.95 & 23.94% & 0.39\n",
      "for 2021-01-07, MAE is:27.47 & sMAPE is:46.36% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :11.59 & 27.14% & 0.42\n",
      "for 2021-01-08, MAE is:22.30 & sMAPE is:29.43% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :12.93 & 27.43% & 0.42\n",
      "for 2021-01-09, MAE is:22.10 & sMAPE is:42.25% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :13.95 & 29.08% & 0.53\n",
      "for 2021-01-10, MAE is:5.34 & sMAPE is:13.34% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :13.09 & 27.50% & 0.52\n",
      "for 2021-01-11, MAE is:3.86 & sMAPE is:9.52% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :12.25 & 25.87% & 0.50\n",
      "for 2021-01-12, MAE is:4.39 & sMAPE is:13.15% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :11.59 & 24.81% & 0.48\n",
      "for 2021-01-13, MAE is:5.61 & sMAPE is:13.73% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 23.96% & 0.54\n",
      "for 2021-01-14, MAE is:26.18 & sMAPE is:39.38% & rMAE is:4.44 ||| daily mean of MAE & sMAPE & rMAE till now are :12.21 & 25.06% & 0.82\n",
      "for 2021-01-15, MAE is:21.95 & sMAPE is:40.57% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :12.86 & 26.09% & 0.81\n",
      "for 2021-01-16, MAE is:1.84 & sMAPE is:4.54% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :12.17 & 24.74% & 0.78\n",
      "for 2021-01-17, MAE is:2.24 & sMAPE is:5.30% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :11.58 & 23.60% & 0.76\n",
      "for 2021-01-18, MAE is:4.70 & sMAPE is:9.50% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :11.20 & 22.82% & 0.75\n",
      "for 2021-01-19, MAE is:4.33 & sMAPE is:10.30% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :10.84 & 22.16% & 0.74\n",
      "for 2021-01-20, MAE is:3.50 & sMAPE is:10.44% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :10.47 & 21.57% & 0.73\n",
      "for 2021-01-21, MAE is:8.04 & sMAPE is:26.50% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 21.81% & 0.70\n",
      "for 2021-01-22, MAE is:1.86 & sMAPE is:7.48% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :9.97 & 21.16% & 0.68\n",
      "for 2021-01-23, MAE is:7.22 & sMAPE is:23.66% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :9.85 & 21.26% & 0.69\n",
      "for 2021-01-24, MAE is:11.25 & sMAPE is:26.53% & rMAE is:2.42 ||| daily mean of MAE & sMAPE & rMAE till now are :9.91 & 21.48% & 0.76\n",
      "for 2021-01-25, MAE is:11.72 & sMAPE is:22.44% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :9.98 & 21.52% & 0.79\n",
      "for 2021-01-26, MAE is:9.52 & sMAPE is:20.16% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :9.96 & 21.47% & 0.80\n",
      "for 2021-01-27, MAE is:8.03 & sMAPE is:14.89% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :9.89 & 21.23% & 0.79\n",
      "for 2021-01-28, MAE is:9.10 & sMAPE is:16.82% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :9.86 & 21.07% & 0.77\n",
      "for 2021-01-29, MAE is:5.61 & sMAPE is:10.93% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :9.72 & 20.72% & 0.75\n",
      "for 2021-01-30, MAE is:3.22 & sMAPE is:6.83% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :9.50 & 20.26% & 0.73\n",
      "for 2021-01-31, MAE is:4.28 & sMAPE is:8.50% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :9.33 & 19.88% & 0.75\n",
      "for 2021-02-01, MAE is:36.65 & sMAPE is:41.65% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :10.19 & 20.56% & 0.76\n",
      "for 2021-02-02, MAE is:20.10 & sMAPE is:28.16% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :10.49 & 20.79% & 0.77\n",
      "for 2021-02-03, MAE is:9.10 & sMAPE is:19.09% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 20.74% & 0.77\n",
      "for 2021-02-04, MAE is:2.69 & sMAPE is:6.58% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :10.22 & 20.33% & 0.76\n",
      "for 2021-02-05, MAE is:4.44 & sMAPE is:10.04% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :10.06 & 20.05% & 0.76\n",
      "for 2021-02-06, MAE is:2.71 & sMAPE is:5.95% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :9.86 & 19.67% & 0.76\n",
      "for 2021-02-07, MAE is:1.11 & sMAPE is:2.67% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :9.63 & 19.22% & 0.74\n",
      "for 2021-02-08, MAE is:6.99 & sMAPE is:13.45% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.57 & 19.07% & 0.73\n",
      "for 2021-02-09, MAE is:12.30 & sMAPE is:18.82% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :9.63 & 19.07% & 0.74\n",
      "for 2021-02-10, MAE is:6.97 & sMAPE is:11.59% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :9.57 & 18.88% & 0.74\n",
      "for 2021-02-11, MAE is:3.39 & sMAPE is:6.92% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 18.60% & 0.73\n",
      "for 2021-02-12, MAE is:5.20 & sMAPE is:12.15% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :9.32 & 18.45% & 0.73\n",
      "for 2021-02-13, MAE is:2.57 & sMAPE is:6.67% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :9.17 & 18.18% & 0.72\n",
      "for 2021-02-14, MAE is:6.56 & sMAPE is:16.48% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :9.11 & 18.14% & 0.76\n",
      "for 2021-02-15, MAE is:3.06 & sMAPE is:6.82% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.98 & 17.90% & 0.75\n",
      "for 2021-02-16, MAE is:3.44 & sMAPE is:7.19% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :8.86 & 17.67% & 0.74\n",
      "for 2021-02-17, MAE is:3.72 & sMAPE is:8.84% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.76 & 17.49% & 0.73\n",
      "for 2021-02-18, MAE is:1.94 & sMAPE is:5.18% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :8.62 & 17.23% & 0.72\n",
      "for 2021-02-19, MAE is:4.90 & sMAPE is:11.98% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :8.54 & 17.13% & 0.73\n",
      "for 2021-02-20, MAE is:2.54 & sMAPE is:6.94% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :8.42 & 16.93% & 0.74\n",
      "for 2021-02-21, MAE is:3.56 & sMAPE is:9.89% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 16.79% & 0.73\n",
      "for 2021-02-22, MAE is:4.26 & sMAPE is:10.52% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 16.68% & 0.74\n",
      "for 2021-02-23, MAE is:3.10 & sMAPE is:8.01% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 16.51% & 0.73\n",
      "for 2021-02-24, MAE is:5.35 & sMAPE is:16.63% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 16.52% & 0.73\n",
      "for 2021-02-25, MAE is:1.16 & sMAPE is:4.25% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 16.30% & 0.72\n",
      "for 2021-02-26, MAE is:2.47 & sMAPE is:9.33% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.89 & 16.18% & 0.71\n",
      "for 2021-02-27, MAE is:1.38 & sMAPE is:5.60% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 15.99% & 0.70\n",
      "for 2021-02-28, MAE is:1.02 & sMAPE is:4.14% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 15.79% & 0.69\n",
      "for 2021-03-01, MAE is:1.27 & sMAPE is:5.48% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 15.62% & 0.68\n",
      "for 2021-03-02, MAE is:1.50 & sMAPE is:5.98% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 15.46% & 0.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-03-03, MAE is:0.92 & sMAPE is:3.70% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 15.27% & 0.66\n",
      "for 2021-03-04, MAE is:1.18 & sMAPE is:4.56% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 15.10% & 0.66\n",
      "for 2021-03-05, MAE is:1.91 & sMAPE is:7.06% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 14.98% & 0.66\n",
      "for 2021-03-06, MAE is:2.23 & sMAPE is:9.77% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.90% & 0.66\n",
      "for 2021-03-07, MAE is:2.94 & sMAPE is:12.96% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 14.87% & 0.67\n",
      "for 2021-03-08, MAE is:2.08 & sMAPE is:7.56% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 14.76% & 0.66\n",
      "for 2021-03-09, MAE is:2.28 & sMAPE is:8.41% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 14.66% & 0.67\n",
      "for 2021-03-10, MAE is:1.91 & sMAPE is:7.19% & rMAE is:2.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 14.56% & 0.69\n",
      "for 2021-03-11, MAE is:1.93 & sMAPE is:9.64% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 14.49% & 0.69\n",
      "for 2021-03-12, MAE is:5.22 & sMAPE is:21.46% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 14.58% & 0.70\n",
      "for 2021-03-13, MAE is:2.12 & sMAPE is:7.92% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 14.49% & 0.69\n",
      "for 2021-03-14, MAE is:3.48 & sMAPE is:12.45% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 14.46% & 0.69\n",
      "for 2021-03-15, MAE is:3.66 & sMAPE is:10.69% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 14.41% & 0.69\n",
      "for 2021-03-16, MAE is:2.58 & sMAPE is:8.77% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 14.34% & 0.70\n",
      "for 2021-03-17, MAE is:3.62 & sMAPE is:11.50% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 14.30% & 0.70\n",
      "for 2021-03-18, MAE is:3.93 & sMAPE is:12.59% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 14.28% & 0.69\n",
      "for 2021-03-19, MAE is:6.86 & sMAPE is:21.77% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 14.37% & 0.70\n",
      "for 2021-03-20, MAE is:2.31 & sMAPE is:10.37% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 14.32% & 0.69\n",
      "for 2021-03-21, MAE is:3.40 & sMAPE is:18.17% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 14.37% & 0.69\n",
      "for 2021-03-22, MAE is:1.13 & sMAPE is:4.93% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 14.26% & 0.68\n",
      "for 2021-03-23, MAE is:0.82 & sMAPE is:3.73% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 14.13% & 0.67\n",
      "for 2021-03-24, MAE is:1.44 & sMAPE is:6.91% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 14.04% & 0.67\n",
      "for 2021-03-25, MAE is:1.36 & sMAPE is:6.51% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 13.95% & 0.66\n",
      "for 2021-03-26, MAE is:1.71 & sMAPE is:7.92% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 13.88% & 0.65\n",
      "for 2021-03-27, MAE is:1.01 & sMAPE is:5.23% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 13.78% & 0.65\n",
      "for 2021-03-28, MAE is:2.00 & sMAPE is:10.48% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 13.74% & 0.65\n",
      "for 2021-03-29, MAE is:1.96 & sMAPE is:9.69% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 13.69% & 0.65\n",
      "for 2021-03-30, MAE is:2.16 & sMAPE is:12.93% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 13.69% & 0.65\n",
      "for 2021-03-31, MAE is:1.02 & sMAPE is:5.31% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 13.59% & 0.65\n",
      "for 2021-04-01, MAE is:0.56 & sMAPE is:3.05% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 13.48% & 0.65\n",
      "for 2021-04-02, MAE is:2.33 & sMAPE is:16.41% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 13.51% & 0.64\n",
      "for 2021-04-03, MAE is:1.77 & sMAPE is:10.03% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 13.47% & 0.65\n",
      "for 2021-04-04, MAE is:5.75 & sMAPE is:48.77% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 13.85% & 0.65\n",
      "for 2021-04-05, MAE is:3.70 & sMAPE is:36.07% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 14.08% & 0.65\n",
      "for 2021-04-06, MAE is:4.53 & sMAPE is:26.32% & rMAE is:2.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 14.21% & 0.67\n",
      "for 2021-04-07, MAE is:0.97 & sMAPE is:4.92% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 14.11% & 0.68\n",
      "for 2021-04-08, MAE is:7.98 & sMAPE is:26.69% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 14.24% & 0.68\n",
      "for 2021-04-09, MAE is:2.17 & sMAPE is:10.63% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 14.21% & 0.68\n",
      "for 2021-04-10, MAE is:1.28 & sMAPE is:6.62% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 14.13% & 0.68\n",
      "for 2021-04-11, MAE is:4.49 & sMAPE is:21.63% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 14.20% & 0.68\n",
      "for 2021-04-12, MAE is:1.48 & sMAPE is:6.27% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 14.13% & 0.67\n",
      "for 2021-04-13, MAE is:1.97 & sMAPE is:8.43% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 14.07% & 0.67\n",
      "for 2021-04-14, MAE is:1.09 & sMAPE is:4.70% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 13.98% & 0.66\n",
      "for 2021-04-15, MAE is:4.08 & sMAPE is:16.07% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 14.00% & 0.66\n",
      "for 2021-04-16, MAE is:3.72 & sMAPE is:13.08% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 13.99% & 0.66\n",
      "for 2021-04-17, MAE is:1.99 & sMAPE is:7.39% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 13.93% & 0.66\n",
      "for 2021-04-18, MAE is:0.95 & sMAPE is:3.82% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 13.84% & 0.66\n",
      "for 2021-04-19, MAE is:9.27 & sMAPE is:27.22% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 13.96% & 0.66\n",
      "for 2021-04-20, MAE is:2.41 & sMAPE is:9.07% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 13.91% & 0.66\n",
      "for 2021-04-21, MAE is:2.75 & sMAPE is:10.60% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 13.88% & 0.66\n",
      "for 2021-04-22, MAE is:2.47 & sMAPE is:10.43% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 13.85% & 0.66\n",
      "for 2021-04-23, MAE is:2.27 & sMAPE is:9.30% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 13.81% & 0.66\n",
      "for 2021-04-24, MAE is:1.65 & sMAPE is:7.17% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 13.76% & 0.66\n",
      "for 2021-04-25, MAE is:3.65 & sMAPE is:14.57% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 13.76% & 0.67\n",
      "for 2021-04-26, MAE is:26.76 & sMAPE is:60.80% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 14.17% & 0.68\n",
      "for 2021-04-27, MAE is:6.20 & sMAPE is:10.85% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 14.14% & 0.67\n",
      "for 2021-04-28, MAE is:8.80 & sMAPE is:14.77% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 14.14% & 0.67\n",
      "for 2021-04-29, MAE is:7.13 & sMAPE is:12.79% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 14.13% & 0.66\n",
      "for 2021-04-30, MAE is:2.32 & sMAPE is:5.73% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 14.06% & 0.66\n",
      "for 2021-05-01, MAE is:8.10 & sMAPE is:19.01% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 14.10% & 0.66\n",
      "for 2021-05-02, MAE is:5.52 & sMAPE is:12.58% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 14.09% & 0.66\n",
      "for 2021-05-03, MAE is:10.69 & sMAPE is:17.72% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 14.12% & 0.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-05-04, MAE is:17.95 & sMAPE is:37.80% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 14.31% & 0.67\n",
      "for 2021-05-05, MAE is:9.17 & sMAPE is:22.68% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 14.38% & 0.67\n",
      "for 2021-05-06, MAE is:16.51 & sMAPE is:29.35% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 14.50% & 0.67\n",
      "for 2021-05-07, MAE is:8.95 & sMAPE is:13.36% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 14.49% & 0.67\n",
      "for 2021-05-08, MAE is:8.22 & sMAPE is:17.45% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 14.51% & 0.67\n",
      "for 2021-05-09, MAE is:16.73 & sMAPE is:44.07% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 14.74% & 0.68\n",
      "for 2021-05-10, MAE is:10.52 & sMAPE is:25.79% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 14.83% & 0.68\n",
      "for 2021-05-11, MAE is:12.42 & sMAPE is:33.90% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 14.97% & 0.68\n",
      "for 2021-05-12, MAE is:10.05 & sMAPE is:26.89% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 15.06% & 0.68\n",
      "for 2021-05-13, MAE is:4.73 & sMAPE is:16.79% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 15.08% & 0.68\n",
      "for 2021-05-14, MAE is:3.43 & sMAPE is:12.60% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 15.06% & 0.68\n",
      "for 2021-05-15, MAE is:5.03 & sMAPE is:24.17% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 15.12% & 0.67\n",
      "for 2021-05-16, MAE is:4.95 & sMAPE is:19.10% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 15.15% & 0.67\n",
      "for 2021-05-17, MAE is:8.52 & sMAPE is:24.35% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 15.22% & 0.68\n",
      "for 2021-05-18, MAE is:4.43 & sMAPE is:13.76% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 15.21% & 0.68\n",
      "for 2021-05-19, MAE is:17.76 & sMAPE is:33.82% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 15.34% & 0.68\n",
      "for 2021-05-20, MAE is:10.28 & sMAPE is:33.37% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 15.47% & 0.69\n",
      "for 2021-05-21, MAE is:10.71 & sMAPE is:41.23% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 15.66% & 0.69\n",
      "for 2021-05-22, MAE is:4.04 & sMAPE is:20.08% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 15.69% & 0.70\n",
      "for 2021-05-23, MAE is:7.96 & sMAPE is:42.16% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 15.87% & 0.70\n",
      "for 2021-05-24, MAE is:8.05 & sMAPE is:28.16% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 15.96% & 0.70\n",
      "for 2021-05-25, MAE is:4.61 & sMAPE is:13.44% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 15.94% & 0.71\n",
      "for 2021-05-26, MAE is:4.13 & sMAPE is:14.22% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 15.93% & 0.70\n",
      "for 2021-05-27, MAE is:4.65 & sMAPE is:15.67% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.93% & 0.70\n",
      "for 2021-05-28, MAE is:2.09 & sMAPE is:6.74% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 15.86% & 0.70\n",
      "for 2021-05-29, MAE is:4.16 & sMAPE is:13.63% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 15.85% & 0.70\n",
      "for 2021-05-30, MAE is:4.97 & sMAPE is:18.39% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 15.87% & 0.70\n",
      "for 2021-05-31, MAE is:8.65 & sMAPE is:26.20% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 15.93% & 0.70\n",
      "for 2021-06-01, MAE is:11.86 & sMAPE is:27.82% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 16.01% & 0.71\n",
      "for 2021-06-02, MAE is:7.50 & sMAPE is:17.42% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 16.02% & 0.71\n",
      "for 2021-06-03, MAE is:3.27 & sMAPE is:8.70% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 15.97% & 0.70\n",
      "for 2021-06-04, MAE is:5.90 & sMAPE is:15.59% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.97% & 0.70\n",
      "for 2021-06-05, MAE is:4.95 & sMAPE is:12.71% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.95% & 0.70\n",
      "for 2021-06-06, MAE is:2.69 & sMAPE is:6.88% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 15.89% & 0.70\n",
      "for 2021-06-07, MAE is:16.33 & sMAPE is:31.80% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 15.99% & 0.70\n",
      "for 2021-06-08, MAE is:5.61 & sMAPE is:10.74% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 15.96% & 0.70\n",
      "for 2021-06-09, MAE is:6.23 & sMAPE is:11.86% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 15.94% & 0.70\n",
      "for 2021-06-10, MAE is:5.94 & sMAPE is:11.57% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 15.91% & 0.70\n",
      "for 2021-06-11, MAE is:7.77 & sMAPE is:19.51% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 15.93% & 0.70\n",
      "for 2021-06-12, MAE is:16.57 & sMAPE is:76.52% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 16.30% & 0.70\n",
      "for 2021-06-13, MAE is:14.73 & sMAPE is:99.68% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 16.81% & 0.70\n",
      "for 2021-06-14, MAE is:4.21 & sMAPE is:15.39% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 16.80% & 0.70\n",
      "for 2021-06-15, MAE is:4.72 & sMAPE is:29.71% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 16.88% & 0.69\n",
      "for 2021-06-16, MAE is:5.65 & sMAPE is:19.17% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 16.89% & 0.69\n",
      "for 2021-06-17, MAE is:1.68 & sMAPE is:5.53% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 16.83% & 0.69\n",
      "for 2021-06-18, MAE is:2.67 & sMAPE is:10.02% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 16.79% & 0.69\n",
      "for 2021-06-19, MAE is:2.97 & sMAPE is:11.84% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 16.76% & 0.68\n",
      "for 2021-06-20, MAE is:1.87 & sMAPE is:7.28% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 16.70% & 0.68\n",
      "for 2021-06-21, MAE is:1.39 & sMAPE is:5.39% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 16.64% & 0.68\n",
      "for 2021-06-22, MAE is:2.97 & sMAPE is:10.13% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 16.60% & 0.68\n",
      "for 2021-06-23, MAE is:3.49 & sMAPE is:11.43% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 16.57% & 0.68\n",
      "for 2021-06-24, MAE is:5.45 & sMAPE is:16.36% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 16.57% & 0.68\n",
      "for 2021-06-25, MAE is:1.57 & sMAPE is:4.73% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 16.50% & 0.68\n",
      "for 2021-06-26, MAE is:3.22 & sMAPE is:10.19% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 16.46% & 0.68\n",
      "for 2021-06-27, MAE is:1.14 & sMAPE is:3.54% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 16.39% & 0.68\n",
      "for 2021-06-28, MAE is:3.89 & sMAPE is:11.62% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 16.36% & 0.67\n",
      "for 2021-06-29, MAE is:3.06 & sMAPE is:8.48% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 16.32% & 0.67\n",
      "for 2021-06-30, MAE is:3.64 & sMAPE is:10.01% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 16.29% & 0.67\n",
      "for 2021-07-01, MAE is:1.63 & sMAPE is:4.20% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 16.22% & 0.67\n",
      "for 2021-07-02, MAE is:9.15 & sMAPE is:21.08% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 16.25% & 0.67\n",
      "for 2021-07-03, MAE is:5.08 & sMAPE is:11.23% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 16.22% & 0.67\n",
      "for 2021-07-04, MAE is:3.32 & sMAPE is:7.31% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 16.17% & 0.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-07-05, MAE is:5.02 & sMAPE is:9.92% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 16.14% & 0.67\n",
      "for 2021-07-06, MAE is:3.29 & sMAPE is:7.24% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 16.09% & 0.66\n",
      "for 2021-07-07, MAE is:2.33 & sMAPE is:5.00% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 16.03% & 0.66\n",
      "for 2021-07-08, MAE is:25.67 & sMAPE is:40.09% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 16.16% & 0.66\n",
      "for 2021-07-09, MAE is:14.58 & sMAPE is:23.64% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 16.20% & 0.67\n",
      "for 2021-07-10, MAE is:4.86 & sMAPE is:9.37% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 16.16% & 0.67\n",
      "for 2021-07-11, MAE is:9.41 & sMAPE is:21.71% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 16.19% & 0.67\n",
      "for 2021-07-12, MAE is:8.85 & sMAPE is:19.76% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 16.21% & 0.68\n",
      "for 2021-07-13, MAE is:2.12 & sMAPE is:4.55% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 16.15% & 0.67\n",
      "for 2021-07-14, MAE is:12.87 & sMAPE is:25.21% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 16.20% & 0.68\n",
      "for 2021-07-15, MAE is:16.20 & sMAPE is:35.61% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 16.29% & 0.68\n",
      "for 2021-07-16, MAE is:7.12 & sMAPE is:16.69% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 16.30% & 0.68\n",
      "for 2021-07-17, MAE is:3.96 & sMAPE is:10.91% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 16.27% & 0.67\n",
      "for 2021-07-18, MAE is:6.11 & sMAPE is:22.06% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 16.30% & 0.67\n",
      "for 2021-07-19, MAE is:1.71 & sMAPE is:5.30% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 16.24% & 0.67\n",
      "for 2021-07-20, MAE is:12.74 & sMAPE is:32.82% & rMAE is:2.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 16.33% & 0.68\n",
      "for 2021-07-21, MAE is:2.41 & sMAPE is:5.46% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 16.27% & 0.68\n",
      "for 2021-07-22, MAE is:3.29 & sMAPE is:8.45% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 16.23% & 0.68\n",
      "for 2021-07-23, MAE is:6.55 & sMAPE is:14.56% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 16.22% & 0.68\n",
      "for 2021-07-24, MAE is:5.27 & sMAPE is:10.90% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 16.20% & 0.68\n",
      "for 2021-07-25, MAE is:1.29 & sMAPE is:2.67% & rMAE is:0.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 16.13% & 0.68\n",
      "for 2021-07-26, MAE is:2.42 & sMAPE is:5.19% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 16.08% & 0.67\n",
      "for 2021-07-27, MAE is:2.17 & sMAPE is:4.98% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 16.03% & 0.67\n",
      "for 2021-07-28, MAE is:2.40 & sMAPE is:5.80% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 15.98% & 0.67\n",
      "for 2021-07-29, MAE is:3.26 & sMAPE is:7.45% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 15.94% & 0.67\n",
      "for 2021-07-30, MAE is:3.02 & sMAPE is:6.70% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 15.89% & 0.67\n",
      "for 2021-07-31, MAE is:5.33 & sMAPE is:12.39% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 15.88% & 0.67\n",
      "for 2021-08-01, MAE is:3.99 & sMAPE is:8.61% & rMAE is:3.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 15.84% & 0.68\n",
      "for 2021-08-02, MAE is:5.88 & sMAPE is:11.16% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 15.82% & 0.69\n",
      "for 2021-08-03, MAE is:3.90 & sMAPE is:7.15% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 15.78% & 0.68\n",
      "for 2021-08-04, MAE is:5.37 & sMAPE is:9.32% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 15.75% & 0.68\n",
      "for 2021-08-05, MAE is:2.20 & sMAPE is:3.73% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 15.70% & 0.68\n",
      "for 2021-08-06, MAE is:3.16 & sMAPE is:5.57% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 15.65% & 0.68\n",
      "for 2021-08-07, MAE is:3.41 & sMAPE is:6.61% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 15.61% & 0.68\n",
      "for 2021-08-08, MAE is:14.35 & sMAPE is:36.18% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 15.70% & 0.68\n",
      "for 2021-08-09, MAE is:13.58 & sMAPE is:22.11% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 15.73% & 0.68\n",
      "for 2021-08-10, MAE is:15.37 & sMAPE is:18.91% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 15.74% & 0.68\n",
      "for 2021-08-11, MAE is:8.76 & sMAPE is:10.03% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 15.72% & 0.68\n",
      "for 2021-08-12, MAE is:10.77 & sMAPE is:12.04% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 15.70% & 0.68\n",
      "for 2021-08-13, MAE is:7.39 & sMAPE is:9.73% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 15.68% & 0.68\n",
      "for 2021-08-14, MAE is:7.64 & sMAPE is:12.61% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 15.66% & 0.68\n",
      "for 2021-08-15, MAE is:5.12 & sMAPE is:8.76% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 15.63% & 0.68\n",
      "for 2021-08-16, MAE is:5.17 & sMAPE is:7.79% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 15.60% & 0.68\n",
      "for 2021-08-17, MAE is:6.02 & sMAPE is:10.58% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 15.58% & 0.68\n",
      "for 2021-08-18, MAE is:12.16 & sMAPE is:23.47% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 15.61% & 0.67\n",
      "for 2021-08-19, MAE is:6.94 & sMAPE is:16.33% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 15.61% & 0.67\n",
      "for 2021-08-20, MAE is:12.38 & sMAPE is:27.54% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 15.66% & 0.67\n",
      "for 2021-08-21, MAE is:3.04 & sMAPE is:6.18% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 15.62% & 0.67\n",
      "for 2021-08-22, MAE is:2.94 & sMAPE is:5.74% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 15.58% & 0.67\n",
      "for 2021-08-23, MAE is:11.87 & sMAPE is:18.44% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 15.59% & 0.67\n",
      "for 2021-08-24, MAE is:13.29 & sMAPE is:21.52% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 15.62% & 0.67\n",
      "for 2021-08-25, MAE is:11.51 & sMAPE is:30.20% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 15.68% & 0.67\n",
      "for 2021-08-26, MAE is:12.30 & sMAPE is:28.95% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 15.74% & 0.68\n",
      "for 2021-08-27, MAE is:1.33 & sMAPE is:2.81% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 15.68% & 0.68\n",
      "for 2021-08-28, MAE is:2.92 & sMAPE is:5.64% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 15.64% & 0.68\n",
      "for 2021-08-29, MAE is:1.17 & sMAPE is:2.20% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 15.58% & 0.68\n",
      "for 2021-08-30, MAE is:5.79 & sMAPE is:10.00% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 15.56% & 0.68\n",
      "for 2021-08-31, MAE is:8.69 & sMAPE is:18.01% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 15.57% & 0.68\n",
      "for 2021-09-01, MAE is:3.92 & sMAPE is:10.69% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 15.55% & 0.68\n",
      "for 2021-09-02, MAE is:4.37 & sMAPE is:9.89% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 15.53% & 0.68\n",
      "for 2021-09-03, MAE is:3.54 & sMAPE is:8.86% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 15.50% & 0.68\n",
      "for 2021-09-04, MAE is:3.70 & sMAPE is:7.83% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 15.47% & 0.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-09-05, MAE is:1.84 & sMAPE is:3.76% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 15.42% & 0.68\n",
      "for 2021-09-06, MAE is:2.79 & sMAPE is:5.64% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 15.38% & 0.68\n",
      "for 2021-09-07, MAE is:5.15 & sMAPE is:11.47% & rMAE is:3.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 15.37% & 0.69\n",
      "for 2021-09-08, MAE is:7.61 & sMAPE is:19.26% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 15.38% & 0.69\n",
      "for 2021-09-09, MAE is:6.50 & sMAPE is:13.06% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 15.37% & 0.69\n",
      "for 2021-09-10, MAE is:4.01 & sMAPE is:7.54% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 15.34% & 0.69\n",
      "for 2021-09-11, MAE is:6.46 & sMAPE is:12.53% & rMAE is:2.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 15.33% & 0.70\n",
      "for 2021-09-12, MAE is:1.86 & sMAPE is:4.11% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 15.29% & 0.70\n",
      "for 2021-09-13, MAE is:2.24 & sMAPE is:4.58% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.25% & 0.70\n",
      "for 2021-09-14, MAE is:5.35 & sMAPE is:9.87% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.23% & 0.70\n",
      "for 2021-09-15, MAE is:6.36 & sMAPE is:10.50% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.21% & 0.69\n",
      "for 2021-09-16, MAE is:2.73 & sMAPE is:4.52% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 15.17% & 0.69\n",
      "for 2021-09-17, MAE is:3.36 & sMAPE is:5.55% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 15.13% & 0.69\n",
      "for 2021-09-18, MAE is:2.66 & sMAPE is:4.48% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 15.09% & 0.69\n",
      "for 2021-09-19, MAE is:3.38 & sMAPE is:5.55% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 15.05% & 0.69\n",
      "for 2021-09-20, MAE is:3.32 & sMAPE is:5.19% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 15.01% & 0.69\n",
      "for 2021-09-21, MAE is:2.26 & sMAPE is:3.78% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 14.97% & 0.69\n",
      "for 2021-09-22, MAE is:4.42 & sMAPE is:7.75% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 14.94% & 0.69\n",
      "for 2021-09-23, MAE is:4.11 & sMAPE is:7.74% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 14.92% & 0.69\n",
      "for 2021-09-24, MAE is:6.08 & sMAPE is:12.85% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 14.91% & 0.69\n",
      "for 2021-09-25, MAE is:4.38 & sMAPE is:8.49% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 14.89% & 0.69\n",
      "for 2021-09-26, MAE is:2.16 & sMAPE is:3.97% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 14.85% & 0.68\n",
      "for 2021-09-27, MAE is:3.88 & sMAPE is:7.21% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 14.82% & 0.68\n",
      "for 2021-09-28, MAE is:1.73 & sMAPE is:3.45% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 14.77% & 0.68\n",
      "for 2021-09-29, MAE is:1.87 & sMAPE is:3.54% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 14.73% & 0.68\n",
      "for 2021-09-30, MAE is:3.91 & sMAPE is:7.44% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 14.71% & 0.68\n",
      "for 2021-10-01, MAE is:7.17 & sMAPE is:17.47% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 14.72% & 0.68\n",
      "for 2021-10-02, MAE is:10.54 & sMAPE is:29.54% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 14.77% & 0.68\n",
      "for 2021-10-03, MAE is:26.55 & sMAPE is:132.03% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 15.20% & 0.68\n",
      "for 2021-10-04, MAE is:15.22 & sMAPE is:78.68% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 15.43% & 0.68\n",
      "for 2021-10-05, MAE is:18.19 & sMAPE is:48.19% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 15.54% & 0.69\n",
      "for 2021-10-06, MAE is:8.17 & sMAPE is:16.76% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 15.55% & 0.69\n",
      "for 2021-10-07, MAE is:4.69 & sMAPE is:10.28% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 15.53% & 0.69\n",
      "for 2021-10-08, MAE is:2.82 & sMAPE is:6.18% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 15.50% & 0.69\n",
      "for 2021-10-09, MAE is:2.09 & sMAPE is:4.49% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 15.46% & 0.69\n",
      "for 2021-10-10, MAE is:10.67 & sMAPE is:32.54% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 15.52% & 0.69\n",
      "for 2021-10-11, MAE is:10.10 & sMAPE is:30.54% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 15.57% & 0.69\n",
      "for 2021-10-12, MAE is:2.29 & sMAPE is:5.94% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 15.54% & 0.69\n",
      "for 2021-10-13, MAE is:2.68 & sMAPE is:6.89% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 15.51% & 0.68\n",
      "for 2021-10-14, MAE is:18.86 & sMAPE is:72.12% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 15.70% & 0.68\n",
      "for 2021-10-15, MAE is:7.90 & sMAPE is:63.32% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 15.87% & 0.68\n",
      "for 2021-10-16, MAE is:6.24 & sMAPE is:66.00% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 16.04% & 0.68\n",
      "for 2021-10-17, MAE is:6.43 & sMAPE is:55.15% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 16.18% & 0.68\n",
      "for 2021-10-18, MAE is:1.93 & sMAPE is:9.91% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 16.15% & 0.68\n",
      "for 2021-10-19, MAE is:2.93 & sMAPE is:14.13% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 16.15% & 0.67\n",
      "for 2021-10-20, MAE is:6.17 & sMAPE is:44.66% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 16.25% & 0.67\n",
      "for 2021-10-21, MAE is:1.28 & sMAPE is:9.31% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 16.22% & 0.67\n",
      "for 2021-10-22, MAE is:2.67 & sMAPE is:30.07% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 16.27% & 0.67\n",
      "for 2021-10-23, MAE is:5.45 & sMAPE is:36.27% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 16.34% & 0.67\n",
      "for 2021-10-24, MAE is:1.86 & sMAPE is:11.67% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 16.32% & 0.67\n",
      "for 2021-10-25, MAE is:0.77 & sMAPE is:4.86% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 16.28% & 0.67\n",
      "for 2021-10-26, MAE is:1.25 & sMAPE is:7.15% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 16.25% & 0.67\n",
      "for 2021-10-27, MAE is:2.75 & sMAPE is:19.27% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 16.26% & 0.67\n",
      "for 2021-10-28, MAE is:2.11 & sMAPE is:15.93% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 16.26% & 0.67\n",
      "for 2021-10-29, MAE is:2.01 & sMAPE is:13.46% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 16.25% & 0.67\n",
      "for 2021-10-30, MAE is:2.01 & sMAPE is:14.96% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 16.25% & 0.67\n",
      "for 2021-10-31, MAE is:2.57 & sMAPE is:18.04% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 16.25% & 0.67\n",
      "for 2021-11-01, MAE is:2.26 & sMAPE is:16.37% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 16.25% & 0.67\n",
      "for 2021-11-02, MAE is:1.95 & sMAPE is:21.08% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 16.27% & 0.67\n",
      "for 2021-11-03, MAE is:5.34 & sMAPE is:30.02% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 16.31% & 0.67\n",
      "for 2021-11-04, MAE is:4.82 & sMAPE is:19.46% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 16.32% & 0.67\n",
      "for 2021-11-05, MAE is:5.21 & sMAPE is:28.63% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 16.36% & 0.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-11-06, MAE is:3.72 & sMAPE is:45.51% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 16.46% & 0.68\n",
      "for 2021-11-07, MAE is:5.34 & sMAPE is:56.04% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 16.59% & 0.68\n",
      "for 2021-11-08, MAE is:6.80 & sMAPE is:36.40% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 16.65% & 0.68\n",
      "for 2021-11-09, MAE is:6.46 & sMAPE is:40.21% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 16.72% & 0.69\n",
      "for 2021-11-10, MAE is:2.90 & sMAPE is:33.95% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 16.78% & 0.68\n",
      "for 2021-11-11, MAE is:3.16 & sMAPE is:36.51% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 16.84% & 0.68\n",
      "for 2021-11-12, MAE is:2.43 & sMAPE is:18.01% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 16.85% & 0.68\n",
      "for 2021-11-13, MAE is:2.88 & sMAPE is:19.19% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 16.85% & 0.68\n",
      "for 2021-11-14, MAE is:1.73 & sMAPE is:9.81% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 16.83% & 0.68\n",
      "for 2021-11-15, MAE is:2.45 & sMAPE is:15.93% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 16.83% & 0.68\n",
      "for 2021-11-16, MAE is:1.39 & sMAPE is:10.11% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 16.81% & 0.68\n",
      "for 2021-11-17, MAE is:0.86 & sMAPE is:5.77% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 16.77% & 0.68\n",
      "for 2021-11-18, MAE is:2.38 & sMAPE is:16.22% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 16.77% & 0.68\n",
      "for 2021-11-19, MAE is:2.10 & sMAPE is:19.76% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 16.78% & 0.68\n",
      "for 2021-11-20, MAE is:4.03 & sMAPE is:40.03% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 16.85% & 0.68\n",
      "for 2021-11-21, MAE is:3.47 & sMAPE is:25.54% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 16.88% & 0.68\n",
      "for 2021-11-22, MAE is:2.14 & sMAPE is:13.25% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 16.87% & 0.69\n",
      "for 2021-11-23, MAE is:1.84 & sMAPE is:12.34% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 16.85% & 0.69\n",
      "for 2021-11-24, MAE is:8.10 & sMAPE is:39.08% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 16.92% & 0.69\n",
      "for 2021-11-25, MAE is:15.01 & sMAPE is:39.22% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 16.99% & 0.69\n",
      "for 2021-11-26, MAE is:68.94 & sMAPE is:83.73% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 17.19% & 0.69\n",
      "for 2021-11-27, MAE is:63.96 & sMAPE is:42.24% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 17.27% & 0.69\n",
      "for 2021-11-28, MAE is:48.78 & sMAPE is:28.20% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 17.30% & 0.68\n",
      "for 2021-11-29, MAE is:87.18 & sMAPE is:41.98% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 17.37% & 0.68\n",
      "for 2021-11-30, MAE is:59.08 & sMAPE is:46.57% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 17.46% & 0.68\n",
      "for 2021-12-01, MAE is:18.99 & sMAPE is:16.17% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 17.46% & 0.68\n",
      "for 2021-12-02, MAE is:67.89 & sMAPE is:51.05% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 17.56% & 0.68\n",
      "for 2021-12-03, MAE is:24.01 & sMAPE is:21.14% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 17.57% & 0.68\n",
      "for 2021-12-04, MAE is:9.04 & sMAPE is:12.34% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 17.55% & 0.68\n",
      "for 2021-12-05, MAE is:41.77 & sMAPE is:41.76% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 17.62% & 0.68\n",
      "for 2021-12-06, MAE is:34.67 & sMAPE is:29.93% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 17.66% & 0.68\n",
      "for 2021-12-07, MAE is:35.50 & sMAPE is:29.09% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 17.69% & 0.68\n",
      "for 2021-12-08, MAE is:11.15 & sMAPE is:15.44% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 17.69% & 0.68\n",
      "for 2021-12-09, MAE is:27.74 & sMAPE is:50.10% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 17.78% & 0.68\n",
      "for 2021-12-10, MAE is:4.28 & sMAPE is:9.41% & rMAE is:0.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 17.76% & 0.67\n",
      "for 2021-12-11, MAE is:3.35 & sMAPE is:6.73% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 17.73% & 0.67\n",
      "for 2021-12-12, MAE is:9.20 & sMAPE is:19.00% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 17.73% & 0.67\n",
      "for 2021-12-13, MAE is:5.32 & sMAPE is:11.49% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 17.71% & 0.67\n",
      "for 2021-12-14, MAE is:11.24 & sMAPE is:27.79% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 17.74% & 0.67\n",
      "for 2021-12-15, MAE is:9.93 & sMAPE is:37.19% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 17.80% & 0.67\n",
      "for 2021-12-16, MAE is:1.93 & sMAPE is:9.89% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 17.77% & 0.67\n",
      "for 2021-12-17, MAE is:4.61 & sMAPE is:20.75% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 17.78% & 0.66\n",
      "for 2021-12-18, MAE is:1.62 & sMAPE is:7.90% & rMAE is:0.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 17.75% & 0.66\n",
      "for 2021-12-19, MAE is:4.18 & sMAPE is:19.89% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 17.76% & 0.66\n",
      "for 2021-12-20, MAE is:31.48 & sMAPE is:72.45% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 17.91% & 0.67\n",
      "for 2021-12-21, MAE is:10.41 & sMAPE is:18.05% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 17.91% & 0.66\n",
      "for 2021-12-22, MAE is:11.22 & sMAPE is:18.42% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 17.92% & 0.66\n",
      "for 2021-12-23, MAE is:6.16 & sMAPE is:14.62% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 17.91% & 0.66\n",
      "for 2021-12-24, MAE is:6.08 & sMAPE is:17.82% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 17.91% & 0.66\n",
      "for 2021-12-25, MAE is:2.74 & sMAPE is:9.05% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 17.88% & 0.66\n",
      "for 2021-12-26, MAE is:18.98 & sMAPE is:46.87% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 17.96% & 0.66\n",
      "for 2021-12-27, MAE is:6.12 & sMAPE is:10.53% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 17.94% & 0.66\n",
      "for 2021-12-28, MAE is:10.71 & sMAPE is:18.33% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 17.94% & 0.66\n",
      "for 2021-12-29, MAE is:9.91 & sMAPE is:14.00% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 17.93% & 0.66\n",
      "for 2021-12-30, MAE is:11.29 & sMAPE is:21.12% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 17.94% & 0.66\n",
      "for 2021-12-31, MAE is:12.36 & sMAPE is:31.60% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 17.98% & 0.66\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:24:52,821]\u001b[0m A new study created in RDB with name: NO_3_2022\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:25:15,048]\u001b[0m Trial 2 finished with value: 7.304599658364023 and parameters: {'n_hidden': 3, 'learning_rate': 0.00972523084187328, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023810331696356404, 'dropout_rate_Layer_2': 0.3420211970944127, 'dropout_rate_Layer_3': 0.24089155862793638, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00043064313093786204, 'l1_Layer_2': 0.0035471339581763218, 'l1_Layer_3': 6.233503441107888e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 270, 'n_units_Layer_3': 110}. Best is trial 2 with value: 7.304599658364023.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.30 | sMAPE for Validation Set is: 17.43% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 15.02 | sMAPE for Test Set is: 41.59% | rMAE for Test Set is: 0.49\n",
      "MAE for Validation Set is: 10.82 | sMAPE for Validation Set is: 24.74% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 24.46 | sMAPE for Test Set is: 53.10% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:25:15,055]\u001b[0m Trial 0 finished with value: 10.824701020861914 and parameters: {'n_hidden': 3, 'learning_rate': 0.0065948599828445685, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15173427000359918, 'dropout_rate_Layer_2': 0.03269421786585247, 'dropout_rate_Layer_3': 0.33530129107218687, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00043558673440629995, 'l1_Layer_2': 0.00013919618512760055, 'l1_Layer_3': 0.04705871915954364, 'n_units_Layer_1': 185, 'n_units_Layer_2': 55, 'n_units_Layer_3': 75}. Best is trial 2 with value: 7.304599658364023.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:25:15,224]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 71.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:25:21,769]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:25:22,379]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:25:23,957]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:25:29,958]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:25:30,308]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:25:36,524]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:25:36,775]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:25:42,900]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:25:45,298]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:25:48,077]\u001b[0m Trial 7 finished with value: 10.885172097318886 and parameters: {'n_hidden': 3, 'learning_rate': 0.026218815238095345, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.325867800934895, 'dropout_rate_Layer_2': 0.005868556231614175, 'dropout_rate_Layer_3': 0.35343114889738736, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.2328579910045019e-05, 'l1_Layer_2': 1.027012430657506e-05, 'l1_Layer_3': 0.035700268003022936, 'n_units_Layer_1': 230, 'n_units_Layer_2': 265, 'n_units_Layer_3': 235}. Best is trial 2 with value: 7.304599658364023.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.89 | sMAPE for Validation Set is: 24.69% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 25.23 | sMAPE for Test Set is: 57.80% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:25:55,314]\u001b[0m Trial 1 finished with value: 9.30704183784277 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005812602521914976, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.367601388119297, 'dropout_rate_Layer_2': 0.25264421010485905, 'dropout_rate_Layer_3': 0.24659806854102806, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016383112110233845, 'l1_Layer_2': 1.0422827170662069e-05, 'l1_Layer_3': 0.005175874578323246, 'n_units_Layer_1': 265, 'n_units_Layer_2': 200, 'n_units_Layer_3': 185}. Best is trial 2 with value: 7.304599658364023.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.31 | sMAPE for Validation Set is: 20.53% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 22.84 | sMAPE for Test Set is: 42.51% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:25:57,155]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:26:07,759]\u001b[0m Trial 17 finished with value: 14.764539498803337 and parameters: {'n_hidden': 3, 'learning_rate': 0.09292503064200991, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2903631910965761, 'dropout_rate_Layer_2': 0.06703176353098499, 'dropout_rate_Layer_3': 0.07017123486101076, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0371840200887968, 'l1_Layer_2': 0.004641351076186972, 'l1_Layer_3': 0.00018809284149422242, 'n_units_Layer_1': 55, 'n_units_Layer_2': 75, 'n_units_Layer_3': 220}. Best is trial 2 with value: 7.304599658364023.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.76 | sMAPE for Validation Set is: 34.92% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 28.76 | sMAPE for Test Set is: 70.61% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:26:17,635]\u001b[0m Trial 18 finished with value: 11.05434537254454 and parameters: {'n_hidden': 3, 'learning_rate': 0.07458546105814694, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16232618384289188, 'dropout_rate_Layer_2': 0.09322085963855248, 'dropout_rate_Layer_3': 0.04825164538556934, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007990742777202891, 'l1_Layer_2': 0.00033340946642997456, 'l1_Layer_3': 0.09217952127029556, 'n_units_Layer_1': 160, 'n_units_Layer_2': 80, 'n_units_Layer_3': 220}. Best is trial 2 with value: 7.304599658364023.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.05 | sMAPE for Validation Set is: 25.57% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.97 | sMAPE for Test Set is: 53.77% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:26:25,319]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:26:28,795]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:26:36,830]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:26:39,583]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:26:42,160]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:26:49,047]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:26:56,047]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:01,111]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:03,492]\u001b[0m Trial 20 finished with value: 8.90826374076154 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008224738003922036, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.034442642752989985, 'dropout_rate_Layer_2': 0.21609648771898998, 'dropout_rate_Layer_3': 0.052721753752275016, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.02117228036816038, 'l1_Layer_2': 2.3379450018575933e-05, 'l1_Layer_3': 0.0053867880578144746, 'n_units_Layer_1': 250, 'n_units_Layer_2': 245, 'n_units_Layer_3': 175}. Best is trial 2 with value: 7.304599658364023.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.91 | sMAPE for Validation Set is: 19.84% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 22.58 | sMAPE for Test Set is: 44.14% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:27:03,677]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:09,207]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:12,488]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:14,555]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:14,911]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:17,224]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:18,227]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:20,248]\u001b[0m Trial 15 finished with value: 7.485523096653782 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022530856231016195, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23281273977532774, 'dropout_rate_Layer_2': 0.38486602929739766, 'dropout_rate_Layer_3': 0.2487398995922414, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.687651568191537e-05, 'l1_Layer_2': 0.014130560222911483, 'l1_Layer_3': 3.498337554707849e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 170, 'n_units_Layer_3': 115}. Best is trial 2 with value: 7.304599658364023.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.49 | sMAPE for Validation Set is: 17.76% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 14.97 | sMAPE for Test Set is: 36.63% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:27:21,199]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:24,005]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:27,325]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:27,606]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:27,843]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:31,773]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:36,608]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:38,493]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:43,218]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:45,779]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:51,512]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:54,031]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:57,438]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:27:58,005]\u001b[0m Trial 45 finished with value: 8.971390600284384 and parameters: {'n_hidden': 3, 'learning_rate': 0.012214014797644612, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16120972982083065, 'dropout_rate_Layer_2': 0.3524698487664577, 'dropout_rate_Layer_3': 0.06478988695457791, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0055481510709872285, 'l1_Layer_2': 4.559275091547957e-05, 'l1_Layer_3': 0.00828496757004448, 'n_units_Layer_1': 255, 'n_units_Layer_2': 145, 'n_units_Layer_3': 180}. Best is trial 2 with value: 7.304599658364023.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.97 | sMAPE for Validation Set is: 20.04% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 22.58 | sMAPE for Test Set is: 44.99% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:27:58,228]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:28:02,382]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:28:05,365]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:28:05,463]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:28:08,413]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:28:12,256]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:28:17,314]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:28:21,818]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:28:23,546]\u001b[0m Trial 56 finished with value: 12.467350237886777 and parameters: {'n_hidden': 3, 'learning_rate': 0.019918197514485567, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27359249457593454, 'dropout_rate_Layer_2': 0.10293619862966255, 'dropout_rate_Layer_3': 0.35108216117307633, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.01955859963507655, 'l1_Layer_2': 0.0033665636961216342, 'l1_Layer_3': 0.012777764277271942, 'n_units_Layer_1': 260, 'n_units_Layer_2': 90, 'n_units_Layer_3': 55}. Best is trial 2 with value: 7.304599658364023.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.47 | sMAPE for Validation Set is: 29.76% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 26.01 | sMAPE for Test Set is: 60.24% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:28:28,161]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:28:31,923]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:28:32,293]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:28:40,634]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:28:44,692]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:28:50,088]\u001b[0m Trial 46 finished with value: 10.615090124584887 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017559926102869454, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36866037757368225, 'dropout_rate_Layer_2': 0.1866806397052265, 'dropout_rate_Layer_3': 0.18527005147477255, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08560815576967114, 'l1_Layer_2': 0.025479164091933532, 'l1_Layer_3': 4.765411541179867e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 300, 'n_units_Layer_3': 100}. Best is trial 2 with value: 7.304599658364023.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.62 | sMAPE for Validation Set is: 23.49% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 24.27 | sMAPE for Test Set is: 52.60% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:28:51,475]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:28:53,980]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:28:54,604]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:28:58,720]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:01,597]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:04,796]\u001b[0m Trial 65 finished with value: 7.605910122541076 and parameters: {'n_hidden': 3, 'learning_rate': 0.010558848539627111, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26298115624305995, 'dropout_rate_Layer_2': 0.11814570643149913, 'dropout_rate_Layer_3': 0.1156334494224991, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0031881715216525376, 'l1_Layer_2': 0.0054412002344181405, 'l1_Layer_3': 0.0032807434478719175, 'n_units_Layer_1': 225, 'n_units_Layer_2': 280, 'n_units_Layer_3': 245}. Best is trial 2 with value: 7.304599658364023.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.61 | sMAPE for Validation Set is: 18.19% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 14.84 | sMAPE for Test Set is: 38.66% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:29:05,125]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:11,019]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:11,476]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:15,995]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:16,182]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:21,718]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:24,140]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:25,909]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:29,660]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:33,985]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:38,229]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:40,451]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:40,978]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:47,281]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:51,134]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:52,997]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:55,537]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:57,335]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:29:59,799]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:00,644]\u001b[0m Trial 75 finished with value: 7.196445311842905 and parameters: {'n_hidden': 4, 'learning_rate': 0.012143391625386985, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13311668455778913, 'dropout_rate_Layer_2': 0.3971401120237785, 'dropout_rate_Layer_3': 0.39953974078038096, 'dropout_rate_Layer_4': 0.00515049988405486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006282579967225592, 'l1_Layer_2': 0.0013415447492501177, 'l1_Layer_3': 1.3977800630242847e-05, 'l1_Layer_4': 0.07078892270178791, 'n_units_Layer_1': 170, 'n_units_Layer_2': 300, 'n_units_Layer_3': 50, 'n_units_Layer_4': 295}. Best is trial 75 with value: 7.196445311842905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.20 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.37 | sMAPE for Test Set is: 44.98% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:30:01,753]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:04,894]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:08,327]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:09,918]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:13,017]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:15,779]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:19,229]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:21,763]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:24,163]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:26,098]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:28,664]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:31,287]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:31,654]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:35,420]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:37,836]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:46,718]\u001b[0m Trial 92 finished with value: 7.63046825401388 and parameters: {'n_hidden': 4, 'learning_rate': 0.02687367094950659, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12014557884656898, 'dropout_rate_Layer_2': 0.3428936838388035, 'dropout_rate_Layer_3': 0.38532995667733405, 'dropout_rate_Layer_4': 0.012019209268087888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005382067775031172, 'l1_Layer_2': 0.0021710627297119836, 'l1_Layer_3': 1.251098546120498e-05, 'l1_Layer_4': 0.03787350262807341, 'n_units_Layer_1': 135, 'n_units_Layer_2': 295, 'n_units_Layer_3': 85, 'n_units_Layer_4': 275}. Best is trial 75 with value: 7.196445311842905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.63 | sMAPE for Validation Set is: 17.85% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 16.24 | sMAPE for Test Set is: 45.81% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:30:49,643]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:54,220]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:30:58,787]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:00,220]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:03,415]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:07,908]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:10,769]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:14,157]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:14,520]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:19,250]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:21,901]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:25,092]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:27,749]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:30,177]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:32,557]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:35,398]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:37,919]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:39,994]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:40,580]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:44,022]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:45,816]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:47,801]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:48,052]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:52,045]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:52,286]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:56,980]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.17 | sMAPE for Validation Set is: 17.15% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.42 | sMAPE for Test Set is: 33.43% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:31:57,728]\u001b[0m Trial 55 finished with value: 7.173374954322196 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008258484920634151, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37816670309709255, 'dropout_rate_Layer_2': 0.21501003629299117, 'dropout_rate_Layer_3': 0.177420443097881, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007033666509972496, 'l1_Layer_2': 0.0015662669781439857, 'l1_Layer_3': 0.01881096889335576, 'n_units_Layer_1': 135, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265}. Best is trial 55 with value: 7.173374954322196.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:31:59,886]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:02,764]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:05,525]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:06,196]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:10,192]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:13,561]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:16,423]\u001b[0m Trial 130 finished with value: 8.480494772273511 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037474261003980084, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3851115975053847, 'dropout_rate_Layer_2': 0.3998699634405254, 'dropout_rate_Layer_3': 0.1452277938626897, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028668284854684455, 'l1_Layer_2': 1.2745815231973598e-05, 'l1_Layer_3': 3.390986344330393e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 150, 'n_units_Layer_3': 70}. Best is trial 55 with value: 7.173374954322196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.48 | sMAPE for Validation Set is: 18.98% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 21.94 | sMAPE for Test Set is: 42.12% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:32:16,826]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:22,098]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:26,511]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:28,320]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:31,619]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:36,373]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:41,805]\u001b[0m Trial 145 finished with value: 8.997354544478865 and parameters: {'n_hidden': 3, 'learning_rate': 0.006387606987157923, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26273464158571597, 'dropout_rate_Layer_2': 0.39793298593848697, 'dropout_rate_Layer_3': 0.1388925486583375, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00043208866983926117, 'l1_Layer_2': 1.5930316689713057e-05, 'l1_Layer_3': 1.2063962925991645e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 155, 'n_units_Layer_3': 175}. Best is trial 55 with value: 7.173374954322196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.00 | sMAPE for Validation Set is: 20.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 22.28 | sMAPE for Test Set is: 42.75% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:32:42,193]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:47,050]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:49,554]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:49,721]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:53,845]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:55,707]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:58,211]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:32:58,809]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:33:03,137]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:33:06,586]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:33:11,350]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:33:13,673]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:33:17,206]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:33:17,989]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:33:23,594]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:33:26,593]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:33:31,340]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:33:40,096]\u001b[0m Trial 157 finished with value: 7.0996953368808535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020412075764213774, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02223862006052845, 'dropout_rate_Layer_2': 0.26724440751824496, 'dropout_rate_Layer_3': 0.1664053881616372, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2744177093658143e-05, 'l1_Layer_2': 0.001895541414829365, 'l1_Layer_3': 1.8951142511923688e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 185, 'n_units_Layer_3': 70}. Best is trial 157 with value: 7.0996953368808535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.10 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.63 | sMAPE for Test Set is: 33.72% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:33:45,626]\u001b[0m Trial 166 finished with value: 8.850531713727245 and parameters: {'n_hidden': 3, 'learning_rate': 0.009855219143739975, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1375141522686244, 'dropout_rate_Layer_2': 0.3237440180387448, 'dropout_rate_Layer_3': 0.09589190913000988, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011472539825525531, 'l1_Layer_2': 1.5488730978386373e-05, 'l1_Layer_3': 0.0002974016091896713, 'n_units_Layer_1': 260, 'n_units_Layer_2': 125, 'n_units_Layer_3': 180}. Best is trial 157 with value: 7.0996953368808535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.85 | sMAPE for Validation Set is: 20.24% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 22.36 | sMAPE for Test Set is: 43.31% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:33:54,564]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:34:01,786]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:34:05,418]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:34:08,331]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:34:11,646]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:34:16,813]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:34:19,699]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:34:22,504]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:34:24,073]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:34:29,665]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:34:29,932]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:34:37,485]\u001b[0m Trial 169 finished with value: 7.043058198741472 and parameters: {'n_hidden': 3, 'learning_rate': 0.001432686244816848, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00019195292326430746, 'dropout_rate_Layer_2': 0.24648388389553355, 'dropout_rate_Layer_3': 0.15071870097146564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7504907940342114e-05, 'l1_Layer_2': 0.0013576028694507686, 'l1_Layer_3': 7.312674232298751e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 150, 'n_units_Layer_3': 70}. Best is trial 169 with value: 7.043058198741472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 16.84% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.83 | sMAPE for Test Set is: 33.32% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:34:38,077]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:34:42,592]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:34:51,817]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:34:54,593]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:34:59,294]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:01,968]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:04,025]\u001b[0m Trial 180 finished with value: 7.36983347468536 and parameters: {'n_hidden': 4, 'learning_rate': 0.04446929151439395, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04386731948672895, 'dropout_rate_Layer_2': 0.3962296731862466, 'dropout_rate_Layer_3': 0.3353210451576894, 'dropout_rate_Layer_4': 0.06385831775298781, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002869827587399765, 'l1_Layer_2': 0.0004791425023867085, 'l1_Layer_3': 1.0088460169594848e-05, 'l1_Layer_4': 0.03631390652158291, 'n_units_Layer_1': 100, 'n_units_Layer_2': 255, 'n_units_Layer_3': 95, 'n_units_Layer_4': 260}. Best is trial 169 with value: 7.043058198741472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.37 | sMAPE for Validation Set is: 17.79% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 15.08 | sMAPE for Test Set is: 38.98% | rMAE for Test Set is: 0.50\n",
      "MAE for Validation Set is: 7.07 | sMAPE for Validation Set is: 16.92% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.44 | sMAPE for Test Set is: 34.94% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:35:04,104]\u001b[0m Trial 167 finished with value: 7.07493582444706 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014503578284949528, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.049099073590733816, 'dropout_rate_Layer_2': 0.2672616268313026, 'dropout_rate_Layer_3': 0.14699817533434012, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017195458767933758, 'l1_Layer_2': 0.00138758471463317, 'l1_Layer_3': 0.000155485533506343, 'n_units_Layer_1': 55, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 169 with value: 7.043058198741472.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:06,907]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:08,539]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:08,681]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:09,849]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:13,980]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:16,859]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:17,012]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:17,535]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:17,946]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:26,525]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:29,354]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:29,504]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:33,267]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:34,906]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:34,975]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:37,240]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:42,925]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:43,069]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:43,578]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:52,147]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:54,803]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:35:56,964]\u001b[0m Trial 194 finished with value: 7.025742951178683 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015219921712037044, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03723719261627262, 'dropout_rate_Layer_2': 0.249301593510841, 'dropout_rate_Layer_3': 0.19100200915730975, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0372662255608344e-05, 'l1_Layer_2': 0.001388671510122643, 'l1_Layer_3': 9.516784478404296e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 175, 'n_units_Layer_3': 105}. Best is trial 194 with value: 7.025742951178683.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.03 | sMAPE for Validation Set is: 16.80% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.70 | sMAPE for Test Set is: 34.84% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:36:06,567]\u001b[0m Trial 210 finished with value: 12.494911004739988 and parameters: {'n_hidden': 3, 'learning_rate': 0.04241141749228568, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12584005184775565, 'dropout_rate_Layer_2': 0.2855344412223124, 'dropout_rate_Layer_3': 0.10863228710350961, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0001006775321512151, 'l1_Layer_2': 0.00019698566659117595, 'l1_Layer_3': 0.0003399784218417012, 'n_units_Layer_1': 260, 'n_units_Layer_2': 230, 'n_units_Layer_3': 170}. Best is trial 194 with value: 7.025742951178683.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.49 | sMAPE for Validation Set is: 30.18% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 27.69 | sMAPE for Test Set is: 62.53% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:36:08,561]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:36:09,232]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:36:11,327]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:36:13,226]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:36:21,660]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:36:24,263]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:36:27,018]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:36:35,526]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:37:09,403]\u001b[0m Trial 214 finished with value: 7.001631616678097 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008822996610159151, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0325860419166749, 'dropout_rate_Layer_2': 0.2523326148925714, 'dropout_rate_Layer_3': 0.14979801715774635, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005774399468410677, 'l1_Layer_2': 0.0010476645682843734, 'l1_Layer_3': 0.00011104763844842768, 'n_units_Layer_1': 60, 'n_units_Layer_2': 150, 'n_units_Layer_3': 105}. Best is trial 214 with value: 7.001631616678097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.00 | sMAPE for Validation Set is: 16.71% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.67 | sMAPE for Test Set is: 34.80% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:37:12,432]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:37:23,377]\u001b[0m Trial 208 finished with value: 6.918027241668443 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009131885393573162, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.001058283535194493, 'dropout_rate_Layer_2': 0.19673366360808645, 'dropout_rate_Layer_3': 0.1602052069929322, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.575953512285222e-05, 'l1_Layer_2': 0.002369292774964411, 'l1_Layer_3': 0.00015266779258570095, 'n_units_Layer_1': 105, 'n_units_Layer_2': 145, 'n_units_Layer_3': 110}. Best is trial 208 with value: 6.918027241668443.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.92 | sMAPE for Validation Set is: 16.57% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.68 | sMAPE for Test Set is: 35.03% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:37:25,630]\u001b[0m Trial 219 finished with value: 7.470571415799512 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010834471960172432, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23171234736871213, 'dropout_rate_Layer_2': 0.3550447004465064, 'dropout_rate_Layer_3': 0.34352801177712666, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000921255532040973, 'l1_Layer_2': 0.00024141062297786654, 'l1_Layer_3': 0.05149071442710332, 'n_units_Layer_1': 230, 'n_units_Layer_2': 155, 'n_units_Layer_3': 250}. Best is trial 208 with value: 6.918027241668443.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.47 | sMAPE for Validation Set is: 17.64% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 15.18 | sMAPE for Test Set is: 39.00% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:37:27,776]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:37:29,391]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:37:31,973]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:37:42,787]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:37:45,266]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:37:54,278]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:37:54,384]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:38:11,163]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:38:11,315]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:38:17,265]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:38:22,718]\u001b[0m Trial 218 finished with value: 7.238533811817845 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008146942136601085, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17574582737341868, 'dropout_rate_Layer_2': 0.34774729120175524, 'dropout_rate_Layer_3': 0.33581145992532585, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008500971217717527, 'l1_Layer_2': 0.00019845041077842156, 'l1_Layer_3': 0.09629326650674266, 'n_units_Layer_1': 250, 'n_units_Layer_2': 135, 'n_units_Layer_3': 245}. Best is trial 208 with value: 6.918027241668443.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.24 | sMAPE for Validation Set is: 17.31% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.80 | sMAPE for Test Set is: 39.13% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:38:30,300]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:38:30,535]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:38:34,469]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:38:37,989]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:38:41,716]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:38:43,287]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:38:54,211]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:39:03,185]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:39:10,022]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:39:13,400]\u001b[0m Trial 240 finished with value: 7.108180316300366 and parameters: {'n_hidden': 3, 'learning_rate': 0.001104082427633021, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3389420992170816, 'dropout_rate_Layer_2': 0.1861177363645003, 'dropout_rate_Layer_3': 0.15087839240552686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00047341125139263113, 'l1_Layer_2': 1.512857978343199e-05, 'l1_Layer_3': 4.81440589083616e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 160, 'n_units_Layer_3': 130}. Best is trial 208 with value: 6.918027241668443.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 16.95% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.94 | sMAPE for Test Set is: 39.73% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:39:17,712]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:39:30,034]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:39:36,346]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:39:42,041]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:39:44,765]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:39:48,707]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:39:51,776]\u001b[0m Trial 233 finished with value: 6.901741282242859 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006551272279310548, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006859840429003079, 'dropout_rate_Layer_2': 0.022902941367218946, 'dropout_rate_Layer_3': 0.17216855856130453, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008046760491569343, 'l1_Layer_2': 0.00010716674272505696, 'l1_Layer_3': 0.0003644075643640452, 'n_units_Layer_1': 105, 'n_units_Layer_2': 155, 'n_units_Layer_3': 100}. Best is trial 233 with value: 6.901741282242859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.90 | sMAPE for Validation Set is: 16.47% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.70 | sMAPE for Test Set is: 35.40% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:39:54,902]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:39:55,219]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:39:59,081]\u001b[0m Trial 235 finished with value: 6.922892972597197 and parameters: {'n_hidden': 3, 'learning_rate': 0.00111218418605626, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01181659573773427, 'dropout_rate_Layer_2': 0.1814110153073874, 'dropout_rate_Layer_3': 0.1748434544546466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001951678251217493, 'l1_Layer_2': 5.7600623707315535e-05, 'l1_Layer_3': 5.524127644090478e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 155, 'n_units_Layer_3': 100}. Best is trial 233 with value: 6.901741282242859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.92 | sMAPE for Validation Set is: 16.44% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.44 | sMAPE for Test Set is: 35.91% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:40:02,103]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:40:05,076]\u001b[0m Trial 243 finished with value: 6.918280088676198 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006381956698103354, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03140247909827987, 'dropout_rate_Layer_2': 0.1876757585397057, 'dropout_rate_Layer_3': 0.15350670867142022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5866975632441988e-05, 'l1_Layer_2': 1.9696122697183464e-05, 'l1_Layer_3': 0.00012952995373378994, 'n_units_Layer_1': 90, 'n_units_Layer_2': 140, 'n_units_Layer_3': 115}. Best is trial 233 with value: 6.901741282242859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.92 | sMAPE for Validation Set is: 16.58% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.82 | sMAPE for Test Set is: 39.17% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:40:25,214]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:40:40,671]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:40:47,173]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:40:50,702]\u001b[0m Trial 254 finished with value: 6.939150070625755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007844701757665949, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009493771326596345, 'dropout_rate_Layer_2': 0.17492673230875277, 'dropout_rate_Layer_3': 0.15350400902261035, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006766987322027679, 'l1_Layer_2': 6.814553122501651e-05, 'l1_Layer_3': 4.918399751088086e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 155, 'n_units_Layer_3': 115}. Best is trial 233 with value: 6.901741282242859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.94 | sMAPE for Validation Set is: 16.57% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.58 | sMAPE for Test Set is: 34.70% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:40:56,888]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:41:03,397]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:41:10,481]\u001b[0m Trial 256 finished with value: 6.920800618027619 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006736305953961591, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0005038336359382365, 'dropout_rate_Layer_2': 0.1783366106600523, 'dropout_rate_Layer_3': 0.1433066137946733, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009042801968894248, 'l1_Layer_2': 1.0137248727277008e-05, 'l1_Layer_3': 0.00015369640702147066, 'n_units_Layer_1': 90, 'n_units_Layer_2': 150, 'n_units_Layer_3': 110}. Best is trial 233 with value: 6.901741282242859.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.92 | sMAPE for Validation Set is: 16.52% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.57 | sMAPE for Test Set is: 33.42% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:41:15,874]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:41:16,215]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:41:26,555]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:41:31,125]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:41:31,400]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:41:37,645]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:41:39,589]\u001b[0m Trial 255 finished with value: 6.829527051146914 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009567459343051192, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013284652234351576, 'dropout_rate_Layer_2': 0.028336407189420293, 'dropout_rate_Layer_3': 0.1728512736499754, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000906082127862887, 'l1_Layer_2': 0.00010232373733827098, 'l1_Layer_3': 0.0002191738986319938, 'n_units_Layer_1': 90, 'n_units_Layer_2': 155, 'n_units_Layer_3': 115}. Best is trial 255 with value: 6.829527051146914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.83 | sMAPE for Validation Set is: 16.27% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.37 | sMAPE for Test Set is: 33.36% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:41:51,363]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:41:55,542]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:42:04,509]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:42:04,909]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:42:10,352]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:42:13,024]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:42:20,048]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:42:22,861]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:42:33,661]\u001b[0m Trial 269 finished with value: 6.954881086371685 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006427184117843985, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0003625423182954963, 'dropout_rate_Layer_2': 0.1547503442370864, 'dropout_rate_Layer_3': 0.14650480461262136, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006647773658683537, 'l1_Layer_2': 1.0321377446733018e-05, 'l1_Layer_3': 7.295412862964134e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 180, 'n_units_Layer_3': 120}. Best is trial 255 with value: 6.829527051146914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.95 | sMAPE for Validation Set is: 16.56% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 15.14 | sMAPE for Test Set is: 34.91% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:42:48,251]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:42:54,616]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:42:59,698]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:43:16,254]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:43:18,148]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:43:35,657]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:43:37,228]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:43:39,354]\u001b[0m Trial 276 finished with value: 6.822567908699509 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009844287704459064, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008528149475387393, 'dropout_rate_Layer_2': 0.016019502318779785, 'dropout_rate_Layer_3': 0.13349062512789622, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008070128474215489, 'l1_Layer_2': 1.4218247337295071e-05, 'l1_Layer_3': 9.073950090720128e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 150, 'n_units_Layer_3': 125}. Best is trial 276 with value: 6.822567908699509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 16.25% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.52 | sMAPE for Test Set is: 35.53% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:43:41,344]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:43:41,497]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:43:42,444]\u001b[0m Trial 272 finished with value: 6.898280543237647 and parameters: {'n_hidden': 3, 'learning_rate': 0.001181787395391972, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00895018253713774, 'dropout_rate_Layer_2': 0.018780209836736218, 'dropout_rate_Layer_3': 0.1327346211306094, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011061459989638615, 'l1_Layer_2': 3.7273370078677224e-05, 'l1_Layer_3': 9.319668145235119e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 140, 'n_units_Layer_3': 125}. Best is trial 276 with value: 6.822567908699509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.90 | sMAPE for Validation Set is: 16.63% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.51 | sMAPE for Test Set is: 34.86% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:43:52,560]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:43:54,156]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:43:57,470]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:44:02,833]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:44:20,830]\u001b[0m Trial 287 finished with value: 7.184228501995847 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010694072498836158, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018182331931726588, 'dropout_rate_Layer_2': 0.03960866456098033, 'dropout_rate_Layer_3': 0.12253220471386589, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005709385189812565, 'l1_Layer_2': 2.0680556099763242e-05, 'l1_Layer_3': 8.775649615728243e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 150, 'n_units_Layer_3': 105}. Best is trial 276 with value: 6.822567908699509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.18 | sMAPE for Validation Set is: 17.33% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.40 | sMAPE for Test Set is: 37.40% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:44:41,532]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:45:00,683]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:45:09,239]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:45:17,091]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:45:26,885]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:45:34,162]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:45:38,205]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:45:43,859]\u001b[0m Trial 289 finished with value: 6.862858941571673 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010919571937091578, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028652631040113542, 'dropout_rate_Layer_2': 0.04114623373343197, 'dropout_rate_Layer_3': 0.13504341981480233, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008866338813064508, 'l1_Layer_2': 9.123582446655883e-05, 'l1_Layer_3': 8.299110164086271e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 135, 'n_units_Layer_3': 135}. Best is trial 276 with value: 6.822567908699509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.86 | sMAPE for Validation Set is: 16.49% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.43 | sMAPE for Test Set is: 34.62% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:45:46,114]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:45:56,219]\u001b[0m Trial 299 finished with value: 7.243842308012911 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013881606169714128, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016441014552583906, 'dropout_rate_Layer_2': 0.03582893151787919, 'dropout_rate_Layer_3': 0.1186401249185038, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008688514593765105, 'l1_Layer_2': 3.256995402730372e-05, 'l1_Layer_3': 4.068296109431041e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 150, 'n_units_Layer_3': 100}. Best is trial 276 with value: 6.822567908699509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.24 | sMAPE for Validation Set is: 17.33% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.36 | sMAPE for Test Set is: 35.45% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:46:07,376]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:46:11,871]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:46:18,094]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:46:21,456]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:46:21,468]\u001b[0m Trial 293 finished with value: 6.918619137294243 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009292986801257429, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009613307519883965, 'dropout_rate_Layer_2': 0.026621540846590203, 'dropout_rate_Layer_3': 0.14912429032279276, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008349506464324336, 'l1_Layer_2': 4.082896344236574e-05, 'l1_Layer_3': 7.098740301797983e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 145, 'n_units_Layer_3': 130}. Best is trial 276 with value: 6.822567908699509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.92 | sMAPE for Validation Set is: 16.68% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.56 | sMAPE for Test Set is: 35.03% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:46:26,243]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:46:34,982]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:46:38,551]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:46:59,247]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:47:05,441]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:47:08,656]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:47:20,505]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:47:39,910]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:47:46,554]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:47:50,311]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:47:54,467]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:48:05,757]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:48:18,113]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:48:40,225]\u001b[0m Trial 320 finished with value: 6.850276265727075 and parameters: {'n_hidden': 3, 'learning_rate': 0.000869312392968028, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02534294402900056, 'dropout_rate_Layer_2': 0.06615889000343617, 'dropout_rate_Layer_3': 0.14011975372114066, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011969051679231243, 'l1_Layer_2': 0.00012155119328859088, 'l1_Layer_3': 0.0001343589940607288, 'n_units_Layer_1': 130, 'n_units_Layer_2': 145, 'n_units_Layer_3': 130}. Best is trial 276 with value: 6.822567908699509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.85 | sMAPE for Validation Set is: 16.41% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.59 | sMAPE for Test Set is: 34.81% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:48:46,682]\u001b[0m Trial 303 finished with value: 6.827687583100641 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006623218801919968, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03165984305707917, 'dropout_rate_Layer_2': 0.026720838163084903, 'dropout_rate_Layer_3': 0.18165518015164087, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001115295157980033, 'l1_Layer_2': 0.00014499068202515175, 'l1_Layer_3': 0.00013871179442389773, 'n_units_Layer_1': 150, 'n_units_Layer_2': 140, 'n_units_Layer_3': 125}. Best is trial 276 with value: 6.822567908699509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.83 | sMAPE for Validation Set is: 16.27% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.43 | sMAPE for Test Set is: 34.64% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:48:50,584]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:48:53,693]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:48:56,209]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:48:56,340]\u001b[0m Trial 321 finished with value: 6.874069746579539 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008502596391181894, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0004211988442961494, 'dropout_rate_Layer_2': 0.19469435236755414, 'dropout_rate_Layer_3': 0.13933312691785193, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008156599758911061, 'l1_Layer_2': 0.00010498863337883682, 'l1_Layer_3': 0.00012864666939399607, 'n_units_Layer_1': 130, 'n_units_Layer_2': 145, 'n_units_Layer_3': 130}. Best is trial 276 with value: 6.822567908699509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.87 | sMAPE for Validation Set is: 16.44% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.54 | sMAPE for Test Set is: 33.71% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:49:01,759]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:49:02,049]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:49:02,424]\u001b[0m Trial 323 finished with value: 6.925448993919505 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011257001185718924, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.042362541095937324, 'dropout_rate_Layer_2': 0.19589427055647882, 'dropout_rate_Layer_3': 0.1950666053689653, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008063178448360212, 'l1_Layer_2': 5.8398890354969153e-05, 'l1_Layer_3': 0.0003203109844235454, 'n_units_Layer_1': 130, 'n_units_Layer_2': 150, 'n_units_Layer_3': 110}. Best is trial 276 with value: 6.822567908699509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.93 | sMAPE for Validation Set is: 16.58% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.67 | sMAPE for Test Set is: 36.17% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:49:07,984]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:49:12,199]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:49:12,628]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:49:24,944]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:49:32,712]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:49:39,458]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:49:44,748]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:49:47,121]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:49:49,549]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:49:52,859]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:49:57,220]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:50:04,225]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:50:08,741]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:50:14,275]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:50:15,595]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:50:18,629]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:50:21,084]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:50:21,605]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:50:27,937]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:50:31,305]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:50:36,976]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:50:40,479]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:50:45,878]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:51:01,364]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:51:06,866]\u001b[0m Trial 334 finished with value: 6.818083055858506 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009475319385792201, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014068227784236019, 'dropout_rate_Layer_2': 0.0001269949745777814, 'dropout_rate_Layer_3': 0.18249347271204597, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008188088667374693, 'l1_Layer_2': 8.291295069874076e-05, 'l1_Layer_3': 0.0004499843322660577, 'n_units_Layer_1': 145, 'n_units_Layer_2': 135, 'n_units_Layer_3': 110}. Best is trial 334 with value: 6.818083055858506.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 16.28% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.41 | sMAPE for Test Set is: 33.43% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:51:20,950]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:51:23,315]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:51:38,511]\u001b[0m Trial 336 finished with value: 6.798748393595996 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005764401389540878, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 7.757069905561798e-05, 'dropout_rate_Layer_2': 0.0014801671999824535, 'dropout_rate_Layer_3': 0.18256533645592998, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006538706089638844, 'l1_Layer_2': 7.963245803898555e-05, 'l1_Layer_3': 0.0002599863106475254, 'n_units_Layer_1': 145, 'n_units_Layer_2': 140, 'n_units_Layer_3': 125}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.80 | sMAPE for Validation Set is: 16.26% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.52 | sMAPE for Test Set is: 35.93% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:51:58,683]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:52:07,019]\u001b[0m Trial 352 finished with value: 6.85848494788011 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009221641373537271, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.033380393534559794, 'dropout_rate_Layer_2': 0.01588857160539784, 'dropout_rate_Layer_3': 0.1434763803721945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015898696145488455, 'l1_Layer_2': 7.829756460163961e-05, 'l1_Layer_3': 0.00012586633750556338, 'n_units_Layer_1': 150, 'n_units_Layer_2': 145, 'n_units_Layer_3': 115}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.86 | sMAPE for Validation Set is: 16.31% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.44 | sMAPE for Test Set is: 35.38% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:52:14,583]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:52:31,745]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:52:37,064]\u001b[0m Trial 358 finished with value: 6.83696065270257 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009062731135605984, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011861872673233553, 'dropout_rate_Layer_2': 0.011880206322411263, 'dropout_rate_Layer_3': 0.19465330144063353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009072436762011468, 'l1_Layer_2': 7.168146285606025e-05, 'l1_Layer_3': 6.178462191796394e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 135, 'n_units_Layer_3': 115}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.84 | sMAPE for Validation Set is: 16.36% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.47 | sMAPE for Test Set is: 33.98% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:52:38,525]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:52:45,597]\u001b[0m Trial 359 finished with value: 6.871139091985852 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009031893566428308, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009870642250475778, 'dropout_rate_Layer_2': 0.011936016328243216, 'dropout_rate_Layer_3': 0.19319968396978837, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008338144606116478, 'l1_Layer_2': 7.804134742807521e-05, 'l1_Layer_3': 0.00042550450647965926, 'n_units_Layer_1': 155, 'n_units_Layer_2': 135, 'n_units_Layer_3': 115}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.87 | sMAPE for Validation Set is: 16.37% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.47 | sMAPE for Test Set is: 34.30% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:52:49,853]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:53:18,165]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:53:32,748]\u001b[0m Trial 361 finished with value: 6.842827511536342 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005969781742149247, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00802980660206445, 'dropout_rate_Layer_2': 0.014605396080054728, 'dropout_rate_Layer_3': 0.19029693015905527, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006742609587785745, 'l1_Layer_2': 8.25007829823351e-05, 'l1_Layer_3': 0.0004449609960332356, 'n_units_Layer_1': 155, 'n_units_Layer_2': 135, 'n_units_Layer_3': 120}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.84 | sMAPE for Validation Set is: 16.30% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.51 | sMAPE for Test Set is: 33.50% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:53:53,311]\u001b[0m Trial 368 finished with value: 6.93711939422112 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009159807673438566, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01040322415626799, 'dropout_rate_Layer_2': 0.009924779792736758, 'dropout_rate_Layer_3': 0.19304502357163056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007328846341931147, 'l1_Layer_2': 7.593620307797748e-05, 'l1_Layer_3': 0.0005824497551514681, 'n_units_Layer_1': 155, 'n_units_Layer_2': 130, 'n_units_Layer_3': 115}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.94 | sMAPE for Validation Set is: 16.57% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.56 | sMAPE for Test Set is: 33.97% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:54:00,977]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:54:26,002]\u001b[0m Trial 370 finished with value: 7.116910330982848 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009500732770137953, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07034902737783412, 'dropout_rate_Layer_2': 0.057798858288108816, 'dropout_rate_Layer_3': 0.2265787441646224, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001245577169779933, 'l1_Layer_2': 5.913076923581113e-05, 'l1_Layer_3': 0.0005627150547257076, 'n_units_Layer_1': 155, 'n_units_Layer_2': 225, 'n_units_Layer_3': 235}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.12 | sMAPE for Validation Set is: 16.88% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.88 | sMAPE for Test Set is: 34.47% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:54:37,343]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:54:51,813]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:55:03,976]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:55:10,921]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:55:16,065]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:55:18,640]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:55:22,502]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:55:28,185]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:55:40,248]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:55:57,304]\u001b[0m Trial 372 finished with value: 6.801608220288872 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005070402902698692, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016215947516252667, 'dropout_rate_Layer_2': 0.011448806964511704, 'dropout_rate_Layer_3': 0.20754133274110992, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007303382358494382, 'l1_Layer_2': 9.057391421846717e-05, 'l1_Layer_3': 0.0006339882081332986, 'n_units_Layer_1': 165, 'n_units_Layer_2': 125, 'n_units_Layer_3': 125}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.80 | sMAPE for Validation Set is: 16.21% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.40 | sMAPE for Test Set is: 35.57% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:55:59,720]\u001b[0m Trial 382 finished with value: 7.713009874330108 and parameters: {'n_hidden': 3, 'learning_rate': 0.07082101464998854, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008486119345367537, 'dropout_rate_Layer_2': 0.2717477194272564, 'dropout_rate_Layer_3': 0.3994196009622848, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.031659455126339185, 'l1_Layer_2': 0.038207575619277956, 'l1_Layer_3': 0.004587483287559538, 'n_units_Layer_1': 280, 'n_units_Layer_2': 275, 'n_units_Layer_3': 165}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.71 | sMAPE for Validation Set is: 18.56% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 15.01 | sMAPE for Test Set is: 48.59% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:56:09,426]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:56:09,664]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:56:15,093]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:56:23,777]\u001b[0m Trial 373 finished with value: 6.806019897558059 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007828706139945946, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016978751673106546, 'dropout_rate_Layer_2': 0.010220876194944613, 'dropout_rate_Layer_3': 0.1831487354468273, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007298372190354531, 'l1_Layer_2': 8.706688950348161e-05, 'l1_Layer_3': 0.0005135400500508707, 'n_units_Layer_1': 165, 'n_units_Layer_2': 125, 'n_units_Layer_3': 125}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 16.23% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.38 | sMAPE for Test Set is: 36.24% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:56:28,124]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:56:38,127]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:56:42,433]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:56:46,853]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:56:48,966]\u001b[0m Trial 389 finished with value: 7.9067946201729375 and parameters: {'n_hidden': 3, 'learning_rate': 0.07052419168599278, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010648896025690132, 'dropout_rate_Layer_2': 0.27860705843620903, 'dropout_rate_Layer_3': 0.3871038228579426, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.91282523626267e-05, 'l1_Layer_2': 0.062097342369692506, 'l1_Layer_3': 0.0038559836407793704, 'n_units_Layer_1': 285, 'n_units_Layer_2': 275, 'n_units_Layer_3': 150}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.91 | sMAPE for Validation Set is: 18.61% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.62 | sMAPE for Test Set is: 43.28% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:56:52,371]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:57:03,269]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:57:10,034]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:57:16,911]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:57:25,723]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:57:25,860]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:57:31,469]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:57:31,962]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:57:48,235]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:57:54,107]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:57:57,360]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:58:15,717]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:58:23,195]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:58:26,541]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:58:32,525]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:58:40,233]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:58:43,766]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:58:58,026]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:58:58,492]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:58:59,134]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:59:15,504]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:59:19,578]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:59:22,190]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:59:27,183]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:59:27,732]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:59:33,391]\u001b[0m Trial 410 finished with value: 7.160029028418788 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011823247671933338, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04958498078731999, 'dropout_rate_Layer_2': 0.08034752203334788, 'dropout_rate_Layer_3': 0.23175979839084626, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002082001020717043, 'l1_Layer_2': 5.9748385358421576e-05, 'l1_Layer_3': 0.0011053670833230224, 'n_units_Layer_1': 175, 'n_units_Layer_2': 240, 'n_units_Layer_3': 250}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.16 | sMAPE for Validation Set is: 17.02% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.52 | sMAPE for Test Set is: 32.01% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:59:33,891]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:59:37,770]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:59:38,604]\u001b[0m Trial 411 finished with value: 7.213057598457212 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018408839676016884, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07628719843675469, 'dropout_rate_Layer_2': 0.05904953109880674, 'dropout_rate_Layer_3': 0.23228907025829323, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020507874106130545, 'l1_Layer_2': 0.00010309173470285437, 'l1_Layer_3': 0.0012159665992640142, 'n_units_Layer_1': 185, 'n_units_Layer_2': 230, 'n_units_Layer_3': 245}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.21 | sMAPE for Validation Set is: 17.31% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.61 | sMAPE for Test Set is: 36.65% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 09:59:45,751]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:59:50,898]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:59:53,917]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 09:59:54,957]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:00:00,208]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:00:03,474]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:00:03,968]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:00:09,001]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:00:09,203]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:00:10,121]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:00:19,334]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:00:23,746]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:00:24,027]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:00:30,164]\u001b[0m Trial 430 finished with value: 8.079600224943356 and parameters: {'n_hidden': 3, 'learning_rate': 0.05079503685371887, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0003285510596077682, 'dropout_rate_Layer_2': 0.27158719325520425, 'dropout_rate_Layer_3': 0.38450179486699326, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010101681540739683, 'l1_Layer_2': 0.06233955123870665, 'l1_Layer_3': 0.0037842762590446716, 'n_units_Layer_1': 275, 'n_units_Layer_2': 275, 'n_units_Layer_3': 150}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.08 | sMAPE for Validation Set is: 19.01% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.59 | sMAPE for Test Set is: 40.57% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:00:30,419]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:00:34,880]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:00:39,014]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:00:44,193]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:00:48,806]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:00:56,340]\u001b[0m Trial 434 finished with value: 7.204303297177373 and parameters: {'n_hidden': 3, 'learning_rate': 0.003042854536570518, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12336341133182849, 'dropout_rate_Layer_2': 0.20802881118526137, 'dropout_rate_Layer_3': 0.2013375888188882, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05286786813293646, 'l1_Layer_2': 0.0009857496675698134, 'l1_Layer_3': 0.0029483566469960336, 'n_units_Layer_1': 200, 'n_units_Layer_2': 135, 'n_units_Layer_3': 165}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.20 | sMAPE for Validation Set is: 17.31% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.75 | sMAPE for Test Set is: 37.56% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:01:09,410]\u001b[0m Trial 441 finished with value: 8.28820646226517 and parameters: {'n_hidden': 3, 'learning_rate': 0.07156019687761803, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01795307630395887, 'dropout_rate_Layer_2': 0.2907097908148192, 'dropout_rate_Layer_3': 0.3596802941234405, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001841548000529726, 'l1_Layer_2': 0.04228644931250429, 'l1_Layer_3': 0.00787300139018469, 'n_units_Layer_1': 280, 'n_units_Layer_2': 300, 'n_units_Layer_3': 165}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.29 | sMAPE for Validation Set is: 19.76% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 16.15 | sMAPE for Test Set is: 43.13% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:01:14,627]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:01:23,067]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:01:33,579]\u001b[0m Trial 444 finished with value: 8.359320534654172 and parameters: {'n_hidden': 3, 'learning_rate': 0.035433411748300565, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03572105103990489, 'dropout_rate_Layer_2': 0.3753267420465342, 'dropout_rate_Layer_3': 0.35838429524288107, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.086899937539169e-05, 'l1_Layer_2': 0.03411363097939427, 'l1_Layer_3': 0.001749429250898322, 'n_units_Layer_1': 260, 'n_units_Layer_2': 255, 'n_units_Layer_3': 130}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.36 | sMAPE for Validation Set is: 20.58% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 15.84 | sMAPE for Test Set is: 42.28% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:01:39,867]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:01:44,214]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:01:55,719]\u001b[0m Trial 442 finished with value: 7.223907273628193 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009372740472520608, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0727207481195795, 'dropout_rate_Layer_2': 0.03299269519993625, 'dropout_rate_Layer_3': 0.20420450030104156, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015044610624358455, 'l1_Layer_2': 4.827013916709937e-05, 'l1_Layer_3': 0.0004301127937148124, 'n_units_Layer_1': 195, 'n_units_Layer_2': 220, 'n_units_Layer_3': 245}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 17.14% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.07 | sMAPE for Test Set is: 35.66% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:02:08,309]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:02:13,881]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:02:18,349]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:02:26,639]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:02:28,452]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:02:30,874]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:02:33,417]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:02:35,065]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:02:38,964]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:02:43,262]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:02:47,472]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:02:49,925]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:02:51,785]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:02:54,868]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:02:55,415]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:02:55,744]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:02:57,399]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:02,737]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:03,165]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:03,475]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:08,799]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:10,152]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:13,359]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:14,562]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:17,140]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:19,192]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:19,732]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:21,431]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:27,833]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:28,344]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:32,215]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:36,531]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:40,529]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:42,536]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:45,425]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:03:59,526]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:04:09,587]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:04:17,047]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:04:17,750]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:04:22,368]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:04:32,202]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:04:42,925]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:04:54,047]\u001b[0m Trial 484 finished with value: 7.426676814951267 and parameters: {'n_hidden': 3, 'learning_rate': 0.001388355578236014, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31463506376861594, 'dropout_rate_Layer_2': 0.19936514466625185, 'dropout_rate_Layer_3': 0.2459068909666731, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.2464197413873584e-05, 'l1_Layer_2': 0.03155437508649297, 'l1_Layer_3': 0.0022207883565277, 'n_units_Layer_1': 145, 'n_units_Layer_2': 70, 'n_units_Layer_3': 105}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.43 | sMAPE for Validation Set is: 17.86% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 14.80 | sMAPE for Test Set is: 37.30% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:04:57,957]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:04:58,734]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:05:03,800]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:05:07,816]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:05:10,725]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:05:13,655]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:05:17,604]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:05:24,749]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:05:27,857]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:05:33,979]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:05:38,888]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:05:42,572]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:05:45,540]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:05:48,923]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:05:51,855]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:05:57,017]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:06:00,642]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:06:03,769]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:06:08,060]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:06:13,491]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:06:13,881]\u001b[0m Trial 493 finished with value: 7.128871516106959 and parameters: {'n_hidden': 3, 'learning_rate': 0.000746593717854717, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031334816270388574, 'dropout_rate_Layer_2': 0.07185026954994825, 'dropout_rate_Layer_3': 0.2332217684583686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001933596970355947, 'l1_Layer_2': 4.6573593312410394e-05, 'l1_Layer_3': 0.0008029663606434528, 'n_units_Layer_1': 215, 'n_units_Layer_2': 230, 'n_units_Layer_3': 215}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.13 | sMAPE for Validation Set is: 16.89% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.81 | sMAPE for Test Set is: 34.91% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:06:19,888]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:06:20,308]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:06:23,692]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:06:26,980]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:06:29,953]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:06:34,070]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:06:39,039]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:06:50,483]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:06:53,691]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:07:07,465]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:07:13,166]\u001b[0m Trial 516 finished with value: 7.237832205617451 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009224929278912204, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07046582427103282, 'dropout_rate_Layer_2': 0.061841967112848506, 'dropout_rate_Layer_3': 0.24735521957136883, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013543428283869395, 'l1_Layer_2': 0.00015114038767505037, 'l1_Layer_3': 0.0005162757910961402, 'n_units_Layer_1': 235, 'n_units_Layer_2': 215, 'n_units_Layer_3': 235}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.24 | sMAPE for Validation Set is: 17.12% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.94 | sMAPE for Test Set is: 34.42% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:07:24,716]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:07:34,731]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:07:38,140]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:07:42,903]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:07:49,269]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:07:53,670]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:07:54,126]\u001b[0m Trial 497 finished with value: 7.408303009682306 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006340721438513485, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34006587532241683, 'dropout_rate_Layer_2': 0.19777179356621788, 'dropout_rate_Layer_3': 0.23663238907397183, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.9428091759609853e-05, 'l1_Layer_2': 0.047587226700208395, 'l1_Layer_3': 0.003538109252617218, 'n_units_Layer_1': 145, 'n_units_Layer_2': 70, 'n_units_Layer_3': 105}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.41 | sMAPE for Validation Set is: 17.85% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.79 | sMAPE for Test Set is: 37.07% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:07:59,474]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:08:02,517]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:08:06,523]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:08:08,522]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:08:14,021]\u001b[0m Trial 524 finished with value: 7.248858685758749 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009486462184663375, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01610497488561785, 'dropout_rate_Layer_2': 0.09196877381372151, 'dropout_rate_Layer_3': 0.24625372747612984, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012357946101362988, 'l1_Layer_2': 0.00017555231271787863, 'l1_Layer_3': 0.0004961222507728234, 'n_units_Layer_1': 230, 'n_units_Layer_2': 300, 'n_units_Layer_3': 215}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.25 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.46 | sMAPE for Test Set is: 34.19% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:08:15,947]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:08:18,272]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:08:20,520]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:08:23,907]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:08:31,033]\u001b[0m Trial 525 finished with value: 7.339591315196657 and parameters: {'n_hidden': 3, 'learning_rate': 0.001129713652516244, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35513300692119376, 'dropout_rate_Layer_2': 0.14036604942155778, 'dropout_rate_Layer_3': 0.2817808819132551, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015552357050883025, 'l1_Layer_2': 0.029196209860223837, 'l1_Layer_3': 0.0004682765978837532, 'n_units_Layer_1': 130, 'n_units_Layer_2': 65, 'n_units_Layer_3': 130}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.34 | sMAPE for Validation Set is: 17.80% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.69 | sMAPE for Test Set is: 38.19% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:08:33,911]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:08:36,023]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:08:38,663]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:08:43,059]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:08:53,456]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:09:08,729]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:09:08,938]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:09:24,716]\u001b[0m Trial 546 finished with value: 7.930618304866653 and parameters: {'n_hidden': 3, 'learning_rate': 0.0848812136624313, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04496098078852395, 'dropout_rate_Layer_2': 0.23946758227177564, 'dropout_rate_Layer_3': 0.36860211652842473, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.504865644258383e-05, 'l1_Layer_2': 0.0263123650820448, 'l1_Layer_3': 0.006199375940046712, 'n_units_Layer_1': 185, 'n_units_Layer_2': 50, 'n_units_Layer_3': 135}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.93 | sMAPE for Validation Set is: 19.23% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.47 | sMAPE for Test Set is: 46.42% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:09:33,534]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:09:33,795]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:09:38,990]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:09:39,503]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:09:39,887]\u001b[0m Trial 538 finished with value: 7.093220077497777 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010334668332063115, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3111195095240926, 'dropout_rate_Layer_2': 0.14268449996388333, 'dropout_rate_Layer_3': 0.27687562164852186, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04113413931164302, 'l1_Layer_2': 0.03736082456327674, 'l1_Layer_3': 0.0045209816211962345, 'n_units_Layer_1': 85, 'n_units_Layer_2': 70, 'n_units_Layer_3': 130}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.09 | sMAPE for Validation Set is: 17.06% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.77 | sMAPE for Test Set is: 37.40% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:09:47,450]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:09:50,073]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:09:53,090]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:10:13,404]\u001b[0m Trial 549 finished with value: 7.189159785087327 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007649445656932111, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.043798152153033156, 'dropout_rate_Layer_2': 0.3727072230109055, 'dropout_rate_Layer_3': 0.21267716511832385, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018287014468558337, 'l1_Layer_2': 0.0002120907918649522, 'l1_Layer_3': 0.00039798947433027494, 'n_units_Layer_1': 220, 'n_units_Layer_2': 280, 'n_units_Layer_3': 255}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.19 | sMAPE for Validation Set is: 16.96% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.66 | sMAPE for Test Set is: 33.60% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:10:18,108]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:10:18,279]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:10:23,089]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:10:25,919]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:10:31,539]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:10:36,634]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:10:40,480]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:10:43,356]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:10:43,623]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:10:49,056]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:10:49,259]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:10:49,399]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:10:56,289]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:10:56,677]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:10:57,385]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:11:03,890]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:11:06,656]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:11:09,090]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:11:09,807]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:11:14,486]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:11:39,619]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:11:45,260]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:11:54,786]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:12:09,293]\u001b[0m Trial 573 finished with value: 7.199355877595686 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007192009315403776, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2869670561516916, 'dropout_rate_Layer_2': 0.14947148052530893, 'dropout_rate_Layer_3': 0.2736850044951066, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.040271066259625524, 'l1_Layer_2': 0.0069395256730695395, 'l1_Layer_3': 0.016228632610640552, 'n_units_Layer_1': 125, 'n_units_Layer_2': 50, 'n_units_Layer_3': 135}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.20 | sMAPE for Validation Set is: 17.23% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.78 | sMAPE for Test Set is: 38.15% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:12:22,356]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:12:25,599]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:12:28,359]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:12:32,721]\u001b[0m Trial 576 finished with value: 7.293461791274713 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008481299824971302, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29244724634303504, 'dropout_rate_Layer_2': 0.14853163845417724, 'dropout_rate_Layer_3': 0.27930717521194715, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04359305360912502, 'l1_Layer_2': 0.010357788014556155, 'l1_Layer_3': 0.013545696726815399, 'n_units_Layer_1': 120, 'n_units_Layer_2': 55, 'n_units_Layer_3': 145}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.29 | sMAPE for Validation Set is: 17.44% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.66 | sMAPE for Test Set is: 38.21% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:12:35,516]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:12:38,966]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:12:43,317]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:12:44,812]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:12:47,674]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:12:54,907]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:01,523]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:05,102]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:08,007]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:12,563]\u001b[0m Trial 581 finished with value: 7.269252180380529 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008525997106518339, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2854202891890329, 'dropout_rate_Layer_2': 0.15451832969628734, 'dropout_rate_Layer_3': 0.27071717820005636, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04125267307849521, 'l1_Layer_2': 0.0072203022517008395, 'l1_Layer_3': 0.016321267373837853, 'n_units_Layer_1': 120, 'n_units_Layer_2': 55, 'n_units_Layer_3': 135}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.27 | sMAPE for Validation Set is: 17.43% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.76 | sMAPE for Test Set is: 38.23% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:13:14,369]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:18,561]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:22,556]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:25,603]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:26,177]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:26,565]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:32,549]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:34,363]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:35,212]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:37,851]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:41,625]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:41,830]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:47,308]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:52,386]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:13:57,560]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:14:00,411]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:14:03,684]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:14:06,688]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:14:10,154]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:14:13,177]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:14:30,997]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:14:34,368]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:14:36,511]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:14:39,761]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:14:54,363]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:14:59,017]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:02,133]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:05,158]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:08,400]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:11,992]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:13,837]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:20,706]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:23,449]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:26,272]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:28,305]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:30,356]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:33,435]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:34,627]\u001b[0m Trial 578 finished with value: 6.821179321609175 and parameters: {'n_hidden': 3, 'learning_rate': 0.001067228360894794, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007909538129550494, 'dropout_rate_Layer_2': 0.007915421283646239, 'dropout_rate_Layer_3': 0.1434722703985265, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004828624041984997, 'l1_Layer_2': 1.81665782367743e-05, 'l1_Layer_3': 7.558064820210776e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 145, 'n_units_Layer_3': 135}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 16.41% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.48 | sMAPE for Test Set is: 34.24% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:15:37,640]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:39,475]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:45,214]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:48,201]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:50,998]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:52,898]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:15:56,337]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:16:00,845]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:16:05,524]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:16:05,833]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:16:09,537]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:16:13,056]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:16:18,411]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:16:25,068]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:16:28,012]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:16:28,115]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:16:39,060]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:16:44,009]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:16:48,466]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:16:51,739]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:16:59,016]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:02,812]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:11,382]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:14,983]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:17,522]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:22,300]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:22,535]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:23,047]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:29,683]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:30,244]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:30,313]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:36,004]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:36,383]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:41,397]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:45,261]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:47,684]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:50,011]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:53,864]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:56,529]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:17:59,278]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:18:01,986]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:18:04,944]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:18:05,226]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:18:09,887]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:18:17,748]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:18:21,706]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:18:24,779]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:18:27,842]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:18:31,053]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:18:36,698]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:18:37,334]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:18:42,277]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:18:42,829]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:18:48,206]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:18:48,394]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.35 | sMAPE for Validation Set is: 17.35% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.81 | sMAPE for Test Set is: 36.37% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:18:51,479]\u001b[0m Trial 676 finished with value: 7.3496172733280245 and parameters: {'n_hidden': 3, 'learning_rate': 0.001186296799278021, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15812922337666718, 'dropout_rate_Layer_2': 0.35611563482649217, 'dropout_rate_Layer_3': 0.35445617635015203, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0027769829678086964, 'l1_Layer_2': 4.72453917677355e-05, 'l1_Layer_3': 0.0005867953718951182, 'n_units_Layer_1': 225, 'n_units_Layer_2': 220, 'n_units_Layer_3': 260}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:18:56,073]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:18:58,496]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:00,464]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:06,230]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:09,102]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:13,667]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:17,614]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:20,562]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:26,088]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:26,437]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:31,368]\u001b[0m Trial 695 finished with value: 8.140234391782537 and parameters: {'n_hidden': 3, 'learning_rate': 0.035333640997483075, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029689415834213348, 'dropout_rate_Layer_2': 0.3998779109285757, 'dropout_rate_Layer_3': 0.357800758808605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7985437382087564e-05, 'l1_Layer_2': 0.035500631109949235, 'l1_Layer_3': 0.0015390540758811486, 'n_units_Layer_1': 255, 'n_units_Layer_2': 255, 'n_units_Layer_3': 130}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.14 | sMAPE for Validation Set is: 19.46% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 15.59 | sMAPE for Test Set is: 44.60% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:19:33,413]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:37,218]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:40,504]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:43,698]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:46,439]\u001b[0m Trial 693 finished with value: 7.254168965734361 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017631347364698857, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.052732498544025244, 'dropout_rate_Layer_2': 0.3605298941491491, 'dropout_rate_Layer_3': 0.3549059196184862, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0038215954435237374, 'l1_Layer_2': 3.45960627931457e-05, 'l1_Layer_3': 0.00033780494228279745, 'n_units_Layer_1': 235, 'n_units_Layer_2': 225, 'n_units_Layer_3': 265}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.25 | sMAPE for Validation Set is: 17.27% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.64 | sMAPE for Test Set is: 34.40% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:19:47,149]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:47,353]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:51,617]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:52,046]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:52,385]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:52,482]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:19:59,343]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:01,632]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:01,774]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:02,619]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:08,092]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:09,577]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:12,030]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:14,686]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:15,017]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:15,547]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:20,573]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:23,693]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:24,671]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:29,294]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:31,841]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:32,099]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:39,912]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:40,228]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:44,560]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:44,692]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:49,599]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:52,790]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:52,994]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:53,663]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:20:53,700]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:01,619]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:01,778]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:02,160]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:02,290]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:08,873]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:09,527]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:09,582]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:12,046]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:18,518]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:18,974]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:19,147]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:19,682]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:26,248]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:28,791]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:33,299]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:39,567]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:44,838]\u001b[0m Trial 751 finished with value: 8.181423109434615 and parameters: {'n_hidden': 3, 'learning_rate': 0.04255625143904236, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03507258347155618, 'dropout_rate_Layer_2': 0.37850079348154725, 'dropout_rate_Layer_3': 0.35799876350845583, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2761808025416363e-05, 'l1_Layer_2': 0.03267432952622381, 'l1_Layer_3': 0.001639533208969596, 'n_units_Layer_1': 260, 'n_units_Layer_2': 255, 'n_units_Layer_3': 130}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.18 | sMAPE for Validation Set is: 19.16% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 16.13 | sMAPE for Test Set is: 42.05% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:21:47,965]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:50,739]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:51,406]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:55,316]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:21:59,099]\u001b[0m Trial 752 finished with value: 7.662500371247031 and parameters: {'n_hidden': 3, 'learning_rate': 0.001976525722926515, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1408525437356839, 'dropout_rate_Layer_2': 0.34936162183630737, 'dropout_rate_Layer_3': 0.35148866763840425, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025454268592194013, 'l1_Layer_2': 4.5139574416002234e-05, 'l1_Layer_3': 0.0007637282722432916, 'n_units_Layer_1': 225, 'n_units_Layer_2': 225, 'n_units_Layer_3': 255}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.66 | sMAPE for Validation Set is: 18.23% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 15.03 | sMAPE for Test Set is: 33.12% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:22:04,348]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:22:07,538]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:22:11,239]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:22:18,116]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:22:33,512]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:22:46,738]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:22:50,366]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:22:52,588]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:23:00,896]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:23:01,566]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:23:06,739]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:23:06,987]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:23:17,422]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:23:26,983]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:23:30,476]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:23:46,562]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:23:52,642]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:23:58,401]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:07,140]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:07,608]\u001b[0m Trial 767 finished with value: 7.16776101575828 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016228325478700398, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05407400675738194, 'dropout_rate_Layer_2': 0.37275213402872853, 'dropout_rate_Layer_3': 0.3654733013438225, 'dropout_rate_Layer_4': 0.11283680221436353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010527567726290214, 'l1_Layer_2': 0.00027141282510994744, 'l1_Layer_3': 0.0004817476161299875, 'l1_Layer_4': 0.00042016216433314184, 'n_units_Layer_1': 230, 'n_units_Layer_2': 285, 'n_units_Layer_3': 270, 'n_units_Layer_4': 265}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.17 | sMAPE for Validation Set is: 17.41% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.09 | sMAPE for Test Set is: 36.42% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:24:11,369]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:12,923]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:15,650]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:16,111]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:16,885]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:22,195]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:22,937]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:23,985]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:28,515]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:31,079]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:31,900]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:36,972]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:40,096]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:43,187]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:43,625]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:48,814]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:52,106]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:24:56,051]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:25:10,715]\u001b[0m Trial 787 finished with value: 7.320294413574359 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013653706617509727, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06088370345855347, 'dropout_rate_Layer_2': 0.3669856813158914, 'dropout_rate_Layer_3': 0.35258750810861716, 'dropout_rate_Layer_4': 0.10151991143203183, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.237509982545849e-05, 'l1_Layer_2': 0.00017744868691414446, 'l1_Layer_3': 0.0003774390095553894, 'l1_Layer_4': 0.0005047948620905314, 'n_units_Layer_1': 220, 'n_units_Layer_2': 300, 'n_units_Layer_3': 280, 'n_units_Layer_4': 260}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.32 | sMAPE for Validation Set is: 17.62% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 15.48 | sMAPE for Test Set is: 35.10% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:25:15,597]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:25:17,848]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:25:22,148]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:25:22,347]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:25:28,286]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.89 | sMAPE for Validation Set is: 16.45% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.51 | sMAPE for Test Set is: 34.36% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:25:29,986]\u001b[0m Trial 757 finished with value: 6.885891327529424 and parameters: {'n_hidden': 3, 'learning_rate': 0.000714289207227303, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00608862255341758, 'dropout_rate_Layer_2': 0.0248432373566895, 'dropout_rate_Layer_3': 0.17121606517361213, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007621506709250372, 'l1_Layer_2': 0.0005641225473771975, 'l1_Layer_3': 0.000644691409986709, 'n_units_Layer_1': 150, 'n_units_Layer_2': 145, 'n_units_Layer_3': 110}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:25:33,932]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:25:34,279]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:25:36,410]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:25:53,182]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:25:53,861]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:26:01,429]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:26:11,547]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:26:12,267]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:26:16,979]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:26:21,215]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:26:23,363]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:26:26,370]\u001b[0m Trial 794 finished with value: 7.179778498372329 and parameters: {'n_hidden': 3, 'learning_rate': 0.001355826591679694, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.051881772381667926, 'dropout_rate_Layer_2': 0.3489821215150023, 'dropout_rate_Layer_3': 0.3596951981560343, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029001880012211636, 'l1_Layer_2': 0.00023548798714486077, 'l1_Layer_3': 3.3825287528688144e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 285, 'n_units_Layer_3': 280}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.18 | sMAPE for Validation Set is: 17.03% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.54 | sMAPE for Test Set is: 34.96% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:26:32,219]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:26:32,329]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:26:38,970]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:26:43,379]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:26:50,623]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:26:53,630]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:26:58,436]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:27:05,330]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:27:08,280]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:27:16,303]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:27:21,491]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:27:27,526]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:27:31,627]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:27:33,550]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:27:33,805]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:27:41,457]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:27:45,045]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:27:48,673]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:27:51,333]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:27:54,388]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:28:07,472]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:28:11,544]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:28:13,140]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:28:16,026]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:28:20,637]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:29:17,029]\u001b[0m Trial 840 finished with value: 7.7501455761778075 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010910697924290955, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03361897857655419, 'dropout_rate_Layer_2': 0.3331255332866029, 'dropout_rate_Layer_3': 0.3612768168303422, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.246351980868369e-05, 'l1_Layer_2': 0.03434643077926766, 'l1_Layer_3': 0.0028548199704776585, 'n_units_Layer_1': 255, 'n_units_Layer_2': 255, 'n_units_Layer_3': 155}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.75 | sMAPE for Validation Set is: 18.23% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 15.28 | sMAPE for Test Set is: 35.63% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:29:20,509]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:29:28,335]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:29:54,428]\u001b[0m Trial 830 finished with value: 6.904813199812473 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011965186624012325, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00015359518957427237, 'dropout_rate_Layer_2': 0.011671667691717218, 'dropout_rate_Layer_3': 0.18266921273594555, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008738866319420887, 'l1_Layer_2': 0.00011279396859471868, 'l1_Layer_3': 0.0006530555918594634, 'n_units_Layer_1': 140, 'n_units_Layer_2': 140, 'n_units_Layer_3': 125}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.90 | sMAPE for Validation Set is: 16.58% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.48 | sMAPE for Test Set is: 34.94% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:29:59,487]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:30:05,865]\u001b[0m Trial 841 finished with value: 7.199113095778993 and parameters: {'n_hidden': 3, 'learning_rate': 0.001064498932961173, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06760015668186353, 'dropout_rate_Layer_2': 0.35149998986900166, 'dropout_rate_Layer_3': 0.32964358740412075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.229578689084237e-05, 'l1_Layer_2': 0.00021451275605731125, 'l1_Layer_3': 0.0010482483848492723, 'n_units_Layer_1': 230, 'n_units_Layer_2': 295, 'n_units_Layer_3': 190}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.20 | sMAPE for Validation Set is: 17.12% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.04 | sMAPE for Test Set is: 34.53% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:30:11,298]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:30:22,382]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:31:00,096]\u001b[0m Trial 844 finished with value: 7.228789446176319 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010460406352291991, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06851539266964239, 'dropout_rate_Layer_2': 0.37605775427758137, 'dropout_rate_Layer_3': 0.37874869328483324, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.312720094305459e-05, 'l1_Layer_2': 0.00019882166236893294, 'l1_Layer_3': 0.001117516373311481, 'n_units_Layer_1': 265, 'n_units_Layer_2': 295, 'n_units_Layer_3': 190}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.23 | sMAPE for Validation Set is: 17.21% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.97 | sMAPE for Test Set is: 36.32% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:31:07,900]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:31:08,950]\u001b[0m Trial 807 finished with value: 6.874116637162878 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006144519641088393, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 8.404571766004384e-05, 'dropout_rate_Layer_2': 0.024368167839156338, 'dropout_rate_Layer_3': 0.18207847735300253, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000999390229691287, 'l1_Layer_2': 0.00036594913610581994, 'l1_Layer_3': 0.0008082170627801822, 'n_units_Layer_1': 155, 'n_units_Layer_2': 135, 'n_units_Layer_3': 100}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.87 | sMAPE for Validation Set is: 16.41% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.52 | sMAPE for Test Set is: 34.14% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:31:15,305]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:31:26,952]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:31:51,191]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:31:55,895]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:32:07,761]\u001b[0m Trial 854 finished with value: 7.838394206258393 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021001131852100828, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02118509881284511, 'dropout_rate_Layer_2': 0.33558256771885175, 'dropout_rate_Layer_3': 0.38793194658862656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.88510820224661e-05, 'l1_Layer_2': 0.044591902448081734, 'l1_Layer_3': 0.0024185571421531733, 'n_units_Layer_1': 200, 'n_units_Layer_2': 245, 'n_units_Layer_3': 155}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.84 | sMAPE for Validation Set is: 18.47% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 15.39 | sMAPE for Test Set is: 36.26% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:32:10,240]\u001b[0m Trial 852 finished with value: 7.23482383383719 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010439466296416264, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3261038821758309, 'dropout_rate_Layer_2': 0.16153029763543708, 'dropout_rate_Layer_3': 0.33045352749471213, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004160466267477783, 'l1_Layer_2': 0.0015585276160610406, 'l1_Layer_3': 0.06060359556559513, 'n_units_Layer_1': 165, 'n_units_Layer_2': 95, 'n_units_Layer_3': 95}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.23 | sMAPE for Validation Set is: 17.33% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.62 | sMAPE for Test Set is: 37.30% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:32:15,384]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:32:18,429]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:32:30,962]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:32:39,272]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:32:45,018]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:33:02,111]\u001b[0m Trial 849 finished with value: 6.876728639988926 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014031937414901178, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006925771987409474, 'dropout_rate_Layer_2': 0.015253956092268948, 'dropout_rate_Layer_3': 0.1626190111227049, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009026796302701296, 'l1_Layer_2': 0.00011724833394909028, 'l1_Layer_3': 0.0001271006039266834, 'n_units_Layer_1': 140, 'n_units_Layer_2': 145, 'n_units_Layer_3': 135}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.88 | sMAPE for Validation Set is: 16.59% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.45 | sMAPE for Test Set is: 36.50% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:33:02,357]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:33:11,509]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:33:19,187]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:33:24,746]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:33:27,710]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:33:31,174]\u001b[0m Trial 859 finished with value: 7.435370013292054 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018905369260047969, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02585979775658196, 'dropout_rate_Layer_2': 0.33857250907106096, 'dropout_rate_Layer_3': 0.3847890124794053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.0852477483495914e-05, 'l1_Layer_2': 0.0017172497125162959, 'l1_Layer_3': 0.002367532849602368, 'n_units_Layer_1': 190, 'n_units_Layer_2': 245, 'n_units_Layer_3': 155}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.44 | sMAPE for Validation Set is: 17.85% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 14.84 | sMAPE for Test Set is: 36.00% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:33:35,553]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:33:44,706]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:33:47,729]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:33:58,409]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:34:32,246]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:34:35,591]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:34:41,413]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:34:41,650]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:35:11,787]\u001b[0m Trial 873 finished with value: 7.33176825966471 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009858440075449558, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09274404529336462, 'dropout_rate_Layer_2': 0.37517910164677837, 'dropout_rate_Layer_3': 0.3542379286410108, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.373751658490082e-05, 'l1_Layer_2': 0.0001716219570055856, 'l1_Layer_3': 0.0007587883046701291, 'n_units_Layer_1': 250, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.33 | sMAPE for Validation Set is: 17.43% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 15.64 | sMAPE for Test Set is: 36.85% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:35:18,970]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:35:23,671]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:35:31,059]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:35:36,051]\u001b[0m Trial 868 finished with value: 7.280189037362125 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009642924472993133, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06882354767824306, 'dropout_rate_Layer_2': 0.3584200381388091, 'dropout_rate_Layer_3': 0.36675134815782884, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.218337493640133e-05, 'l1_Layer_2': 0.00019685247983443506, 'l1_Layer_3': 0.0009477562141917655, 'n_units_Layer_1': 265, 'n_units_Layer_2': 290, 'n_units_Layer_3': 200}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.28 | sMAPE for Validation Set is: 17.67% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 15.52 | sMAPE for Test Set is: 35.47% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:35:43,321]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:36:16,478]\u001b[0m Trial 880 finished with value: 7.220718284818713 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020923765482372867, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0914610458472939, 'dropout_rate_Layer_2': 0.15904806090842366, 'dropout_rate_Layer_3': 0.3354933261193089, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008822760339363857, 'l1_Layer_2': 0.003042106206892231, 'l1_Layer_3': 0.034330213542986515, 'n_units_Layer_1': 165, 'n_units_Layer_2': 60, 'n_units_Layer_3': 135}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 17.36% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.70 | sMAPE for Test Set is: 37.65% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:36:23,541]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:36:39,480]\u001b[0m Trial 884 finished with value: 7.197579244046682 and parameters: {'n_hidden': 3, 'learning_rate': 0.002130175328749022, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09447147450410358, 'dropout_rate_Layer_2': 0.15982981499615426, 'dropout_rate_Layer_3': 0.39820502704771993, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001789365350785411, 'l1_Layer_2': 0.0008323380778626169, 'l1_Layer_3': 0.036944434460767325, 'n_units_Layer_1': 220, 'n_units_Layer_2': 60, 'n_units_Layer_3': 130}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.20 | sMAPE for Validation Set is: 17.27% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.66 | sMAPE for Test Set is: 37.14% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:36:44,450]\u001b[0m Trial 877 finished with value: 6.878523640477234 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007998902218602381, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019055247904390372, 'dropout_rate_Layer_2': 0.02482562624823262, 'dropout_rate_Layer_3': 0.13589613346895751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023276167388561767, 'l1_Layer_2': 0.00016995834049895371, 'l1_Layer_3': 0.00014702416724255817, 'n_units_Layer_1': 150, 'n_units_Layer_2': 145, 'n_units_Layer_3': 125}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.88 | sMAPE for Validation Set is: 16.64% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.52 | sMAPE for Test Set is: 36.37% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:36:50,064]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:37:03,588]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:37:07,595]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:37:11,490]\u001b[0m Trial 882 finished with value: 7.325886895697654 and parameters: {'n_hidden': 3, 'learning_rate': 0.001167162745354157, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24365410453407665, 'dropout_rate_Layer_2': 0.3759728341760798, 'dropout_rate_Layer_3': 0.39446990852321673, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.5250117429815385e-05, 'l1_Layer_2': 0.00034003913396383903, 'l1_Layer_3': 0.0007521876128377045, 'n_units_Layer_1': 275, 'n_units_Layer_2': 295, 'n_units_Layer_3': 170}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.33 | sMAPE for Validation Set is: 17.33% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 15.31 | sMAPE for Test Set is: 36.78% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:37:12,255]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:37:16,377]\u001b[0m Trial 889 finished with value: 7.654252185741616 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028253996900949193, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03569233048391821, 'dropout_rate_Layer_2': 0.33249178803422563, 'dropout_rate_Layer_3': 0.39141210590445474, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.908823109658106e-05, 'l1_Layer_2': 0.002779483656345524, 'l1_Layer_3': 1.6240407272626584e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 250, 'n_units_Layer_3': 155}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.65 | sMAPE for Validation Set is: 18.24% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 15.16 | sMAPE for Test Set is: 36.69% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:37:21,897]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:37:26,690]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:37:37,204]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:37:37,422]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:37:38,146]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:37:44,087]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:37:49,031]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:37:51,727]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:37:59,577]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:38:02,310]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:38:04,942]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:38:09,274]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:38:10,174]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:38:17,287]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:38:24,280]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:38:29,638]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:38:34,898]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:38:40,202]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:38:44,250]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:38:50,108]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:38:57,354]\u001b[0m Trial 907 finished with value: 7.274765476035007 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027115996579404286, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09179080245581187, 'dropout_rate_Layer_2': 0.1772884625291091, 'dropout_rate_Layer_3': 0.34947164681715037, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009005391088621906, 'l1_Layer_2': 0.0031935049196784708, 'l1_Layer_3': 0.02573526634761004, 'n_units_Layer_1': 170, 'n_units_Layer_2': 85, 'n_units_Layer_3': 300}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.27 | sMAPE for Validation Set is: 17.64% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.86 | sMAPE for Test Set is: 40.11% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:39:02,325]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:39:13,784]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:39:14,152]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:39:36,093]\u001b[0m Trial 908 finished with value: 7.3852241990441945 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009947293922411423, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23855489245380454, 'dropout_rate_Layer_2': 0.3872459018091893, 'dropout_rate_Layer_3': 0.3945243006513809, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.4561550737097706e-05, 'l1_Layer_2': 0.0002877755014594571, 'l1_Layer_3': 0.0006844163638750365, 'n_units_Layer_1': 270, 'n_units_Layer_2': 280, 'n_units_Layer_3': 195}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.39 | sMAPE for Validation Set is: 17.76% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 15.23 | sMAPE for Test Set is: 36.48% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:39:53,582]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:39:59,309]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:40:02,073]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:40:04,843]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:40:13,627]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:40:27,193]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:40:30,350]\u001b[0m Trial 919 finished with value: 7.2215481133745145 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016514980442782481, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04483045332922029, 'dropout_rate_Layer_2': 0.33137668888133087, 'dropout_rate_Layer_3': 0.39308799791543575, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1397894347288537e-05, 'l1_Layer_2': 0.000706132818290954, 'l1_Layer_3': 1.0023967063688527e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 230, 'n_units_Layer_3': 155}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 17.31% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.74 | sMAPE for Test Set is: 39.40% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:40:38,972]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:41:09,919]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:41:17,516]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:41:25,405]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:41:25,775]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:41:32,235]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:41:36,853]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:41:43,629]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:41:53,736]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:41:53,861]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:41:54,707]\u001b[0m Trial 925 finished with value: 7.382484537807035 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023761041312617957, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04042556197726453, 'dropout_rate_Layer_2': 0.33227162112511266, 'dropout_rate_Layer_3': 0.3929653260874113, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0236915504220662e-05, 'l1_Layer_2': 0.0019384002047018389, 'l1_Layer_3': 1.548621958633438e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 110, 'n_units_Layer_3': 155}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.38 | sMAPE for Validation Set is: 17.77% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 15.00 | sMAPE for Test Set is: 39.14% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:42:08,005]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:42:18,975]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:42:21,479]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:42:22,497]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:42:34,720]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:42:37,724]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:42:50,854]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:43:07,671]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:43:08,191]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:43:19,200]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:44:44,646]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:44:47,330]\u001b[0m Trial 945 finished with value: 7.293562692883296 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008228493164703489, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2206672763612585, 'dropout_rate_Layer_2': 0.37818223691514075, 'dropout_rate_Layer_3': 0.3738705592822501, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.9039084918023e-05, 'l1_Layer_2': 0.0016258618975378768, 'l1_Layer_3': 0.00036636277884587377, 'n_units_Layer_1': 135, 'n_units_Layer_2': 300, 'n_units_Layer_3': 200}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.29 | sMAPE for Validation Set is: 17.48% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.59 | sMAPE for Test Set is: 35.39% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:44:47,560]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:44:51,787]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:44:56,976]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:45:01,945]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:45:02,727]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:45:08,285]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:45:11,469]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:45:14,049]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:45:17,907]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:45:21,143]\u001b[0m Trial 924 finished with value: 6.966780356896879 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009191987165690027, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025949317879613687, 'dropout_rate_Layer_2': 0.01950812829313674, 'dropout_rate_Layer_3': 0.14936650635447968, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013633618089341425, 'l1_Layer_2': 0.00010350997603727966, 'l1_Layer_3': 0.00045551033540230674, 'n_units_Layer_1': 150, 'n_units_Layer_2': 145, 'n_units_Layer_3': 115}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.97 | sMAPE for Validation Set is: 16.60% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.65 | sMAPE for Test Set is: 35.03% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:45:25,053]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:45:27,335]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:45:50,500]\u001b[0m Trial 957 finished with value: 7.185770487341357 and parameters: {'n_hidden': 3, 'learning_rate': 0.002620717392924689, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09129134834021185, 'dropout_rate_Layer_2': 0.1784041293268323, 'dropout_rate_Layer_3': 0.34357812833053475, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00883181812011342, 'l1_Layer_2': 0.0029094303892591134, 'l1_Layer_3': 0.02547489011878293, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 285}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.19 | sMAPE for Validation Set is: 17.20% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.76 | sMAPE for Test Set is: 38.49% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:45:53,765]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:45:56,730]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:45:59,562]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:46:42,675]\u001b[0m Trial 961 finished with value: 7.79547553037576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017843230097973105, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04561374753341424, 'dropout_rate_Layer_2': 0.3322109375479173, 'dropout_rate_Layer_3': 0.3763955444230932, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4764001249755392e-05, 'l1_Layer_2': 0.0009714704219395467, 'l1_Layer_3': 1.0091640783172231e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 230, 'n_units_Layer_3': 180}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.80 | sMAPE for Validation Set is: 18.76% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 15.29 | sMAPE for Test Set is: 37.76% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:46:46,475]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:46:53,504]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:46:56,265]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:47:02,609]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:47:04,437]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:47:12,457]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:47:16,228]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:47:20,736]\u001b[0m Trial 947 finished with value: 6.826342027251724 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009521283598474132, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0073763209859752255, 'dropout_rate_Layer_2': 0.01313432486652486, 'dropout_rate_Layer_3': 0.17471421943712592, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.640611165924846e-05, 'l1_Layer_2': 0.00017040203766278733, 'l1_Layer_3': 0.00016630316310610837, 'n_units_Layer_1': 155, 'n_units_Layer_2': 145, 'n_units_Layer_3': 125}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.83 | sMAPE for Validation Set is: 16.40% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.38 | sMAPE for Test Set is: 33.35% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:47:22,749]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:47:27,297]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:47:29,967]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:47:30,160]\u001b[0m Trial 960 finished with value: 7.145434273836556 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006737137134857649, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2136852025573433, 'dropout_rate_Layer_2': 0.3845505479592407, 'dropout_rate_Layer_3': 0.37329339154641605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.046036975019557e-05, 'l1_Layer_2': 0.0012188005651894746, 'l1_Layer_3': 0.00036272379431031887, 'n_units_Layer_1': 140, 'n_units_Layer_2': 295, 'n_units_Layer_3': 205}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.15 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.62 | sMAPE for Test Set is: 34.81% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:47:36,049]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:47:44,162]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:47:48,481]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:47:50,584]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:47:54,799]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:47:59,114]\u001b[0m Trial 976 finished with value: 7.622622166186072 and parameters: {'n_hidden': 3, 'learning_rate': 0.007557318706660147, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05355494960530327, 'dropout_rate_Layer_2': 0.16167227208772164, 'dropout_rate_Layer_3': 0.3226232625695121, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018432746861963049, 'l1_Layer_2': 0.0017107321925134726, 'l1_Layer_3': 0.05239239334741584, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 255}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.62 | sMAPE for Validation Set is: 18.28% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 14.93 | sMAPE for Test Set is: 37.96% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:48:02,521]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:48:19,708]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:48:33,730]\u001b[0m Trial 978 finished with value: 7.181806711511239 and parameters: {'n_hidden': 3, 'learning_rate': 0.003717541010999118, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019906662890870508, 'dropout_rate_Layer_2': 0.19001568728798193, 'dropout_rate_Layer_3': 0.33369738197649645, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001908515371353737, 'l1_Layer_2': 0.004385939628487287, 'l1_Layer_3': 0.050422726742659636, 'n_units_Layer_1': 180, 'n_units_Layer_2': 60, 'n_units_Layer_3': 265}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.18 | sMAPE for Validation Set is: 17.22% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.59 | sMAPE for Test Set is: 36.95% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:48:57,374]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:48:58,350]\u001b[0m Trial 985 finished with value: 7.188025543045954 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010450131557062485, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014979235760378518, 'dropout_rate_Layer_2': 0.18798634195021424, 'dropout_rate_Layer_3': 0.38429496008436476, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02263073085132098, 'l1_Layer_2': 0.0009523932621048806, 'l1_Layer_3': 0.017394038308960042, 'n_units_Layer_1': 145, 'n_units_Layer_2': 60, 'n_units_Layer_3': 230}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.19 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.60 | sMAPE for Test Set is: 36.07% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:49:02,970]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:49:21,402]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:49:23,615]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:49:29,929]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:49:33,276]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:49:41,853]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:49:46,048]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:50:16,704]\u001b[0m Trial 995 finished with value: 7.374741344234354 and parameters: {'n_hidden': 3, 'learning_rate': 0.001216350225818104, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06108944620446425, 'dropout_rate_Layer_2': 0.3877588256255194, 'dropout_rate_Layer_3': 0.3778593361262067, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.40719413302625e-05, 'l1_Layer_2': 0.00015815927009704946, 'l1_Layer_3': 0.0005137594744977959, 'n_units_Layer_1': 135, 'n_units_Layer_2': 300, 'n_units_Layer_3': 200}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.37 | sMAPE for Validation Set is: 17.33% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 15.50 | sMAPE for Test Set is: 36.30% | rMAE for Test Set is: 0.51\n",
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 17.14% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.82 | sMAPE for Test Set is: 33.39% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:50:18,535]\u001b[0m Trial 987 finished with value: 7.224398472653199 and parameters: {'n_hidden': 3, 'learning_rate': 0.000787720631102, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2367124475212431, 'dropout_rate_Layer_2': 0.3813718467054718, 'dropout_rate_Layer_3': 0.36467044194585635, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.80223544457242e-05, 'l1_Layer_2': 0.0009316225104015651, 'l1_Layer_3': 0.00032534008273981736, 'n_units_Layer_1': 140, 'n_units_Layer_2': 295, 'n_units_Layer_3': 220}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:50:23,929]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:50:28,073]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:50:31,444]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:50:37,266]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:51:13,543]\u001b[0m Trial 997 finished with value: 7.174559868198977 and parameters: {'n_hidden': 3, 'learning_rate': 0.005070586265290863, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019503039908923964, 'dropout_rate_Layer_2': 0.21006591159122318, 'dropout_rate_Layer_3': 0.3896866329664762, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02321985248899216, 'l1_Layer_2': 0.00032490422970334884, 'l1_Layer_3': 0.004508027159463236, 'n_units_Layer_1': 150, 'n_units_Layer_2': 60, 'n_units_Layer_3': 270}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.17 | sMAPE for Validation Set is: 17.44% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.79 | sMAPE for Test Set is: 39.92% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:51:17,225]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:51:37,933]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:51:43,463]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:51:49,064]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:51:55,714]\u001b[0m Trial 993 finished with value: 6.8199526292751615 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006414461945699904, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02292390554909117, 'dropout_rate_Layer_2': 0.020004231312670387, 'dropout_rate_Layer_3': 0.20767197580787122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.23079837146242e-05, 'l1_Layer_2': 0.00013008717851328578, 'l1_Layer_3': 0.00011260780086484181, 'n_units_Layer_1': 160, 'n_units_Layer_2': 115, 'n_units_Layer_3': 115}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 16.42% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.75 | sMAPE for Test Set is: 40.17% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:52:00,381]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:52:14,135]\u001b[0m Trial 1000 finished with value: 7.200465458339598 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008069205014790176, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0637293070172874, 'dropout_rate_Layer_2': 0.38967360068823137, 'dropout_rate_Layer_3': 0.37670571595485386, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.629463041908697e-05, 'l1_Layer_2': 0.001712316983438316, 'l1_Layer_3': 0.0001975963331231919, 'n_units_Layer_1': 130, 'n_units_Layer_2': 300, 'n_units_Layer_3': 210}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.20 | sMAPE for Validation Set is: 17.30% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.95 | sMAPE for Test Set is: 37.10% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:52:19,622]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:52:20,609]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:52:26,708]\u001b[0m Trial 1008 finished with value: 7.732265233025648 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035867114588808333, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04792279069576849, 'dropout_rate_Layer_2': 0.3214355004642963, 'dropout_rate_Layer_3': 0.3777833257690304, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.712785392096244e-05, 'l1_Layer_2': 0.0018080939144378815, 'l1_Layer_3': 1.7875484403129287e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 105, 'n_units_Layer_3': 180}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.73 | sMAPE for Validation Set is: 18.45% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 15.17 | sMAPE for Test Set is: 36.60% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:52:29,154]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:52:41,505]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:52:42,370]\u001b[0m Trial 1002 finished with value: 7.167254042613496 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008285165076993755, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06125492980316023, 'dropout_rate_Layer_2': 0.38843415278393195, 'dropout_rate_Layer_3': 0.3765905408071181, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010160854376618955, 'l1_Layer_2': 0.0008786333142468825, 'l1_Layer_3': 0.0005591561517971812, 'n_units_Layer_1': 125, 'n_units_Layer_2': 300, 'n_units_Layer_3': 210}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.17 | sMAPE for Validation Set is: 17.18% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.27 | sMAPE for Test Set is: 37.01% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:52:57,853]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:53:05,293]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:53:27,067]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:53:35,705]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:53:48,712]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:53:51,025]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:53:57,936]\u001b[0m Trial 1014 finished with value: 7.683923827971383 and parameters: {'n_hidden': 3, 'learning_rate': 0.003624147663898303, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03535340059524424, 'dropout_rate_Layer_2': 0.325673287439907, 'dropout_rate_Layer_3': 0.21511502380936798, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5498852152161262e-05, 'l1_Layer_2': 0.0019032458317101873, 'l1_Layer_3': 1.7319416976294816e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 105, 'n_units_Layer_3': 195}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.68 | sMAPE for Validation Set is: 18.38% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 15.19 | sMAPE for Test Set is: 35.98% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:55:20,462]\u001b[0m Trial 1022 finished with value: 7.062051903346841 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006913316171486709, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06334021413224188, 'dropout_rate_Layer_2': 0.37667026140930376, 'dropout_rate_Layer_3': 0.3707381744008383, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010186265810579442, 'l1_Layer_2': 0.0008701482970474699, 'l1_Layer_3': 0.0003761036566959796, 'n_units_Layer_1': 135, 'n_units_Layer_2': 300, 'n_units_Layer_3': 220}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.06 | sMAPE for Validation Set is: 16.80% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.83 | sMAPE for Test Set is: 36.41% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:55:35,224]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:55:40,133]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:55:46,394]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:55:52,586]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:55:55,518]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:55:58,022]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:56:51,375]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:56:56,559]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:57:21,151]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:57:59,877]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:58:07,420]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:58:20,975]\u001b[0m Trial 1025 finished with value: 7.119800839537349 and parameters: {'n_hidden': 3, 'learning_rate': 0.000669811523420989, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07051176219849242, 'dropout_rate_Layer_2': 0.3784235893477423, 'dropout_rate_Layer_3': 0.3696191379023887, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012930089832515745, 'l1_Layer_2': 0.0008475619310792796, 'l1_Layer_3': 0.00020237638877662048, 'n_units_Layer_1': 120, 'n_units_Layer_2': 290, 'n_units_Layer_3': 220}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.12 | sMAPE for Validation Set is: 17.10% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.27 | sMAPE for Test Set is: 37.54% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:58:23,887]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:58:29,853]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:58:30,429]\u001b[0m Trial 1030 finished with value: 7.1298772657888785 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006115891514518694, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07091620793161625, 'dropout_rate_Layer_2': 0.3764806778910911, 'dropout_rate_Layer_3': 0.3678745424387679, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017077660118318058, 'l1_Layer_2': 0.0010751859073568962, 'l1_Layer_3': 0.00034708484366512924, 'n_units_Layer_1': 125, 'n_units_Layer_2': 290, 'n_units_Layer_3': 220}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.13 | sMAPE for Validation Set is: 17.10% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.13 | sMAPE for Test Set is: 35.91% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:58:38,620]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:58:39,678]\u001b[0m Trial 1027 finished with value: 6.859605406332949 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009715903218040861, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024039524247067685, 'dropout_rate_Layer_2': 0.007750544912520969, 'dropout_rate_Layer_3': 0.1894569611592934, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007302211826412985, 'l1_Layer_2': 7.384909400289292e-05, 'l1_Layer_3': 0.00020086447882499683, 'n_units_Layer_1': 170, 'n_units_Layer_2': 105, 'n_units_Layer_3': 125}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.86 | sMAPE for Validation Set is: 16.50% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.35 | sMAPE for Test Set is: 33.69% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:58:45,897]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:58:55,575]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:58:59,720]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:59:02,022]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:59:22,800]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:59:30,233]\u001b[0m Trial 1035 finished with value: 7.3609434935811295 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012990580410019693, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05666775712322068, 'dropout_rate_Layer_2': 0.3410694920552929, 'dropout_rate_Layer_3': 0.20545841440750431, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8543700902363555e-05, 'l1_Layer_2': 0.0030553749962939627, 'l1_Layer_3': 1.425842529125307e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 110, 'n_units_Layer_3': 180}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.36 | sMAPE for Validation Set is: 17.55% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.81 | sMAPE for Test Set is: 34.14% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 10:59:30,348]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:59:40,417]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 10:59:45,695]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:00:00,393]\u001b[0m Trial 1045 finished with value: 7.514474794955672 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031054555388741233, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.059691916040869944, 'dropout_rate_Layer_2': 0.3300765130011027, 'dropout_rate_Layer_3': 0.20009565472340693, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.022044309444604e-05, 'l1_Layer_2': 0.0013907098847034637, 'l1_Layer_3': 1.2580636126254579e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 105, 'n_units_Layer_3': 185}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.51 | sMAPE for Validation Set is: 18.30% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 14.98 | sMAPE for Test Set is: 37.29% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:00:03,981]\u001b[0m Trial 1048 finished with value: 7.205029195331773 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036577287956713694, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014529781024854456, 'dropout_rate_Layer_2': 0.24268474971315984, 'dropout_rate_Layer_3': 0.3805596702834551, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03621094799117017, 'l1_Layer_2': 0.0005697580770266626, 'l1_Layer_3': 0.0016697872268342812, 'n_units_Layer_1': 235, 'n_units_Layer_2': 190, 'n_units_Layer_3': 270}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.21 | sMAPE for Validation Set is: 17.34% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.68 | sMAPE for Test Set is: 35.97% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:00:08,054]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:00:31,718]\u001b[0m Trial 1050 finished with value: 7.229240002661 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032746167532021002, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.037525959995954185, 'dropout_rate_Layer_2': 0.23773300032146133, 'dropout_rate_Layer_3': 0.34611770463512304, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07728924608055815, 'l1_Layer_2': 0.0005556493088202506, 'l1_Layer_3': 0.0015684759733050038, 'n_units_Layer_1': 185, 'n_units_Layer_2': 50, 'n_units_Layer_3': 275}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.23 | sMAPE for Validation Set is: 17.64% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.66 | sMAPE for Test Set is: 35.58% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:00:38,613]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:00:39,451]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:00:47,587]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:00:48,533]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:00:53,250]\u001b[0m Trial 1053 finished with value: 7.615004471791302 and parameters: {'n_hidden': 4, 'learning_rate': 0.003995965972436383, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07950843712890386, 'dropout_rate_Layer_2': 0.34523309196211743, 'dropout_rate_Layer_3': 0.24979437365000104, 'dropout_rate_Layer_4': 0.01884642144649865, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.008424655552585366, 'l1_Layer_2': 0.0013827454912961478, 'l1_Layer_3': 2.6086777870000828e-05, 'l1_Layer_4': 0.00664042881434312, 'n_units_Layer_1': 150, 'n_units_Layer_2': 130, 'n_units_Layer_3': 210, 'n_units_Layer_4': 285}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.62 | sMAPE for Validation Set is: 18.40% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 14.96 | sMAPE for Test Set is: 38.07% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:00:55,941]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:00:56,935]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:01:03,655]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:01:04,453]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:01:09,906]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:01:10,844]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:01:16,145]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:01:19,301]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:01:20,179]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:01:23,941]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:01:27,063]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:01:30,701]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:01:37,830]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:01:56,980]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:02:02,586]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:02:08,321]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:02:15,791]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:02:25,673]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:02:34,134]\u001b[0m Trial 1068 finished with value: 7.336778482121019 and parameters: {'n_hidden': 4, 'learning_rate': 0.0041446777045115075, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0957826025469017, 'dropout_rate_Layer_2': 0.36009920996229156, 'dropout_rate_Layer_3': 0.23655198318451742, 'dropout_rate_Layer_4': 0.058225106379455105, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.039977472391181816, 'l1_Layer_2': 0.0024804361773745, 'l1_Layer_3': 1.4461755188358853e-05, 'l1_Layer_4': 0.0060955864992070456, 'n_units_Layer_1': 155, 'n_units_Layer_2': 90, 'n_units_Layer_3': 205, 'n_units_Layer_4': 290}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.34 | sMAPE for Validation Set is: 18.38% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 15.15 | sMAPE for Test Set is: 43.87% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:03:15,677]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:03:28,524]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:03:36,402]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:03:41,740]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:03:42,368]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:03:48,216]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:04:07,175]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:04:10,764]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:04:17,713]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:04:20,985]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:04:26,615]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:04:50,559]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:04:54,372]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:05:02,396]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.67 | sMAPE for Validation Set is: 18.80% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 14.81 | sMAPE for Test Set is: 37.02% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:05:04,053]\u001b[0m Trial 1088 finished with value: 7.668406001922139 and parameters: {'n_hidden': 4, 'learning_rate': 0.004126892277061214, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1064980200560071, 'dropout_rate_Layer_2': 0.35973075662153564, 'dropout_rate_Layer_3': 0.20147505302649538, 'dropout_rate_Layer_4': 0.05464583526183896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.013621594586505126, 'l1_Layer_2': 0.002431403870255478, 'l1_Layer_3': 1.5665547949757752e-05, 'l1_Layer_4': 0.025019271206013223, 'n_units_Layer_1': 150, 'n_units_Layer_2': 85, 'n_units_Layer_3': 230, 'n_units_Layer_4': 290}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:05:22,480]\u001b[0m Trial 1084 finished with value: 7.592717349605853 and parameters: {'n_hidden': 4, 'learning_rate': 0.004132033257259361, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09749661557309965, 'dropout_rate_Layer_2': 0.36219195393276477, 'dropout_rate_Layer_3': 0.24164972613987593, 'dropout_rate_Layer_4': 0.05861536859411351, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04021825270334681, 'l1_Layer_2': 0.0023919146352611434, 'l1_Layer_3': 1.489854981651544e-05, 'l1_Layer_4': 0.005991876984517008, 'n_units_Layer_1': 155, 'n_units_Layer_2': 125, 'n_units_Layer_3': 205, 'n_units_Layer_4': 290}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.59 | sMAPE for Validation Set is: 19.56% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 15.48 | sMAPE for Test Set is: 43.36% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:05:27,768]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:05:45,847]\u001b[0m Trial 1093 finished with value: 7.138967135867148 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034646487439839837, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013100419483280572, 'dropout_rate_Layer_2': 0.20589894978997306, 'dropout_rate_Layer_3': 0.37806087656465004, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.034251758726826426, 'l1_Layer_2': 0.0010943882963629014, 'l1_Layer_3': 0.003011376240619953, 'n_units_Layer_1': 210, 'n_units_Layer_2': 180, 'n_units_Layer_3': 285}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.14 | sMAPE for Validation Set is: 17.18% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.65 | sMAPE for Test Set is: 35.64% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:05:50,073]\u001b[0m Trial 1092 finished with value: 7.152457684001 and parameters: {'n_hidden': 3, 'learning_rate': 0.003747461448623189, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010840233773826126, 'dropout_rate_Layer_2': 0.20510758828974654, 'dropout_rate_Layer_3': 0.3837749325683758, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02141265588903394, 'l1_Layer_2': 0.00019307403611338572, 'l1_Layer_3': 0.0010473660919255137, 'n_units_Layer_1': 215, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.15 | sMAPE for Validation Set is: 17.23% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.60 | sMAPE for Test Set is: 36.04% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:05:54,664]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:05:55,016]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:06:04,792]\u001b[0m Trial 1095 finished with value: 7.130397630648019 and parameters: {'n_hidden': 3, 'learning_rate': 0.003418150182650802, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015656198479329263, 'dropout_rate_Layer_2': 0.23086382023247604, 'dropout_rate_Layer_3': 0.38661688118869597, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02178368556777317, 'l1_Layer_2': 0.0010994176082941357, 'l1_Layer_3': 0.0010490247588437673, 'n_units_Layer_1': 210, 'n_units_Layer_2': 185, 'n_units_Layer_3': 285}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.13 | sMAPE for Validation Set is: 17.17% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.57 | sMAPE for Test Set is: 36.79% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:06:21,495]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:06:38,519]\u001b[0m Trial 1098 finished with value: 7.43248983583415 and parameters: {'n_hidden': 4, 'learning_rate': 0.004084683687444419, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11050988541072015, 'dropout_rate_Layer_2': 0.36136273133481295, 'dropout_rate_Layer_3': 0.24402459154441955, 'dropout_rate_Layer_4': 0.05442019704793864, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03290110382053629, 'l1_Layer_2': 0.0024849453329151886, 'l1_Layer_3': 1.457513065485017e-05, 'l1_Layer_4': 0.005557511526364601, 'n_units_Layer_1': 150, 'n_units_Layer_2': 85, 'n_units_Layer_3': 220, 'n_units_Layer_4': 285}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.43 | sMAPE for Validation Set is: 18.05% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 15.02 | sMAPE for Test Set is: 41.70% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:06:51,307]\u001b[0m Trial 1101 finished with value: 7.348364621007909 and parameters: {'n_hidden': 3, 'learning_rate': 0.004318262072459195, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007982513268942797, 'dropout_rate_Layer_2': 0.22591334405736077, 'dropout_rate_Layer_3': 0.36232765363036445, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.019802958769577165, 'l1_Layer_2': 0.0011766072823242032, 'l1_Layer_3': 0.0010255149471108842, 'n_units_Layer_1': 215, 'n_units_Layer_2': 170, 'n_units_Layer_3': 285}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.35 | sMAPE for Validation Set is: 17.72% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.64 | sMAPE for Test Set is: 36.53% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:07:05,707]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:07:10,787]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:07:26,190]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:07:34,478]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:07:50,737]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:07:51,344]\u001b[0m Trial 1102 finished with value: 7.491401322953528 and parameters: {'n_hidden': 4, 'learning_rate': 0.0052019426455999955, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11673797570758064, 'dropout_rate_Layer_2': 0.3637402359703052, 'dropout_rate_Layer_3': 0.24418771570444484, 'dropout_rate_Layer_4': 0.054498161903407824, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03724909404856627, 'l1_Layer_2': 0.0024615339423643694, 'l1_Layer_3': 1.3638806886196637e-05, 'l1_Layer_4': 0.004656777017566501, 'n_units_Layer_1': 150, 'n_units_Layer_2': 85, 'n_units_Layer_3': 235, 'n_units_Layer_4': 290}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.49 | sMAPE for Validation Set is: 18.34% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 15.19 | sMAPE for Test Set is: 43.64% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:08:03,118]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:08:03,291]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:08:04,169]\u001b[0m Trial 1079 finished with value: 6.8897505330950635 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008243406822224853, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020209900606833423, 'dropout_rate_Layer_2': 0.01074336552703903, 'dropout_rate_Layer_3': 0.17404598347996708, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007734063390655754, 'l1_Layer_2': 8.479600287390868e-05, 'l1_Layer_3': 0.0007621209294576347, 'n_units_Layer_1': 130, 'n_units_Layer_2': 130, 'n_units_Layer_3': 130}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.89 | sMAPE for Validation Set is: 16.40% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.47 | sMAPE for Test Set is: 33.92% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:08:05,141]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:08:16,130]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:08:17,235]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:08:21,721]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:08:30,630]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:08:42,214]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:08:45,915]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:08:46,162]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:08:48,973]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:09:08,468]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:09:21,980]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:10:10,893]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:10:14,167]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:10:19,446]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:10:23,003]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:10:29,405]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:10:34,807]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:10:38,317]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:10:50,162]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:10:57,063]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:11:20,484]\u001b[0m Trial 1117 finished with value: 7.089921368387159 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007988503071099787, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.034790310629027654, 'dropout_rate_Layer_2': 0.2932380098809061, 'dropout_rate_Layer_3': 0.22252913552664216, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014697628486595767, 'l1_Layer_2': 0.0009018472359686636, 'l1_Layer_3': 0.0004463158399664755, 'n_units_Layer_1': 115, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.09 | sMAPE for Validation Set is: 17.03% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 15.37 | sMAPE for Test Set is: 37.52% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:11:27,153]\u001b[0m Trial 1127 finished with value: 7.5680399311476805 and parameters: {'n_hidden': 4, 'learning_rate': 0.00405282066230705, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10549669411394128, 'dropout_rate_Layer_2': 0.35444202741878295, 'dropout_rate_Layer_3': 0.2017857033728788, 'dropout_rate_Layer_4': 0.05443080240311614, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.024228358280339805, 'l1_Layer_2': 0.0022531169109496476, 'l1_Layer_3': 1.55139073220642e-05, 'l1_Layer_4': 0.02978618844694084, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 215, 'n_units_Layer_4': 290}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.57 | sMAPE for Validation Set is: 18.58% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 15.26 | sMAPE for Test Set is: 43.39% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:11:32,790]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:11:48,654]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:11:52,272]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:12:05,525]\u001b[0m Trial 1133 finished with value: 7.244731506202474 and parameters: {'n_hidden': 4, 'learning_rate': 0.002441503778146077, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0781786958952934, 'dropout_rate_Layer_2': 0.3545120812533352, 'dropout_rate_Layer_3': 0.20221793011399253, 'dropout_rate_Layer_4': 0.053182496393729295, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.024411560169750143, 'l1_Layer_2': 0.002476602158195999, 'l1_Layer_3': 1.0096702772407708e-05, 'l1_Layer_4': 0.024454894519210204, 'n_units_Layer_1': 165, 'n_units_Layer_2': 90, 'n_units_Layer_3': 230, 'n_units_Layer_4': 290}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.24 | sMAPE for Validation Set is: 17.71% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.86 | sMAPE for Test Set is: 39.57% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:12:09,435]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:12:33,626]\u001b[0m Trial 1137 finished with value: 7.39235974811087 and parameters: {'n_hidden': 4, 'learning_rate': 0.002644051869973345, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07652517360341295, 'dropout_rate_Layer_2': 0.1398790809539257, 'dropout_rate_Layer_3': 0.1757929720548853, 'dropout_rate_Layer_4': 0.0879824580466895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04230703374527504, 'l1_Layer_2': 0.0070020776023085336, 'l1_Layer_3': 1.1969661785284127e-05, 'l1_Layer_4': 0.005440560169255997, 'n_units_Layer_1': 165, 'n_units_Layer_2': 90, 'n_units_Layer_3': 265, 'n_units_Layer_4': 265}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.39 | sMAPE for Validation Set is: 17.85% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.78 | sMAPE for Test Set is: 36.40% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:12:42,939]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:12:44,019]\u001b[0m Trial 1132 finished with value: 7.2133657051153905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008086380854744165, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05022252035746631, 'dropout_rate_Layer_2': 0.37151368364401094, 'dropout_rate_Layer_3': 0.3840212359548832, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.747144439268868e-05, 'l1_Layer_2': 0.000836909030079151, 'l1_Layer_3': 0.0002427124997984467, 'n_units_Layer_1': 120, 'n_units_Layer_2': 285, 'n_units_Layer_3': 165}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.21 | sMAPE for Validation Set is: 17.28% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.10 | sMAPE for Test Set is: 35.00% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:13:00,065]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:13:14,686]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:13:20,163]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:13:23,020]\u001b[0m Trial 1142 finished with value: 7.171787809033634 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034918672512240794, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06745507113503256, 'dropout_rate_Layer_2': 0.2759049349976247, 'dropout_rate_Layer_3': 0.38516925003770064, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006926063841020148, 'l1_Layer_2': 0.00021774454867169198, 'l1_Layer_3': 0.011587439368458873, 'n_units_Layer_1': 225, 'n_units_Layer_2': 205, 'n_units_Layer_3': 290}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.17 | sMAPE for Validation Set is: 17.31% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.61 | sMAPE for Test Set is: 37.54% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:13:24,180]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:13:27,814]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:13:50,025]\u001b[0m Trial 1143 finished with value: 7.222434030280655 and parameters: {'n_hidden': 4, 'learning_rate': 0.0039684149280222744, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07437298339673017, 'dropout_rate_Layer_2': 0.10465492319531983, 'dropout_rate_Layer_3': 0.17062783472675613, 'dropout_rate_Layer_4': 0.08305877576691303, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.025898305591952196, 'l1_Layer_2': 0.0014190369934414704, 'l1_Layer_3': 1.1762577756524941e-05, 'l1_Layer_4': 0.006264172071345632, 'n_units_Layer_1': 155, 'n_units_Layer_2': 85, 'n_units_Layer_3': 255, 'n_units_Layer_4': 290}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 17.67% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.69 | sMAPE for Test Set is: 36.90% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:14:33,017]\u001b[0m Trial 1122 finished with value: 6.824914111690371 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006670967656622006, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019534566720045624, 'dropout_rate_Layer_2': 0.0176526465620405, 'dropout_rate_Layer_3': 0.1255108602014343, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000966804644695914, 'l1_Layer_2': 9.150584123187772e-05, 'l1_Layer_3': 0.0003773770142722058, 'n_units_Layer_1': 155, 'n_units_Layer_2': 135, 'n_units_Layer_3': 120}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 16.36% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.33 | sMAPE for Test Set is: 33.54% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:14:33,095]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:14:33,487]\u001b[0m Trial 1148 finished with value: 7.10328533056284 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024168822365022114, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07640563908988053, 'dropout_rate_Layer_2': 0.1372662958418226, 'dropout_rate_Layer_3': 0.16919504614789221, 'dropout_rate_Layer_4': 0.07770280511763475, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.022118832022413076, 'l1_Layer_2': 0.006245537860008319, 'l1_Layer_3': 1.0220540983294571e-05, 'l1_Layer_4': 0.006656629740934254, 'n_units_Layer_1': 165, 'n_units_Layer_2': 75, 'n_units_Layer_3': 280, 'n_units_Layer_4': 290}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.10 | sMAPE for Validation Set is: 17.15% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.66 | sMAPE for Test Set is: 37.82% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:14:45,103]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:14:45,854]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:14:51,082]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:15:00,270]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:15:19,259]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:15:26,975]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:15:31,157]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:15:46,050]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:15:50,657]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:15:57,076]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:16:34,281]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:16:38,131]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:16:43,756]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:16:48,302]\u001b[0m Trial 1147 finished with value: 6.807168476965619 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008313433409212858, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018596519014890553, 'dropout_rate_Layer_2': 0.01206028818339131, 'dropout_rate_Layer_3': 0.08320424733323967, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004466984219666774, 'l1_Layer_2': 0.00012551739618532544, 'l1_Layer_3': 0.0001608209634107819, 'n_units_Layer_1': 135, 'n_units_Layer_2': 165, 'n_units_Layer_3': 125}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 16.28% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.44 | sMAPE for Test Set is: 34.06% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:16:49,588]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:16:56,816]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:17:27,586]\u001b[0m Trial 1167 finished with value: 7.297890826272787 and parameters: {'n_hidden': 3, 'learning_rate': 0.004151039087480087, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04893948341741181, 'dropout_rate_Layer_2': 0.18613361527157635, 'dropout_rate_Layer_3': 0.38326824697581785, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010984022957843708, 'l1_Layer_2': 0.00019747599747727194, 'l1_Layer_3': 0.01132772202036402, 'n_units_Layer_1': 230, 'n_units_Layer_2': 180, 'n_units_Layer_3': 290}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.30 | sMAPE for Validation Set is: 17.65% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.97 | sMAPE for Test Set is: 39.72% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:17:41,688]\u001b[0m Trial 1168 finished with value: 7.359025172738835 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025909038046172776, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08683306892169132, 'dropout_rate_Layer_2': 0.11518412713836407, 'dropout_rate_Layer_3': 0.18280539789153505, 'dropout_rate_Layer_4': 0.06918900071503807, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02323869014266586, 'l1_Layer_2': 0.003299254583646656, 'l1_Layer_3': 2.1253300105524583e-05, 'l1_Layer_4': 0.019900599069675187, 'n_units_Layer_1': 160, 'n_units_Layer_2': 85, 'n_units_Layer_3': 255, 'n_units_Layer_4': 280}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.36 | sMAPE for Validation Set is: 17.78% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.77 | sMAPE for Test Set is: 37.95% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:17:45,389]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:18:00,370]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:18:06,690]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:18:16,486]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:18:22,413]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:18:25,575]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:18:30,550]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:18:38,219]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:18:43,540]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:18:49,087]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:18:57,229]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:19:02,824]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:19:15,617]\u001b[0m Trial 1173 finished with value: 7.233364611124859 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007470885596799931, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08480698741604699, 'dropout_rate_Layer_2': 0.38537510298402256, 'dropout_rate_Layer_3': 0.2447168186980534, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024386326123307668, 'l1_Layer_2': 0.0013126856202126651, 'l1_Layer_3': 0.00019116939579810432, 'n_units_Layer_1': 115, 'n_units_Layer_2': 290, 'n_units_Layer_3': 160}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.23 | sMAPE for Validation Set is: 17.21% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.65 | sMAPE for Test Set is: 35.10% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:19:23,775]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:19:26,906]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:19:44,793]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:20:15,122]\u001b[0m Trial 1175 finished with value: 7.22268966415741 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006767254852258755, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.044800033427140354, 'dropout_rate_Layer_2': 0.29191563384863656, 'dropout_rate_Layer_3': 0.23662892901541946, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002489131325839978, 'l1_Layer_2': 0.0008737814531525117, 'l1_Layer_3': 0.00015785789716592203, 'n_units_Layer_1': 115, 'n_units_Layer_2': 270, 'n_units_Layer_3': 160}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 17.24% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.48 | sMAPE for Test Set is: 36.05% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:20:23,174]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:20:33,231]\u001b[0m Trial 1180 finished with value: 7.143782200260535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006732724969887187, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04112569057260498, 'dropout_rate_Layer_2': 0.08089058842892638, 'dropout_rate_Layer_3': 0.23757917025607928, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014170168405757213, 'l1_Layer_2': 0.0012528057137268108, 'l1_Layer_3': 0.0004581165522236772, 'n_units_Layer_1': 115, 'n_units_Layer_2': 270, 'n_units_Layer_3': 205}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.14 | sMAPE for Validation Set is: 17.05% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.31 | sMAPE for Test Set is: 36.09% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:21:00,504]\u001b[0m Trial 1188 finished with value: 7.378967898218325 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026098569207334394, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06573217238675448, 'dropout_rate_Layer_2': 0.11543082182306266, 'dropout_rate_Layer_3': 0.19932521334451875, 'dropout_rate_Layer_4': 0.045303637977631234, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.033327783527627344, 'l1_Layer_2': 0.00862216877871528, 'l1_Layer_3': 2.0659905522588885e-05, 'l1_Layer_4': 0.020069524422845566, 'n_units_Layer_1': 160, 'n_units_Layer_2': 85, 'n_units_Layer_3': 255, 'n_units_Layer_4': 295}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.38 | sMAPE for Validation Set is: 17.76% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.65 | sMAPE for Test Set is: 34.17% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:21:06,694]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:21:18,905]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:21:22,289]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:21:23,003]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:22:47,979]\u001b[0m Trial 1186 finished with value: 7.1191748887134 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007085283387469814, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.084844469608547, 'dropout_rate_Layer_2': 0.3990969233177332, 'dropout_rate_Layer_3': 0.2402111666777566, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000272808407795028, 'l1_Layer_2': 0.0012738741755048892, 'l1_Layer_3': 0.00020238593069871034, 'n_units_Layer_1': 115, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.12 | sMAPE for Validation Set is: 17.17% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.73 | sMAPE for Test Set is: 34.88% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:22:57,508]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:23:19,587]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:23:35,576]\u001b[0m Trial 1192 finished with value: 6.859615200391694 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006848628459942567, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.053797674842842216, 'dropout_rate_Layer_2': 0.014069714757477538, 'dropout_rate_Layer_3': 0.030694785459814203, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007252651517444171, 'l1_Layer_2': 0.00013890560310871614, 'l1_Layer_3': 0.000162147231561736, 'n_units_Layer_1': 160, 'n_units_Layer_2': 125, 'n_units_Layer_3': 130}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.86 | sMAPE for Validation Set is: 16.43% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.51 | sMAPE for Test Set is: 34.71% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:23:42,121]\u001b[0m Trial 1194 finished with value: 7.0479070414300296 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005829294194805746, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015817950938519617, 'dropout_rate_Layer_2': 0.39863617508452814, 'dropout_rate_Layer_3': 0.23353800572679245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022456301432068382, 'l1_Layer_2': 0.0012951207259895062, 'l1_Layer_3': 0.00019748700695163788, 'n_units_Layer_1': 110, 'n_units_Layer_2': 270, 'n_units_Layer_3': 160}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.05 | sMAPE for Validation Set is: 16.85% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.94 | sMAPE for Test Set is: 35.35% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:23:53,259]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:24:00,203]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:24:08,860]\u001b[0m Trial 1197 finished with value: 7.283246185788452 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025987959499133755, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0693854308197459, 'dropout_rate_Layer_2': 0.11394760042583214, 'dropout_rate_Layer_3': 0.15317785089076974, 'dropout_rate_Layer_4': 0.09346177821614389, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.023441948569268786, 'l1_Layer_2': 0.006574770650155255, 'l1_Layer_3': 1.2814277438632851e-05, 'l1_Layer_4': 0.020897584589573272, 'n_units_Layer_1': 155, 'n_units_Layer_2': 80, 'n_units_Layer_3': 290, 'n_units_Layer_4': 270}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.28 | sMAPE for Validation Set is: 17.61% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.72 | sMAPE for Test Set is: 37.49% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:24:40,063]\u001b[0m Trial 1200 finished with value: 7.561133693245758 and parameters: {'n_hidden': 4, 'learning_rate': 0.002558475638203196, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09056245465104362, 'dropout_rate_Layer_2': 0.06582503245676662, 'dropout_rate_Layer_3': 0.17810449527956215, 'dropout_rate_Layer_4': 0.09534685015952821, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.020138751394330075, 'l1_Layer_2': 0.0070423405260029714, 'l1_Layer_3': 3.825853492395057e-05, 'l1_Layer_4': 0.021396183950622566, 'n_units_Layer_1': 155, 'n_units_Layer_2': 80, 'n_units_Layer_3': 260, 'n_units_Layer_4': 300}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.56 | sMAPE for Validation Set is: 18.39% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 14.90 | sMAPE for Test Set is: 39.31% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:24:45,883]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.15 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.00 | sMAPE for Test Set is: 37.23% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:25:52,402]\u001b[0m Trial 1196 finished with value: 7.151532311988942 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006839132372650674, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08183404573118698, 'dropout_rate_Layer_2': 0.3122006845373042, 'dropout_rate_Layer_3': 0.2362790565554987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002952274433532786, 'l1_Layer_2': 0.000978172958948514, 'l1_Layer_3': 0.00020339223936785344, 'n_units_Layer_1': 110, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:26:35,282]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:26:43,935]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:26:54,834]\u001b[0m Trial 1206 finished with value: 7.354724738569011 and parameters: {'n_hidden': 3, 'learning_rate': 0.0048660847214976885, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06299810400881697, 'dropout_rate_Layer_2': 0.2002632298888623, 'dropout_rate_Layer_3': 0.39767474467776803, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0259997971419155, 'l1_Layer_2': 0.0002621431887309333, 'l1_Layer_3': 0.007199779140417683, 'n_units_Layer_1': 205, 'n_units_Layer_2': 230, 'n_units_Layer_3': 250}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.35 | sMAPE for Validation Set is: 17.75% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.91 | sMAPE for Test Set is: 39.00% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:27:11,437]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:27:25,544]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:27:30,853]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:27:53,513]\u001b[0m Trial 1203 finished with value: 6.821081832328766 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006814689451397652, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.035548508358007214, 'dropout_rate_Layer_2': 0.05083196559853708, 'dropout_rate_Layer_3': 0.07590038866559684, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000645872894053698, 'l1_Layer_2': 0.00022490578828574353, 'l1_Layer_3': 0.00015185991691061475, 'n_units_Layer_1': 170, 'n_units_Layer_2': 115, 'n_units_Layer_3': 140}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 16.34% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.41 | sMAPE for Test Set is: 33.26% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:28:08,497]\u001b[0m Trial 1202 finished with value: 6.799962946639382 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006908189675338825, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03561827272970883, 'dropout_rate_Layer_2': 0.04606301808494748, 'dropout_rate_Layer_3': 0.03370586100037952, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006785868286927835, 'l1_Layer_2': 0.00017873345413228195, 'l1_Layer_3': 0.00015222629623616094, 'n_units_Layer_1': 170, 'n_units_Layer_2': 125, 'n_units_Layer_3': 140}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.80 | sMAPE for Validation Set is: 16.26% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.32 | sMAPE for Test Set is: 32.89% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:28:33,350]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:28:42,379]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:28:45,749]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:29:26,130]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:29:31,561]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:30:22,258]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:30:22,532]\u001b[0m Trial 1210 finished with value: 7.1529498963216165 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006921315716340257, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03313817814749414, 'dropout_rate_Layer_2': 0.39632586186936747, 'dropout_rate_Layer_3': 0.23954926523425496, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001958531871229976, 'l1_Layer_2': 0.0013853696209480144, 'l1_Layer_3': 0.0002248616413676383, 'n_units_Layer_1': 105, 'n_units_Layer_2': 270, 'n_units_Layer_3': 160}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.15 | sMAPE for Validation Set is: 17.12% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.83 | sMAPE for Test Set is: 35.39% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:30:31,161]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:30:31,457]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:30:37,413]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:31:21,974]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:31:31,922]\u001b[0m Trial 1213 finished with value: 6.817455178509211 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005396074628037054, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06524197327174165, 'dropout_rate_Layer_2': 0.06031220685088628, 'dropout_rate_Layer_3': 0.03194126489243277, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005640711963780662, 'l1_Layer_2': 0.00019849232112275267, 'l1_Layer_3': 0.0001667642149095839, 'n_units_Layer_1': 180, 'n_units_Layer_2': 110, 'n_units_Layer_3': 145}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 16.37% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.43 | sMAPE for Test Set is: 35.34% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:31:36,273]\u001b[0m Trial 1221 finished with value: 7.251105405793733 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025326393621552317, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07044051661201542, 'dropout_rate_Layer_2': 0.15270658636357598, 'dropout_rate_Layer_3': 0.14773644454376123, 'dropout_rate_Layer_4': 0.0911918842340152, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02524320170964774, 'l1_Layer_2': 0.0006386825371222476, 'l1_Layer_3': 1.422172315150492e-05, 'l1_Layer_4': 0.008207358478279386, 'n_units_Layer_1': 180, 'n_units_Layer_2': 90, 'n_units_Layer_3': 295, 'n_units_Layer_4': 285}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.25 | sMAPE for Validation Set is: 17.58% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.67 | sMAPE for Test Set is: 36.68% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:31:42,606]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:31:52,413]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:31:56,511]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:32:02,809]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:32:06,342]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:32:22,465]\u001b[0m Trial 1225 finished with value: 7.3124981563584095 and parameters: {'n_hidden': 3, 'learning_rate': 0.003332593941676948, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02303673841859, 'dropout_rate_Layer_2': 0.29851237187210816, 'dropout_rate_Layer_3': 0.3999112838096219, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0024565981490056146, 'l1_Layer_2': 0.00016892686917587438, 'l1_Layer_3': 0.005004336994590102, 'n_units_Layer_1': 195, 'n_units_Layer_2': 185, 'n_units_Layer_3': 295}. Best is trial 336 with value: 6.798748393595996.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.31 | sMAPE for Validation Set is: 17.51% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.68 | sMAPE for Test Set is: 36.56% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:32:37,365]\u001b[0m Trial 1211 finished with value: 6.772384909301497 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005692360750166436, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0326412258175873, 'dropout_rate_Layer_2': 0.12886331028246084, 'dropout_rate_Layer_3': 0.04421609623496126, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008709743083851224, 'l1_Layer_2': 0.00019247898663614694, 'l1_Layer_3': 0.00013286965526152994, 'n_units_Layer_1': 155, 'n_units_Layer_2': 145, 'n_units_Layer_3': 115}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.77 | sMAPE for Validation Set is: 16.19% | rMAE for Validation Set is: 0.42\n",
      "MAE for Test Set is: 14.26 | sMAPE for Test Set is: 32.66% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:32:41,149]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:32:50,499]\u001b[0m Trial 1231 finished with value: 7.255728710840978 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027065041674647354, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023894019448968056, 'dropout_rate_Layer_2': 0.27362203052795897, 'dropout_rate_Layer_3': 0.3758838496550328, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0031202011392451826, 'l1_Layer_2': 0.0002382942617909068, 'l1_Layer_3': 0.0012538205411133476, 'n_units_Layer_1': 195, 'n_units_Layer_2': 200, 'n_units_Layer_3': 295}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.26 | sMAPE for Validation Set is: 17.54% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.54 | sMAPE for Test Set is: 36.50% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:32:58,921]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:33:14,551]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:33:21,411]\u001b[0m Trial 1232 finished with value: 7.174342263395338 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026098400954347248, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06847694128228934, 'dropout_rate_Layer_2': 0.15031508742151933, 'dropout_rate_Layer_3': 0.1428716107778193, 'dropout_rate_Layer_4': 0.0911065772238416, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.036543312974545085, 'l1_Layer_2': 0.00047140360425457526, 'l1_Layer_3': 1.2345425548900628e-05, 'l1_Layer_4': 0.005244525295620312, 'n_units_Layer_1': 170, 'n_units_Layer_2': 85, 'n_units_Layer_3': 280, 'n_units_Layer_4': 280}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.17 | sMAPE for Validation Set is: 17.20% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.81 | sMAPE for Test Set is: 39.00% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:33:28,106]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:33:35,764]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:33:40,142]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:33:43,685]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:33:46,321]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:34:17,504]\u001b[0m Trial 1241 finished with value: 7.239033867855535 and parameters: {'n_hidden': 3, 'learning_rate': 0.005690440126453281, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.035355488383288655, 'dropout_rate_Layer_2': 0.19552203370833407, 'dropout_rate_Layer_3': 0.3693167070419877, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01250672099515166, 'l1_Layer_2': 8.486793677426882e-05, 'l1_Layer_3': 0.0035926426350841633, 'n_units_Layer_1': 240, 'n_units_Layer_2': 220, 'n_units_Layer_3': 260}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.24 | sMAPE for Validation Set is: 17.39% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.58 | sMAPE for Test Set is: 35.07% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:34:25,580]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:34:37,937]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:36:06,974]\u001b[0m Trial 1234 finished with value: 6.806234119764253 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005670913388262507, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04179746864612526, 'dropout_rate_Layer_2': 0.07131426021872708, 'dropout_rate_Layer_3': 0.04768462019734891, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006507709748843811, 'l1_Layer_2': 0.00019150952107704433, 'l1_Layer_3': 0.00017052000840556592, 'n_units_Layer_1': 185, 'n_units_Layer_2': 105, 'n_units_Layer_3': 150}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 16.25% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.31 | sMAPE for Test Set is: 34.42% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:36:15,971]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:36:24,551]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:36:30,341]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:36:47,889]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:37:11,422]\u001b[0m Trial 1246 finished with value: 6.822206274946975 and parameters: {'n_hidden': 3, 'learning_rate': 0.000554807158518182, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07264495336385626, 'dropout_rate_Layer_2': 0.08449720541186355, 'dropout_rate_Layer_3': 0.06775189416299504, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006843261333713977, 'l1_Layer_2': 0.0001546124631249406, 'l1_Layer_3': 1.125556926761979e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 100, 'n_units_Layer_3': 140}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 16.32% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.63 | sMAPE for Test Set is: 36.06% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:37:29,693]\u001b[0m Trial 1243 finished with value: 6.830031654855837 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005505108964187718, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06936153997928138, 'dropout_rate_Layer_2': 0.06672607985385086, 'dropout_rate_Layer_3': 0.03988925053342803, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006760080402938906, 'l1_Layer_2': 0.00016096803691022273, 'l1_Layer_3': 0.00013374745192446487, 'n_units_Layer_1': 165, 'n_units_Layer_2': 100, 'n_units_Layer_3': 140}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.83 | sMAPE for Validation Set is: 16.35% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.38 | sMAPE for Test Set is: 33.77% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:37:38,051]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:37:50,716]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:38:02,255]\u001b[0m Trial 1251 finished with value: 7.173771382148484 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006117006481402739, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021305896696428267, 'dropout_rate_Layer_2': 0.301808291791342, 'dropout_rate_Layer_3': 0.20517118809607499, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014385978304653178, 'l1_Layer_2': 0.0010345757188539616, 'l1_Layer_3': 0.00024393618143757389, 'n_units_Layer_1': 125, 'n_units_Layer_2': 280, 'n_units_Layer_3': 145}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.17 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.92 | sMAPE for Test Set is: 34.76% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:38:18,032]\u001b[0m Trial 1242 finished with value: 6.778068842690307 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005358446131647972, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05128677356568556, 'dropout_rate_Layer_2': 0.05373506688073913, 'dropout_rate_Layer_3': 0.04157690900637193, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003986542725018713, 'l1_Layer_2': 0.00019125545692397396, 'l1_Layer_3': 0.00023899149888920507, 'n_units_Layer_1': 165, 'n_units_Layer_2': 120, 'n_units_Layer_3': 140}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.78 | sMAPE for Validation Set is: 16.15% | rMAE for Validation Set is: 0.42\n",
      "MAE for Test Set is: 14.40 | sMAPE for Test Set is: 33.52% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:38:26,191]\u001b[0m Trial 1256 finished with value: 7.314140938860078 and parameters: {'n_hidden': 3, 'learning_rate': 0.004079449480577881, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05090324771982778, 'dropout_rate_Layer_2': 0.13796406206536335, 'dropout_rate_Layer_3': 0.3411434643413138, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007209391465335385, 'l1_Layer_2': 0.00041218296266428117, 'l1_Layer_3': 0.013331532007890784, 'n_units_Layer_1': 230, 'n_units_Layer_2': 165, 'n_units_Layer_3': 265}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.31 | sMAPE for Validation Set is: 17.75% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.75 | sMAPE for Test Set is: 37.57% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:38:32,228]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:38:59,814]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:39:34,246]\u001b[0m Trial 1252 finished with value: 7.075535778230129 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006113903261665682, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02594747208848684, 'dropout_rate_Layer_2': 0.39015270328491336, 'dropout_rate_Layer_3': 0.20612759835022226, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001397779338252231, 'l1_Layer_2': 0.0009517763289533573, 'l1_Layer_3': 0.0002712230624928418, 'n_units_Layer_1': 125, 'n_units_Layer_2': 280, 'n_units_Layer_3': 170}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.08 | sMAPE for Validation Set is: 16.79% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 15.06 | sMAPE for Test Set is: 35.51% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:39:38,462]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:39:39,141]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:40:19,581]\u001b[0m Trial 1255 finished with value: 7.120918312678789 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006065441446761735, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05686496144771199, 'dropout_rate_Layer_2': 0.3030917765711431, 'dropout_rate_Layer_3': 0.22135009023439697, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001602064996409268, 'l1_Layer_2': 0.0011363343212999165, 'l1_Layer_3': 0.00026154202283692427, 'n_units_Layer_1': 125, 'n_units_Layer_2': 280, 'n_units_Layer_3': 145}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.12 | sMAPE for Validation Set is: 17.07% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.19 | sMAPE for Test Set is: 34.84% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:40:26,269]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:40:43,242]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:40:50,954]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:41:28,332]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:41:32,154]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:41:46,676]\u001b[0m Trial 1263 finished with value: 7.11169218125623 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005078614708453618, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014898626462367484, 'dropout_rate_Layer_2': 0.2944809143194952, 'dropout_rate_Layer_3': 0.19044058783465606, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013957257074993248, 'l1_Layer_2': 0.0006676507949513207, 'l1_Layer_3': 0.00017500832060005853, 'n_units_Layer_1': 120, 'n_units_Layer_2': 265, 'n_units_Layer_3': 150}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 17.03% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.38 | sMAPE for Test Set is: 36.77% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:41:58,450]\u001b[0m Trial 1264 finished with value: 7.160461347398368 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005026520062649294, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017272741187718224, 'dropout_rate_Layer_2': 0.3084878415003191, 'dropout_rate_Layer_3': 0.22155101807286537, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015101298650571586, 'l1_Layer_2': 0.0011506768541517751, 'l1_Layer_3': 0.00016222117169952498, 'n_units_Layer_1': 120, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.16 | sMAPE for Validation Set is: 16.94% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.02 | sMAPE for Test Set is: 33.86% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:42:03,045]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:42:31,954]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:42:33,402]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:42:49,580]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:42:52,897]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:44:45,154]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:44:53,293]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:44:58,979]\u001b[0m Trial 1275 finished with value: 7.104979774159426 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005054392257078129, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020182473219921337, 'dropout_rate_Layer_2': 0.28167928834198797, 'dropout_rate_Layer_3': 0.1981329158064053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011686545988873443, 'l1_Layer_2': 0.0011834685015153395, 'l1_Layer_3': 0.0002755585379951005, 'n_units_Layer_1': 110, 'n_units_Layer_2': 260, 'n_units_Layer_3': 145}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.10 | sMAPE for Validation Set is: 17.18% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.89 | sMAPE for Test Set is: 35.07% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:45:09,863]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:45:33,471]\u001b[0m Trial 1271 finished with value: 6.807610663406455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005029629437924321, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04223184931243003, 'dropout_rate_Layer_2': 0.07814859839972295, 'dropout_rate_Layer_3': 0.07779412903479212, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004658918832528713, 'l1_Layer_2': 0.0001994237195409974, 'l1_Layer_3': 2.2606907833000482e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 105, 'n_units_Layer_3': 150}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 16.32% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.35 | sMAPE for Test Set is: 37.82% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:45:41,411]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:45:47,705]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:45:54,067]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:46:00,300]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:46:17,057]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:46:22,163]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:46:28,080]\u001b[0m Trial 1279 finished with value: 7.139257164696296 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019356984880160974, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.056076136223137285, 'dropout_rate_Layer_2': 0.12218045729157072, 'dropout_rate_Layer_3': 0.1514342325969204, 'dropout_rate_Layer_4': 0.08583649661902096, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.024090653009729807, 'l1_Layer_2': 0.00041892643525339216, 'l1_Layer_3': 1.689768904944819e-05, 'l1_Layer_4': 0.03743024762874664, 'n_units_Layer_1': 175, 'n_units_Layer_2': 100, 'n_units_Layer_3': 285, 'n_units_Layer_4': 295}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.14 | sMAPE for Validation Set is: 17.14% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.67 | sMAPE for Test Set is: 36.48% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:46:52,485]\u001b[0m Trial 1288 finished with value: 7.587479679941908 and parameters: {'n_hidden': 4, 'learning_rate': 0.003319139879258903, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.054906770849488716, 'dropout_rate_Layer_2': 0.14348752523037817, 'dropout_rate_Layer_3': 0.1138827722626223, 'dropout_rate_Layer_4': 0.08521134502054219, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.020681547257034496, 'l1_Layer_2': 0.000379653469076338, 'l1_Layer_3': 1.7244539035538766e-05, 'l1_Layer_4': 0.042535600876995636, 'n_units_Layer_1': 165, 'n_units_Layer_2': 100, 'n_units_Layer_3': 280, 'n_units_Layer_4': 295}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.59 | sMAPE for Validation Set is: 18.08% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 14.95 | sMAPE for Test Set is: 35.82% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:47:22,659]\u001b[0m Trial 1274 finished with value: 7.089033719554294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005116798652829609, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00895718801405347, 'dropout_rate_Layer_2': 0.32587137544118633, 'dropout_rate_Layer_3': 0.2011096564279095, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013182622824250962, 'l1_Layer_2': 0.001441478380559712, 'l1_Layer_3': 0.0001948197260129076, 'n_units_Layer_1': 130, 'n_units_Layer_2': 265, 'n_units_Layer_3': 145}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.09 | sMAPE for Validation Set is: 17.01% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 15.09 | sMAPE for Test Set is: 35.86% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:48:20,341]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:48:43,912]\u001b[0m Trial 1289 finished with value: 7.177121381297902 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005559026477361088, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06036235562649137, 'dropout_rate_Layer_2': 0.0726701173502734, 'dropout_rate_Layer_3': 0.05352651724507365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005411637343687001, 'l1_Layer_2': 0.00016283507284705525, 'l1_Layer_3': 2.485507892347476e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 105, 'n_units_Layer_3': 145}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.18 | sMAPE for Validation Set is: 17.06% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 15.21 | sMAPE for Test Set is: 34.22% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:49:19,736]\u001b[0m Trial 1280 finished with value: 6.819783739809439 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005018845298632197, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08400828046378844, 'dropout_rate_Layer_2': 0.09476445021937728, 'dropout_rate_Layer_3': 0.04241696083257838, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000510618005515126, 'l1_Layer_2': 0.00017691233563809844, 'l1_Layer_3': 1.283232908090761e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 100, 'n_units_Layer_3': 145}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 16.30% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.34 | sMAPE for Test Set is: 34.13% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:49:22,591]\u001b[0m Trial 1290 finished with value: 7.100162343324008 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005543123281421272, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05573592466514809, 'dropout_rate_Layer_2': 0.07287299904705295, 'dropout_rate_Layer_3': 0.038445555461022914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003418525406094288, 'l1_Layer_2': 0.0001614193426087252, 'l1_Layer_3': 0.00014061642369382027, 'n_units_Layer_1': 185, 'n_units_Layer_2': 105, 'n_units_Layer_3': 145}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.10 | sMAPE for Validation Set is: 16.85% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 15.29 | sMAPE for Test Set is: 35.94% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:49:27,430]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:49:58,733]\u001b[0m Trial 1294 finished with value: 7.308449904039587 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026459646555540193, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06664276138771359, 'dropout_rate_Layer_2': 0.16419477738583307, 'dropout_rate_Layer_3': 0.14943312848658347, 'dropout_rate_Layer_4': 0.13372672755350054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05326725595793758, 'l1_Layer_2': 0.0002761164202104372, 'l1_Layer_3': 6.049549487880048e-05, 'l1_Layer_4': 0.03135722745200016, 'n_units_Layer_1': 175, 'n_units_Layer_2': 70, 'n_units_Layer_3': 285, 'n_units_Layer_4': 285}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.31 | sMAPE for Validation Set is: 17.74% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.73 | sMAPE for Test Set is: 38.33% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:50:03,272]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:50:08,374]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:50:09,269]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:50:17,086]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:50:24,204]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:50:44,433]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:52:02,207]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:52:10,213]\u001b[0m Trial 1291 finished with value: 6.8181132124311645 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005643651893446341, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06152026566026911, 'dropout_rate_Layer_2': 0.05543231900832173, 'dropout_rate_Layer_3': 0.038993838329715556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003105203122305448, 'l1_Layer_2': 0.0002058316553633494, 'l1_Layer_3': 0.0001309961040210084, 'n_units_Layer_1': 190, 'n_units_Layer_2': 100, 'n_units_Layer_3': 145}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 16.27% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.34 | sMAPE for Test Set is: 34.92% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:52:19,874]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:52:55,638]\u001b[0m Trial 1303 finished with value: 7.123449671095311 and parameters: {'n_hidden': 3, 'learning_rate': 0.001727355132810787, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1060604191675531, 'dropout_rate_Layer_2': 0.14815204144301894, 'dropout_rate_Layer_3': 0.3733214256465818, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04719827204321318, 'l1_Layer_2': 0.0011401797718832098, 'l1_Layer_3': 0.00987681044427299, 'n_units_Layer_1': 160, 'n_units_Layer_2': 175, 'n_units_Layer_3': 290}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.12 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.68 | sMAPE for Test Set is: 36.62% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:53:01,210]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:53:04,823]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:54:00,724]\u001b[0m Trial 1308 finished with value: 7.265676637559408 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016468044432988989, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.056021249576347076, 'dropout_rate_Layer_2': 0.11987519304710645, 'dropout_rate_Layer_3': 0.129341753173476, 'dropout_rate_Layer_4': 0.13605764887015445, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.025337840726452884, 'l1_Layer_2': 0.00040254956197626564, 'l1_Layer_3': 2.078919646050252e-05, 'l1_Layer_4': 0.06772768043395846, 'n_units_Layer_1': 160, 'n_units_Layer_2': 100, 'n_units_Layer_3': 285, 'n_units_Layer_4': 280}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.27 | sMAPE for Validation Set is: 17.60% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.74 | sMAPE for Test Set is: 38.25% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:54:19,739]\u001b[0m Trial 1299 finished with value: 7.081894533951632 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005157998898737309, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0020806044680896155, 'dropout_rate_Layer_2': 0.3235430415758125, 'dropout_rate_Layer_3': 0.18937774328781368, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019867523666234347, 'l1_Layer_2': 0.0009748603324976793, 'l1_Layer_3': 0.00021824528032541083, 'n_units_Layer_1': 110, 'n_units_Layer_2': 270, 'n_units_Layer_3': 145}. Best is trial 1211 with value: 6.772384909301497.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.08 | sMAPE for Validation Set is: 16.96% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 15.08 | sMAPE for Test Set is: 35.69% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:54:25,271]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:55:20,232]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:55:36,579]\u001b[0m Trial 1302 finished with value: 6.757749072660725 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006287743993951281, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.058357464509871185, 'dropout_rate_Layer_2': 0.10995038559204634, 'dropout_rate_Layer_3': 0.06227676890027943, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004428372744310182, 'l1_Layer_2': 0.00018463901204702663, 'l1_Layer_3': 1.3530165366651737e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 90, 'n_units_Layer_3': 160}. Best is trial 1302 with value: 6.757749072660725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.76 | sMAPE for Validation Set is: 16.19% | rMAE for Validation Set is: 0.42\n",
      "MAE for Test Set is: 14.19 | sMAPE for Test Set is: 38.29% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:55:45,711]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:56:33,177]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:57:12,027]\u001b[0m Trial 1314 finished with value: 7.150818863838523 and parameters: {'n_hidden': 4, 'learning_rate': 0.00124622110991107, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0526389507916154, 'dropout_rate_Layer_2': 0.12007114942465302, 'dropout_rate_Layer_3': 0.12041023782131666, 'dropout_rate_Layer_4': 0.11930373084297255, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.024646513396973768, 'l1_Layer_2': 0.00044775983375258276, 'l1_Layer_3': 1.9805443928270955e-05, 'l1_Layer_4': 0.07833138678835208, 'n_units_Layer_1': 160, 'n_units_Layer_2': 100, 'n_units_Layer_3': 285, 'n_units_Layer_4': 285}. Best is trial 1302 with value: 6.757749072660725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.15 | sMAPE for Validation Set is: 17.27% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.66 | sMAPE for Test Set is: 37.26% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:57:15,325]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:57:22,901]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:57:34,888]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:57:36,292]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:58:49,998]\u001b[0m Trial 1311 finished with value: 7.017694236110042 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005732295711944273, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013507631086508771, 'dropout_rate_Layer_2': 0.3288959275156435, 'dropout_rate_Layer_3': 0.18478626942268334, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015086478700066666, 'l1_Layer_2': 0.0014968540796997448, 'l1_Layer_3': 0.00022235937495384712, 'n_units_Layer_1': 110, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135}. Best is trial 1302 with value: 6.757749072660725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.02 | sMAPE for Validation Set is: 16.80% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.85 | sMAPE for Test Set is: 35.95% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:59:08,490]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 11:59:25,192]\u001b[0m Trial 1319 finished with value: 6.970413744186556 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005539040622676624, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08992243270095783, 'dropout_rate_Layer_2': 0.0941851559273863, 'dropout_rate_Layer_3': 0.06652984122809869, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025862997234503654, 'l1_Layer_2': 0.00016568119064689415, 'l1_Layer_3': 1.7011594776313277e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 90, 'n_units_Layer_3': 160}. Best is trial 1302 with value: 6.757749072660725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.97 | sMAPE for Validation Set is: 16.63% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.60 | sMAPE for Test Set is: 40.13% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 11:59:33,894]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:00:05,154]\u001b[0m Trial 1320 finished with value: 6.878267521266609 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005610840432385518, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09095678111980211, 'dropout_rate_Layer_2': 0.09546617882128232, 'dropout_rate_Layer_3': 0.06556714875027353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00044452892565741695, 'l1_Layer_2': 0.00016154566443656897, 'l1_Layer_3': 1.5067695279461888e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 90, 'n_units_Layer_3': 165}. Best is trial 1302 with value: 6.757749072660725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.88 | sMAPE for Validation Set is: 16.43% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.34 | sMAPE for Test Set is: 36.38% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:00:12,231]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:00:18,413]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:00:29,685]\u001b[0m Trial 1312 finished with value: 6.74856899151922 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005511933931195652, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07158918595121341, 'dropout_rate_Layer_2': 0.05562197649503065, 'dropout_rate_Layer_3': 0.03532434979235855, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00046734430734901924, 'l1_Layer_2': 0.00019907881866736978, 'l1_Layer_3': 1.032021162915341e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 110, 'n_units_Layer_3': 150}. Best is trial 1312 with value: 6.74856899151922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.75 | sMAPE for Validation Set is: 16.12% | rMAE for Validation Set is: 0.42\n",
      "MAE for Test Set is: 14.20 | sMAPE for Test Set is: 34.29% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:00:39,001]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:01:03,515]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:01:12,073]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:01:20,433]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:01:24,883]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:01:29,979]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:01:41,962]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:02:10,616]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:02:53,440]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:03:12,649]\u001b[0m Trial 1324 finished with value: 7.01777752769837 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005026903048637236, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015292325610548415, 'dropout_rate_Layer_2': 0.32372232083557173, 'dropout_rate_Layer_3': 0.18531395714602691, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029011517530640543, 'l1_Layer_2': 0.0014627711365997813, 'l1_Layer_3': 0.00021526181831472199, 'n_units_Layer_1': 105, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 1312 with value: 6.74856899151922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.02 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.93 | sMAPE for Test Set is: 36.28% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:03:40,789]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:03:50,700]\u001b[0m Trial 1337 finished with value: 7.163994640051986 and parameters: {'n_hidden': 4, 'learning_rate': 0.001255038870332871, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.050871443923936846, 'dropout_rate_Layer_2': 0.12172673353050088, 'dropout_rate_Layer_3': 0.10600413749344711, 'dropout_rate_Layer_4': 0.1465761911273223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.019572310816003736, 'l1_Layer_2': 0.00025513566794614065, 'l1_Layer_3': 2.48006730799213e-05, 'l1_Layer_4': 0.05848553967140979, 'n_units_Layer_1': 160, 'n_units_Layer_2': 100, 'n_units_Layer_3': 300, 'n_units_Layer_4': 285}. Best is trial 1312 with value: 6.74856899151922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.16 | sMAPE for Validation Set is: 17.55% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.92 | sMAPE for Test Set is: 39.46% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:03:57,789]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:04:30,631]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:05:02,038]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:05:11,853]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:05:20,560]\u001b[0m Trial 1331 finished with value: 6.766822653812404 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006394102504558573, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07008129906138097, 'dropout_rate_Layer_2': 0.051590340462425464, 'dropout_rate_Layer_3': 0.016866796655515957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00045083620849984166, 'l1_Layer_2': 0.0002113753846339088, 'l1_Layer_3': 1.4586905464071125e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 100, 'n_units_Layer_3': 155}. Best is trial 1312 with value: 6.74856899151922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.77 | sMAPE for Validation Set is: 16.15% | rMAE for Validation Set is: 0.42\n",
      "MAE for Test Set is: 14.38 | sMAPE for Test Set is: 34.75% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:05:21,185]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:05:28,789]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:05:39,368]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:05:55,776]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:06:10,587]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:06:27,850]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:06:43,349]\u001b[0m Trial 1341 finished with value: 6.870447237501598 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005485345603846432, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07563648326038747, 'dropout_rate_Layer_2': 0.07033765090762854, 'dropout_rate_Layer_3': 0.07578949658659197, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002821891766578693, 'l1_Layer_2': 0.00019435508536127694, 'l1_Layer_3': 1.3843353271706472e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 105, 'n_units_Layer_3': 150}. Best is trial 1312 with value: 6.74856899151922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.87 | sMAPE for Validation Set is: 16.54% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.52 | sMAPE for Test Set is: 36.14% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:06:47,724]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:06:55,822]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:07:05,273]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:07:13,099]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:07:22,019]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:07:33,632]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:07:40,133]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:07:45,279]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:07:46,357]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:07:56,070]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:08:01,713]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:08:06,603]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:08:08,816]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:08:12,411]\u001b[0m Trial 1339 finished with value: 7.081083666449152 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006110435278605256, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018711216894561244, 'dropout_rate_Layer_2': 0.3125398177453752, 'dropout_rate_Layer_3': 0.16166178915657223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020163930383497165, 'l1_Layer_2': 0.0010766853972580444, 'l1_Layer_3': 0.00017047331066389116, 'n_units_Layer_1': 115, 'n_units_Layer_2': 265, 'n_units_Layer_3': 145}. Best is trial 1312 with value: 6.74856899151922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.08 | sMAPE for Validation Set is: 16.95% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 15.12 | sMAPE for Test Set is: 35.64% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:08:14,216]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:08:21,538]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:08:24,087]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:08:27,634]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:08:29,771]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:08:34,421]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:08:43,528]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:08:47,772]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:08:56,566]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:09:14,358]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:09:28,614]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:09:42,462]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:09:45,301]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:10:00,846]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:10:18,603]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:10:24,148]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:10:36,298]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:10:47,848]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:10:52,576]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:10:58,578]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:10:59,493]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:11:08,474]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:11:24,198]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:11:39,696]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:11:43,392]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:11:47,208]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:11:52,421]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:11:56,945]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:12:01,373]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:12:05,901]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:12:06,738]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:12:28,607]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:12:29,534]\u001b[0m Trial 1378 finished with value: 7.00798344600134 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005632904219011719, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010422281635913614, 'dropout_rate_Layer_2': 0.31427045613062793, 'dropout_rate_Layer_3': 0.15128648966268718, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002182536920979216, 'l1_Layer_2': 0.0015843431329788703, 'l1_Layer_3': 0.00016988004336952704, 'n_units_Layer_1': 115, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135}. Best is trial 1312 with value: 6.74856899151922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.01 | sMAPE for Validation Set is: 16.83% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.83 | sMAPE for Test Set is: 36.41% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:13:40,204]\u001b[0m Trial 1380 finished with value: 7.0958477745758755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005044257293068675, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010661521506615701, 'dropout_rate_Layer_2': 0.3092617958134029, 'dropout_rate_Layer_3': 0.1465357744716236, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022022521212190216, 'l1_Layer_2': 0.001654366840607768, 'l1_Layer_3': 0.00013927099496244727, 'n_units_Layer_1': 110, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135}. Best is trial 1312 with value: 6.74856899151922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.10 | sMAPE for Validation Set is: 17.25% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.99 | sMAPE for Test Set is: 36.61% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:14:33,430]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:14:42,239]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:14:59,692]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:15:05,323]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:15:13,588]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:15:39,662]\u001b[0m Trial 1396 finished with value: 6.807366756136413 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005467302429540602, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04966235428556899, 'dropout_rate_Layer_2': 0.06683437340978568, 'dropout_rate_Layer_3': 0.024121137160840377, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00033175630691348426, 'l1_Layer_2': 0.0001388342580890414, 'l1_Layer_3': 1.5762609466143287e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 90, 'n_units_Layer_3': 140}. Best is trial 1312 with value: 6.74856899151922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 16.36% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.51 | sMAPE for Test Set is: 34.92% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:16:17,194]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:16:25,721]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:16:31,331]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:17:20,742]\u001b[0m Trial 1400 finished with value: 6.842951024149162 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005067345626257337, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16683030710112318, 'dropout_rate_Layer_2': 0.06926281626724795, 'dropout_rate_Layer_3': 0.02637729965950927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003043051119235217, 'l1_Layer_2': 0.00013805525261118955, 'l1_Layer_3': 1.711276037984125e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 95, 'n_units_Layer_3': 140}. Best is trial 1312 with value: 6.74856899151922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.84 | sMAPE for Validation Set is: 16.34% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.40 | sMAPE for Test Set is: 34.35% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:17:28,731]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:17:42,783]\u001b[0m Trial 1399 finished with value: 6.735836281382394 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006495424877241274, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.046808735649116355, 'dropout_rate_Layer_2': 0.06947458941068885, 'dropout_rate_Layer_3': 0.02268234325364627, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00032717253325849956, 'l1_Layer_2': 0.00013920104002593123, 'l1_Layer_3': 1.5828104791641153e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 90, 'n_units_Layer_3': 140}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.74 | sMAPE for Validation Set is: 16.12% | rMAE for Validation Set is: 0.42\n",
      "MAE for Test Set is: 14.25 | sMAPE for Test Set is: 35.23% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:17:46,416]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:17:52,042]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:17:55,867]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:18:02,207]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:18:08,656]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:18:13,443]\u001b[0m Trial 1406 finished with value: 6.83422454247317 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005013221803390068, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.050894740137243294, 'dropout_rate_Layer_2': 0.0680705329754718, 'dropout_rate_Layer_3': 0.013345889770296947, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019940505328864842, 'l1_Layer_2': 0.0001840483976361558, 'l1_Layer_3': 1.8317085698147855e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 85, 'n_units_Layer_3': 140}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.83 | sMAPE for Validation Set is: 16.55% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.54 | sMAPE for Test Set is: 36.17% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:18:21,275]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:18:25,787]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:18:38,645]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:18:59,120]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:21:31,073]\u001b[0m Trial 1421 finished with value: 7.112107179890799 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005687956340346558, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007103379920878269, 'dropout_rate_Layer_2': 0.3150175285074144, 'dropout_rate_Layer_3': 0.18542418993762502, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017773304220583, 'l1_Layer_2': 0.0015911442163697638, 'l1_Layer_3': 0.0001752889484961699, 'n_units_Layer_1': 110, 'n_units_Layer_2': 260, 'n_units_Layer_3': 140}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 17.07% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.84 | sMAPE for Test Set is: 36.00% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:21:35,200]\u001b[0m Trial 1420 finished with value: 7.018630668569766 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005704117849409066, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01338288044496677, 'dropout_rate_Layer_2': 0.318707284310736, 'dropout_rate_Layer_3': 0.17505834149135396, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017360430844490994, 'l1_Layer_2': 0.0011799458037993552, 'l1_Layer_3': 0.00020893601354783642, 'n_units_Layer_1': 115, 'n_units_Layer_2': 260, 'n_units_Layer_3': 135}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.02 | sMAPE for Validation Set is: 16.91% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.69 | sMAPE for Test Set is: 35.73% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:21:44,937]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:21:50,912]\u001b[0m Trial 1415 finished with value: 6.964718327374652 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006517132052145729, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014045151769704133, 'dropout_rate_Layer_2': 0.29436381005673695, 'dropout_rate_Layer_3': 0.14902622060418483, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003480225062405236, 'l1_Layer_2': 0.0014054419930681725, 'l1_Layer_3': 0.00012384475529386425, 'n_units_Layer_1': 90, 'n_units_Layer_2': 270, 'n_units_Layer_3': 140}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.96 | sMAPE for Validation Set is: 16.78% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.82 | sMAPE for Test Set is: 35.78% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:21:53,600]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:22:00,129]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:22:00,747]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:22:21,246]\u001b[0m Trial 1422 finished with value: 6.762819168030994 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005548641192413458, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.042430787191116835, 'dropout_rate_Layer_2': 0.09420845153942618, 'dropout_rate_Layer_3': 0.02300813000995112, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019661383491438011, 'l1_Layer_2': 0.00015809048133442826, 'l1_Layer_3': 1.3605561885745259e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 90, 'n_units_Layer_3': 145}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.76 | sMAPE for Validation Set is: 16.34% | rMAE for Validation Set is: 0.42\n",
      "MAE for Test Set is: 14.45 | sMAPE for Test Set is: 36.29% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:22:43,946]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:23:02,306]\u001b[0m Trial 1430 finished with value: 7.193525577319623 and parameters: {'n_hidden': 4, 'learning_rate': 0.002067919696087753, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04365017346720331, 'dropout_rate_Layer_2': 0.13483533993026797, 'dropout_rate_Layer_3': 0.1477159156085822, 'dropout_rate_Layer_4': 0.04742817643229131, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.026680165079482374, 'l1_Layer_2': 0.0007817718540893311, 'l1_Layer_3': 2.466621203684098e-05, 'l1_Layer_4': 0.0463394255425826, 'n_units_Layer_1': 165, 'n_units_Layer_2': 95, 'n_units_Layer_3': 285, 'n_units_Layer_4': 290}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.19 | sMAPE for Validation Set is: 17.16% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.66 | sMAPE for Test Set is: 37.73% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:23:21,735]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:23:27,963]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:23:39,949]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:24:05,252]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:24:21,660]\u001b[0m Trial 1434 finished with value: 8.397581988863884 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010176228798491566, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06505234899306908, 'dropout_rate_Layer_2': 0.13852142322259342, 'dropout_rate_Layer_3': 0.1306111091209834, 'dropout_rate_Layer_4': 0.03377621656138895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.026534668002601246, 'l1_Layer_2': 0.0006245090937920098, 'l1_Layer_3': 2.5030579334956065e-05, 'l1_Layer_4': 0.06261572222757496, 'n_units_Layer_1': 145, 'n_units_Layer_2': 85, 'n_units_Layer_3': 285, 'n_units_Layer_4': 280}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.40 | sMAPE for Validation Set is: 20.57% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 15.96 | sMAPE for Test Set is: 46.72% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:24:48,092]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:24:56,374]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:26:18,688]\u001b[0m Trial 1431 finished with value: 7.007643375279073 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005610827989802659, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009745310386448516, 'dropout_rate_Layer_2': 0.31975499623544223, 'dropout_rate_Layer_3': 0.16709663946633566, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023446800849579087, 'l1_Layer_2': 0.002546430182466761, 'l1_Layer_3': 0.00010934242707383822, 'n_units_Layer_1': 115, 'n_units_Layer_2': 255, 'n_units_Layer_3': 140}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.01 | sMAPE for Validation Set is: 16.95% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.92 | sMAPE for Test Set is: 35.29% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:26:27,060]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:26:56,630]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:27:13,256]\u001b[0m Trial 1437 finished with value: 7.072606549195292 and parameters: {'n_hidden': 3, 'learning_rate': 0.000666733386821409, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01010380550319498, 'dropout_rate_Layer_2': 0.3180960334477384, 'dropout_rate_Layer_3': 0.184717535461824, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004039602512461742, 'l1_Layer_2': 0.0015470715020480797, 'l1_Layer_3': 0.00011292632732106784, 'n_units_Layer_1': 80, 'n_units_Layer_2': 265, 'n_units_Layer_3': 120}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.07 | sMAPE for Validation Set is: 16.90% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 15.01 | sMAPE for Test Set is: 37.19% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:27:45,599]\u001b[0m Trial 1435 finished with value: 6.920952729664923 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005590029044995165, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00900425814096072, 'dropout_rate_Layer_2': 0.3038204810048288, 'dropout_rate_Layer_3': 0.16509757524429966, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002841393464319327, 'l1_Layer_2': 0.0022789086854260675, 'l1_Layer_3': 0.00010638162691606524, 'n_units_Layer_1': 75, 'n_units_Layer_2': 255, 'n_units_Layer_3': 120}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.92 | sMAPE for Validation Set is: 16.78% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.68 | sMAPE for Test Set is: 36.20% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:27:58,447]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:30:19,917]\u001b[0m Trial 1441 finished with value: 7.021809825475433 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005531426869653117, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007647661598269112, 'dropout_rate_Layer_2': 0.32250687367956077, 'dropout_rate_Layer_3': 0.1627809984780073, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023673505420521564, 'l1_Layer_2': 0.002908229515998426, 'l1_Layer_3': 0.00010243915988504527, 'n_units_Layer_1': 85, 'n_units_Layer_2': 250, 'n_units_Layer_3': 120}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.02 | sMAPE for Validation Set is: 16.90% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.76 | sMAPE for Test Set is: 35.22% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:31:01,502]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:31:40,738]\u001b[0m Trial 1443 finished with value: 6.76268636316838 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005449512377510216, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04316418329928729, 'dropout_rate_Layer_2': 0.07890135274554516, 'dropout_rate_Layer_3': 0.030635118331025522, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002755705271296376, 'l1_Layer_2': 0.00023838581081490087, 'l1_Layer_3': 2.1434025931438578e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 95, 'n_units_Layer_3': 150}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.76 | sMAPE for Validation Set is: 16.21% | rMAE for Validation Set is: 0.42\n",
      "MAE for Test Set is: 14.33 | sMAPE for Test Set is: 38.41% | rMAE for Test Set is: 0.47\n",
      "MAE for Validation Set is: 7.09 | sMAPE for Validation Set is: 17.06% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.61 | sMAPE for Test Set is: 35.49% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:31:40,748]\u001b[0m Trial 1442 finished with value: 7.093410360933016 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005018655602059698, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008270733732001916, 'dropout_rate_Layer_2': 0.30038771226960065, 'dropout_rate_Layer_3': 0.1642542122401412, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002114982070206112, 'l1_Layer_2': 0.0034878646557452947, 'l1_Layer_3': 0.00010630654424687902, 'n_units_Layer_1': 80, 'n_units_Layer_2': 275, 'n_units_Layer_3': 130}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:32:00,343]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:32:00,496]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:32:36,843]\u001b[0m Trial 1445 finished with value: 6.746651044549555 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005496475643740913, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03855435240229033, 'dropout_rate_Layer_2': 0.10020333755751087, 'dropout_rate_Layer_3': 0.028860298961068974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018622313619582972, 'l1_Layer_2': 0.00023960620138182927, 'l1_Layer_3': 1.238853275360939e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 95, 'n_units_Layer_3': 150}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.75 | sMAPE for Validation Set is: 16.25% | rMAE for Validation Set is: 0.42\n",
      "MAE for Test Set is: 14.41 | sMAPE for Test Set is: 35.46% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:32:50,173]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:32:53,813]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:33:00,222]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:33:01,166]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:33:02,066]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:33:36,648]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:33:42,503]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:33:46,193]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:33:49,670]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:33:53,511]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:33:56,227]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:33:59,926]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:34:06,008]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:34:11,230]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:34:13,857]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:34:32,101]\u001b[0m Trial 1450 finished with value: 6.873504644858772 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005352865368079175, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05180386564334325, 'dropout_rate_Layer_2': 0.08693670605310634, 'dropout_rate_Layer_3': 0.02996222899708976, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000378784347692659, 'l1_Layer_2': 0.0003037223247528317, 'l1_Layer_3': 2.0805977081185805e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 100, 'n_units_Layer_3': 145}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.87 | sMAPE for Validation Set is: 16.52% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.39 | sMAPE for Test Set is: 37.33% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:34:39,809]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:34:56,530]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:35:01,808]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:35:15,314]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:35:19,330]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:35:24,725]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:35:53,373]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:36:02,383]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:36:16,063]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:36:44,398]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:36:52,877]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:37:00,560]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:37:01,073]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:38:01,839]\u001b[0m Trial 1467 finished with value: 7.254007597036202 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006188245119454506, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10434224188473595, 'dropout_rate_Layer_2': 0.12203841020473799, 'dropout_rate_Layer_3': 0.39976894217535164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0692398432194845, 'l1_Layer_2': 0.00884001287612008, 'l1_Layer_3': 0.019492527145979224, 'n_units_Layer_1': 145, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.25 | sMAPE for Validation Set is: 17.43% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.66 | sMAPE for Test Set is: 37.31% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:38:10,593]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:38:15,945]\u001b[0m Trial 1476 finished with value: 6.8255828938809415 and parameters: {'n_hidden': 3, 'learning_rate': 0.000627421449752295, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06500651658550327, 'dropout_rate_Layer_2': 0.05931277069260868, 'dropout_rate_Layer_3': 0.018409001127053556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018162798631711288, 'l1_Layer_2': 0.0001570253129807964, 'l1_Layer_3': 3.261105838947022e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 95, 'n_units_Layer_3': 150}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.83 | sMAPE for Validation Set is: 16.35% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.47 | sMAPE for Test Set is: 36.73% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:38:19,608]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:38:40,273]\u001b[0m Trial 1481 finished with value: 6.886289285934172 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005009445239801515, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08172251729671035, 'dropout_rate_Layer_2': 0.0896856244145396, 'dropout_rate_Layer_3': 0.0351943567863751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013560486459386463, 'l1_Layer_2': 0.00019924575005980715, 'l1_Layer_3': 1.2324653110336476e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 95, 'n_units_Layer_3': 140}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.89 | sMAPE for Validation Set is: 16.49% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 14.51 | sMAPE for Test Set is: 34.60% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:38:54,977]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:38:59,151]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:39:01,955]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:39:17,912]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:40:00,588]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:40:36,650]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:41:11,444]\u001b[0m Trial 1488 finished with value: 7.115686830266671 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005840542303209877, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023579488689610316, 'dropout_rate_Layer_2': 0.2963294604861772, 'dropout_rate_Layer_3': 0.18540213564591376, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00042618891877424015, 'l1_Layer_2': 0.002049590670594343, 'l1_Layer_3': 0.0001229567605835088, 'n_units_Layer_1': 85, 'n_units_Layer_2': 275, 'n_units_Layer_3': 130}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.12 | sMAPE for Validation Set is: 17.21% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 14.75 | sMAPE for Test Set is: 35.59% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:41:15,751]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:41:43,044]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:41:51,917]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:42:00,066]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:42:06,655]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:42:11,048]\u001b[0m Trial 1480 finished with value: 7.011768853195996 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005966458616045124, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021393278911347582, 'dropout_rate_Layer_2': 0.2962856075969547, 'dropout_rate_Layer_3': 0.18311042597167224, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00037965240380271773, 'l1_Layer_2': 0.0028332667561716167, 'l1_Layer_3': 0.00013919600087912757, 'n_units_Layer_1': 85, 'n_units_Layer_2': 275, 'n_units_Layer_3': 130}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.01 | sMAPE for Validation Set is: 16.80% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.67 | sMAPE for Test Set is: 34.49% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:42:17,083]\u001b[0m Trial 1484 finished with value: 7.04021165929693 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005001102747671208, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02088767987438418, 'dropout_rate_Layer_2': 0.29913617190105574, 'dropout_rate_Layer_3': 0.15362360369656644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00037861084747715435, 'l1_Layer_2': 0.0027308067803833162, 'l1_Layer_3': 0.00012762051253572705, 'n_units_Layer_1': 90, 'n_units_Layer_2': 275, 'n_units_Layer_3': 130}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 16.84% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.85 | sMAPE for Test Set is: 35.32% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:42:19,632]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 12:42:31,798]\u001b[0m Trial 1498 finished with value: 7.347288980035586 and parameters: {'n_hidden': 3, 'learning_rate': 0.003067672467821554, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11069966884261212, 'dropout_rate_Layer_2': 0.1974417698476518, 'dropout_rate_Layer_3': 0.3922377802818089, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.04273784233459083, 'l1_Layer_2': 0.00023556292798814375, 'l1_Layer_3': 0.004760614080082015, 'n_units_Layer_1': 130, 'n_units_Layer_2': 65, 'n_units_Layer_3': 265}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.35 | sMAPE for Validation Set is: 17.71% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 14.86 | sMAPE for Test Set is: 39.68% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 12:43:28,420]\u001b[0m Trial 1496 finished with value: 7.002085605819798 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005464057199153071, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02386196112652664, 'dropout_rate_Layer_2': 0.2933007238473488, 'dropout_rate_Layer_3': 0.15548509178600414, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00040856341743868315, 'l1_Layer_2': 0.0021321198261482744, 'l1_Layer_3': 5.936109105145861e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 255, 'n_units_Layer_3': 115}. Best is trial 1399 with value: 6.735836281382394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.00 | sMAPE for Validation Set is: 16.75% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 14.70 | sMAPE for Test Set is: 34.51% | rMAE for Test Set is: 0.48\n",
      "for 2022-01-01, MAE is:7.67 & sMAPE is:19.89% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 19.89% & 0.71\n",
      "for 2022-01-02, MAE is:1.93 & sMAPE is:5.58% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 12.73% & 0.42\n",
      "for 2022-01-03, MAE is:4.41 & sMAPE is:14.43% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 13.30% & 0.34\n",
      "for 2022-01-04, MAE is:6.69 & sMAPE is:16.61% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 14.13% & 0.36\n",
      "for 2022-01-05, MAE is:6.39 & sMAPE is:12.56% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 13.81% & 0.35\n",
      "for 2022-01-06, MAE is:8.68 & sMAPE is:17.96% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 14.50% & 0.46\n",
      "for 2022-01-07, MAE is:4.41 & sMAPE is:8.99% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 13.72% & 0.44\n",
      "for 2022-01-08, MAE is:3.40 & sMAPE is:7.80% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 12.98% & 0.45\n",
      "for 2022-01-09, MAE is:4.19 & sMAPE is:9.75% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 12.62% & 0.45\n",
      "for 2022-01-10, MAE is:3.63 & sMAPE is:7.54% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 12.11% & 0.43\n",
      "for 2022-01-11, MAE is:9.12 & sMAPE is:26.98% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 13.46% & 0.46\n",
      "for 2022-01-12, MAE is:5.95 & sMAPE is:25.55% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 14.47% & 0.43\n",
      "for 2022-01-13, MAE is:3.52 & sMAPE is:19.92% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 14.89% & 0.41\n",
      "for 2022-01-14, MAE is:5.96 & sMAPE is:42.26% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 16.84% & 0.39\n",
      "for 2022-01-15, MAE is:2.15 & sMAPE is:11.69% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 16.50% & 0.37\n",
      "for 2022-01-16, MAE is:1.89 & sMAPE is:11.74% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 16.20% & 0.35\n",
      "for 2022-01-17, MAE is:0.99 & sMAPE is:6.26% & rMAE is:0.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 15.62% & 0.33\n",
      "for 2022-01-18, MAE is:2.37 & sMAPE is:14.47% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 15.55% & 0.33\n",
      "for 2022-01-19, MAE is:1.92 & sMAPE is:12.44% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 15.39% & 0.33\n",
      "for 2022-01-20, MAE is:0.84 & sMAPE is:6.71% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 14.96% & 0.32\n",
      "for 2022-01-21, MAE is:3.89 & sMAPE is:24.62% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 15.42% & 0.41\n",
      "for 2022-01-22, MAE is:1.99 & sMAPE is:13.06% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 15.31% & 0.41\n",
      "for 2022-01-23, MAE is:1.00 & sMAPE is:8.43% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 15.01% & 0.40\n",
      "for 2022-01-24, MAE is:2.32 & sMAPE is:21.40% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 15.28% & 0.40\n",
      "for 2022-01-25, MAE is:1.66 & sMAPE is:12.44% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 15.16% & 0.40\n",
      "for 2022-01-26, MAE is:2.18 & sMAPE is:15.75% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.81 & 15.19% & 0.47\n",
      "for 2022-01-27, MAE is:12.48 & sMAPE is:39.97% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 16.10% & 0.49\n",
      "for 2022-01-28, MAE is:6.92 & sMAPE is:59.70% & rMAE is:2.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 17.66% & 0.56\n",
      "for 2022-01-29, MAE is:1.59 & sMAPE is:10.92% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 17.43% & 0.59\n",
      "for 2022-01-30, MAE is:1.55 & sMAPE is:12.08% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 17.25% & 0.59\n",
      "for 2022-01-31, MAE is:12.27 & sMAPE is:56.75% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 18.52% & 0.60\n",
      "for 2022-02-01, MAE is:5.77 & sMAPE is:26.15% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 18.76% & 0.61\n",
      "for 2022-02-02, MAE is:55.42 & sMAPE is:102.45% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 21.30% & 0.62\n",
      "for 2022-02-03, MAE is:16.04 & sMAPE is:58.74% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 22.40% & 0.63\n",
      "for 2022-02-04, MAE is:4.20 & sMAPE is:25.56% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 22.49% & 0.68\n",
      "for 2022-02-05, MAE is:0.85 & sMAPE is:6.73% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 22.05% & 0.67\n",
      "for 2022-02-06, MAE is:1.76 & sMAPE is:14.46% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 21.85% & 0.69\n",
      "for 2022-02-07, MAE is:1.46 & sMAPE is:10.89% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 21.56% & 0.67\n",
      "for 2022-02-08, MAE is:1.06 & sMAPE is:7.80% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 21.21% & 0.66\n",
      "for 2022-02-09, MAE is:9.90 & sMAPE is:51.14% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 21.95% & 0.65\n",
      "for 2022-02-10, MAE is:0.88 & sMAPE is:7.36% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 21.60% & 0.63\n",
      "for 2022-02-11, MAE is:0.78 & sMAPE is:7.01% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 21.25% & 0.63\n",
      "for 2022-02-12, MAE is:1.87 & sMAPE is:15.72% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 21.12% & 0.66\n",
      "for 2022-02-13, MAE is:0.50 & sMAPE is:4.20% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 20.74% & 0.65\n",
      "for 2022-02-14, MAE is:2.11 & sMAPE is:14.11% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 20.59% & 0.67\n",
      "for 2022-02-15, MAE is:0.73 & sMAPE is:5.50% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 20.26% & 0.67\n",
      "for 2022-02-16, MAE is:2.26 & sMAPE is:16.03% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 20.17% & 0.68\n",
      "for 2022-02-17, MAE is:1.27 & sMAPE is:7.84% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 19.92% & 0.67\n",
      "for 2022-02-18, MAE is:0.94 & sMAPE is:6.61% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 19.64% & 0.67\n",
      "for 2022-02-19, MAE is:2.08 & sMAPE is:15.05% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 19.55% & 0.68\n",
      "for 2022-02-20, MAE is:1.73 & sMAPE is:13.46% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 19.43% & 0.68\n",
      "for 2022-02-21, MAE is:2.77 & sMAPE is:19.05% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 19.42% & 0.70\n",
      "for 2022-02-22, MAE is:40.32 & sMAPE is:59.31% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 20.18% & 0.70\n",
      "for 2022-02-23, MAE is:13.20 & sMAPE is:178.20% & rMAE is:5.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 23.10% & 0.79\n",
      "for 2022-02-24, MAE is:3.12 & sMAPE is:26.62% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 23.17% & 0.80\n",
      "for 2022-02-25, MAE is:1.66 & sMAPE is:12.51% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 22.98% & 0.81\n",
      "for 2022-02-26, MAE is:0.41 & sMAPE is:2.92% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 22.63% & 0.80\n",
      "for 2022-02-27, MAE is:0.68 & sMAPE is:4.80% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 22.32% & 0.79\n",
      "for 2022-02-28, MAE is:0.98 & sMAPE is:6.49% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 22.05% & 0.79\n",
      "for 2022-03-01, MAE is:11.47 & sMAPE is:52.85% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 22.56% & 0.78\n",
      "for 2022-03-02, MAE is:1.53 & sMAPE is:11.99% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 22.39% & 0.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-03-03, MAE is:3.54 & sMAPE is:20.22% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 22.35% & 0.78\n",
      "for 2022-03-04, MAE is:1.72 & sMAPE is:9.68% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 22.15% & 0.78\n",
      "for 2022-03-05, MAE is:1.50 & sMAPE is:10.51% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 21.97% & 0.80\n",
      "for 2022-03-06, MAE is:3.13 & sMAPE is:25.03% & rMAE is:7.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 22.02% & 0.90\n",
      "for 2022-03-07, MAE is:0.81 & sMAPE is:5.59% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 21.77% & 0.90\n",
      "for 2022-03-08, MAE is:3.29 & sMAPE is:21.32% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 21.76% & 0.91\n",
      "for 2022-03-09, MAE is:0.54 & sMAPE is:3.55% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 21.50% & 0.90\n",
      "for 2022-03-10, MAE is:0.83 & sMAPE is:6.19% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.89 & 21.27% & 0.89\n",
      "for 2022-03-11, MAE is:0.97 & sMAPE is:6.91% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 21.07% & 0.88\n",
      "for 2022-03-12, MAE is:1.18 & sMAPE is:8.73% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 20.89% & 0.88\n",
      "for 2022-03-13, MAE is:3.28 & sMAPE is:23.71% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 20.93% & 0.90\n",
      "for 2022-03-14, MAE is:2.41 & sMAPE is:14.49% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 20.85% & 0.90\n",
      "for 2022-03-15, MAE is:1.83 & sMAPE is:10.46% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 20.71% & 0.91\n",
      "for 2022-03-16, MAE is:0.59 & sMAPE is:4.07% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 20.48% & 0.90\n",
      "for 2022-03-17, MAE is:1.10 & sMAPE is:8.08% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 20.32% & 0.90\n",
      "for 2022-03-18, MAE is:1.30 & sMAPE is:9.66% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 20.18% & 0.90\n",
      "for 2022-03-19, MAE is:0.87 & sMAPE is:7.36% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 20.02% & 0.90\n",
      "for 2022-03-20, MAE is:1.51 & sMAPE is:11.55% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 19.91% & 0.89\n",
      "for 2022-03-21, MAE is:3.18 & sMAPE is:18.70% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 19.89% & 0.91\n",
      "for 2022-03-22, MAE is:7.88 & sMAPE is:32.22% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 20.05% & 0.91\n",
      "for 2022-03-23, MAE is:1.77 & sMAPE is:13.39% & rMAE is:3.70 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 19.97% & 0.94\n",
      "for 2022-03-24, MAE is:2.27 & sMAPE is:17.70% & rMAE is:2.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 19.94% & 0.96\n",
      "for 2022-03-25, MAE is:1.51 & sMAPE is:12.35% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 19.85% & 0.97\n",
      "for 2022-03-26, MAE is:5.60 & sMAPE is:40.69% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 20.09% & 0.97\n",
      "for 2022-03-27, MAE is:3.85 & sMAPE is:24.18% & rMAE is:3.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 20.14% & 1.00\n",
      "for 2022-03-28, MAE is:1.63 & sMAPE is:12.71% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 20.06% & 0.99\n",
      "for 2022-03-29, MAE is:14.08 & sMAPE is:46.17% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 20.35% & 0.99\n",
      "for 2022-03-30, MAE is:13.51 & sMAPE is:43.59% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 20.61% & 0.99\n",
      "for 2022-03-31, MAE is:25.68 & sMAPE is:44.46% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 20.88% & 0.98\n",
      "for 2022-04-01, MAE is:36.92 & sMAPE is:42.55% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 21.12% & 0.98\n",
      "for 2022-04-02, MAE is:9.40 & sMAPE is:35.49% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 21.27% & 0.97\n",
      "for 2022-04-03, MAE is:19.64 & sMAPE is:44.28% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 21.52% & 0.97\n",
      "for 2022-04-04, MAE is:11.04 & sMAPE is:18.18% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 21.48% & 0.96\n",
      "for 2022-04-05, MAE is:24.65 & sMAPE is:56.88% & rMAE is:3.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 21.86% & 0.99\n",
      "for 2022-04-06, MAE is:7.71 & sMAPE is:20.88% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 21.85% & 0.99\n",
      "for 2022-04-07, MAE is:16.09 & sMAPE is:25.77% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 21.89% & 0.99\n",
      "for 2022-04-08, MAE is:29.56 & sMAPE is:81.34% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 22.49% & 0.98\n",
      "for 2022-04-09, MAE is:6.02 & sMAPE is:25.52% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 22.52% & 0.98\n",
      "for 2022-04-10, MAE is:12.03 & sMAPE is:60.52% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 22.90% & 0.97\n",
      "for 2022-04-11, MAE is:9.59 & sMAPE is:42.92% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 23.10% & 0.97\n",
      "for 2022-04-12, MAE is:64.29 & sMAPE is:85.61% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 23.72% & 0.97\n",
      "for 2022-04-13, MAE is:49.08 & sMAPE is:43.10% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 23.90% & 0.96\n",
      "for 2022-04-14, MAE is:22.77 & sMAPE is:30.08% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 23.96% & 0.97\n",
      "for 2022-04-15, MAE is:6.41 & sMAPE is:11.48% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 23.84% & 0.96\n",
      "for 2022-04-16, MAE is:4.07 & sMAPE is:8.78% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 23.70% & 0.95\n",
      "for 2022-04-17, MAE is:14.58 & sMAPE is:32.21% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 23.78% & 0.95\n",
      "for 2022-04-18, MAE is:9.27 & sMAPE is:17.35% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 23.72% & 0.94\n",
      "for 2022-04-19, MAE is:66.15 & sMAPE is:76.23% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 24.20% & 0.94\n",
      "for 2022-04-20, MAE is:11.24 & sMAPE is:16.10% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 24.13% & 0.94\n",
      "for 2022-04-21, MAE is:16.41 & sMAPE is:35.51% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 24.23% & 0.93\n",
      "for 2022-04-22, MAE is:8.50 & sMAPE is:27.64% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 24.26% & 0.93\n",
      "for 2022-04-23, MAE is:8.16 & sMAPE is:32.53% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 24.34% & 0.92\n",
      "for 2022-04-24, MAE is:10.87 & sMAPE is:34.45% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 24.43% & 0.92\n",
      "for 2022-04-25, MAE is:10.67 & sMAPE is:28.78% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 24.46% & 0.92\n",
      "for 2022-04-26, MAE is:9.27 & sMAPE is:34.49% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 24.55% & 0.91\n",
      "for 2022-04-27, MAE is:9.34 & sMAPE is:27.09% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.01 & 24.57% & 0.91\n",
      "for 2022-04-28, MAE is:4.30 & sMAPE is:23.64% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 24.56% & 0.90\n",
      "for 2022-04-29, MAE is:10.65 & sMAPE is:41.00% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 24.70% & 0.91\n",
      "for 2022-04-30, MAE is:6.42 & sMAPE is:27.08% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 24.72% & 0.91\n",
      "for 2022-05-01, MAE is:9.95 & sMAPE is:41.60% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 24.86% & 0.90\n",
      "for 2022-05-02, MAE is:1.50 & sMAPE is:12.01% & rMAE is:0.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 24.76% & 0.90\n",
      "for 2022-05-03, MAE is:3.94 & sMAPE is:22.30% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 24.74% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-05-04, MAE is:4.55 & sMAPE is:18.29% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.89 & 24.68% & 0.89\n",
      "for 2022-05-05, MAE is:4.40 & sMAPE is:28.83% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 24.72% & 0.89\n",
      "for 2022-05-06, MAE is:3.32 & sMAPE is:29.92% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 24.76% & 0.89\n",
      "for 2022-05-07, MAE is:1.55 & sMAPE is:30.78% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 24.81% & 0.88\n",
      "for 2022-05-08, MAE is:8.39 & sMAPE is:86.50% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 25.29% & 0.88\n",
      "for 2022-05-09, MAE is:1.96 & sMAPE is:13.95% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 25.20% & 0.88\n",
      "for 2022-05-10, MAE is:1.52 & sMAPE is:10.51% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 25.09% & 0.88\n",
      "for 2022-05-11, MAE is:1.30 & sMAPE is:13.05% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 24.99% & 0.87\n",
      "for 2022-05-12, MAE is:3.58 & sMAPE is:32.73% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 25.05% & 0.87\n",
      "for 2022-05-13, MAE is:4.93 & sMAPE is:50.06% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 25.24% & 0.88\n",
      "for 2022-05-14, MAE is:2.52 & sMAPE is:28.76% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 25.27% & 0.88\n",
      "for 2022-05-15, MAE is:0.97 & sMAPE is:15.93% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 25.20% & 0.88\n",
      "for 2022-05-16, MAE is:0.93 & sMAPE is:10.47% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 25.09% & 0.87\n",
      "for 2022-05-17, MAE is:3.43 & sMAPE is:32.49% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 25.14% & 0.89\n",
      "for 2022-05-18, MAE is:3.09 & sMAPE is:21.13% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 25.11% & 0.89\n",
      "for 2022-05-19, MAE is:3.64 & sMAPE is:34.77% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 25.18% & 0.89\n",
      "for 2022-05-20, MAE is:12.29 & sMAPE is:40.37% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 25.29% & 0.89\n",
      "for 2022-05-21, MAE is:13.20 & sMAPE is:187.77% & rMAE is:2.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 26.45% & 0.90\n",
      "for 2022-05-22, MAE is:1.24 & sMAPE is:8.83% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 26.32% & 0.90\n",
      "for 2022-05-23, MAE is:2.35 & sMAPE is:25.17% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 26.31% & 0.90\n",
      "for 2022-05-24, MAE is:0.84 & sMAPE is:13.11% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 26.22% & 0.89\n",
      "for 2022-05-25, MAE is:1.73 & sMAPE is:25.42% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 26.22% & 0.89\n",
      "for 2022-05-26, MAE is:2.79 & sMAPE is:37.61% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 26.29% & 0.89\n",
      "for 2022-05-27, MAE is:4.68 & sMAPE is:45.17% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 26.42% & 0.88\n",
      "for 2022-05-28, MAE is:3.31 & sMAPE is:69.89% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 26.72% & 0.88\n",
      "for 2022-05-29, MAE is:6.99 & sMAPE is:48.96% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 26.87% & 0.88\n",
      "for 2022-05-30, MAE is:55.85 & sMAPE is:73.80% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 27.18% & 0.88\n",
      "for 2022-05-31, MAE is:63.40 & sMAPE is:98.10% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 27.65% & 0.89\n",
      "for 2022-06-01, MAE is:51.98 & sMAPE is:153.74% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 28.48% & 0.89\n",
      "for 2022-06-02, MAE is:36.69 & sMAPE is:69.05% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 28.74% & 0.89\n",
      "for 2022-06-03, MAE is:6.49 & sMAPE is:85.36% & rMAE is:2.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.36 & 29.11% & 0.90\n",
      "for 2022-06-04, MAE is:3.03 & sMAPE is:34.98% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 29.15% & 0.90\n",
      "for 2022-06-05, MAE is:1.81 & sMAPE is:23.23% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.28 & 29.11% & 0.89\n",
      "for 2022-06-06, MAE is:7.75 & sMAPE is:104.00% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.28 & 29.59% & 0.89\n",
      "for 2022-06-07, MAE is:7.57 & sMAPE is:60.10% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :8.28 & 29.78% & 0.88\n",
      "for 2022-06-08, MAE is:3.39 & sMAPE is:37.02% & rMAE is:0.06 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 29.83% & 0.88\n",
      "for 2022-06-09, MAE is:3.21 & sMAPE is:34.49% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :8.21 & 29.85% & 0.87\n",
      "for 2022-06-10, MAE is:7.98 & sMAPE is:63.77% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :8.21 & 30.07% & 0.88\n",
      "for 2022-06-11, MAE is:2.37 & sMAPE is:21.25% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :8.18 & 30.01% & 0.88\n",
      "for 2022-06-12, MAE is:1.66 & sMAPE is:19.37% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 29.95% & 0.88\n",
      "for 2022-06-13, MAE is:1.18 & sMAPE is:12.94% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 29.84% & 0.87\n",
      "for 2022-06-14, MAE is:2.79 & sMAPE is:26.80% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.06 & 29.82% & 0.87\n",
      "for 2022-06-15, MAE is:1.90 & sMAPE is:16.57% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 29.74% & 0.87\n",
      "for 2022-06-16, MAE is:0.66 & sMAPE is:6.41% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 29.60% & 0.87\n",
      "for 2022-06-17, MAE is:1.61 & sMAPE is:15.65% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 29.52% & 0.86\n",
      "for 2022-06-18, MAE is:2.19 & sMAPE is:37.42% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 29.57% & 0.86\n",
      "for 2022-06-19, MAE is:2.39 & sMAPE is:42.47% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.88 & 29.64% & 0.86\n",
      "for 2022-06-20, MAE is:3.66 & sMAPE is:28.21% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 29.64% & 0.86\n",
      "for 2022-06-21, MAE is:2.37 & sMAPE is:25.76% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 29.61% & 0.86\n",
      "for 2022-06-22, MAE is:2.32 & sMAPE is:23.52% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 29.58% & 0.86\n",
      "for 2022-06-23, MAE is:1.26 & sMAPE is:26.91% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 29.56% & 0.85\n",
      "for 2022-06-24, MAE is:0.85 & sMAPE is:12.67% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 29.47% & 0.85\n",
      "for 2022-06-25, MAE is:0.69 & sMAPE is:18.85% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 29.41% & 0.85\n",
      "for 2022-06-26, MAE is:1.67 & sMAPE is:40.52% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 29.47% & 0.85\n",
      "for 2022-06-27, MAE is:3.98 & sMAPE is:200.00% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 30.43% & 0.84\n",
      "for 2022-06-28, MAE is:1.41 & sMAPE is:50.87% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 30.54% & 0.84\n",
      "for 2022-06-29, MAE is:2.20 & sMAPE is:116.25% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 31.02% & 0.84\n",
      "for 2022-06-30, MAE is:1.09 & sMAPE is:48.09% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 31.11% & 0.83\n",
      "for 2022-07-01, MAE is:0.51 & sMAPE is:22.57% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 31.06% & 0.83\n",
      "for 2022-07-02, MAE is:2.80 & sMAPE is:199.36% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 31.98% & 0.83\n",
      "for 2022-07-03, MAE is:0.57 & sMAPE is:54.28% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 32.10% & 0.83\n",
      "for 2022-07-04, MAE is:1.43 & sMAPE is:103.77% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 32.49% & 0.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-07-05, MAE is:2.00 & sMAPE is:199.01% & rMAE is:3.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 33.39% & 0.85\n",
      "for 2022-07-06, MAE is:1.98 & sMAPE is:167.22% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 34.10% & 0.85\n",
      "for 2022-07-07, MAE is:0.24 & sMAPE is:19.30% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 34.02% & 0.85\n",
      "for 2022-07-08, MAE is:0.64 & sMAPE is:79.67% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 34.27% & 0.85\n",
      "for 2022-07-09, MAE is:0.59 & sMAPE is:62.53% & rMAE is:3.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 34.41% & 0.86\n",
      "for 2022-07-10, MAE is:0.12 & sMAPE is:6.51% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 34.27% & 0.86\n",
      "for 2022-07-11, MAE is:2.18 & sMAPE is:108.44% & rMAE is:2.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 34.66% & 0.86\n",
      "for 2022-07-12, MAE is:1.22 & sMAPE is:49.65% & rMAE is:3.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 34.73% & 0.87\n",
      "for 2022-07-13, MAE is:0.43 & sMAPE is:26.82% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 34.69% & 0.88\n",
      "for 2022-07-14, MAE is:0.66 & sMAPE is:38.37% & rMAE is:2.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 34.71% & 0.88\n",
      "for 2022-07-15, MAE is:0.86 & sMAPE is:91.62% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 35.00% & 0.89\n",
      "for 2022-07-16, MAE is:2.13 & sMAPE is:200.00% & rMAE is:4.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 35.84% & 0.91\n",
      "for 2022-07-17, MAE is:3.06 & sMAPE is:200.00% & rMAE is:9.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 36.67% & 0.95\n",
      "for 2022-07-18, MAE is:1.43 & sMAPE is:122.69% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 37.10% & 0.95\n",
      "for 2022-07-19, MAE is:0.97 & sMAPE is:43.68% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 37.13% & 0.96\n",
      "for 2022-07-20, MAE is:1.03 & sMAPE is:74.75% & rMAE is:2.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 37.32% & 0.96\n",
      "for 2022-07-21, MAE is:0.65 & sMAPE is:23.19% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 37.25% & 0.96\n",
      "for 2022-07-22, MAE is:1.65 & sMAPE is:146.24% & rMAE is:3.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 37.79% & 0.97\n",
      "for 2022-07-23, MAE is:0.38 & sMAPE is:21.48% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 37.71% & 0.97\n",
      "for 2022-07-24, MAE is:2.18 & sMAPE is:195.52% & rMAE is:13.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 38.48% & 1.03\n",
      "for 2022-07-25, MAE is:2.42 & sMAPE is:188.18% & rMAE is:5.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 39.20% & 1.05\n",
      "for 2022-07-26, MAE is:0.57 & sMAPE is:39.85% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 39.21% & 1.05\n",
      "for 2022-07-27, MAE is:0.78 & sMAPE is:59.54% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 39.30% & 1.05\n",
      "for 2022-07-28, MAE is:0.89 & sMAPE is:39.77% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 39.31% & 1.06\n",
      "for 2022-07-29, MAE is:1.42 & sMAPE is:89.61% & rMAE is:3.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 39.55% & 1.07\n",
      "for 2022-07-30, MAE is:0.83 & sMAPE is:63.85% & rMAE is:3.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 39.66% & 1.08\n",
      "for 2022-07-31, MAE is:1.80 & sMAPE is:118.40% & rMAE is:2.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 40.03% & 1.09\n",
      "for 2022-08-01, MAE is:0.77 & sMAPE is:32.28% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 40.00% & 1.09\n",
      "for 2022-08-02, MAE is:0.74 & sMAPE is:50.41% & rMAE is:3.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 40.05% & 1.10\n",
      "for 2022-08-03, MAE is:1.86 & sMAPE is:151.94% & rMAE is:17.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 40.57% & 1.18\n",
      "for 2022-08-04, MAE is:0.92 & sMAPE is:47.99% & rMAE is:6.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 40.60% & 1.20\n",
      "for 2022-08-05, MAE is:0.36 & sMAPE is:21.05% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 40.51% & 1.20\n",
      "for 2022-08-06, MAE is:1.41 & sMAPE is:142.14% & rMAE is:4.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 40.98% & 1.21\n",
      "for 2022-08-07, MAE is:2.05 & sMAPE is:175.60% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 41.59% & 1.22\n",
      "for 2022-08-08, MAE is:0.43 & sMAPE is:19.82% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 41.49% & 1.22\n",
      "for 2022-08-09, MAE is:0.37 & sMAPE is:29.61% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 41.44% & 1.22\n",
      "for 2022-08-10, MAE is:0.99 & sMAPE is:142.58% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 41.89% & 1.22\n",
      "for 2022-08-11, MAE is:2.02 & sMAPE is:192.06% & rMAE is:3.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 42.57% & 1.23\n",
      "for 2022-08-12, MAE is:16.77 & sMAPE is:123.53% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 42.93% & 1.23\n",
      "for 2022-08-13, MAE is:45.07 & sMAPE is:85.54% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 43.12% & 1.23\n",
      "for 2022-08-14, MAE is:68.35 & sMAPE is:134.35% & rMAE is:3.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 43.52% & 1.24\n",
      "for 2022-08-15, MAE is:55.45 & sMAPE is:101.63% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 43.78% & 1.23\n",
      "for 2022-08-16, MAE is:58.57 & sMAPE is:102.11% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 44.03% & 1.23\n",
      "for 2022-08-17, MAE is:19.45 & sMAPE is:115.57% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 44.35% & 1.23\n",
      "for 2022-08-18, MAE is:25.67 & sMAPE is:119.77% & rMAE is:2.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 44.67% & 1.24\n",
      "for 2022-08-19, MAE is:19.98 & sMAPE is:100.90% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 44.92% & 1.24\n",
      "for 2022-08-20, MAE is:35.69 & sMAPE is:155.03% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 45.39% & 1.23\n",
      "for 2022-08-21, MAE is:14.63 & sMAPE is:41.93% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 45.38% & 1.23\n",
      "for 2022-08-22, MAE is:10.99 & sMAPE is:79.45% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 45.52% & 1.23\n",
      "for 2022-08-23, MAE is:16.76 & sMAPE is:60.25% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 45.59% & 1.22\n",
      "for 2022-08-24, MAE is:8.27 & sMAPE is:31.92% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 45.53% & 1.22\n",
      "for 2022-08-25, MAE is:7.65 & sMAPE is:45.89% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 45.53% & 1.22\n",
      "for 2022-08-26, MAE is:3.16 & sMAPE is:20.95% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 45.43% & 1.21\n",
      "for 2022-08-27, MAE is:4.09 & sMAPE is:36.37% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 45.39% & 1.21\n",
      "for 2022-08-28, MAE is:3.80 & sMAPE is:32.33% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 45.33% & 1.20\n",
      "for 2022-08-29, MAE is:9.50 & sMAPE is:56.72% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 45.38% & 1.20\n",
      "for 2022-08-30, MAE is:11.22 & sMAPE is:49.88% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 45.40% & 1.20\n",
      "for 2022-08-31, MAE is:5.54 & sMAPE is:21.48% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 45.30% & 1.20\n",
      "for 2022-09-01, MAE is:11.80 & sMAPE is:39.68% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 45.28% & 1.20\n",
      "for 2022-09-02, MAE is:9.75 & sMAPE is:27.19% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 45.20% & 1.19\n",
      "for 2022-09-03, MAE is:24.26 & sMAPE is:54.32% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 45.24% & 1.19\n",
      "for 2022-09-04, MAE is:118.96 & sMAPE is:63.00% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 45.31% & 1.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-09-05, MAE is:193.58 & sMAPE is:89.85% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.91 & 45.49% & 1.19\n",
      "for 2022-09-06, MAE is:31.78 & sMAPE is:32.11% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :9.00 & 45.44% & 1.19\n",
      "for 2022-09-07, MAE is:13.10 & sMAPE is:17.63% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :9.02 & 45.33% & 1.18\n",
      "for 2022-09-08, MAE is:14.02 & sMAPE is:17.86% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :9.04 & 45.22% & 1.18\n",
      "for 2022-09-09, MAE is:13.25 & sMAPE is:15.57% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :9.06 & 45.10% & 1.18\n",
      "for 2022-09-10, MAE is:26.84 & sMAPE is:25.45% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :9.13 & 45.02% & 1.17\n",
      "for 2022-09-11, MAE is:74.18 & sMAPE is:44.68% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 45.02% & 1.17\n",
      "for 2022-09-12, MAE is:97.45 & sMAPE is:50.77% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :9.73 & 45.04% & 1.17\n",
      "for 2022-09-13, MAE is:33.34 & sMAPE is:46.23% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :9.82 & 45.05% & 1.17\n",
      "for 2022-09-14, MAE is:21.70 & sMAPE is:36.74% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.87 & 45.02% & 1.17\n",
      "for 2022-09-15, MAE is:13.59 & sMAPE is:34.66% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :9.88 & 44.98% & 1.17\n",
      "for 2022-09-16, MAE is:12.81 & sMAPE is:32.82% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :9.89 & 44.93% & 1.16\n",
      "for 2022-09-17, MAE is:8.29 & sMAPE is:27.94% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :9.89 & 44.86% & 1.16\n",
      "for 2022-09-18, MAE is:10.93 & sMAPE is:33.74% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :9.89 & 44.82% & 1.15\n",
      "for 2022-09-19, MAE is:11.40 & sMAPE is:37.08% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :9.90 & 44.79% & 1.15\n",
      "for 2022-09-20, MAE is:35.92 & sMAPE is:65.31% & rMAE is:2.86 ||| daily mean of MAE & sMAPE & rMAE till now are :9.99 & 44.87% & 1.16\n",
      "for 2022-09-21, MAE is:10.34 & sMAPE is:20.44% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :10.00 & 44.78% & 1.15\n",
      "for 2022-09-22, MAE is:16.79 & sMAPE is:35.38% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :10.02 & 44.74% & 1.15\n",
      "for 2022-09-23, MAE is:17.25 & sMAPE is:28.76% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :10.05 & 44.68% & 1.15\n",
      "for 2022-09-24, MAE is:6.45 & sMAPE is:9.98% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :10.03 & 44.55% & 1.15\n",
      "for 2022-09-25, MAE is:25.26 & sMAPE is:46.03% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.09 & 44.56% & 1.15\n",
      "for 2022-09-26, MAE is:12.19 & sMAPE is:29.82% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :10.10 & 44.50% & 1.15\n",
      "for 2022-09-27, MAE is:6.09 & sMAPE is:24.05% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :10.08 & 44.43% & 1.15\n",
      "for 2022-09-28, MAE is:19.90 & sMAPE is:53.40% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :10.12 & 44.46% & 1.15\n",
      "for 2022-09-29, MAE is:42.95 & sMAPE is:54.94% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.24 & 44.50% & 1.15\n",
      "for 2022-09-30, MAE is:38.31 & sMAPE is:42.15% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :10.34 & 44.49% & 1.15\n",
      "for 2022-10-01, MAE is:13.35 & sMAPE is:29.79% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 44.44% & 1.15\n",
      "for 2022-10-02, MAE is:29.42 & sMAPE is:33.76% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 44.40% & 1.15\n",
      "for 2022-10-03, MAE is:19.67 & sMAPE is:29.28% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 44.34% & 1.15\n",
      "for 2022-10-04, MAE is:11.84 & sMAPE is:21.60% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 44.26% & 1.15\n",
      "for 2022-10-05, MAE is:25.21 & sMAPE is:77.98% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :10.52 & 44.38% & 1.14\n",
      "for 2022-10-06, MAE is:8.35 & sMAPE is:116.63% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :10.51 & 44.64% & 1.14\n",
      "for 2022-10-07, MAE is:5.61 & sMAPE is:78.13% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :10.49 & 44.76% & 1.14\n",
      "for 2022-10-08, MAE is:3.01 & sMAPE is:67.11% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 44.84% & 1.13\n",
      "for 2022-10-09, MAE is:5.98 & sMAPE is:68.83% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 44.92% & 1.13\n",
      "for 2022-10-10, MAE is:1.95 & sMAPE is:19.97% & rMAE is:0.04 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 44.84% & 1.13\n",
      "for 2022-10-11, MAE is:3.28 & sMAPE is:45.59% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :10.39 & 44.84% & 1.12\n",
      "for 2022-10-12, MAE is:7.91 & sMAPE is:66.86% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :10.38 & 44.92% & 1.12\n",
      "for 2022-10-13, MAE is:9.79 & sMAPE is:50.99% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :10.38 & 44.94% & 1.12\n",
      "for 2022-10-14, MAE is:4.62 & sMAPE is:23.82% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 44.86% & 1.12\n",
      "for 2022-10-15, MAE is:2.38 & sMAPE is:13.64% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 44.76% & 1.11\n",
      "for 2022-10-16, MAE is:4.84 & sMAPE is:32.14% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :10.32 & 44.71% & 1.11\n",
      "for 2022-10-17, MAE is:5.18 & sMAPE is:23.18% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :10.30 & 44.64% & 1.11\n",
      "for 2022-10-18, MAE is:5.01 & sMAPE is:19.00% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 44.55% & 1.11\n",
      "for 2022-10-19, MAE is:1.38 & sMAPE is:7.05% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.25 & 44.42% & 1.10\n",
      "for 2022-10-20, MAE is:33.48 & sMAPE is:90.23% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 44.58% & 1.10\n",
      "for 2022-10-21, MAE is:18.59 & sMAPE is:25.73% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 44.51% & 1.10\n",
      "for 2022-10-22, MAE is:29.91 & sMAPE is:36.98% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 44.49% & 1.10\n",
      "for 2022-10-23, MAE is:9.69 & sMAPE is:21.15% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 44.41% & 1.10\n",
      "for 2022-10-24, MAE is:18.43 & sMAPE is:35.01% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 44.38% & 1.09\n",
      "for 2022-10-25, MAE is:29.28 & sMAPE is:61.90% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :10.51 & 44.44% & 1.09\n",
      "for 2022-10-26, MAE is:14.77 & sMAPE is:21.99% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :10.52 & 44.36% & 1.09\n",
      "for 2022-10-27, MAE is:21.31 & sMAPE is:47.41% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :10.56 & 44.37% & 1.09\n",
      "for 2022-10-28, MAE is:2.84 & sMAPE is:10.44% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :10.53 & 44.26% & 1.09\n",
      "for 2022-10-29, MAE is:14.66 & sMAPE is:70.70% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :10.55 & 44.35% & 1.09\n",
      "for 2022-10-30, MAE is:19.16 & sMAPE is:62.05% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :10.58 & 44.40% & 1.09\n",
      "for 2022-10-31, MAE is:4.03 & sMAPE is:9.60% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.56 & 44.29% & 1.08\n",
      "for 2022-11-01, MAE is:8.15 & sMAPE is:27.78% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.55 & 44.24% & 1.08\n",
      "for 2022-11-02, MAE is:18.93 & sMAPE is:58.20% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :10.57 & 44.28% & 1.08\n",
      "for 2022-11-03, MAE is:8.79 & sMAPE is:27.29% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :10.57 & 44.23% & 1.08\n",
      "for 2022-11-04, MAE is:4.74 & sMAPE is:18.31% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :10.55 & 44.14% & 1.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-11-05, MAE is:4.43 & sMAPE is:17.97% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.53 & 44.06% & 1.08\n",
      "for 2022-11-06, MAE is:5.09 & sMAPE is:15.18% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :10.51 & 43.96% & 1.08\n",
      "for 2022-11-07, MAE is:15.43 & sMAPE is:45.59% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :10.53 & 43.97% & 1.08\n",
      "for 2022-11-08, MAE is:9.01 & sMAPE is:20.63% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :10.52 & 43.89% & 1.08\n",
      "for 2022-11-09, MAE is:4.78 & sMAPE is:17.10% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :10.51 & 43.81% & 1.07\n",
      "for 2022-11-10, MAE is:7.21 & sMAPE is:30.36% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :10.49 & 43.77% & 1.07\n",
      "for 2022-11-11, MAE is:13.66 & sMAPE is:160.23% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :10.50 & 44.14% & 1.07\n",
      "for 2022-11-12, MAE is:2.78 & sMAPE is:142.79% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :10.48 & 44.45% & 1.07\n",
      "for 2022-11-13, MAE is:19.01 & sMAPE is:118.17% & rMAE is:2.55 ||| daily mean of MAE & sMAPE & rMAE till now are :10.51 & 44.68% & 1.07\n",
      "for 2022-11-14, MAE is:19.47 & sMAPE is:53.63% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :10.54 & 44.71% & 1.07\n",
      "for 2022-11-15, MAE is:9.70 & sMAPE is:42.12% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :10.53 & 44.70% & 1.07\n",
      "for 2022-11-16, MAE is:7.80 & sMAPE is:38.05% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :10.52 & 44.68% & 1.07\n",
      "for 2022-11-17, MAE is:14.63 & sMAPE is:54.12% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :10.54 & 44.71% & 1.07\n",
      "for 2022-11-18, MAE is:16.76 & sMAPE is:48.70% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :10.56 & 44.72% & 1.07\n",
      "for 2022-11-19, MAE is:29.97 & sMAPE is:39.89% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :10.62 & 44.71% & 1.07\n",
      "for 2022-11-20, MAE is:4.57 & sMAPE is:10.10% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :10.60 & 44.60% & 1.07\n",
      "for 2022-11-21, MAE is:128.76 & sMAPE is:105.07% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :10.96 & 44.79% & 1.07\n",
      "for 2022-11-22, MAE is:55.76 & sMAPE is:65.41% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :11.10 & 44.85% & 1.07\n",
      "for 2022-11-23, MAE is:4.42 & sMAPE is:8.34% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :11.08 & 44.74% & 1.07\n",
      "for 2022-11-24, MAE is:22.45 & sMAPE is:40.26% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 44.72% & 1.06\n",
      "for 2022-11-25, MAE is:4.49 & sMAPE is:7.60% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :11.09 & 44.61% & 1.06\n",
      "for 2022-11-26, MAE is:13.07 & sMAPE is:20.30% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :11.10 & 44.54% & 1.06\n",
      "for 2022-11-27, MAE is:10.29 & sMAPE is:16.42% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :11.10 & 44.45% & 1.06\n",
      "for 2022-11-28, MAE is:22.89 & sMAPE is:35.27% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 44.42% & 1.06\n",
      "for 2022-11-29, MAE is:170.15 & sMAPE is:88.84% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :11.61 & 44.56% & 1.06\n",
      "for 2022-11-30, MAE is:149.30 & sMAPE is:44.08% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :12.02 & 44.56% & 1.05\n",
      "for 2022-12-01, MAE is:31.70 & sMAPE is:9.51% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :12.08 & 44.45% & 1.05\n",
      "for 2022-12-02, MAE is:45.64 & sMAPE is:17.73% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :12.18 & 44.37% & 1.05\n",
      "for 2022-12-03, MAE is:35.51 & sMAPE is:15.33% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :12.25 & 44.29% & 1.05\n",
      "for 2022-12-04, MAE is:23.55 & sMAPE is:8.74% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :12.28 & 44.18% & 1.04\n",
      "for 2022-12-05, MAE is:49.56 & sMAPE is:24.04% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :12.39 & 44.12% & 1.04\n",
      "for 2022-12-06, MAE is:54.69 & sMAPE is:30.43% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :12.52 & 44.08% & 1.04\n",
      "for 2022-12-07, MAE is:63.74 & sMAPE is:30.28% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :12.67 & 44.04% & 1.04\n",
      "for 2022-12-08, MAE is:66.18 & sMAPE is:27.09% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :12.82 & 43.99% & 1.04\n",
      "for 2022-12-09, MAE is:28.00 & sMAPE is:10.01% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :12.87 & 43.89% & 1.04\n",
      "for 2022-12-10, MAE is:31.77 & sMAPE is:12.75% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :12.92 & 43.80% & 1.04\n",
      "for 2022-12-11, MAE is:13.17 & sMAPE is:5.51% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :12.92 & 43.69% & 1.03\n",
      "for 2022-12-12, MAE is:59.79 & sMAPE is:22.12% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :13.06 & 43.63% & 1.03\n",
      "for 2022-12-13, MAE is:137.24 & sMAPE is:40.91% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :13.42 & 43.62% & 1.03\n",
      "for 2022-12-14, MAE is:113.48 & sMAPE is:26.21% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :13.71 & 43.57% & 1.03\n",
      "for 2022-12-15, MAE is:158.35 & sMAPE is:51.51% & rMAE is:3.19 ||| daily mean of MAE & sMAPE & rMAE till now are :14.12 & 43.59% & 1.04\n",
      "for 2022-12-16, MAE is:59.48 & sMAPE is:38.46% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :14.25 & 43.58% & 1.04\n",
      "for 2022-12-17, MAE is:11.03 & sMAPE is:9.57% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :14.24 & 43.48% & 1.03\n",
      "for 2022-12-18, MAE is:44.50 & sMAPE is:45.82% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :14.33 & 43.49% & 1.03\n",
      "for 2022-12-19, MAE is:23.61 & sMAPE is:28.38% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :14.35 & 43.45% & 1.03\n",
      "for 2022-12-20, MAE is:20.48 & sMAPE is:17.91% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :14.37 & 43.37% & 1.03\n",
      "for 2022-12-21, MAE is:30.01 & sMAPE is:20.73% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :14.41 & 43.31% & 1.02\n",
      "for 2022-12-22, MAE is:24.75 & sMAPE is:15.67% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :14.44 & 43.23% & 1.02\n",
      "for 2022-12-23, MAE is:48.97 & sMAPE is:47.02% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :14.54 & 43.24% & 1.02\n",
      "for 2022-12-24, MAE is:11.72 & sMAPE is:18.28% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :14.53 & 43.17% & 1.02\n",
      "for 2022-12-25, MAE is:9.21 & sMAPE is:14.33% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :14.52 & 43.09% & 1.02\n",
      "for 2022-12-26, MAE is:16.19 & sMAPE is:39.31% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :14.52 & 43.08% & 1.02\n",
      "for 2022-12-27, MAE is:22.35 & sMAPE is:43.67% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :14.54 & 43.08% & 1.01\n",
      "for 2022-12-28, MAE is:17.41 & sMAPE is:23.75% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :14.55 & 43.03% & 1.01\n",
      "for 2022-12-29, MAE is:40.69 & sMAPE is:82.76% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :14.62 & 43.14% & 1.01\n",
      "for 2022-12-30, MAE is:8.35 & sMAPE is:27.20% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :14.61 & 43.10% & 1.01\n",
      "for 2022-12-31, MAE is:3.59 & sMAPE is:14.06% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :14.58 & 43.02% & 1.01\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:33:45,430]\u001b[0m A new study created in RDB with name: NO_3_2023\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:34:13,966]\u001b[0m Trial 2 finished with value: 23.744492693069486 and parameters: {'n_hidden': 4, 'learning_rate': 0.019518069295049165, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03523943633981861, 'dropout_rate_Layer_2': 0.01735341518546658, 'dropout_rate_Layer_3': 0.1930684477883725, 'dropout_rate_Layer_4': 0.0684976831000852, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014151161475366904, 'l1_Layer_2': 0.0008210454486479885, 'l1_Layer_3': 0.07300176325937549, 'l1_Layer_4': 0.006625373126673392, 'n_units_Layer_1': 140, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155, 'n_units_Layer_4': 290}. Best is trial 2 with value: 23.744492693069486.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.74 | sMAPE for Validation Set is: 54.53% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 15.70 | sMAPE for Test Set is: 45.25% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:34:20,860]\u001b[0m Trial 0 finished with value: 19.33046018522212 and parameters: {'n_hidden': 4, 'learning_rate': 0.005634423965770022, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12352580963732125, 'dropout_rate_Layer_2': 0.23662234841199112, 'dropout_rate_Layer_3': 0.21750591346797188, 'dropout_rate_Layer_4': 0.30742031818417365, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0200590322304395, 'l1_Layer_2': 0.0036188425965225013, 'l1_Layer_3': 0.0007383442563508526, 'l1_Layer_4': 0.0004426315233642196, 'n_units_Layer_1': 70, 'n_units_Layer_2': 55, 'n_units_Layer_3': 245, 'n_units_Layer_4': 65}. Best is trial 0 with value: 19.33046018522212.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.33 | sMAPE for Validation Set is: 43.89% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.36 | sMAPE for Test Set is: 35.28% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:34:22,250]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:34:25,812]\u001b[0m Trial 1 finished with value: 22.180536740401717 and parameters: {'n_hidden': 4, 'learning_rate': 0.004171973721546393, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09351731038991923, 'dropout_rate_Layer_2': 0.08564759872525385, 'dropout_rate_Layer_3': 0.20470188849154716, 'dropout_rate_Layer_4': 0.35584673572425185, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.002133668358789929, 'l1_Layer_2': 0.0060734825354191065, 'l1_Layer_3': 5.111945436453611e-05, 'l1_Layer_4': 0.0031549863945596226, 'n_units_Layer_1': 275, 'n_units_Layer_2': 195, 'n_units_Layer_3': 200, 'n_units_Layer_4': 195}. Best is trial 0 with value: 19.33046018522212.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.18 | sMAPE for Validation Set is: 41.71% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 13.12 | sMAPE for Test Set is: 37.86% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:34:27,740]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:34:32,438]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:34:40,902]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:34:44,597]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:34:51,650]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:34:55,790]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:35:02,246]\u001b[0m Trial 9 finished with value: 32.756913643948856 and parameters: {'n_hidden': 3, 'learning_rate': 0.002116791776296312, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0240298962223128, 'dropout_rate_Layer_2': 0.3400234407040187, 'dropout_rate_Layer_3': 0.13627448903559816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.022282712953796878, 'l1_Layer_2': 0.07317678390292913, 'l1_Layer_3': 0.011317529221213112, 'n_units_Layer_1': 80, 'n_units_Layer_2': 170, 'n_units_Layer_3': 260}. Best is trial 0 with value: 19.33046018522212.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.76 | sMAPE for Validation Set is: 80.66% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 30.35 | sMAPE for Test Set is: 88.10% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:35:33,633]\u001b[0m Trial 14 finished with value: 14.521282728014711 and parameters: {'n_hidden': 3, 'learning_rate': 0.009963238659111336, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.002709956419119308, 'dropout_rate_Layer_2': 0.053072432152481544, 'dropout_rate_Layer_3': 0.2588485484745858, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001969298820424985, 'l1_Layer_2': 0.07905530463956813, 'l1_Layer_3': 0.00029040972072621026, 'n_units_Layer_1': 165, 'n_units_Layer_2': 90, 'n_units_Layer_3': 225}. Best is trial 14 with value: 14.521282728014711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.52 | sMAPE for Validation Set is: 36.78% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.81 | sMAPE for Test Set is: 36.64% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:35:36,225]\u001b[0m Trial 13 finished with value: 21.904597923383808 and parameters: {'n_hidden': 3, 'learning_rate': 0.005333533052587896, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22206481470309092, 'dropout_rate_Layer_2': 0.28944551647386707, 'dropout_rate_Layer_3': 0.35359794794991734, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006647190715635604, 'l1_Layer_2': 0.0008423455739931902, 'l1_Layer_3': 0.004780758347215114, 'n_units_Layer_1': 155, 'n_units_Layer_2': 65, 'n_units_Layer_3': 245}. Best is trial 14 with value: 14.521282728014711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.90 | sMAPE for Validation Set is: 45.90% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 12.90 | sMAPE for Test Set is: 39.99% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:35:37,774]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:35:40,766]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:35:44,188]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:35:51,351]\u001b[0m Trial 7 finished with value: 15.971075945257367 and parameters: {'n_hidden': 4, 'learning_rate': 0.08023908103374558, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30469121292527046, 'dropout_rate_Layer_2': 0.10554782874556255, 'dropout_rate_Layer_3': 0.2996503961938499, 'dropout_rate_Layer_4': 0.017392395180844566, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.950078310091539e-05, 'l1_Layer_2': 0.00015822772618351478, 'l1_Layer_3': 0.01826317678877392, 'l1_Layer_4': 0.0018038787533902496, 'n_units_Layer_1': 130, 'n_units_Layer_2': 240, 'n_units_Layer_3': 300, 'n_units_Layer_4': 105}. Best is trial 14 with value: 14.521282728014711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.97 | sMAPE for Validation Set is: 38.41% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 13.46 | sMAPE for Test Set is: 40.65% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:35:52,799]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:35:55,973]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:35:59,965]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:36:00,251]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:36:05,365]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:36:07,721]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:36:12,946]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:36:18,721]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:36:23,878]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:36:29,191]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:36:35,556]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:36:39,505]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:36:45,755]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:36:51,654]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:00,909]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:05,444]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:09,184]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:12,175]\u001b[0m Trial 33 finished with value: 20.05493773557842 and parameters: {'n_hidden': 4, 'learning_rate': 0.0030944257587507676, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.054716930376724406, 'dropout_rate_Layer_2': 0.12425843116005582, 'dropout_rate_Layer_3': 0.08445771848644848, 'dropout_rate_Layer_4': 0.10702787749824108, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05530333886644288, 'l1_Layer_2': 2.938612390763064e-05, 'l1_Layer_3': 1.948812919013465e-05, 'l1_Layer_4': 1.380996727221757e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 290, 'n_units_Layer_3': 195, 'n_units_Layer_4': 185}. Best is trial 14 with value: 14.521282728014711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.05 | sMAPE for Validation Set is: 41.79% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.35 | sMAPE for Test Set is: 35.01% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:37:17,211]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:22,091]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:23,604]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.84 | sMAPE for Validation Set is: 54.19% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 15.52 | sMAPE for Test Set is: 44.93% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:37:26,524]\u001b[0m Trial 3 finished with value: 23.84484760019033 and parameters: {'n_hidden': 4, 'learning_rate': 0.02443856997622565, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3450686359515825, 'dropout_rate_Layer_2': 0.0025634205960682003, 'dropout_rate_Layer_3': 0.38007833314435546, 'dropout_rate_Layer_4': 0.13072031428669192, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0016148963057995038, 'l1_Layer_2': 0.02599295673228464, 'l1_Layer_3': 6.694129451824884e-05, 'l1_Layer_4': 1.0220992804775968e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 180, 'n_units_Layer_3': 215, 'n_units_Layer_4': 230}. Best is trial 14 with value: 14.521282728014711.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:30,627]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:30,793]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:31,484]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.67 | sMAPE for Validation Set is: 39.26% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.99 | sMAPE for Test Set is: 37.42% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:37:36,443]\u001b[0m Trial 30 finished with value: 20.67398754137882 and parameters: {'n_hidden': 3, 'learning_rate': 0.004333887677527499, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2889742422324668, 'dropout_rate_Layer_2': 0.3239351759220772, 'dropout_rate_Layer_3': 0.0782766054779533, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.295354314600582e-05, 'l1_Layer_2': 9.781394040821573e-05, 'l1_Layer_3': 0.00853403726531703, 'n_units_Layer_1': 90, 'n_units_Layer_2': 200, 'n_units_Layer_3': 290}. Best is trial 14 with value: 14.521282728014711.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:37,833]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:42,126]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:44,279]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:45,173]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:50,600]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:54,360]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:55,000]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:55,501]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:37:59,818]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:38:01,640]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:38:05,484]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:38:05,748]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:38:06,530]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:38:12,366]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:38:15,142]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:38:18,181]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:38:21,855]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:38:24,633]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:38:26,493]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:38:31,016]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:38:36,328]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:38:42,665]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:38:45,299]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:38:51,536]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:38:55,048]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:38:55,296]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:39:02,504]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:39:02,866]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:39:10,543]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:39:19,454]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:39:25,453]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:39:29,529]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:39:34,361]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:39:34,405]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:39:35,129]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.59 | sMAPE for Validation Set is: 37.03% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.27 | sMAPE for Test Set is: 35.09% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:39:40,651]\u001b[0m Trial 58 finished with value: 17.588420930971537 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005986547091549529, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3965486322922389, 'dropout_rate_Layer_2': 0.17789995550044174, 'dropout_rate_Layer_3': 0.3587969055353856, 'dropout_rate_Layer_4': 0.043755541109623854, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0020992559726868676, 'l1_Layer_2': 0.006707477670467162, 'l1_Layer_3': 0.0005732116973716648, 'l1_Layer_4': 0.0001103086500439925, 'n_units_Layer_1': 245, 'n_units_Layer_2': 280, 'n_units_Layer_3': 240, 'n_units_Layer_4': 100}. Best is trial 14 with value: 14.521282728014711.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:39:41,101]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:39:44,032]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:39:44,425]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:39:48,928]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:39:49,514]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:39:51,264]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:39:56,330]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:39:56,364]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:40:05,235]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:40:10,988]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:40:14,815]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:40:17,343]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:40:21,875]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:40:25,273]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:40:35,585]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:40:39,205]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:40:40,022]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:40:44,393]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:40:48,784]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:40:53,114]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:41:01,064]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:41:07,292]\u001b[0m Trial 87 finished with value: 14.185200784069309 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005306751855772298, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04985391220902282, 'dropout_rate_Layer_2': 0.10927597245306395, 'dropout_rate_Layer_3': 0.2751002387992409, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.047240417157779546, 'l1_Layer_2': 0.005113009277604004, 'l1_Layer_3': 0.000385217090950788, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 180}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.19 | sMAPE for Validation Set is: 33.04% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.66 | sMAPE for Test Set is: 35.94% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:41:09,707]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:41:14,079]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:41:18,361]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:41:19,235]\u001b[0m Trial 89 finished with value: 17.029612063045168 and parameters: {'n_hidden': 4, 'learning_rate': 0.05530885853368276, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0037756848051219427, 'dropout_rate_Layer_2': 0.19438439911973757, 'dropout_rate_Layer_3': 0.1405257465509283, 'dropout_rate_Layer_4': 0.0036027425815270825, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.000787426041952946, 'l1_Layer_2': 0.004219963183100892, 'l1_Layer_3': 0.0035381259639486805, 'l1_Layer_4': 0.0011503758127375014, 'n_units_Layer_1': 135, 'n_units_Layer_2': 220, 'n_units_Layer_3': 235, 'n_units_Layer_4': 50}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.03 | sMAPE for Validation Set is: 48.76% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 13.08 | sMAPE for Test Set is: 38.36% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:41:22,709]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:41:27,720]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:41:28,339]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:41:33,911]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:41:35,775]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:41:41,478]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:41:43,874]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:41:51,367]\u001b[0m Trial 109 finished with value: 26.32080751118602 and parameters: {'n_hidden': 3, 'learning_rate': 0.07176034616405765, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08418854034619866, 'dropout_rate_Layer_2': 0.23000289072297547, 'dropout_rate_Layer_3': 0.36815806645616433, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0017036236340420565, 'l1_Layer_2': 0.021249495165130593, 'l1_Layer_3': 0.0242597819393651, 'n_units_Layer_1': 135, 'n_units_Layer_2': 205, 'n_units_Layer_3': 190}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.32 | sMAPE for Validation Set is: 60.32% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 19.13 | sMAPE for Test Set is: 54.18% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:41:55,004]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:41:57,195]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:42:01,736]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:42:02,213]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:42:29,416]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:42:29,892]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:42:34,769]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:42:35,075]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.17 | sMAPE for Validation Set is: 37.77% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 11.93 | sMAPE for Test Set is: 36.58% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:42:50,960]\u001b[0m Trial 114 finished with value: 17.171830360504277 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016131126816012256, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.035365379977086775, 'dropout_rate_Layer_2': 0.046368989150451824, 'dropout_rate_Layer_3': 0.31665825606740683, 'dropout_rate_Layer_4': 0.34090239774119274, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005909111781824349, 'l1_Layer_2': 0.0009185292160833669, 'l1_Layer_3': 0.000507903219449978, 'l1_Layer_4': 0.0001999248196102933, 'n_units_Layer_1': 55, 'n_units_Layer_2': 280, 'n_units_Layer_3': 75, 'n_units_Layer_4': 215}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:42:55,065]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:42:58,579]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:43:06,363]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:43:12,254]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:43:15,264]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:43:28,674]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:43:31,877]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:43:34,905]\u001b[0m Trial 124 finished with value: 14.550621747326806 and parameters: {'n_hidden': 4, 'learning_rate': 0.003827881667063624, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27888483011683485, 'dropout_rate_Layer_2': 0.11825879744018968, 'dropout_rate_Layer_3': 0.1762609005233285, 'dropout_rate_Layer_4': 0.12716197966068166, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006353058953124137, 'l1_Layer_2': 0.03999298319549226, 'l1_Layer_3': 0.06964914072188462, 'l1_Layer_4': 0.0006306470244899693, 'n_units_Layer_1': 245, 'n_units_Layer_2': 65, 'n_units_Layer_3': 85, 'n_units_Layer_4': 140}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.55 | sMAPE for Validation Set is: 40.33% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.54 | sMAPE for Test Set is: 35.30% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:43:50,065]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:43:55,926]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:43:56,352]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:43:56,445]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:44:02,485]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:44:06,563]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:44:11,299]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:44:13,819]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:44:18,938]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:44:32,837]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:45:01,309]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:45:07,775]\u001b[0m Trial 102 finished with value: 16.060617153000234 and parameters: {'n_hidden': 3, 'learning_rate': 0.001356089132934269, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06948729751763993, 'dropout_rate_Layer_2': 0.09723212743700616, 'dropout_rate_Layer_3': 0.09558374491734475, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.014505031804539492, 'l1_Layer_2': 0.00013952327715375807, 'l1_Layer_3': 3.669175695197555e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 100, 'n_units_Layer_3': 270}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.06 | sMAPE for Validation Set is: 35.68% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 12.91 | sMAPE for Test Set is: 36.79% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:45:10,513]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:45:17,532]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:45:25,501]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:45:31,334]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:45:40,860]\u001b[0m Trial 142 finished with value: 14.193376547214706 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005434191084743539, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09766911445650549, 'dropout_rate_Layer_2': 0.09877600760355715, 'dropout_rate_Layer_3': 0.2683614368132744, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.022397142136606443, 'l1_Layer_2': 0.0197813346268892, 'l1_Layer_3': 0.0006902842300533463, 'n_units_Layer_1': 180, 'n_units_Layer_2': 100, 'n_units_Layer_3': 180}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.19 | sMAPE for Validation Set is: 34.02% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.60 | sMAPE for Test Set is: 35.78% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:45:44,060]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:46:03,220]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:46:16,457]\u001b[0m Trial 148 finished with value: 14.64258389431671 and parameters: {'n_hidden': 4, 'learning_rate': 0.004734290392556087, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20032795695110736, 'dropout_rate_Layer_2': 0.2108739938950519, 'dropout_rate_Layer_3': 0.14127181207889075, 'dropout_rate_Layer_4': 0.06906512123083001, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006753661623133566, 'l1_Layer_2': 0.04189652994372467, 'l1_Layer_3': 0.0006932897607712225, 'l1_Layer_4': 0.0004634941479179634, 'n_units_Layer_1': 125, 'n_units_Layer_2': 265, 'n_units_Layer_3': 85, 'n_units_Layer_4': 150}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.64 | sMAPE for Validation Set is: 39.83% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.96 | sMAPE for Test Set is: 36.83% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:46:28,599]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:46:32,487]\u001b[0m Trial 150 finished with value: 14.490299516874098 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027711780691366985, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20263902234673759, 'dropout_rate_Layer_2': 0.20416882403096573, 'dropout_rate_Layer_3': 0.14071254016362195, 'dropout_rate_Layer_4': 0.018075235359167063, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0069492841776631195, 'l1_Layer_2': 0.04001919240499705, 'l1_Layer_3': 0.004496917382305538, 'l1_Layer_4': 0.0012522294971790968, 'n_units_Layer_1': 150, 'n_units_Layer_2': 265, 'n_units_Layer_3': 85, 'n_units_Layer_4': 145}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.49 | sMAPE for Validation Set is: 37.34% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.57 | sMAPE for Test Set is: 35.90% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:46:33,000]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:46:39,259]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:46:51,191]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:46:57,425]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:47:04,995]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:47:11,041]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:47:27,048]\u001b[0m Trial 145 finished with value: 20.837260304969675 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009143220725232944, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.035337041003145775, 'dropout_rate_Layer_2': 0.041523872923606125, 'dropout_rate_Layer_3': 0.16367436467778032, 'dropout_rate_Layer_4': 0.001484599077542878, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.014906396077029902, 'l1_Layer_2': 0.0004328893692022102, 'l1_Layer_3': 1.386135581981965e-05, 'l1_Layer_4': 1.051658325754895e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 95, 'n_units_Layer_3': 260, 'n_units_Layer_4': 50}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.84 | sMAPE for Validation Set is: 39.03% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.99 | sMAPE for Test Set is: 36.64% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:47:30,646]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:47:44,719]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:47:57,901]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:48:10,114]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:48:48,449]\u001b[0m Trial 163 finished with value: 14.416106600138727 and parameters: {'n_hidden': 4, 'learning_rate': 0.002813445131876576, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24132486008310167, 'dropout_rate_Layer_2': 0.031691430195026335, 'dropout_rate_Layer_3': 0.10457115728461251, 'dropout_rate_Layer_4': 0.0015822700314126882, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0060819293460809285, 'l1_Layer_2': 0.03897686821137013, 'l1_Layer_3': 0.0009530707981545742, 'l1_Layer_4': 0.001305857285817545, 'n_units_Layer_1': 125, 'n_units_Layer_2': 60, 'n_units_Layer_3': 90, 'n_units_Layer_4': 60}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.42 | sMAPE for Validation Set is: 37.77% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.75 | sMAPE for Test Set is: 35.68% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:49:07,092]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:49:16,059]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:49:21,839]\u001b[0m Trial 152 finished with value: 17.9335716583731 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009110993520650121, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04157577864385545, 'dropout_rate_Layer_2': 0.016066485681511186, 'dropout_rate_Layer_3': 0.25116313840400956, 'dropout_rate_Layer_4': 0.229342386352358, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.08262265743920558, 'l1_Layer_2': 0.0005208738324926156, 'l1_Layer_3': 4.766924587392357e-05, 'l1_Layer_4': 5.588195832332456e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 85, 'n_units_Layer_3': 185, 'n_units_Layer_4': 130}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.93 | sMAPE for Validation Set is: 37.04% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 11.61 | sMAPE for Test Set is: 35.47% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:49:26,076]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:49:26,256]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:49:27,191]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:49:34,900]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:49:35,318]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:49:35,684]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:49:43,246]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:49:43,550]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:49:48,229]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:49:51,877]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:49:55,984]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:49:59,466]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:50:03,930]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:50:31,190]\u001b[0m Trial 183 finished with value: 14.210273229273339 and parameters: {'n_hidden': 4, 'learning_rate': 0.003393113378584486, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21529789020447124, 'dropout_rate_Layer_2': 0.04133251195445244, 'dropout_rate_Layer_3': 0.08841484197384998, 'dropout_rate_Layer_4': 0.02099359923232992, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.008609992917620159, 'l1_Layer_2': 0.035084428066178744, 'l1_Layer_3': 0.0003266023919688767, 'l1_Layer_4': 0.001052324947427489, 'n_units_Layer_1': 135, 'n_units_Layer_2': 265, 'n_units_Layer_3': 115, 'n_units_Layer_4': 85}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.21 | sMAPE for Validation Set is: 35.28% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.27 | sMAPE for Test Set is: 34.88% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:50:35,321]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:50:40,176]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:50:49,600]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:51:12,907]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:51:17,230]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:51:40,177]\u001b[0m Trial 161 finished with value: 17.534840712701584 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009597061334894095, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.036837097586769896, 'dropout_rate_Layer_2': 0.05026309562170089, 'dropout_rate_Layer_3': 0.2361523268456811, 'dropout_rate_Layer_4': 0.13731334447873747, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.07851182887731986, 'l1_Layer_2': 0.0005557069010413615, 'l1_Layer_3': 5.323285724922506e-05, 'l1_Layer_4': 1.074756066289591e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 75, 'n_units_Layer_3': 195, 'n_units_Layer_4': 55}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.53 | sMAPE for Validation Set is: 37.29% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.99 | sMAPE for Test Set is: 36.28% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:51:43,142]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:51:45,712]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:51:47,972]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:51:51,298]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:51:51,429]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:51:58,989]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:52:13,460]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:52:22,449]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:52:32,179]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:52:36,058]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:52:40,893]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:52:41,962]\u001b[0m Trial 174 finished with value: 17.898578555491827 and parameters: {'n_hidden': 4, 'learning_rate': 0.00080342456469973, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0916100865492222, 'dropout_rate_Layer_2': 0.01087647707941896, 'dropout_rate_Layer_3': 0.24439605613814966, 'dropout_rate_Layer_4': 0.23297393836352676, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09421263351885631, 'l1_Layer_2': 0.0019168467584179925, 'l1_Layer_3': 4.327220977736158e-05, 'l1_Layer_4': 4.085487982391636e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 90, 'n_units_Layer_3': 180, 'n_units_Layer_4': 125}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.90 | sMAPE for Validation Set is: 38.06% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 12.31 | sMAPE for Test Set is: 36.56% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:52:47,418]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:52:48,540]\u001b[0m Trial 196 finished with value: 14.32371495932729 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009131888147216397, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17691218946421008, 'dropout_rate_Layer_2': 0.16031260271866477, 'dropout_rate_Layer_3': 0.3008225371502665, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.093616170644068, 'l1_Layer_2': 0.007106225745518146, 'l1_Layer_3': 0.0005723400905817608, 'n_units_Layer_1': 130, 'n_units_Layer_2': 235, 'n_units_Layer_3': 215}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.32 | sMAPE for Validation Set is: 35.67% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.49 | sMAPE for Test Set is: 35.53% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:52:54,083]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:52:54,378]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:52:55,687]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:02,128]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:03,934]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:07,581]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:08,160]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:12,188]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:15,583]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:20,725]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:25,275]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:25,381]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:29,411]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:33,432]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:38,639]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:40,410]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:46,081]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:46,153]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:52,545]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:54,459]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:58,213]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:53:58,354]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:02,976]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:05,465]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:08,319]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:08,819]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:09,348]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:14,670]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:15,792]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:16,685]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:18,524]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:20,592]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:22,008]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:26,292]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:29,394]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:30,872]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:31,345]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:38,660]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:38,992]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:42,874]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:48,314]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:51,020]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:54,065]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:57,588]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:54:59,071]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:55:03,297]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:55:09,633]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:55:11,935]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:55:16,638]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:55:18,608]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:55:23,240]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:55:24,807]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:55:25,238]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:55:31,622]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:55:35,720]\u001b[0m Trial 242 finished with value: 14.574409150018928 and parameters: {'n_hidden': 4, 'learning_rate': 0.004516340274855786, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01871679815672094, 'dropout_rate_Layer_2': 0.10944007577612208, 'dropout_rate_Layer_3': 0.1827193615784542, 'dropout_rate_Layer_4': 0.11781690759914681, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.1428307828906836e-05, 'l1_Layer_2': 0.024530996378962017, 'l1_Layer_3': 0.04032757134956084, 'l1_Layer_4': 0.00124059644947969, 'n_units_Layer_1': 110, 'n_units_Layer_2': 285, 'n_units_Layer_3': 120, 'n_units_Layer_4': 135}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.57 | sMAPE for Validation Set is: 37.51% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.89 | sMAPE for Test Set is: 36.89% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:55:40,792]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:55:43,163]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:55:55,394]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:55:57,663]\u001b[0m Trial 257 finished with value: 14.542575481834803 and parameters: {'n_hidden': 3, 'learning_rate': 0.007175911460533463, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03999371593021103, 'dropout_rate_Layer_2': 0.16699750098642768, 'dropout_rate_Layer_3': 0.19701805806450745, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02377771471937029, 'l1_Layer_2': 0.0014582514774794761, 'l1_Layer_3': 0.0006637379548570559, 'n_units_Layer_1': 130, 'n_units_Layer_2': 200, 'n_units_Layer_3': 215}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.54 | sMAPE for Validation Set is: 37.83% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.19 | sMAPE for Test Set is: 38.08% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:55:59,154]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:56:02,059]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:56:12,772]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:56:16,190]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:56:19,120]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:56:25,159]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:56:34,135]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:56:43,044]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:56:48,914]\u001b[0m Trial 262 finished with value: 14.56656985355711 and parameters: {'n_hidden': 4, 'learning_rate': 0.003853626655044805, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.003985249679942492, 'dropout_rate_Layer_2': 0.11651528740065487, 'dropout_rate_Layer_3': 0.17253089565866125, 'dropout_rate_Layer_4': 0.10113639025079117, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.7826367776680355e-05, 'l1_Layer_2': 0.04667087166143003, 'l1_Layer_3': 0.04418554867460604, 'l1_Layer_4': 0.0016350889240045287, 'n_units_Layer_1': 125, 'n_units_Layer_2': 250, 'n_units_Layer_3': 125, 'n_units_Layer_4': 125}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.57 | sMAPE for Validation Set is: 39.26% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.93 | sMAPE for Test Set is: 36.75% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:56:53,950]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:57:00,421]\u001b[0m Trial 264 finished with value: 14.412969440462646 and parameters: {'n_hidden': 4, 'learning_rate': 0.003778108997191282, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.003981486233658963, 'dropout_rate_Layer_2': 0.11454814770605905, 'dropout_rate_Layer_3': 0.15597478721665975, 'dropout_rate_Layer_4': 0.1327347370271692, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.420424079261424e-05, 'l1_Layer_2': 0.04470606245577762, 'l1_Layer_3': 0.041911141476155093, 'l1_Layer_4': 0.0015622438835331627, 'n_units_Layer_1': 125, 'n_units_Layer_2': 270, 'n_units_Layer_3': 125, 'n_units_Layer_4': 140}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.41 | sMAPE for Validation Set is: 38.33% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 12.03 | sMAPE for Test Set is: 37.04% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:57:10,784]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:57:22,974]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:57:35,766]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:57:41,182]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:57:47,770]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:57:51,352]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:57:53,570]\u001b[0m Trial 275 finished with value: 14.681661437755414 and parameters: {'n_hidden': 4, 'learning_rate': 0.0039041767811278444, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0027872157016698503, 'dropout_rate_Layer_2': 0.1358990792713155, 'dropout_rate_Layer_3': 0.18584080574344408, 'dropout_rate_Layer_4': 0.10561893418033766, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.1821229239841135e-05, 'l1_Layer_2': 0.04426057095175953, 'l1_Layer_3': 0.06468810217574664, 'l1_Layer_4': 0.0009353595600176659, 'n_units_Layer_1': 120, 'n_units_Layer_2': 250, 'n_units_Layer_3': 120, 'n_units_Layer_4': 125}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.68 | sMAPE for Validation Set is: 37.78% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.25 | sMAPE for Test Set is: 38.46% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:57:57,700]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:58:02,769]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:58:24,665]\u001b[0m Trial 276 finished with value: 14.452224273128882 and parameters: {'n_hidden': 4, 'learning_rate': 0.003938890386256125, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.001621625197458505, 'dropout_rate_Layer_2': 0.12655779950803359, 'dropout_rate_Layer_3': 0.1851658544779346, 'dropout_rate_Layer_4': 0.10067830681961423, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.0159801420709382e-05, 'l1_Layer_2': 0.042897054466217194, 'l1_Layer_3': 0.04324351320720739, 'l1_Layer_4': 0.002101361427294906, 'n_units_Layer_1': 155, 'n_units_Layer_2': 250, 'n_units_Layer_3': 135, 'n_units_Layer_4': 130}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.45 | sMAPE for Validation Set is: 39.12% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.69 | sMAPE for Test Set is: 35.83% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:58:32,309]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:58:43,624]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:58:54,682]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:59:04,184]\u001b[0m Trial 280 finished with value: 18.112673046822824 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011695314419244973, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32932812623296354, 'dropout_rate_Layer_2': 0.07097653905048656, 'dropout_rate_Layer_3': 0.16705781767064284, 'dropout_rate_Layer_4': 0.3962532223048279, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00041540739076339887, 'l1_Layer_2': 1.138842137720312e-05, 'l1_Layer_3': 8.824743675035742e-05, 'l1_Layer_4': 4.018142555380963e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 130, 'n_units_Layer_3': 265, 'n_units_Layer_4': 240}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.11 | sMAPE for Validation Set is: 37.99% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 11.63 | sMAPE for Test Set is: 37.63% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:59:04,503]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:59:11,766]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:59:17,858]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:59:23,416]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:59:23,733]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:59:29,755]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:59:30,052]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:59:35,253]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:59:39,347]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:59:39,418]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:59:44,229]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:59:49,805]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 16:59:55,687]\u001b[0m Trial 277 finished with value: 18.128568536771297 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010717563960509805, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0380651223811989, 'dropout_rate_Layer_2': 0.027371263113015715, 'dropout_rate_Layer_3': 0.23978868749224674, 'dropout_rate_Layer_4': 0.18416323008833696, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.052072572433590134, 'l1_Layer_2': 0.0007495583670532061, 'l1_Layer_3': 8.106285102212882e-05, 'l1_Layer_4': 2.1916211974283444e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 95, 'n_units_Layer_3': 195, 'n_units_Layer_4': 135}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.13 | sMAPE for Validation Set is: 36.06% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 11.79 | sMAPE for Test Set is: 35.68% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 16:59:55,869]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:00:44,268]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:00:50,885]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:00:56,854]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:01:01,668]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:01:01,997]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:01:21,612]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:01:21,834]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.69 | sMAPE for Validation Set is: 35.69% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.70 | sMAPE for Test Set is: 36.16% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:01:25,059]\u001b[0m Trial 301 finished with value: 17.686323780386363 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007294720094353297, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.041508284952548775, 'dropout_rate_Layer_2': 0.07920869791483318, 'dropout_rate_Layer_3': 0.2010110205434928, 'dropout_rate_Layer_4': 0.21175269318507614, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.06303102583842526, 'l1_Layer_2': 0.001968694777619392, 'l1_Layer_3': 2.8744275210023978e-05, 'l1_Layer_4': 7.899728119014749e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 85, 'n_units_Layer_3': 215, 'n_units_Layer_4': 50}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:01:28,727]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:01:29,628]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:01:34,862]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:01:34,926]\u001b[0m Trial 297 finished with value: 14.195679602586912 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005053661518306138, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1880952841613544, 'dropout_rate_Layer_2': 0.038755490083405536, 'dropout_rate_Layer_3': 0.15005626279762463, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0790749368263528, 'l1_Layer_2': 0.00011896157534150167, 'l1_Layer_3': 0.008148120989581039, 'n_units_Layer_1': 200, 'n_units_Layer_2': 230, 'n_units_Layer_3': 200}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.20 | sMAPE for Validation Set is: 34.56% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.32 | sMAPE for Test Set is: 34.80% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:01:43,768]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:01:44,193]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:01:50,953]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:01:52,328]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:01:56,650]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:02:05,155]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:02:11,842]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:02:16,892]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:02:21,823]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:02:30,145]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:02:35,355]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:02:39,183]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:02:40,893]\u001b[0m Trial 318 finished with value: 14.474456886771227 and parameters: {'n_hidden': 4, 'learning_rate': 0.00321807361458135, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03794344949256151, 'dropout_rate_Layer_2': 0.06899399622008855, 'dropout_rate_Layer_3': 0.1674720871167132, 'dropout_rate_Layer_4': 0.12440255470131943, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4607228512809587e-05, 'l1_Layer_2': 0.013467154870913966, 'l1_Layer_3': 0.03241865296512264, 'l1_Layer_4': 9.027620283785342e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 285, 'n_units_Layer_3': 110, 'n_units_Layer_4': 170}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.47 | sMAPE for Validation Set is: 39.52% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.49 | sMAPE for Test Set is: 35.44% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:02:45,365]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:02:47,660]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:03:07,793]\u001b[0m Trial 308 finished with value: 18.188253460569197 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017978891081231584, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03783005046591115, 'dropout_rate_Layer_2': 0.08198183394588149, 'dropout_rate_Layer_3': 0.21123827310212542, 'dropout_rate_Layer_4': 0.21328375071632455, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.057345209254640775, 'l1_Layer_2': 0.0005565541472639879, 'l1_Layer_3': 2.5385868693698397e-05, 'l1_Layer_4': 7.431803972268224e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 85, 'n_units_Layer_3': 215, 'n_units_Layer_4': 110}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.19 | sMAPE for Validation Set is: 37.05% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 11.91 | sMAPE for Test Set is: 35.93% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:03:53,006]\u001b[0m Trial 323 finished with value: 16.76248258755527 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007768601657872506, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04766628529062328, 'dropout_rate_Layer_2': 0.08404984804767138, 'dropout_rate_Layer_3': 0.1805873200134899, 'dropout_rate_Layer_4': 0.12939786257511948, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004293068302415643, 'l1_Layer_2': 0.0014511393291297121, 'l1_Layer_3': 7.103793367943099e-05, 'l1_Layer_4': 2.4630273486161058e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 85, 'n_units_Layer_3': 210, 'n_units_Layer_4': 80}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.76 | sMAPE for Validation Set is: 37.21% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 12.31 | sMAPE for Test Set is: 35.65% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:03:55,165]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:03:57,829]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:04:04,072]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:04:07,814]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:04:12,252]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:04:15,878]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:04:23,574]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:04:42,546]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:04:50,904]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:04:53,982]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:05:07,124]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:05:21,263]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:05:27,654]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:06:01,377]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:06:15,497]\u001b[0m Trial 341 finished with value: 14.270235109998529 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028166622985490767, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0011819748574193713, 'dropout_rate_Layer_2': 0.05031032959007956, 'dropout_rate_Layer_3': 0.1711071815777215, 'dropout_rate_Layer_4': 0.11812453347582959, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.009747127550405481, 'l1_Layer_2': 0.048377479250380453, 'l1_Layer_3': 0.02987364142158775, 'l1_Layer_4': 8.833524695088896e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 280, 'n_units_Layer_3': 105, 'n_units_Layer_4': 150}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.27 | sMAPE for Validation Set is: 37.02% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.55 | sMAPE for Test Set is: 35.80% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:06:18,296]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:06:24,419]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:06:28,525]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:06:28,774]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:06:35,075]\u001b[0m Trial 345 finished with value: 14.55620573466897 and parameters: {'n_hidden': 4, 'learning_rate': 0.002025616924201782, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34904850398949844, 'dropout_rate_Layer_2': 0.16879528628769352, 'dropout_rate_Layer_3': 0.29653035103980235, 'dropout_rate_Layer_4': 0.30479499397779997, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006216550386841819, 'l1_Layer_2': 0.0002163549356842801, 'l1_Layer_3': 3.8292132572560194e-05, 'l1_Layer_4': 0.00048628967125486397, 'n_units_Layer_1': 125, 'n_units_Layer_2': 160, 'n_units_Layer_3': 170, 'n_units_Layer_4': 105}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.56 | sMAPE for Validation Set is: 33.84% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.69 | sMAPE for Test Set is: 36.63% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:06:39,050]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:06:39,317]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:06:46,361]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:06:55,881]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:06:56,030]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:07:06,198]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:07:06,425]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:07:16,515]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:07:18,583]\u001b[0m Trial 355 finished with value: 18.263564144821363 and parameters: {'n_hidden': 4, 'learning_rate': 0.011668808273166523, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2727277689171441, 'dropout_rate_Layer_2': 0.2574006613078689, 'dropout_rate_Layer_3': 0.34625583176261754, 'dropout_rate_Layer_4': 0.32966164379535734, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000921898911757021, 'l1_Layer_2': 0.0006762816614856448, 'l1_Layer_3': 0.0006727295091004951, 'l1_Layer_4': 0.0003984515249977525, 'n_units_Layer_1': 70, 'n_units_Layer_2': 170, 'n_units_Layer_3': 80, 'n_units_Layer_4': 110}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.26 | sMAPE for Validation Set is: 41.90% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 12.01 | sMAPE for Test Set is: 36.53% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:07:23,674]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:07:28,457]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:07:35,337]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:07:38,573]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:07:41,151]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:07:44,343]\u001b[0m Trial 359 finished with value: 17.370735920253633 and parameters: {'n_hidden': 4, 'learning_rate': 0.0056572531344060515, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2799878625123127, 'dropout_rate_Layer_2': 0.16815354104410604, 'dropout_rate_Layer_3': 0.34391279179329554, 'dropout_rate_Layer_4': 0.33378218706884266, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000854348050047381, 'l1_Layer_2': 0.0006289574927988445, 'l1_Layer_3': 0.000586592261102522, 'l1_Layer_4': 0.00044103165695559836, 'n_units_Layer_1': 95, 'n_units_Layer_2': 170, 'n_units_Layer_3': 80, 'n_units_Layer_4': 100}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.37 | sMAPE for Validation Set is: 40.76% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 12.84 | sMAPE for Test Set is: 36.97% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:07:44,966]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:07:48,501]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:07:53,775]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:08:08,778]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:08:18,528]\u001b[0m Trial 366 finished with value: 20.555389167477742 and parameters: {'n_hidden': 4, 'learning_rate': 0.01866601249238352, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04291420659900573, 'dropout_rate_Layer_2': 0.21111004167345163, 'dropout_rate_Layer_3': 0.2803310504123424, 'dropout_rate_Layer_4': 0.2618273100625062, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.347734808355116e-05, 'l1_Layer_2': 0.00011776948006454408, 'l1_Layer_3': 0.0001597849474623602, 'l1_Layer_4': 0.009433879313423028, 'n_units_Layer_1': 50, 'n_units_Layer_2': 150, 'n_units_Layer_3': 80, 'n_units_Layer_4': 145}. Best is trial 87 with value: 14.185200784069309.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.56 | sMAPE for Validation Set is: 48.74% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 14.16 | sMAPE for Test Set is: 43.38% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:08:51,705]\u001b[0m Trial 354 finished with value: 14.073945499362226 and parameters: {'n_hidden': 4, 'learning_rate': 0.000704407113230288, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07423669992428186, 'dropout_rate_Layer_2': 0.06277365730944118, 'dropout_rate_Layer_3': 0.16526843057838908, 'dropout_rate_Layer_4': 0.1532114539660608, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.09822235201467076, 'l1_Layer_2': 0.00380104751354263, 'l1_Layer_3': 7.900759825618435e-05, 'l1_Layer_4': 0.0015381520379550576, 'n_units_Layer_1': 185, 'n_units_Layer_2': 65, 'n_units_Layer_3': 165, 'n_units_Layer_4': 85}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.07 | sMAPE for Validation Set is: 34.77% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.19 | sMAPE for Test Set is: 34.18% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:08:55,907]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:09:08,531]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:09:12,806]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:09:17,043]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:09:19,860]\u001b[0m Trial 367 finished with value: 14.138653205735835 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007129477864290118, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07612391824096243, 'dropout_rate_Layer_2': 0.0587519845464851, 'dropout_rate_Layer_3': 0.17858115872863803, 'dropout_rate_Layer_4': 0.15560971680992794, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.03960999317799329, 'l1_Layer_2': 0.003562905742189632, 'l1_Layer_3': 7.124089813203401e-05, 'l1_Layer_4': 1.6272773256990278e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 65, 'n_units_Layer_3': 245, 'n_units_Layer_4': 80}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.14 | sMAPE for Validation Set is: 33.26% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.37 | sMAPE for Test Set is: 34.70% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:09:24,778]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:09:29,667]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:09:46,183]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:09:54,397]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:10:02,304]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:10:05,612]\u001b[0m Trial 371 finished with value: 14.14352755335345 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006630925552768048, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07599680676654857, 'dropout_rate_Layer_2': 0.058395614522432485, 'dropout_rate_Layer_3': 0.2737137591862867, 'dropout_rate_Layer_4': 0.16523370820801103, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.011362211832742377, 'l1_Layer_2': 0.0036698949817406622, 'l1_Layer_3': 7.40744983010476e-05, 'l1_Layer_4': 1.5589932460484717e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 65, 'n_units_Layer_3': 280, 'n_units_Layer_4': 85}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.14 | sMAPE for Validation Set is: 35.40% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.54 | sMAPE for Test Set is: 35.71% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:10:09,231]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:10:10,141]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:10:50,183]\u001b[0m Trial 374 finished with value: 14.375172542203737 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006381880422972827, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07665572652542697, 'dropout_rate_Layer_2': 0.06256729262122528, 'dropout_rate_Layer_3': 0.18725355946181094, 'dropout_rate_Layer_4': 0.15949006195338927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.011492360503556152, 'l1_Layer_2': 0.0030775889877327827, 'l1_Layer_3': 6.53854515392591e-05, 'l1_Layer_4': 0.0015582733130766347, 'n_units_Layer_1': 215, 'n_units_Layer_2': 65, 'n_units_Layer_3': 80, 'n_units_Layer_4': 80}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.38 | sMAPE for Validation Set is: 35.87% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.36 | sMAPE for Test Set is: 34.96% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:10:57,335]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:11:13,937]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:11:20,280]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:11:25,476]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:11:26,082]\u001b[0m Trial 376 finished with value: 14.220774130338397 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006397477783830921, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0756547560907847, 'dropout_rate_Layer_2': 0.0641201107668789, 'dropout_rate_Layer_3': 0.15973963074935266, 'dropout_rate_Layer_4': 0.15035083072385005, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.010386395127992552, 'l1_Layer_2': 0.003534930366854797, 'l1_Layer_3': 8.207957009927157e-05, 'l1_Layer_4': 0.0014998915319016479, 'n_units_Layer_1': 210, 'n_units_Layer_2': 65, 'n_units_Layer_3': 90, 'n_units_Layer_4': 85}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.22 | sMAPE for Validation Set is: 34.89% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.30 | sMAPE for Test Set is: 34.67% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:11:33,223]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:11:36,886]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:11:55,797]\u001b[0m Trial 385 finished with value: 14.206312550426196 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006211552099119578, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12615410581474412, 'dropout_rate_Layer_2': 0.06578146393518258, 'dropout_rate_Layer_3': 0.1746692652418142, 'dropout_rate_Layer_4': 0.11118787563667994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00998138337566692, 'l1_Layer_2': 0.003273447681915102, 'l1_Layer_3': 0.00017698498674228257, 'l1_Layer_4': 0.0015559796026461874, 'n_units_Layer_1': 210, 'n_units_Layer_2': 65, 'n_units_Layer_3': 280, 'n_units_Layer_4': 85}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.21 | sMAPE for Validation Set is: 35.30% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.50 | sMAPE for Test Set is: 35.61% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:12:01,212]\u001b[0m Trial 388 finished with value: 14.539480330026128 and parameters: {'n_hidden': 4, 'learning_rate': 0.0037412310704811017, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11966124742654899, 'dropout_rate_Layer_2': 0.027886797531198198, 'dropout_rate_Layer_3': 0.12216485908714164, 'dropout_rate_Layer_4': 0.0853588685459896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.012993196431172228, 'l1_Layer_2': 0.015924883019893664, 'l1_Layer_3': 0.032015463639346514, 'l1_Layer_4': 0.0006880570496192062, 'n_units_Layer_1': 285, 'n_units_Layer_2': 190, 'n_units_Layer_3': 100, 'n_units_Layer_4': 130}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.54 | sMAPE for Validation Set is: 37.94% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.58 | sMAPE for Test Set is: 35.59% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:12:01,802]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:12:12,162]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:12:14,833]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:12:17,148]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:12:23,067]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:12:30,129]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:12:43,562]\u001b[0m Trial 391 finished with value: 14.429734125555782 and parameters: {'n_hidden': 4, 'learning_rate': 0.00268712275341231, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014586145325796433, 'dropout_rate_Layer_2': 0.12786164074096146, 'dropout_rate_Layer_3': 0.13824115885090982, 'dropout_rate_Layer_4': 0.027900475112265948, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00999138925027205, 'l1_Layer_2': 0.06491604520173981, 'l1_Layer_3': 0.04144374439046551, 'l1_Layer_4': 0.0018606976829691733, 'n_units_Layer_1': 140, 'n_units_Layer_2': 140, 'n_units_Layer_3': 125, 'n_units_Layer_4': 185}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.43 | sMAPE for Validation Set is: 37.67% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.87 | sMAPE for Test Set is: 35.96% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:12:48,357]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:13:03,755]\u001b[0m Trial 400 finished with value: 14.249188344276595 and parameters: {'n_hidden': 4, 'learning_rate': 0.003969183971304143, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007704949473262349, 'dropout_rate_Layer_2': 0.009120967244039045, 'dropout_rate_Layer_3': 0.13411992523223973, 'dropout_rate_Layer_4': 0.0801073602610453, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005881317820351842, 'l1_Layer_2': 0.034559668093859804, 'l1_Layer_3': 0.02487189116423727, 'l1_Layer_4': 0.0013471841088715248, 'n_units_Layer_1': 285, 'n_units_Layer_2': 270, 'n_units_Layer_3': 110, 'n_units_Layer_4': 145}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.25 | sMAPE for Validation Set is: 35.84% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.57 | sMAPE for Test Set is: 34.86% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:13:06,909]\u001b[0m Trial 393 finished with value: 14.288267241957243 and parameters: {'n_hidden': 3, 'learning_rate': 0.000619069611324591, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16913355217871953, 'dropout_rate_Layer_2': 0.02712335453253757, 'dropout_rate_Layer_3': 0.20959066653431196, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09982498326224701, 'l1_Layer_2': 0.00013534819957344103, 'l1_Layer_3': 0.006955586219737646, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 245}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.29 | sMAPE for Validation Set is: 35.59% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.45 | sMAPE for Test Set is: 35.40% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:13:12,677]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:13:15,043]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:13:17,963]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:13:21,667]\u001b[0m Trial 403 finished with value: 18.19604107207537 and parameters: {'n_hidden': 4, 'learning_rate': 0.005468024626168136, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3625317391660204, 'dropout_rate_Layer_2': 0.09860996956523173, 'dropout_rate_Layer_3': 0.3231425029171824, 'dropout_rate_Layer_4': 0.35656016644931515, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0020626894342000907, 'l1_Layer_2': 0.0028012203629300373, 'l1_Layer_3': 0.0005607500009140758, 'l1_Layer_4': 0.0006908779991562007, 'n_units_Layer_1': 90, 'n_units_Layer_2': 200, 'n_units_Layer_3': 205, 'n_units_Layer_4': 105}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.20 | sMAPE for Validation Set is: 39.51% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 11.62 | sMAPE for Test Set is: 35.76% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:13:26,410]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:14:04,908]\u001b[0m Trial 406 finished with value: 14.514546784080386 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033234767484775036, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11607378810052589, 'dropout_rate_Layer_2': 0.0006067582239292976, 'dropout_rate_Layer_3': 0.14393755453533688, 'dropout_rate_Layer_4': 0.06368833637485082, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.011642164045140442, 'l1_Layer_2': 0.04391343603175817, 'l1_Layer_3': 0.04873854809383492, 'l1_Layer_4': 0.0011729651208848108, 'n_units_Layer_1': 270, 'n_units_Layer_2': 185, 'n_units_Layer_3': 125, 'n_units_Layer_4': 150}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.51 | sMAPE for Validation Set is: 38.56% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.00 | sMAPE for Test Set is: 37.48% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:14:50,494]\u001b[0m Trial 407 finished with value: 14.258426144189675 and parameters: {'n_hidden': 4, 'learning_rate': 0.002613332612341035, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007914516837854497, 'dropout_rate_Layer_2': 0.12940205326457926, 'dropout_rate_Layer_3': 0.14410764447593175, 'dropout_rate_Layer_4': 0.06042986744649244, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007629076572691732, 'l1_Layer_2': 0.04329533277778644, 'l1_Layer_3': 0.052464067804167194, 'l1_Layer_4': 0.0032647368857512743, 'n_units_Layer_1': 290, 'n_units_Layer_2': 185, 'n_units_Layer_3': 120, 'n_units_Layer_4': 150}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.26 | sMAPE for Validation Set is: 37.07% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.55 | sMAPE for Test Set is: 35.64% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:14:56,011]\u001b[0m Trial 410 finished with value: 14.18311741796064 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005300712171769576, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08115744830767102, 'dropout_rate_Layer_2': 0.02572241542170578, 'dropout_rate_Layer_3': 0.14707834078273996, 'dropout_rate_Layer_4': 0.11637818020995316, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.03127942675558616, 'l1_Layer_2': 0.00535686454464406, 'l1_Layer_3': 0.000189424788935152, 'l1_Layer_4': 0.0014666314237378182, 'n_units_Layer_1': 215, 'n_units_Layer_2': 60, 'n_units_Layer_3': 90, 'n_units_Layer_4': 80}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.18 | sMAPE for Validation Set is: 34.70% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.48 | sMAPE for Test Set is: 35.06% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:15:02,967]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:15:08,321]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:15:16,613]\u001b[0m Trial 408 finished with value: 14.293579781680355 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005112840033030795, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.165902463025201, 'dropout_rate_Layer_2': 0.03159273553448789, 'dropout_rate_Layer_3': 0.14786982710643604, 'dropout_rate_Layer_4': 0.10719161974814476, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005230335432639962, 'l1_Layer_2': 0.004643111832634803, 'l1_Layer_3': 0.0004581084397961684, 'l1_Layer_4': 0.0006439326214373433, 'n_units_Layer_1': 250, 'n_units_Layer_2': 60, 'n_units_Layer_3': 85, 'n_units_Layer_4': 80}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.29 | sMAPE for Validation Set is: 34.64% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.35 | sMAPE for Test Set is: 34.77% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:15:17,133]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:15:33,747]\u001b[0m Trial 411 finished with value: 14.257083476567622 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005016345656991435, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16178199389562078, 'dropout_rate_Layer_2': 0.028927550611113587, 'dropout_rate_Layer_3': 0.14846721262923981, 'dropout_rate_Layer_4': 0.10455980880566741, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006378146968695972, 'l1_Layer_2': 0.005459923283953784, 'l1_Layer_3': 0.0004067821720742531, 'l1_Layer_4': 0.0006152614286352378, 'n_units_Layer_1': 245, 'n_units_Layer_2': 55, 'n_units_Layer_3': 95, 'n_units_Layer_4': 80}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.26 | sMAPE for Validation Set is: 34.54% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.31 | sMAPE for Test Set is: 34.83% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:16:21,146]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:16:30,918]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:16:31,828]\u001b[0m Trial 418 finished with value: 14.17807336474264 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025517571822743913, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007671913991237942, 'dropout_rate_Layer_2': 0.008373959287069044, 'dropout_rate_Layer_3': 0.1351858419841824, 'dropout_rate_Layer_4': 0.06541387423569787, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00583408726446019, 'l1_Layer_2': 0.0465023245174808, 'l1_Layer_3': 0.05071081262668017, 'l1_Layer_4': 0.003575681178189764, 'n_units_Layer_1': 285, 'n_units_Layer_2': 185, 'n_units_Layer_3': 120, 'n_units_Layer_4': 150}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.18 | sMAPE for Validation Set is: 36.10% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.60 | sMAPE for Test Set is: 35.93% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:16:43,808]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:16:44,195]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:17:04,680]\u001b[0m Trial 416 finished with value: 14.398619287126111 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005093952644764022, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17363939515866172, 'dropout_rate_Layer_2': 0.03220420675272107, 'dropout_rate_Layer_3': 0.14728950006904606, 'dropout_rate_Layer_4': 0.10622462454787585, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005362298044219173, 'l1_Layer_2': 0.005178220190016412, 'l1_Layer_3': 0.0004485210992070153, 'l1_Layer_4': 0.0006223922872943564, 'n_units_Layer_1': 250, 'n_units_Layer_2': 55, 'n_units_Layer_3': 90, 'n_units_Layer_4': 90}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.40 | sMAPE for Validation Set is: 36.53% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.59 | sMAPE for Test Set is: 36.02% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:17:22,690]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:17:26,366]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:17:53,131]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:17:57,670]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:17:57,831]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:18:03,345]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:18:10,546]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:18:15,696]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:18:28,855]\u001b[0m Trial 424 finished with value: 14.2522778922386 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021283514819004593, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007265911754989455, 'dropout_rate_Layer_2': 0.0025819978771598733, 'dropout_rate_Layer_3': 0.14115295095960503, 'dropout_rate_Layer_4': 0.07603380252487671, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005475437224898471, 'l1_Layer_2': 0.08516000560470857, 'l1_Layer_3': 0.05967209423760014, 'l1_Layer_4': 0.003990862503683761, 'n_units_Layer_1': 290, 'n_units_Layer_2': 170, 'n_units_Layer_3': 130, 'n_units_Layer_4': 150}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.25 | sMAPE for Validation Set is: 35.04% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.74 | sMAPE for Test Set is: 36.21% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:18:33,402]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:18:39,607]\u001b[0m Trial 422 finished with value: 14.277836937940984 and parameters: {'n_hidden': 4, 'learning_rate': 0.001832382557228476, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008218362429811624, 'dropout_rate_Layer_2': 0.0005498852421909079, 'dropout_rate_Layer_3': 0.1359739861347596, 'dropout_rate_Layer_4': 0.05460275228181782, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005199718340083755, 'l1_Layer_2': 0.08340729889689935, 'l1_Layer_3': 0.06369293680833532, 'l1_Layer_4': 0.0038034263613792897, 'n_units_Layer_1': 290, 'n_units_Layer_2': 185, 'n_units_Layer_3': 130, 'n_units_Layer_4': 150}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.28 | sMAPE for Validation Set is: 35.38% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.60 | sMAPE for Test Set is: 35.83% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:18:39,942]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:19:12,495]\u001b[0m Trial 430 finished with value: 14.302376496446646 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014358467419920745, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1187385571563514, 'dropout_rate_Layer_2': 0.0009647399531092823, 'dropout_rate_Layer_3': 0.15422917204609252, 'dropout_rate_Layer_4': 0.07736973240822252, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005677640447476365, 'l1_Layer_2': 0.05046854273356502, 'l1_Layer_3': 0.03718094340995547, 'l1_Layer_4': 0.004165781690872166, 'n_units_Layer_1': 285, 'n_units_Layer_2': 195, 'n_units_Layer_3': 115, 'n_units_Layer_4': 145}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.30 | sMAPE for Validation Set is: 37.12% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.45 | sMAPE for Test Set is: 34.98% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:19:21,222]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:19:35,929]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:19:45,026]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:19:54,060]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:19:54,728]\u001b[0m Trial 432 finished with value: 14.273771186675217 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007324961748704515, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1858482301635026, 'dropout_rate_Layer_2': 0.03136169221872697, 'dropout_rate_Layer_3': 0.23671135429167917, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.026352625638468984, 'l1_Layer_2': 4.7506376875475186e-05, 'l1_Layer_3': 0.005259301145604619, 'n_units_Layer_1': 195, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.27 | sMAPE for Validation Set is: 37.95% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.43 | sMAPE for Test Set is: 34.86% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:19:59,012]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:19:59,360]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:20:11,201]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:20:25,261]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:20:28,870]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:20:36,428]\u001b[0m Trial 443 finished with value: 14.657271494630104 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014325965738661206, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3717885537540439, 'dropout_rate_Layer_2': 0.3286822000701417, 'dropout_rate_Layer_3': 0.2786238183406532, 'dropout_rate_Layer_4': 0.346228603706147, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005553651688827241, 'l1_Layer_2': 0.00033102955319219175, 'l1_Layer_3': 0.003638157399816742, 'l1_Layer_4': 9.978113353999948e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 215, 'n_units_Layer_3': 145, 'n_units_Layer_4': 175}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.66 | sMAPE for Validation Set is: 40.01% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.35 | sMAPE for Test Set is: 35.44% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:20:52,813]\u001b[0m Trial 445 finished with value: 14.79672281932398 and parameters: {'n_hidden': 4, 'learning_rate': 0.00135722771366171, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37120445080431635, 'dropout_rate_Layer_2': 0.34125024753501076, 'dropout_rate_Layer_3': 0.27638761450943244, 'dropout_rate_Layer_4': 0.17181159174713542, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0007845175937630693, 'l1_Layer_2': 0.00026929110549305814, 'l1_Layer_3': 0.0007312762142227452, 'l1_Layer_4': 9.007323780618261e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 275, 'n_units_Layer_3': 150, 'n_units_Layer_4': 130}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.80 | sMAPE for Validation Set is: 38.11% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 11.65 | sMAPE for Test Set is: 35.88% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:21:17,341]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:21:25,417]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:21:39,486]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:21:40,245]\u001b[0m Trial 440 finished with value: 14.182648907395935 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014954484156207786, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11476013626006774, 'dropout_rate_Layer_2': 0.009104584326079065, 'dropout_rate_Layer_3': 0.14103216722933307, 'dropout_rate_Layer_4': 0.05010038427731516, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00498509210578385, 'l1_Layer_2': 0.08029558403864309, 'l1_Layer_3': 0.04892966244498954, 'l1_Layer_4': 0.004152417994160561, 'n_units_Layer_1': 295, 'n_units_Layer_2': 190, 'n_units_Layer_3': 130, 'n_units_Layer_4': 140}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.18 | sMAPE for Validation Set is: 34.96% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.60 | sMAPE for Test Set is: 35.72% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:22:20,064]\u001b[0m Trial 451 finished with value: 14.285543753209504 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008540559089644907, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12841948688611882, 'dropout_rate_Layer_2': 0.02269678725060527, 'dropout_rate_Layer_3': 0.12249401897733361, 'dropout_rate_Layer_4': 0.18801433360877431, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007456063081921017, 'l1_Layer_2': 0.01128443737300276, 'l1_Layer_3': 9.485834481715053e-05, 'l1_Layer_4': 0.001632814511405848, 'n_units_Layer_1': 205, 'n_units_Layer_2': 70, 'n_units_Layer_3': 100, 'n_units_Layer_4': 95}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.29 | sMAPE for Validation Set is: 35.53% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.59 | sMAPE for Test Set is: 35.32% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:22:29,503]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:22:41,044]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:22:48,169]\u001b[0m Trial 453 finished with value: 14.170513119482239 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012892574238691486, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007089430098589086, 'dropout_rate_Layer_2': 0.0028536683966216623, 'dropout_rate_Layer_3': 0.1317077883948182, 'dropout_rate_Layer_4': 0.043520582089131635, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0048325061382257445, 'l1_Layer_2': 0.055542724425348265, 'l1_Layer_3': 0.03358469336858519, 'l1_Layer_4': 0.005398877065438734, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 115, 'n_units_Layer_4': 140}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.17 | sMAPE for Validation Set is: 34.90% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.60 | sMAPE for Test Set is: 35.37% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:22:52,411]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:22:59,495]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:23:10,208]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:23:21,218]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:23:32,377]\u001b[0m Trial 452 finished with value: 14.20232773315862 and parameters: {'n_hidden': 4, 'learning_rate': 0.002275584731080857, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007113687659078688, 'dropout_rate_Layer_2': 0.0014088011991468092, 'dropout_rate_Layer_3': 0.1313014655639319, 'dropout_rate_Layer_4': 0.05993278384418729, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005287008451413754, 'l1_Layer_2': 0.0812468197350958, 'l1_Layer_3': 0.03350983443308974, 'l1_Layer_4': 0.0029684928269473935, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 135, 'n_units_Layer_4': 140}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.20 | sMAPE for Validation Set is: 34.69% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.46 | sMAPE for Test Set is: 34.80% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:23:32,719]\u001b[0m Trial 454 finished with value: 14.21216524647268 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014517869090671057, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006269383854508185, 'dropout_rate_Layer_2': 0.01391396361965977, 'dropout_rate_Layer_3': 0.1317373690194682, 'dropout_rate_Layer_4': 0.04235122535480895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004863518334856804, 'l1_Layer_2': 0.07401512715943438, 'l1_Layer_3': 0.034052668180456616, 'l1_Layer_4': 0.004676791726346025, 'n_units_Layer_1': 275, 'n_units_Layer_2': 185, 'n_units_Layer_3': 140, 'n_units_Layer_4': 140}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.21 | sMAPE for Validation Set is: 35.48% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.60 | sMAPE for Test Set is: 35.63% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:23:55,855]\u001b[0m Trial 458 finished with value: 14.206908090348795 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011382729672484869, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00016912472745680323, 'dropout_rate_Layer_2': 0.0013774777672408995, 'dropout_rate_Layer_3': 0.13502379141586587, 'dropout_rate_Layer_4': 0.042352625288165996, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00396989651092967, 'l1_Layer_2': 0.05252352289643191, 'l1_Layer_3': 0.03374339056587186, 'l1_Layer_4': 0.004895711111256656, 'n_units_Layer_1': 295, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110, 'n_units_Layer_4': 140}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.21 | sMAPE for Validation Set is: 35.09% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.76 | sMAPE for Test Set is: 36.16% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:24:01,623]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:24:15,656]\u001b[0m Trial 463 finished with value: 14.265558414710076 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006611310475748067, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08549360928449495, 'dropout_rate_Layer_2': 0.07097847065999599, 'dropout_rate_Layer_3': 0.15238744311776473, 'dropout_rate_Layer_4': 0.14071670869112668, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.012097975403598938, 'l1_Layer_2': 0.02205453395456588, 'l1_Layer_3': 0.0010882650979261207, 'l1_Layer_4': 0.0012451947017855052, 'n_units_Layer_1': 215, 'n_units_Layer_2': 60, 'n_units_Layer_3': 70, 'n_units_Layer_4': 60}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.27 | sMAPE for Validation Set is: 34.18% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.58 | sMAPE for Test Set is: 35.52% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:24:32,782]\u001b[0m Trial 462 finished with value: 14.176941952363515 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020545238119194934, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013776838097838334, 'dropout_rate_Layer_2': 0.0007347790239505118, 'dropout_rate_Layer_3': 0.11766281226826217, 'dropout_rate_Layer_4': 0.0660162977890385, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005012552951484482, 'l1_Layer_2': 0.09706542001652901, 'l1_Layer_3': 0.0271737435949839, 'l1_Layer_4': 0.00327537416097675, 'n_units_Layer_1': 295, 'n_units_Layer_2': 170, 'n_units_Layer_3': 135, 'n_units_Layer_4': 140}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.18 | sMAPE for Validation Set is: 35.02% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.69 | sMAPE for Test Set is: 35.77% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:24:35,681]\u001b[0m Trial 461 finished with value: 14.304869928537578 and parameters: {'n_hidden': 4, 'learning_rate': 0.002066902501830322, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01263775674917348, 'dropout_rate_Layer_2': 0.021065960043762703, 'dropout_rate_Layer_3': 0.12096035684948295, 'dropout_rate_Layer_4': 0.061796823247676956, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004652413443806593, 'l1_Layer_2': 0.09926774185752708, 'l1_Layer_3': 0.04212420979095299, 'l1_Layer_4': 0.004161471846538812, 'n_units_Layer_1': 295, 'n_units_Layer_2': 190, 'n_units_Layer_3': 115, 'n_units_Layer_4': 145}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.30 | sMAPE for Validation Set is: 36.21% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.72 | sMAPE for Test Set is: 35.95% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:24:38,470]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:24:52,483]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:24:56,695]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:25:04,499]\u001b[0m Trial 466 finished with value: 14.634871794948808 and parameters: {'n_hidden': 4, 'learning_rate': 0.005279031798556698, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09756654046079571, 'dropout_rate_Layer_2': 0.10694272615814632, 'dropout_rate_Layer_3': 0.3974061576882365, 'dropout_rate_Layer_4': 0.11968938252350228, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0035947061185452834, 'l1_Layer_2': 0.0036076129693901546, 'l1_Layer_3': 0.00035268452220826716, 'l1_Layer_4': 0.05816447501459424, 'n_units_Layer_1': 235, 'n_units_Layer_2': 50, 'n_units_Layer_3': 280, 'n_units_Layer_4': 230}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.63 | sMAPE for Validation Set is: 38.47% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.72 | sMAPE for Test Set is: 36.49% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:25:13,626]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:25:44,522]\u001b[0m Trial 465 finished with value: 14.458082712206648 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011677688054301375, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16462226150839107, 'dropout_rate_Layer_2': 0.0010327200930260183, 'dropout_rate_Layer_3': 0.23648020043708515, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016559923888250712, 'l1_Layer_2': 0.041330139646241604, 'l1_Layer_3': 0.0014874764889775721, 'n_units_Layer_1': 170, 'n_units_Layer_2': 115, 'n_units_Layer_3': 180}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.46 | sMAPE for Validation Set is: 33.67% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.91 | sMAPE for Test Set is: 36.94% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:25:59,923]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:26:18,345]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.49 | sMAPE for Validation Set is: 38.36% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.87 | sMAPE for Test Set is: 36.50% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:26:22,004]\u001b[0m Trial 474 finished with value: 14.488697695472387 and parameters: {'n_hidden': 4, 'learning_rate': 0.001414115344185862, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3794664591673143, 'dropout_rate_Layer_2': 0.38554771705978336, 'dropout_rate_Layer_3': 0.3089456952480465, 'dropout_rate_Layer_4': 0.35333718915005785, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0029646665307202277, 'l1_Layer_2': 7.023852442618833e-05, 'l1_Layer_3': 0.01622043626316416, 'l1_Layer_4': 9.064388619891131e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 220, 'n_units_Layer_3': 185, 'n_units_Layer_4': 180}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:26:26,630]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:26:36,256]\u001b[0m Trial 469 finished with value: 14.248627863197797 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013248107228311641, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007665965802370847, 'dropout_rate_Layer_2': 0.010099162014322823, 'dropout_rate_Layer_3': 0.11487140771955484, 'dropout_rate_Layer_4': 0.04177966637353847, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004013839464815872, 'l1_Layer_2': 0.08830079473110765, 'l1_Layer_3': 0.03050482226460197, 'l1_Layer_4': 0.0035704058790222313, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 145, 'n_units_Layer_4': 140}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.25 | sMAPE for Validation Set is: 34.92% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.70 | sMAPE for Test Set is: 36.17% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:26:40,361]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:26:49,040]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:26:55,339]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:27:07,342]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:27:18,086]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:27:36,915]\u001b[0m Trial 479 finished with value: 14.170342929425408 and parameters: {'n_hidden': 4, 'learning_rate': 0.001277672236772667, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023440142642546718, 'dropout_rate_Layer_2': 0.01546243987428543, 'dropout_rate_Layer_3': 0.12759890662096712, 'dropout_rate_Layer_4': 0.0625511810163648, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005042077566255492, 'l1_Layer_2': 0.08511898615143217, 'l1_Layer_3': 0.026981861454820573, 'l1_Layer_4': 0.0047734203353615124, 'n_units_Layer_1': 290, 'n_units_Layer_2': 160, 'n_units_Layer_3': 140, 'n_units_Layer_4': 145}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.17 | sMAPE for Validation Set is: 35.16% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.64 | sMAPE for Test Set is: 35.56% | rMAE for Test Set is: 0.48\n",
      "MAE for Validation Set is: 14.23 | sMAPE for Validation Set is: 35.43% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.70 | sMAPE for Test Set is: 36.19% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:27:39,649]\u001b[0m Trial 478 finished with value: 14.233306845957118 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012925114440435052, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00844076392464056, 'dropout_rate_Layer_2': 0.012833589116994245, 'dropout_rate_Layer_3': 0.12474239321489465, 'dropout_rate_Layer_4': 0.06214135888375499, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005441100991027202, 'l1_Layer_2': 0.08281435522026649, 'l1_Layer_3': 0.03633236840875001, 'l1_Layer_4': 0.004816589680896676, 'n_units_Layer_1': 290, 'n_units_Layer_2': 175, 'n_units_Layer_3': 140, 'n_units_Layer_4': 145}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:27:45,381]\u001b[0m Trial 482 finished with value: 14.192134238680758 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008882714447684185, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07466406219054893, 'dropout_rate_Layer_2': 3.561606691977401e-05, 'dropout_rate_Layer_3': 0.1358195503339767, 'dropout_rate_Layer_4': 0.16610877717758796, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.043458360838564275, 'l1_Layer_2': 0.0025184191978966227, 'l1_Layer_3': 0.00017731412726407184, 'l1_Layer_4': 0.00027103528074104395, 'n_units_Layer_1': 185, 'n_units_Layer_2': 65, 'n_units_Layer_3': 75, 'n_units_Layer_4': 85}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.19 | sMAPE for Validation Set is: 34.35% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.63 | sMAPE for Test Set is: 35.78% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:27:57,095]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:28:02,600]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:28:08,376]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:28:27,888]\u001b[0m Trial 487 finished with value: 14.250055402801467 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008410664560941902, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07258052219344414, 'dropout_rate_Layer_2': 0.01912653694894989, 'dropout_rate_Layer_3': 0.19261227305113232, 'dropout_rate_Layer_4': 0.1632043970115008, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.041729221970981105, 'l1_Layer_2': 0.0025166736523224613, 'l1_Layer_3': 0.00014817822065342086, 'l1_Layer_4': 0.0002675305376674373, 'n_units_Layer_1': 185, 'n_units_Layer_2': 65, 'n_units_Layer_3': 70, 'n_units_Layer_4': 85}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.25 | sMAPE for Validation Set is: 35.59% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.53 | sMAPE for Test Set is: 35.46% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:28:30,297]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:28:32,856]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:28:37,320]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:28:40,707]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:28:48,580]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:29:06,350]\u001b[0m Trial 490 finished with value: 14.148886387617894 and parameters: {'n_hidden': 4, 'learning_rate': 0.001468336985681797, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009765443988260656, 'dropout_rate_Layer_2': 0.007918106033550766, 'dropout_rate_Layer_3': 0.1346901198316936, 'dropout_rate_Layer_4': 0.044431446368325495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0033372755616259257, 'l1_Layer_2': 0.08114896138726117, 'l1_Layer_3': 0.03923236781533803, 'l1_Layer_4': 0.0053905532028692155, 'n_units_Layer_1': 290, 'n_units_Layer_2': 180, 'n_units_Layer_3': 145, 'n_units_Layer_4': 145}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.15 | sMAPE for Validation Set is: 35.35% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.65 | sMAPE for Test Set is: 35.69% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:29:17,005]\u001b[0m Trial 488 finished with value: 14.150483118360603 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008722301446030177, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07327550008311463, 'dropout_rate_Layer_2': 0.034263004711007475, 'dropout_rate_Layer_3': 0.13905600451742042, 'dropout_rate_Layer_4': 0.15079955045499208, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.04071161974713501, 'l1_Layer_2': 0.002633575786583397, 'l1_Layer_3': 0.00014825199216026886, 'l1_Layer_4': 0.0002714088540275034, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 75, 'n_units_Layer_4': 85}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.15 | sMAPE for Validation Set is: 34.36% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.31 | sMAPE for Test Set is: 34.45% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:29:19,561]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:29:23,877]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:29:26,160]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:29:34,599]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:29:43,758]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:29:48,239]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:29:51,373]\u001b[0m Trial 496 finished with value: 14.16891320981682 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012182597771800928, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020614810908581305, 'dropout_rate_Layer_2': 0.008211395669100733, 'dropout_rate_Layer_3': 0.11387058902672947, 'dropout_rate_Layer_4': 0.05065080924377219, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005833451689166918, 'l1_Layer_2': 0.08066481820642926, 'l1_Layer_3': 0.025987022148962497, 'l1_Layer_4': 0.003998985693482422, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 140, 'n_units_Layer_4': 140}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.17 | sMAPE for Validation Set is: 35.25% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.61 | sMAPE for Test Set is: 35.49% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:30:00,142]\u001b[0m Trial 498 finished with value: 14.771898192012998 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008539505221624534, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37247903892072604, 'dropout_rate_Layer_2': 0.39944584522735355, 'dropout_rate_Layer_3': 0.23846049712187325, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0027045886307055173, 'l1_Layer_2': 7.142718404674276e-05, 'l1_Layer_3': 0.02703107495113242, 'n_units_Layer_1': 160, 'n_units_Layer_2': 220, 'n_units_Layer_3': 190}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.77 | sMAPE for Validation Set is: 41.46% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 11.72 | sMAPE for Test Set is: 36.44% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:30:11,943]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:30:37,253]\u001b[0m Trial 507 finished with value: 15.715887577777913 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007687782537670517, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3553910522955512, 'dropout_rate_Layer_2': 0.3445030536038459, 'dropout_rate_Layer_3': 0.2917930479420344, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007731314615117328, 'l1_Layer_2': 2.4319498904134113e-05, 'l1_Layer_3': 0.08866104489710726, 'n_units_Layer_1': 170, 'n_units_Layer_2': 215, 'n_units_Layer_3': 215}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.72 | sMAPE for Validation Set is: 43.48% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 12.23 | sMAPE for Test Set is: 37.56% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:30:47,316]\u001b[0m Trial 505 finished with value: 14.342743859723958 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006633394934622888, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17457862602139415, 'dropout_rate_Layer_2': 0.02594239325766682, 'dropout_rate_Layer_3': 0.20704282787084896, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015510921995172684, 'l1_Layer_2': 0.002395163052012856, 'l1_Layer_3': 0.005524513067971928, 'n_units_Layer_1': 180, 'n_units_Layer_2': 235, 'n_units_Layer_3': 245}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:30:47,391]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.34 | sMAPE for Validation Set is: 35.23% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.72 | sMAPE for Test Set is: 36.15% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:31:00,812]\u001b[0m Trial 500 finished with value: 14.19745284925959 and parameters: {'n_hidden': 3, 'learning_rate': 0.001296088556793309, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009708862513907707, 'dropout_rate_Layer_2': 0.009030635074586664, 'dropout_rate_Layer_3': 0.11144829152039262, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005715232097075488, 'l1_Layer_2': 0.0859190539138926, 'l1_Layer_3': 0.03827010155823434, 'n_units_Layer_1': 285, 'n_units_Layer_2': 180, 'n_units_Layer_3': 150}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.20 | sMAPE for Validation Set is: 34.58% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.62 | sMAPE for Test Set is: 35.46% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:31:05,559]\u001b[0m Trial 506 finished with value: 14.24896715258087 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015597759645481365, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022925364769504557, 'dropout_rate_Layer_2': 0.015671208118144667, 'dropout_rate_Layer_3': 0.10800479326591979, 'dropout_rate_Layer_4': 0.03528709688141605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0024070851694197666, 'l1_Layer_2': 0.08046908531819372, 'l1_Layer_3': 0.027847521403216172, 'l1_Layer_4': 0.0037502687699437843, 'n_units_Layer_1': 295, 'n_units_Layer_2': 170, 'n_units_Layer_3': 150, 'n_units_Layer_4': 135}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.25 | sMAPE for Validation Set is: 35.66% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.59 | sMAPE for Test Set is: 35.26% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:32:00,592]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:32:01,524]\u001b[0m Trial 509 finished with value: 14.223149008498956 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011357037409172434, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021355146805910673, 'dropout_rate_Layer_2': 0.007118707637257719, 'dropout_rate_Layer_3': 0.10294522501088488, 'dropout_rate_Layer_4': 0.036937991235585915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004884274576985, 'l1_Layer_2': 0.06709741690915369, 'l1_Layer_3': 0.03837747268191742, 'l1_Layer_4': 0.00386496572038871, 'n_units_Layer_1': 295, 'n_units_Layer_2': 175, 'n_units_Layer_3': 140, 'n_units_Layer_4': 135}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.22 | sMAPE for Validation Set is: 34.95% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.63 | sMAPE for Test Set is: 35.63% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:32:43,487]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:32:56,979]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:33:02,646]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:33:22,005]\u001b[0m Trial 517 finished with value: 15.416559501160455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014546817355591205, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31569806425909963, 'dropout_rate_Layer_2': 0.3719630612576116, 'dropout_rate_Layer_3': 0.2461489736740687, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001518644339016187, 'l1_Layer_2': 0.00022250048505017506, 'l1_Layer_3': 0.04103265598702169, 'n_units_Layer_1': 165, 'n_units_Layer_2': 190, 'n_units_Layer_3': 190}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.42 | sMAPE for Validation Set is: 44.06% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 12.38 | sMAPE for Test Set is: 38.13% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:33:45,269]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:33:55,326]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:34:00,516]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:34:04,632]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:34:12,895]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:34:39,952]\u001b[0m Trial 516 finished with value: 14.171331268177132 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006085123738682014, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.056372797955755054, 'dropout_rate_Layer_2': 0.26336308782236745, 'dropout_rate_Layer_3': 0.10255240911056203, 'dropout_rate_Layer_4': 0.19403317137984646, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.02542330807319856, 'l1_Layer_2': 0.0008165609451771489, 'l1_Layer_3': 0.0003022217326206785, 'l1_Layer_4': 0.002008398207798917, 'n_units_Layer_1': 205, 'n_units_Layer_2': 70, 'n_units_Layer_3': 55, 'n_units_Layer_4': 105}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.17 | sMAPE for Validation Set is: 35.42% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.30 | sMAPE for Test Set is: 34.45% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:34:44,680]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:34:54,701]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:35:13,417]\u001b[0m Trial 523 finished with value: 14.310062470159716 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015367459806549658, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007745547585562759, 'dropout_rate_Layer_2': 0.023373080281809035, 'dropout_rate_Layer_3': 0.11676992290186178, 'dropout_rate_Layer_4': 0.04922986424659859, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0040331892760707465, 'l1_Layer_2': 0.07824421021773899, 'l1_Layer_3': 0.03469205809929858, 'l1_Layer_4': 0.005738864246891428, 'n_units_Layer_1': 280, 'n_units_Layer_2': 165, 'n_units_Layer_3': 145, 'n_units_Layer_4': 135}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.31 | sMAPE for Validation Set is: 36.73% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.72 | sMAPE for Test Set is: 36.07% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:35:17,967]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:35:18,014]\u001b[0m Trial 518 finished with value: 14.167738520113447 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005106615825027536, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19320166360565677, 'dropout_rate_Layer_2': 0.032690046915204635, 'dropout_rate_Layer_3': 0.15668548464365095, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01938698707936617, 'l1_Layer_2': 0.0023592249347490868, 'l1_Layer_3': 0.0009689474361460637, 'n_units_Layer_1': 175, 'n_units_Layer_2': 95, 'n_units_Layer_3': 190}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.17 | sMAPE for Validation Set is: 35.83% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.47 | sMAPE for Test Set is: 35.69% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:35:20,675]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:35:25,461]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:35:26,020]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:35:31,002]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:35:33,795]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:35:34,258]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:35:43,349]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:35:43,577]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:35:44,232]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:36:13,243]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:36:32,390]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:36:35,821]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:36:38,051]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:36:46,647]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:36:50,152]\u001b[0m Trial 531 finished with value: 14.315320628306496 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015561918972068615, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00036151391503253926, 'dropout_rate_Layer_2': 0.00012192444850155125, 'dropout_rate_Layer_3': 0.12721210602034125, 'dropout_rate_Layer_4': 0.05617779809494597, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003968080664072374, 'l1_Layer_2': 0.06246822236949877, 'l1_Layer_3': 0.030167740369246198, 'l1_Layer_4': 0.003487138627847485, 'n_units_Layer_1': 295, 'n_units_Layer_2': 155, 'n_units_Layer_3': 160, 'n_units_Layer_4': 135}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.32 | sMAPE for Validation Set is: 35.30% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.59 | sMAPE for Test Set is: 35.71% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:37:01,244]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:37:06,640]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:37:30,999]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:37:39,218]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:37:42,856]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:37:53,024]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:37:57,513]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:38:01,226]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:38:07,157]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:38:13,148]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:38:13,857]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:38:22,929]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:38:36,361]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:38:41,338]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:38:45,470]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:38:52,590]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:38:56,990]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:39:03,257]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:39:08,632]\u001b[0m Trial 539 finished with value: 14.264129258611794 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015367518021720326, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016164317029450436, 'dropout_rate_Layer_2': 0.007696784781356519, 'dropout_rate_Layer_3': 0.11382496057758863, 'dropout_rate_Layer_4': 0.07143631716968714, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005892819011105552, 'l1_Layer_2': 0.06756984967038551, 'l1_Layer_3': 0.023955203252368912, 'l1_Layer_4': 0.006818640357802471, 'n_units_Layer_1': 295, 'n_units_Layer_2': 170, 'n_units_Layer_3': 150, 'n_units_Layer_4': 130}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.26 | sMAPE for Validation Set is: 35.26% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.44 | sMAPE for Test Set is: 35.09% | rMAE for Test Set is: 0.47\n",
      "MAE for Validation Set is: 14.17 | sMAPE for Validation Set is: 34.77% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.52 | sMAPE for Test Set is: 35.29% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:39:11,036]\u001b[0m Trial 551 finished with value: 14.167244802229453 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007109601455401981, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0556435424119273, 'dropout_rate_Layer_2': 0.22203957984602718, 'dropout_rate_Layer_3': 0.04702809767167511, 'dropout_rate_Layer_4': 0.1247739027914132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.022012958031615303, 'l1_Layer_2': 0.002239981218732886, 'l1_Layer_3': 8.791975050079761e-05, 'l1_Layer_4': 0.0032092594059299553, 'n_units_Layer_1': 205, 'n_units_Layer_2': 180, 'n_units_Layer_3': 80, 'n_units_Layer_4': 75}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:39:14,391]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:39:15,517]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:39:16,807]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:39:23,298]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:39:23,746]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:39:32,368]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:39:36,163]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:39:40,632]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:39:45,175]\u001b[0m Trial 563 finished with value: 14.509156086177356 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009082950597366664, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38138344316412714, 'dropout_rate_Layer_2': 0.3159189397044323, 'dropout_rate_Layer_3': 0.2035486592855177, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09475708249158227, 'l1_Layer_2': 3.313636771167243e-05, 'l1_Layer_3': 0.012381429065814254, 'n_units_Layer_1': 150, 'n_units_Layer_2': 235, 'n_units_Layer_3': 145}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.51 | sMAPE for Validation Set is: 37.31% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.42 | sMAPE for Test Set is: 35.03% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:39:50,750]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:39:53,366]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:39:56,570]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:39:59,390]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:40:02,090]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:40:12,354]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:40:14,980]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:40:15,295]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:40:21,688]\u001b[0m Trial 565 finished with value: 14.188357480620096 and parameters: {'n_hidden': 4, 'learning_rate': 0.001855496460017761, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02041609918720093, 'dropout_rate_Layer_2': 0.017147827016823606, 'dropout_rate_Layer_3': 0.08806621823632982, 'dropout_rate_Layer_4': 0.0771296391068774, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005763233560906669, 'l1_Layer_2': 0.07425503479101847, 'l1_Layer_3': 0.05040869111125978, 'l1_Layer_4': 0.010568252459203151, 'n_units_Layer_1': 300, 'n_units_Layer_2': 170, 'n_units_Layer_3': 135, 'n_units_Layer_4': 145}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.19 | sMAPE for Validation Set is: 35.53% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.63 | sMAPE for Test Set is: 35.36% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:40:27,600]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:40:29,622]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:40:37,214]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:40:46,494]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:40:49,905]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:40:54,700]\u001b[0m Trial 579 finished with value: 14.319881000831806 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009503418886427143, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35466041212729255, 'dropout_rate_Layer_2': 0.37138314954762813, 'dropout_rate_Layer_3': 0.2019146016386421, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03169526442770154, 'l1_Layer_2': 3.914808232491279e-05, 'l1_Layer_3': 0.0063108888281264595, 'n_units_Layer_1': 155, 'n_units_Layer_2': 230, 'n_units_Layer_3': 165}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.32 | sMAPE for Validation Set is: 37.51% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.44 | sMAPE for Test Set is: 35.35% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:40:56,284]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:40:57,449]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:41:01,845]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:41:02,388]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:41:02,951]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:41:08,296]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:41:12,074]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:41:12,664]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:41:18,345]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:41:22,871]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:41:24,930]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:41:33,277]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:41:38,294]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:41:42,533]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:41:52,803]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:41:53,358]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:41:59,940]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:42:05,971]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:42:19,244]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:42:20,031]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:42:26,708]\u001b[0m Trial 596 finished with value: 14.214608123450084 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014665369166286396, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016147106417452768, 'dropout_rate_Layer_2': 0.00624238818700956, 'dropout_rate_Layer_3': 0.0815229007928198, 'dropout_rate_Layer_4': 0.05472751360150991, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00508975208370183, 'l1_Layer_2': 0.062326557714352804, 'l1_Layer_3': 0.046157353572260695, 'l1_Layer_4': 0.003657039387490625, 'n_units_Layer_1': 290, 'n_units_Layer_2': 185, 'n_units_Layer_3': 115, 'n_units_Layer_4': 155}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.21 | sMAPE for Validation Set is: 35.07% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.60 | sMAPE for Test Set is: 35.57% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:42:37,161]\u001b[0m Trial 606 finished with value: 14.236979009110613 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011363071933291446, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08883297322674288, 'dropout_rate_Layer_2': 0.267856109620082, 'dropout_rate_Layer_3': 0.10134883696079283, 'dropout_rate_Layer_4': 0.22622458811295879, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0315199774455422, 'l1_Layer_2': 0.009442167701533326, 'l1_Layer_3': 3.6237824180033187e-05, 'l1_Layer_4': 0.004456171757324556, 'n_units_Layer_1': 190, 'n_units_Layer_2': 215, 'n_units_Layer_3': 105, 'n_units_Layer_4': 95}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.24 | sMAPE for Validation Set is: 34.44% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.49 | sMAPE for Test Set is: 35.44% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:42:40,961]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:42:44,026]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:42:45,181]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:42:49,226]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:42:51,556]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:42:56,268]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:43:01,077]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:43:55,091]\u001b[0m Trial 609 finished with value: 14.409517021737507 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006449670871423714, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06913449486602373, 'dropout_rate_Layer_2': 0.2714829360710831, 'dropout_rate_Layer_3': 0.12975704390466297, 'dropout_rate_Layer_4': 0.17311895349848622, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.009007642798363073, 'l1_Layer_2': 0.0035673604433073547, 'l1_Layer_3': 7.823463270548518e-05, 'l1_Layer_4': 0.0008121034360616269, 'n_units_Layer_1': 215, 'n_units_Layer_2': 180, 'n_units_Layer_3': 100, 'n_units_Layer_4': 85}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.41 | sMAPE for Validation Set is: 36.06% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.48 | sMAPE for Test Set is: 35.06% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:43:59,664]\u001b[0m Trial 614 finished with value: 14.417803131459587 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006595390633277109, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06570959453401999, 'dropout_rate_Layer_2': 0.18893498380027735, 'dropout_rate_Layer_3': 0.16444542632836504, 'dropout_rate_Layer_4': 0.13746340953899924, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.010104450819990392, 'l1_Layer_2': 0.006910637849640661, 'l1_Layer_3': 5.479814488445757e-05, 'l1_Layer_4': 0.0014661151068324828, 'n_units_Layer_1': 215, 'n_units_Layer_2': 175, 'n_units_Layer_3': 90, 'n_units_Layer_4': 65}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.42 | sMAPE for Validation Set is: 36.09% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.62 | sMAPE for Test Set is: 35.66% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:44:09,907]\u001b[0m Trial 608 finished with value: 14.354199247028353 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006684532479510736, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06689312209270601, 'dropout_rate_Layer_2': 0.18036373284623303, 'dropout_rate_Layer_3': 0.163916472677205, 'dropout_rate_Layer_4': 0.17386011550442584, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.009345497084572428, 'l1_Layer_2': 0.0036127428367384276, 'l1_Layer_3': 7.299197645648183e-05, 'l1_Layer_4': 0.0031861687218460366, 'n_units_Layer_1': 200, 'n_units_Layer_2': 180, 'n_units_Layer_3': 100, 'n_units_Layer_4': 85}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.35 | sMAPE for Validation Set is: 36.24% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.55 | sMAPE for Test Set is: 35.82% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:44:13,176]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:44:15,656]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:44:17,455]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:44:19,825]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:44:22,344]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:44:25,124]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:44:29,822]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:44:33,417]\u001b[0m Trial 617 finished with value: 14.297127091725889 and parameters: {'n_hidden': 4, 'learning_rate': 0.000664451208055553, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0691365640288663, 'dropout_rate_Layer_2': 0.19271209797589237, 'dropout_rate_Layer_3': 0.16580993471953628, 'dropout_rate_Layer_4': 0.14000083245901285, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.008900664762594433, 'l1_Layer_2': 0.007051784986387126, 'l1_Layer_3': 0.00011587040432644007, 'l1_Layer_4': 0.0014908896886815378, 'n_units_Layer_1': 215, 'n_units_Layer_2': 175, 'n_units_Layer_3': 90, 'n_units_Layer_4': 65}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.30 | sMAPE for Validation Set is: 35.17% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.46 | sMAPE for Test Set is: 35.28% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:44:34,557]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:44:37,998]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:44:40,729]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:44:40,907]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:44:41,896]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:44:43,879]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:44:54,151]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:44:57,883]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:45:00,125]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:45:03,285]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:45:13,909]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:45:24,023]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:45:29,310]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:45:47,433]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:45:51,389]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:46:02,883]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:46:09,056]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:46:15,721]\u001b[0m Trial 632 finished with value: 14.177984991564209 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014872751648851907, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02122145028739502, 'dropout_rate_Layer_2': 0.013996897992342737, 'dropout_rate_Layer_3': 0.13909670082826006, 'dropout_rate_Layer_4': 0.06855544569975752, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004894983285121851, 'l1_Layer_2': 0.07738175587649117, 'l1_Layer_3': 0.05599983207560812, 'l1_Layer_4': 0.002953232737304934, 'n_units_Layer_1': 285, 'n_units_Layer_2': 195, 'n_units_Layer_3': 150, 'n_units_Layer_4': 155}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.18 | sMAPE for Validation Set is: 35.22% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.66 | sMAPE for Test Set is: 35.68% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:46:20,498]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:46:24,926]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:46:30,484]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:46:41,215]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:46:47,372]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:46:54,342]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:47:05,445]\u001b[0m Trial 645 finished with value: 14.326174917940321 and parameters: {'n_hidden': 3, 'learning_rate': 0.001047502691117114, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16577891854571913, 'dropout_rate_Layer_2': 0.31214226575236154, 'dropout_rate_Layer_3': 0.25636705498685336, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.018457903164019313, 'l1_Layer_2': 0.0005099699326843934, 'l1_Layer_3': 0.0023621755507464925, 'n_units_Layer_1': 185, 'n_units_Layer_2': 220, 'n_units_Layer_3': 185}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.33 | sMAPE for Validation Set is: 35.82% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.64 | sMAPE for Test Set is: 36.03% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:47:07,756]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:47:14,479]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:47:20,688]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:47:29,244]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:47:36,017]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:47:41,090]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:47:46,266]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:48:10,138]\u001b[0m Trial 655 finished with value: 14.264494668547224 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005600335963203415, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0965484540590843, 'dropout_rate_Layer_2': 0.3017415050334994, 'dropout_rate_Layer_3': 0.15520982011866646, 'dropout_rate_Layer_4': 0.217271477327217, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.029495314029584975, 'l1_Layer_2': 0.008391771959204116, 'l1_Layer_3': 3.969570623865868e-05, 'l1_Layer_4': 0.004227798301186665, 'n_units_Layer_1': 185, 'n_units_Layer_2': 195, 'n_units_Layer_3': 170, 'n_units_Layer_4': 90}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.26 | sMAPE for Validation Set is: 34.52% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.50 | sMAPE for Test Set is: 34.85% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:48:14,695]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:48:25,512]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:48:29,237]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:48:32,334]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:48:36,295]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:48:57,340]\u001b[0m Trial 639 finished with value: 14.14585850133354 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013476898950102914, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06899682622144118, 'dropout_rate_Layer_2': 0.0001846069408761343, 'dropout_rate_Layer_3': 0.12885600424222582, 'dropout_rate_Layer_4': 0.046744918234158175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004429220091712253, 'l1_Layer_2': 0.0593129233221637, 'l1_Layer_3': 0.04627970314236143, 'l1_Layer_4': 0.002550745954393474, 'n_units_Layer_1': 290, 'n_units_Layer_2': 185, 'n_units_Layer_3': 115, 'n_units_Layer_4': 140}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.15 | sMAPE for Validation Set is: 35.20% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.46 | sMAPE for Test Set is: 35.37% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:49:03,826]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:49:04,623]\u001b[0m Trial 652 finished with value: 14.235021351034193 and parameters: {'n_hidden': 4, 'learning_rate': 0.001346523622001151, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017055460164759204, 'dropout_rate_Layer_2': 0.030995610991564403, 'dropout_rate_Layer_3': 0.12414227982397298, 'dropout_rate_Layer_4': 0.06798551801916493, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004402300980931559, 'l1_Layer_2': 0.06854420597937926, 'l1_Layer_3': 0.0856383921470924, 'l1_Layer_4': 0.0029780540368914664, 'n_units_Layer_1': 285, 'n_units_Layer_2': 190, 'n_units_Layer_3': 135, 'n_units_Layer_4': 150}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.24 | sMAPE for Validation Set is: 36.54% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.59 | sMAPE for Test Set is: 35.44% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:49:16,004]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:49:16,460]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:49:38,025]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:49:42,393]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:49:54,578]\u001b[0m Trial 670 finished with value: 14.339164482866806 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009366131034358169, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0859793128220921, 'dropout_rate_Layer_2': 0.07716370236862767, 'dropout_rate_Layer_3': 0.0685463125745007, 'dropout_rate_Layer_4': 0.22155828781789563, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.038592033370452694, 'l1_Layer_2': 0.013919916576174607, 'l1_Layer_3': 6.546049159926741e-05, 'l1_Layer_4': 0.015600081701720484, 'n_units_Layer_1': 180, 'n_units_Layer_2': 260, 'n_units_Layer_3': 85, 'n_units_Layer_4': 170}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.34 | sMAPE for Validation Set is: 35.80% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.51 | sMAPE for Test Set is: 34.92% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:50:02,118]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:50:06,732]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:50:24,986]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:50:30,851]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:50:37,549]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:50:57,792]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:51:00,720]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:51:07,896]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:51:12,136]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:51:21,799]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:51:24,911]\u001b[0m Trial 681 finished with value: 14.613725404923633 and parameters: {'n_hidden': 3, 'learning_rate': 0.00291073501214196, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3009931711324931, 'dropout_rate_Layer_2': 0.3136126817193602, 'dropout_rate_Layer_3': 0.21159319059838852, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09775750292458976, 'l1_Layer_2': 3.6038635592229086e-05, 'l1_Layer_3': 0.011068456100966127, 'n_units_Layer_1': 150, 'n_units_Layer_2': 245, 'n_units_Layer_3': 175}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.61 | sMAPE for Validation Set is: 38.56% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.75 | sMAPE for Test Set is: 36.46% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:51:27,701]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:51:30,240]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:51:35,259]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:51:41,010]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:51:41,342]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:51:48,184]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:51:52,649]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:52:11,963]\u001b[0m Trial 692 finished with value: 14.811816790825384 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031129569885824794, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3016201965558421, 'dropout_rate_Layer_2': 0.2963600111846906, 'dropout_rate_Layer_3': 0.208028795576149, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09019889007129203, 'l1_Layer_2': 1.7504303026764316e-05, 'l1_Layer_3': 0.013385528517509074, 'n_units_Layer_1': 150, 'n_units_Layer_2': 245, 'n_units_Layer_3': 175}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.81 | sMAPE for Validation Set is: 40.58% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 11.55 | sMAPE for Test Set is: 35.35% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:52:21,448]\u001b[0m Trial 675 finished with value: 14.25526347097849 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012710097065703801, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05717581525444522, 'dropout_rate_Layer_2': 0.01878256099643389, 'dropout_rate_Layer_3': 0.10582705007529813, 'dropout_rate_Layer_4': 0.06160577691910469, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00322506923536434, 'l1_Layer_2': 0.07067488236025272, 'l1_Layer_3': 0.07875544601059822, 'l1_Layer_4': 0.0032016772076146932, 'n_units_Layer_1': 285, 'n_units_Layer_2': 200, 'n_units_Layer_3': 120, 'n_units_Layer_4': 140}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.26 | sMAPE for Validation Set is: 36.49% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.58 | sMAPE for Test Set is: 35.57% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:52:22,488]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:52:25,366]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:52:28,676]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:52:30,818]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:52:33,834]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:52:38,027]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:52:38,707]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:52:45,621]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:52:46,246]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:52:50,082]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:52:58,372]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:53:03,866]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:53:12,740]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:53:13,421]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:53:19,227]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:53:20,930]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:53:27,332]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:53:27,639]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:53:34,028]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:53:36,374]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:53:40,315]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:53:58,304]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:54:02,441]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:54:07,822]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:54:12,813]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:54:14,064]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:54:18,927]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:54:20,776]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:54:28,335]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:54:32,646]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:54:42,396]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:54:47,121]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:54:51,459]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:54:57,865]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:55:01,129]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:55:03,876]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:55:07,220]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:55:16,940]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:55:20,484]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:55:26,930]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:55:31,293]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:55:40,981]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:55:54,920]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:55:59,557]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:56:00,421]\u001b[0m Trial 722 finished with value: 14.24439090599561 and parameters: {'n_hidden': 4, 'learning_rate': 0.000775248763476816, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03280526909460297, 'dropout_rate_Layer_2': 0.32730983270395375, 'dropout_rate_Layer_3': 0.19447154168158695, 'dropout_rate_Layer_4': 0.14273841722781178, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.03718578386405053, 'l1_Layer_2': 0.0057319339211283045, 'l1_Layer_3': 0.0005677547588147983, 'l1_Layer_4': 0.0010120015327507, 'n_units_Layer_1': 195, 'n_units_Layer_2': 285, 'n_units_Layer_3': 280, 'n_units_Layer_4': 70}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.24 | sMAPE for Validation Set is: 35.41% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.50 | sMAPE for Test Set is: 35.61% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:56:06,861]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:56:11,516]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:56:14,681]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:56:18,431]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:56:27,505]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:56:36,792]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:56:43,536]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:56:43,958]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:56:50,009]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:56:54,289]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:56:59,868]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:57:04,391]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:57:06,662]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:57:10,599]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:57:16,093]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:57:16,486]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:57:17,166]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:57:24,950]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:57:27,499]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:57:33,077]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:57:39,175]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:57:44,736]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:57:49,949]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:57:55,444]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:57:56,163]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:58:05,296]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:58:07,538]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:58:13,097]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:58:19,946]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:58:29,044]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:58:29,235]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:58:33,271]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:58:38,800]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:58:38,941]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:58:43,272]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:58:47,727]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:58:48,101]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:58:50,672]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:59:10,234]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:59:10,414]\u001b[0m Trial 756 finished with value: 14.222105279678074 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008654223529376275, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029743268890866738, 'dropout_rate_Layer_2': 0.3665082961601099, 'dropout_rate_Layer_3': 0.2139403814963529, 'dropout_rate_Layer_4': 0.15668405218299697, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.061704287689051326, 'l1_Layer_2': 0.0039308655522607965, 'l1_Layer_3': 0.00036776157797484494, 'l1_Layer_4': 0.0009559889283404838, 'n_units_Layer_1': 190, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280, 'n_units_Layer_4': 55}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.22 | sMAPE for Validation Set is: 35.14% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.63 | sMAPE for Test Set is: 35.96% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:59:17,407]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:59:31,481]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:59:37,150]\u001b[0m Trial 775 finished with value: 14.233389575509165 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016239750268156796, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025426435415837313, 'dropout_rate_Layer_2': 0.013653382374666352, 'dropout_rate_Layer_3': 0.10727659306249554, 'dropout_rate_Layer_4': 0.07485338637809273, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006155491033803148, 'l1_Layer_2': 0.08595976134376782, 'l1_Layer_3': 0.05241877000563026, 'l1_Layer_4': 0.0037887393062877627, 'n_units_Layer_1': 290, 'n_units_Layer_2': 165, 'n_units_Layer_3': 110, 'n_units_Layer_4': 135}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.23 | sMAPE for Validation Set is: 35.30% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.63 | sMAPE for Test Set is: 35.91% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 17:59:43,686]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:59:50,086]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:59:54,256]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:59:54,949]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 17:59:56,125]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:00:03,039]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:00:06,554]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:00:07,367]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:00:13,361]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:00:18,210]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:00:19,085]\u001b[0m Trial 780 finished with value: 14.122024616560788 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005431732496585882, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0472844963080972, 'dropout_rate_Layer_2': 0.3771340792865441, 'dropout_rate_Layer_3': 0.26780392599995234, 'dropout_rate_Layer_4': 0.18145259049680393, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.06324551081819506, 'l1_Layer_2': 0.0019389596778670286, 'l1_Layer_3': 0.00015373699769677697, 'l1_Layer_4': 0.0001123023868848484, 'n_units_Layer_1': 165, 'n_units_Layer_2': 240, 'n_units_Layer_3': 270, 'n_units_Layer_4': 95}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.12 | sMAPE for Validation Set is: 33.71% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.51 | sMAPE for Test Set is: 35.79% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:00:25,095]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:00:25,295]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:00:31,689]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:00:31,949]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:00:32,997]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.34 | sMAPE for Validation Set is: 38.17% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.43 | sMAPE for Test Set is: 35.07% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:00:35,653]\u001b[0m Trial 787 finished with value: 14.34097299698567 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011233364841161627, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3868385377810316, 'dropout_rate_Layer_2': 0.3217279809788488, 'dropout_rate_Layer_3': 0.3135618329934459, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06092014665524451, 'l1_Layer_2': 9.97037594286033e-05, 'l1_Layer_3': 0.0037791663337460326, 'n_units_Layer_1': 130, 'n_units_Layer_2': 225, 'n_units_Layer_3': 140}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:00:41,160]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:00:43,455]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:00:44,865]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:00:50,691]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:00:59,223]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:01:09,362]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:01:28,559]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:01:31,101]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:01:31,644]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:01:35,958]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:01:40,255]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:01:50,994]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:02:01,573]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:02:08,522]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:02:14,483]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:02:19,401]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:02:24,696]\u001b[0m Trial 807 finished with value: 14.23042644655238 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009826832611295197, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3959212658047384, 'dropout_rate_Layer_2': 0.2880488471086921, 'dropout_rate_Layer_3': 0.3093104303454287, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05727150304226544, 'l1_Layer_2': 9.007980155024926e-05, 'l1_Layer_3': 0.034374245480983716, 'n_units_Layer_1': 135, 'n_units_Layer_2': 230, 'n_units_Layer_3': 135}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.23 | sMAPE for Validation Set is: 36.59% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.50 | sMAPE for Test Set is: 35.06% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:02:26,725]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:02:31,132]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:02:34,708]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:02:38,369]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:02:44,532]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:02:49,171]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:03:19,547]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:03:39,442]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:03:44,863]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:03:44,973]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:03:53,632]\u001b[0m Trial 804 finished with value: 14.276166582949998 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012001041176312416, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006946256281751204, 'dropout_rate_Layer_2': 0.007108405464509068, 'dropout_rate_Layer_3': 0.12591899823321073, 'dropout_rate_Layer_4': 0.075483173286193, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0066046867202360585, 'l1_Layer_2': 0.08803381352656603, 'l1_Layer_3': 0.03727684410489986, 'l1_Layer_4': 0.0017412663466999858, 'n_units_Layer_1': 285, 'n_units_Layer_2': 175, 'n_units_Layer_3': 125, 'n_units_Layer_4': 140}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.28 | sMAPE for Validation Set is: 35.08% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.66 | sMAPE for Test Set is: 36.01% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:03:58,559]\u001b[0m Trial 822 finished with value: 14.09224527832294 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005086577161798218, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09079771522823557, 'dropout_rate_Layer_2': 0.3774800349893451, 'dropout_rate_Layer_3': 0.24379019826534448, 'dropout_rate_Layer_4': 0.10051404550715483, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.09771297918965553, 'l1_Layer_2': 0.00450927792058106, 'l1_Layer_3': 0.000132695132976647, 'l1_Layer_4': 0.002827431740371288, 'n_units_Layer_1': 160, 'n_units_Layer_2': 205, 'n_units_Layer_3': 255, 'n_units_Layer_4': 65}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.09 | sMAPE for Validation Set is: 34.13% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.42 | sMAPE for Test Set is: 34.99% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:04:03,555]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:06,833]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:10,728]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:13,111]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:18,032]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:18,086]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:19,269]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:20,466]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:25,960]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:30,236]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:30,870]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:32,765]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:38,513]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:38,971]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:45,332]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:47,073]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:51,486]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:55,723]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:55,946]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:04:56,180]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:05:06,582]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:05:10,705]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:05:15,671]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:05:19,762]\u001b[0m Trial 847 finished with value: 14.409869264812665 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009685706832899244, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35244292722096415, 'dropout_rate_Layer_2': 0.2913198396008308, 'dropout_rate_Layer_3': 0.3149207982845854, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06239057037568175, 'l1_Layer_2': 0.00015056442713226335, 'l1_Layer_3': 0.015262790229641032, 'n_units_Layer_1': 140, 'n_units_Layer_2': 205, 'n_units_Layer_3': 125}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.41 | sMAPE for Validation Set is: 37.26% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.38 | sMAPE for Test Set is: 34.85% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:05:29,091]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:05:32,979]\u001b[0m Trial 850 finished with value: 14.490503559845118 and parameters: {'n_hidden': 3, 'learning_rate': 0.00108690481762956, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.394550307449383, 'dropout_rate_Layer_2': 0.28814367232085775, 'dropout_rate_Layer_3': 0.31250010594238115, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0651449537140796, 'l1_Layer_2': 0.00014702912147574916, 'l1_Layer_3': 0.05500657094243051, 'n_units_Layer_1': 135, 'n_units_Layer_2': 205, 'n_units_Layer_3': 130}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.49 | sMAPE for Validation Set is: 36.97% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.52 | sMAPE for Test Set is: 35.35% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:05:37,062]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:05:43,378]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:05:52,879]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:06:03,281]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:06:09,689]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:06:28,151]\u001b[0m Trial 857 finished with value: 14.321949645416254 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010119417302995772, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3620141346363124, 'dropout_rate_Layer_2': 0.2394854872368425, 'dropout_rate_Layer_3': 0.33730832321977655, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06080642729516559, 'l1_Layer_2': 9.944000460750487e-05, 'l1_Layer_3': 0.01666184597554409, 'n_units_Layer_1': 135, 'n_units_Layer_2': 185, 'n_units_Layer_3': 130}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.32 | sMAPE for Validation Set is: 36.14% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.43 | sMAPE for Test Set is: 34.88% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:06:34,032]\u001b[0m Trial 851 finished with value: 14.22949658382594 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007179283076746936, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08477011805328129, 'dropout_rate_Layer_2': 0.06951311077825623, 'dropout_rate_Layer_3': 0.2833943828477603, 'dropout_rate_Layer_4': 0.07968624382473108, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.054576119690138175, 'l1_Layer_2': 0.0029909570119643993, 'l1_Layer_3': 7.413026399371546e-05, 'l1_Layer_4': 0.0001811758548395209, 'n_units_Layer_1': 210, 'n_units_Layer_2': 190, 'n_units_Layer_3': 285, 'n_units_Layer_4': 85}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.23 | sMAPE for Validation Set is: 33.87% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.50 | sMAPE for Test Set is: 35.42% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:06:34,503]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:06:34,673]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:06:44,015]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:06:46,150]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:06:49,755]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:06:54,148]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:07:01,904]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:07:06,071]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:07:07,740]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:07:12,294]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:07:15,012]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:07:20,109]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:07:20,398]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.24 | sMAPE for Validation Set is: 36.27% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.55 | sMAPE for Test Set is: 35.74% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:07:22,578]\u001b[0m Trial 865 finished with value: 14.242635685724919 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009974803116345457, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36647079503024044, 'dropout_rate_Layer_2': 0.24045487953727074, 'dropout_rate_Layer_3': 0.3771150262783658, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013141722304303438, 'l1_Layer_2': 8.443514917657711e-05, 'l1_Layer_3': 0.015631720498737116, 'n_units_Layer_1': 160, 'n_units_Layer_2': 190, 'n_units_Layer_3': 130}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:07:29,332]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:07:31,811]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:07:35,173]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:07:41,211]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:07:45,988]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:07:53,290]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:08:15,847]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:08:55,993]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:09:00,804]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:09:01,979]\u001b[0m Trial 878 finished with value: 14.208959734775055 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005004417137410603, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06138125543898619, 'dropout_rate_Layer_2': 0.08485277206835745, 'dropout_rate_Layer_3': 0.25952036536167633, 'dropout_rate_Layer_4': 0.0742077794669191, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.06489308317399649, 'l1_Layer_2': 0.002598321708708579, 'l1_Layer_3': 0.00010608279535714372, 'l1_Layer_4': 8.73979317411226e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 190, 'n_units_Layer_3': 275, 'n_units_Layer_4': 75}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.21 | sMAPE for Validation Set is: 34.06% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.44 | sMAPE for Test Set is: 35.24% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:09:06,301]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:09:09,114]\u001b[0m Trial 863 finished with value: 14.10984403116854 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006174336074577756, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04591432710941816, 'dropout_rate_Layer_2': 0.022224644871853938, 'dropout_rate_Layer_3': 0.1977618324248464, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01912090964848819, 'l1_Layer_2': 4.6411689031060276e-05, 'l1_Layer_3': 0.007815419415616164, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 205}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.11 | sMAPE for Validation Set is: 35.61% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.52 | sMAPE for Test Set is: 35.61% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:09:13,892]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:09:20,228]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:09:21,146]\u001b[0m Trial 882 finished with value: 14.186368767889965 and parameters: {'n_hidden': 4, 'learning_rate': 0.000717037932289587, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06097334844979675, 'dropout_rate_Layer_2': 0.380630113092982, 'dropout_rate_Layer_3': 0.27587636775582414, 'dropout_rate_Layer_4': 0.07964913215014827, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.05529993887581692, 'l1_Layer_2': 0.0018249221197844487, 'l1_Layer_3': 0.0001027021386880117, 'l1_Layer_4': 0.0002521510464292547, 'n_units_Layer_1': 170, 'n_units_Layer_2': 190, 'n_units_Layer_3': 275, 'n_units_Layer_4': 75}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.19 | sMAPE for Validation Set is: 35.15% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.59 | sMAPE for Test Set is: 35.90% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:09:26,857]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:09:27,818]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:09:33,924]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:09:39,887]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:09:45,791]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:09:52,203]\u001b[0m Trial 886 finished with value: 14.2116349614721 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011611947359794197, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35802894683732733, 'dropout_rate_Layer_2': 0.2512770161087152, 'dropout_rate_Layer_3': 0.33952032476031946, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015570860890616614, 'l1_Layer_2': 0.00010018258548851368, 'l1_Layer_3': 0.027656516154378273, 'n_units_Layer_1': 110, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.21 | sMAPE for Validation Set is: 36.85% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.40 | sMAPE for Test Set is: 34.71% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:09:56,011]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:09:59,273]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:10:00,455]\u001b[0m Trial 892 finished with value: 14.306052810462049 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009990296291980823, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3622286382662072, 'dropout_rate_Layer_2': 0.23705351015898107, 'dropout_rate_Layer_3': 0.3808371387032715, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014581502477781552, 'l1_Layer_2': 9.080831934394274e-05, 'l1_Layer_3': 0.03433527142011193, 'n_units_Layer_1': 110, 'n_units_Layer_2': 190, 'n_units_Layer_3': 115}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.31 | sMAPE for Validation Set is: 38.25% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.53 | sMAPE for Test Set is: 35.53% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:10:05,276]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:10:06,741]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:10:12,543]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:10:18,088]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:10:19,743]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:10:23,620]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:10:24,201]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:10:24,439]\u001b[0m Trial 887 finished with value: 14.668181477301724 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005035395056436934, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.061746338663547506, 'dropout_rate_Layer_2': 0.08318367689605666, 'dropout_rate_Layer_3': 0.2591726555455016, 'dropout_rate_Layer_4': 0.07097198844428848, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0046478747162636e-05, 'l1_Layer_2': 0.0018058849393564611, 'l1_Layer_3': 0.00010108144795956815, 'l1_Layer_4': 7.091524321297932e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 185, 'n_units_Layer_3': 270, 'n_units_Layer_4': 75}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.67 | sMAPE for Validation Set is: 34.38% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.81 | sMAPE for Test Set is: 36.46% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:10:32,293]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:10:36,224]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:10:36,635]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:10:43,099]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:10:43,951]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:10:51,043]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:10:55,673]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:11:00,697]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:11:01,438]\u001b[0m Trial 906 finished with value: 14.324324792499205 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007206473472416763, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3661654737078673, 'dropout_rate_Layer_2': 0.23779567173428215, 'dropout_rate_Layer_3': 0.3807484849807764, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015133641087590374, 'l1_Layer_2': 5.124313812187542e-05, 'l1_Layer_3': 0.03121270135593065, 'n_units_Layer_1': 115, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.32 | sMAPE for Validation Set is: 37.88% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.43 | sMAPE for Test Set is: 35.09% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:11:06,628]\u001b[0m Trial 908 finished with value: 14.250165897752098 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011780329166338587, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36300864091526813, 'dropout_rate_Layer_2': 0.24318479237109114, 'dropout_rate_Layer_3': 0.3795277119047824, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013629108416270849, 'l1_Layer_2': 9.185423066512217e-05, 'l1_Layer_3': 0.034255447347098615, 'n_units_Layer_1': 105, 'n_units_Layer_2': 185, 'n_units_Layer_3': 105}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.25 | sMAPE for Validation Set is: 37.51% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.40 | sMAPE for Test Set is: 35.13% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:11:11,567]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:11:14,628]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:11:19,169]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:11:23,011]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:11:23,142]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:11:23,664]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.22 | sMAPE for Validation Set is: 36.56% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.40 | sMAPE for Test Set is: 35.47% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:11:27,634]\u001b[0m Trial 912 finished with value: 14.218727895159072 and parameters: {'n_hidden': 3, 'learning_rate': 0.001199446455667493, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3583651089552838, 'dropout_rate_Layer_2': 0.24039358138911113, 'dropout_rate_Layer_3': 0.3775214048599512, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014947880271682023, 'l1_Layer_2': 9.55689854428184e-05, 'l1_Layer_3': 0.030370702090988105, 'n_units_Layer_1': 110, 'n_units_Layer_2': 185, 'n_units_Layer_3': 105}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:11:33,292]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:11:34,409]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:11:48,463]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:11:55,855]\u001b[0m Trial 923 finished with value: 14.294500648969823 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011436898770286344, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3424348909392667, 'dropout_rate_Layer_2': 0.24591982558757733, 'dropout_rate_Layer_3': 0.37921436811292636, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02902291022311578, 'l1_Layer_2': 1.9518105621476705e-05, 'l1_Layer_3': 0.02032088143289855, 'n_units_Layer_1': 110, 'n_units_Layer_2': 165, 'n_units_Layer_3': 105}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.29 | sMAPE for Validation Set is: 36.53% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.43 | sMAPE for Test Set is: 34.89% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:12:04,905]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:12:09,686]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:12:14,800]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:12:24,939]\u001b[0m Trial 926 finished with value: 14.34055573667339 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010433377766905475, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1861981496446509, 'dropout_rate_Layer_2': 0.03348691966471111, 'dropout_rate_Layer_3': 0.2127240285773558, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.024954194738577583, 'l1_Layer_2': 6.294201252123753e-05, 'l1_Layer_3': 0.007736690146279243, 'n_units_Layer_1': 180, 'n_units_Layer_2': 110, 'n_units_Layer_3': 235}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.34 | sMAPE for Validation Set is: 35.33% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.49 | sMAPE for Test Set is: 35.23% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:12:29,592]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:12:34,882]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:12:46,205]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:12:55,435]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:13:01,326]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:13:07,569]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:13:13,651]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:13:17,031]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:13:21,749]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.30 | sMAPE for Validation Set is: 36.33% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.35 | sMAPE for Test Set is: 34.79% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:13:23,369]\u001b[0m Trial 925 finished with value: 14.296129648866378 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005825386617682102, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07378852914749894, 'dropout_rate_Layer_2': 0.3816855834647645, 'dropout_rate_Layer_3': 0.27574034213338605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.036698501316871426, 'l1_Layer_2': 0.0010590530457254366, 'l1_Layer_3': 0.0661695340225438, 'n_units_Layer_1': 145, 'n_units_Layer_2': 185, 'n_units_Layer_3': 265}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:13:30,639]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:13:31,826]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:13:36,554]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:13:38,637]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:13:39,464]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:13:44,668]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:13:45,663]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:13:53,118]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:13:56,592]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:14:07,468]\u001b[0m Trial 927 finished with value: 14.114592626740256 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005962310649717476, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04180837149122969, 'dropout_rate_Layer_2': 0.39904354901673506, 'dropout_rate_Layer_3': 0.2756479970124412, 'dropout_rate_Layer_4': 0.11135166535237201, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.06249410618156533, 'l1_Layer_2': 0.0011580911713719398, 'l1_Layer_3': 0.0001995332751558386, 'l1_Layer_4': 0.00012642622072839825, 'n_units_Layer_1': 145, 'n_units_Layer_2': 185, 'n_units_Layer_3': 265, 'n_units_Layer_4': 80}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.11 | sMAPE for Validation Set is: 35.77% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.28 | sMAPE for Test Set is: 34.50% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:14:12,497]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:14:18,334]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:14:20,157]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:14:40,843]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:14:46,827]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:14:53,096]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:14:55,754]\u001b[0m Trial 945 finished with value: 14.171926480241439 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006650560433756873, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04096114180570339, 'dropout_rate_Layer_2': 0.3591053719148578, 'dropout_rate_Layer_3': 0.15665987475265897, 'dropout_rate_Layer_4': 0.11367308640578709, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.07943800347337314, 'l1_Layer_2': 0.0024727917672201193, 'l1_Layer_3': 0.0001459953354439791, 'l1_Layer_4': 0.00030191113015546337, 'n_units_Layer_1': 175, 'n_units_Layer_2': 60, 'n_units_Layer_3': 260, 'n_units_Layer_4': 80}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.17 | sMAPE for Validation Set is: 33.11% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.48 | sMAPE for Test Set is: 35.47% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:15:00,601]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:15:06,986]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:15:12,198]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:15:13,135]\u001b[0m Trial 955 finished with value: 14.21160005293523 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006598737287105153, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04677464167803494, 'dropout_rate_Layer_2': 0.05085036967545056, 'dropout_rate_Layer_3': 0.1547110025337618, 'dropout_rate_Layer_4': 0.09285650756522677, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.04656246613772563, 'l1_Layer_2': 0.0012106162214621996, 'l1_Layer_3': 0.00014733356744937265, 'l1_Layer_4': 0.00010002319116983022, 'n_units_Layer_1': 175, 'n_units_Layer_2': 195, 'n_units_Layer_3': 250, 'n_units_Layer_4': 80}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.21 | sMAPE for Validation Set is: 34.20% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.41 | sMAPE for Test Set is: 35.05% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:15:19,708]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:15:25,294]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:15:26,125]\u001b[0m Trial 948 finished with value: 14.17774196404929 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006624265515026542, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04262507175981212, 'dropout_rate_Layer_2': 0.35592357318724327, 'dropout_rate_Layer_3': 0.22900537833647364, 'dropout_rate_Layer_4': 0.1308309797606805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.08458254723340515, 'l1_Layer_2': 0.004395988154463341, 'l1_Layer_3': 0.0002841454272114759, 'l1_Layer_4': 0.00027451850377068155, 'n_units_Layer_1': 175, 'n_units_Layer_2': 60, 'n_units_Layer_3': 290, 'n_units_Layer_4': 80}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.18 | sMAPE for Validation Set is: 34.65% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.45 | sMAPE for Test Set is: 34.93% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:15:47,308]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:16:03,922]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:16:07,154]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:16:11,107]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:16:17,737]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:16:21,492]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:16:37,657]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:16:42,463]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:16:50,499]\u001b[0m Trial 958 finished with value: 14.24613865902415 and parameters: {'n_hidden': 4, 'learning_rate': 0.002014332356726465, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00816903007644397, 'dropout_rate_Layer_2': 0.01414746377600265, 'dropout_rate_Layer_3': 0.15982408446239083, 'dropout_rate_Layer_4': 0.08155697457525106, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0072836677461087206, 'l1_Layer_2': 0.08457046680413598, 'l1_Layer_3': 0.035035186053850066, 'l1_Layer_4': 0.006382516251826344, 'n_units_Layer_1': 290, 'n_units_Layer_2': 185, 'n_units_Layer_3': 130, 'n_units_Layer_4': 155}. Best is trial 354 with value: 14.073945499362226.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.25 | sMAPE for Validation Set is: 35.85% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.70 | sMAPE for Test Set is: 36.17% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:16:59,448]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:17:11,405]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:17:18,533]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:17:25,462]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:17:30,334]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:17:41,668]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:17:47,617]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:17:52,167]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:18:00,119]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:18:06,920]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:18:12,307]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:18:25,858]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:18:30,077]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:18:34,560]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:18:38,245]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:18:43,709]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:18:52,696]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:18:57,555]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:18:57,929]\u001b[0m Trial 980 finished with value: 14.066628518716138 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005903334812947129, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06505799490392836, 'dropout_rate_Layer_2': 0.3621686946110327, 'dropout_rate_Layer_3': 0.2511761473860316, 'dropout_rate_Layer_4': 0.09691368540158124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.07014152815442774, 'l1_Layer_2': 0.0024820980844708516, 'l1_Layer_3': 0.00010836843036568381, 'l1_Layer_4': 0.00022176475563552963, 'n_units_Layer_1': 175, 'n_units_Layer_2': 70, 'n_units_Layer_3': 275, 'n_units_Layer_4': 300}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.07 | sMAPE for Validation Set is: 34.00% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.33 | sMAPE for Test Set is: 34.79% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:19:04,423]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:19:09,267]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:19:13,992]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:19:14,560]\u001b[0m Trial 986 finished with value: 14.168947958050495 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005760823274175278, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2072297090579617, 'dropout_rate_Layer_2': 0.2695450002231914, 'dropout_rate_Layer_3': 0.399586956945345, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015413947760308142, 'l1_Layer_2': 8.183455714081771e-05, 'l1_Layer_3': 0.009153167259703845, 'n_units_Layer_1': 115, 'n_units_Layer_2': 180, 'n_units_Layer_3': 60}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.17 | sMAPE for Validation Set is: 36.48% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.67 | sMAPE for Test Set is: 36.31% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:19:21,117]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:19:24,177]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:19:26,443]\u001b[0m Trial 969 finished with value: 14.214683607312773 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010211583323680457, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00021134684597016312, 'dropout_rate_Layer_2': 8.682834170229293e-05, 'dropout_rate_Layer_3': 0.11225488104743617, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002943517628598226, 'l1_Layer_2': 0.07373286269982549, 'l1_Layer_3': 0.026871799069076652, 'n_units_Layer_1': 290, 'n_units_Layer_2': 180, 'n_units_Layer_3': 110}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.21 | sMAPE for Validation Set is: 32.99% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.61 | sMAPE for Test Set is: 35.69% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:19:41,254]\u001b[0m Trial 996 finished with value: 14.463893879720843 and parameters: {'n_hidden': 3, 'learning_rate': 0.001725055070560862, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3999090542526281, 'dropout_rate_Layer_2': 0.27078283587896973, 'dropout_rate_Layer_3': 0.3989732141567532, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01592937970019827, 'l1_Layer_2': 0.0004216329334671952, 'l1_Layer_3': 0.030521132211447782, 'n_units_Layer_1': 110, 'n_units_Layer_2': 140, 'n_units_Layer_3': 115}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.46 | sMAPE for Validation Set is: 38.52% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.62 | sMAPE for Test Set is: 35.58% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:19:46,875]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:19:52,483]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:20:06,729]\u001b[0m Trial 1001 finished with value: 14.190307023725031 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005580790230605484, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2235950270275852, 'dropout_rate_Layer_2': 0.2750358988837238, 'dropout_rate_Layer_3': 0.39904590918323657, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01897968657924354, 'l1_Layer_2': 2.5111662567930815e-05, 'l1_Layer_3': 0.019740980355694868, 'n_units_Layer_1': 120, 'n_units_Layer_2': 160, 'n_units_Layer_3': 65}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.19 | sMAPE for Validation Set is: 35.65% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.34 | sMAPE for Test Set is: 34.31% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:20:26,477]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:20:34,638]\u001b[0m Trial 999 finished with value: 14.225635661168695 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007984335572482601, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06844326322925687, 'dropout_rate_Layer_2': 0.34982127961185633, 'dropout_rate_Layer_3': 0.24184904565272933, 'dropout_rate_Layer_4': 0.09921502489033628, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0719388451098903, 'l1_Layer_2': 0.0032569324422588347, 'l1_Layer_3': 0.00017476936832344468, 'l1_Layer_4': 0.0002464571780285917, 'n_units_Layer_1': 175, 'n_units_Layer_2': 80, 'n_units_Layer_3': 270, 'n_units_Layer_4': 295}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.23 | sMAPE for Validation Set is: 34.69% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.52 | sMAPE for Test Set is: 35.57% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:21:22,539]\u001b[0m Trial 1004 finished with value: 14.140059861283284 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007631461267956991, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20277453596753534, 'dropout_rate_Layer_2': 0.02772635136792123, 'dropout_rate_Layer_3': 0.2178600030370027, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.014575966987330971, 'l1_Layer_2': 4.514930043511534e-05, 'l1_Layer_3': 0.0006582522683991036, 'n_units_Layer_1': 185, 'n_units_Layer_2': 100, 'n_units_Layer_3': 185}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.14 | sMAPE for Validation Set is: 34.62% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.38 | sMAPE for Test Set is: 35.09% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:21:28,281]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:21:33,535]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:21:37,917]\u001b[0m Trial 1006 finished with value: 14.158815599675508 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007909264724364096, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06869328710076146, 'dropout_rate_Layer_2': 0.36054044866750795, 'dropout_rate_Layer_3': 0.24193187322727377, 'dropout_rate_Layer_4': 0.09701422604931596, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.053477509195313584, 'l1_Layer_2': 0.0030587857131755447, 'l1_Layer_3': 0.00016933280011226148, 'l1_Layer_4': 0.00023632888051551866, 'n_units_Layer_1': 175, 'n_units_Layer_2': 80, 'n_units_Layer_3': 265, 'n_units_Layer_4': 145}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.16 | sMAPE for Validation Set is: 35.26% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.32 | sMAPE for Test Set is: 34.70% | rMAE for Test Set is: 0.47\n",
      "MAE for Validation Set is: 14.35 | sMAPE for Validation Set is: 35.54% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.56 | sMAPE for Test Set is: 35.67% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:21:39,973]\u001b[0m Trial 1007 finished with value: 14.34759386367971 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017675367604169016, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03605195830193964, 'dropout_rate_Layer_2': 0.3638567741360059, 'dropout_rate_Layer_3': 0.2182375703086482, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.013978830040923738, 'l1_Layer_2': 4.5420955911100935e-05, 'l1_Layer_3': 0.0029614151577533683, 'n_units_Layer_1': 80, 'n_units_Layer_2': 260, 'n_units_Layer_3': 185}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:21:47,707]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:21:57,211]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:22:24,404]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:22:30,667]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:22:34,902]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:22:39,395]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:22:43,642]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:22:48,080]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:22:52,740]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:22:55,327]\u001b[0m Trial 1010 finished with value: 14.159458277068437 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005856298623555116, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.052320835399622886, 'dropout_rate_Layer_2': 0.3603348204924352, 'dropout_rate_Layer_3': 0.2533875836572778, 'dropout_rate_Layer_4': 0.12460661722059987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0981883772046556, 'l1_Layer_2': 0.004499811489204811, 'l1_Layer_3': 0.00011414221010904092, 'l1_Layer_4': 0.00021666281641474582, 'n_units_Layer_1': 180, 'n_units_Layer_2': 70, 'n_units_Layer_3': 265, 'n_units_Layer_4': 85}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.16 | sMAPE for Validation Set is: 33.09% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.40 | sMAPE for Test Set is: 35.30% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:22:58,480]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:23:02,075]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:23:09,633]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:23:14,138]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:23:20,646]\u001b[0m Trial 1005 finished with value: 14.259371392024297 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010388858157574022, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02806871013840149, 'dropout_rate_Layer_2': 0.04826848303424271, 'dropout_rate_Layer_3': 0.12055059688132189, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0033794306969252, 'l1_Layer_2': 0.03913913798913609, 'l1_Layer_3': 0.02391882015425424, 'n_units_Layer_1': 275, 'n_units_Layer_2': 180, 'n_units_Layer_3': 110}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.26 | sMAPE for Validation Set is: 35.20% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.70 | sMAPE for Test Set is: 35.96% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:23:24,274]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:23:29,018]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:23:33,969]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:23:34,319]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:23:40,073]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:23:47,565]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:23:47,864]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:23:54,233]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:23:57,085]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:24:01,090]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:24:03,781]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:24:07,309]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:24:09,680]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:24:16,823]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:24:29,734]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:24:36,014]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:24:41,363]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:24:41,799]\u001b[0m Trial 1024 finished with value: 14.189053333699704 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005662649232101716, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.046030777216485325, 'dropout_rate_Layer_2': 0.37434887389378263, 'dropout_rate_Layer_3': 0.23625499466704264, 'dropout_rate_Layer_4': 0.12505795411570036, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.08263570689368545, 'l1_Layer_2': 0.004587916330614037, 'l1_Layer_3': 8.629385120198248e-05, 'l1_Layer_4': 0.0002379769434475509, 'n_units_Layer_1': 170, 'n_units_Layer_2': 75, 'n_units_Layer_3': 255, 'n_units_Layer_4': 145}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.19 | sMAPE for Validation Set is: 34.00% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.51 | sMAPE for Test Set is: 35.05% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:24:44,157]\u001b[0m Trial 1038 finished with value: 14.215903526192713 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005827235959462759, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2312844894772734, 'dropout_rate_Layer_2': 0.24507974832974752, 'dropout_rate_Layer_3': 0.3695910549440914, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.025128266223283825, 'l1_Layer_2': 7.652293241278543e-05, 'l1_Layer_3': 0.009650667776972384, 'n_units_Layer_1': 100, 'n_units_Layer_2': 180, 'n_units_Layer_3': 60}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.22 | sMAPE for Validation Set is: 35.52% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.30 | sMAPE for Test Set is: 34.98% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:24:48,643]\u001b[0m Trial 1041 finished with value: 14.419520495478446 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006083017972536803, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21745966784479576, 'dropout_rate_Layer_2': 0.25352555421339856, 'dropout_rate_Layer_3': 0.37063621430094634, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.024673477388199094, 'l1_Layer_2': 1.3073241869567684e-05, 'l1_Layer_3': 0.008686969282352994, 'n_units_Layer_1': 100, 'n_units_Layer_2': 180, 'n_units_Layer_3': 60}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.42 | sMAPE for Validation Set is: 37.10% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.52 | sMAPE for Test Set is: 35.61% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:24:51,637]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:24:52,277]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:24:53,585]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:05,589]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:09,001]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:12,582]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:13,925]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:18,212]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:21,179]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:22,422]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:23,253]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:27,566]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:28,406]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:36,409]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:40,417]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:40,620]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:46,964]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:49,444]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:53,736]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:58,634]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:58,783]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:25:59,905]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:26:08,109]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:26:09,154]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:26:12,244]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:26:13,418]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:26:17,052]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:26:20,432]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:26:20,619]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:26:28,271]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:26:28,611]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:26:37,037]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:26:37,115]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:26:45,468]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:26:47,028]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:26:48,733]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:26:59,546]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:27:06,716]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:27:12,697]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:27:19,504]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:27:20,084]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:27:28,223]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:27:28,901]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:27:36,463]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:27:39,105]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:27:45,122]\u001b[0m Trial 1074 finished with value: 14.18278747693842 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005620863489487199, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04300036691628435, 'dropout_rate_Layer_2': 0.37597733724341753, 'dropout_rate_Layer_3': 0.23527778713348593, 'dropout_rate_Layer_4': 0.124390374029889, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.07723614216305724, 'l1_Layer_2': 0.004062866822308252, 'l1_Layer_3': 8.592827078604107e-05, 'l1_Layer_4': 0.00013671737743667413, 'n_units_Layer_1': 165, 'n_units_Layer_2': 80, 'n_units_Layer_3': 250, 'n_units_Layer_4': 155}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.18 | sMAPE for Validation Set is: 32.86% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.46 | sMAPE for Test Set is: 35.50% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:27:49,397]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:28:00,858]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:28:07,771]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:28:08,540]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:28:11,860]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:28:16,911]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:28:18,396]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:28:22,954]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:28:43,586]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:28:48,361]\u001b[0m Trial 1086 finished with value: 14.172361781884064 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006976476026565043, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.038048177118049725, 'dropout_rate_Layer_2': 0.37727632269047195, 'dropout_rate_Layer_3': 0.2370314430642153, 'dropout_rate_Layer_4': 0.13506535671915731, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.06827197234731182, 'l1_Layer_2': 0.006218565400104295, 'l1_Layer_3': 8.600958466197672e-05, 'l1_Layer_4': 0.00031619599036171323, 'n_units_Layer_1': 155, 'n_units_Layer_2': 65, 'n_units_Layer_3': 260, 'n_units_Layer_4': 145}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.17 | sMAPE for Validation Set is: 34.38% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.57 | sMAPE for Test Set is: 35.79% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:28:55,803]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:29:11,041]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:29:13,946]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:29:24,419]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:29:36,884]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:29:42,968]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:29:46,037]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:29:51,628]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:29:54,644]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:29:55,741]\u001b[0m Trial 1099 finished with value: 14.178883119107846 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012052967765133885, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022878294681896415, 'dropout_rate_Layer_2': 0.021916233042638882, 'dropout_rate_Layer_3': 0.12690696453006867, 'dropout_rate_Layer_4': 0.008977234734821121, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005396913199232254, 'l1_Layer_2': 0.06383479253558035, 'l1_Layer_3': 0.0215276038951672, 'l1_Layer_4': 1.027824480493631e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 120, 'n_units_Layer_3': 295, 'n_units_Layer_4': 155}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.18 | sMAPE for Validation Set is: 34.95% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.48 | sMAPE for Test Set is: 35.18% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:30:02,708]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:30:04,442]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:30:13,326]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:30:15,949]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:30:17,503]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:30:25,441]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:30:26,233]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:30:26,234]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:30:27,417]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:30:38,170]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:30:40,609]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:30:41,369]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:30:47,995]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:30:55,637]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:31:02,161]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:31:05,992]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:31:10,802]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:31:11,340]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:31:12,524]\u001b[0m Trial 1123 finished with value: 14.339896951066939 and parameters: {'n_hidden': 3, 'learning_rate': 0.001201424672947853, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23885268744117674, 'dropout_rate_Layer_2': 0.24129428799508462, 'dropout_rate_Layer_3': 0.38565284332359234, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03006598514085305, 'l1_Layer_2': 6.922209330228466e-05, 'l1_Layer_3': 0.01947185258749879, 'n_units_Layer_1': 105, 'n_units_Layer_2': 160, 'n_units_Layer_3': 75}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.34 | sMAPE for Validation Set is: 37.43% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.48 | sMAPE for Test Set is: 35.16% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:31:19,720]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:31:25,778]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:31:31,850]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:31:40,175]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:31:43,373]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:31:45,412]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:31:53,879]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:31:59,043]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:32:03,927]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:32:06,304]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:32:11,507]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:32:15,629]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:32:20,221]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:32:26,617]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:32:31,983]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:32:41,895]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:32:47,159]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:32:54,251]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:33:02,171]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:33:06,910]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:33:13,658]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:33:19,264]\u001b[0m Trial 1128 finished with value: 14.227387018810882 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005840092588389006, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17501987609356146, 'dropout_rate_Layer_2': 0.010876065712975311, 'dropout_rate_Layer_3': 0.055568087099923, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004802471442186071, 'l1_Layer_2': 0.010400272527985638, 'l1_Layer_3': 0.0002336919296698127, 'n_units_Layer_1': 190, 'n_units_Layer_2': 95, 'n_units_Layer_3': 250}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.23 | sMAPE for Validation Set is: 33.94% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.62 | sMAPE for Test Set is: 35.92% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:33:19,598]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:33:29,171]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:33:34,141]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:33:37,821]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:33:41,099]\u001b[0m Trial 1132 finished with value: 14.188620615093734 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006466681368179098, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07706131390787936, 'dropout_rate_Layer_2': 0.388795007825393, 'dropout_rate_Layer_3': 0.24483065747046745, 'dropout_rate_Layer_4': 0.13879698724287803, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0647993336792267, 'l1_Layer_2': 0.005357155552687669, 'l1_Layer_3': 6.560632746492457e-05, 'l1_Layer_4': 0.0003538079781018666, 'n_units_Layer_1': 165, 'n_units_Layer_2': 65, 'n_units_Layer_3': 275, 'n_units_Layer_4': 150}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.19 | sMAPE for Validation Set is: 34.76% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.37 | sMAPE for Test Set is: 34.67% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:33:43,286]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:33:52,796]\u001b[0m Trial 1141 finished with value: 14.241272393760289 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006256113393835688, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08003753736872829, 'dropout_rate_Layer_2': 0.39255973942687317, 'dropout_rate_Layer_3': 0.24306907353077462, 'dropout_rate_Layer_4': 0.13835429932585705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.061878810679511995, 'l1_Layer_2': 0.006793589713097263, 'l1_Layer_3': 7.213256313810179e-05, 'l1_Layer_4': 0.000490269157365559, 'n_units_Layer_1': 165, 'n_units_Layer_2': 65, 'n_units_Layer_3': 275, 'n_units_Layer_4': 150}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.24 | sMAPE for Validation Set is: 34.43% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.63 | sMAPE for Test Set is: 35.87% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:33:59,431]\u001b[0m Trial 1160 finished with value: 14.912103514802302 and parameters: {'n_hidden': 3, 'learning_rate': 0.011119120346221274, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15773388009792025, 'dropout_rate_Layer_2': 0.26670978710741944, 'dropout_rate_Layer_3': 0.3554341747964372, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03146425287958504, 'l1_Layer_2': 0.048632750158097475, 'l1_Layer_3': 0.0052135456412740686, 'n_units_Layer_1': 130, 'n_units_Layer_2': 170, 'n_units_Layer_3': 55}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.91 | sMAPE for Validation Set is: 40.38% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.27 | sMAPE for Test Set is: 37.64% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:34:03,564]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:34:04,003]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:34:10,424]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:34:10,747]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:34:16,869]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:34:18,304]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:34:18,923]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:34:26,776]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:34:27,077]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:34:29,758]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:34:40,337]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:34:42,794]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:34:45,633]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:34:49,736]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:34:52,084]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:34:52,854]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:34:55,321]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:34:57,357]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:35:03,916]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:35:04,161]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:35:05,163]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:35:10,035]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:35:12,906]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:35:16,267]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:35:21,903]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:35:22,056]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:35:22,483]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:35:29,463]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:35:31,878]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:35:38,619]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:35:44,011]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:35:46,052]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:35:50,123]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:35:56,824]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:35:57,000]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:36:04,036]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:36:06,870]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:36:09,557]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:36:13,376]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:36:17,822]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:36:18,673]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:36:24,812]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:36:29,194]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:36:33,940]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:36:38,226]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:36:45,528]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:36:47,905]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:36:51,637]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:36:54,631]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:36:58,787]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:37:03,770]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:37:09,894]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:37:16,252]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:37:24,676]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:37:44,430]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:37:51,755]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:38:00,613]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:38:08,455]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:38:12,334]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:38:15,276]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:38:18,541]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:38:19,392]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:38:24,514]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:38:29,214]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:38:34,321]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:38:39,312]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:38:39,994]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:38:45,321]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:38:51,343]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:38:54,715]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:38:59,994]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:39:03,473]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:39:07,538]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:39:09,712]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:39:16,835]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:39:23,308]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:39:57,737]\u001b[0m Trial 1218 finished with value: 14.262464332255902 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006510214375523357, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06462111745152223, 'dropout_rate_Layer_2': 0.35375103725279494, 'dropout_rate_Layer_3': 0.2388902905810806, 'dropout_rate_Layer_4': 0.1205171975440679, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.06895380792896806, 'l1_Layer_2': 0.004192464813638532, 'l1_Layer_3': 9.953451718810014e-05, 'l1_Layer_4': 0.0003491854841351842, 'n_units_Layer_1': 150, 'n_units_Layer_2': 60, 'n_units_Layer_3': 280, 'n_units_Layer_4': 85}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.26 | sMAPE for Validation Set is: 34.78% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.41 | sMAPE for Test Set is: 34.95% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:40:02,888]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:40:06,864]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:40:13,695]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:40:14,793]\u001b[0m Trial 1224 finished with value: 14.182278888328227 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006399379888249528, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07361145967552081, 'dropout_rate_Layer_2': 0.3830856260056871, 'dropout_rate_Layer_3': 0.23867906980522152, 'dropout_rate_Layer_4': 0.17948535106839078, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.09563286182976427, 'l1_Layer_2': 0.006312888976867784, 'l1_Layer_3': 9.681792470161429e-05, 'l1_Layer_4': 0.00033775823272655446, 'n_units_Layer_1': 160, 'n_units_Layer_2': 65, 'n_units_Layer_3': 275, 'n_units_Layer_4': 85}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.18 | sMAPE for Validation Set is: 33.63% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.38 | sMAPE for Test Set is: 35.00% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:40:19,772]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:40:25,232]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:40:25,490]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:40:38,400]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:40:43,713]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:40:47,789]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:40:53,239]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:40:57,585]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:40:57,893]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:41:06,759]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:41:06,951]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:41:10,848]\u001b[0m Trial 1235 finished with value: 14.17918716025641 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006623011084221196, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07344385332786521, 'dropout_rate_Layer_2': 0.3847480573894589, 'dropout_rate_Layer_3': 0.16796899412030425, 'dropout_rate_Layer_4': 0.11976821412161381, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.06995996823630744, 'l1_Layer_2': 0.004118962765515964, 'l1_Layer_3': 9.645363515607684e-05, 'l1_Layer_4': 0.0003493513152933379, 'n_units_Layer_1': 155, 'n_units_Layer_2': 60, 'n_units_Layer_3': 280, 'n_units_Layer_4': 145}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.18 | sMAPE for Validation Set is: 35.90% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.37 | sMAPE for Test Set is: 34.91% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:41:13,639]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:41:17,008]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:41:20,627]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:41:23,542]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:41:27,051]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:41:30,227]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:41:30,573]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:41:31,111]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:41:31,291]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:41:41,764]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:41:42,371]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:41:42,417]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:41:50,716]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:41:54,709]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:41:55,417]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:42:01,897]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:42:04,848]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:42:07,306]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:42:12,161]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:42:12,162]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:42:12,345]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:42:22,463]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:42:23,063]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:42:32,003]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:42:32,427]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:42:43,476]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:42:51,003]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:42:55,618]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:42:59,304]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:43:02,458]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:43:06,370]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:43:21,695]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:43:45,522]\u001b[0m Trial 1287 finished with value: 14.287907826134614 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020558411624092944, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36065984845230814, 'dropout_rate_Layer_2': 0.215324539016728, 'dropout_rate_Layer_3': 0.3850469439215574, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014592184379887126, 'l1_Layer_2': 0.00014691431552032723, 'l1_Layer_3': 0.025521367253225166, 'n_units_Layer_1': 115, 'n_units_Layer_2': 200, 'n_units_Layer_3': 125}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.29 | sMAPE for Validation Set is: 37.42% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.38 | sMAPE for Test Set is: 34.46% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:43:58,687]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:44:04,393]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:44:09,755]\u001b[0m Trial 1286 finished with value: 14.113504928677886 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007185352415106728, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06329493302136276, 'dropout_rate_Layer_2': 0.3744788854476773, 'dropout_rate_Layer_3': 0.1984626354816007, 'dropout_rate_Layer_4': 0.10163671645115017, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.04424799256621881, 'l1_Layer_2': 0.0036279227977617733, 'l1_Layer_3': 8.717613425760756e-05, 'l1_Layer_4': 0.00020483981445152617, 'n_units_Layer_1': 150, 'n_units_Layer_2': 55, 'n_units_Layer_3': 285, 'n_units_Layer_4': 80}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.11 | sMAPE for Validation Set is: 32.66% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.47 | sMAPE for Test Set is: 35.70% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:44:10,315]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:44:20,026]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:44:24,410]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:44:29,605]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:44:29,697]\u001b[0m Trial 1283 finished with value: 14.197754411628017 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005009003402289575, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17021429259969847, 'dropout_rate_Layer_2': 0.018561334633108953, 'dropout_rate_Layer_3': 0.21940928602086246, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02053456604845599, 'l1_Layer_2': 0.00023003535656952612, 'l1_Layer_3': 0.0009353767657061074, 'n_units_Layer_1': 190, 'n_units_Layer_2': 235, 'n_units_Layer_3': 240}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.20 | sMAPE for Validation Set is: 33.86% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.55 | sMAPE for Test Set is: 36.10% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:44:34,542]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.56 | sMAPE for Validation Set is: 37.88% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.92 | sMAPE for Test Set is: 36.84% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:44:37,791]\u001b[0m Trial 1292 finished with value: 14.55526277036418 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020867624582201435, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36872832098081176, 'dropout_rate_Layer_2': 0.21338085005532537, 'dropout_rate_Layer_3': 0.3891380271747233, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.035299166401465916, 'l1_Layer_2': 0.00014422300235997592, 'l1_Layer_3': 0.026030170926306273, 'n_units_Layer_1': 130, 'n_units_Layer_2': 200, 'n_units_Layer_3': 135}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:44:43,832]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:44:50,940]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:45:01,163]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:45:09,115]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:45:11,745]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:45:15,715]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:45:19,096]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:45:23,693]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:45:30,164]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:45:35,838]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:45:40,667]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:45:47,170]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:45:53,550]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:45:57,893]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:45:58,304]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:46:04,189]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:46:05,052]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:46:10,974]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:46:15,441]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:46:15,687]\u001b[0m Trial 1305 finished with value: 14.28544505183701 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008443147199034327, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3578877119883969, 'dropout_rate_Layer_2': 0.21829035960705678, 'dropout_rate_Layer_3': 0.3582958472554325, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009979801907370385, 'l1_Layer_2': 0.00017465222750989666, 'l1_Layer_3': 0.015467387817628315, 'n_units_Layer_1': 115, 'n_units_Layer_2': 175, 'n_units_Layer_3': 125}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.29 | sMAPE for Validation Set is: 38.14% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.37 | sMAPE for Test Set is: 34.75% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:46:18,634]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:46:24,747]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:46:28,360]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:46:30,831]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:46:36,826]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:46:43,006]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:46:43,469]\u001b[0m Trial 1300 finished with value: 14.172226475548257 and parameters: {'n_hidden': 4, 'learning_rate': 0.000700152237874843, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04665438372260029, 'dropout_rate_Layer_2': 0.354718633260088, 'dropout_rate_Layer_3': 0.1809791805707928, 'dropout_rate_Layer_4': 0.09921097568931737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.04553747632218823, 'l1_Layer_2': 0.005066155253016197, 'l1_Layer_3': 7.983425458110509e-05, 'l1_Layer_4': 0.00018953604981634142, 'n_units_Layer_1': 150, 'n_units_Layer_2': 60, 'n_units_Layer_3': 290, 'n_units_Layer_4': 80}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.17 | sMAPE for Validation Set is: 33.80% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.50 | sMAPE for Test Set is: 35.65% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:46:48,796]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:46:51,657]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:46:51,851]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:46:52,387]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:47:00,940]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:47:01,817]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:47:03,180]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:47:09,363]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:47:12,766]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:47:16,770]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:47:19,716]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:47:20,567]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:47:23,029]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:47:28,962]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:47:29,249]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:47:34,472]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:47:38,899]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:47:44,431]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:47:47,338]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:47:51,438]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:47:52,260]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:48:00,667]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:48:06,772]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:48:22,789]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:48:29,420]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:48:36,996]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:48:43,274]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:48:49,127]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:48:56,339]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:48:58,883]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:49:02,496]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:49:05,507]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:49:08,762]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:49:16,815]\u001b[0m Trial 1347 finished with value: 14.212370142545447 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008520764037184346, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03439347070676081, 'dropout_rate_Layer_2': 0.35178981732912573, 'dropout_rate_Layer_3': 0.1831638574878969, 'dropout_rate_Layer_4': 0.09319330419501758, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.06679872324649491, 'l1_Layer_2': 0.003575646001942879, 'l1_Layer_3': 6.147365907431003e-05, 'l1_Layer_4': 0.0001490542050993019, 'n_units_Layer_1': 145, 'n_units_Layer_2': 55, 'n_units_Layer_3': 290, 'n_units_Layer_4': 70}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.21 | sMAPE for Validation Set is: 34.07% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.30 | sMAPE for Test Set is: 34.79% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:49:20,198]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:49:20,901]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:49:22,895]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:49:30,154]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:49:30,341]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:49:32,340]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:49:34,239]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:49:40,491]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:49:40,923]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:49:43,892]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:49:50,544]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:49:52,468]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:49:58,480]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:49:59,035]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:50:06,338]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:50:09,931]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:50:14,774]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:50:15,388]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:50:23,640]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:50:24,333]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:50:26,780]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:50:32,376]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:50:37,261]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:50:37,510]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:50:40,320]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:50:49,878]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:50:50,343]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:50:50,637]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:50:59,906]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:51:02,418]\u001b[0m Trial 1365 finished with value: 14.098676514578377 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007523897316528101, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08267395670947703, 'dropout_rate_Layer_2': 0.017706170963693396, 'dropout_rate_Layer_3': 0.14636423171217616, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.020970901362291555, 'l1_Layer_2': 9.769105449927002e-05, 'l1_Layer_3': 0.0005961722587423437, 'n_units_Layer_1': 230, 'n_units_Layer_2': 245, 'n_units_Layer_3': 215}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.10 | sMAPE for Validation Set is: 33.84% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.37 | sMAPE for Test Set is: 35.20% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:51:04,074]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:51:09,720]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:51:14,546]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:51:16,746]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:51:21,194]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:51:28,782]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:51:31,441]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:51:37,582]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:51:40,553]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:51:42,538]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:51:47,929]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:52:14,083]\u001b[0m Trial 1400 finished with value: 14.408923925099204 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008779522337492354, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37641684414077253, 'dropout_rate_Layer_2': 0.2327816550411374, 'dropout_rate_Layer_3': 0.3755307413530117, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0733184018021422, 'l1_Layer_2': 3.233358342409112e-05, 'l1_Layer_3': 0.019787876660218338, 'n_units_Layer_1': 115, 'n_units_Layer_2': 175, 'n_units_Layer_3': 115}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.41 | sMAPE for Validation Set is: 36.58% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.37 | sMAPE for Test Set is: 35.00% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:52:19,634]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:52:33,089]\u001b[0m Trial 1392 finished with value: 14.17979388442175 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005536336089575801, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31932246519378527, 'dropout_rate_Layer_2': 0.3628327681050954, 'dropout_rate_Layer_3': 0.14359390459530305, 'dropout_rate_Layer_4': 0.11747167596544465, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.03829212222724778, 'l1_Layer_2': 0.0055546543263536065, 'l1_Layer_3': 0.000199921803103637, 'l1_Layer_4': 0.00023754173813036325, 'n_units_Layer_1': 165, 'n_units_Layer_2': 65, 'n_units_Layer_3': 265, 'n_units_Layer_4': 90}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.18 | sMAPE for Validation Set is: 34.49% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.41 | sMAPE for Test Set is: 35.13% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:52:39,926]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:52:42,700]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:52:43,004]\u001b[0m Trial 1389 finished with value: 14.16174322333527 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005497649072589938, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.060097355313879344, 'dropout_rate_Layer_2': 0.37852474447212575, 'dropout_rate_Layer_3': 0.1423680919389605, 'dropout_rate_Layer_4': 0.11552595194787198, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.03543726026809616, 'l1_Layer_2': 0.005429294670922824, 'l1_Layer_3': 0.0001933241467157211, 'l1_Layer_4': 0.0017542750493892139, 'n_units_Layer_1': 165, 'n_units_Layer_2': 65, 'n_units_Layer_3': 265, 'n_units_Layer_4': 90}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.16 | sMAPE for Validation Set is: 35.17% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.44 | sMAPE for Test Set is: 35.34% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:52:48,591]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:52:52,914]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:52:54,308]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:52:58,014]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:52:59,523]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:53:01,884]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:53:14,696]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:53:19,393]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:53:28,490]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:53:35,425]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:53:40,805]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:53:49,279]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:53:58,992]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:54:03,992]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:54:11,482]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:54:18,255]\u001b[0m Trial 1398 finished with value: 14.217984325220911 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005458306922783397, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06128641652131073, 'dropout_rate_Layer_2': 0.34185918280248184, 'dropout_rate_Layer_3': 0.216258602263726, 'dropout_rate_Layer_4': 0.1154287224554176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.03604864109768711, 'l1_Layer_2': 0.005482660562658874, 'l1_Layer_3': 0.0001998989742180131, 'l1_Layer_4': 0.0017294177331246233, 'n_units_Layer_1': 165, 'n_units_Layer_2': 65, 'n_units_Layer_3': 265, 'n_units_Layer_4': 90}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.22 | sMAPE for Validation Set is: 35.96% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.39 | sMAPE for Test Set is: 35.16% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:54:40,174]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:54:46,357]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:54:48,746]\u001b[0m Trial 1412 finished with value: 14.164737151802365 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007011984673643398, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3142123843101942, 'dropout_rate_Layer_2': 0.3432085703339147, 'dropout_rate_Layer_3': 0.1436718598075278, 'dropout_rate_Layer_4': 0.10570259902301347, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.036908113388403885, 'l1_Layer_2': 0.007903995032010119, 'l1_Layer_3': 0.00018929953791619485, 'l1_Layer_4': 0.001994162646793861, 'n_units_Layer_1': 160, 'n_units_Layer_2': 65, 'n_units_Layer_3': 280, 'n_units_Layer_4': 105}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.16 | sMAPE for Validation Set is: 35.88% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.33 | sMAPE for Test Set is: 34.63% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:54:53,980]\u001b[0m Trial 1414 finished with value: 14.206000729439646 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007169948993462895, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25166414726500524, 'dropout_rate_Layer_2': 0.3622264653145107, 'dropout_rate_Layer_3': 0.140839075569857, 'dropout_rate_Layer_4': 0.11286924127217322, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.037003306969135195, 'l1_Layer_2': 0.007351405952568205, 'l1_Layer_3': 0.0001941092430628252, 'l1_Layer_4': 0.0019363992064812161, 'n_units_Layer_1': 160, 'n_units_Layer_2': 65, 'n_units_Layer_3': 280, 'n_units_Layer_4': 90}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.21 | sMAPE for Validation Set is: 35.85% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.24 | sMAPE for Test Set is: 34.39% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:55:00,472]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:55:01,406]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:55:08,737]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:55:12,707]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:55:18,397]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:55:20,713]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:55:23,202]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.23 | sMAPE for Validation Set is: 34.26% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.53 | sMAPE for Test Set is: 35.72% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:55:28,388]\u001b[0m Trial 1422 finished with value: 14.225619177675668 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007324614838753962, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0705852401023249, 'dropout_rate_Layer_2': 0.35777596071210394, 'dropout_rate_Layer_3': 0.1366404322864208, 'dropout_rate_Layer_4': 0.10481968970402188, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.02585531508127251, 'l1_Layer_2': 0.007672170084156266, 'l1_Layer_3': 0.00015794752321531553, 'l1_Layer_4': 2.8200207820392657e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 70, 'n_units_Layer_3': 265, 'n_units_Layer_4': 105}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:55:30,100]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:55:34,487]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:55:35,016]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:55:35,900]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:55:43,493]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:55:46,969]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:55:52,737]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:55:57,533]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:55:59,494]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:56:02,836]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:56:05,961]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:56:07,180]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:56:13,525]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:56:14,507]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:56:18,274]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:56:22,262]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:56:25,581]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:56:27,409]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:56:28,247]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:57:12,770]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:57:15,522]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:57:17,192]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:57:24,879]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:57:27,119]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:57:37,677]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:57:40,271]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:57:48,018]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:57:52,627]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:58:12,092]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:58:17,247]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:58:17,854]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:58:25,205]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:58:31,568]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:58:37,317]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:58:42,994]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:58:48,601]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:58:51,433]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:58:56,099]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:58:57,556]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:58:59,185]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:59:07,155]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:59:07,997]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:59:08,022]\u001b[0m Trial 1459 finished with value: 14.216586225340263 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009536781176227915, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08064987508827713, 'dropout_rate_Layer_2': 0.02250703154717787, 'dropout_rate_Layer_3': 0.14490169975869696, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.022513497664028298, 'l1_Layer_2': 0.00035196729222483966, 'l1_Layer_3': 0.00021590186390012527, 'n_units_Layer_1': 200, 'n_units_Layer_2': 95, 'n_units_Layer_3': 225}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.22 | sMAPE for Validation Set is: 33.44% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.42 | sMAPE for Test Set is: 34.77% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-08 18:59:21,960]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:59:22,663]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:59:27,681]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:59:28,414]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:59:35,546]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:59:38,605]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:59:44,687]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:59:46,616]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:59:54,065]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 18:59:54,397]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 19:00:02,117]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 19:00:04,380]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 19:00:08,055]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 19:00:12,264]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 19:00:12,386]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 19:00:20,924]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 19:00:42,815]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 19:00:46,877]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 19:00:48,747]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 19:00:53,088]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 19:00:54,945]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 19:00:55,083]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 19:01:03,423]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 19:01:04,369]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 19:01:12,255]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-08 19:01:13,206]\u001b[0m Trial 1491 finished with value: 14.282783643069992 and parameters: {'n_hidden': 4, 'learning_rate': 0.000598882235919431, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.042219945115045225, 'dropout_rate_Layer_2': 0.3676678194798266, 'dropout_rate_Layer_3': 0.1987014892861995, 'dropout_rate_Layer_4': 0.12567192083568718, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.07792485701253936, 'l1_Layer_2': 0.003972983249718445, 'l1_Layer_3': 8.886494056888933e-05, 'l1_Layer_4': 0.0001367887215778093, 'n_units_Layer_1': 170, 'n_units_Layer_2': 80, 'n_units_Layer_3': 250, 'n_units_Layer_4': 85}. Best is trial 980 with value: 14.066628518716138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.28 | sMAPE for Validation Set is: 33.81% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.39 | sMAPE for Test Set is: 34.84% | rMAE for Test Set is: 0.47\n",
      "for 2023-01-01, MAE is:25.81 & sMAPE is:60.63% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :25.81 & 60.63% & 1.12\n",
      "for 2023-01-02, MAE is:71.48 & sMAPE is:79.38% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :48.65 & 70.01% & 0.98\n",
      "for 2023-01-03, MAE is:16.79 & sMAPE is:15.54% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :38.03 & 51.85% & 0.78\n",
      "for 2023-01-04, MAE is:25.74 & sMAPE is:31.74% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :34.96 & 46.82% & 0.99\n",
      "for 2023-01-05, MAE is:26.48 & sMAPE is:43.25% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :33.26 & 46.11% & 0.92\n",
      "for 2023-01-06, MAE is:5.78 & sMAPE is:7.73% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :28.68 & 39.71% & 0.79\n",
      "for 2023-01-07, MAE is:7.54 & sMAPE is:11.60% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :25.66 & 35.70% & 0.70\n",
      "for 2023-01-08, MAE is:17.68 & sMAPE is:45.23% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :24.66 & 36.89% & 0.80\n",
      "for 2023-01-09, MAE is:25.01 & sMAPE is:38.35% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :24.70 & 37.05% & 0.77\n",
      "for 2023-01-10, MAE is:19.15 & sMAPE is:20.58% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :24.15 & 35.40% & 0.83\n",
      "for 2023-01-11, MAE is:20.66 & sMAPE is:36.10% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :23.83 & 35.47% & 0.86\n",
      "for 2023-01-12, MAE is:17.96 & sMAPE is:35.54% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :23.34 & 35.47% & 0.92\n",
      "for 2023-01-13, MAE is:15.98 & sMAPE is:20.50% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :22.77 & 34.32% & 1.02\n",
      "for 2023-01-14, MAE is:10.18 & sMAPE is:15.48% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :21.88 & 32.98% & 1.09\n",
      "for 2023-01-15, MAE is:24.13 & sMAPE is:49.71% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :22.03 & 34.09% & 1.14\n",
      "for 2023-01-16, MAE is:12.29 & sMAPE is:15.77% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :21.42 & 32.95% & 1.16\n",
      "for 2023-01-17, MAE is:9.69 & sMAPE is:16.81% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :20.73 & 32.00% & 1.11\n",
      "for 2023-01-18, MAE is:23.79 & sMAPE is:35.58% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :20.90 & 32.20% & 1.13\n",
      "for 2023-01-19, MAE is:52.34 & sMAPE is:48.69% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :22.55 & 33.06% & 1.11\n",
      "for 2023-01-20, MAE is:27.38 & sMAPE is:27.89% & rMAE is:2.62 ||| daily mean of MAE & sMAPE & rMAE till now are :22.79 & 32.81% & 1.18\n",
      "for 2023-01-21, MAE is:5.60 & sMAPE is:7.55% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :21.97 & 31.60% & 1.16\n",
      "for 2023-01-22, MAE is:8.36 & sMAPE is:13.42% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :21.36 & 30.78% & 1.12\n",
      "for 2023-01-23, MAE is:3.84 & sMAPE is:7.22% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :20.59 & 29.75% & 1.07\n",
      "for 2023-01-24, MAE is:10.98 & sMAPE is:29.32% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :20.19 & 29.73% & 1.05\n",
      "for 2023-01-25, MAE is:5.84 & sMAPE is:31.61% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :19.62 & 29.81% & 1.01\n",
      "for 2023-01-26, MAE is:10.28 & sMAPE is:27.35% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :19.26 & 29.71% & 0.98\n",
      "for 2023-01-27, MAE is:6.36 & sMAPE is:15.07% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :18.78 & 29.17% & 0.95\n",
      "for 2023-01-28, MAE is:4.31 & sMAPE is:13.04% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :18.27 & 28.60% & 0.92\n",
      "for 2023-01-29, MAE is:5.04 & sMAPE is:15.86% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :17.81 & 28.16% & 0.89\n",
      "for 2023-01-30, MAE is:1.62 & sMAPE is:6.40% & rMAE is:0.06 ||| daily mean of MAE & sMAPE & rMAE till now are :17.27 & 27.43% & 0.86\n",
      "for 2023-01-31, MAE is:40.88 & sMAPE is:76.93% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :18.03 & 29.03% & 0.88\n",
      "for 2023-02-01, MAE is:26.24 & sMAPE is:31.78% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :18.29 & 29.11% & 0.86\n",
      "for 2023-02-02, MAE is:15.14 & sMAPE is:16.20% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :18.19 & 28.72% & 0.85\n",
      "for 2023-02-03, MAE is:17.10 & sMAPE is:22.52% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :18.16 & 28.54% & 0.84\n",
      "for 2023-02-04, MAE is:26.70 & sMAPE is:38.96% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :18.40 & 28.84% & 0.84\n",
      "for 2023-02-05, MAE is:11.14 & sMAPE is:27.81% & rMAE is:2.64 ||| daily mean of MAE & sMAPE & rMAE till now are :18.20 & 28.81% & 0.89\n",
      "for 2023-02-06, MAE is:2.92 & sMAPE is:7.99% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :17.79 & 28.25% & 0.88\n",
      "for 2023-02-07, MAE is:2.00 & sMAPE is:5.43% & rMAE is:0.06 ||| daily mean of MAE & sMAPE & rMAE till now are :17.37 & 27.65% & 0.85\n",
      "for 2023-02-08, MAE is:8.57 & sMAPE is:27.02% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :17.15 & 27.63% & 0.84\n",
      "for 2023-02-09, MAE is:3.96 & sMAPE is:22.23% & rMAE is:0.05 ||| daily mean of MAE & sMAPE & rMAE till now are :16.82 & 27.50% & 0.82\n",
      "for 2023-02-10, MAE is:3.08 & sMAPE is:12.25% & rMAE is:0.06 ||| daily mean of MAE & sMAPE & rMAE till now are :16.48 & 27.12% & 0.80\n",
      "for 2023-02-11, MAE is:5.31 & sMAPE is:15.99% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :16.22 & 26.86% & 0.79\n",
      "for 2023-02-12, MAE is:3.68 & sMAPE is:14.97% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :15.93 & 26.58% & 0.77\n",
      "for 2023-02-13, MAE is:3.82 & sMAPE is:16.84% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :15.65 & 26.36% & 0.76\n",
      "for 2023-02-14, MAE is:13.82 & sMAPE is:33.79% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :15.61 & 26.53% & 0.78\n",
      "for 2023-02-15, MAE is:15.96 & sMAPE is:26.88% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :15.62 & 26.53% & 0.77\n",
      "for 2023-02-16, MAE is:2.40 & sMAPE is:6.79% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :15.34 & 26.11% & 0.76\n",
      "for 2023-02-17, MAE is:6.01 & sMAPE is:15.53% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :15.14 & 25.89% & 0.75\n",
      "for 2023-02-18, MAE is:2.30 & sMAPE is:8.22% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :14.88 & 25.53% & 0.74\n",
      "for 2023-02-19, MAE is:10.43 & sMAPE is:27.58% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :14.79 & 25.57% & 0.74\n",
      "for 2023-02-20, MAE is:8.30 & sMAPE is:18.25% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :14.66 & 25.43% & 0.73\n",
      "for 2023-02-21, MAE is:46.15 & sMAPE is:55.89% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :15.27 & 26.01% & 0.74\n",
      "for 2023-02-22, MAE is:24.36 & sMAPE is:47.60% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :15.44 & 26.42% & 0.75\n",
      "for 2023-02-23, MAE is:8.20 & sMAPE is:22.90% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :15.31 & 26.36% & 0.77\n",
      "for 2023-02-24, MAE is:12.65 & sMAPE is:25.25% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :15.26 & 26.34% & 0.78\n",
      "for 2023-02-25, MAE is:5.75 & sMAPE is:17.82% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :15.09 & 26.18% & 0.79\n",
      "for 2023-02-26, MAE is:4.99 & sMAPE is:12.61% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :14.91 & 25.95% & 0.78\n",
      "for 2023-02-27, MAE is:3.00 & sMAPE is:10.15% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :14.71 & 25.67% & 0.77\n",
      "for 2023-02-28, MAE is:10.42 & sMAPE is:31.64% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :14.63 & 25.78% & 0.76\n",
      "for 2023-03-01, MAE is:5.23 & sMAPE is:17.39% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :14.48 & 25.64% & 0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-03-02, MAE is:2.31 & sMAPE is:12.13% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :14.28 & 25.41% & 0.75\n",
      "for 2023-03-03, MAE is:1.89 & sMAPE is:7.52% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :14.08 & 25.13% & 0.73\n",
      "for 2023-03-04, MAE is:7.44 & sMAPE is:28.70% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :13.97 & 25.18% & 0.75\n",
      "for 2023-03-05, MAE is:10.59 & sMAPE is:25.51% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :13.92 & 25.19% & 0.76\n",
      "for 2023-03-06, MAE is:72.27 & sMAPE is:79.30% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :14.82 & 26.02% & 0.76\n",
      "for 2023-03-07, MAE is:14.23 & sMAPE is:15.29% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :14.81 & 25.86% & 0.75\n",
      "for 2023-03-08, MAE is:6.45 & sMAPE is:9.38% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :14.68 & 25.61% & 0.74\n",
      "for 2023-03-09, MAE is:8.01 & sMAPE is:12.17% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :14.59 & 25.41% & 0.73\n",
      "for 2023-03-10, MAE is:4.91 & sMAPE is:7.61% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :14.45 & 25.16% & 0.72\n",
      "for 2023-03-11, MAE is:19.38 & sMAPE is:28.73% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :14.52 & 25.21% & 0.72\n",
      "for 2023-03-12, MAE is:7.89 & sMAPE is:13.71% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :14.42 & 25.04% & 0.72\n",
      "for 2023-03-13, MAE is:25.67 & sMAPE is:35.25% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :14.58 & 25.19% & 0.71\n",
      "for 2023-03-14, MAE is:18.66 & sMAPE is:30.14% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :14.63 & 25.25% & 0.71\n",
      "for 2023-03-15, MAE is:8.80 & sMAPE is:16.56% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :14.56 & 25.14% & 0.71\n",
      "for 2023-03-16, MAE is:14.09 & sMAPE is:25.89% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :14.55 & 25.15% & 0.72\n",
      "for 2023-03-17, MAE is:13.12 & sMAPE is:34.37% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :14.53 & 25.27% & 0.71\n",
      "for 2023-03-18, MAE is:10.34 & sMAPE is:31.76% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :14.48 & 25.35% & 0.71\n",
      "for 2023-03-19, MAE is:7.96 & sMAPE is:18.92% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :14.39 & 25.27% & 0.71\n",
      "for 2023-03-20, MAE is:14.19 & sMAPE is:34.66% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :14.39 & 25.39% & 0.70\n",
      "for 2023-03-21, MAE is:15.20 & sMAPE is:30.97% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :14.40 & 25.46% & 0.71\n",
      "for 2023-03-22, MAE is:6.76 & sMAPE is:13.63% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :14.31 & 25.31% & 0.71\n",
      "for 2023-03-23, MAE is:3.87 & sMAPE is:8.98% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :14.18 & 25.11% & 0.70\n",
      "for 2023-03-24, MAE is:10.05 & sMAPE is:23.93% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :14.13 & 25.10% & 0.70\n",
      "for 2023-03-25, MAE is:7.32 & sMAPE is:16.10% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :14.05 & 24.99% & 0.70\n",
      "for 2023-03-26, MAE is:4.08 & sMAPE is:8.37% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :13.93 & 24.80% & 0.70\n",
      "for 2023-03-27, MAE is:26.75 & sMAPE is:40.45% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :14.08 & 24.98% & 0.70\n",
      "for 2023-03-28, MAE is:26.14 & sMAPE is:32.14% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :14.22 & 25.06% & 0.70\n",
      "for 2023-03-29, MAE is:45.78 & sMAPE is:56.74% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :14.58 & 25.42% & 0.71\n",
      "for 2023-03-30, MAE is:20.29 & sMAPE is:28.69% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :14.64 & 25.46% & 0.71\n",
      "for 2023-03-31, MAE is:18.03 & sMAPE is:27.67% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :14.68 & 25.48% & 0.71\n",
      "for 2023-04-01, MAE is:6.89 & sMAPE is:12.18% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :14.59 & 25.34% & 0.71\n",
      "for 2023-04-02, MAE is:13.23 & sMAPE is:20.84% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :14.58 & 25.29% & 0.71\n",
      "for 2023-04-03, MAE is:17.64 & sMAPE is:25.88% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :14.61 & 25.29% & 0.72\n",
      "for 2023-04-04, MAE is:32.45 & sMAPE is:34.30% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :14.80 & 25.39% & 0.72\n",
      "for 2023-04-05, MAE is:15.11 & sMAPE is:14.45% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :14.80 & 25.27% & 0.72\n",
      "for 2023-04-06, MAE is:12.88 & sMAPE is:19.20% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :14.78 & 25.21% & 0.72\n",
      "for 2023-04-07, MAE is:10.74 & sMAPE is:18.23% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :14.74 & 25.14% & 0.71\n",
      "for 2023-04-08, MAE is:4.27 & sMAPE is:7.35% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :14.64 & 24.96% & 0.71\n",
      "for 2023-04-09, MAE is:5.58 & sMAPE is:10.48% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :14.54 & 24.81% & 0.71\n",
      "for 2023-04-10, MAE is:14.67 & sMAPE is:41.31% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :14.55 & 24.98% & 0.71\n",
      "for 2023-04-11, MAE is:8.99 & sMAPE is:27.28% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :14.49 & 25.00% & 0.70\n",
      "for 2023-04-12, MAE is:11.19 & sMAPE is:32.68% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :14.46 & 25.07% & 0.70\n",
      "for 2023-04-13, MAE is:7.09 & sMAPE is:55.39% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :14.39 & 25.37% & 0.69\n",
      "for 2023-04-14, MAE is:16.13 & sMAPE is:66.00% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :14.40 & 25.76% & 0.69\n",
      "for 2023-04-15, MAE is:15.83 & sMAPE is:46.05% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :14.42 & 25.95% & 0.69\n",
      "for 2023-04-16, MAE is:22.37 & sMAPE is:39.47% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :14.49 & 26.08% & 0.70\n",
      "for 2023-04-17, MAE is:27.56 & sMAPE is:34.70% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :14.61 & 26.16% & 0.70\n",
      "for 2023-04-18, MAE is:23.26 & sMAPE is:28.47% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :14.69 & 26.18% & 0.70\n",
      "for 2023-04-19, MAE is:12.50 & sMAPE is:21.59% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :14.67 & 26.14% & 0.70\n",
      "for 2023-04-20, MAE is:7.49 & sMAPE is:14.11% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :14.61 & 26.03% & 0.69\n",
      "for 2023-04-21, MAE is:16.54 & sMAPE is:30.14% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :14.63 & 26.07% & 0.69\n",
      "for 2023-04-22, MAE is:6.14 & sMAPE is:17.23% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :14.55 & 25.99% & 0.69\n",
      "for 2023-04-23, MAE is:4.36 & sMAPE is:12.28% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :14.46 & 25.87% & 0.69\n",
      "for 2023-04-24, MAE is:27.22 & sMAPE is:46.91% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :14.57 & 26.05% & 0.69\n",
      "for 2023-04-25, MAE is:8.36 & sMAPE is:14.67% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :14.52 & 25.95% & 0.69\n",
      "for 2023-04-26, MAE is:18.83 & sMAPE is:25.15% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :14.56 & 25.95% & 0.69\n",
      "for 2023-04-27, MAE is:37.97 & sMAPE is:46.78% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :14.76 & 26.12% & 0.69\n",
      "for 2023-04-28, MAE is:10.11 & sMAPE is:10.46% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :14.72 & 25.99% & 0.69\n",
      "for 2023-04-29, MAE is:26.96 & sMAPE is:40.69% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :14.82 & 26.11% & 0.69\n",
      "for 2023-04-30, MAE is:15.39 & sMAPE is:45.19% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :14.82 & 26.27% & 0.70\n",
      "for 2023-05-01, MAE is:24.53 & sMAPE is:51.17% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :14.90 & 26.48% & 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-05-02, MAE is:32.34 & sMAPE is:42.09% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :15.05 & 26.61% & 0.71\n",
      "for 2023-05-03, MAE is:9.25 & sMAPE is:12.72% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :15.00 & 26.49% & 0.72\n",
      "for 2023-05-04, MAE is:18.64 & sMAPE is:21.26% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :15.03 & 26.45% & 0.72\n",
      "for 2023-05-05, MAE is:8.67 & sMAPE is:10.12% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :14.98 & 26.32% & 0.72\n",
      "for 2023-05-06, MAE is:5.72 & sMAPE is:7.82% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :14.90 & 26.17% & 0.72\n",
      "for 2023-05-07, MAE is:6.66 & sMAPE is:10.01% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :14.84 & 26.05% & 0.71\n",
      "for 2023-05-08, MAE is:12.12 & sMAPE is:18.25% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :14.82 & 25.99% & 0.71\n",
      "for 2023-05-09, MAE is:11.64 & sMAPE is:32.51% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :14.79 & 26.04% & 0.71\n",
      "for 2023-05-10, MAE is:5.51 & sMAPE is:20.83% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :14.72 & 26.00% & 0.70\n",
      "for 2023-05-11, MAE is:3.32 & sMAPE is:10.31% & rMAE is:0.05 ||| daily mean of MAE & sMAPE & rMAE till now are :14.64 & 25.88% & 0.70\n",
      "for 2023-05-12, MAE is:12.22 & sMAPE is:34.72% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :14.62 & 25.94% & 0.70\n",
      "for 2023-05-13, MAE is:14.02 & sMAPE is:54.16% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :14.61 & 26.16% & 0.69\n",
      "for 2023-05-14, MAE is:10.92 & sMAPE is:83.74% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :14.59 & 26.59% & 0.69\n",
      "for 2023-05-15, MAE is:10.64 & sMAPE is:109.32% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :14.56 & 27.20% & 0.69\n",
      "for 2023-05-16, MAE is:5.87 & sMAPE is:54.19% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :14.49 & 27.40% & 0.68\n",
      "for 2023-05-17, MAE is:1.95 & sMAPE is:143.85% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :14.40 & 28.25% & 0.68\n",
      "for 2023-05-18, MAE is:5.75 & sMAPE is:118.59% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :14.34 & 28.90% & 0.67\n",
      "for 2023-05-19, MAE is:5.72 & sMAPE is:67.27% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :14.28 & 29.18% & 0.67\n",
      "for 2023-05-20, MAE is:1.99 & sMAPE is:88.60% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :14.19 & 29.60% & 0.67\n",
      "for 2023-05-21, MAE is:2.38 & sMAPE is:126.18% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :14.10 & 30.29% & 0.66\n",
      "for 2023-05-22, MAE is:9.51 & sMAPE is:112.65% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :14.07 & 30.87% & 0.68\n",
      "for 2023-05-23, MAE is:6.66 & sMAPE is:74.69% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :14.02 & 31.17% & 0.69\n",
      "for 2023-05-24, MAE is:2.32 & sMAPE is:127.51% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :13.94 & 31.84% & 0.69\n",
      "for 2023-05-25, MAE is:2.88 & sMAPE is:167.03% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :13.86 & 32.78% & 0.69\n",
      "for 2023-05-26, MAE is:1.07 & sMAPE is:79.65% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :13.78 & 33.10% & 0.68\n",
      "for 2023-05-27, MAE is:3.80 & sMAPE is:110.10% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :13.71 & 33.62% & 0.69\n",
      "for 2023-05-28, MAE is:4.71 & sMAPE is:164.81% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :13.65 & 34.51% & 0.69\n",
      "for 2023-05-29, MAE is:2.60 & sMAPE is:85.16% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :13.57 & 34.85% & 0.69\n",
      "for 2023-05-30, MAE is:9.02 & sMAPE is:126.86% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :13.54 & 35.46% & 0.70\n",
      "for 2023-05-31, MAE is:4.36 & sMAPE is:185.91% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :13.48 & 36.46% & 0.70\n",
      "for 2023-06-01, MAE is:3.54 & sMAPE is:101.70% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :13.42 & 36.89% & 0.70\n",
      "for 2023-06-02, MAE is:9.55 & sMAPE is:102.88% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :13.39 & 37.32% & 0.71\n",
      "for 2023-06-03, MAE is:5.85 & sMAPE is:64.54% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :13.34 & 37.49% & 0.71\n",
      "for 2023-06-04, MAE is:3.55 & sMAPE is:40.75% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :13.28 & 37.52% & 0.70\n",
      "for 2023-06-05, MAE is:1.73 & sMAPE is:58.20% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :13.20 & 37.65% & 0.70\n",
      "for 2023-06-06, MAE is:14.65 & sMAPE is:144.73% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :13.21 & 38.33% & 0.71\n",
      "for 2023-06-07, MAE is:7.97 & sMAPE is:40.41% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :13.18 & 38.34% & 0.71\n",
      "for 2023-06-08, MAE is:7.10 & sMAPE is:34.77% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :13.14 & 38.32% & 0.71\n",
      "for 2023-06-09, MAE is:8.04 & sMAPE is:35.53% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :13.11 & 38.30% & 0.71\n",
      "for 2023-06-10, MAE is:6.88 & sMAPE is:34.98% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :13.07 & 38.28% & 0.71\n",
      "for 2023-06-11, MAE is:8.90 & sMAPE is:82.93% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :13.05 & 38.56% & 0.71\n",
      "for 2023-06-12, MAE is:6.68 & sMAPE is:40.57% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :13.01 & 38.57% & 0.71\n",
      "for 2023-06-13, MAE is:14.53 & sMAPE is:69.36% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :13.02 & 38.76% & 0.72\n",
      "for 2023-06-14, MAE is:8.16 & sMAPE is:29.39% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :12.99 & 38.70% & 0.72\n",
      "for 2023-06-15, MAE is:1.58 & sMAPE is:5.69% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :12.92 & 38.50% & 0.72\n",
      "for 2023-06-16, MAE is:4.80 & sMAPE is:19.40% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :12.87 & 38.39% & 0.72\n",
      "for 2023-06-17, MAE is:1.27 & sMAPE is:5.38% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :12.80 & 38.19% & 0.72\n",
      "for 2023-06-18, MAE is:7.71 & sMAPE is:33.41% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :12.77 & 38.16% & 0.71\n",
      "for 2023-06-19, MAE is:1.39 & sMAPE is:5.95% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :12.70 & 37.97% & 0.71\n",
      "for 2023-06-20, MAE is:5.74 & sMAPE is:23.60% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :12.66 & 37.89% & 0.71\n",
      "for 2023-06-21, MAE is:1.76 & sMAPE is:7.25% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :12.60 & 37.71% & 0.71\n",
      "for 2023-06-22, MAE is:2.91 & sMAPE is:13.74% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :12.54 & 37.57% & 0.71\n",
      "for 2023-06-23, MAE is:5.77 & sMAPE is:55.84% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :12.50 & 37.68% & 0.71\n",
      "for 2023-06-24, MAE is:7.55 & sMAPE is:64.16% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :12.48 & 37.83% & 0.71\n",
      "for 2023-06-25, MAE is:7.57 & sMAPE is:55.32% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :12.45 & 37.93% & 0.71\n",
      "for 2023-06-26, MAE is:4.61 & sMAPE is:23.43% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :12.40 & 37.85% & 0.72\n",
      "for 2023-06-27, MAE is:7.86 & sMAPE is:39.81% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :12.38 & 37.86% & 0.73\n",
      "for 2023-06-28, MAE is:1.35 & sMAPE is:5.55% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :12.32 & 37.68% & 0.73\n",
      "for 2023-06-29, MAE is:1.13 & sMAPE is:5.07% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :12.25 & 37.50% & 0.73\n",
      "for 2023-06-30, MAE is:1.93 & sMAPE is:9.50% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :12.20 & 37.34% & 0.72\n",
      "CPU times: total: 2d 11h 38min 49s\n",
      "Wall time: 1d 6h 44min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "large_scale_predictor(zone, first_year=2018, last_year=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
