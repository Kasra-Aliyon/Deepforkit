{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_scale_prediction import large_scale_predictor, large_scale_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = ['NL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:28:00,505]\u001b[0m A new study created in RDB with name: NL_2018\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:28:20,927]\u001b[0m Trial 0 finished with value: 7.3761062630594765 and parameters: {'n_hidden': 4, 'learning_rate': 0.07050924025284454, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2797105915789752, 'dropout_rate_Layer_2': 0.36649596824418457, 'dropout_rate_Layer_3': 0.36162029783743876, 'dropout_rate_Layer_4': 0.0008773571547096015, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007343824014548977, 'l1_Layer_2': 3.326815747248795e-05, 'l1_Layer_3': 0.00024880942085935746, 'l1_Layer_4': 0.0063289591020097655, 'n_units_Layer_1': 70, 'n_units_Layer_2': 80, 'n_units_Layer_3': 285, 'n_units_Layer_4': 225}. Best is trial 0 with value: 7.3761062630594765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.38 | sMAPE for Validation Set is: 17.84% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 16.25 | sMAPE for Test Set is: 33.71% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:28:24,765]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:28:29,167]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:28:32,149]\u001b[0m Trial 3 finished with value: 6.117402813252568 and parameters: {'n_hidden': 4, 'learning_rate': 0.006960575850528489, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26256279913035646, 'dropout_rate_Layer_2': 0.16629491514152528, 'dropout_rate_Layer_3': 0.3964285791993455, 'dropout_rate_Layer_4': 0.08079091762237463, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.012226047559390997, 'l1_Layer_2': 0.005044737710917925, 'l1_Layer_3': 8.038317267443936e-05, 'l1_Layer_4': 0.0010809401102188946, 'n_units_Layer_1': 205, 'n_units_Layer_2': 115, 'n_units_Layer_3': 90, 'n_units_Layer_4': 245}. Best is trial 3 with value: 6.117402813252568.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 14.99% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 12.55 | sMAPE for Test Set is: 25.04% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:28:34,668]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:28:36,149]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:28:41,310]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:28:41,547]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:28:48,423]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:28:48,816]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:28:55,480]\u001b[0m Trial 2 finished with value: 5.951034891032639 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026988131758451136, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26969865694623646, 'dropout_rate_Layer_2': 0.1872602359168375, 'dropout_rate_Layer_3': 0.23843112909963013, 'dropout_rate_Layer_4': 0.23850720837634248, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005410091505364991, 'l1_Layer_2': 0.06994109011237679, 'l1_Layer_3': 7.803731178074152e-05, 'l1_Layer_4': 0.009899645348595072, 'n_units_Layer_1': 55, 'n_units_Layer_2': 290, 'n_units_Layer_3': 295, 'n_units_Layer_4': 235}. Best is trial 2 with value: 5.951034891032639.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.95 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 9.65 | sMAPE for Test Set is: 18.97% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:28:56,906]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:29:01,306]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:29:04,838]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:29:11,100]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:29:16,274]\u001b[0m Trial 12 finished with value: 5.724712505384974 and parameters: {'n_hidden': 3, 'learning_rate': 0.0481193416129199, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16354149781737518, 'dropout_rate_Layer_2': 0.2799601690216242, 'dropout_rate_Layer_3': 0.30722563709110406, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.009375558420074e-05, 'l1_Layer_2': 0.0034049756923573236, 'l1_Layer_3': 0.008773609654522108, 'n_units_Layer_1': 300, 'n_units_Layer_2': 140, 'n_units_Layer_3': 95}. Best is trial 12 with value: 5.724712505384974.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 14.06% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 10.80 | sMAPE for Test Set is: 20.95% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:29:18,205]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:29:24,548]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:29:30,301]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:29:37,066]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:29:37,452]\u001b[0m Trial 1 finished with value: 6.054862722524717 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009740920849687596, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12875050249692885, 'dropout_rate_Layer_2': 0.1548056726040334, 'dropout_rate_Layer_3': 0.06820581490369282, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0024925066360447245, 'l1_Layer_2': 0.022515693202830207, 'l1_Layer_3': 0.028709239405051868, 'n_units_Layer_1': 240, 'n_units_Layer_2': 145, 'n_units_Layer_3': 55}. Best is trial 12 with value: 5.724712505384974.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.05 | sMAPE for Validation Set is: 14.78% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 12.53 | sMAPE for Test Set is: 24.94% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:29:44,282]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:29:44,813]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:29:45,012]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:29:54,114]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:29:58,387]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:30:02,742]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:30:08,455]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:30:12,470]\u001b[0m Trial 27 finished with value: 7.412430773180955 and parameters: {'n_hidden': 3, 'learning_rate': 0.01129103438168212, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34942164004541415, 'dropout_rate_Layer_2': 0.15457158587005582, 'dropout_rate_Layer_3': 0.3673326983825349, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.016360962891039128, 'l1_Layer_2': 0.09060934722313939, 'l1_Layer_3': 0.00044638091164820497, 'n_units_Layer_1': 250, 'n_units_Layer_2': 115, 'n_units_Layer_3': 90}. Best is trial 12 with value: 5.724712505384974.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.41 | sMAPE for Validation Set is: 18.07% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 17.50 | sMAPE for Test Set is: 36.95% | rMAE for Test Set is: 1.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:30:18,666]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:30:18,818]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:30:30,570]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:30:34,015]\u001b[0m Trial 26 finished with value: 5.823810325183902 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033875831057106143, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2686528867673518, 'dropout_rate_Layer_2': 0.0069734712825211265, 'dropout_rate_Layer_3': 0.07153736578050354, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03893088920086515, 'l1_Layer_2': 0.019765475655105134, 'l1_Layer_3': 2.2883952615892806e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 250, 'n_units_Layer_3': 235}. Best is trial 12 with value: 5.724712505384974.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 14.09% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 11.51 | sMAPE for Test Set is: 22.61% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:30:37,382]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:30:45,893]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:30:49,542]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:30:51,209]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:30:55,094]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:30:55,722]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:01,218]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:05,394]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:10,117]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:13,641]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:14,027]\u001b[0m Trial 16 finished with value: 5.802004262615182 and parameters: {'n_hidden': 4, 'learning_rate': 0.005739177106323733, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04725145034232754, 'dropout_rate_Layer_2': 0.27387306077553053, 'dropout_rate_Layer_3': 0.14166552116739337, 'dropout_rate_Layer_4': 0.09379051206720833, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.3399759420476693e-05, 'l1_Layer_2': 0.022349299548799932, 'l1_Layer_3': 0.014720841387722483, 'l1_Layer_4': 0.06563258964694332, 'n_units_Layer_1': 195, 'n_units_Layer_2': 160, 'n_units_Layer_3': 70, 'n_units_Layer_4': 80}. Best is trial 12 with value: 5.724712505384974.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 14.04% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 11.53 | sMAPE for Test Set is: 23.05% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:31:18,655]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:18,962]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:19,741]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:25,957]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:26,283]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:26,284]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:26,975]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:35,247]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:35,851]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:36,071]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:38,556]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:40,204]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:45,579]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:51,695]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:31:56,984]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:32:02,150]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:32:05,132]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:32:09,115]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:32:13,138]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:32:13,404]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:32:28,987]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:32:32,187]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:32:38,022]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:32:41,611]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:32:43,451]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:32:44,813]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:32:48,257]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:32:51,795]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:32:52,399]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:32:58,493]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:32:59,020]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:33:01,407]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:33:09,884]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:33:11,778]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:33:27,050]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:33:31,107]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:33:35,491]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:33:39,239]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:33:54,261]\u001b[0m Trial 79 finished with value: 5.521534900558727 and parameters: {'n_hidden': 3, 'learning_rate': 0.003462976975726908, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2798018677632205, 'dropout_rate_Layer_2': 0.14933969108139422, 'dropout_rate_Layer_3': 0.001088618577883227, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005796580977680432, 'l1_Layer_2': 0.00047691116899992116, 'l1_Layer_3': 0.00047848572419801315, 'n_units_Layer_1': 155, 'n_units_Layer_2': 135, 'n_units_Layer_3': 220}. Best is trial 79 with value: 5.521534900558727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 13.23% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 10.65 | sMAPE for Test Set is: 20.81% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:33:57,332]\u001b[0m Trial 81 finished with value: 5.938567568931721 and parameters: {'n_hidden': 4, 'learning_rate': 0.005699762385921578, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2292193137545983, 'dropout_rate_Layer_2': 0.2806094243318068, 'dropout_rate_Layer_3': 0.33748745757066767, 'dropout_rate_Layer_4': 0.15370720126405374, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0026027720725510435, 'l1_Layer_2': 0.0059355606659431135, 'l1_Layer_3': 3.5149308755747794e-05, 'l1_Layer_4': 0.003364768689178848, 'n_units_Layer_1': 160, 'n_units_Layer_2': 60, 'n_units_Layer_3': 200, 'n_units_Layer_4': 235}. Best is trial 79 with value: 5.521534900558727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.94 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 12.54 | sMAPE for Test Set is: 25.15% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:33:59,636]\u001b[0m Trial 85 finished with value: 5.907423593389699 and parameters: {'n_hidden': 3, 'learning_rate': 0.09819029159134852, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.003803891185729269, 'dropout_rate_Layer_2': 0.38910362161641304, 'dropout_rate_Layer_3': 0.28050166766948254, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3472859718888308e-05, 'l1_Layer_2': 0.0019576482547394415, 'l1_Layer_3': 0.004392655610535433, 'n_units_Layer_1': 290, 'n_units_Layer_2': 115, 'n_units_Layer_3': 125}. Best is trial 79 with value: 5.521534900558727.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 12.22 | sMAPE for Test Set is: 24.31% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:33:59,966]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:34:05,700]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:34:15,484]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:34:21,354]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:34:27,030]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:34:31,977]\u001b[0m Trial 88 finished with value: 5.511333350060816 and parameters: {'n_hidden': 3, 'learning_rate': 0.004996281898718178, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0020871506543750085, 'dropout_rate_Layer_2': 0.1486679968960686, 'dropout_rate_Layer_3': 0.005996147515520598, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005674982186062576, 'l1_Layer_2': 0.000491515852494095, 'l1_Layer_3': 0.00020506239590357527, 'n_units_Layer_1': 155, 'n_units_Layer_2': 115, 'n_units_Layer_3': 255}. Best is trial 88 with value: 5.511333350060816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 13.41% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 11.91 | sMAPE for Test Set is: 23.61% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:34:37,328]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:34:41,996]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:34:47,596]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:34:56,324]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:35:01,532]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:35:13,505]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:35:23,390]\u001b[0m Trial 98 finished with value: 5.476332865516123 and parameters: {'n_hidden': 3, 'learning_rate': 0.004240584998444601, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010384128666477956, 'dropout_rate_Layer_2': 0.15964149391283672, 'dropout_rate_Layer_3': 0.028881659614400736, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010473754990172877, 'l1_Layer_2': 0.00045165337301203185, 'l1_Layer_3': 3.176732068982171e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 115, 'n_units_Layer_3': 225}. Best is trial 98 with value: 5.476332865516123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 13.29% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 12.15 | sMAPE for Test Set is: 24.25% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:35:38,445]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:35:43,137]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:35:46,419]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:35:49,161]\u001b[0m Trial 100 finished with value: 5.550150274076053 and parameters: {'n_hidden': 3, 'learning_rate': 0.0039023959637451374, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06059578931637802, 'dropout_rate_Layer_2': 0.14480041483290054, 'dropout_rate_Layer_3': 0.03552817001261494, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010603552195045272, 'l1_Layer_2': 0.00042717840896955967, 'l1_Layer_3': 3.946236801700491e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 115, 'n_units_Layer_3': 220}. Best is trial 98 with value: 5.476332865516123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 13.38% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 11.49 | sMAPE for Test Set is: 22.82% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:35:59,682]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:36:17,548]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:36:23,100]\u001b[0m Trial 89 finished with value: 6.014071837377281 and parameters: {'n_hidden': 4, 'learning_rate': 0.026918917427740108, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014965312906868332, 'dropout_rate_Layer_2': 0.30202917339867225, 'dropout_rate_Layer_3': 0.11999000765980015, 'dropout_rate_Layer_4': 0.05212336612632158, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.4407442992189937e-05, 'l1_Layer_2': 0.002081078773145668, 'l1_Layer_3': 0.08678820705161026, 'l1_Layer_4': 0.09457294711325358, 'n_units_Layer_1': 290, 'n_units_Layer_2': 210, 'n_units_Layer_3': 125, 'n_units_Layer_4': 70}. Best is trial 98 with value: 5.476332865516123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 15.07% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 11.23 | sMAPE for Test Set is: 22.63% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:36:29,449]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:36:34,520]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:36:38,136]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:36:42,695]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:36:50,499]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:36:53,912]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:36:56,619]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:37:03,580]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:37:06,168]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:37:07,830]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:37:12,762]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:37:15,281]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:37:19,240]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:37:24,677]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:37:41,002]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:37:44,619]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:37:57,598]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:38:05,094]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:38:25,992]\u001b[0m Trial 115 finished with value: 5.670567421797711 and parameters: {'n_hidden': 3, 'learning_rate': 0.024688096894815544, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07008569433606672, 'dropout_rate_Layer_2': 0.11106330735975617, 'dropout_rate_Layer_3': 0.1389636047375517, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 9.839244272880644e-05, 'l1_Layer_2': 0.006052834951623541, 'l1_Layer_3': 0.00526491154248237, 'n_units_Layer_1': 160, 'n_units_Layer_2': 115, 'n_units_Layer_3': 120}. Best is trial 98 with value: 5.476332865516123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 13.74% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 10.81 | sMAPE for Test Set is: 21.33% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:38:35,898]\u001b[0m Trial 57 finished with value: 5.533906046656035 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005849282169696354, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2700581256908852, 'dropout_rate_Layer_2': 0.04094571696237606, 'dropout_rate_Layer_3': 0.24452421680924472, 'dropout_rate_Layer_4': 0.21052861227205266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.639487961917114e-05, 'l1_Layer_2': 0.0007651697219107122, 'l1_Layer_3': 0.045293026793296005, 'l1_Layer_4': 0.0015524302908548058, 'n_units_Layer_1': 70, 'n_units_Layer_2': 60, 'n_units_Layer_3': 140, 'n_units_Layer_4': 120}. Best is trial 98 with value: 5.476332865516123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 13.41% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 10.41 | sMAPE for Test Set is: 20.40% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:38:39,503]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:38:43,310]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 14.57% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 12.98 | sMAPE for Test Set is: 25.84% | rMAE for Test Set is: 1.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:38:44,951]\u001b[0m Trial 121 finished with value: 6.036598118306093 and parameters: {'n_hidden': 4, 'learning_rate': 0.0040327797415763405, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3513602422954686, 'dropout_rate_Layer_2': 0.2142793034168687, 'dropout_rate_Layer_3': 0.36787258391265504, 'dropout_rate_Layer_4': 0.2538597832889044, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.010350681602474857, 'l1_Layer_2': 0.0008448989147930194, 'l1_Layer_3': 0.0002069978730407666, 'l1_Layer_4': 0.0018927211811862858, 'n_units_Layer_1': 175, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225, 'n_units_Layer_4': 270}. Best is trial 98 with value: 5.476332865516123.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:39:15,213]\u001b[0m Trial 126 finished with value: 5.605258900533175 and parameters: {'n_hidden': 3, 'learning_rate': 0.02226163083031849, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07012714546739673, 'dropout_rate_Layer_2': 0.10351400260888832, 'dropout_rate_Layer_3': 0.14379079460078578, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0001061392466801157, 'l1_Layer_2': 0.00862903596089038, 'l1_Layer_3': 0.0044351262538342385, 'n_units_Layer_1': 160, 'n_units_Layer_2': 115, 'n_units_Layer_3': 120}. Best is trial 98 with value: 5.476332865516123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 13.87% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 11.61 | sMAPE for Test Set is: 23.12% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:39:21,824]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:39:25,489]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:39:35,904]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:40:28,334]\u001b[0m Trial 134 finished with value: 5.822737707940781 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023493284413195776, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33412943850252724, 'dropout_rate_Layer_2': 0.042824247806311916, 'dropout_rate_Layer_3': 0.3155451513477199, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01603397107358156, 'l1_Layer_2': 0.01526278064400507, 'l1_Layer_3': 0.002100604362098148, 'n_units_Layer_1': 215, 'n_units_Layer_2': 105, 'n_units_Layer_3': 240}. Best is trial 98 with value: 5.476332865516123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 14.10% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 10.85 | sMAPE for Test Set is: 21.21% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:40:32,752]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:40:36,281]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:41:40,696]\u001b[0m Trial 130 finished with value: 5.685392029565141 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005384415500563601, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32490449815223893, 'dropout_rate_Layer_2': 0.02796804630024339, 'dropout_rate_Layer_3': 0.004661261605089034, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00018878560787245343, 'l1_Layer_2': 0.00036814765526215984, 'l1_Layer_3': 0.0020931697732192046, 'n_units_Layer_1': 145, 'n_units_Layer_2': 50, 'n_units_Layer_3': 160}. Best is trial 98 with value: 5.476332865516123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 14.11% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 11.21 | sMAPE for Test Set is: 22.05% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:42:12,000]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:42:49,478]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:42:53,823]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:43:11,183]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:43:15,997]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:43:23,291]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:43:31,628]\u001b[0m Trial 139 finished with value: 5.8551597938502065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020366899658339046, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2331236564167626, 'dropout_rate_Layer_2': 0.05066843575215782, 'dropout_rate_Layer_3': 0.29162852500397984, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02943526807909186, 'l1_Layer_2': 0.008597072677128115, 'l1_Layer_3': 0.002675084850533758, 'n_units_Layer_1': 210, 'n_units_Layer_2': 215, 'n_units_Layer_3': 245}. Best is trial 98 with value: 5.476332865516123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 11.35 | sMAPE for Test Set is: 22.32% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:43:48,865]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:43:55,797]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:43:59,477]\u001b[0m Trial 145 finished with value: 5.5047767692704435 and parameters: {'n_hidden': 3, 'learning_rate': 0.006089312989678966, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01809898013156053, 'dropout_rate_Layer_2': 0.19220215166140334, 'dropout_rate_Layer_3': 0.04036607346551935, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008200710869806047, 'l1_Layer_2': 0.0008884181744235437, 'l1_Layer_3': 1.8135842963069297e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 125, 'n_units_Layer_3': 215}. Best is trial 98 with value: 5.476332865516123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 13.44% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 10.71 | sMAPE for Test Set is: 21.17% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:44:02,317]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:44:05,521]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:44:12,478]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:44:15,727]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:44:20,560]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:44:39,403]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:44:44,575]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:44:48,393]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:44:52,641]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:44:56,778]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:45:48,952]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:45:54,647]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:45:58,694]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:46:06,255]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:46:13,549]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:46:18,929]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:46:22,940]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:46:27,189]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:46:32,261]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:46:39,959]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:46:46,342]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:46:51,655]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:46:51,926]\u001b[0m Trial 131 finished with value: 5.561708990928182 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005470228251667673, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3123365080848862, 'dropout_rate_Layer_2': 0.051359180622240354, 'dropout_rate_Layer_3': 0.20864485882604697, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00014012349359260963, 'l1_Layer_2': 0.0002513949504698235, 'l1_Layer_3': 0.0032865661468353376, 'n_units_Layer_1': 140, 'n_units_Layer_2': 50, 'n_units_Layer_3': 165}. Best is trial 98 with value: 5.476332865516123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 13.49% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 12.10 | sMAPE for Test Set is: 24.08% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:46:59,262]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:47:03,921]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:47:08,561]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:47:13,119]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:47:18,280]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:47:23,219]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:47:26,841]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:47:42,294]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:47:47,857]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:47:56,279]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:48:01,518]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:48:04,844]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:48:05,219]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:48:09,438]\u001b[0m Trial 153 finished with value: 5.544973707909468 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005867853584468737, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31638460966536064, 'dropout_rate_Layer_2': 0.008358808430921544, 'dropout_rate_Layer_3': 0.19084051140907585, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004738990487112395, 'l1_Layer_2': 0.00045523700472819943, 'l1_Layer_3': 0.001915182066022149, 'n_units_Layer_1': 110, 'n_units_Layer_2': 155, 'n_units_Layer_3': 300}. Best is trial 98 with value: 5.476332865516123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 13.34% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 11.25 | sMAPE for Test Set is: 21.98% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:48:13,776]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:48:14,111]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:48:19,802]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:48:20,182]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:48:28,608]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:48:31,513]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:48:36,122]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:48:43,019]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:48:47,983]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:48:50,609]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:48:53,419]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:48:54,214]\u001b[0m Trial 190 finished with value: 5.438343912627221 and parameters: {'n_hidden': 3, 'learning_rate': 0.005478586964348116, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07197163887862312, 'dropout_rate_Layer_2': 0.13672511405083684, 'dropout_rate_Layer_3': 0.0433704879458741, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001151936238501796, 'l1_Layer_2': 0.00030990659640460396, 'l1_Layer_3': 2.600951554148892e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 150, 'n_units_Layer_3': 230}. Best is trial 190 with value: 5.438343912627221.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 13.12% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 10.81 | sMAPE for Test Set is: 21.20% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:48:55,005]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:48:58,138]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:49:03,737]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:49:08,051]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:49:08,671]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:49:12,896]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:49:15,371]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:49:19,657]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:49:22,402]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:49:25,283]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:49:33,710]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:50:04,153]\u001b[0m Trial 209 finished with value: 5.442844462634465 and parameters: {'n_hidden': 3, 'learning_rate': 0.00493529267948753, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28827424054063155, 'dropout_rate_Layer_2': 0.14347267322061877, 'dropout_rate_Layer_3': 0.030977617297535193, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008791408627807511, 'l1_Layer_2': 0.00015451493980095127, 'l1_Layer_3': 5.349406020329427e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 155, 'n_units_Layer_3': 295}. Best is trial 190 with value: 5.438343912627221.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 13.22% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 11.74 | sMAPE for Test Set is: 23.28% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:50:07,867]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:50:14,028]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:50:16,401]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:50:24,185]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:50:31,112]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:50:37,048]\u001b[0m Trial 191 finished with value: 5.5891159302073925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013129521052817434, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35922869629426957, 'dropout_rate_Layer_2': 0.05352515295727242, 'dropout_rate_Layer_3': 0.22742484558186327, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 4.489642835884543e-05, 'l1_Layer_2': 0.0008381030102107083, 'l1_Layer_3': 0.0006592181138773633, 'n_units_Layer_1': 180, 'n_units_Layer_2': 120, 'n_units_Layer_3': 130}. Best is trial 190 with value: 5.438343912627221.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 13.62% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.71 | sMAPE for Test Set is: 25.44% | rMAE for Test Set is: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:50:53,116]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:00,727]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:03,914]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:08,660]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:16,224]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:17,479]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:20,649]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:21,166]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:24,621]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:25,168]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:30,684]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:33,535]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:37,071]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:40,818]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:41,036]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:41,367]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:49,634]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:49,963]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:52,654]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:51:57,876]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:04,643]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:07,966]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:08,043]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:14,338]\u001b[0m Trial 224 finished with value: 5.938758935502122 and parameters: {'n_hidden': 4, 'learning_rate': 0.004278399786526892, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33544578384313184, 'dropout_rate_Layer_2': 0.11350545620730715, 'dropout_rate_Layer_3': 0.38204004021086246, 'dropout_rate_Layer_4': 0.04884375505047288, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.010012951762308965, 'l1_Layer_2': 0.02108903359577966, 'l1_Layer_3': 6.407074906742632e-05, 'l1_Layer_4': 0.00030541492058951483, 'n_units_Layer_1': 230, 'n_units_Layer_2': 55, 'n_units_Layer_3': 220, 'n_units_Layer_4': 205}. Best is trial 190 with value: 5.438343912627221.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.94 | sMAPE for Validation Set is: 14.35% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 11.62 | sMAPE for Test Set is: 22.86% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:52:19,213]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:22,784]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:26,060]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:26,767]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:28,726]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:31,006]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:31,140]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:36,206]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:38,227]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:42,847]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:43,000]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:46,329]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:47,665]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:49,435]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:49,565]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:57,021]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:52:59,098]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:02,594]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:06,518]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:06,768]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:11,360]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:11,828]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:15,527]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:16,648]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:18,934]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:19,338]\u001b[0m Trial 253 finished with value: 5.351297452827183 and parameters: {'n_hidden': 3, 'learning_rate': 0.0045058717809734255, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09191961305552653, 'dropout_rate_Layer_2': 0.1568331926736575, 'dropout_rate_Layer_3': 0.03796042220432442, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005493107102588622, 'l1_Layer_2': 0.0007388123676762318, 'l1_Layer_3': 3.677352613385793e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 240, 'n_units_Layer_3': 230}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 12.82% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 9.16 | sMAPE for Test Set is: 17.57% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:53:21,952]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:27,696]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:27,852]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:30,124]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:40,158]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:43,476]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:43,841]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:49,840]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:50,179]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:55,006]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:53:59,636]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:54:03,200]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:54:34,024]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:54:41,691]\u001b[0m Trial 268 finished with value: 6.455177965989992 and parameters: {'n_hidden': 3, 'learning_rate': 0.04477824418512001, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.295573446256487, 'dropout_rate_Layer_2': 0.03229443980194589, 'dropout_rate_Layer_3': 0.1539586111754664, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 5.4581129854536633e-05, 'l1_Layer_2': 0.0004639560102109471, 'l1_Layer_3': 0.011363399120355866, 'n_units_Layer_1': 150, 'n_units_Layer_2': 135, 'n_units_Layer_3': 140}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 15.69% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 13.38 | sMAPE for Test Set is: 26.59% | rMAE for Test Set is: 1.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:54:44,094]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:54:47,538]\u001b[0m Trial 267 finished with value: 6.591041504648589 and parameters: {'n_hidden': 3, 'learning_rate': 0.04799548662813852, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31824549335726504, 'dropout_rate_Layer_2': 0.03657741535815853, 'dropout_rate_Layer_3': 0.14232614906571822, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 5.5077809331146956e-05, 'l1_Layer_2': 0.01003097600186918, 'l1_Layer_3': 0.01325262805581113, 'n_units_Layer_1': 155, 'n_units_Layer_2': 130, 'n_units_Layer_3': 140}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 16.08% | rMAE for Validation Set is: 0.95\n",
      "MAE for Test Set is: 14.54 | sMAPE for Test Set is: 29.51% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:54:53,486]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:54:57,180]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:55:00,803]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:55:03,142]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:55:06,190]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:55:07,121]\u001b[0m Trial 275 finished with value: 6.495122933298959 and parameters: {'n_hidden': 3, 'learning_rate': 0.04495886347997409, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29495684435451275, 'dropout_rate_Layer_2': 0.11725759214227434, 'dropout_rate_Layer_3': 0.15216114994519203, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 5.138139197221671e-05, 'l1_Layer_2': 0.000528434624251643, 'l1_Layer_3': 0.0006820716187275648, 'n_units_Layer_1': 150, 'n_units_Layer_2': 125, 'n_units_Layer_3': 145}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.50 | sMAPE for Validation Set is: 15.86% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 13.00 | sMAPE for Test Set is: 25.82% | rMAE for Test Set is: 1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:55:11,257]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:55:15,420]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:55:19,944]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:55:25,247]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:55:25,843]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:55:31,553]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:55:38,758]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:55:40,701]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:55:44,354]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:55:47,210]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:55:49,196]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:55:51,636]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:55:53,644]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:55:57,237]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:56:00,201]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:56:03,147]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:56:04,782]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:56:11,120]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:56:13,592]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:56:17,230]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:56:19,525]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:56:22,067]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:56:34,404]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:56:36,997]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:56:40,557]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:56:44,159]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:56:47,295]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:56:50,269]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:56:53,431]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:56:55,581]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:00,648]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:01,199]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:07,248]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:10,820]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:18,813]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:23,565]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:25,580]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:29,880]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:30,092]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:34,313]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:36,644]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:39,217]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:42,476]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:43,782]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:49,306]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:51,751]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:55,992]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:58,212]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:58,364]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:57:59,914]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:58:05,132]\u001b[0m Trial 292 finished with value: 5.782218153623229 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005539253878414133, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31335784867864436, 'dropout_rate_Layer_2': 0.38337849911816346, 'dropout_rate_Layer_3': 0.24294454698045795, 'dropout_rate_Layer_4': 0.24353669325233251, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.012786168190619692, 'l1_Layer_2': 0.07384444410811405, 'l1_Layer_3': 0.00018064465242674307, 'l1_Layer_4': 0.0040405001264368304, 'n_units_Layer_1': 145, 'n_units_Layer_2': 55, 'n_units_Layer_3': 115, 'n_units_Layer_4': 285}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 14.14% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 9.74 | sMAPE for Test Set is: 18.95% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:58:05,662]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:58:05,748]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:58:06,202]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:58:12,737]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:58:18,109]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:58:19,798]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:58:22,302]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:58:22,709]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:58:24,037]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:58:29,992]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:58:33,117]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:58:36,856]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:58:38,378]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:58:43,254]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:58:51,928]\u001b[0m Trial 347 finished with value: 5.409583982080498 and parameters: {'n_hidden': 3, 'learning_rate': 0.00544741708548382, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0320779111591219, 'dropout_rate_Layer_2': 0.19948653190048254, 'dropout_rate_Layer_3': 0.03778821928641929, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000823671395385705, 'l1_Layer_2': 0.0009381552783612573, 'l1_Layer_3': 4.707470527194564e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 150, 'n_units_Layer_3': 230}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 13.25% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 10.63 | sMAPE for Test Set is: 20.96% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:58:53,966]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:58:57,931]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:58:58,185]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:59:02,627]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:59:19,833]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:59:32,131]\u001b[0m Trial 343 finished with value: 5.684170103410547 and parameters: {'n_hidden': 3, 'learning_rate': 0.018769875887732036, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06552337872348124, 'dropout_rate_Layer_2': 0.015896836738634568, 'dropout_rate_Layer_3': 0.1652567698740189, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 9.879290595602409e-05, 'l1_Layer_2': 0.01667953737605341, 'l1_Layer_3': 0.0027283195001935943, 'n_units_Layer_1': 165, 'n_units_Layer_2': 115, 'n_units_Layer_3': 120}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 13.83% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 11.75 | sMAPE for Test Set is: 23.52% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 16:59:36,554]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:59:36,668]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 16:59:41,909]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:00:32,971]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:00:37,121]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:00:38,634]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:00:39,765]\u001b[0m Trial 358 finished with value: 5.835545163163481 and parameters: {'n_hidden': 3, 'learning_rate': 0.023383896051843534, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.034329904246870435, 'dropout_rate_Layer_2': 0.16898637284074727, 'dropout_rate_Layer_3': 0.08040788482949075, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 8.326862242825113e-05, 'l1_Layer_2': 0.004206049434401905, 'l1_Layer_3': 0.003034973913696245, 'n_units_Layer_1': 160, 'n_units_Layer_2': 115, 'n_units_Layer_3': 120}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 13.92% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 12.95 | sMAPE for Test Set is: 25.95% | rMAE for Test Set is: 1.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:00:41,397]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:00:46,394]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:00:57,375]\u001b[0m Trial 353 finished with value: 5.759377081904774 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007119452616507617, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3731501117672894, 'dropout_rate_Layer_2': 0.3389608409102807, 'dropout_rate_Layer_3': 0.24189431116089324, 'dropout_rate_Layer_4': 0.14174301379514068, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0019301949035569078, 'l1_Layer_2': 0.06571608411955186, 'l1_Layer_3': 0.00024251631390114162, 'l1_Layer_4': 0.0028937637861150213, 'n_units_Layer_1': 150, 'n_units_Layer_2': 70, 'n_units_Layer_3': 95, 'n_units_Layer_4': 290}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 14.12% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 9.49 | sMAPE for Test Set is: 18.43% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:01:32,564]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:01:33,023]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:01:38,377]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:01:40,128]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:01:44,580]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:01:47,104]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:01:49,020]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:01:53,788]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:01:57,528]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:01:59,773]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:02:02,292]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:02:07,119]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:02:09,340]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:02:10,151]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:02:12,612]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:02:16,958]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:02:20,222]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:02:32,662]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:02:36,817]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:02:42,689]\u001b[0m Trial 386 finished with value: 5.486485569650235 and parameters: {'n_hidden': 3, 'learning_rate': 0.005867128804597629, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.044991611447152295, 'dropout_rate_Layer_2': 0.19536086260434585, 'dropout_rate_Layer_3': 0.04034278461833067, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000940846909522452, 'l1_Layer_2': 0.000843363026623737, 'l1_Layer_3': 3.522646519237591e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 150, 'n_units_Layer_3': 225}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 13.43% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 10.87 | sMAPE for Test Set is: 21.34% | rMAE for Test Set is: 1.23\n",
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 13.36% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 10.66 | sMAPE for Test Set is: 21.02% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:02:48,682]\u001b[0m Trial 387 finished with value: 5.464122361879331 and parameters: {'n_hidden': 3, 'learning_rate': 0.0060235922121348005, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030435273683329527, 'dropout_rate_Layer_2': 0.17674825364619526, 'dropout_rate_Layer_3': 0.03111141113025038, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005556368430726159, 'l1_Layer_2': 0.0006879112075508366, 'l1_Layer_3': 2.9203762514931626e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 155, 'n_units_Layer_3': 240}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:02:58,264]\u001b[0m Trial 368 finished with value: 5.74559659114319 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009076310748764782, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28120638092866207, 'dropout_rate_Layer_2': 0.056356541425125056, 'dropout_rate_Layer_3': 0.24134823526040888, 'dropout_rate_Layer_4': 0.18791058797757573, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0032987236876294494, 'l1_Layer_2': 0.0037394652997079303, 'l1_Layer_3': 0.0002735163350900185, 'l1_Layer_4': 0.003220666689616653, 'n_units_Layer_1': 180, 'n_units_Layer_2': 70, 'n_units_Layer_3': 85, 'n_units_Layer_4': 295}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 13.97% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 9.35 | sMAPE for Test Set is: 18.05% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:03:02,592]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:06,363]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:06,746]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:12,851]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:14,382]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:19,460]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:24,384]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:24,683]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:30,504]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:34,277]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:34,777]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:38,802]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:41,614]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:45,609]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:47,967]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:49,300]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:53,443]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:54,935]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:55,223]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:03:56,761]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:04:04,433]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:04:04,605]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:04:11,372]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:04:14,724]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:04:59,526]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:05:03,925]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:05:28,906]\u001b[0m Trial 406 finished with value: 5.797023589899642 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015102110233482454, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2785924832976093, 'dropout_rate_Layer_2': 0.04837649432698084, 'dropout_rate_Layer_3': 0.24959553357866726, 'dropout_rate_Layer_4': 0.21540322184062233, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002164137430839929, 'l1_Layer_2': 0.006790392564310625, 'l1_Layer_3': 0.00023432148291977522, 'l1_Layer_4': 0.0022976417220457387, 'n_units_Layer_1': 150, 'n_units_Layer_2': 55, 'n_units_Layer_3': 65, 'n_units_Layer_4': 275}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 14.14% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 10.88 | sMAPE for Test Set is: 21.33% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:05:32,703]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:05:36,342]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:05:42,140]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:05:57,828]\u001b[0m Trial 410 finished with value: 5.576853569437449 and parameters: {'n_hidden': 3, 'learning_rate': 0.014989031560538553, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12911862509974092, 'dropout_rate_Layer_2': 0.10264393869544283, 'dropout_rate_Layer_3': 0.06067042391167993, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5997075482807402e-05, 'l1_Layer_2': 0.0037060834599340164, 'l1_Layer_3': 0.003566626381174884, 'n_units_Layer_1': 80, 'n_units_Layer_2': 65, 'n_units_Layer_3': 245}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 13.81% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 9.02 | sMAPE for Test Set is: 17.84% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:06:02,501]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:06:06,464]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:06:11,541]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:06:17,351]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:06:24,632]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:06:32,263]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:06:36,104]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:06:41,843]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:06:42,189]\u001b[0m Trial 414 finished with value: 5.43929499036551 and parameters: {'n_hidden': 3, 'learning_rate': 0.013462687925721393, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14994816034408598, 'dropout_rate_Layer_2': 0.04619628074211195, 'dropout_rate_Layer_3': 0.05480362863114077, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1560340952786577e-05, 'l1_Layer_2': 0.02656022223401394, 'l1_Layer_3': 0.0003970207595693873, 'n_units_Layer_1': 170, 'n_units_Layer_2': 170, 'n_units_Layer_3': 105}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 13.17% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 9.72 | sMAPE for Test Set is: 18.87% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:06:47,532]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:06:50,677]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:06:54,351]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:06:59,070]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:07:02,480]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:07:04,345]\u001b[0m Trial 422 finished with value: 5.926219576981258 and parameters: {'n_hidden': 3, 'learning_rate': 0.033713197986475305, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39737761079694034, 'dropout_rate_Layer_2': 0.041385621612457235, 'dropout_rate_Layer_3': 0.051915438974456496, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1225050541293252e-05, 'l1_Layer_2': 0.025122647348520072, 'l1_Layer_3': 0.0015784273409402015, 'n_units_Layer_1': 85, 'n_units_Layer_2': 300, 'n_units_Layer_3': 105}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 14.52% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 11.49 | sMAPE for Test Set is: 23.02% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:07:14,375]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:07:24,223]\u001b[0m Trial 418 finished with value: 5.422584407529352 and parameters: {'n_hidden': 3, 'learning_rate': 0.01638540405421622, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1152396052267206, 'dropout_rate_Layer_2': 0.039550424199445475, 'dropout_rate_Layer_3': 0.040580748109892276, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1925263347333166e-05, 'l1_Layer_2': 0.0034972860012104316, 'l1_Layer_3': 0.003799948517402764, 'n_units_Layer_1': 225, 'n_units_Layer_2': 165, 'n_units_Layer_3': 110}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 13.12% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 8.81 | sMAPE for Test Set is: 16.90% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:07:33,303]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:07:38,028]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:07:42,367]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:07:51,406]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:07:55,671]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:08:01,500]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:08:02,093]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:08:07,241]\u001b[0m Trial 443 finished with value: 5.504338617502422 and parameters: {'n_hidden': 3, 'learning_rate': 0.005320946820298029, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04305781154454021, 'dropout_rate_Layer_2': 0.1863933086104226, 'dropout_rate_Layer_3': 0.03620977686823249, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012906035433717091, 'l1_Layer_2': 0.0007934246379325342, 'l1_Layer_3': 3.442798734468884e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 155, 'n_units_Layer_3': 230}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 13.41% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 10.75 | sMAPE for Test Set is: 21.13% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:08:11,315]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:08:11,687]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:08:17,415]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:08:41,163]\u001b[0m Trial 447 finished with value: 5.919128874338315 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009137236045078982, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2701719217769639, 'dropout_rate_Layer_2': 0.014634676999628643, 'dropout_rate_Layer_3': 0.2292153695878778, 'dropout_rate_Layer_4': 0.23339506709703403, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002066160715817407, 'l1_Layer_2': 0.022416597157964527, 'l1_Layer_3': 0.00033728667417610194, 'l1_Layer_4': 0.0011697557034726536, 'n_units_Layer_1': 185, 'n_units_Layer_2': 85, 'n_units_Layer_3': 55, 'n_units_Layer_4': 285}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.92 | sMAPE for Validation Set is: 14.56% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 9.58 | sMAPE for Test Set is: 18.65% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:08:46,621]\u001b[0m Trial 446 finished with value: 5.731753647820242 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005521470197038253, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.287662199989626, 'dropout_rate_Layer_2': 0.2026044058508873, 'dropout_rate_Layer_3': 0.2148416038897865, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.012522716171558725, 'l1_Layer_2': 0.007565105932013781, 'l1_Layer_3': 6.847346928759947e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 150, 'n_units_Layer_3': 200}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 13.99% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 9.10 | sMAPE for Test Set is: 17.61% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:08:48,781]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:08:51,739]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:08:54,534]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:08:56,047]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:09:29,157]\u001b[0m Trial 455 finished with value: 7.861646936512526 and parameters: {'n_hidden': 4, 'learning_rate': 0.015340950322231567, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14158060578175313, 'dropout_rate_Layer_2': 0.01672254009391086, 'dropout_rate_Layer_3': 0.03300489827674316, 'dropout_rate_Layer_4': 0.32272278971569174, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.6576478531537758e-05, 'l1_Layer_2': 0.004021476823846034, 'l1_Layer_3': 0.00035565785241446676, 'l1_Layer_4': 0.0007345244234782716, 'n_units_Layer_1': 260, 'n_units_Layer_2': 220, 'n_units_Layer_3': 270, 'n_units_Layer_4': 185}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.86 | sMAPE for Validation Set is: 19.53% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 18.56 | sMAPE for Test Set is: 39.95% | rMAE for Test Set is: 2.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:09:33,563]\u001b[0m Trial 456 finished with value: 6.538005010899664 and parameters: {'n_hidden': 4, 'learning_rate': 0.01681544248203761, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13630390590568167, 'dropout_rate_Layer_2': 0.016894309115229746, 'dropout_rate_Layer_3': 0.02216841957531257, 'dropout_rate_Layer_4': 0.12246420331777018, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4711006350125714e-05, 'l1_Layer_2': 0.018023095907850003, 'l1_Layer_3': 0.00023943348167490466, 'l1_Layer_4': 0.0010377007176615297, 'n_units_Layer_1': 255, 'n_units_Layer_2': 215, 'n_units_Layer_3': 220, 'n_units_Layer_4': 190}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 16.16% | rMAE for Validation Set is: 0.95\n",
      "MAE for Test Set is: 10.64 | sMAPE for Test Set is: 21.24% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:09:37,259]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:09:41,640]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:09:46,161]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:09:48,735]\u001b[0m Trial 457 finished with value: 5.684745268715159 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005010415373671178, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2825181680690704, 'dropout_rate_Layer_2': 0.19647260904592537, 'dropout_rate_Layer_3': 0.21195644621706952, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0126050659973935, 'l1_Layer_2': 0.0027779622246621644, 'l1_Layer_3': 2.2056347663328878e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 130, 'n_units_Layer_3': 205}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 13.91% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 8.86 | sMAPE for Test Set is: 17.17% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:09:50,181]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:09:54,150]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:09:57,993]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:10:03,906]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:10:04,692]\u001b[0m Trial 451 finished with value: 5.654462077595444 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006160152882458857, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2754735996648321, 'dropout_rate_Layer_2': 0.37870041003055976, 'dropout_rate_Layer_3': 0.2132684024945062, 'dropout_rate_Layer_4': 0.15230052060703914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002819271257334977, 'l1_Layer_2': 0.02277790386341821, 'l1_Layer_3': 0.000662337993575748, 'l1_Layer_4': 0.0011356134151537707, 'n_units_Layer_1': 185, 'n_units_Layer_2': 90, 'n_units_Layer_3': 50, 'n_units_Layer_4': 270}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 13.80% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 9.50 | sMAPE for Test Set is: 18.43% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:10:12,043]\u001b[0m Trial 458 finished with value: 5.7345489383764985 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005399554748854023, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2861572526445743, 'dropout_rate_Layer_2': 0.18429873904166888, 'dropout_rate_Layer_3': 0.15584388434471622, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01372912623128655, 'l1_Layer_2': 0.006284843296572167, 'l1_Layer_3': 1.043752505757316e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 150, 'n_units_Layer_3': 205}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:10:12,175]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 14.03% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 9.21 | sMAPE for Test Set is: 17.87% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:10:13,066]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:10:18,292]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:10:20,627]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:10:21,695]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:10:23,380]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:10:23,795]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:10:24,519]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:10:31,092]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:10:34,827]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:10:39,224]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:10:43,057]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:10:48,764]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:10:55,274]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:10:55,831]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:11:00,628]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:11:01,923]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:11:02,670]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:11:08,213]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:11:08,971]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:11:14,102]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:11:36,595]\u001b[0m Trial 474 finished with value: 5.442262921848332 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005114054254987916, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2836452959292859, 'dropout_rate_Layer_2': 0.20409972229429885, 'dropout_rate_Layer_3': 0.15434958447471578, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003976920174259914, 'l1_Layer_2': 0.0027485833808352303, 'l1_Layer_3': 1.0690232692732463e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 205}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 13.10% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.98 | sMAPE for Test Set is: 15.26% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:11:38,679]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:11:40,885]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:11:46,405]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:11:56,795]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:12:01,296]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:12:04,790]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:12:05,036]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:12:10,540]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:12:17,259]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:12:27,684]\u001b[0m Trial 490 finished with value: 5.710444597780595 and parameters: {'n_hidden': 3, 'learning_rate': 0.013145662166318618, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11598205329901817, 'dropout_rate_Layer_2': 0.04960844786172094, 'dropout_rate_Layer_3': 0.06340213128764748, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0185493748609327e-05, 'l1_Layer_2': 0.00029267377241146077, 'l1_Layer_3': 5.494880627659226e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 185, 'n_units_Layer_3': 300}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 14.06% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 11.70 | sMAPE for Test Set is: 23.14% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:12:35,376]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:12:40,005]\u001b[0m Trial 489 finished with value: 5.613457842024123 and parameters: {'n_hidden': 3, 'learning_rate': 0.013097823499702364, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.113543415802012, 'dropout_rate_Layer_2': 0.045119570659931565, 'dropout_rate_Layer_3': 0.06266405270723008, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9481615751899503e-05, 'l1_Layer_2': 0.00152525202712539, 'l1_Layer_3': 4.464475713109915e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 190, 'n_units_Layer_3': 85}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 13.65% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 11.75 | sMAPE for Test Set is: 23.32% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:12:43,534]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:12:50,042]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:13:22,724]\u001b[0m Trial 499 finished with value: 5.5596225969129875 and parameters: {'n_hidden': 3, 'learning_rate': 0.011556789446082153, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11380927878419342, 'dropout_rate_Layer_2': 0.04752851429905448, 'dropout_rate_Layer_3': 0.060910582612989865, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.042510961127277e-05, 'l1_Layer_2': 0.00030875964970861913, 'l1_Layer_3': 6.528082598888716e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 165, 'n_units_Layer_3': 300}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 13.57% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 11.57 | sMAPE for Test Set is: 22.82% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:13:29,443]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:13:34,286]\u001b[0m Trial 500 finished with value: 5.618060878073481 and parameters: {'n_hidden': 3, 'learning_rate': 0.01287941709968807, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1195922291136811, 'dropout_rate_Layer_2': 0.04420315152562127, 'dropout_rate_Layer_3': 0.07021081047515898, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1468845447131314e-05, 'l1_Layer_2': 0.001565670348941126, 'l1_Layer_3': 0.0009411194353584811, 'n_units_Layer_1': 70, 'n_units_Layer_2': 165, 'n_units_Layer_3': 235}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 13.62% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 11.62 | sMAPE for Test Set is: 22.97% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:13:34,478]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:13:42,216]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:13:47,034]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:13:50,241]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:13:55,812]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:13:59,042]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:00,510]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:03,151]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:07,626]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:08,520]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:13,359]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:17,241]\u001b[0m Trial 505 finished with value: 5.650030538072355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006726772003076947, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32199391852618464, 'dropout_rate_Layer_2': 0.24856827112226074, 'dropout_rate_Layer_3': 0.2226648044062758, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0062724061793227644, 'l1_Layer_2': 0.001236948559460925, 'l1_Layer_3': 6.708285316666983e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 145, 'n_units_Layer_3': 170}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 13.82% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 9.00 | sMAPE for Test Set is: 17.49% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:14:20,016]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:23,039]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:26,280]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:26,739]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:31,457]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:34,178]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:34,694]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:37,972]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:41,880]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:50,941]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:51,336]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:56,801]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:14:59,671]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:15:03,388]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:15:07,173]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:15:12,198]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:15:29,048]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:15:33,327]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:15:34,233]\u001b[0m Trial 536 finished with value: 5.389454822966506 and parameters: {'n_hidden': 3, 'learning_rate': 0.007885888019974988, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20562709809860819, 'dropout_rate_Layer_2': 0.07618373856804928, 'dropout_rate_Layer_3': 0.04292532360858945, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.0062414499866726e-05, 'l1_Layer_2': 0.00017516909517169597, 'l1_Layer_3': 1.5419230771477857e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 250, 'n_units_Layer_3': 260}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 13.41% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 10.43 | sMAPE for Test Set is: 20.58% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:15:40,280]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:15:44,111]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:15:46,327]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:15:49,536]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:15:51,771]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:15:54,223]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:15:54,532]\u001b[0m Trial 528 finished with value: 5.738566902798202 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016579162494490185, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16875377876915884, 'dropout_rate_Layer_2': 0.39882081909789285, 'dropout_rate_Layer_3': 0.21387611237356027, 'dropout_rate_Layer_4': 0.1050299815232469, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.014890832598449229, 'l1_Layer_2': 0.015785406986509404, 'l1_Layer_3': 0.00021398185669864328, 'l1_Layer_4': 0.0020292777039236875, 'n_units_Layer_1': 180, 'n_units_Layer_2': 50, 'n_units_Layer_3': 75, 'n_units_Layer_4': 290}. Best is trial 253 with value: 5.351297452827183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 14.01% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 9.84 | sMAPE for Test Set is: 19.10% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:16:14,487]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:16:19,786]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:16:30,889]\u001b[0m Trial 517 finished with value: 5.347748762287019 and parameters: {'n_hidden': 3, 'learning_rate': 0.007897265397950567, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21156610974456816, 'dropout_rate_Layer_2': 0.07309354176120308, 'dropout_rate_Layer_3': 0.04185703484183796, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.0292217644603204e-05, 'l1_Layer_2': 0.00018387600253655267, 'l1_Layer_3': 1.730957794146248e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 200, 'n_units_Layer_3': 265}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 13.01% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 9.62 | sMAPE for Test Set is: 18.78% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:16:34,582]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:16:39,573]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:16:45,251]\u001b[0m Trial 547 finished with value: 5.488561426456635 and parameters: {'n_hidden': 3, 'learning_rate': 0.006062885267353962, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18924177756362678, 'dropout_rate_Layer_2': 0.07490367575630238, 'dropout_rate_Layer_3': 0.04745795605510185, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.827223253348665e-05, 'l1_Layer_2': 4.6706275348851416e-05, 'l1_Layer_3': 1.4331373861900543e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 13.39% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 10.65 | sMAPE for Test Set is: 21.15% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:16:51,508]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:16:57,083]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:17:02,224]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:17:05,487]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:17:08,874]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:17:12,727]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:17:16,509]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:17:17,016]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:17:21,449]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:17:22,023]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:17:26,463]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:17:27,393]\u001b[0m Trial 545 finished with value: 5.735387804601445 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014497282596200045, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16210147516339357, 'dropout_rate_Layer_2': 0.3990563613386587, 'dropout_rate_Layer_3': 0.2254586354892056, 'dropout_rate_Layer_4': 0.10134628543881868, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.013455323815889857, 'l1_Layer_2': 0.01295392883525223, 'l1_Layer_3': 0.0002348365756403937, 'l1_Layer_4': 0.0020793362021072066, 'n_units_Layer_1': 175, 'n_units_Layer_2': 50, 'n_units_Layer_3': 75, 'n_units_Layer_4': 300}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 14.00% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 9.45 | sMAPE for Test Set is: 18.27% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:17:39,740]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:17:43,655]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:17:47,406]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:17:55,569]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:18:00,089]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:18:05,257]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:18:10,949]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:18:14,897]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:18:18,730]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:18:24,040]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:18:27,762]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:18:34,077]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:18:34,859]\u001b[0m Trial 563 finished with value: 5.680910783488879 and parameters: {'n_hidden': 3, 'learning_rate': 0.00059712068693023, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34991240440212534, 'dropout_rate_Layer_2': 0.22856074992617592, 'dropout_rate_Layer_3': 0.17292703398819076, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011706238532030646, 'l1_Layer_2': 0.005548715506001667, 'l1_Layer_3': 1.864312425465595e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 100, 'n_units_Layer_3': 215}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 13.90% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 8.94 | sMAPE for Test Set is: 17.27% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:18:39,432]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:18:42,395]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:18:45,171]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:18:48,040]\u001b[0m Trial 567 finished with value: 5.710282087299411 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006063782464846413, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3494373908117605, 'dropout_rate_Layer_2': 0.2336805205519178, 'dropout_rate_Layer_3': 0.19543361901448825, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009070560818602018, 'l1_Layer_2': 0.003559414113543649, 'l1_Layer_3': 2.09541756209394e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 120, 'n_units_Layer_3': 215}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 14.00% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 9.17 | sMAPE for Test Set is: 17.82% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:18:48,619]\u001b[0m Trial 548 finished with value: 5.724437754833498 and parameters: {'n_hidden': 4, 'learning_rate': 0.002055484852904267, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1511897923148319, 'dropout_rate_Layer_2': 0.3841133780940638, 'dropout_rate_Layer_3': 0.21121512879632834, 'dropout_rate_Layer_4': 0.09954134673308115, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.021497700994927423, 'l1_Layer_2': 0.014244257285263186, 'l1_Layer_3': 0.00015398789996732163, 'l1_Layer_4': 0.002894685899818613, 'n_units_Layer_1': 145, 'n_units_Layer_2': 50, 'n_units_Layer_3': 95, 'n_units_Layer_4': 90}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 13.98% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 9.52 | sMAPE for Test Set is: 18.48% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:18:49,330]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:18:49,389]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:18:51,843]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:19:01,419]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:19:06,301]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:19:06,917]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:19:12,261]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:19:12,980]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:19:17,983]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:19:21,054]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:19:25,600]\u001b[0m Trial 585 finished with value: 5.359855537139282 and parameters: {'n_hidden': 3, 'learning_rate': 0.006378491161449068, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2026373463566447, 'dropout_rate_Layer_2': 0.06989176903475235, 'dropout_rate_Layer_3': 0.0420573253236793, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.862136887233993e-05, 'l1_Layer_2': 3.9382512866992924e-05, 'l1_Layer_3': 1.3105726393439845e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 13.06% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 9.59 | sMAPE for Test Set is: 19.25% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:19:34,497]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:19:47,058]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:19:51,331]\u001b[0m Trial 592 finished with value: 5.441724557592438 and parameters: {'n_hidden': 3, 'learning_rate': 0.00609250750571239, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22009181641479272, 'dropout_rate_Layer_2': 0.12616768779837573, 'dropout_rate_Layer_3': 0.03674661360306171, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.2026783271872073e-05, 'l1_Layer_2': 5.4070294715269376e-05, 'l1_Layer_3': 1.0305611576171999e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 265, 'n_units_Layer_3': 275}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 13.34% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 8.99 | sMAPE for Test Set is: 17.62% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:19:55,394]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:19:57,908]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:20:05,074]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:20:13,884]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:20:17,873]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:20:20,655]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:20:25,601]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:20:26,090]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:20:30,640]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:20:32,306]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:20:35,398]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:20:36,635]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:20:41,180]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:20:46,494]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:20:52,672]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:21:03,516]\u001b[0m Trial 607 finished with value: 5.585775975728168 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007344661526987145, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3394087159913652, 'dropout_rate_Layer_2': 0.2575532151169031, 'dropout_rate_Layer_3': 0.1419215171124556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.7333876838524404e-05, 'l1_Layer_2': 0.00017046117530539654, 'l1_Layer_3': 2.7580597667821538e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 120, 'n_units_Layer_3': 230}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 13.43% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 13.34 | sMAPE for Test Set is: 26.78% | rMAE for Test Set is: 1.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:21:05,499]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:21:09,561]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 13.97% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 9.48 | sMAPE for Test Set is: 18.38% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:21:11,551]\u001b[0m Trial 591 finished with value: 5.719636602357334 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017235628643493585, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15927646114100003, 'dropout_rate_Layer_2': 0.35160014734893075, 'dropout_rate_Layer_3': 0.22317919158906208, 'dropout_rate_Layer_4': 0.09283533746507308, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.041558994090916006, 'l1_Layer_2': 0.015906693282078173, 'l1_Layer_3': 0.0001013362665976613, 'l1_Layer_4': 0.002517599889694995, 'n_units_Layer_1': 180, 'n_units_Layer_2': 60, 'n_units_Layer_3': 100, 'n_units_Layer_4': 115}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:21:19,164]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:21:21,120]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:21:21,791]\u001b[0m Trial 599 finished with value: 5.789016277430442 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016913277402314491, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1699411848117089, 'dropout_rate_Layer_2': 0.3749613717404293, 'dropout_rate_Layer_3': 0.2409018483544675, 'dropout_rate_Layer_4': 0.06774623730961832, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.011718507841114776, 'l1_Layer_2': 0.004924743833183669, 'l1_Layer_3': 0.00010356057483226565, 'l1_Layer_4': 0.002337749335896415, 'n_units_Layer_1': 165, 'n_units_Layer_2': 70, 'n_units_Layer_3': 65, 'n_units_Layer_4': 100}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 14.14% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 9.98 | sMAPE for Test Set is: 19.46% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:21:26,878]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:21:28,874]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:21:32,948]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:21:36,552]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:21:39,041]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:21:43,435]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:21:46,532]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:21:50,654]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:21:50,895]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:21:56,663]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:22:00,453]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:22:00,503]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:22:05,994]\u001b[0m Trial 616 finished with value: 5.538169177826113 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007615715394162161, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3477489388607689, 'dropout_rate_Layer_2': 0.2625281020840908, 'dropout_rate_Layer_3': 0.11646591510073699, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021682007776795592, 'l1_Layer_2': 0.0001548372864228023, 'l1_Layer_3': 2.5857319812882208e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 125, 'n_units_Layer_3': 230}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 13.36% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 12.28 | sMAPE for Test Set is: 24.13% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:22:08,344]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:22:10,493]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:22:15,610]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:22:15,746]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:22:24,226]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:22:29,368]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:22:32,864]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:22:38,323]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:22:43,019]\u001b[0m Trial 633 finished with value: 5.602915308089229 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008458907888907449, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3462729700820001, 'dropout_rate_Layer_2': 0.22797128510301023, 'dropout_rate_Layer_3': 0.12916000353486462, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.787785539913371e-05, 'l1_Layer_2': 0.0002703815504470244, 'l1_Layer_3': 1.3489452883584214e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 95, 'n_units_Layer_3': 215}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 13.46% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.16 | sMAPE for Test Set is: 23.95% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:22:46,805]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 12.93% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 13.06 | sMAPE for Test Set is: 26.08% | rMAE for Test Set is: 1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:22:48,293]\u001b[0m Trial 626 finished with value: 5.384951943001489 and parameters: {'n_hidden': 3, 'learning_rate': 0.00060544584200953, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3125209079833214, 'dropout_rate_Layer_2': 0.28210612001294677, 'dropout_rate_Layer_3': 0.13972015479074607, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010875625163171113, 'l1_Layer_2': 5.096213236915129e-05, 'l1_Layer_3': 4.9451323191966406e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 140, 'n_units_Layer_3': 230}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:22:54,585]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:22:54,838]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:23:00,819]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:23:05,226]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:23:05,510]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 13.55% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 9.48 | sMAPE for Test Set is: 19.28% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:23:08,093]\u001b[0m Trial 639 finished with value: 5.446354971713416 and parameters: {'n_hidden': 3, 'learning_rate': 0.008612612871240507, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20175576559396938, 'dropout_rate_Layer_2': 0.1264585207318146, 'dropout_rate_Layer_3': 0.0825632061493517, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.3835402355199706e-05, 'l1_Layer_2': 5.755000387246754e-05, 'l1_Layer_3': 1.7947340073164463e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 265, 'n_units_Layer_3': 260}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:23:11,818]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:23:12,425]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:23:13,317]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:23:17,489]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:23:20,350]\u001b[0m Trial 641 finished with value: 5.5340385489712425 and parameters: {'n_hidden': 3, 'learning_rate': 0.008228240798155213, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19913401048393056, 'dropout_rate_Layer_2': 0.125637196573414, 'dropout_rate_Layer_3': 0.01643577724594497, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.198288088590036e-05, 'l1_Layer_2': 5.2306256445056736e-05, 'l1_Layer_3': 1.98560441179626e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 260, 'n_units_Layer_3': 260}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 13.64% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 9.79 | sMAPE for Test Set is: 19.70% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:23:23,706]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:23:27,297]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:23:35,334]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:23:37,076]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:23:42,861]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:23:46,995]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:23:51,542]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:23:55,360]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:23:59,859]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:24:00,704]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:24:05,068]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:24:09,694]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:24:13,173]\u001b[0m Trial 656 finished with value: 5.424524238762243 and parameters: {'n_hidden': 3, 'learning_rate': 0.004991036368056105, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22567398638262065, 'dropout_rate_Layer_2': 0.09519133649701803, 'dropout_rate_Layer_3': 0.08655501990955344, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.787283990034451e-05, 'l1_Layer_2': 2.6556659583694728e-05, 'l1_Layer_3': 2.4962533831950073e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 245, 'n_units_Layer_3': 280}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 13.32% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 8.95 | sMAPE for Test Set is: 17.81% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:24:24,927]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:24:29,951]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:24:33,231]\u001b[0m Trial 663 finished with value: 5.6697974286265875 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008580278234816979, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37022408667236284, 'dropout_rate_Layer_2': 0.25048309180426026, 'dropout_rate_Layer_3': 0.12842839758696717, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019098584342216825, 'l1_Layer_2': 1.5512863679225374e-05, 'l1_Layer_3': 9.301037493512051e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 85, 'n_units_Layer_3': 225}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 13.64% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 11.65 | sMAPE for Test Set is: 22.94% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:24:34,427]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:24:38,807]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:24:44,761]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:24:48,359]\u001b[0m Trial 655 finished with value: 5.395033833008238 and parameters: {'n_hidden': 3, 'learning_rate': 0.000896764907570853, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3257917312686971, 'dropout_rate_Layer_2': 0.3189065634405, 'dropout_rate_Layer_3': 0.12349975044963889, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.6907886098294805e-05, 'l1_Layer_2': 3.776641107205619e-05, 'l1_Layer_3': 4.7346633325151644e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 95, 'n_units_Layer_3': 245}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 12.91% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 12.44 | sMAPE for Test Set is: 24.52% | rMAE for Test Set is: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:24:54,061]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:24:56,772]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:25:02,058]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:25:05,104]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:25:06,241]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:25:11,072]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:25:16,381]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:25:23,571]\u001b[0m Trial 669 finished with value: 5.364106049155834 and parameters: {'n_hidden': 3, 'learning_rate': 0.004350777130194509, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15475354704313193, 'dropout_rate_Layer_2': 0.08232824378326295, 'dropout_rate_Layer_3': 0.032156825904228616, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.718318261998419e-05, 'l1_Layer_2': 1.0770325208022904e-05, 'l1_Layer_3': 2.9974405027113327e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 280, 'n_units_Layer_3': 280}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 13.08% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 7.70 | sMAPE for Test Set is: 14.93% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:25:29,051]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:25:29,996]\u001b[0m Trial 670 finished with value: 5.531384892441484 and parameters: {'n_hidden': 3, 'learning_rate': 0.004556224641045493, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23119426154028563, 'dropout_rate_Layer_2': 0.09528164658275662, 'dropout_rate_Layer_3': 0.02631447797271386, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.1363612325687025e-05, 'l1_Layer_2': 1.0451923701752838e-05, 'l1_Layer_3': 3.2126821571857275e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 280, 'n_units_Layer_3': 280}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 13.49% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 8.24 | sMAPE for Test Set is: 15.45% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:25:35,016]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:25:35,507]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:25:41,099]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:25:41,338]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:25:42,656]\u001b[0m Trial 678 finished with value: 5.460012584704927 and parameters: {'n_hidden': 3, 'learning_rate': 0.004101967199642402, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23488546836656002, 'dropout_rate_Layer_2': 0.09570514997052935, 'dropout_rate_Layer_3': 0.032857407567619394, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.611288914833925e-05, 'l1_Layer_2': 2.8329601602705924e-05, 'l1_Layer_3': 2.9303767929532457e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 235, 'n_units_Layer_3': 245}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 13.35% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 10.66 | sMAPE for Test Set is: 21.34% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:25:49,251]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:25:49,650]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:26:00,697]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:26:04,682]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:26:05,331]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:26:11,003]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:26:14,234]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:26:15,297]\u001b[0m Trial 683 finished with value: 5.59168801035073 and parameters: {'n_hidden': 3, 'learning_rate': 0.003035427697445332, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14928142050398044, 'dropout_rate_Layer_2': 0.0844776560966812, 'dropout_rate_Layer_3': 0.007320001816168598, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4314724364523894e-05, 'l1_Layer_2': 2.3715143949218928e-05, 'l1_Layer_3': 2.8491406009150632e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 240, 'n_units_Layer_3': 250}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 13.59% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 9.08 | sMAPE for Test Set is: 17.95% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:26:17,818]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:26:21,761]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:26:24,572]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:26:27,489]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:26:30,583]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:26:33,730]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:26:40,331]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:26:40,550]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 13.40% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.07 | sMAPE for Test Set is: 23.68% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:26:45,269]\u001b[0m Trial 690 finished with value: 5.580022756462878 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010904207192875659, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39026667392113606, 'dropout_rate_Layer_2': 0.3151996017313325, 'dropout_rate_Layer_3': 0.06845193663959595, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.828290050883279e-05, 'l1_Layer_2': 2.444947959654402e-05, 'l1_Layer_3': 0.00012369652387468052, 'n_units_Layer_1': 70, 'n_units_Layer_2': 160, 'n_units_Layer_3': 270}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:26:48,663]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:26:50,825]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:26:54,983]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:26:58,863]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:02,408]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:05,002]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:08,566]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:08,976]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:14,715]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:15,271]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:17,549]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 13.36% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 12.32 | sMAPE for Test Set is: 24.30% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:27:18,918]\u001b[0m Trial 698 finished with value: 5.545001659553144 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008401658615202166, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37396379871657653, 'dropout_rate_Layer_2': 0.25437386604647955, 'dropout_rate_Layer_3': 0.1301243600693657, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002247061857660452, 'l1_Layer_2': 1.587225108957551e-05, 'l1_Layer_3': 8.590196623748629e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 85, 'n_units_Layer_3': 225}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:20,338]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:22,505]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:26,568]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:29,131]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:33,896]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:34,617]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:36,884]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:39,704]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:42,732]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:45,241]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:47,260]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:47,918]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:48,669]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:50,224]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:57,023]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:57,562]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:27:57,816]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:06,957]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:07,532]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:10,951]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:14,032]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:14,863]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:15,890]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:21,372]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:21,991]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:26,963]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:32,041]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:32,526]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:37,402]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:38,058]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:43,105]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:46,185]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:46,739]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:54,577]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:54,918]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:28:55,244]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:29:02,854]\u001b[0m Trial 742 finished with value: 5.591511766355576 and parameters: {'n_hidden': 3, 'learning_rate': 0.004842050697423791, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20789465099004745, 'dropout_rate_Layer_2': 0.1090933959968863, 'dropout_rate_Layer_3': 0.07507504634006068, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3553787480144037e-05, 'l1_Layer_2': 1.755379083963291e-05, 'l1_Layer_3': 4.260525361114427e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 250, 'n_units_Layer_3': 230}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 13.89% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 11.91 | sMAPE for Test Set is: 25.11% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:29:03,310]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:29:03,867]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:29:10,548]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:29:13,188]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:29:17,103]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:29:21,012]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:29:24,657]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:29:26,175]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:29:32,046]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:29:38,969]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:29:41,929]\u001b[0m Trial 756 finished with value: 5.590475998129037 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026939282579168697, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1656885967585778, 'dropout_rate_Layer_2': 0.14693042826077096, 'dropout_rate_Layer_3': 0.08929178823256102, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3159256989750561e-05, 'l1_Layer_2': 0.00017850215683240533, 'l1_Layer_3': 1.480774909332175e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 225, 'n_units_Layer_3': 265}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 13.73% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 11.92 | sMAPE for Test Set is: 23.72% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:29:44,883]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:29:48,019]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:29:49,837]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:29:50,438]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:29:53,065]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:29:58,854]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:30:03,137]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:30:06,166]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:30:08,798]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:30:12,527]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:30:13,152]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:30:14,030]\u001b[0m Trial 769 finished with value: 5.483840771209817 and parameters: {'n_hidden': 3, 'learning_rate': 0.005821737725447497, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22859581740546522, 'dropout_rate_Layer_2': 0.06697775181977522, 'dropout_rate_Layer_3': 0.04241964586035868, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.694738882013771e-05, 'l1_Layer_2': 0.00011683362051311525, 'l1_Layer_3': 3.905842423039699e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 285, 'n_units_Layer_3': 290}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 13.34% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 10.85 | sMAPE for Test Set is: 21.23% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:30:21,188]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:30:24,473]\u001b[0m Trial 763 finished with value: 5.490300512251685 and parameters: {'n_hidden': 3, 'learning_rate': 0.0058506394455174, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1665456061456356, 'dropout_rate_Layer_2': 0.02780229230245091, 'dropout_rate_Layer_3': 0.0002734740472388683, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.023180181165130584, 'l1_Layer_2': 9.587009428257833e-05, 'l1_Layer_3': 1.3121254691963458e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 280, 'n_units_Layer_3': 290}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 13.54% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.77 | sMAPE for Test Set is: 15.10% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:30:27,034]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:30:30,042]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:30:32,309]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:30:34,736]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:30:39,129]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:30:43,038]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:30:47,990]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:30:51,862]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:30:51,913]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 13.39% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 11.45 | sMAPE for Test Set is: 22.62% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:30:55,558]\u001b[0m Trial 778 finished with value: 5.483799705869437 and parameters: {'n_hidden': 3, 'learning_rate': 0.004793746855583029, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02300296169277432, 'dropout_rate_Layer_2': 0.20615574913970425, 'dropout_rate_Layer_3': 0.023033838184315585, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006606466827727723, 'l1_Layer_2': 0.00016880775716368254, 'l1_Layer_3': 3.143216141288739e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 145, 'n_units_Layer_3': 295}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:30:59,993]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:31:03,844]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:31:04,443]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:31:15,120]\u001b[0m Trial 780 finished with value: 5.5527491904992194 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006786783235687263, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32768728294227284, 'dropout_rate_Layer_2': 0.23767002245341953, 'dropout_rate_Layer_3': 0.1488108414320632, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.817322900543587e-05, 'l1_Layer_2': 1.033265417333752e-05, 'l1_Layer_3': 0.00012380312467350735, 'n_units_Layer_1': 115, 'n_units_Layer_2': 160, 'n_units_Layer_3': 265}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 13.31% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 11.66 | sMAPE for Test Set is: 22.85% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:31:30,194]\u001b[0m Trial 789 finished with value: 5.449150734622606 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007922792379832376, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2996655244926919, 'dropout_rate_Layer_2': 0.25327602371204005, 'dropout_rate_Layer_3': 0.09450785693333891, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002852424102815248, 'l1_Layer_2': 4.401392941597539e-05, 'l1_Layer_3': 4.740279706388113e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 125, 'n_units_Layer_3': 220}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 13.08% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 12.14 | sMAPE for Test Set is: 23.89% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:31:34,758]\u001b[0m Trial 792 finished with value: 5.350210499106393 and parameters: {'n_hidden': 3, 'learning_rate': 0.009337652833316373, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.241298358996879, 'dropout_rate_Layer_2': 0.09204556336637683, 'dropout_rate_Layer_3': 0.05345508525463338, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.0043563890344656e-05, 'l1_Layer_2': 5.420688422632182e-05, 'l1_Layer_3': 1.9898929973284234e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 270, 'n_units_Layer_3': 255}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 13.12% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 8.80 | sMAPE for Test Set is: 17.50% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:31:37,143]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:31:38,132]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:31:50,695]\u001b[0m Trial 793 finished with value: 5.599613263016528 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010001399182859192, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3395266997998229, 'dropout_rate_Layer_2': 0.25682139661188835, 'dropout_rate_Layer_3': 0.16466646706009816, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3665964069501105e-05, 'l1_Layer_2': 2.4532739026891656e-05, 'l1_Layer_3': 0.00016112183667375184, 'n_units_Layer_1': 100, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 13.45% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.01 | sMAPE for Test Set is: 23.63% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:31:56,357]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:31:57,843]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:32:01,974]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:32:02,657]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:32:03,290]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:32:09,746]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:32:12,796]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:32:13,055]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:32:13,300]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:32:13,848]\u001b[0m Trial 796 finished with value: 5.4115725597589375 and parameters: {'n_hidden': 3, 'learning_rate': 0.004046988965709121, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26661846876090445, 'dropout_rate_Layer_2': 0.08610801823043224, 'dropout_rate_Layer_3': 0.05376509699041205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.9293192405266313e-05, 'l1_Layer_2': 6.729988952075208e-05, 'l1_Layer_3': 2.130704656801397e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 270, 'n_units_Layer_3': 275}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 13.49% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 9.15 | sMAPE for Test Set is: 18.42% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:32:21,075]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:32:21,454]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:32:23,429]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:32:23,566]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:32:29,780]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:32:33,088]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:32:33,557]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:32:37,441]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:32:42,644]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:32:46,049]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:33:02,011]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:33:09,255]\u001b[0m Trial 815 finished with value: 5.441592461343585 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036296368105551385, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2646889448842786, 'dropout_rate_Layer_2': 0.00854321292895801, 'dropout_rate_Layer_3': 0.0934667816629357, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.431473316600331e-05, 'l1_Layer_2': 7.147272948212065e-05, 'l1_Layer_3': 2.105603635746009e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 275, 'n_units_Layer_3': 255}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 13.38% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 8.73 | sMAPE for Test Set is: 17.14% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:33:14,070]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:33:17,853]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:33:21,386]\u001b[0m Trial 817 finished with value: 5.50624097333052 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005706215443567097, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2644765759136112, 'dropout_rate_Layer_2': 0.2768234111137054, 'dropout_rate_Layer_3': 0.09736884591423677, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011457641791226324, 'l1_Layer_2': 3.0400273887350425e-05, 'l1_Layer_3': 3.5787356247320626e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 155, 'n_units_Layer_3': 225}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 13.27% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 12.40 | sMAPE for Test Set is: 24.54% | rMAE for Test Set is: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:33:25,196]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:33:29,619]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:33:35,072]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:33:41,614]\u001b[0m Trial 819 finished with value: 5.423494322544147 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005631190157078599, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3134656219418952, 'dropout_rate_Layer_2': 0.2749176716409378, 'dropout_rate_Layer_3': 0.08653734899745257, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.59561121260118e-05, 'l1_Layer_2': 4.64542948589074e-05, 'l1_Layer_3': 3.5649595945063456e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 155, 'n_units_Layer_3': 245}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 13.02% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 12.61 | sMAPE for Test Set is: 24.95% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:33:41,975]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:33:47,826]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:33:48,215]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:33:54,518]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:33:58,967]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:00,939]\u001b[0m Trial 822 finished with value: 5.509635449876554 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007311521252224779, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30873245228013607, 'dropout_rate_Layer_2': 0.27577428072406984, 'dropout_rate_Layer_3': 0.09043901050770092, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010323976668542266, 'l1_Layer_2': 4.658016346563674e-05, 'l1_Layer_3': 3.7724475597935336e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 155, 'n_units_Layer_3': 245}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 13.30% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 12.37 | sMAPE for Test Set is: 24.46% | rMAE for Test Set is: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:34:04,522]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:05,013]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:11,458]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:12,215]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:17,837]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:21,925]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 13.84% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 12.51 | sMAPE for Test Set is: 24.91% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:34:23,763]\u001b[0m Trial 826 finished with value: 5.754360323520568 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010182443338371875, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24130608913034485, 'dropout_rate_Layer_2': 0.2748940723548608, 'dropout_rate_Layer_3': 0.09431119515202267, 'dropout_rate_Layer_4': 0.10685038926582696, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.933572752025938e-05, 'l1_Layer_2': 4.9221588739949345e-05, 'l1_Layer_3': 0.00034738447886567477, 'l1_Layer_4': 7.534793855899152e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 170, 'n_units_Layer_3': 290, 'n_units_Layer_4': 200}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:27,254]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:29,915]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:34,634]\u001b[0m Trial 830 finished with value: 5.436765183869688 and parameters: {'n_hidden': 3, 'learning_rate': 0.007769750558797353, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24184350395421275, 'dropout_rate_Layer_2': 0.0748051394354317, 'dropout_rate_Layer_3': 0.056710442686853275, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7630700963910613e-05, 'l1_Layer_2': 0.047388391348583546, 'l1_Layer_3': 5.602415239516537e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 175, 'n_units_Layer_3': 240}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 13.41% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 11.21 | sMAPE for Test Set is: 22.20% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:34:37,060]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:37,380]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:38,728]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:44,213]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:45,054]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:49,675]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:49,839]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:50,455]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:50,497]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:34:58,757]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:02,497]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:04,174]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:04,232]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:05,746]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:15,758]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:19,677]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:23,497]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:26,016]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:28,844]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:31,717]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:34,793]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:35,461]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:39,822]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:40,435]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:40,770]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:46,287]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:49,382]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:51,877]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:55,730]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:35:56,689]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:36:02,062]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:36:02,154]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:36:08,466]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:36:13,323]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:36:16,400]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:36:20,716]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:36:25,512]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:36:30,357]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:36:34,086]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:36:37,962]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:36:45,019]\u001b[0m Trial 875 finished with value: 5.541355996584759 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005673135669534919, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3082924843998195, 'dropout_rate_Layer_2': 0.30195293832026343, 'dropout_rate_Layer_3': 0.08312733245267816, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012146810120946138, 'l1_Layer_2': 1.1426371237192925e-05, 'l1_Layer_3': 6.584926569372089e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 170, 'n_units_Layer_3': 235}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 13.29% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 12.05 | sMAPE for Test Set is: 23.70% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:36:49,572]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:37:00,490]\u001b[0m Trial 877 finished with value: 5.39424124802069 and parameters: {'n_hidden': 3, 'learning_rate': 0.007688231248707541, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23947239572052434, 'dropout_rate_Layer_2': 0.033522849863288365, 'dropout_rate_Layer_3': 0.042709654431671365, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3767152443596488e-05, 'l1_Layer_2': 0.03995500313103458, 'l1_Layer_3': 0.00020217417002043548, 'n_units_Layer_1': 65, 'n_units_Layer_2': 200, 'n_units_Layer_3': 235}. Best is trial 517 with value: 5.347748762287019.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 13.13% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 10.12 | sMAPE for Test Set is: 19.96% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:37:07,901]\u001b[0m Trial 883 finished with value: 5.3287725488922 and parameters: {'n_hidden': 3, 'learning_rate': 0.019815807052487196, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23829520510726948, 'dropout_rate_Layer_2': 0.0864737224655776, 'dropout_rate_Layer_3': 0.04250894314189217, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3022459079954306e-05, 'l1_Layer_2': 0.05022796043496425, 'l1_Layer_3': 0.00020540449773333446, 'n_units_Layer_1': 60, 'n_units_Layer_2': 190, 'n_units_Layer_3': 280}. Best is trial 883 with value: 5.3287725488922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 9.44 | sMAPE for Test Set is: 18.43% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:37:13,174]\u001b[0m Trial 871 finished with value: 5.404559245065158 and parameters: {'n_hidden': 3, 'learning_rate': 0.007231901963421816, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23416528634546158, 'dropout_rate_Layer_2': 0.09284720875837142, 'dropout_rate_Layer_3': 0.04590356200502124, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.4970668599934318e-05, 'l1_Layer_2': 0.0850679613916446, 'l1_Layer_3': 5.379942523851011e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 155, 'n_units_Layer_3': 240}. Best is trial 883 with value: 5.3287725488922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 13.10% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 9.23 | sMAPE for Test Set is: 17.86% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:37:21,110]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:37:29,849]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:37:33,527]\u001b[0m Trial 886 finished with value: 5.416856634195067 and parameters: {'n_hidden': 3, 'learning_rate': 0.007062015928420318, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23900083924674456, 'dropout_rate_Layer_2': 0.08692994245038381, 'dropout_rate_Layer_3': 0.04261677785310227, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.4485276140206808e-05, 'l1_Layer_2': 0.04697442493976338, 'l1_Layer_3': 2.1539638472310847e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 205, 'n_units_Layer_3': 235}. Best is trial 883 with value: 5.3287725488922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 13.21% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 10.42 | sMAPE for Test Set is: 20.61% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:37:43,304]\u001b[0m Trial 885 finished with value: 5.1256488683103845 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005624059610914016, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27882715041203576, 'dropout_rate_Layer_2': 0.2837050919673568, 'dropout_rate_Layer_3': 0.10146616370962833, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012591349623347717, 'l1_Layer_2': 4.498213215244725e-05, 'l1_Layer_3': 6.48528910143271e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 180, 'n_units_Layer_3': 235}. Best is trial 885 with value: 5.1256488683103845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 12.36% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 9.78 | sMAPE for Test Set is: 18.88% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:37:48,116]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:37:52,358]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:37:55,791]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:37:59,712]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:38:02,940]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:38:06,526]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:38:07,172]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:38:15,345]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:38:15,935]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:38:20,651]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:38:27,713]\u001b[0m Trial 890 finished with value: 5.163967410971998 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005739756320982288, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2750850310076231, 'dropout_rate_Layer_2': 0.3035677393042039, 'dropout_rate_Layer_3': 0.055291634458176274, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013311419136148798, 'l1_Layer_2': 4.604541616328143e-05, 'l1_Layer_3': 7.28256017368374e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 170, 'n_units_Layer_3': 220}. Best is trial 885 with value: 5.1256488683103845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 12.41% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 10.26 | sMAPE for Test Set is: 19.83% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:38:31,358]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:38:35,573]\u001b[0m Trial 893 finished with value: 5.4193377493657655 and parameters: {'n_hidden': 3, 'learning_rate': 0.006858287887541542, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.285443176416392, 'dropout_rate_Layer_2': 0.08534889037399761, 'dropout_rate_Layer_3': 0.031461086776558386, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.187844973113573e-05, 'l1_Layer_2': 0.0981515285854433, 'l1_Layer_3': 0.00023544240677645113, 'n_units_Layer_1': 60, 'n_units_Layer_2': 195, 'n_units_Layer_3': 235}. Best is trial 885 with value: 5.1256488683103845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 13.14% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 10.54 | sMAPE for Test Set is: 20.79% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:38:39,089]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:38:42,984]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:38:43,645]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:38:48,900]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:38:49,590]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:38:55,807]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:38:59,380]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:39:01,927]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:39:03,242]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:39:08,486]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:39:11,736]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:39:16,057]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:39:21,446]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:39:25,202]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:39:29,705]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:39:33,879]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:39:35,133]\u001b[0m Trial 904 finished with value: 5.136246424786871 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005459413028143919, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2220732828308242, 'dropout_rate_Layer_2': 0.2948009493546469, 'dropout_rate_Layer_3': 0.05635450339613495, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012799892362937154, 'l1_Layer_2': 4.939507735560297e-05, 'l1_Layer_3': 6.323742298601456e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 190, 'n_units_Layer_3': 220}. Best is trial 885 with value: 5.1256488683103845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 12.36% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 9.79 | sMAPE for Test Set is: 18.86% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:39:39,902]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:39:41,869]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:39:45,453]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:39:45,940]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:39:52,356]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 12.38% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 10.06 | sMAPE for Test Set is: 19.43% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:39:54,662]\u001b[0m Trial 912 finished with value: 5.155894178846917 and parameters: {'n_hidden': 3, 'learning_rate': 0.000570547924067799, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2648378928552053, 'dropout_rate_Layer_2': 0.28351500856259276, 'dropout_rate_Layer_3': 0.08258294503340832, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012799063915547778, 'l1_Layer_2': 7.646814119892797e-05, 'l1_Layer_3': 5.928123566276691e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 190, 'n_units_Layer_3': 220}. Best is trial 885 with value: 5.1256488683103845.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:39:59,475]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:40:07,004]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:40:13,297]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:40:16,805]\u001b[0m Trial 917 finished with value: 5.111040815765409 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005602823643237891, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26324267953725994, 'dropout_rate_Layer_2': 0.2843897486631843, 'dropout_rate_Layer_3': 0.057108358063309675, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.490026664588472e-05, 'l1_Layer_2': 7.18710561712459e-05, 'l1_Layer_3': 5.838295393674063e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 185, 'n_units_Layer_3': 220}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 12.32% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 9.51 | sMAPE for Test Set is: 18.27% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:40:26,100]\u001b[0m Trial 925 finished with value: 5.154872040819633 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005571665826563276, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2629563691797086, 'dropout_rate_Layer_2': 0.2816252077056353, 'dropout_rate_Layer_3': 0.0559850661910387, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000163824425048662, 'l1_Layer_2': 7.307631615383616e-05, 'l1_Layer_3': 3.2638811592570704e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 195, 'n_units_Layer_3': 220}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 12.40% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 9.99 | sMAPE for Test Set is: 19.25% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:40:30,407]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:40:30,865]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:40:31,227]\u001b[0m Trial 927 finished with value: 5.149175347820118 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005544721832311226, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2263396546970003, 'dropout_rate_Layer_2': 0.2833695453326993, 'dropout_rate_Layer_3': 0.04317209581880444, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016630585304796877, 'l1_Layer_2': 7.183069931299822e-05, 'l1_Layer_3': 4.650517315373528e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 195, 'n_units_Layer_3': 220}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 12.37% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 10.26 | sMAPE for Test Set is: 19.84% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:40:42,216]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:40:42,683]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:40:47,946]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:40:54,449]\u001b[0m Trial 931 finished with value: 5.176740997099565 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005453279134774894, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26472931705844954, 'dropout_rate_Layer_2': 0.2846651760510635, 'dropout_rate_Layer_3': 0.05737329732423058, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016779990586967902, 'l1_Layer_2': 4.6954889126426284e-05, 'l1_Layer_3': 7.73335409681127e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 195, 'n_units_Layer_3': 210}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 12.48% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 10.02 | sMAPE for Test Set is: 19.36% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:40:59,417]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:41:07,531]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:41:15,025]\u001b[0m Trial 934 finished with value: 5.153190359225707 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005756953549499588, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2531151915215126, 'dropout_rate_Layer_2': 0.2929245983500399, 'dropout_rate_Layer_3': 0.05435107090906537, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017846858779954077, 'l1_Layer_2': 8.678240730820323e-05, 'l1_Layer_3': 7.477978414554529e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 190, 'n_units_Layer_3': 220}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 9.33 | sMAPE for Test Set is: 17.92% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:41:19,826]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:41:26,007]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:41:30,576]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:41:35,592]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:41:42,713]\u001b[0m Trial 938 finished with value: 5.117995287603949 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005100209321594662, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2285830640023447, 'dropout_rate_Layer_2': 0.2843090062774169, 'dropout_rate_Layer_3': 0.057247571207429765, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001590920350670476, 'l1_Layer_2': 7.216788165803446e-05, 'l1_Layer_3': 5.821035725280619e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 195, 'n_units_Layer_3': 210}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 12.32% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 9.22 | sMAPE for Test Set is: 17.62% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:41:45,864]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:41:48,928]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:41:55,115]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:41:55,318]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:42:04,856]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:42:08,833]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:42:16,445]\u001b[0m Trial 939 finished with value: 5.460784220526783 and parameters: {'n_hidden': 3, 'learning_rate': 0.007224702386073602, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2582263041846852, 'dropout_rate_Layer_2': 0.05657505395006988, 'dropout_rate_Layer_3': 0.06784479183018471, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.551419545701666e-05, 'l1_Layer_2': 0.07170982845183756, 'l1_Layer_3': 0.00018362413969541777, 'n_units_Layer_1': 60, 'n_units_Layer_2': 210, 'n_units_Layer_3': 225}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 13.23% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 11.55 | sMAPE for Test Set is: 23.00% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:42:18,956]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:42:19,333]\u001b[0m Trial 942 finished with value: 5.121622844985521 and parameters: {'n_hidden': 3, 'learning_rate': 0.000552571117931818, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22363734586540807, 'dropout_rate_Layer_2': 0.33355128153428015, 'dropout_rate_Layer_3': 0.05767312214835302, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.482959517552669e-05, 'l1_Layer_2': 7.47497765941181e-05, 'l1_Layer_3': 7.645482400886835e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 210}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 12.26% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 9.83 | sMAPE for Test Set is: 18.91% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:42:20,341]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:42:27,662]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:42:30,033]\u001b[0m Trial 952 finished with value: 5.3268266569435925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006477756920666183, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22126039994611138, 'dropout_rate_Layer_2': 0.30766049425033104, 'dropout_rate_Layer_3': 0.05474273281912869, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017592567047718067, 'l1_Layer_2': 7.654116871043115e-05, 'l1_Layer_3': 7.509639894867656e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 200, 'n_units_Layer_3': 200}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 12.87% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 11.88 | sMAPE for Test Set is: 23.45% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:42:30,806]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:42:31,053]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:42:34,086]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:42:42,603]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:42:44,608]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:42:48,104]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:42:48,275]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:42:53,197]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:42:54,042]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:42:54,795]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:43:00,097]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:43:00,208]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:43:06,878]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:43:11,765]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:43:16,356]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:43:21,072]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:43:29,487]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:43:35,172]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:43:39,628]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:43:43,948]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:43:44,954]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:43:50,363]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:43:51,699]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 12.59% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 10.38 | sMAPE for Test Set is: 20.21% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:43:51,991]\u001b[0m Trial 965 finished with value: 5.190953880279868 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005452553861101134, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24034817460065894, 'dropout_rate_Layer_2': 0.33335122162192476, 'dropout_rate_Layer_3': 0.02505007671990533, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000313693187540232, 'l1_Layer_2': 6.81179329005647e-05, 'l1_Layer_3': 7.66497844259488e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 190, 'n_units_Layer_3': 195}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:43:55,405]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:43:56,106]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:43:57,931]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:44:07,095]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:44:07,654]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:44:15,512]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:44:19,283]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:44:19,711]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:44:27,749]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:44:50,535]\u001b[0m Trial 986 finished with value: 5.27365313154359 and parameters: {'n_hidden': 3, 'learning_rate': 0.00658872696667105, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26103611989941794, 'dropout_rate_Layer_2': 0.09055146053533542, 'dropout_rate_Layer_3': 0.026613763084337057, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.552564063408505e-05, 'l1_Layer_2': 0.08463487883514248, 'l1_Layer_3': 0.00024128089248470915, 'n_units_Layer_1': 60, 'n_units_Layer_2': 195, 'n_units_Layer_3': 240}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 12.73% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 11.27 | sMAPE for Test Set is: 22.48% | rMAE for Test Set is: 1.28\n",
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 12.86% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 11.97 | sMAPE for Test Set is: 23.77% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:44:53,242]\u001b[0m Trial 993 finished with value: 5.321960831381088 and parameters: {'n_hidden': 3, 'learning_rate': 0.000502560533287918, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2426436905439501, 'dropout_rate_Layer_2': 0.30731251543889865, 'dropout_rate_Layer_3': 0.03344430697453822, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.752622265624894e-05, 'l1_Layer_2': 7.889790417305542e-05, 'l1_Layer_3': 5.762017795566396e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 220, 'n_units_Layer_3': 200}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:44:57,740]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:44:58,506]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:45:03,781]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:45:04,000]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 12.71% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 11.18 | sMAPE for Test Set is: 22.02% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:45:09,913]\u001b[0m Trial 991 finished with value: 5.228809568486844 and parameters: {'n_hidden': 3, 'learning_rate': 0.000501588093414539, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24557529847769125, 'dropout_rate_Layer_2': 0.30838822420092626, 'dropout_rate_Layer_3': 0.057468265635163676, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017859036405021107, 'l1_Layer_2': 8.766648298289223e-05, 'l1_Layer_3': 0.00017973624228359602, 'n_units_Layer_1': 170, 'n_units_Layer_2': 215, 'n_units_Layer_3': 220}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:45:11,979]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:45:17,038]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:45:19,273]\u001b[0m Trial 990 finished with value: 5.317484260182583 and parameters: {'n_hidden': 3, 'learning_rate': 0.00662241248525903, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28891997546374376, 'dropout_rate_Layer_2': 0.09002560789886448, 'dropout_rate_Layer_3': 0.027463874507017705, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001964109847147677, 'l1_Layer_2': 0.05631413292753943, 'l1_Layer_3': 0.00023193196034843196, 'n_units_Layer_1': 60, 'n_units_Layer_2': 200, 'n_units_Layer_3': 240}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 12.87% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 8.21 | sMAPE for Test Set is: 15.74% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:45:23,321]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:45:24,016]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:45:30,053]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:45:33,756]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:45:39,464]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:45:41,982]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:45:45,158]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:45:47,646]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:45:49,299]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:45:53,336]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:45:54,307]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:45:55,375]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:46:06,597]\u001b[0m Trial 998 finished with value: 5.318661700440518 and parameters: {'n_hidden': 3, 'learning_rate': 0.006160571903624197, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2579671489459021, 'dropout_rate_Layer_2': 0.08674124761823515, 'dropout_rate_Layer_3': 0.011211321153770566, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.056895126250767e-05, 'l1_Layer_2': 0.03583562296680996, 'l1_Layer_3': 0.00028105504388455506, 'n_units_Layer_1': 70, 'n_units_Layer_2': 210, 'n_units_Layer_3': 260}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 13.05% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 8.61 | sMAPE for Test Set is: 16.39% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:46:11,167]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:46:15,438]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:46:20,472]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:46:25,247]\u001b[0m Trial 1013 finished with value: 5.331165655391842 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005698446390477382, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19003070117558737, 'dropout_rate_Layer_2': 0.2995595357080827, 'dropout_rate_Layer_3': 0.060081034276184, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001801951971913048, 'l1_Layer_2': 6.714328704485813e-05, 'l1_Layer_3': 6.18457181360828e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 180, 'n_units_Layer_3': 210}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 12.93% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 12.10 | sMAPE for Test Set is: 24.14% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:46:29,810]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:46:34,735]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:46:43,756]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:46:44,128]\u001b[0m Trial 1015 finished with value: 5.332177993642994 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034867500836396883, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30188732660073436, 'dropout_rate_Layer_2': 0.09526784677879536, 'dropout_rate_Layer_3': 0.014167686026778713, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016176075194797575, 'l1_Layer_2': 0.03270467798647218, 'l1_Layer_3': 0.00018024374994938643, 'n_units_Layer_1': 75, 'n_units_Layer_2': 155, 'n_units_Layer_3': 260}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 13.17% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 12.09 | sMAPE for Test Set is: 24.26% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:46:50,429]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:46:50,724]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:46:56,714]\u001b[0m Trial 1019 finished with value: 5.357883331309483 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005717017209421878, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19014441892992298, 'dropout_rate_Layer_2': 0.36489747712096987, 'dropout_rate_Layer_3': 0.059149521543989246, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018052943599941248, 'l1_Layer_2': 5.9143693035631723e-05, 'l1_Layer_3': 0.00015109124623907113, 'n_units_Layer_1': 140, 'n_units_Layer_2': 180, 'n_units_Layer_3': 210}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:46:56,850]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 12.94% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 11.85 | sMAPE for Test Set is: 23.45% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:46:57,010]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:47:02,582]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:47:09,936]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:47:10,391]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:47:17,638]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:47:18,479]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:47:23,473]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:47:30,005]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:47:34,260]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:47:34,537]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:47:40,525]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:47:45,737]\u001b[0m Trial 1029 finished with value: 5.945189790192928 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011239818095317357, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16236914662353838, 'dropout_rate_Layer_2': 0.004407843636087865, 'dropout_rate_Layer_3': 0.24004135949445593, 'dropout_rate_Layer_4': 0.06471349291673997, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.011263171645062487, 'l1_Layer_2': 0.019272087718678627, 'l1_Layer_3': 6.493708301471438e-05, 'l1_Layer_4': 0.0023916441080824103, 'n_units_Layer_1': 225, 'n_units_Layer_2': 55, 'n_units_Layer_3': 70, 'n_units_Layer_4': 295}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.95 | sMAPE for Validation Set is: 14.64% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 9.84 | sMAPE for Test Set is: 19.15% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:47:48,607]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:47:54,246]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:47:58,422]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:47:59,006]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:48:05,808]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:48:06,067]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:48:06,321]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:48:06,565]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:48:13,699]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:48:17,093]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:48:18,777]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:48:24,131]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:48:25,737]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:48:27,791]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:48:34,805]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:48:37,850]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:48:39,680]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:48:40,823]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:48:49,672]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:48:53,821]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:48:54,299]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:49:03,570]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:49:10,001]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:49:10,172]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:49:16,494]\u001b[0m Trial 1050 finished with value: 5.1830397256126615 and parameters: {'n_hidden': 3, 'learning_rate': 0.002138078670635529, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21442999746998978, 'dropout_rate_Layer_2': 0.11593958843382027, 'dropout_rate_Layer_3': 0.0032038755757137632, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008572822862620411, 'l1_Layer_2': 0.058016469608697205, 'l1_Layer_3': 0.0004878242196677495, 'n_units_Layer_1': 70, 'n_units_Layer_2': 180, 'n_units_Layer_3': 260}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 12.66% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.93 | sMAPE for Test Set is: 13.26% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:49:17,147]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:49:17,320]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:49:25,033]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:49:27,300]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:49:27,901]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:49:35,641]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:49:36,176]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:49:42,130]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:49:42,488]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:49:53,498]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:49:54,313]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:49:54,936]\u001b[0m Trial 1056 finished with value: 5.188769516243393 and parameters: {'n_hidden': 3, 'learning_rate': 0.000510810419879234, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2747659425813896, 'dropout_rate_Layer_2': 0.32162639591651326, 'dropout_rate_Layer_3': 0.04022466159821871, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002611562992296858, 'l1_Layer_2': 9.01077946682238e-05, 'l1_Layer_3': 7.62324035554062e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 215, 'n_units_Layer_3': 215}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 12.62% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 9.75 | sMAPE for Test Set is: 18.86% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:50:04,255]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:50:06,007]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:50:11,925]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:50:12,905]\u001b[0m Trial 1071 finished with value: 5.28894340861443 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006137230028304511, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27598000276160306, 'dropout_rate_Layer_2': 0.3003539139616739, 'dropout_rate_Layer_3': 0.04823580119624818, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.197090722860483e-05, 'l1_Layer_2': 8.641324626277477e-05, 'l1_Layer_3': 9.43110665311308e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 225, 'n_units_Layer_3': 220}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 12.76% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 12.09 | sMAPE for Test Set is: 23.99% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:50:20,618]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:50:31,748]\u001b[0m Trial 1078 finished with value: 5.249890991784563 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006376678294022458, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27259419806074137, 'dropout_rate_Layer_2': 0.32794500859988496, 'dropout_rate_Layer_3': 0.04534894633497108, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015262026376931776, 'l1_Layer_2': 5.745690039319988e-05, 'l1_Layer_3': 8.723330680781884e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 205, 'n_units_Layer_3': 220}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 12.71% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 11.90 | sMAPE for Test Set is: 23.61% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:50:37,363]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 12.69% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 11.62 | sMAPE for Test Set is: 22.89% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:50:39,908]\u001b[0m Trial 1076 finished with value: 5.2475730316155 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006196557026584542, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2762890891332341, 'dropout_rate_Layer_2': 0.32892803771338336, 'dropout_rate_Layer_3': 0.046126494351997296, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015125697798927494, 'l1_Layer_2': 5.619683563956497e-05, 'l1_Layer_3': 8.887846759981728e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 205, 'n_units_Layer_3': 220}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:50:44,492]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:50:48,483]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:50:49,037]\u001b[0m Trial 1081 finished with value: 5.270468656523933 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006951826078723147, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25202932119600324, 'dropout_rate_Layer_2': 0.32991677023600485, 'dropout_rate_Layer_3': 0.01027398209446765, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015018657838874718, 'l1_Layer_2': 5.4273753192049915e-05, 'l1_Layer_3': 4.525517257080642e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 190, 'n_units_Layer_3': 215}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 12.80% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 11.73 | sMAPE for Test Set is: 23.22% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:50:56,061]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:50:56,462]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:51:03,214]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:51:04,671]\u001b[0m Trial 1082 finished with value: 5.163192638862509 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006786749545278975, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2524607705258254, 'dropout_rate_Layer_2': 0.33005364168158463, 'dropout_rate_Layer_3': 0.043966907228671484, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003949359545679362, 'l1_Layer_2': 5.4214828552265995e-05, 'l1_Layer_3': 4.394846957732501e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 190, 'n_units_Layer_3': 215}. Best is trial 917 with value: 5.111040815765409.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 12.48% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 9.85 | sMAPE for Test Set is: 19.12% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:51:10,051]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:51:13,569]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:51:16,975]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:51:17,804]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:51:24,639]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:51:28,968]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:51:32,744]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:51:36,746]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:51:38,124]\u001b[0m Trial 1084 finished with value: 5.078349998632178 and parameters: {'n_hidden': 3, 'learning_rate': 0.000707575215455381, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2506302402641272, 'dropout_rate_Layer_2': 0.29493211730826274, 'dropout_rate_Layer_3': 0.07880778025775108, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021827142051285983, 'l1_Layer_2': 4.1563067620958266e-05, 'l1_Layer_3': 4.267443681014213e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 195, 'n_units_Layer_3': 210}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 12.23% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 9.97 | sMAPE for Test Set is: 19.21% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:51:44,054]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:51:46,920]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 13.02% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 7.27 | sMAPE for Test Set is: 14.07% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:51:49,244]\u001b[0m Trial 1090 finished with value: 5.292345961370059 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014327551622602343, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2580693355484619, 'dropout_rate_Layer_2': 0.25857778508551577, 'dropout_rate_Layer_3': 0.025654743007423, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008147938507355271, 'l1_Layer_2': 0.034068365257559546, 'l1_Layer_3': 0.00013076047788329655, 'n_units_Layer_1': 95, 'n_units_Layer_2': 230, 'n_units_Layer_3': 265}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:51:54,627]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:51:56,835]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:51:57,798]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:52:02,641]\u001b[0m Trial 1098 finished with value: 5.423581995102723 and parameters: {'n_hidden': 3, 'learning_rate': 0.0044768989894042755, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22608411231715878, 'dropout_rate_Layer_2': 0.13220924063170678, 'dropout_rate_Layer_3': 0.026134049289104365, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0059006205472284905, 'l1_Layer_2': 0.03305193729957901, 'l1_Layer_3': 0.00045611619831203266, 'n_units_Layer_1': 95, 'n_units_Layer_2': 230, 'n_units_Layer_3': 265}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 13.29% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 7.47 | sMAPE for Test Set is: 14.49% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:52:04,888]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:52:05,550]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:52:11,382]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:52:13,205]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:52:13,458]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:52:20,984]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:52:25,579]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:52:28,367]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:52:31,968]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:52:39,083]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:52:41,201]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:52:45,184]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:52:47,551]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:52:50,497]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:52:52,523]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:52:58,734]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:53:03,509]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:53:17,927]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:53:21,773]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:53:26,336]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:53:30,058]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:53:30,596]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:53:36,436]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:53:38,660]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:53:39,113]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:53:41,151]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:53:44,709]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:53:52,705]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:53:53,342]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:53:59,188]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:53:59,446]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:53:59,624]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:54:08,520]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:54:10,972]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:54:11,748]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:54:20,148]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:54:20,391]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:54:27,561]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:54:30,992]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:54:33,081]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:54:38,170]\u001b[0m Trial 1134 finished with value: 5.353915272504923 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011177881971467577, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25893488905425194, 'dropout_rate_Layer_2': 0.07878277283537709, 'dropout_rate_Layer_3': 0.01631794370722467, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007844727334240344, 'l1_Layer_2': 0.022394338871356088, 'l1_Layer_3': 0.00010651869987865435, 'n_units_Layer_1': 60, 'n_units_Layer_2': 220, 'n_units_Layer_3': 265}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 13.27% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 7.49 | sMAPE for Test Set is: 14.53% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:54:39,406]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:54:47,102]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:54:50,519]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:54:51,013]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:54:57,014]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:55:00,813]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:55:09,177]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:55:13,754]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:55:18,419]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:55:19,621]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:55:24,985]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:55:25,186]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 12.34% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 9.73 | sMAPE for Test Set is: 18.68% | rMAE for Test Set is: 1.11\n",
      "MAE for Validation Set is: 5.17 | sMAPE for Validation Set is: 12.45% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 10.31 | sMAPE for Test Set is: 19.95% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:55:31,802]\u001b[0m Trial 1148 finished with value: 5.150530262419631 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007137449406358201, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21581701567572542, 'dropout_rate_Layer_2': 0.26654981800641736, 'dropout_rate_Layer_3': 0.05088435637214928, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001018731621674317, 'l1_Layer_2': 6.530718439386444e-05, 'l1_Layer_3': 5.2755949996163074e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 195}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:55:31,808]\u001b[0m Trial 1147 finished with value: 5.173039042359179 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006984827203005678, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2150537546953591, 'dropout_rate_Layer_2': 0.2687809889973411, 'dropout_rate_Layer_3': 0.07275117661711514, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010186455451673782, 'l1_Layer_2': 0.00013663961953745764, 'l1_Layer_3': 5.0332167684437264e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 200, 'n_units_Layer_3': 225}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:55:32,462]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:55:39,704]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:55:43,061]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:55:45,909]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:55:51,394]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:56:01,817]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:56:02,457]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:56:08,878]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:56:12,787]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:56:21,019]\u001b[0m Trial 1163 finished with value: 5.153383917577663 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007152466343029769, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21386722372203193, 'dropout_rate_Layer_2': 0.26930335753166434, 'dropout_rate_Layer_3': 0.07006343508558796, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010260147210291788, 'l1_Layer_2': 0.00013506974718187616, 'l1_Layer_3': 4.001146141823829e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 200, 'n_units_Layer_3': 235}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 10.63 | sMAPE for Test Set is: 20.74% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:56:25,100]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:56:32,773]\u001b[0m Trial 1166 finished with value: 5.109882678674807 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009156627344535253, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21778538559730448, 'dropout_rate_Layer_2': 0.2674165460442225, 'dropout_rate_Layer_3': 0.0715806178896491, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010563833043738696, 'l1_Layer_2': 0.00017910354280669785, 'l1_Layer_3': 2.2898365271313688e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 200, 'n_units_Layer_3': 235}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 12.33% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 10.09 | sMAPE for Test Set is: 19.56% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:56:38,602]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:56:42,576]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:56:47,406]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:56:51,550]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:57:04,926]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:57:10,833]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:57:19,414]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:57:19,877]\u001b[0m Trial 1173 finished with value: 5.267701199840566 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007287667099541007, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19259166705748612, 'dropout_rate_Layer_2': 0.06346854944147647, 'dropout_rate_Layer_3': 0.015810779740331505, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008607291217889432, 'l1_Layer_2': 0.028302131243150317, 'l1_Layer_3': 0.0002824445347262694, 'n_units_Layer_1': 85, 'n_units_Layer_2': 285, 'n_units_Layer_3': 255}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 12.91% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.00 | sMAPE for Test Set is: 13.46% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:57:20,993]\u001b[0m Trial 1174 finished with value: 5.278175407930014 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007092795660164465, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2050921380347264, 'dropout_rate_Layer_2': 0.09100409049387054, 'dropout_rate_Layer_3': 0.01750971291348746, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0023149052396976943, 'l1_Layer_2': 0.03818828704358567, 'l1_Layer_3': 0.0007818918373323076, 'n_units_Layer_1': 85, 'n_units_Layer_2': 180, 'n_units_Layer_3': 255}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 12.95% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.80 | sMAPE for Test Set is: 13.08% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:57:31,973]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:57:32,963]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:57:38,913]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:57:44,162]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:57:44,331]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:57:52,016]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:57:57,231]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:58:04,185]\u001b[0m Trial 1179 finished with value: 5.266916692074894 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006764462432069406, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20565091349153827, 'dropout_rate_Layer_2': 0.09192694559244874, 'dropout_rate_Layer_3': 0.016482052337151443, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014272782995958986, 'l1_Layer_2': 0.037520842834390764, 'l1_Layer_3': 0.000274554696108967, 'n_units_Layer_1': 85, 'n_units_Layer_2': 210, 'n_units_Layer_3': 255}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 12.98% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 13.22% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:58:12,512]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:58:19,616]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:58:25,693]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:58:30,375]\u001b[0m Trial 1186 finished with value: 5.154364237683223 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007399896248213853, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20238372662281665, 'dropout_rate_Layer_2': 0.268567719710794, 'dropout_rate_Layer_3': 0.06366641401965908, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.794216923582565e-05, 'l1_Layer_2': 0.0001362439988147843, 'l1_Layer_3': 3.930659482106528e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 210, 'n_units_Layer_3': 225}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 12.48% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 9.82 | sMAPE for Test Set is: 19.07% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:58:39,016]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:58:44,073]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:58:49,942]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:58:51,090]\u001b[0m Trial 1193 finished with value: 5.160870873888112 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007311442114627475, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1997097171179113, 'dropout_rate_Layer_2': 0.26857544994104326, 'dropout_rate_Layer_3': 0.06361336394067578, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012694853251501856, 'l1_Layer_2': 0.0001322160423605512, 'l1_Layer_3': 3.855201908078236e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 210, 'n_units_Layer_3': 225}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 12.47% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 10.75 | sMAPE for Test Set is: 21.03% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:58:55,616]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:58:56,454]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:59:05,248]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:59:14,150]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:59:18,751]\u001b[0m Trial 1200 finished with value: 5.347260262482215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007468568833473256, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19952568363545958, 'dropout_rate_Layer_2': 0.26882877455882864, 'dropout_rate_Layer_3': 0.0645470784118344, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.171293080741962e-05, 'l1_Layer_2': 0.00014652755108112597, 'l1_Layer_3': 3.0109761978002124e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 210, 'n_units_Layer_3': 235}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 12.87% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 10.85 | sMAPE for Test Set is: 21.33% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 17:59:21,842]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:59:25,145]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:59:26,662]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:59:30,996]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:59:32,875]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:59:38,904]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:59:42,701]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:59:47,793]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:59:52,419]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 17:59:57,111]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:00:01,471]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:00:01,639]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:00:08,850]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:00:09,942]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:00:17,443]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:00:20,266]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:00:24,714]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:00:28,480]\u001b[0m Trial 1203 finished with value: 5.239586803562369 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009063532946552503, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25261737580981275, 'dropout_rate_Layer_2': 0.11113517977863206, 'dropout_rate_Layer_3': 0.016403719935955217, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008277395080048439, 'l1_Layer_2': 0.022016061366924532, 'l1_Layer_3': 0.0003382673491036054, 'n_units_Layer_1': 100, 'n_units_Layer_2': 220, 'n_units_Layer_3': 245}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 12.84% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.15 | sMAPE for Test Set is: 13.72% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:00:29,288]\u001b[0m Trial 1201 finished with value: 5.226239541362783 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006702090075754657, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2966049156716291, 'dropout_rate_Layer_2': 0.17289047086662737, 'dropout_rate_Layer_3': 0.01624512483888577, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009545649186764892, 'l1_Layer_2': 0.06840006782139353, 'l1_Layer_3': 0.00010966886829298879, 'n_units_Layer_1': 100, 'n_units_Layer_2': 220, 'n_units_Layer_3': 240}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 12.79% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.98 | sMAPE for Test Set is: 13.42% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:00:29,585]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:00:37,478]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:00:38,019]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:00:38,205]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:00:46,749]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:00:49,152]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:00:50,436]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:00:55,808]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:00:59,131]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:02,847]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:03,349]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:04,363]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:10,221]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:13,100]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:20,148]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:20,794]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:22,139]\u001b[0m Trial 1222 finished with value: 5.3106286777908345 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013983543188367026, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.201820016595102, 'dropout_rate_Layer_2': 0.054025287759807514, 'dropout_rate_Layer_3': 0.027423073701360132, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0033116272162429156, 'l1_Layer_2': 0.07215772293205823, 'l1_Layer_3': 0.000530457128494081, 'n_units_Layer_1': 85, 'n_units_Layer_2': 205, 'n_units_Layer_3': 265}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 12.98% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 7.04 | sMAPE for Test Set is: 13.58% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:01:22,559]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:29,422]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:29,724]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:36,728]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:37,105]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:42,963]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:47,888]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:48,570]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:49,100]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:49,285]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:01:56,410]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:00,550]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:02,213]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:05,375]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:11,421]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:15,658]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:15,716]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:17,795]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:24,035]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:24,989]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:26,214]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:34,203]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:35,106]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:38,944]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:42,146]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:42,409]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:48,871]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:49,041]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:02:56,488]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:03:01,807]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:03:05,105]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:03:08,722]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:03:13,828]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:03:14,133]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:03:14,653]\u001b[0m Trial 1268 finished with value: 5.374088808109417 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006506363996237781, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20760726979925373, 'dropout_rate_Layer_2': 0.25756586492037226, 'dropout_rate_Layer_3': 0.08434557229471658, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.611389968791989e-05, 'l1_Layer_2': 0.0001042634439167802, 'l1_Layer_3': 3.860853291180602e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 180, 'n_units_Layer_3': 230}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 12.98% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 10.45 | sMAPE for Test Set is: 20.48% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:03:14,986]\u001b[0m Trial 1260 finished with value: 5.180863704925586 and parameters: {'n_hidden': 3, 'learning_rate': 0.000653718323999279, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20954337236410223, 'dropout_rate_Layer_2': 0.2807693542834451, 'dropout_rate_Layer_3': 0.08365039031166045, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011832050967073883, 'l1_Layer_2': 6.827544791924582e-05, 'l1_Layer_3': 4.216673230839964e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 230, 'n_units_Layer_3': 230}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 12.44% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 10.06 | sMAPE for Test Set is: 19.41% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:03:24,870]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:03:25,625]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:03:32,107]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:03:32,280]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:03:39,295]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:03:39,413]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:03:47,713]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:03:49,231]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:03:54,496]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:03:55,778]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:02,852]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:03,141]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:13,954]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:14,878]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:21,059]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:21,286]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:26,522]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:29,081]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:33,564]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:34,260]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:39,617]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:42,562]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:43,095]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:44,404]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:45,122]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:50,864]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:52,737]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:59,513]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:04:59,865]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:05:06,778]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:05:10,801]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:05:15,013]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:05:20,561]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:05:24,669]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:05:25,091]\u001b[0m Trial 1304 finished with value: 5.489385761912751 and parameters: {'n_hidden': 3, 'learning_rate': 0.006532155078883679, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011639452356372908, 'dropout_rate_Layer_2': 0.18264458882833245, 'dropout_rate_Layer_3': 0.019165354220302036, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006105447512010311, 'l1_Layer_2': 0.00034269678994495334, 'l1_Layer_3': 7.791802586373384e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 115, 'n_units_Layer_3': 225}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 13.20% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 11.14 | sMAPE for Test Set is: 21.94% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:05:31,656]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:05:32,053]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:05:39,211]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:05:42,208]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:05:47,707]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:05:51,707]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:05:52,306]\u001b[0m Trial 1301 finished with value: 5.102631447035507 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005884835598648754, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19192962966944213, 'dropout_rate_Layer_2': 0.2861934945655808, 'dropout_rate_Layer_3': 0.07039377547500225, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.838334860500644e-05, 'l1_Layer_2': 3.3265757687561124e-05, 'l1_Layer_3': 6.015046065535694e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 205, 'n_units_Layer_3': 225}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 12.30% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 10.22 | sMAPE for Test Set is: 19.83% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:06:02,235]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:06:03,525]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:06:09,508]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:06:10,310]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:06:16,482]\u001b[0m Trial 1308 finished with value: 5.0981670139444155 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005884286873703017, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19180321779544618, 'dropout_rate_Layer_2': 0.2875440797798445, 'dropout_rate_Layer_3': 0.0702368261435602, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.534499726362643e-05, 'l1_Layer_2': 0.00011171754854188302, 'l1_Layer_3': 6.295856902821194e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 195, 'n_units_Layer_3': 225}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 12.28% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 10.40 | sMAPE for Test Set is: 20.27% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:06:20,026]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:06:22,358]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:06:27,921]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:06:30,085]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:06:33,643]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:06:37,570]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:06:38,088]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:06:39,187]\u001b[0m Trial 1316 finished with value: 5.191661842157942 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005810444958380056, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1899759362239769, 'dropout_rate_Layer_2': 0.28557425368845885, 'dropout_rate_Layer_3': 0.036701119669347984, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010494531215332522, 'l1_Layer_2': 0.00011554071910868901, 'l1_Layer_3': 3.153871124354684e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 205, 'n_units_Layer_3': 225}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 12.49% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 10.29 | sMAPE for Test Set is: 19.96% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:06:46,707]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:06:50,335]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:06:50,967]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:06:54,216]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:06:57,446]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:07:02,159]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:07:04,277]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:07:08,916]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:07:12,027]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:07:13,117]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:07:19,256]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:07:23,342]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:07:26,317]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:07:27,008]\u001b[0m Trial 1327 finished with value: 5.1615536501420936 and parameters: {'n_hidden': 3, 'learning_rate': 0.000577589309071153, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1879238216727072, 'dropout_rate_Layer_2': 0.2638278760583376, 'dropout_rate_Layer_3': 0.06376532150081293, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.123467021417304e-05, 'l1_Layer_2': 0.00011321499187392664, 'l1_Layer_3': 6.140597056109186e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 210, 'n_units_Layer_3': 235}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 12.41% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 10.56 | sMAPE for Test Set is: 20.59% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:07:28,231]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:07:36,441]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:07:37,828]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:07:40,560]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:07:41,504]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:07:45,021]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:07:51,859]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:07:52,365]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:07:55,667]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:08:00,666]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:08:03,664]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:08:05,999]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:08:10,881]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:08:14,809]\u001b[0m Trial 1336 finished with value: 5.283750117939499 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008039872263970213, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27813242274069255, 'dropout_rate_Layer_2': 0.11828677497095154, 'dropout_rate_Layer_3': 0.03708135028484208, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001949237705137512, 'l1_Layer_2': 0.0538172549684086, 'l1_Layer_3': 0.0004403199299795502, 'n_units_Layer_1': 85, 'n_units_Layer_2': 190, 'n_units_Layer_3': 265}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 12.97% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.90 | sMAPE for Test Set is: 13.33% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:08:18,474]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:08:19,223]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:08:25,216]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:08:28,379]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:08:29,258]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:08:36,073]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:08:36,598]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:08:43,319]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:08:43,485]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:08:50,136]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:08:55,130]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:08:58,617]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:08:59,238]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:09:05,240]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:09:05,525]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:09:06,038]\u001b[0m Trial 1359 finished with value: 5.163598182534371 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006124639759030778, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19569865731128558, 'dropout_rate_Layer_2': 0.2627871343663045, 'dropout_rate_Layer_3': 0.0759048948814712, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.98026925272386e-05, 'l1_Layer_2': 0.00011680166483755511, 'l1_Layer_3': 6.16554203706113e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 200, 'n_units_Layer_3': 235}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 12.47% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 10.27 | sMAPE for Test Set is: 19.90% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:09:07,674]\u001b[0m Trial 1353 finished with value: 5.093023087139236 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005961015960119711, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19625029809018285, 'dropout_rate_Layer_2': 0.2622516301211348, 'dropout_rate_Layer_3': 0.07755092825539453, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.675053480833291e-05, 'l1_Layer_2': 0.00011850104020871273, 'l1_Layer_3': 6.0362709145403995e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 200, 'n_units_Layer_3': 240}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 12.26% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 9.61 | sMAPE for Test Set is: 18.56% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:09:11,473]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:09:16,060]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:09:16,754]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:09:19,568]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:09:25,506]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:09:33,122]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:09:33,202]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:09:33,478]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:09:42,281]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:09:42,764]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:09:42,847]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:09:53,039]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:09:57,440]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:10:01,325]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:10:13,578]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:10:13,687]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:10:26,376]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:10:35,221]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.83 | sMAPE for Validation Set is: 14.22% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 10.55 | sMAPE for Test Set is: 20.54% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:10:38,172]\u001b[0m Trial 1391 finished with value: 5.83486533997889 and parameters: {'n_hidden': 3, 'learning_rate': 0.002054900210971321, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15118977104726086, 'dropout_rate_Layer_2': 0.00038226204407670276, 'dropout_rate_Layer_3': 0.2221921918410692, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01671958168354598, 'l1_Layer_2': 0.005676080217016506, 'l1_Layer_3': 0.000983605699252335, 'n_units_Layer_1': 170, 'n_units_Layer_2': 70, 'n_units_Layer_3': 115}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:10:43,001]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:10:44,154]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:10:49,426]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:10:52,358]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:10:53,705]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:10:59,256]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:10:59,672]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:11:06,156]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:11:06,605]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:11:12,753]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:11:13,338]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:11:20,208]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:11:25,337]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:11:30,987]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:11:35,715]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:11:37,145]\u001b[0m Trial 1392 finished with value: 5.287647088759438 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009371976152101838, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3037612186485703, 'dropout_rate_Layer_2': 0.09847835742742428, 'dropout_rate_Layer_3': 0.03779690942953179, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019899843477737674, 'l1_Layer_2': 0.025078372090072173, 'l1_Layer_3': 0.00035569059762294433, 'n_units_Layer_1': 110, 'n_units_Layer_2': 190, 'n_units_Layer_3': 270}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 12.98% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.98 | sMAPE for Test Set is: 13.48% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:11:44,348]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:11:44,872]\u001b[0m Trial 1405 finished with value: 5.2428760413573 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007052141334093536, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2143906390929176, 'dropout_rate_Layer_2': 0.24619788646796248, 'dropout_rate_Layer_3': 0.09190115239610232, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011226167459554354, 'l1_Layer_2': 7.237605861640894e-05, 'l1_Layer_3': 4.1351053274203656e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 215, 'n_units_Layer_3': 250}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 12.64% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 10.43 | sMAPE for Test Set is: 20.33% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:11:51,377]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:11:56,626]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:11:57,549]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:12:02,279]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:12:07,188]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:12:15,085]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:12:16,106]\u001b[0m Trial 1411 finished with value: 5.233908402240476 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007276701295718899, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20545511844227948, 'dropout_rate_Layer_2': 0.24022155648853727, 'dropout_rate_Layer_3': 0.09179587908666001, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010598986377654263, 'l1_Layer_2': 8.501021761537421e-05, 'l1_Layer_3': 3.988058400419677e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 215, 'n_units_Layer_3': 250}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 12.57% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 10.53 | sMAPE for Test Set is: 20.53% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:12:23,884]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:12:27,311]\u001b[0m Trial 1418 finished with value: 5.427292705647772 and parameters: {'n_hidden': 3, 'learning_rate': 0.004899944553280741, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027441659502996846, 'dropout_rate_Layer_2': 0.13961020409628674, 'dropout_rate_Layer_3': 0.035020481022076305, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009036961489211718, 'l1_Layer_2': 0.0004358272286074595, 'l1_Layer_3': 5.591836276241145e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 155, 'n_units_Layer_3': 230}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 13.09% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 10.67 | sMAPE for Test Set is: 20.93% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:12:27,686]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:12:28,441]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:12:29,061]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:12:39,150]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:12:42,210]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:12:42,794]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:12:49,391]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:12:49,443]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:12:51,106]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:12:59,829]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:12:59,976]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:13:01,206]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:13:09,051]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:13:12,108]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:13:15,295]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:13:18,185]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:13:22,326]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:13:27,010]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:13:27,407]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:13:38,667]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:13:39,652]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:13:49,081]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:13:49,945]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:13:57,065]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:14:06,580]\u001b[0m Trial 1434 finished with value: 5.141827952892863 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006269251244418631, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21548237605161077, 'dropout_rate_Layer_2': 0.2531313350306431, 'dropout_rate_Layer_3': 0.06072731261650983, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.235933715942744e-05, 'l1_Layer_2': 6.448082156331372e-05, 'l1_Layer_3': 4.9362315199290225e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 200, 'n_units_Layer_3': 200}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 12.34% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 10.00 | sMAPE for Test Set is: 19.35% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:14:11,036]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:14:15,668]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:14:20,568]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:14:23,188]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:14:29,677]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:14:34,894]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:14:35,325]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:14:50,720]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:14:56,385]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:14:57,511]\u001b[0m Trial 1454 finished with value: 5.305539420516797 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006209436911757204, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2160142911985241, 'dropout_rate_Layer_2': 0.25678011200264644, 'dropout_rate_Layer_3': 0.05340084817864563, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.62505684847288e-05, 'l1_Layer_2': 6.580505040924097e-05, 'l1_Layer_3': 6.810165909581572e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 200, 'n_units_Layer_3': 200}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 12.78% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 10.65 | sMAPE for Test Set is: 20.82% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:14:58,549]\u001b[0m Trial 1447 finished with value: 5.248645685558211 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007373940410182729, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2811798617038376, 'dropout_rate_Layer_2': 0.0917877618767526, 'dropout_rate_Layer_3': 0.037540366241665735, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009865891834815296, 'l1_Layer_2': 0.02152457596582492, 'l1_Layer_3': 0.00021469871530600885, 'n_units_Layer_1': 100, 'n_units_Layer_2': 190, 'n_units_Layer_3': 280}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 12.87% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.78 | sMAPE for Test Set is: 12.98% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:15:02,078]\u001b[0m Trial 1446 finished with value: 5.241684708781748 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007733530655343137, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2841888815192965, 'dropout_rate_Layer_2': 0.12077285649364879, 'dropout_rate_Layer_3': 0.04719449208996422, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002832081450442713, 'l1_Layer_2': 0.020184852875600425, 'l1_Layer_3': 0.0002291858625407005, 'n_units_Layer_1': 100, 'n_units_Layer_2': 190, 'n_units_Layer_3': 280}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 12.85% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 13.14% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:15:09,607]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:15:10,950]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:15:17,830]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:15:18,014]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:15:25,375]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:15:25,545]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:15:32,385]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:15:33,409]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:15:39,084]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:15:42,344]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:15:47,443]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:15:48,147]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 13.37% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 11.96 | sMAPE for Test Set is: 23.85% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 18:15:49,722]\u001b[0m Trial 1459 finished with value: 5.463712637233557 and parameters: {'n_hidden': 3, 'learning_rate': 0.004301340020886871, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06726995225300644, 'dropout_rate_Layer_2': 0.12641073042511536, 'dropout_rate_Layer_3': 0.06831599186917411, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016351772403027543, 'l1_Layer_2': 0.00018477548311293874, 'l1_Layer_3': 0.0002539737178207834, 'n_units_Layer_1': 165, 'n_units_Layer_2': 175, 'n_units_Layer_3': 290}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:15:57,756]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:16:05,266]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:16:09,475]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:16:10,052]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:16:17,028]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:16:21,724]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:16:30,844]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:16:39,127]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:16:42,841]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:16:47,793]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:16:47,823]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:16:57,097]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:16:59,726]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:17:04,068]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:17:08,896]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:17:12,755]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:17:13,129]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:17:20,149]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:17:24,649]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:17:29,517]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:17:30,130]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:17:36,099]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:17:39,775]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:17:42,902]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:17:45,158]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:17:46,130]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:17:52,222]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:17:52,899]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:17:53,481]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 18:18:00,911]\u001b[0m Trial 1491 finished with value: 5.211977182606744 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010200877608635233, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26112169515412953, 'dropout_rate_Layer_2': 0.10381921070150041, 'dropout_rate_Layer_3': 0.05953710990909791, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002502848661315721, 'l1_Layer_2': 0.017356341038059036, 'l1_Layer_3': 0.00011465948658994796, 'n_units_Layer_1': 100, 'n_units_Layer_2': 205, 'n_units_Layer_3': 290}. Best is trial 1084 with value: 5.078349998632178.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 12.74% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 13.30% | rMAE for Test Set is: 0.78\n",
      "for 2018-01-01, MAE is:3.88 & sMAPE is:12.64% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 12.64% & 0.60\n",
      "for 2018-01-02, MAE is:7.17 & sMAPE is:18.99% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 15.82% & 0.57\n",
      "for 2018-01-03, MAE is:3.66 & sMAPE is:9.46% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.90 & 13.70% & 0.52\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002099900F550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-04, MAE is:3.14 & sMAPE is:7.67% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 12.19% & 0.51\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000208FA26FAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-05, MAE is:7.47 & sMAPE is:29.48% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 15.65% & 0.57\n",
      "for 2018-01-06, MAE is:2.42 & sMAPE is:6.54% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 14.13% & 0.56\n",
      "for 2018-01-07, MAE is:14.35 & sMAPE is:48.19% & rMAE is:2.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 19.00% & 0.81\n",
      "for 2018-01-08, MAE is:11.58 & sMAPE is:34.68% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 20.96% & 0.83\n",
      "for 2018-01-09, MAE is:10.30 & sMAPE is:24.42% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 21.34% & 0.86\n",
      "for 2018-01-10, MAE is:5.34 & sMAPE is:11.49% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 20.36% & 0.85\n",
      "for 2018-01-11, MAE is:5.65 & sMAPE is:12.27% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 19.62% & 0.83\n",
      "for 2018-01-12, MAE is:5.49 & sMAPE is:11.08% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 18.91% & 0.80\n",
      "for 2018-01-13, MAE is:4.00 & sMAPE is:9.02% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 18.15% & 0.78\n",
      "for 2018-01-14, MAE is:4.35 & sMAPE is:9.79% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 17.55% & 0.75\n",
      "for 2018-01-15, MAE is:5.12 & sMAPE is:12.00% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 17.18% & 0.74\n",
      "for 2018-01-16, MAE is:2.96 & sMAPE is:7.17% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 16.56% & 0.72\n",
      "for 2018-01-17, MAE is:4.70 & sMAPE is:11.43% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 16.25% & 0.74\n",
      "for 2018-01-18, MAE is:7.09 & sMAPE is:19.77% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 16.45% & 0.74\n",
      "for 2018-01-19, MAE is:4.65 & sMAPE is:11.14% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 16.17% & 0.74\n",
      "for 2018-01-20, MAE is:3.38 & sMAPE is:8.20% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 15.77% & 0.74\n",
      "for 2018-01-21, MAE is:2.75 & sMAPE is:7.44% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 15.37% & 0.73\n",
      "for 2018-01-22, MAE is:4.02 & sMAPE is:13.62% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 15.30% & 0.72\n",
      "for 2018-01-23, MAE is:6.82 & sMAPE is:16.27% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 15.34% & 0.76\n",
      "for 2018-01-24, MAE is:3.63 & sMAPE is:9.42% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 15.09% & 0.77\n",
      "for 2018-01-25, MAE is:5.04 & sMAPE is:13.79% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 15.04% & 0.78\n",
      "for 2018-01-26, MAE is:8.64 & sMAPE is:21.11% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 15.27% & 0.83\n",
      "for 2018-01-27, MAE is:6.52 & sMAPE is:16.45% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 15.32% & 0.85\n",
      "for 2018-01-28, MAE is:3.51 & sMAPE is:10.55% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 15.15% & 0.84\n",
      "for 2018-01-29, MAE is:5.01 & sMAPE is:15.87% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 15.17% & 0.84\n",
      "for 2018-01-30, MAE is:4.80 & sMAPE is:12.30% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 15.07% & 0.85\n",
      "for 2018-01-31, MAE is:5.17 & sMAPE is:13.05% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 15.01% & 0.86\n",
      "for 2018-02-01, MAE is:3.63 & sMAPE is:9.11% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 14.83% & 0.86\n",
      "for 2018-02-02, MAE is:2.47 & sMAPE is:6.16% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 14.56% & 0.85\n",
      "for 2018-02-03, MAE is:2.50 & sMAPE is:5.82% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 14.31% & 0.84\n",
      "for 2018-02-04, MAE is:3.00 & sMAPE is:7.92% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 14.12% & 0.83\n",
      "for 2018-02-05, MAE is:4.09 & sMAPE is:8.90% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 13.98% & 0.82\n",
      "for 2018-02-06, MAE is:4.82 & sMAPE is:10.10% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 13.87% & 0.82\n",
      "for 2018-02-07, MAE is:5.44 & sMAPE is:11.17% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 13.80% & 0.81\n",
      "for 2018-02-08, MAE is:7.29 & sMAPE is:15.14% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 13.84% & 0.82\n",
      "for 2018-02-09, MAE is:3.65 & sMAPE is:8.36% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 13.70% & 0.84\n",
      "for 2018-02-10, MAE is:5.13 & sMAPE is:12.63% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 13.67% & 0.85\n",
      "for 2018-02-11, MAE is:8.32 & sMAPE is:20.93% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 13.85% & 0.85\n",
      "for 2018-02-12, MAE is:5.58 & sMAPE is:12.46% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 13.81% & 0.85\n",
      "for 2018-02-13, MAE is:5.39 & sMAPE is:13.48% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 13.81% & 0.85\n",
      "for 2018-02-14, MAE is:6.85 & sMAPE is:15.83% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 13.85% & 0.86\n",
      "for 2018-02-15, MAE is:3.12 & sMAPE is:7.46% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 13.71% & 0.85\n",
      "for 2018-02-16, MAE is:3.98 & sMAPE is:9.40% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 13.62% & 0.86\n",
      "for 2018-02-17, MAE is:2.02 & sMAPE is:4.88% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 13.44% & 0.85\n",
      "for 2018-02-18, MAE is:4.30 & sMAPE is:10.31% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 13.37% & 0.84\n",
      "for 2018-02-19, MAE is:3.15 & sMAPE is:6.62% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 13.24% & 0.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-02-20, MAE is:4.88 & sMAPE is:9.26% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 13.16% & 0.83\n",
      "for 2018-02-21, MAE is:5.24 & sMAPE is:10.56% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 13.11% & 0.83\n",
      "for 2018-02-22, MAE is:6.08 & sMAPE is:12.66% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 13.10% & 0.83\n",
      "for 2018-02-23, MAE is:7.75 & sMAPE is:15.97% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 13.16% & 0.83\n",
      "for 2018-02-24, MAE is:8.03 & sMAPE is:17.49% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 13.23% & 0.84\n",
      "for 2018-02-25, MAE is:7.04 & sMAPE is:13.20% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 13.23% & 0.84\n",
      "for 2018-02-26, MAE is:10.86 & sMAPE is:19.43% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 13.34% & 0.85\n",
      "for 2018-02-27, MAE is:11.52 & sMAPE is:20.93% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 13.47% & 0.85\n",
      "for 2018-02-28, MAE is:11.45 & sMAPE is:21.50% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 13.61% & 0.86\n",
      "for 2018-03-01, MAE is:24.51 & sMAPE is:35.35% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 13.97% & 0.86\n",
      "for 2018-03-02, MAE is:33.16 & sMAPE is:40.33% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 14.40% & 0.86\n",
      "for 2018-03-03, MAE is:12.62 & sMAPE is:18.88% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 14.48% & 0.85\n",
      "for 2018-03-04, MAE is:10.89 & sMAPE is:17.23% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 14.52% & 0.85\n",
      "for 2018-03-05, MAE is:9.07 & sMAPE is:15.26% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 14.53% & 0.86\n",
      "for 2018-03-06, MAE is:5.24 & sMAPE is:10.17% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 14.46% & 0.86\n",
      "for 2018-03-07, MAE is:4.04 & sMAPE is:8.11% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 14.37% & 0.85\n",
      "for 2018-03-08, MAE is:13.62 & sMAPE is:26.28% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 14.55% & 0.84\n",
      "for 2018-03-09, MAE is:7.85 & sMAPE is:17.38% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 14.59% & 0.83\n",
      "for 2018-03-10, MAE is:10.49 & sMAPE is:24.91% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 14.74% & 0.83\n",
      "for 2018-03-11, MAE is:8.30 & sMAPE is:23.66% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 14.86% & 0.82\n",
      "for 2018-03-12, MAE is:8.20 & sMAPE is:17.08% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 14.90% & 0.82\n",
      "for 2018-03-13, MAE is:17.06 & sMAPE is:25.92% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 15.05% & 0.82\n",
      "for 2018-03-14, MAE is:7.48 & sMAPE is:14.32% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 15.04% & 0.83\n",
      "for 2018-03-15, MAE is:11.79 & sMAPE is:30.12% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 15.24% & 0.83\n",
      "for 2018-03-16, MAE is:10.82 & sMAPE is:20.58% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 15.31% & 0.83\n",
      "for 2018-03-17, MAE is:10.02 & sMAPE is:20.14% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 15.38% & 0.83\n",
      "for 2018-03-18, MAE is:6.61 & sMAPE is:15.69% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 15.38% & 0.83\n",
      "for 2018-03-19, MAE is:8.97 & sMAPE is:16.21% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 15.39% & 0.84\n",
      "for 2018-03-20, MAE is:11.04 & sMAPE is:21.12% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 15.46% & 0.83\n",
      "for 2018-03-21, MAE is:7.69 & sMAPE is:14.07% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 15.45% & 0.84\n",
      "for 2018-03-22, MAE is:7.73 & sMAPE is:13.68% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 15.43% & 0.84\n",
      "for 2018-03-23, MAE is:6.75 & sMAPE is:12.21% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 15.39% & 0.84\n",
      "for 2018-03-24, MAE is:6.60 & sMAPE is:13.00% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 15.36% & 0.85\n",
      "for 2018-03-25, MAE is:6.26 & sMAPE is:13.64% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 15.34% & 0.85\n",
      "for 2018-03-26, MAE is:5.67 & sMAPE is:10.21% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 15.28% & 0.85\n",
      "for 2018-03-27, MAE is:6.74 & sMAPE is:12.90% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 15.25% & 0.85\n",
      "for 2018-03-28, MAE is:9.24 & sMAPE is:17.91% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 15.28% & 0.85\n",
      "for 2018-03-29, MAE is:8.64 & sMAPE is:16.43% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 15.29% & 0.85\n",
      "for 2018-03-30, MAE is:4.99 & sMAPE is:10.57% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 15.24% & 0.85\n",
      "for 2018-03-31, MAE is:7.01 & sMAPE is:14.95% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 15.24% & 0.85\n",
      "for 2018-04-01, MAE is:8.09 & sMAPE is:18.51% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 15.27% & 0.85\n",
      "for 2018-04-02, MAE is:11.77 & sMAPE is:26.37% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 15.39% & 0.85\n",
      "for 2018-04-03, MAE is:7.96 & sMAPE is:20.90% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 15.45% & 0.85\n",
      "for 2018-04-04, MAE is:7.25 & sMAPE is:20.01% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 15.50% & 0.85\n",
      "for 2018-04-05, MAE is:4.00 & sMAPE is:10.94% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 15.45% & 0.84\n",
      "for 2018-04-06, MAE is:9.39 & sMAPE is:23.10% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 15.53% & 0.84\n",
      "for 2018-04-07, MAE is:8.54 & sMAPE is:20.56% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 15.58% & 0.84\n",
      "for 2018-04-08, MAE is:11.47 & sMAPE is:35.09% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 15.78% & 0.84\n",
      "for 2018-04-09, MAE is:7.69 & sMAPE is:16.67% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 15.79% & 0.84\n",
      "for 2018-04-10, MAE is:4.13 & sMAPE is:9.99% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 15.73% & 0.84\n",
      "for 2018-04-11, MAE is:7.82 & sMAPE is:17.94% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 15.76% & 0.84\n",
      "for 2018-04-12, MAE is:6.76 & sMAPE is:14.77% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 15.75% & 0.84\n",
      "for 2018-04-13, MAE is:6.24 & sMAPE is:12.70% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 15.72% & 0.84\n",
      "for 2018-04-14, MAE is:4.84 & sMAPE is:12.51% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 15.69% & 0.84\n",
      "for 2018-04-15, MAE is:4.43 & sMAPE is:11.66% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 15.65% & 0.84\n",
      "for 2018-04-16, MAE is:3.10 & sMAPE is:6.72% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 15.56% & 0.84\n",
      "for 2018-04-17, MAE is:4.79 & sMAPE is:10.60% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 15.52% & 0.84\n",
      "for 2018-04-18, MAE is:7.40 & sMAPE is:16.49% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 15.53% & 0.84\n",
      "for 2018-04-19, MAE is:5.97 & sMAPE is:13.74% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 15.51% & 0.84\n",
      "for 2018-04-20, MAE is:5.95 & sMAPE is:13.99% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 15.50% & 0.84\n",
      "for 2018-04-21, MAE is:7.53 & sMAPE is:20.13% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 15.54% & 0.84\n",
      "for 2018-04-22, MAE is:17.13 & sMAPE is:66.99% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 16.00% & 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-04-23, MAE is:10.98 & sMAPE is:31.88% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 16.14% & 0.85\n",
      "for 2018-04-24, MAE is:4.45 & sMAPE is:10.73% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 16.09% & 0.85\n",
      "for 2018-04-25, MAE is:7.39 & sMAPE is:19.88% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 16.12% & 0.84\n",
      "for 2018-04-26, MAE is:5.25 & sMAPE is:15.39% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 16.12% & 0.84\n",
      "for 2018-04-27, MAE is:6.20 & sMAPE is:14.01% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 16.10% & 0.85\n",
      "for 2018-04-28, MAE is:4.87 & sMAPE is:12.80% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 16.07% & 0.85\n",
      "for 2018-04-29, MAE is:4.94 & sMAPE is:13.12% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 16.05% & 0.84\n",
      "for 2018-04-30, MAE is:9.21 & sMAPE is:24.37% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 16.12% & 0.84\n",
      "for 2018-05-01, MAE is:10.58 & sMAPE is:23.37% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 16.18% & 0.85\n",
      "for 2018-05-02, MAE is:5.52 & sMAPE is:12.95% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 16.15% & 0.85\n",
      "for 2018-05-03, MAE is:7.97 & sMAPE is:16.42% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 16.15% & 0.85\n",
      "for 2018-05-04, MAE is:8.12 & sMAPE is:17.31% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 16.16% & 0.85\n",
      "for 2018-05-05, MAE is:6.21 & sMAPE is:15.33% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 16.15% & 0.85\n",
      "for 2018-05-06, MAE is:10.98 & sMAPE is:34.38% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 16.30% & 0.85\n",
      "for 2018-05-07, MAE is:8.09 & sMAPE is:17.94% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 16.31% & 0.85\n",
      "for 2018-05-08, MAE is:7.02 & sMAPE is:14.63% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 16.30% & 0.85\n",
      "for 2018-05-09, MAE is:6.30 & sMAPE is:14.53% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 16.28% & 0.85\n",
      "for 2018-05-10, MAE is:13.15 & sMAPE is:30.14% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 16.39% & 0.85\n",
      "for 2018-05-11, MAE is:6.31 & sMAPE is:13.55% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 16.37% & 0.86\n",
      "for 2018-05-12, MAE is:4.66 & sMAPE is:11.82% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 16.33% & 0.86\n",
      "for 2018-05-13, MAE is:6.16 & sMAPE is:21.17% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 16.37% & 0.86\n",
      "for 2018-05-14, MAE is:5.43 & sMAPE is:12.06% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 16.34% & 0.85\n",
      "for 2018-05-15, MAE is:5.63 & sMAPE is:12.51% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 16.31% & 0.85\n",
      "for 2018-05-16, MAE is:8.38 & sMAPE is:16.67% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 16.31% & 0.85\n",
      "for 2018-05-17, MAE is:8.99 & sMAPE is:22.33% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 16.36% & 0.85\n",
      "for 2018-05-18, MAE is:9.01 & sMAPE is:18.29% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 16.37% & 0.85\n",
      "for 2018-05-19, MAE is:15.58 & sMAPE is:32.33% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 16.49% & 0.86\n",
      "for 2018-05-20, MAE is:8.04 & sMAPE is:20.74% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 16.52% & 0.85\n",
      "for 2018-05-21, MAE is:11.34 & sMAPE is:29.71% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 16.61% & 0.86\n",
      "for 2018-05-22, MAE is:10.78 & sMAPE is:21.44% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 16.64% & 0.86\n",
      "for 2018-05-23, MAE is:5.02 & sMAPE is:9.34% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 16.59% & 0.86\n",
      "for 2018-05-24, MAE is:7.56 & sMAPE is:15.16% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 16.58% & 0.85\n",
      "for 2018-05-25, MAE is:5.70 & sMAPE is:10.27% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 16.54% & 0.85\n",
      "for 2018-05-26, MAE is:6.01 & sMAPE is:13.06% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 16.52% & 0.85\n",
      "for 2018-05-27, MAE is:9.06 & sMAPE is:20.19% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 16.54% & 0.85\n",
      "for 2018-05-28, MAE is:15.56 & sMAPE is:25.87% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 16.60% & 0.85\n",
      "for 2018-05-29, MAE is:4.73 & sMAPE is:8.07% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 16.55% & 0.85\n",
      "for 2018-05-30, MAE is:10.72 & sMAPE is:16.89% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 16.55% & 0.85\n",
      "for 2018-05-31, MAE is:12.28 & sMAPE is:18.74% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 16.56% & 0.85\n",
      "for 2018-06-01, MAE is:7.40 & sMAPE is:12.22% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 16.53% & 0.85\n",
      "for 2018-06-02, MAE is:5.63 & sMAPE is:11.30% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 16.50% & 0.85\n",
      "for 2018-06-03, MAE is:4.36 & sMAPE is:9.28% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 16.45% & 0.84\n",
      "for 2018-06-04, MAE is:8.42 & sMAPE is:13.91% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 16.44% & 0.85\n",
      "for 2018-06-05, MAE is:5.96 & sMAPE is:10.11% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 16.40% & 0.85\n",
      "for 2018-06-06, MAE is:4.69 & sMAPE is:8.00% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 16.34% & 0.85\n",
      "for 2018-06-07, MAE is:4.19 & sMAPE is:7.29% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 16.29% & 0.85\n",
      "for 2018-06-08, MAE is:7.04 & sMAPE is:12.06% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 16.26% & 0.85\n",
      "for 2018-06-09, MAE is:4.10 & sMAPE is:7.97% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 16.21% & 0.85\n",
      "for 2018-06-10, MAE is:5.04 & sMAPE is:10.14% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 16.17% & 0.85\n",
      "for 2018-06-11, MAE is:6.53 & sMAPE is:11.84% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 16.14% & 0.85\n",
      "for 2018-06-12, MAE is:4.14 & sMAPE is:8.48% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 16.10% & 0.85\n",
      "for 2018-06-13, MAE is:2.93 & sMAPE is:5.75% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 16.03% & 0.84\n",
      "for 2018-06-14, MAE is:4.74 & sMAPE is:8.57% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 15.99% & 0.84\n",
      "for 2018-06-15, MAE is:3.98 & sMAPE is:7.40% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 15.94% & 0.84\n",
      "for 2018-06-16, MAE is:7.22 & sMAPE is:14.63% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 15.93% & 0.84\n",
      "for 2018-06-17, MAE is:8.01 & sMAPE is:22.50% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 15.97% & 0.84\n",
      "for 2018-06-18, MAE is:5.54 & sMAPE is:10.43% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 15.93% & 0.85\n",
      "for 2018-06-19, MAE is:6.85 & sMAPE is:12.66% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 15.92% & 0.85\n",
      "for 2018-06-20, MAE is:4.39 & sMAPE is:8.99% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 15.87% & 0.85\n",
      "for 2018-06-21, MAE is:6.75 & sMAPE is:13.14% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 15.86% & 0.85\n",
      "for 2018-06-22, MAE is:5.22 & sMAPE is:10.63% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 15.83% & 0.85\n",
      "for 2018-06-23, MAE is:3.93 & sMAPE is:8.22% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 15.78% & 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-06-24, MAE is:2.49 & sMAPE is:5.91% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 15.73% & 0.85\n",
      "for 2018-06-25, MAE is:5.25 & sMAPE is:9.75% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 15.69% & 0.84\n",
      "for 2018-06-26, MAE is:6.85 & sMAPE is:12.55% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 15.68% & 0.84\n",
      "for 2018-06-27, MAE is:5.41 & sMAPE is:10.34% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 15.65% & 0.85\n",
      "for 2018-06-28, MAE is:6.18 & sMAPE is:12.08% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 15.63% & 0.85\n",
      "for 2018-06-29, MAE is:3.89 & sMAPE is:7.42% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 15.58% & 0.85\n",
      "for 2018-06-30, MAE is:3.34 & sMAPE is:6.84% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 15.53% & 0.85\n",
      "for 2018-07-01, MAE is:5.54 & sMAPE is:15.42% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 15.53% & 0.85\n",
      "for 2018-07-02, MAE is:8.41 & sMAPE is:16.00% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 15.53% & 0.85\n",
      "for 2018-07-03, MAE is:6.98 & sMAPE is:12.29% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 15.52% & 0.85\n",
      "for 2018-07-04, MAE is:8.59 & sMAPE is:14.57% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 15.51% & 0.85\n",
      "for 2018-07-05, MAE is:4.57 & sMAPE is:8.05% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 15.47% & 0.85\n",
      "for 2018-07-06, MAE is:4.26 & sMAPE is:7.80% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 15.43% & 0.85\n",
      "for 2018-07-07, MAE is:3.86 & sMAPE is:7.44% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 15.39% & 0.85\n",
      "for 2018-07-08, MAE is:8.75 & sMAPE is:19.83% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 15.41% & 0.85\n",
      "for 2018-07-09, MAE is:5.07 & sMAPE is:8.82% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 15.38% & 0.85\n",
      "for 2018-07-10, MAE is:3.12 & sMAPE is:5.90% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 15.33% & 0.85\n",
      "for 2018-07-11, MAE is:4.05 & sMAPE is:7.56% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 15.29% & 0.85\n",
      "for 2018-07-12, MAE is:3.07 & sMAPE is:5.91% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 15.24% & 0.85\n",
      "for 2018-07-13, MAE is:3.63 & sMAPE is:7.19% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 15.20% & 0.85\n",
      "for 2018-07-14, MAE is:3.22 & sMAPE is:6.49% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 15.15% & 0.85\n",
      "for 2018-07-15, MAE is:2.52 & sMAPE is:5.20% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 15.10% & 0.84\n",
      "for 2018-07-16, MAE is:3.18 & sMAPE is:6.08% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 15.06% & 0.84\n",
      "for 2018-07-17, MAE is:4.80 & sMAPE is:8.54% & rMAE is:2.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 15.02% & 0.85\n",
      "for 2018-07-18, MAE is:4.84 & sMAPE is:8.64% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 14.99% & 0.86\n",
      "for 2018-07-19, MAE is:4.76 & sMAPE is:8.69% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 14.96% & 0.86\n",
      "for 2018-07-20, MAE is:3.53 & sMAPE is:7.08% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 14.92% & 0.87\n",
      "for 2018-07-21, MAE is:3.01 & sMAPE is:5.52% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 14.87% & 0.87\n",
      "for 2018-07-22, MAE is:4.00 & sMAPE is:8.21% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 14.84% & 0.87\n",
      "for 2018-07-23, MAE is:2.97 & sMAPE is:5.27% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 14.79% & 0.88\n",
      "for 2018-07-24, MAE is:5.28 & sMAPE is:9.33% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 14.77% & 0.88\n",
      "for 2018-07-25, MAE is:4.55 & sMAPE is:8.13% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 14.74% & 0.88\n",
      "for 2018-07-26, MAE is:9.90 & sMAPE is:15.61% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 14.74% & 0.88\n",
      "for 2018-07-27, MAE is:5.55 & sMAPE is:9.01% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 14.71% & 0.88\n",
      "for 2018-07-28, MAE is:6.08 & sMAPE is:11.26% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 14.70% & 0.88\n",
      "for 2018-07-29, MAE is:3.92 & sMAPE is:8.70% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 14.67% & 0.88\n",
      "for 2018-07-30, MAE is:3.33 & sMAPE is:6.07% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 14.63% & 0.88\n",
      "for 2018-07-31, MAE is:6.96 & sMAPE is:12.90% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 14.62% & 0.89\n",
      "for 2018-08-01, MAE is:5.14 & sMAPE is:9.63% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 14.59% & 0.89\n",
      "for 2018-08-02, MAE is:4.69 & sMAPE is:8.18% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 14.56% & 0.89\n",
      "for 2018-08-03, MAE is:8.94 & sMAPE is:14.83% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 14.57% & 0.90\n",
      "for 2018-08-04, MAE is:5.51 & sMAPE is:10.12% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 14.54% & 0.90\n",
      "for 2018-08-05, MAE is:4.39 & sMAPE is:8.52% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 14.52% & 0.90\n",
      "for 2018-08-06, MAE is:7.05 & sMAPE is:10.90% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 14.50% & 0.90\n",
      "for 2018-08-07, MAE is:10.53 & sMAPE is:17.17% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 14.51% & 0.90\n",
      "for 2018-08-08, MAE is:5.26 & sMAPE is:9.18% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 14.49% & 0.90\n",
      "for 2018-08-09, MAE is:6.75 & sMAPE is:11.68% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 14.48% & 0.90\n",
      "for 2018-08-10, MAE is:3.82 & sMAPE is:7.60% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 14.44% & 0.90\n",
      "for 2018-08-11, MAE is:3.20 & sMAPE is:6.45% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 14.41% & 0.90\n",
      "for 2018-08-12, MAE is:7.28 & sMAPE is:15.47% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 14.41% & 0.90\n",
      "for 2018-08-13, MAE is:5.28 & sMAPE is:9.87% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 14.39% & 0.90\n",
      "for 2018-08-14, MAE is:4.92 & sMAPE is:9.31% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 14.37% & 0.90\n",
      "for 2018-08-15, MAE is:4.20 & sMAPE is:7.73% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 14.34% & 0.90\n",
      "for 2018-08-16, MAE is:6.00 & sMAPE is:11.01% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 14.33% & 0.90\n",
      "for 2018-08-17, MAE is:3.23 & sMAPE is:5.75% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 14.29% & 0.90\n",
      "for 2018-08-18, MAE is:4.67 & sMAPE is:8.85% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 14.27% & 0.90\n",
      "for 2018-08-19, MAE is:3.68 & sMAPE is:7.24% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 14.24% & 0.90\n",
      "for 2018-08-20, MAE is:12.51 & sMAPE is:20.30% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 14.26% & 0.90\n",
      "for 2018-08-21, MAE is:11.63 & sMAPE is:17.61% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 14.28% & 0.90\n",
      "for 2018-08-22, MAE is:14.66 & sMAPE is:23.19% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 14.31% & 0.90\n",
      "for 2018-08-23, MAE is:6.67 & sMAPE is:10.80% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 14.30% & 0.90\n",
      "for 2018-08-24, MAE is:6.45 & sMAPE is:10.99% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 14.29% & 0.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-08-25, MAE is:7.77 & sMAPE is:13.76% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 14.28% & 0.90\n",
      "for 2018-08-26, MAE is:3.95 & sMAPE is:7.32% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 14.25% & 0.90\n",
      "for 2018-08-27, MAE is:6.42 & sMAPE is:12.22% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 14.25% & 0.90\n",
      "for 2018-08-28, MAE is:12.32 & sMAPE is:20.40% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 14.27% & 0.91\n",
      "for 2018-08-29, MAE is:8.60 & sMAPE is:13.15% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 14.27% & 0.91\n",
      "for 2018-08-30, MAE is:6.93 & sMAPE is:13.20% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 14.26% & 0.91\n",
      "for 2018-08-31, MAE is:5.68 & sMAPE is:9.53% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 14.24% & 0.91\n",
      "for 2018-09-01, MAE is:2.79 & sMAPE is:4.78% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 14.20% & 0.91\n",
      "for 2018-09-02, MAE is:3.86 & sMAPE is:6.63% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 14.17% & 0.91\n",
      "for 2018-09-03, MAE is:9.42 & sMAPE is:15.44% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 14.18% & 0.91\n",
      "for 2018-09-04, MAE is:4.64 & sMAPE is:7.32% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 14.15% & 0.91\n",
      "for 2018-09-05, MAE is:7.33 & sMAPE is:11.08% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 14.14% & 0.92\n",
      "for 2018-09-06, MAE is:11.28 & sMAPE is:17.33% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 14.15% & 0.92\n",
      "for 2018-09-07, MAE is:5.19 & sMAPE is:8.21% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 14.13% & 0.92\n",
      "for 2018-09-08, MAE is:10.28 & sMAPE is:17.06% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 14.14% & 0.92\n",
      "for 2018-09-09, MAE is:5.24 & sMAPE is:8.96% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 14.12% & 0.93\n",
      "for 2018-09-10, MAE is:9.99 & sMAPE is:15.12% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 14.12% & 0.93\n",
      "for 2018-09-11, MAE is:10.37 & sMAPE is:15.45% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 14.13% & 0.93\n",
      "for 2018-09-12, MAE is:13.09 & sMAPE is:19.56% & rMAE is:2.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 14.15% & 0.94\n",
      "for 2018-09-13, MAE is:10.54 & sMAPE is:15.58% & rMAE is:2.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 14.15% & 0.95\n",
      "for 2018-09-14, MAE is:8.59 & sMAPE is:13.75% & rMAE is:3.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 14.15% & 0.96\n",
      "for 2018-09-15, MAE is:3.20 & sMAPE is:5.31% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 14.12% & 0.95\n",
      "for 2018-09-16, MAE is:8.55 & sMAPE is:16.28% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 14.13% & 0.96\n",
      "for 2018-09-17, MAE is:9.26 & sMAPE is:14.45% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 14.13% & 0.96\n",
      "for 2018-09-18, MAE is:7.80 & sMAPE is:12.46% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 14.12% & 0.96\n",
      "for 2018-09-19, MAE is:7.53 & sMAPE is:12.51% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 14.12% & 0.96\n",
      "for 2018-09-20, MAE is:9.46 & sMAPE is:15.78% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 14.12% & 0.96\n",
      "for 2018-09-21, MAE is:11.68 & sMAPE is:20.90% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 14.15% & 0.96\n",
      "for 2018-09-22, MAE is:11.89 & sMAPE is:19.90% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 14.17% & 0.96\n",
      "for 2018-09-23, MAE is:10.36 & sMAPE is:17.43% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 14.18% & 0.96\n",
      "for 2018-09-24, MAE is:7.19 & sMAPE is:13.13% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 14.18% & 0.96\n",
      "for 2018-09-25, MAE is:17.52 & sMAPE is:25.98% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 14.22% & 0.96\n",
      "for 2018-09-26, MAE is:11.71 & sMAPE is:16.98% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 14.23% & 0.96\n",
      "for 2018-09-27, MAE is:12.58 & sMAPE is:19.74% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 14.25% & 0.96\n",
      "for 2018-09-28, MAE is:8.08 & sMAPE is:12.80% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 14.25% & 0.96\n",
      "for 2018-09-29, MAE is:14.21 & sMAPE is:21.94% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 14.27% & 0.96\n",
      "for 2018-09-30, MAE is:8.57 & sMAPE is:13.67% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 14.27% & 0.96\n",
      "for 2018-10-01, MAE is:7.41 & sMAPE is:11.83% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 14.26% & 0.96\n",
      "for 2018-10-02, MAE is:8.94 & sMAPE is:14.52% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 14.26% & 0.96\n",
      "for 2018-10-03, MAE is:8.79 & sMAPE is:13.73% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 14.26% & 0.96\n",
      "for 2018-10-04, MAE is:9.76 & sMAPE is:15.04% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 14.27% & 0.96\n",
      "for 2018-10-05, MAE is:8.11 & sMAPE is:12.69% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 14.26% & 0.96\n",
      "for 2018-10-06, MAE is:5.13 & sMAPE is:8.41% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 14.24% & 0.96\n",
      "for 2018-10-07, MAE is:4.55 & sMAPE is:7.62% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 14.22% & 0.95\n",
      "for 2018-10-08, MAE is:10.84 & sMAPE is:16.65% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 14.22% & 0.95\n",
      "for 2018-10-09, MAE is:11.79 & sMAPE is:16.59% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 14.23% & 0.95\n",
      "for 2018-10-10, MAE is:9.62 & sMAPE is:14.11% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 14.23% & 0.95\n",
      "for 2018-10-11, MAE is:7.29 & sMAPE is:11.55% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 14.22% & 0.95\n",
      "for 2018-10-12, MAE is:8.25 & sMAPE is:14.15% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 14.22% & 0.96\n",
      "for 2018-10-13, MAE is:8.13 & sMAPE is:14.18% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 14.22% & 0.96\n",
      "for 2018-10-14, MAE is:9.08 & sMAPE is:16.57% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 14.23% & 0.96\n",
      "for 2018-10-15, MAE is:12.27 & sMAPE is:18.04% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 14.24% & 0.96\n",
      "for 2018-10-16, MAE is:9.51 & sMAPE is:13.32% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.24% & 0.96\n",
      "for 2018-10-17, MAE is:12.38 & sMAPE is:17.42% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 14.25% & 0.96\n",
      "for 2018-10-18, MAE is:7.11 & sMAPE is:11.20% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 14.24% & 0.96\n",
      "for 2018-10-19, MAE is:6.78 & sMAPE is:10.12% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 14.23% & 0.96\n",
      "for 2018-10-20, MAE is:4.39 & sMAPE is:7.34% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 14.20% & 0.96\n",
      "for 2018-10-21, MAE is:4.20 & sMAPE is:7.36% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.18% & 0.96\n",
      "for 2018-10-22, MAE is:8.94 & sMAPE is:15.05% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.18% & 0.96\n",
      "for 2018-10-23, MAE is:5.08 & sMAPE is:8.54% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.16% & 0.96\n",
      "for 2018-10-24, MAE is:7.05 & sMAPE is:12.61% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.16% & 0.96\n",
      "for 2018-10-25, MAE is:6.07 & sMAPE is:10.98% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 14.15% & 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-10-26, MAE is:7.63 & sMAPE is:12.90% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 14.14% & 0.96\n",
      "for 2018-10-27, MAE is:6.72 & sMAPE is:12.00% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 14.14% & 0.95\n",
      "for 2018-10-28, MAE is:6.03 & sMAPE is:10.82% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 14.13% & 0.95\n",
      "for 2018-10-29, MAE is:9.53 & sMAPE is:16.49% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.13% & 0.95\n",
      "for 2018-10-30, MAE is:7.80 & sMAPE is:13.39% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.13% & 0.95\n",
      "for 2018-10-31, MAE is:8.52 & sMAPE is:14.94% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.13% & 0.96\n",
      "for 2018-11-01, MAE is:6.12 & sMAPE is:10.95% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.12% & 0.96\n",
      "for 2018-11-02, MAE is:8.27 & sMAPE is:14.34% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.12% & 0.96\n",
      "for 2018-11-03, MAE is:8.70 & sMAPE is:15.39% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 14.13% & 0.96\n",
      "for 2018-11-04, MAE is:4.57 & sMAPE is:8.68% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.11% & 0.96\n",
      "for 2018-11-05, MAE is:7.05 & sMAPE is:11.59% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.10% & 0.96\n",
      "for 2018-11-06, MAE is:5.67 & sMAPE is:9.26% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.09% & 0.95\n",
      "for 2018-11-07, MAE is:6.38 & sMAPE is:10.85% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 14.08% & 0.95\n",
      "for 2018-11-08, MAE is:7.29 & sMAPE is:11.41% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.07% & 0.95\n",
      "for 2018-11-09, MAE is:6.30 & sMAPE is:9.75% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 14.05% & 0.95\n",
      "for 2018-11-10, MAE is:8.50 & sMAPE is:12.99% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.05% & 0.95\n",
      "for 2018-11-11, MAE is:8.49 & sMAPE is:14.63% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.05% & 0.95\n",
      "for 2018-11-12, MAE is:6.50 & sMAPE is:9.52% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.04% & 0.95\n",
      "for 2018-11-13, MAE is:7.02 & sMAPE is:10.71% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.03% & 0.95\n",
      "for 2018-11-14, MAE is:5.72 & sMAPE is:8.96% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 14.01% & 0.95\n",
      "for 2018-11-15, MAE is:6.46 & sMAPE is:9.70% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 14.00% & 0.95\n",
      "for 2018-11-16, MAE is:7.22 & sMAPE is:10.60% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 13.99% & 0.95\n",
      "for 2018-11-17, MAE is:7.53 & sMAPE is:12.15% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 13.98% & 0.95\n",
      "for 2018-11-18, MAE is:6.86 & sMAPE is:10.34% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 13.97% & 0.95\n",
      "for 2018-11-19, MAE is:11.45 & sMAPE is:18.89% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 13.99% & 0.95\n",
      "for 2018-11-20, MAE is:9.03 & sMAPE is:15.70% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 13.99% & 0.95\n",
      "for 2018-11-21, MAE is:9.55 & sMAPE is:13.61% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 13.99% & 0.95\n",
      "for 2018-11-22, MAE is:22.91 & sMAPE is:25.29% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 14.02% & 0.95\n",
      "for 2018-11-23, MAE is:17.01 & sMAPE is:21.83% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 14.05% & 0.96\n",
      "for 2018-11-24, MAE is:4.91 & sMAPE is:7.37% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 14.03% & 0.95\n",
      "for 2018-11-25, MAE is:7.48 & sMAPE is:11.81% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 14.02% & 0.95\n",
      "for 2018-11-26, MAE is:18.96 & sMAPE is:22.50% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 14.05% & 0.95\n",
      "for 2018-11-27, MAE is:11.78 & sMAPE is:15.68% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 14.05% & 0.95\n",
      "for 2018-11-28, MAE is:11.31 & sMAPE is:18.16% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 14.06% & 0.95\n",
      "for 2018-11-29, MAE is:6.87 & sMAPE is:11.76% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 14.06% & 0.95\n",
      "for 2018-11-30, MAE is:5.95 & sMAPE is:10.10% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 14.05% & 0.95\n",
      "for 2018-12-01, MAE is:7.99 & sMAPE is:14.05% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 14.05% & 0.95\n",
      "for 2018-12-02, MAE is:7.84 & sMAPE is:14.27% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 14.05% & 0.95\n",
      "for 2018-12-03, MAE is:6.83 & sMAPE is:13.06% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 14.04% & 0.95\n",
      "for 2018-12-04, MAE is:7.19 & sMAPE is:11.18% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 14.03% & 0.95\n",
      "for 2018-12-05, MAE is:5.93 & sMAPE is:9.90% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 14.02% & 0.95\n",
      "for 2018-12-06, MAE is:6.12 & sMAPE is:10.54% & rMAE is:2.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 14.01% & 0.95\n",
      "for 2018-12-07, MAE is:10.73 & sMAPE is:19.26% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 14.03% & 0.95\n",
      "for 2018-12-08, MAE is:9.07 & sMAPE is:17.81% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 14.04% & 0.95\n",
      "for 2018-12-09, MAE is:6.75 & sMAPE is:11.68% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 14.03% & 0.95\n",
      "for 2018-12-10, MAE is:6.94 & sMAPE is:10.76% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 14.02% & 0.95\n",
      "for 2018-12-11, MAE is:5.30 & sMAPE is:8.51% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 14.01% & 0.95\n",
      "for 2018-12-12, MAE is:11.18 & sMAPE is:16.28% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 14.01% & 0.95\n",
      "for 2018-12-13, MAE is:8.55 & sMAPE is:13.08% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 14.01% & 0.95\n",
      "for 2018-12-14, MAE is:10.21 & sMAPE is:14.54% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 14.01% & 0.95\n",
      "for 2018-12-15, MAE is:7.05 & sMAPE is:11.16% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 14.00% & 0.95\n",
      "for 2018-12-16, MAE is:7.43 & sMAPE is:12.32% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 14.00% & 0.95\n",
      "for 2018-12-17, MAE is:7.86 & sMAPE is:11.85% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 13.99% & 0.95\n",
      "for 2018-12-18, MAE is:7.31 & sMAPE is:11.52% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 13.99% & 0.95\n",
      "for 2018-12-19, MAE is:6.00 & sMAPE is:9.80% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 13.97% & 0.95\n",
      "for 2018-12-20, MAE is:5.77 & sMAPE is:9.29% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 13.96% & 0.95\n",
      "for 2018-12-21, MAE is:8.40 & sMAPE is:14.04% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 13.96% & 0.95\n",
      "for 2018-12-22, MAE is:6.13 & sMAPE is:10.99% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 13.95% & 0.95\n",
      "for 2018-12-23, MAE is:5.74 & sMAPE is:9.96% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 13.94% & 0.95\n",
      "for 2018-12-24, MAE is:9.42 & sMAPE is:15.52% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 13.95% & 0.94\n",
      "for 2018-12-25, MAE is:12.74 & sMAPE is:21.22% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 13.97% & 0.94\n",
      "for 2018-12-26, MAE is:6.44 & sMAPE is:10.71% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 13.96% & 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-12-27, MAE is:4.00 & sMAPE is:6.42% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 13.94% & 0.94\n",
      "for 2018-12-28, MAE is:8.46 & sMAPE is:12.46% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 13.93% & 0.95\n",
      "for 2018-12-29, MAE is:5.00 & sMAPE is:8.68% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 13.92% & 0.95\n",
      "for 2018-12-30, MAE is:10.33 & sMAPE is:17.40% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 13.93% & 0.95\n",
      "for 2018-12-31, MAE is:7.56 & sMAPE is:12.11% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 13.92% & 0.95\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:40:53,528]\u001b[0m A new study created in RDB with name: NL_2019\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:41:15,694]\u001b[0m Trial 0 finished with value: 11.424883296929258 and parameters: {'n_hidden': 3, 'learning_rate': 0.07540944037690493, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12021565654640815, 'dropout_rate_Layer_2': 0.1842972029207776, 'dropout_rate_Layer_3': 0.0023093075311404923, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.051970999030865e-05, 'l1_Layer_2': 0.0016598191838865944, 'l1_Layer_3': 4.016964654642e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 265, 'n_units_Layer_3': 150}. Best is trial 0 with value: 11.424883296929258.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.42 | sMAPE for Validation Set is: 22.43% | rMAE for Validation Set is: 1.30\n",
      "MAE for Test Set is: 6.22 | sMAPE for Test Set is: 15.55% | rMAE for Test Set is: 1.01\n",
      "MAE for Validation Set is: 12.55 | sMAPE for Validation Set is: 25.37% | rMAE for Validation Set is: 1.43\n",
      "MAE for Test Set is: 6.63 | sMAPE for Test Set is: 16.96% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:41:17,459]\u001b[0m Trial 2 finished with value: 12.554877620631311 and parameters: {'n_hidden': 4, 'learning_rate': 0.09205560248905681, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3568463178246073, 'dropout_rate_Layer_2': 0.03513722625925171, 'dropout_rate_Layer_3': 0.25742702788133465, 'dropout_rate_Layer_4': 0.25323393879115286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.006874683375579507, 'l1_Layer_2': 0.01850139547205979, 'l1_Layer_3': 0.08316320867928577, 'l1_Layer_4': 1.788266991616345e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 260, 'n_units_Layer_3': 95, 'n_units_Layer_4': 205}. Best is trial 0 with value: 11.424883296929258.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:41:21,850]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:41:25,315]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:41:30,103]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:41:35,869]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:41:40,929]\u001b[0m Trial 4 finished with value: 11.377863175225215 and parameters: {'n_hidden': 3, 'learning_rate': 0.039328804143294975, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29618569300864506, 'dropout_rate_Layer_2': 0.0890280881585241, 'dropout_rate_Layer_3': 0.1421934735190971, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002933059937204938, 'l1_Layer_2': 0.0042593326058804545, 'l1_Layer_3': 0.001997516509125765, 'n_units_Layer_1': 240, 'n_units_Layer_2': 90, 'n_units_Layer_3': 210}. Best is trial 4 with value: 11.377863175225215.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.38 | sMAPE for Validation Set is: 22.59% | rMAE for Validation Set is: 1.29\n",
      "MAE for Test Set is: 6.14 | sMAPE for Test Set is: 15.42% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:41:46,104]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:41:50,952]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:41:55,764]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:41:59,849]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:42:07,790]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:42:08,301]\u001b[0m Trial 3 finished with value: 18.253191451502467 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005039590924584779, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38207175080340905, 'dropout_rate_Layer_2': 0.2914794063604317, 'dropout_rate_Layer_3': 0.11812213486271368, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0035954011781496598, 'l1_Layer_2': 0.05826499226382278, 'l1_Layer_3': 0.0016876991633186255, 'n_units_Layer_1': 190, 'n_units_Layer_2': 220, 'n_units_Layer_3': 90}. Best is trial 4 with value: 11.377863175225215.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.25 | sMAPE for Validation Set is: 38.66% | rMAE for Validation Set is: 2.07\n",
      "MAE for Test Set is: 8.15 | sMAPE for Test Set is: 20.42% | rMAE for Test Set is: 1.32\n",
      "MAE for Validation Set is: 7.81 | sMAPE for Validation Set is: 14.81% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 5.57 | sMAPE for Test Set is: 13.83% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:42:08,462]\u001b[0m Trial 9 finished with value: 7.806056548052882 and parameters: {'n_hidden': 3, 'learning_rate': 0.016314228653794137, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37983948625730657, 'dropout_rate_Layer_2': 0.02704078064899003, 'dropout_rate_Layer_3': 0.23971487085625454, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014940863542217892, 'l1_Layer_2': 0.03954957451073458, 'l1_Layer_3': 0.0017273510860295507, 'n_units_Layer_1': 205, 'n_units_Layer_2': 205, 'n_units_Layer_3': 285}. Best is trial 9 with value: 7.806056548052882.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:42:16,448]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:42:24,022]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:42:27,621]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:42:32,441]\u001b[0m Trial 1 finished with value: 10.119653427001483 and parameters: {'n_hidden': 3, 'learning_rate': 0.009310834152621916, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2671440537354482, 'dropout_rate_Layer_2': 0.19731852470762173, 'dropout_rate_Layer_3': 0.33335280275150003, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.016351924507334182, 'l1_Layer_2': 0.00033803350483019084, 'l1_Layer_3': 0.006044576980464884, 'n_units_Layer_1': 220, 'n_units_Layer_2': 170, 'n_units_Layer_3': 65}. Best is trial 9 with value: 7.806056548052882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.12 | sMAPE for Validation Set is: 19.69% | rMAE for Validation Set is: 1.15\n",
      "MAE for Test Set is: 6.17 | sMAPE for Test Set is: 15.11% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:42:34,703]\u001b[0m Trial 17 finished with value: 9.749636716079001 and parameters: {'n_hidden': 3, 'learning_rate': 0.0057349747785666455, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.362873935656244, 'dropout_rate_Layer_2': 0.20293896235413894, 'dropout_rate_Layer_3': 0.15215269384863858, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00046504377437751816, 'l1_Layer_2': 0.00041330183971779484, 'l1_Layer_3': 0.00023285162438814474, 'n_units_Layer_1': 150, 'n_units_Layer_2': 125, 'n_units_Layer_3': 65}. Best is trial 9 with value: 7.806056548052882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.75 | sMAPE for Validation Set is: 18.98% | rMAE for Validation Set is: 1.11\n",
      "MAE for Test Set is: 5.47 | sMAPE for Test Set is: 13.52% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:42:35,054]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:42:37,050]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:42:42,043]\u001b[0m Trial 16 finished with value: 7.503731566851809 and parameters: {'n_hidden': 3, 'learning_rate': 0.09012818713961546, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04585848260993605, 'dropout_rate_Layer_2': 0.16472655662027427, 'dropout_rate_Layer_3': 0.36222467062114194, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011762535806906469, 'l1_Layer_2': 0.001256282867770647, 'l1_Layer_3': 0.00012667652797456128, 'n_units_Layer_1': 55, 'n_units_Layer_2': 250, 'n_units_Layer_3': 185}. Best is trial 16 with value: 7.503731566851809.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.50 | sMAPE for Validation Set is: 14.41% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 4.92 | sMAPE for Test Set is: 12.29% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:42:43,460]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:42:43,729]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:42:46,741]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:42:56,011]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:00,281]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:01,092]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:02,533]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:08,863]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:09,842]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:11,078]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:14,755]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:20,352]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:20,541]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:25,815]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:27,388]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:32,750]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:34,544]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:38,160]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:39,286]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:42,981]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:44,133]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:46,086]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:48,040]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:51,890]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:52,418]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:43:52,670]\u001b[0m Trial 24 finished with value: 8.569635321068363 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023278715170140674, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16752508243890485, 'dropout_rate_Layer_2': 0.21852457248526247, 'dropout_rate_Layer_3': 0.3274814617782701, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020045842981549725, 'l1_Layer_2': 0.0004577989488879477, 'l1_Layer_3': 0.00031020087115614267, 'n_units_Layer_1': 300, 'n_units_Layer_2': 130, 'n_units_Layer_3': 145}. Best is trial 16 with value: 7.503731566851809.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.57 | sMAPE for Validation Set is: 16.49% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 5.50 | sMAPE for Test Set is: 13.77% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:43:53,147]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:00,701]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:02,189]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:02,379]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:04,426]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:08,881]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:09,004]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:13,969]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:15,498]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:18,896]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:22,193]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:22,401]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:27,773]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:30,234]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:30,631]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:32,241]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:37,425]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:37,622]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:42,829]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:43,119]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:43,426]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:47,194]\u001b[0m Trial 49 finished with value: 7.438531192481186 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006967047667850817, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16182762992671618, 'dropout_rate_Layer_2': 0.32366735478253783, 'dropout_rate_Layer_3': 0.35980931028245944, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002590383496497158, 'l1_Layer_2': 0.0013557452776508858, 'l1_Layer_3': 5.860529922835601e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 100, 'n_units_Layer_3': 190}. Best is trial 49 with value: 7.438531192481186.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.44 | sMAPE for Validation Set is: 14.26% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 5.15 | sMAPE for Test Set is: 12.87% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:44:48,564]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:52,704]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:54,016]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:57,723]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:58,294]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:44:58,750]\u001b[0m Trial 71 finished with value: 10.563022276453909 and parameters: {'n_hidden': 3, 'learning_rate': 0.027363246742795718, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3414418650126977, 'dropout_rate_Layer_2': 0.3261994120400914, 'dropout_rate_Layer_3': 0.37280613075560054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0006217522810553397, 'l1_Layer_2': 0.012119682038897295, 'l1_Layer_3': 0.01338463493291541, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 225}. Best is trial 49 with value: 7.438531192481186.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.56 | sMAPE for Validation Set is: 20.50% | rMAE for Validation Set is: 1.20\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 15.29% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:45:04,051]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:45:04,553]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:45:10,029]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:45:11,782]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:45:14,614]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:45:19,259]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:45:21,201]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:45:21,466]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:45:24,337]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:45:28,902]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:45:32,166]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:45:37,909]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:45:37,995]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:45:46,047]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:45:53,947]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:45:56,754]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:45:57,257]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:02,403]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:04,826]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:10,205]\u001b[0m Trial 86 finished with value: 6.72757609105421 and parameters: {'n_hidden': 3, 'learning_rate': 0.001187595655643435, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21006132714443926, 'dropout_rate_Layer_2': 0.34791423741151073, 'dropout_rate_Layer_3': 0.0601862643770493, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014577865640323132, 'l1_Layer_2': 0.00015965080805262278, 'l1_Layer_3': 0.00012306994557569737, 'n_units_Layer_1': 285, 'n_units_Layer_2': 235, 'n_units_Layer_3': 95}. Best is trial 86 with value: 6.72757609105421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.73 | sMAPE for Validation Set is: 12.78% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 14.39% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:46:12,000]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:15,403]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:18,119]\u001b[0m Trial 96 finished with value: 9.045916394752275 and parameters: {'n_hidden': 3, 'learning_rate': 0.015789316526827295, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3679390018494303, 'dropout_rate_Layer_2': 0.20968334285013746, 'dropout_rate_Layer_3': 0.11629604941755042, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0035852880734587467, 'l1_Layer_2': 0.00155789889199439, 'l1_Layer_3': 0.0012117127946117607, 'n_units_Layer_1': 95, 'n_units_Layer_2': 125, 'n_units_Layer_3': 80}. Best is trial 86 with value: 6.72757609105421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.05 | sMAPE for Validation Set is: 17.52% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 5.62 | sMAPE for Test Set is: 13.95% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:46:18,700]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:20,227]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:22,281]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:26,078]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:26,967]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:27,535]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:29,628]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:36,232]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:37,967]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:38,291]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:46,264]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:49,582]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:52,919]\u001b[0m Trial 108 finished with value: 9.435184403762248 and parameters: {'n_hidden': 3, 'learning_rate': 0.006160123938608685, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23403608224769878, 'dropout_rate_Layer_2': 0.30817370242932846, 'dropout_rate_Layer_3': 0.2025900599953163, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.194859400108825e-05, 'l1_Layer_2': 6.938257146425058e-05, 'l1_Layer_3': 0.0016829995857368845, 'n_units_Layer_1': 90, 'n_units_Layer_2': 160, 'n_units_Layer_3': 170}. Best is trial 86 with value: 6.72757609105421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.44 | sMAPE for Validation Set is: 18.54% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 5.66 | sMAPE for Test Set is: 13.90% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:46:55,020]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:57,753]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:46:59,637]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:47:02,144]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:47:06,751]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:47:10,156]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:47:12,849]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:47:15,100]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:47:19,439]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:47:24,670]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:47:25,027]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:47:30,680]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:47:34,407]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:47:41,064]\u001b[0m Trial 113 finished with value: 6.375467434648695 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005784885621395321, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1549038552620196, 'dropout_rate_Layer_2': 0.3166419133585003, 'dropout_rate_Layer_3': 0.36509780083001514, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008775532779336908, 'l1_Layer_2': 0.00011389701516796825, 'l1_Layer_3': 0.0009280218653179766, 'n_units_Layer_1': 135, 'n_units_Layer_2': 245, 'n_units_Layer_3': 175}. Best is trial 113 with value: 6.375467434648695.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 12.20% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.26 | sMAPE for Test Set is: 13.23% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:47:45,063]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:47:48,138]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:47:57,650]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:48:06,694]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:48:09,997]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:48:14,352]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:48:16,222]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:48:20,553]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:48:27,293]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:48:31,556]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:48:36,236]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:48:36,695]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:48:43,632]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:48:44,108]\u001b[0m Trial 137 finished with value: 6.976021591431601 and parameters: {'n_hidden': 3, 'learning_rate': 0.040709719205060536, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27601867810575514, 'dropout_rate_Layer_2': 0.05108733331498511, 'dropout_rate_Layer_3': 0.1527628629827965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00211393187694106, 'l1_Layer_2': 0.022147792201937862, 'l1_Layer_3': 0.000744616672417356, 'n_units_Layer_1': 140, 'n_units_Layer_2': 300, 'n_units_Layer_3': 55}. Best is trial 113 with value: 6.375467434648695.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.98 | sMAPE for Validation Set is: 13.27% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 5.00 | sMAPE for Test Set is: 12.53% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:48:44,493]\u001b[0m Trial 136 finished with value: 8.691866511845719 and parameters: {'n_hidden': 3, 'learning_rate': 0.04884636168460554, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27380805214221776, 'dropout_rate_Layer_2': 0.04961106644253417, 'dropout_rate_Layer_3': 0.15677526661061733, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0028435784648399454, 'l1_Layer_2': 0.0014282806773003164, 'l1_Layer_3': 0.0007330176897821499, 'n_units_Layer_1': 130, 'n_units_Layer_2': 95, 'n_units_Layer_3': 270}. Best is trial 113 with value: 6.375467434648695.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.69 | sMAPE for Validation Set is: 16.60% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 14.12% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:48:52,069]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:48:52,181]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:48:52,326]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:48:53,083]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:49:02,084]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:49:03,132]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:49:04,314]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:49:06,810]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:49:09,832]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:49:12,344]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:49:16,823]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:49:20,498]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:49:20,804]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:49:21,284]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:49:32,935]\u001b[0m Trial 148 finished with value: 6.826487240169745 and parameters: {'n_hidden': 3, 'learning_rate': 0.017302694802009463, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19359314552210055, 'dropout_rate_Layer_2': 0.26849404755291617, 'dropout_rate_Layer_3': 0.0644059755200726, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008098622866055572, 'l1_Layer_2': 0.0442071702757597, 'l1_Layer_3': 6.393327927364578e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 285, 'n_units_Layer_3': 60}. Best is trial 113 with value: 6.375467434648695.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.83 | sMAPE for Validation Set is: 12.96% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 14.73% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:49:49,846]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:49:50,316]\u001b[0m Trial 158 finished with value: 6.639344101857873 and parameters: {'n_hidden': 3, 'learning_rate': 0.0576840600762504, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1673438474008241, 'dropout_rate_Layer_2': 0.0005063655844341486, 'dropout_rate_Layer_3': 0.16875655394069564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016986406803534398, 'l1_Layer_2': 0.00830398276368642, 'l1_Layer_3': 0.00038733642285880164, 'n_units_Layer_1': 180, 'n_units_Layer_2': 150, 'n_units_Layer_3': 275}. Best is trial 113 with value: 6.375467434648695.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.64 | sMAPE for Validation Set is: 12.69% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 5.92 | sMAPE for Test Set is: 14.66% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:49:55,475]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:50:00,650]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:50:02,960]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:50:06,990]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:50:07,676]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:50:13,051]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:50:25,454]\u001b[0m Trial 159 finished with value: 6.004403577081763 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006425121725977016, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10730715224617576, 'dropout_rate_Layer_2': 0.31883949397567224, 'dropout_rate_Layer_3': 0.04702222924204144, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.379149397676784e-05, 'l1_Layer_2': 0.001911712903301922, 'l1_Layer_3': 5.543614743474941e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 215, 'n_units_Layer_3': 125}. Best is trial 159 with value: 6.004403577081763.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 11.45% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.91 | sMAPE for Test Set is: 12.31% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:50:32,362]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:50:32,695]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:50:33,169]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:50:40,157]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:50:43,096]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:50:46,234]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:50:48,744]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:50:51,881]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:50:56,401]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:50:59,206]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:51:01,980]\u001b[0m Trial 161 finished with value: 6.448282158396985 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006262307025042109, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09540087844740064, 'dropout_rate_Layer_2': 0.31944241564385256, 'dropout_rate_Layer_3': 0.052139795821096985, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.129558161648307e-05, 'l1_Layer_2': 0.0016794629476985369, 'l1_Layer_3': 0.07430151296049647, 'n_units_Layer_1': 290, 'n_units_Layer_2': 100, 'n_units_Layer_3': 135}. Best is trial 159 with value: 6.004403577081763.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 12.35% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 12.75% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:51:04,760]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:51:09,288]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:51:15,066]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:51:18,118]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:51:23,083]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:51:28,485]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:51:30,175]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:51:33,517]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:51:36,789]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:51:39,514]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:51:40,035]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:51:46,477]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:51:49,717]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:51:55,322]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:51:58,398]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:52:01,410]\u001b[0m Trial 178 finished with value: 6.065314630867159 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010654310525019517, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13809315173061623, 'dropout_rate_Layer_2': 0.3175063083285513, 'dropout_rate_Layer_3': 0.021965893364061764, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.451961897676227e-05, 'l1_Layer_2': 0.011506755001332311, 'l1_Layer_3': 0.00032573067919832187, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110}. Best is trial 159 with value: 6.004403577081763.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 11.55% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 12.25% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:52:04,177]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:52:11,079]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:52:15,364]\u001b[0m Trial 194 finished with value: 8.029643208390063 and parameters: {'n_hidden': 3, 'learning_rate': 0.023684500358978355, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.379099047040122, 'dropout_rate_Layer_2': 0.1963967185894409, 'dropout_rate_Layer_3': 0.1605511956641639, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011364593991500649, 'l1_Layer_2': 0.0046384970286411425, 'l1_Layer_3': 4.6086707258810313e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 135, 'n_units_Layer_3': 60}. Best is trial 159 with value: 6.004403577081763.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.03 | sMAPE for Validation Set is: 15.27% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 5.72 | sMAPE for Test Set is: 13.99% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:52:16,317]\u001b[0m Trial 177 finished with value: 6.061899959157522 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005945965246721674, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13821722899349972, 'dropout_rate_Layer_2': 0.13205423630929297, 'dropout_rate_Layer_3': 0.03266027677002007, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012143563525141188, 'l1_Layer_2': 0.0034134522641930906, 'l1_Layer_3': 0.0021778411801826048, 'n_units_Layer_1': 295, 'n_units_Layer_2': 190, 'n_units_Layer_3': 115}. Best is trial 159 with value: 6.004403577081763.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.06 | sMAPE for Validation Set is: 11.57% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.82 | sMAPE for Test Set is: 12.12% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:52:19,919]\u001b[0m Trial 195 finished with value: 7.761595390220371 and parameters: {'n_hidden': 3, 'learning_rate': 0.025047809908749677, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3757542940674888, 'dropout_rate_Layer_2': 0.09008712373368823, 'dropout_rate_Layer_3': 0.16392270232013656, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5408949097437403e-05, 'l1_Layer_2': 0.005008359812956811, 'l1_Layer_3': 0.0002616929572044304, 'n_units_Layer_1': 90, 'n_units_Layer_2': 135, 'n_units_Layer_3': 65}. Best is trial 159 with value: 6.004403577081763.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.76 | sMAPE for Validation Set is: 14.73% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 14.04% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:52:22,520]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:52:25,551]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:52:26,108]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:52:28,758]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:52:31,500]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:52:36,315]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:52:36,962]\u001b[0m Trial 200 finished with value: 7.784966947859225 and parameters: {'n_hidden': 3, 'learning_rate': 0.02073052542722666, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36840215452776864, 'dropout_rate_Layer_2': 0.07855424143152723, 'dropout_rate_Layer_3': 0.10255872325109319, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011798511212305149, 'l1_Layer_2': 0.0027197811355325744, 'l1_Layer_3': 3.6982582859073546e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 140, 'n_units_Layer_3': 60}. Best is trial 159 with value: 6.004403577081763.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.78 | sMAPE for Validation Set is: 14.81% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 5.53 | sMAPE for Test Set is: 13.65% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:52:40,930]\u001b[0m Trial 203 finished with value: 8.005776628133749 and parameters: {'n_hidden': 3, 'learning_rate': 0.021701097311224396, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3688023077923708, 'dropout_rate_Layer_2': 0.08114536665060018, 'dropout_rate_Layer_3': 0.10235006487740994, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.965715220165503e-05, 'l1_Layer_2': 0.002649824775903093, 'l1_Layer_3': 4.1366968324251474e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 140, 'n_units_Layer_3': 50}. Best is trial 159 with value: 6.004403577081763.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.01 | sMAPE for Validation Set is: 15.27% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 16.12% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:52:44,313]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.46 | sMAPE for Validation Set is: 14.17% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 6.09 | sMAPE for Test Set is: 14.95% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:52:46,731]\u001b[0m Trial 204 finished with value: 7.461812497845796 and parameters: {'n_hidden': 3, 'learning_rate': 0.02167490081000457, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3684350237766441, 'dropout_rate_Layer_2': 0.023124553548117543, 'dropout_rate_Layer_3': 0.10205099945029751, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012593297143254943, 'l1_Layer_2': 0.0023313952958006943, 'l1_Layer_3': 0.0003508927765184914, 'n_units_Layer_1': 105, 'n_units_Layer_2': 140, 'n_units_Layer_3': 50}. Best is trial 159 with value: 6.004403577081763.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:52:46,887]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:52:52,644]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.43 | sMAPE for Validation Set is: 14.14% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 14.62% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:52:54,197]\u001b[0m Trial 206 finished with value: 7.427420473480578 and parameters: {'n_hidden': 3, 'learning_rate': 0.02148424003761364, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36086583440681436, 'dropout_rate_Layer_2': 0.07495930165671924, 'dropout_rate_Layer_3': 0.10019135226184499, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011573077908873472, 'l1_Layer_2': 0.002730744516863555, 'l1_Layer_3': 4.001538528819682e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 140, 'n_units_Layer_3': 60}. Best is trial 159 with value: 6.004403577081763.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:52:58,507]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:53:05,931]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:53:10,495]\u001b[0m Trial 214 finished with value: 8.022244769909749 and parameters: {'n_hidden': 3, 'learning_rate': 0.04308439838046648, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3560055334785991, 'dropout_rate_Layer_2': 0.028752772682345842, 'dropout_rate_Layer_3': 0.07617223626255361, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.967734456937924e-05, 'l1_Layer_2': 0.004127233372005578, 'l1_Layer_3': 4.0956242554398305e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 140, 'n_units_Layer_3': 55}. Best is trial 159 with value: 6.004403577081763.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.02 | sMAPE for Validation Set is: 15.24% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 15.73% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:53:13,984]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:53:14,500]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:53:20,279]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:53:27,228]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:53:31,441]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:53:35,450]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:53:49,025]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:53:52,074]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:54:03,698]\u001b[0m Trial 211 finished with value: 5.986819840010317 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006412695503679155, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16198824797397116, 'dropout_rate_Layer_2': 0.3312652256747278, 'dropout_rate_Layer_3': 0.04846378572919322, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002561978513163003, 'l1_Layer_2': 0.00022908974907906714, 'l1_Layer_3': 0.0051385311555476425, 'n_units_Layer_1': 220, 'n_units_Layer_2': 140, 'n_units_Layer_3': 135}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.99 | sMAPE for Validation Set is: 11.41% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.91 | sMAPE for Test Set is: 12.35% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:54:03,908]\u001b[0m Trial 212 finished with value: 6.038701678263631 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006636333017344314, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12634292842409348, 'dropout_rate_Layer_2': 0.09222431712395471, 'dropout_rate_Layer_3': 0.04387064398281031, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016607347910150243, 'l1_Layer_2': 0.0014361214219945954, 'l1_Layer_3': 0.0001650504937909869, 'n_units_Layer_1': 290, 'n_units_Layer_2': 240, 'n_units_Layer_3': 110}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 11.56% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.91 | sMAPE for Test Set is: 12.42% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:54:12,384]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:54:17,588]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:54:28,564]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:54:32,593]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:54:37,691]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:54:38,173]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:54:38,308]\u001b[0m Trial 222 finished with value: 6.136728743956297 and parameters: {'n_hidden': 3, 'learning_rate': 0.000608475591499682, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16294802863332164, 'dropout_rate_Layer_2': 0.3542883053760088, 'dropout_rate_Layer_3': 0.0430525414366192, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002578047800479918, 'l1_Layer_2': 6.465487450258347e-05, 'l1_Layer_3': 0.01433651738794845, 'n_units_Layer_1': 290, 'n_units_Layer_2': 235, 'n_units_Layer_3': 200}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 11.71% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.97 | sMAPE for Test Set is: 12.49% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:54:47,342]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:54:47,890]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:54:53,110]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:54:53,450]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.41 | sMAPE for Validation Set is: 14.08% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 14.58% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:54:55,733]\u001b[0m Trial 233 finished with value: 7.412695861670779 and parameters: {'n_hidden': 3, 'learning_rate': 0.015330066169609479, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32755133871341646, 'dropout_rate_Layer_2': 0.04169619112112318, 'dropout_rate_Layer_3': 0.06815392093382798, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003017032188547668, 'l1_Layer_2': 0.00356953186123562, 'l1_Layer_3': 1.8304281896442803e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 120, 'n_units_Layer_3': 95}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:55:01,510]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:55:04,520]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:55:04,914]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:55:20,347]\u001b[0m Trial 224 finished with value: 6.087205145301322 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005755528994495657, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07648975130071502, 'dropout_rate_Layer_2': 0.1662366679456708, 'dropout_rate_Layer_3': 0.027650104452109546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002796093791139846, 'l1_Layer_2': 0.006247083925738862, 'l1_Layer_3': 0.00017004150248365094, 'n_units_Layer_1': 185, 'n_units_Layer_2': 265, 'n_units_Layer_3': 150}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 11.60% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.91 | sMAPE for Test Set is: 12.37% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:55:21,097]\u001b[0m Trial 241 finished with value: 7.59860533090055 and parameters: {'n_hidden': 3, 'learning_rate': 0.017659024349950724, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36954743655471867, 'dropout_rate_Layer_2': 0.037201244920688895, 'dropout_rate_Layer_3': 0.10920914842492058, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011672228792328413, 'l1_Layer_2': 0.002935971138686241, 'l1_Layer_3': 4.75547922486979e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 140, 'n_units_Layer_3': 65}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.60 | sMAPE for Validation Set is: 14.38% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 5.38 | sMAPE for Test Set is: 13.34% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:55:24,140]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:55:27,708]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:55:41,276]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:55:49,423]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:55:53,853]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:55:59,432]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:56:02,819]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:56:10,961]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:56:12,816]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:56:23,019]\u001b[0m Trial 240 finished with value: 6.128452386234503 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007255644073963131, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17012990133722133, 'dropout_rate_Layer_2': 0.39730209217164525, 'dropout_rate_Layer_3': 0.04123132917873912, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008828671807351989, 'l1_Layer_2': 0.0003511838731028135, 'l1_Layer_3': 0.005325686200316041, 'n_units_Layer_1': 260, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 11.69% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 12.35% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:56:28,125]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:56:30,580]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:56:31,273]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:56:35,678]\u001b[0m Trial 244 finished with value: 6.058300926156993 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007407626794397495, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07729322545934403, 'dropout_rate_Layer_2': 0.058409266953411115, 'dropout_rate_Layer_3': 0.07269853910298485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004025347969351125, 'l1_Layer_2': 0.006376216730798001, 'l1_Layer_3': 0.00022456155337880593, 'n_units_Layer_1': 260, 'n_units_Layer_2': 110, 'n_units_Layer_3': 205}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.06 | sMAPE for Validation Set is: 11.54% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.77 | sMAPE for Test Set is: 11.97% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:56:40,147]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:56:41,923]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:56:46,644]\u001b[0m Trial 254 finished with value: 7.571273295093515 and parameters: {'n_hidden': 3, 'learning_rate': 0.025806801156303946, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3134564307054847, 'dropout_rate_Layer_2': 0.0698842822180253, 'dropout_rate_Layer_3': 0.055476113605718816, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.176286772062028e-05, 'l1_Layer_2': 0.002759557883370152, 'l1_Layer_3': 3.2013514229043875e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 165, 'n_units_Layer_3': 55}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.57 | sMAPE for Validation Set is: 14.29% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 5.44 | sMAPE for Test Set is: 13.56% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:56:46,949]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:56:47,252]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:56:47,460]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:56:57,529]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:56:58,415]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:02,198]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:05,379]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:07,976]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:11,072]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:13,976]\u001b[0m Trial 263 finished with value: 7.699974360492643 and parameters: {'n_hidden': 3, 'learning_rate': 0.022958758475791395, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19890267163777212, 'dropout_rate_Layer_2': 0.22559224858627466, 'dropout_rate_Layer_3': 0.09279717526434605, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007500658975005184, 'l1_Layer_2': 0.0002775089862135032, 'l1_Layer_3': 1.2002284477776964e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 245, 'n_units_Layer_3': 65}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:14,129]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.70 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 13.42% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:57:14,584]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:20,093]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:20,341]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:20,750]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:26,235]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:28,696]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:28,721]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:32,982]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:34,489]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:37,236]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:43,168]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:46,448]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:48,293]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:52,345]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:54,469]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:57:55,727]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:01,203]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:02,794]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:05,317]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:05,817]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:08,175]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:10,994]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:12,905]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:17,785]\u001b[0m Trial 284 finished with value: 7.530782718134549 and parameters: {'n_hidden': 3, 'learning_rate': 0.0385467402431184, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.250686176227055, 'dropout_rate_Layer_2': 0.2456095872838992, 'dropout_rate_Layer_3': 0.03543163828450621, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007760764932380417, 'l1_Layer_2': 0.0007519944208235443, 'l1_Layer_3': 1.5440266796415694e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 240, 'n_units_Layer_3': 90}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.53 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 6.34 | sMAPE for Test Set is: 16.44% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:58:20,083]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:20,757]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:23,067]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:26,894]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:32,635]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:32,721]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:37,813]\u001b[0m Trial 294 finished with value: 7.755960518305973 and parameters: {'n_hidden': 3, 'learning_rate': 0.038427574396356086, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19842397602606704, 'dropout_rate_Layer_2': 0.17713035230214905, 'dropout_rate_Layer_3': 0.15373929320916474, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008030361791751818, 'l1_Layer_2': 0.0004833367025943916, 'l1_Layer_3': 3.688217412194634e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 240, 'n_units_Layer_3': 90}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.76 | sMAPE for Validation Set is: 14.72% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 14.81% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:58:38,210]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:38,780]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:44,659]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:47,629]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:48,853]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:51,935]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:58:56,348]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:01,279]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:04,530]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:05,041]\u001b[0m Trial 300 finished with value: 7.874151819511497 and parameters: {'n_hidden': 3, 'learning_rate': 0.03353349658694318, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19777067553197814, 'dropout_rate_Layer_2': 0.21462432020190442, 'dropout_rate_Layer_3': 0.08520148286076988, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001175523812310492, 'l1_Layer_2': 0.0005548028726527364, 'l1_Layer_3': 1.6331335753452117e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 265, 'n_units_Layer_3': 65}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:05,069]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.87 | sMAPE for Validation Set is: 14.90% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 6.78 | sMAPE for Test Set is: 16.56% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:59:05,299]\u001b[0m Trial 306 finished with value: 7.96244547463884 and parameters: {'n_hidden': 3, 'learning_rate': 0.01560905754239802, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37015570497738287, 'dropout_rate_Layer_2': 0.10020960214474765, 'dropout_rate_Layer_3': 0.15079485049304608, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000404748382903303, 'l1_Layer_2': 0.007352415267353269, 'l1_Layer_3': 2.077743800197889e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 180, 'n_units_Layer_3': 60}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.96 | sMAPE for Validation Set is: 15.10% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 14.51% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:59:08,091]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:15,217]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:15,632]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:17,242]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:21,823]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:22,785]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:28,956]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.53 | sMAPE for Validation Set is: 14.31% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 13.67% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:59:29,105]\u001b[0m Trial 315 finished with value: 7.533882306008363 and parameters: {'n_hidden': 3, 'learning_rate': 0.01590521989317668, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39003186289530845, 'dropout_rate_Layer_2': 0.05300436824322478, 'dropout_rate_Layer_3': 0.08530173631596115, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00047468189802936215, 'l1_Layer_2': 0.00387185055006523, 'l1_Layer_3': 3.597966753196864e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 210, 'n_units_Layer_3': 60}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:30,321]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:34,728]\u001b[0m Trial 316 finished with value: 7.79869162105759 and parameters: {'n_hidden': 3, 'learning_rate': 0.015525776173444647, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3885161331055037, 'dropout_rate_Layer_2': 0.10462495779427955, 'dropout_rate_Layer_3': 0.14464585053147433, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004151752350439044, 'l1_Layer_2': 0.0056173684455714116, 'l1_Layer_3': 3.727790168162158e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 200, 'n_units_Layer_3': 70}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.80 | sMAPE for Validation Set is: 14.83% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 5.34 | sMAPE for Test Set is: 13.14% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 19:59:40,452]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:40,687]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:40,711]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:41,413]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:48,033]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:51,570]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:52,006]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:52,122]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:54,584]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 19:59:58,215]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:01,125]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:02,529]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:05,120]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:07,991]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:07,993]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:12,392]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:16,265]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:16,812]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:20,151]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:23,541]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:23,648]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:24,047]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:30,082]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:31,368]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:33,620]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:33,825]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:34,673]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.94 | sMAPE for Validation Set is: 15.09% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 5.69 | sMAPE for Test Set is: 14.26% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:00:38,476]\u001b[0m Trial 339 finished with value: 7.940169519996288 and parameters: {'n_hidden': 3, 'learning_rate': 0.03832013238059775, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22340965996495513, 'dropout_rate_Layer_2': 0.27879126881566524, 'dropout_rate_Layer_3': 0.14251483674707785, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007251548569081376, 'l1_Layer_2': 0.00031522025043172436, 'l1_Layer_3': 1.07091575747186e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 240, 'n_units_Layer_3': 90}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:42,868]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:43,234]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:48,270]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:48,779]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:50,907]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:56,054]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:56,182]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:56,865]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:00:57,738]\u001b[0m Trial 350 finished with value: 7.951676269794086 and parameters: {'n_hidden': 3, 'learning_rate': 0.0432625676179104, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19227070692981868, 'dropout_rate_Layer_2': 0.27899086727372713, 'dropout_rate_Layer_3': 0.14452658988661235, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007531323838454868, 'l1_Layer_2': 0.0003293982162453019, 'l1_Layer_3': 3.560386111792685e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 235, 'n_units_Layer_3': 125}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.95 | sMAPE for Validation Set is: 15.12% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 5.60 | sMAPE for Test Set is: 13.88% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:01:04,705]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:05,216]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:05,844]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:11,059]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:11,314]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:13,701]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:16,749]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:21,549]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:22,116]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:22,379]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:29,516]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:30,055]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:33,714]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:33,882]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:40,148]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:45,113]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:45,644]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:46,126]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:53,602]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:55,726]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:01:56,375]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:03,186]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:03,491]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:07,536]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:11,775]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:13,545]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:14,483]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:18,414]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:20,626]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:20,891]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:25,709]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:26,692]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:30,788]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:30,921]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:35,255]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:35,533]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:35,586]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:35,928]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:45,206]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:46,865]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:47,499]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:49,955]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:52,513]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:55,078]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:02:57,002]\u001b[0m Trial 398 finished with value: 8.157887764341114 and parameters: {'n_hidden': 3, 'learning_rate': 0.03573653729318582, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38744689837391344, 'dropout_rate_Layer_2': 0.09297678541102716, 'dropout_rate_Layer_3': 0.08120703365846323, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.893822544455183e-05, 'l1_Layer_2': 0.003069634137207914, 'l1_Layer_3': 7.110313136478788e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 110, 'n_units_Layer_3': 65}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.16 | sMAPE for Validation Set is: 15.54% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 6.16 | sMAPE for Test Set is: 15.04% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:02:59,166]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:02,259]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:02,693]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:05,776]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:11,099]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:13,572]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:15,765]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:16,730]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:22,684]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:26,868]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:29,860]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:31,740]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:35,086]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:39,173]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:42,475]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:45,177]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:48,109]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:48,784]\u001b[0m Trial 406 finished with value: 6.71032683661974 and parameters: {'n_hidden': 3, 'learning_rate': 0.013317421263450873, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34795148260600595, 'dropout_rate_Layer_2': 0.0009752055376554027, 'dropout_rate_Layer_3': 0.2485388008607309, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015047585926187992, 'l1_Layer_2': 0.03834275247753614, 'l1_Layer_3': 0.0006448824024148442, 'n_units_Layer_1': 205, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.71 | sMAPE for Validation Set is: 12.77% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 16.14% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:03:54,369]\u001b[0m Trial 417 finished with value: 6.531978477543736 and parameters: {'n_hidden': 3, 'learning_rate': 0.007930126767271879, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14952935105725312, 'dropout_rate_Layer_2': 0.06277312948439581, 'dropout_rate_Layer_3': 0.2054829483984759, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002401273741556293, 'l1_Layer_2': 0.0002172779759549013, 'l1_Layer_3': 0.003504348931721585, 'n_units_Layer_1': 140, 'n_units_Layer_2': 215, 'n_units_Layer_3': 300}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:54,432]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.53 | sMAPE for Validation Set is: 12.53% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 16.10% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:03:54,678]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:03:55,301]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:00,597]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:02,199]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:03,214]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:08,916]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:09,001]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:09,337]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:09,527]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:19,033]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:22,729]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:22,836]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:23,504]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:31,428]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:35,149]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:39,642]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:44,073]\u001b[0m Trial 432 finished with value: 6.358624558200162 and parameters: {'n_hidden': 3, 'learning_rate': 0.007771880233691568, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15160635325441352, 'dropout_rate_Layer_2': 0.004967349613927065, 'dropout_rate_Layer_3': 0.3013869399579199, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007704653343492205, 'l1_Layer_2': 0.00020540385543894407, 'l1_Layer_3': 0.002993664466164972, 'n_units_Layer_1': 145, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 12.08% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 4.91 | sMAPE for Test Set is: 12.32% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:04:49,310]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:51,816]\u001b[0m Trial 437 finished with value: 6.27421102239655 and parameters: {'n_hidden': 3, 'learning_rate': 0.007363443522014329, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14477650787451338, 'dropout_rate_Layer_2': 0.05967635428765125, 'dropout_rate_Layer_3': 0.26080347887667643, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007079316644764548, 'l1_Layer_2': 0.00023036662047661643, 'l1_Layer_3': 0.00029991068945543694, 'n_units_Layer_1': 145, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 11.93% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 12.29% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:04:52,614]\u001b[0m Trial 440 finished with value: 7.205685899048987 and parameters: {'n_hidden': 3, 'learning_rate': 0.005611313725800813, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39934862673174815, 'dropout_rate_Layer_2': 0.0030657785016575435, 'dropout_rate_Layer_3': 0.0390593842709564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007710586409221901, 'l1_Layer_2': 0.02579333770843629, 'l1_Layer_3': 0.0032342249302387124, 'n_units_Layer_1': 140, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.21 | sMAPE for Validation Set is: 13.73% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 12.70% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:04:54,658]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:58,497]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:04:59,510]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:02,460]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:06,486]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:06,811]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:10,786]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:13,705]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:15,280]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:16,456]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:20,672]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:20,860]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:21,765]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:27,824]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:29,286]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:30,110]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 13.70% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 5.17 | sMAPE for Test Set is: 12.98% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:05:33,993]\u001b[0m Trial 448 finished with value: 7.1110846465215545 and parameters: {'n_hidden': 3, 'learning_rate': 0.005250516694966378, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34902464191604754, 'dropout_rate_Layer_2': 0.06629869626252904, 'dropout_rate_Layer_3': 0.29397253268590345, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008067225799711784, 'l1_Layer_2': 0.028170596572572915, 'l1_Layer_3': 0.002754248637828989, 'n_units_Layer_1': 145, 'n_units_Layer_2': 295, 'n_units_Layer_3': 300}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:35,458]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:37,988]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:40,248]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:46,021]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:46,242]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:50,838]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:51,915]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:56,230]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:05:58,979]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:00,856]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:01,378]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:02,176]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:10,858]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:11,360]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:16,293]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:16,402]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.74 | sMAPE for Validation Set is: 14.81% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 14.31% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:06:19,303]\u001b[0m Trial 473 finished with value: 7.741408323335913 and parameters: {'n_hidden': 3, 'learning_rate': 0.007605483552072438, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3734008827129156, 'dropout_rate_Layer_2': 0.08053053282401446, 'dropout_rate_Layer_3': 0.33327293137088265, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004700150522723412, 'l1_Layer_2': 0.09422246246421319, 'l1_Layer_3': 0.004748211297528724, 'n_units_Layer_1': 150, 'n_units_Layer_2': 275, 'n_units_Layer_3': 290}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:23,705]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:24,133]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:29,645]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:30,024]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:30,041]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:30,041]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:37,695]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:38,036]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:38,098]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:46,505]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:46,602]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:47,525]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:48,220]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:52,983]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:53,344]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:55,117]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:06:58,141]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:02,535]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:07,718]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:08,103]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:11,683]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:15,120]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:16,137]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:17,865]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:17,906]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:18,901]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:24,705]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:26,752]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:27,289]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:27,353]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:28,334]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:36,762]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:37,714]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:43,850]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:44,117]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:46,893]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:51,070]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:51,430]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:51,819]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:55,002]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:07:58,751]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:02,393]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:03,507]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:07,994]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:08,125]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:14,316]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:17,107]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:21,808]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:22,097]\u001b[0m Trial 525 finished with value: 6.652068316434793 and parameters: {'n_hidden': 3, 'learning_rate': 0.014794160061366921, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3239200059201819, 'dropout_rate_Layer_2': 0.15484553732022505, 'dropout_rate_Layer_3': 0.194743469236962, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001223078472612081, 'l1_Layer_2': 0.0010073635526088582, 'l1_Layer_3': 0.002630062091699501, 'n_units_Layer_1': 115, 'n_units_Layer_2': 185, 'n_units_Layer_3': 150}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.65 | sMAPE for Validation Set is: 12.76% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 13.18% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:08:26,795]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:28,419]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:32,390]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:36,873]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:40,115]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:40,650]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:45,275]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:48,423]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:48,698]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:49,922]\u001b[0m Trial 529 finished with value: 6.235317999175585 and parameters: {'n_hidden': 3, 'learning_rate': 0.003606288511226201, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10822911078997732, 'dropout_rate_Layer_2': 0.012111634760565315, 'dropout_rate_Layer_3': 0.28269681953594333, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004419591240522173, 'l1_Layer_2': 0.00013268958128874074, 'l1_Layer_3': 0.0006495705811571321, 'n_units_Layer_1': 115, 'n_units_Layer_2': 270, 'n_units_Layer_3': 245}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.81 | sMAPE for Test Set is: 12.09% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:08:55,093]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:55,355]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:08:59,071]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:01,814]\u001b[0m Trial 527 finished with value: 6.3824821096913995 and parameters: {'n_hidden': 3, 'learning_rate': 0.001518004524899732, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2559942184506645, 'dropout_rate_Layer_2': 0.0673546436785212, 'dropout_rate_Layer_3': 0.15013640078183713, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001224856191331458, 'l1_Layer_2': 0.005165142691696015, 'l1_Layer_3': 0.0009597759246709309, 'n_units_Layer_1': 120, 'n_units_Layer_2': 125, 'n_units_Layer_3': 255}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 12.22% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 4.92 | sMAPE for Test Set is: 12.47% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:09:02,833]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:03,471]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:07,687]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:12,955]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:15,312]\u001b[0m Trial 543 finished with value: 6.448590147224439 and parameters: {'n_hidden': 3, 'learning_rate': 0.015390576997326245, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2504944169329602, 'dropout_rate_Layer_2': 0.07448846821101088, 'dropout_rate_Layer_3': 0.1491521506214585, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011969981018004885, 'l1_Layer_2': 0.006330702209001181, 'l1_Layer_3': 0.0005609754132080839, 'n_units_Layer_1': 115, 'n_units_Layer_2': 125, 'n_units_Layer_3': 65}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 12.35% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 4.92 | sMAPE for Test Set is: 12.38% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:09:16,586]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 12.62% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 4.76 | sMAPE for Test Set is: 12.00% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:09:17,451]\u001b[0m Trial 541 finished with value: 6.613225804085616 and parameters: {'n_hidden': 3, 'learning_rate': 0.009909816937694571, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3635896606237869, 'dropout_rate_Layer_2': 0.17864538646847872, 'dropout_rate_Layer_3': 0.16388353051215618, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00248291227929746, 'l1_Layer_2': 0.0010315561314859479, 'l1_Layer_3': 0.004043529244969864, 'n_units_Layer_1': 95, 'n_units_Layer_2': 125, 'n_units_Layer_3': 160}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:24,292]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:26,469]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:26,830]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:27,530]\u001b[0m Trial 545 finished with value: 6.603263121672405 and parameters: {'n_hidden': 3, 'learning_rate': 0.012567814443318935, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36204319906692933, 'dropout_rate_Layer_2': 0.07756194824221652, 'dropout_rate_Layer_3': 0.14640409048098207, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.601882461968402e-05, 'l1_Layer_2': 0.0031868014470078764, 'l1_Layer_3': 0.0010655150148886142, 'n_units_Layer_1': 115, 'n_units_Layer_2': 115, 'n_units_Layer_3': 130}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 12.55% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 4.80 | sMAPE for Test Set is: 12.11% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:09:32,664]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:34,157]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:34,530]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:35,628]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:42,828]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:43,273]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:43,988]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:50,640]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:52,017]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:09:56,769]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:10:01,173]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:10:04,784]\u001b[0m Trial 556 finished with value: 6.179364425811909 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028065737289636105, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06305376785529863, 'dropout_rate_Layer_2': 0.02513667596842809, 'dropout_rate_Layer_3': 0.33051901528856586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023773203875162, 'l1_Layer_2': 0.00036965102355573145, 'l1_Layer_3': 0.0007588324741164156, 'n_units_Layer_1': 295, 'n_units_Layer_2': 300, 'n_units_Layer_3': 230}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 11.79% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.80 | sMAPE for Test Set is: 12.16% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:10:05,317]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:10:05,947]\u001b[0m Trial 561 finished with value: 6.863293488074504 and parameters: {'n_hidden': 3, 'learning_rate': 0.012110899139185652, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2684648402504196, 'dropout_rate_Layer_2': 0.19790210998714758, 'dropout_rate_Layer_3': 0.15221844502084203, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021824527929737475, 'l1_Layer_2': 0.008411297015865165, 'l1_Layer_3': 0.005275203076063939, 'n_units_Layer_1': 125, 'n_units_Layer_2': 140, 'n_units_Layer_3': 155}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.86 | sMAPE for Validation Set is: 12.96% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 4.88 | sMAPE for Test Set is: 12.20% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:10:12,594]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:10:13,111]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:10:13,724]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:10:14,454]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:10:22,164]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:10:28,144]\u001b[0m Trial 570 finished with value: 6.699453173989025 and parameters: {'n_hidden': 3, 'learning_rate': 0.011973355064076072, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26489425038168624, 'dropout_rate_Layer_2': 0.17654824886445428, 'dropout_rate_Layer_3': 0.15130060772464615, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014539349080849764, 'l1_Layer_2': 0.008337642958071689, 'l1_Layer_3': 0.005671384923411339, 'n_units_Layer_1': 130, 'n_units_Layer_2': 145, 'n_units_Layer_3': 160}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.70 | sMAPE for Validation Set is: 12.79% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 12.74% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:10:32,099]\u001b[0m Trial 569 finished with value: 6.734744167416679 and parameters: {'n_hidden': 3, 'learning_rate': 0.01199793399750026, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26531368943869815, 'dropout_rate_Layer_2': 0.03623940075388655, 'dropout_rate_Layer_3': 0.15277597991374053, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022502822493150106, 'l1_Layer_2': 0.009333191999364606, 'l1_Layer_3': 0.004896501342436996, 'n_units_Layer_1': 130, 'n_units_Layer_2': 145, 'n_units_Layer_3': 155}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:10:32,227]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.73 | sMAPE for Validation Set is: 12.75% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 4.98 | sMAPE for Test Set is: 12.69% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:10:36,595]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:10:37,895]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:10:41,790]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:10:45,100]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:10:47,103]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:10:48,341]\u001b[0m Trial 572 finished with value: 6.367080438452281 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021361324365673203, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13308719812176453, 'dropout_rate_Layer_2': 0.02799236196332642, 'dropout_rate_Layer_3': 0.3194307089055988, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002631956209349954, 'l1_Layer_2': 0.0001384868535670544, 'l1_Layer_3': 0.0005078705394379181, 'n_units_Layer_1': 285, 'n_units_Layer_2': 300, 'n_units_Layer_3': 240}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 12.13% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.09 | sMAPE for Test Set is: 12.85% | rMAE for Test Set is: 0.82\n",
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 11.79% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.24 | sMAPE for Test Set is: 13.18% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:10:52,195]\u001b[0m Trial 573 finished with value: 6.1532395444014005 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025549059278833597, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.059928767360449525, 'dropout_rate_Layer_2': 0.023056000631848275, 'dropout_rate_Layer_3': 0.3483365509139795, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022864290565530717, 'l1_Layer_2': 0.000371740740552469, 'l1_Layer_3': 0.0003983384693813747, 'n_units_Layer_1': 290, 'n_units_Layer_2': 300, 'n_units_Layer_3': 245}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:10:54,003]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:10:54,604]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:11:00,642]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:11:03,801]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:11:07,693]\u001b[0m Trial 584 finished with value: 6.745971969945471 and parameters: {'n_hidden': 3, 'learning_rate': 0.013756131452127828, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27103676122679315, 'dropout_rate_Layer_2': 0.17878488759674277, 'dropout_rate_Layer_3': 0.13868194116742225, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018466408834050907, 'l1_Layer_2': 0.010173677887117956, 'l1_Layer_3': 0.006971796244470384, 'n_units_Layer_1': 120, 'n_units_Layer_2': 195, 'n_units_Layer_3': 135}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.75 | sMAPE for Validation Set is: 12.86% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 5.08 | sMAPE for Test Set is: 12.83% | rMAE for Test Set is: 0.82\n",
      "MAE for Validation Set is: 6.89 | sMAPE for Validation Set is: 13.25% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 5.41 | sMAPE for Test Set is: 13.78% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:11:07,774]\u001b[0m Trial 583 finished with value: 6.893358393541263 and parameters: {'n_hidden': 3, 'learning_rate': 0.013923534147590887, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.239167056440421, 'dropout_rate_Layer_2': 0.17424285432924838, 'dropout_rate_Layer_3': 0.13349899456946834, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023061451373137445, 'l1_Layer_2': 0.011886814769900158, 'l1_Layer_3': 0.006594267228614615, 'n_units_Layer_1': 120, 'n_units_Layer_2': 195, 'n_units_Layer_3': 135}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:11:14,816]\u001b[0m Trial 587 finished with value: 7.058160755478913 and parameters: {'n_hidden': 3, 'learning_rate': 0.013516080175350399, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2648134645892973, 'dropout_rate_Layer_2': 0.17255161078346948, 'dropout_rate_Layer_3': 0.13883295476561686, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022860592676975755, 'l1_Layer_2': 0.013798782762095542, 'l1_Layer_3': 0.007486207622202821, 'n_units_Layer_1': 120, 'n_units_Layer_2': 195, 'n_units_Layer_3': 160}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.06 | sMAPE for Validation Set is: 13.58% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 5.35 | sMAPE for Test Set is: 13.56% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:11:19,100]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:11:22,486]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:11:26,104]\u001b[0m Trial 580 finished with value: 6.2556772550657485 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019865178460301597, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08344485694983324, 'dropout_rate_Layer_2': 0.026443609437833738, 'dropout_rate_Layer_3': 0.3626344918388446, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0025695270116910156, 'l1_Layer_2': 0.00014577230860976037, 'l1_Layer_3': 0.00048086100605804053, 'n_units_Layer_1': 270, 'n_units_Layer_2': 300, 'n_units_Layer_3': 245}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 11.91% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.23 | sMAPE for Test Set is: 13.10% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:11:26,637]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:11:41,334]\u001b[0m Trial 594 finished with value: 7.321955913209826 and parameters: {'n_hidden': 3, 'learning_rate': 0.010234170839672199, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2672798126204905, 'dropout_rate_Layer_2': 0.200247309983664, 'dropout_rate_Layer_3': 0.1353421856505593, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023808315288934775, 'l1_Layer_2': 0.01209132432662642, 'l1_Layer_3': 0.010941024398514623, 'n_units_Layer_1': 125, 'n_units_Layer_2': 195, 'n_units_Layer_3': 145}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.32 | sMAPE for Validation Set is: 13.93% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 5.12 | sMAPE for Test Set is: 12.77% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:11:43,917]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:11:44,505]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:11:48,492]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:11:54,017]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:11:57,582]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:12:02,401]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:12:08,937]\u001b[0m Trial 599 finished with value: 7.024704242551792 and parameters: {'n_hidden': 3, 'learning_rate': 0.010672313247318672, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2653289602498744, 'dropout_rate_Layer_2': 0.20109569120007367, 'dropout_rate_Layer_3': 0.13230708637431857, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022514163763121724, 'l1_Layer_2': 0.015434497131530339, 'l1_Layer_3': 0.012779597226531212, 'n_units_Layer_1': 125, 'n_units_Layer_2': 195, 'n_units_Layer_3': 145}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.02 | sMAPE for Validation Set is: 13.39% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 5.17 | sMAPE for Test Set is: 13.00% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:12:10,732]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:12:14,495]\u001b[0m Trial 593 finished with value: 6.158458422486787 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019970250791776505, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06596796034124715, 'dropout_rate_Layer_2': 0.024914792907573778, 'dropout_rate_Layer_3': 0.35864967077271864, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002623342442567918, 'l1_Layer_2': 0.0003811834439969124, 'l1_Layer_3': 0.0003832872919091553, 'n_units_Layer_1': 300, 'n_units_Layer_2': 300, 'n_units_Layer_3': 235}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 11.75% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 12.61% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:12:14,847]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:12:20,208]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:12:23,029]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:12:24,817]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:12:27,667]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:12:32,660]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:12:36,588]\u001b[0m Trial 596 finished with value: 6.322170927502367 and parameters: {'n_hidden': 3, 'learning_rate': 0.002096045538312113, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.061904643736762834, 'dropout_rate_Layer_2': 0.027413569830900708, 'dropout_rate_Layer_3': 0.34572609993955133, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004052226869538239, 'l1_Layer_2': 0.0001426393043445369, 'l1_Layer_3': 0.0005098553694305254, 'n_units_Layer_1': 280, 'n_units_Layer_2': 300, 'n_units_Layer_3': 250}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 12.07% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.34 | sMAPE for Test Set is: 13.33% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:12:40,139]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.12 | sMAPE for Validation Set is: 13.56% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 5.14 | sMAPE for Test Set is: 12.87% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:12:41,467]\u001b[0m Trial 608 finished with value: 7.12331263676258 and parameters: {'n_hidden': 3, 'learning_rate': 0.008152636711089373, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24586497402320592, 'dropout_rate_Layer_2': 0.1847737334666218, 'dropout_rate_Layer_3': 0.13565675147773995, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002342471870680562, 'l1_Layer_2': 0.02305521976842415, 'l1_Layer_3': 0.01164984367426757, 'n_units_Layer_1': 120, 'n_units_Layer_2': 195, 'n_units_Layer_3': 155}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:12:49,198]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:12:49,789]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:12:52,595]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:12:57,881]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:12:58,425]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:13:04,078]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:13:07,358]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:13:10,688]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:13:16,647]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:13:26,292]\u001b[0m Trial 609 finished with value: 6.173522620307666 and parameters: {'n_hidden': 3, 'learning_rate': 0.001159086367915772, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08271028971353947, 'dropout_rate_Layer_2': 0.03091032152137163, 'dropout_rate_Layer_3': 0.3440036321346529, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0056075510740982585, 'l1_Layer_2': 0.00012719838140849823, 'l1_Layer_3': 0.0008819360049341038, 'n_units_Layer_1': 275, 'n_units_Layer_2': 300, 'n_units_Layer_3': 230}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 11.78% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 13.16% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:13:27,074]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:13:28,656]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:13:29,999]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:13:35,161]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:13:36,293]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:13:38,864]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:13:44,141]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:13:47,049]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:13:51,027]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:13:52,088]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:13:54,699]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:13:56,665]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:13:58,611]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:14:00,542]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:14:00,982]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:14:08,156]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:14:11,068]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:14:13,516]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:14:17,565]\u001b[0m Trial 635 finished with value: 7.912176275937028 and parameters: {'n_hidden': 3, 'learning_rate': 0.013797165923915961, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2665527838768205, 'dropout_rate_Layer_2': 0.17154556019751768, 'dropout_rate_Layer_3': 0.15454236886174783, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0030405360450381958, 'l1_Layer_2': 0.023594475916022498, 'l1_Layer_3': 0.013396749648059432, 'n_units_Layer_1': 115, 'n_units_Layer_2': 210, 'n_units_Layer_3': 155}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.91 | sMAPE for Validation Set is: 15.31% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 13.66% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:14:19,879]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:14:23,498]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:14:24,023]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:14:28,474]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:14:32,934]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:14:36,946]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:14:38,802]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:14:39,601]\u001b[0m Trial 639 finished with value: 6.192415187061389 and parameters: {'n_hidden': 3, 'learning_rate': 0.00218156631389408, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05942324490728021, 'dropout_rate_Layer_2': 0.01137437407289825, 'dropout_rate_Layer_3': 0.3678499657956452, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0036348702137965413, 'l1_Layer_2': 9.719787360097868e-05, 'l1_Layer_3': 0.0004990593839895629, 'n_units_Layer_1': 290, 'n_units_Layer_2': 290, 'n_units_Layer_3': 235}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 11.80% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 12.43% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:14:39,902]\u001b[0m Trial 644 finished with value: 7.044072345808232 and parameters: {'n_hidden': 3, 'learning_rate': 0.012438088243859792, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2494090646190703, 'dropout_rate_Layer_2': 0.21244322601781543, 'dropout_rate_Layer_3': 0.142073181292819, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0024252177395582652, 'l1_Layer_2': 0.009274749409856991, 'l1_Layer_3': 0.005162406969058276, 'n_units_Layer_1': 125, 'n_units_Layer_2': 185, 'n_units_Layer_3': 125}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 13.43% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 5.07 | sMAPE for Test Set is: 12.71% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:14:40,327]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:14:48,173]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:14:50,802]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:14:51,172]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:14:51,303]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:15:00,493]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:15:07,677]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:15:11,958]\u001b[0m Trial 654 finished with value: 6.764547446515529 and parameters: {'n_hidden': 3, 'learning_rate': 0.00952452199103256, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25026165159478003, 'dropout_rate_Layer_2': 0.21582354701216258, 'dropout_rate_Layer_3': 0.14212591878920802, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0026450653189750875, 'l1_Layer_2': 0.009111991173332171, 'l1_Layer_3': 0.005005993814264998, 'n_units_Layer_1': 135, 'n_units_Layer_2': 180, 'n_units_Layer_3': 180}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.76 | sMAPE for Validation Set is: 12.93% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 14.98% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:15:15,870]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:15:19,311]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:15:19,979]\u001b[0m Trial 653 finished with value: 6.290325479764956 and parameters: {'n_hidden': 3, 'learning_rate': 0.002558307485477328, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06646983447192673, 'dropout_rate_Layer_2': 0.01570324709025111, 'dropout_rate_Layer_3': 0.3207060949263698, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.012680372709543787, 'l1_Layer_2': 4.1816038930790734e-05, 'l1_Layer_3': 0.0007381440687763265, 'n_units_Layer_1': 290, 'n_units_Layer_2': 295, 'n_units_Layer_3': 230}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.97 | sMAPE for Test Set is: 12.54% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:15:20,503]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:15:27,997]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:15:28,168]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:15:30,814]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:15:33,740]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.92 | sMAPE for Validation Set is: 13.10% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 16.00% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:15:34,224]\u001b[0m Trial 659 finished with value: 6.920629534694736 and parameters: {'n_hidden': 3, 'learning_rate': 0.009195988901119365, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2486480075723271, 'dropout_rate_Layer_2': 0.19903150609738685, 'dropout_rate_Layer_3': 0.14425220465422717, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023849790619558425, 'l1_Layer_2': 0.0096532466409187, 'l1_Layer_3': 0.004926241437066518, 'n_units_Layer_1': 135, 'n_units_Layer_2': 190, 'n_units_Layer_3': 175}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:15:42,491]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:15:43,049]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:15:50,163]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:15:50,668]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:15:55,464]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:15:55,974]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:15:56,671]\u001b[0m Trial 666 finished with value: 7.33480429552565 and parameters: {'n_hidden': 3, 'learning_rate': 0.009687261879544898, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24905667656862343, 'dropout_rate_Layer_2': 0.20012202321641293, 'dropout_rate_Layer_3': 0.14623382731132445, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0038482149098985024, 'l1_Layer_2': 0.008586501290375907, 'l1_Layer_3': 0.005216629212136043, 'n_units_Layer_1': 125, 'n_units_Layer_2': 190, 'n_units_Layer_3': 125}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.33 | sMAPE for Validation Set is: 13.78% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 7.43 | sMAPE for Test Set is: 17.72% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:16:03,452]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:16:03,748]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:16:12,283]\u001b[0m Trial 665 finished with value: 6.297525125260239 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013801756254636745, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09374295448680009, 'dropout_rate_Layer_2': 0.020657203737012613, 'dropout_rate_Layer_3': 0.398219717971627, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009635754686198504, 'l1_Layer_2': 9.66060417926659e-05, 'l1_Layer_3': 0.0003570799615556026, 'n_units_Layer_1': 255, 'n_units_Layer_2': 285, 'n_units_Layer_3': 225}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 11.97% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 4.78 | sMAPE for Test Set is: 11.92% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:16:17,216]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:16:19,381]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:16:20,651]\u001b[0m Trial 676 finished with value: 6.671669358159355 and parameters: {'n_hidden': 3, 'learning_rate': 0.00854644917975403, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23439845200441164, 'dropout_rate_Layer_2': 0.2183164133729733, 'dropout_rate_Layer_3': 0.163513196656272, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002693820867546225, 'l1_Layer_2': 0.009916595976721966, 'l1_Layer_3': 0.008973524184500934, 'n_units_Layer_1': 130, 'n_units_Layer_2': 195, 'n_units_Layer_3': 130}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 12.76% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.31 | sMAPE for Test Set is: 15.66% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:16:22,914]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:16:25,569]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:16:27,649]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:16:32,506]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:16:35,792]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:16:40,420]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:16:45,742]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:16:45,792]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:16:46,217]\u001b[0m Trial 682 finished with value: 6.838049898405092 and parameters: {'n_hidden': 3, 'learning_rate': 0.007592310956868816, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23436129729381194, 'dropout_rate_Layer_2': 0.2027890993198569, 'dropout_rate_Layer_3': 0.17184918111536931, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0024737421444703434, 'l1_Layer_2': 0.008704225598406196, 'l1_Layer_3': 0.007716488447191487, 'n_units_Layer_1': 140, 'n_units_Layer_2': 200, 'n_units_Layer_3': 125}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.84 | sMAPE for Validation Set is: 13.04% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 6.04 | sMAPE for Test Set is: 14.91% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:16:47,382]\u001b[0m Trial 673 finished with value: 6.369420272287267 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008879249428079833, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.032899538838986164, 'dropout_rate_Layer_2': 0.052694343816910516, 'dropout_rate_Layer_3': 0.39565994259902204, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009576377520864699, 'l1_Layer_2': 9.749863106723263e-05, 'l1_Layer_3': 0.0007170927491000368, 'n_units_Layer_1': 255, 'n_units_Layer_2': 285, 'n_units_Layer_3': 220}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 12.09% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.03 | sMAPE for Test Set is: 12.56% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:16:55,446]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:16:55,665]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:16:55,974]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:16:56,017]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:05,339]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:06,024]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:06,366]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:10,395]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:15,245]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:18,774]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:23,170]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:26,010]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:30,042]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:30,326]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:30,652]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:37,962]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:37,992]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:38,260]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:45,745]\u001b[0m Trial 700 finished with value: 6.326550899484306 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018490750829618504, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09500535438355844, 'dropout_rate_Layer_2': 0.018361448149584098, 'dropout_rate_Layer_3': 0.3796397662713524, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01186248372989364, 'l1_Layer_2': 2.026015806141833e-05, 'l1_Layer_3': 0.00033071756528217487, 'n_units_Layer_1': 295, 'n_units_Layer_2': 290, 'n_units_Layer_3': 230}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 12.05% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.01 | sMAPE for Test Set is: 12.52% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:17:46,513]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:47,694]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:49,332]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:52,230]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:54,313]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:58,690]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:17:59,452]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:01,378]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:04,013]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:08,652]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:12,303]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:13,063]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:15,242]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:19,215]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:19,990]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:21,263]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:27,678]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:28,006]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:28,268]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:37,196]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:41,019]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:41,315]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:47,584]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:50,423]\u001b[0m Trial 729 finished with value: 6.577744919920767 and parameters: {'n_hidden': 3, 'learning_rate': 0.012934371934812321, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22764973482999623, 'dropout_rate_Layer_2': 0.2395072973190415, 'dropout_rate_Layer_3': 0.14072702130305148, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022503336550526733, 'l1_Layer_2': 0.006417825086108977, 'l1_Layer_3': 0.004752908441138697, 'n_units_Layer_1': 120, 'n_units_Layer_2': 115, 'n_units_Layer_3': 145}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 12.52% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 15.27% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:18:54,710]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:18:57,411]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:19:02,499]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:19:07,410]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:19:10,308]\u001b[0m Trial 728 finished with value: 6.251540614390952 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014820354546798422, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08868668549308947, 'dropout_rate_Layer_2': 0.042039587037886406, 'dropout_rate_Layer_3': 0.36786456334365725, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.018416973390831398, 'l1_Layer_2': 1.118598218480773e-05, 'l1_Layer_3': 0.00036595462561114404, 'n_units_Layer_1': 295, 'n_units_Layer_2': 280, 'n_units_Layer_3': 235}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 11.93% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.84 | sMAPE for Test Set is: 12.20% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:19:10,610]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:19:13,504]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:19:18,711]\u001b[0m Trial 733 finished with value: 6.540986067089953 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030035020762718893, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10543978780919043, 'dropout_rate_Layer_2': 0.02241126485883755, 'dropout_rate_Layer_3': 0.3749600456738569, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009145605992722686, 'l1_Layer_2': 1.0413861968515524e-05, 'l1_Layer_3': 0.0003497995130852862, 'n_units_Layer_1': 275, 'n_units_Layer_2': 290, 'n_units_Layer_3': 200}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 12.51% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 5.57 | sMAPE for Test Set is: 13.92% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:19:22,770]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:19:23,362]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:19:29,391]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:19:30,195]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:19:35,526]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:19:38,459]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:19:45,744]\u001b[0m Trial 745 finished with value: 7.086009220224519 and parameters: {'n_hidden': 3, 'learning_rate': 0.011137478368138741, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23935688979913808, 'dropout_rate_Layer_2': 0.2068938808431884, 'dropout_rate_Layer_3': 0.13697303904504038, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004292241561334483, 'l1_Layer_2': 0.007239466993223816, 'l1_Layer_3': 0.00602202970959398, 'n_units_Layer_1': 120, 'n_units_Layer_2': 105, 'n_units_Layer_3': 125}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.09 | sMAPE for Validation Set is: 13.43% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 15.29% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:19:49,868]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:19:55,511]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:20:00,356]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:20:04,445]\u001b[0m Trial 749 finished with value: 6.884563924995436 and parameters: {'n_hidden': 3, 'learning_rate': 0.011232784409986086, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22754456161916445, 'dropout_rate_Layer_2': 0.20549031728466585, 'dropout_rate_Layer_3': 0.13618651344784166, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0035222961335234057, 'l1_Layer_2': 0.007939786975640063, 'l1_Layer_3': 0.006140913461322261, 'n_units_Layer_1': 125, 'n_units_Layer_2': 100, 'n_units_Layer_3': 105}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.88 | sMAPE for Validation Set is: 13.13% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 6.12 | sMAPE for Test Set is: 15.07% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:20:08,225]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:20:09,363]\u001b[0m Trial 750 finished with value: 6.735925476333503 and parameters: {'n_hidden': 3, 'learning_rate': 0.011217189068519557, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22780128173364775, 'dropout_rate_Layer_2': 0.2091247601967361, 'dropout_rate_Layer_3': 0.13749929797716984, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00487824132186245, 'l1_Layer_2': 0.007422125822729396, 'l1_Layer_3': 0.006335591104183911, 'n_units_Layer_1': 125, 'n_units_Layer_2': 105, 'n_units_Layer_3': 125}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.74 | sMAPE for Validation Set is: 12.84% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 5.72 | sMAPE for Test Set is: 14.29% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:20:11,870]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:20:16,927]\u001b[0m Trial 748 finished with value: 6.188505246759128 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014538991545913393, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07405784386803543, 'dropout_rate_Layer_2': 0.030949490876516265, 'dropout_rate_Layer_3': 0.3898561396848973, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0060389955978525246, 'l1_Layer_2': 4.742040410355494e-05, 'l1_Layer_3': 0.0009486803778225361, 'n_units_Layer_1': 245, 'n_units_Layer_2': 295, 'n_units_Layer_3': 245}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.19 | sMAPE for Test Set is: 13.02% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:20:19,644]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:20:20,218]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:20:22,572]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:20:26,839]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:20:29,286]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:20:31,410]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:20:34,640]\u001b[0m Trial 754 finished with value: 6.846150239406351 and parameters: {'n_hidden': 3, 'learning_rate': 0.01085111187176193, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2415554430801816, 'dropout_rate_Layer_2': 0.20840661352533724, 'dropout_rate_Layer_3': 0.13549068085425126, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005992472877809711, 'l1_Layer_2': 0.007432419062281137, 'l1_Layer_3': 0.006652995839001016, 'n_units_Layer_1': 125, 'n_units_Layer_2': 90, 'n_units_Layer_3': 120}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.85 | sMAPE for Validation Set is: 13.07% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 5.53 | sMAPE for Test Set is: 13.72% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:20:38,823]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:20:41,449]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:20:42,158]\u001b[0m Trial 758 finished with value: 6.813798083832811 and parameters: {'n_hidden': 3, 'learning_rate': 0.009585822950999813, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2372512313884458, 'dropout_rate_Layer_2': 0.22733195791900357, 'dropout_rate_Layer_3': 0.13009834567696557, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0036477050900168818, 'l1_Layer_2': 0.008650675717259797, 'l1_Layer_3': 0.007608599189369501, 'n_units_Layer_1': 130, 'n_units_Layer_2': 110, 'n_units_Layer_3': 125}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 12.99% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 14.37% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:20:47,128]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:20:49,748]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:20:53,599]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:20:54,214]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:20:54,651]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:01,574]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:02,421]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:07,138]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:07,881]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:13,895]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:14,282]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:14,813]\u001b[0m Trial 763 finished with value: 6.373162427445808 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014038296360843591, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04103446269109329, 'dropout_rate_Layer_2': 0.02812535586982101, 'dropout_rate_Layer_3': 0.38811606052396197, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0048353003599978595, 'l1_Layer_2': 4.609203902951505e-05, 'l1_Layer_3': 0.0011433634574484508, 'n_units_Layer_1': 245, 'n_units_Layer_2': 280, 'n_units_Layer_3': 235}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 12.20% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 14.37% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:21:22,643]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:22,866]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:23,059]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:29,169]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:29,229]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:29,522]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:34,482]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:41,220]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:44,850]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:45,800]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:49,495]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:53,233]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:21:53,401]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:22:01,623]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:22:10,116]\u001b[0m Trial 786 finished with value: 6.3095511828410125 and parameters: {'n_hidden': 3, 'learning_rate': 0.003928710507328777, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013626487724474896, 'dropout_rate_Layer_2': 0.010029085915799332, 'dropout_rate_Layer_3': 0.3367214139995345, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01850539460994194, 'l1_Layer_2': 2.679598329072525e-05, 'l1_Layer_3': 0.000226775627685484, 'n_units_Layer_1': 295, 'n_units_Layer_2': 300, 'n_units_Layer_3': 215}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 12.03% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 4.81 | sMAPE for Test Set is: 12.07% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:22:13,564]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:22:18,154]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:22:29,115]\u001b[0m Trial 784 finished with value: 6.307117801431837 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015883947790051652, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06469025566825073, 'dropout_rate_Layer_2': 0.010459870324303178, 'dropout_rate_Layer_3': 0.3430532682949324, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03126155030317922, 'l1_Layer_2': 7.123817314365566e-05, 'l1_Layer_3': 0.0009587622378805869, 'n_units_Layer_1': 260, 'n_units_Layer_2': 50, 'n_units_Layer_3': 255}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 12.01% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.35 | sMAPE for Test Set is: 13.35% | rMAE for Test Set is: 0.87\n",
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 12.19% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 4.86 | sMAPE for Test Set is: 12.26% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:22:32,540]\u001b[0m Trial 793 finished with value: 6.408427937683448 and parameters: {'n_hidden': 4, 'learning_rate': 0.004065387319527742, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014170765816631861, 'dropout_rate_Layer_2': 0.03898100846304904, 'dropout_rate_Layer_3': 0.3684567024347432, 'dropout_rate_Layer_4': 0.09983384196558767, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.01690836406591666, 'l1_Layer_2': 1.4260157848170475e-05, 'l1_Layer_3': 0.0002297920346998319, 'l1_Layer_4': 0.0035915726343830937, 'n_units_Layer_1': 265, 'n_units_Layer_2': 285, 'n_units_Layer_3': 255, 'n_units_Layer_4': 210}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:22:35,235]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:22:36,072]\u001b[0m Trial 796 finished with value: 6.69130069304667 and parameters: {'n_hidden': 4, 'learning_rate': 0.011381671659558668, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25658825426202514, 'dropout_rate_Layer_2': 0.20440311112327725, 'dropout_rate_Layer_3': 0.12674435276490922, 'dropout_rate_Layer_4': 0.08214756635855276, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001066000958907304, 'l1_Layer_2': 0.00578000283261362, 'l1_Layer_3': 0.0007809989152521005, 'l1_Layer_4': 0.00910674741331519, 'n_units_Layer_1': 125, 'n_units_Layer_2': 105, 'n_units_Layer_3': 130, 'n_units_Layer_4': 140}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.69 | sMAPE for Validation Set is: 12.67% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 5.15 | sMAPE for Test Set is: 12.88% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:22:36,687]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:22:44,137]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 11.84% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 12.69% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:22:44,947]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:22:45,001]\u001b[0m Trial 792 finished with value: 6.230503717747482 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016023206343780316, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0627285562111217, 'dropout_rate_Layer_2': 0.010784069085048626, 'dropout_rate_Layer_3': 0.33879978766409513, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006346933690217437, 'l1_Layer_2': 2.7111307961922882e-05, 'l1_Layer_3': 0.0002698958208276076, 'n_units_Layer_1': 300, 'n_units_Layer_2': 300, 'n_units_Layer_3': 255}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:22:47,650]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:22:54,134]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:22:54,289]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:22:54,692]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:05,399]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:07,272]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:12,569]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:13,154]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:13,721]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:21,957]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:25,312]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:26,023]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:31,656]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:32,049]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:32,185]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:37,967]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:38,235]\u001b[0m Trial 802 finished with value: 6.296880842631534 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006874408338378632, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07328231852832456, 'dropout_rate_Layer_2': 0.04990207912059063, 'dropout_rate_Layer_3': 0.3633515299665832, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008869732044350808, 'l1_Layer_2': 4.284527743983626e-05, 'l1_Layer_3': 0.0002851382094782039, 'n_units_Layer_1': 250, 'n_units_Layer_2': 295, 'n_units_Layer_3': 245}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 11.97% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.12 | sMAPE for Test Set is: 12.85% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:23:39,471]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:44,062]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:46,318]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:50,524]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:53,570]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:54,865]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:56,219]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:56,416]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:23:59,915]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:02,623]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:04,801]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:05,737]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:11,461]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:12,107]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:13,664]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:14,627]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:22,676]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:22,849]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:26,832]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:28,792]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:33,549]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:33,748]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:34,071]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:42,439]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:44,564]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:46,032]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:48,776]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:51,219]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:53,761]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:56,419]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:24:57,937]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:03,144]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:03,694]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:03,842]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:08,971]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:12,279]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:13,208]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:18,260]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:22,783]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:27,192]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:27,867]\u001b[0m Trial 857 finished with value: 6.77861055841215 and parameters: {'n_hidden': 3, 'learning_rate': 0.00810698991172629, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26574880974706255, 'dropout_rate_Layer_2': 0.19835257729778477, 'dropout_rate_Layer_3': 0.16288909414947028, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0027988518721823157, 'l1_Layer_2': 0.015169590300246501, 'l1_Layer_3': 0.004400509384317749, 'n_units_Layer_1': 110, 'n_units_Layer_2': 180, 'n_units_Layer_3': 150}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.78 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 5.21 | sMAPE for Test Set is: 13.00% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:25:28,775]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:31,010]\u001b[0m Trial 856 finished with value: 6.269513132407901 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014757976247155233, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05821403297002765, 'dropout_rate_Layer_2': 0.022710019097227127, 'dropout_rate_Layer_3': 0.3327686155334218, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008078254096570169, 'l1_Layer_2': 5.607166213999775e-05, 'l1_Layer_3': 0.0007397859755522055, 'n_units_Layer_1': 275, 'n_units_Layer_2': 300, 'n_units_Layer_3': 185}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 11.98% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.32 | sMAPE for Test Set is: 13.34% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:25:32,796]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:35,012]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:40,163]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:41,514]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:47,860]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:48,426]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:54,348]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:55,465]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:25:59,897]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:26:01,898]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:26:04,438]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:26:09,214]\u001b[0m Trial 865 finished with value: 6.20853467975915 and parameters: {'n_hidden': 3, 'learning_rate': 0.00110848593021529, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026391116268970047, 'dropout_rate_Layer_2': 0.022512541772979462, 'dropout_rate_Layer_3': 0.3158122093504469, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007997874508913112, 'l1_Layer_2': 5.534792899098046e-05, 'l1_Layer_3': 0.0007529197342168476, 'n_units_Layer_1': 275, 'n_units_Layer_2': 300, 'n_units_Layer_3': 190}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.78 | sMAPE for Test Set is: 12.05% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:26:10,257]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:26:14,726]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:26:19,156]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:26:20,289]\u001b[0m Trial 866 finished with value: 6.47237766174409 and parameters: {'n_hidden': 3, 'learning_rate': 0.002701153231738258, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.054987120903179566, 'dropout_rate_Layer_2': 0.023653550020819473, 'dropout_rate_Layer_3': 0.3321075546764846, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0076780386661487775, 'l1_Layer_2': 5.145281329661078e-05, 'l1_Layer_3': 0.0007739840961932026, 'n_units_Layer_1': 270, 'n_units_Layer_2': 300, 'n_units_Layer_3': 165}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 12.33% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 4.86 | sMAPE for Test Set is: 12.20% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:26:27,269]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:26:30,878]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:26:34,376]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:26:40,385]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:26:42,442]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:26:44,907]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:26:47,045]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:26:47,753]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:26:52,344]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:26:54,119]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:26:55,712]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:02,157]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:02,856]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:04,897]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:09,748]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:09,895]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:15,698]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:15,982]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:16,830]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:25,844]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:26,711]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:28,821]\u001b[0m Trial 894 finished with value: 6.723493046138984 and parameters: {'n_hidden': 3, 'learning_rate': 0.0072316971163972855, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2514910630514031, 'dropout_rate_Layer_2': 0.20173918528285326, 'dropout_rate_Layer_3': 0.12289546457483791, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004107038343683969, 'l1_Layer_2': 0.006801821109709381, 'l1_Layer_3': 0.003035422805376322, 'n_units_Layer_1': 130, 'n_units_Layer_2': 110, 'n_units_Layer_3': 130}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.72 | sMAPE for Validation Set is: 12.71% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.00 | sMAPE for Test Set is: 14.79% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:27:29,198]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:31,196]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:39,025]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:41,761]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:43,093]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:47,150]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:49,811]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:55,093]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:56,553]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:57,831]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:27:59,661]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:28:04,486]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:28:06,402]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:28:06,522]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:28:07,159]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:28:11,346]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:28:19,911]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:28:21,098]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:28:26,796]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:28:30,971]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:28:31,536]\u001b[0m Trial 916 finished with value: 6.916263081055114 and parameters: {'n_hidden': 3, 'learning_rate': 0.007406389526945787, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29695999212759644, 'dropout_rate_Layer_2': 0.15355964215800574, 'dropout_rate_Layer_3': 0.11524979748564336, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016584680124910897, 'l1_Layer_2': 0.01147548826102677, 'l1_Layer_3': 0.003850716566025506, 'n_units_Layer_1': 130, 'n_units_Layer_2': 115, 'n_units_Layer_3': 160}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.92 | sMAPE for Validation Set is: 13.15% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 12.29% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:28:37,511]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:28:40,987]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:28:44,152]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:28:47,189]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:28:47,280]\u001b[0m Trial 918 finished with value: 6.383011973494703 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023371837058302446, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04287305765194118, 'dropout_rate_Layer_2': 0.0362936529607147, 'dropout_rate_Layer_3': 0.3499236677675383, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008833353872093533, 'l1_Layer_2': 0.00010313480568072092, 'l1_Layer_3': 0.0004498195520220675, 'n_units_Layer_1': 295, 'n_units_Layer_2': 295, 'n_units_Layer_3': 230}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 12.13% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 4.75 | sMAPE for Test Set is: 11.92% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:28:54,594]\u001b[0m Trial 919 finished with value: 6.3028559985773525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019566490036191033, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08495125734959869, 'dropout_rate_Layer_2': 0.035331220010152625, 'dropout_rate_Layer_3': 0.35314453688393554, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008695541339992353, 'l1_Layer_2': 0.00010102319202497516, 'l1_Layer_3': 0.0004389188618293093, 'n_units_Layer_1': 295, 'n_units_Layer_2': 295, 'n_units_Layer_3': 230}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 12.05% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.15 | sMAPE for Test Set is: 12.93% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:28:55,004]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:01,485]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:01,807]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:03,948]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:09,485]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:10,195]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:14,417]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:17,985]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:19,093]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:23,340]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:24,054]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:29,682]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:31,911]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:37,973]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:42,135]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:46,204]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:49,292]\u001b[0m Trial 922 finished with value: 6.342359319186078 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005049937128360496, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0903510750491185, 'dropout_rate_Layer_2': 0.0372004188420239, 'dropout_rate_Layer_3': 0.3520812603484758, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008673990350402304, 'l1_Layer_2': 2.0713332148108327e-05, 'l1_Layer_3': 0.00048738875540873394, 'n_units_Layer_1': 280, 'n_units_Layer_2': 295, 'n_units_Layer_3': 220}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.34 | sMAPE for Validation Set is: 12.11% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.39 | sMAPE for Test Set is: 13.49% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:29:50,165]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:54,824]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:29:56,579]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:30:01,887]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:30:02,640]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 11.82% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.31 | sMAPE for Test Set is: 13.31% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:30:04,855]\u001b[0m Trial 931 finished with value: 6.203599493543529 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009602980867080546, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.062379665877325616, 'dropout_rate_Layer_2': 0.027785487118077247, 'dropout_rate_Layer_3': 0.36135763146142763, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006124087620666533, 'l1_Layer_2': 1.99803244187528e-05, 'l1_Layer_3': 0.0013897298730259973, 'n_units_Layer_1': 280, 'n_units_Layer_2': 285, 'n_units_Layer_3': 250}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:30:12,652]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:30:20,028]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:30:25,725]\u001b[0m Trial 950 finished with value: 6.732236122534483 and parameters: {'n_hidden': 3, 'learning_rate': 0.0056676998734865895, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021006444842918026, 'dropout_rate_Layer_2': 0.21188655374493776, 'dropout_rate_Layer_3': 0.144640403982931, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018488153675958355, 'l1_Layer_2': 7.806898081708103e-05, 'l1_Layer_3': 0.004084001023928108, 'n_units_Layer_1': 145, 'n_units_Layer_2': 110, 'n_units_Layer_3': 245}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.73 | sMAPE for Validation Set is: 12.86% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 13.85% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:30:29,710]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:30:32,823]\u001b[0m Trial 942 finished with value: 6.153556190957793 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009788386701266817, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0025568562580532105, 'dropout_rate_Layer_2': 0.016331700728538102, 'dropout_rate_Layer_3': 0.28809999071863923, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.014873315111759114, 'l1_Layer_2': 3.172973610024357e-05, 'l1_Layer_3': 0.0005555288715102602, 'n_units_Layer_1': 280, 'n_units_Layer_2': 285, 'n_units_Layer_3': 250}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 11.74% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 12.36% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:30:35,763]\u001b[0m Trial 951 finished with value: 6.268792595463758 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015592324133873049, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04647033807205078, 'dropout_rate_Layer_2': 0.015662804176450704, 'dropout_rate_Layer_3': 0.2870102707289505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004775606859119408, 'l1_Layer_2': 2.5179941651348744e-05, 'l1_Layer_3': 0.0006117792587040267, 'n_units_Layer_1': 300, 'n_units_Layer_2': 275, 'n_units_Layer_3': 250}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.26 | sMAPE for Test Set is: 13.35% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:30:40,554]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:30:41,549]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:30:46,223]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:30:46,342]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:30:53,094]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:30:53,582]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:30:54,624]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:31:01,794]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:31:02,013]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:31:08,177]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:31:13,513]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:31:16,794]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:31:24,052]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:31:41,096]\u001b[0m Trial 963 finished with value: 6.156656937235117 and parameters: {'n_hidden': 3, 'learning_rate': 0.001006988181810463, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009919875088015402, 'dropout_rate_Layer_2': 0.006642120666498174, 'dropout_rate_Layer_3': 0.2859804627707537, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004563467094143922, 'l1_Layer_2': 1.7553099235878947e-05, 'l1_Layer_3': 0.0008803094115333745, 'n_units_Layer_1': 300, 'n_units_Layer_2': 275, 'n_units_Layer_3': 260}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 11.74% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.98 | sMAPE for Test Set is: 12.59% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:31:47,620]\u001b[0m Trial 968 finished with value: 6.236837602611804 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009977835962670107, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03365860994958163, 'dropout_rate_Layer_2': 0.00724585058158721, 'dropout_rate_Layer_3': 0.3005428236002892, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0044083410195240365, 'l1_Layer_2': 1.6446501940646407e-05, 'l1_Layer_3': 0.0006363086570605391, 'n_units_Layer_1': 290, 'n_units_Layer_2': 270, 'n_units_Layer_3': 260}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 13.68% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:31:50,034]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:31:53,458]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:31:54,399]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:31:59,735]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:02,577]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:05,895]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:06,339]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:06,922]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:11,809]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:15,803]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:16,759]\u001b[0m Trial 970 finished with value: 6.200714733054518 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010210679935785379, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03290089273039618, 'dropout_rate_Layer_2': 0.006951538328372659, 'dropout_rate_Layer_3': 0.2740974778765575, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004852567208151664, 'l1_Layer_2': 1.7858645047388446e-05, 'l1_Layer_3': 0.000636820689404923, 'n_units_Layer_1': 290, 'n_units_Layer_2': 270, 'n_units_Layer_3': 260}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 11.79% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.19 | sMAPE for Test Set is: 13.07% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:32:17,003]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:17,627]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:25,208]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:28,137]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:28,304]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:34,816]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:36,342]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:37,357]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:37,962]\u001b[0m Trial 983 finished with value: 6.806070658072858 and parameters: {'n_hidden': 3, 'learning_rate': 0.008737704833088101, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2416619782513739, 'dropout_rate_Layer_2': 0.17608638153656608, 'dropout_rate_Layer_3': 0.1546232040475469, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002175575722583061, 'l1_Layer_2': 0.018213793525523228, 'l1_Layer_3': 0.004500524785839376, 'n_units_Layer_1': 115, 'n_units_Layer_2': 125, 'n_units_Layer_3': 160}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 12.93% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 12.75% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:32:45,367]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:48,423]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:49,499]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.50 | sMAPE for Validation Set is: 12.36% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 11.90% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:32:54,201]\u001b[0m Trial 990 finished with value: 6.4985766422193585 and parameters: {'n_hidden': 3, 'learning_rate': 0.009096587956856582, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1419911527344867, 'dropout_rate_Layer_2': 0.2415340098065511, 'dropout_rate_Layer_3': 0.11012160332699018, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0038367051327678797, 'l1_Layer_2': 0.007763681150910117, 'l1_Layer_3': 0.0005439768204010377, 'n_units_Layer_1': 115, 'n_units_Layer_2': 105, 'n_units_Layer_3': 165}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:54,948]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:32:57,628]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:33:03,860]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:33:04,346]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:33:08,173]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:33:12,723]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:33:20,113]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.69 | sMAPE for Validation Set is: 12.54% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 4.81 | sMAPE for Test Set is: 11.97% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:33:22,997]\u001b[0m Trial 1001 finished with value: 6.689145028897504 and parameters: {'n_hidden': 3, 'learning_rate': 0.013971772798217942, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21696570347461153, 'dropout_rate_Layer_2': 0.2664783950375605, 'dropout_rate_Layer_3': 0.16263524097062843, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008322644699591311, 'l1_Layer_2': 0.00610155901338592, 'l1_Layer_3': 0.0005069192130110992, 'n_units_Layer_1': 110, 'n_units_Layer_2': 105, 'n_units_Layer_3': 160}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:33:24,396]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:33:28,676]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:33:31,592]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:33:32,296]\u001b[0m Trial 993 finished with value: 6.199907632602215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012186040805482364, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02423360380247211, 'dropout_rate_Layer_2': 0.016327323772784456, 'dropout_rate_Layer_3': 0.2792377834679561, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021291732328434657, 'l1_Layer_2': 1.65548687947046e-05, 'l1_Layer_3': 0.0009239235004741612, 'n_units_Layer_1': 285, 'n_units_Layer_2': 265, 'n_units_Layer_3': 260}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 11.79% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.98 | sMAPE for Test Set is: 12.55% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:33:37,499]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:33:38,082]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:33:38,913]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:33:44,159]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:33:47,832]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:33:51,154]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:33:51,949]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:33:56,823]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:34:10,778]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:34:11,518]\u001b[0m Trial 1016 finished with value: 6.287592132779696 and parameters: {'n_hidden': 3, 'learning_rate': 0.015106820166440493, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12960482847710109, 'dropout_rate_Layer_2': 0.29050773385483186, 'dropout_rate_Layer_3': 0.16186061886803296, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0042477160487281755, 'l1_Layer_2': 0.00468436866908028, 'l1_Layer_3': 0.0004832297519794285, 'n_units_Layer_1': 105, 'n_units_Layer_2': 105, 'n_units_Layer_3': 155}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.76 | sMAPE for Test Set is: 12.05% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:34:13,521]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:34:19,048]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:34:19,773]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:34:26,432]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:34:31,147]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 11.68% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.80 | sMAPE for Test Set is: 12.10% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:34:33,098]\u001b[0m Trial 1011 finished with value: 6.150459646557075 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010014934413929352, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02307946714779372, 'dropout_rate_Layer_2': 0.0004854936244924439, 'dropout_rate_Layer_3': 0.29674874634114373, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001728642126677163, 'l1_Layer_2': 1.709558621865384e-05, 'l1_Layer_3': 0.0012128672018176447, 'n_units_Layer_1': 300, 'n_units_Layer_2': 270, 'n_units_Layer_3': 270}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:34:38,498]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.79 | sMAPE for Test Set is: 12.08% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:34:40,677]\u001b[0m Trial 1018 finished with value: 6.20602889446351 and parameters: {'n_hidden': 3, 'learning_rate': 0.012432864284123149, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1370435956599592, 'dropout_rate_Layer_2': 0.26335008999582543, 'dropout_rate_Layer_3': 0.1631616386492675, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004275221506132234, 'l1_Layer_2': 0.00438729596372518, 'l1_Layer_3': 0.00048400691881383696, 'n_units_Layer_1': 105, 'n_units_Layer_2': 95, 'n_units_Layer_3': 155}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:34:44,956]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:34:46,848]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:34:53,040]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:34:56,728]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:35:00,925]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:35:05,504]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:35:09,211]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:35:10,629]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:35:27,800]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:35:31,259]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:35:34,667]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:35:47,089]\u001b[0m Trial 1022 finished with value: 6.0577275251232265 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010015661615426557, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0228206880119372, 'dropout_rate_Layer_2': 0.0003979459173541408, 'dropout_rate_Layer_3': 0.2866564813762334, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001507148090200476, 'l1_Layer_2': 1.0172933658202834e-05, 'l1_Layer_3': 0.0011554260590211378, 'n_units_Layer_1': 300, 'n_units_Layer_2': 270, 'n_units_Layer_3': 265}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.06 | sMAPE for Validation Set is: 11.56% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.77 | sMAPE for Test Set is: 12.09% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:35:48,079]\u001b[0m Trial 1038 finished with value: 6.37054191095647 and parameters: {'n_hidden': 3, 'learning_rate': 0.012030725016633076, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22292114193622378, 'dropout_rate_Layer_2': 0.2751732097005561, 'dropout_rate_Layer_3': 0.17131761945071836, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003060148207584436, 'l1_Layer_2': 0.004451149259210841, 'l1_Layer_3': 0.0003257388137194435, 'n_units_Layer_1': 100, 'n_units_Layer_2': 110, 'n_units_Layer_3': 165}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 12.13% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 4.92 | sMAPE for Test Set is: 12.28% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:35:55,673]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:36:00,956]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:36:04,935]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:36:08,702]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:36:08,743]\u001b[0m Trial 1030 finished with value: 6.115590033291439 and parameters: {'n_hidden': 3, 'learning_rate': 0.000995782994611209, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0004769740191170428, 'dropout_rate_Layer_2': 0.002474900853892046, 'dropout_rate_Layer_3': 0.3002574143042814, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001400544226514181, 'l1_Layer_2': 1.741122873980849e-05, 'l1_Layer_3': 0.0010518088572490573, 'n_units_Layer_1': 280, 'n_units_Layer_2': 270, 'n_units_Layer_3': 270}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 11.64% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.01 | sMAPE for Test Set is: 12.57% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:36:10,395]\u001b[0m Trial 1039 finished with value: 6.41287764058211 and parameters: {'n_hidden': 3, 'learning_rate': 0.017280484936568648, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.049360119748202314, 'dropout_rate_Layer_2': 0.27178203251304356, 'dropout_rate_Layer_3': 0.1702408201517557, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004077151012859963, 'l1_Layer_2': 0.0037537049812856795, 'l1_Layer_3': 0.0003990868689258563, 'n_units_Layer_1': 100, 'n_units_Layer_2': 265, 'n_units_Layer_3': 170}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 12.30% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 5.24 | sMAPE for Test Set is: 13.33% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:36:18,056]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:36:22,010]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:36:22,762]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:36:30,774]\u001b[0m Trial 1046 finished with value: 6.3669331874261355 and parameters: {'n_hidden': 3, 'learning_rate': 0.016891015014238276, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1208463183155074, 'dropout_rate_Layer_2': 0.26914043489519246, 'dropout_rate_Layer_3': 0.1789412772645614, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003233376482780423, 'l1_Layer_2': 0.0034820980686111245, 'l1_Layer_3': 0.0003822665617759547, 'n_units_Layer_1': 100, 'n_units_Layer_2': 275, 'n_units_Layer_3': 170}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 12.16% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.27 | sMAPE for Test Set is: 13.37% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:36:31,832]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:36:38,551]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:36:42,529]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:36:42,705]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:36:48,468]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:36:49,276]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:36:49,564]\u001b[0m Trial 1041 finished with value: 6.097922173256759 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009336075372921001, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023871197325111358, 'dropout_rate_Layer_2': 0.003043300380854305, 'dropout_rate_Layer_3': 0.29870345353857414, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016841379688287976, 'l1_Layer_2': 1.4392323922719782e-05, 'l1_Layer_3': 0.0010284842596573233, 'n_units_Layer_1': 295, 'n_units_Layer_2': 270, 'n_units_Layer_3': 275}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 11.65% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.33 | sMAPE for Test Set is: 13.62% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:36:50,179]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:36:58,503]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:37:02,308]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:37:05,197]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:37:08,415]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:37:11,380]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:37:15,725]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:37:19,847]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:37:23,343]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:37:24,005]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:37:26,857]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:37:30,795]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:37:34,230]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:37:34,504]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:37:40,742]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:37:41,058]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:37:48,698]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:37:51,444]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:37:53,962]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:38:00,489]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:38:02,233]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:38:07,274]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:38:11,812]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:38:16,362]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:38:20,425]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:38:24,776]\u001b[0m Trial 1059 finished with value: 6.1142059826007324 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008681603501008647, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02244218291853022, 'dropout_rate_Layer_2': 0.02051700289499215, 'dropout_rate_Layer_3': 0.2624874131571497, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011524459137472348, 'l1_Layer_2': 2.1863006265756367e-05, 'l1_Layer_3': 0.0010369414677775734, 'n_units_Layer_1': 295, 'n_units_Layer_2': 260, 'n_units_Layer_3': 275}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.11 | sMAPE for Validation Set is: 11.68% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.85 | sMAPE for Test Set is: 12.18% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:38:25,065]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:38:26,147]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:38:33,203]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:38:39,381]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:38:52,212]\u001b[0m Trial 1084 finished with value: 6.4512270140248305 and parameters: {'n_hidden': 3, 'learning_rate': 0.016704051826893242, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14347448829177184, 'dropout_rate_Layer_2': 0.2774241967832948, 'dropout_rate_Layer_3': 0.17595977842919117, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028078564491721826, 'l1_Layer_2': 0.0008388307357331553, 'l1_Layer_3': 0.0006311123907053185, 'n_units_Layer_1': 115, 'n_units_Layer_2': 275, 'n_units_Layer_3': 150}. Best is trial 211 with value: 5.986819840010317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 12.40% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 5.09 | sMAPE for Test Set is: 12.82% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:38:57,309]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:38:57,552]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:39:04,595]\u001b[0m Trial 1069 finished with value: 5.935980201113824 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005602284548988985, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15007961665237893, 'dropout_rate_Layer_2': 0.13898347788396956, 'dropout_rate_Layer_3': 0.14001448788986998, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028710290060646285, 'l1_Layer_2': 0.0007598198309155235, 'l1_Layer_3': 0.0005114052243417556, 'n_units_Layer_1': 220, 'n_units_Layer_2': 145, 'n_units_Layer_3': 135}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.94 | sMAPE for Validation Set is: 11.34% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 4.53 | sMAPE for Test Set is: 11.43% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:39:09,345]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:39:31,513]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:39:37,718]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:39:38,382]\u001b[0m Trial 1086 finished with value: 6.126218437216136 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010391382908611754, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1484121554991727, 'dropout_rate_Layer_2': 0.2713300936424868, 'dropout_rate_Layer_3': 0.16560420263940395, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001297953639796829, 'l1_Layer_2': 0.003994233154195807, 'l1_Layer_3': 0.000775723845100673, 'n_units_Layer_1': 95, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 11.71% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.88 | sMAPE for Test Set is: 12.35% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:39:44,883]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:39:50,627]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:39:56,531]\u001b[0m Trial 1094 finished with value: 7.087509615390218 and parameters: {'n_hidden': 3, 'learning_rate': 0.019483066325367757, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14984383164266357, 'dropout_rate_Layer_2': 0.2931419510322383, 'dropout_rate_Layer_3': 0.17852342379967617, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008487854761820023, 'l1_Layer_2': 0.0030330783161585115, 'l1_Layer_3': 0.0006059721348581236, 'n_units_Layer_1': 100, 'n_units_Layer_2': 275, 'n_units_Layer_3': 155}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.09 | sMAPE for Validation Set is: 13.63% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 13.24% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:40:02,675]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:40:07,490]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:40:12,815]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:40:13,151]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:40:15,108]\u001b[0m Trial 1091 finished with value: 6.076155448776828 and parameters: {'n_hidden': 3, 'learning_rate': 0.000770306806238283, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008613152383237647, 'dropout_rate_Layer_2': 0.024437979777775662, 'dropout_rate_Layer_3': 0.2631444186364569, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018425471162091635, 'l1_Layer_2': 1.798004145395476e-05, 'l1_Layer_3': 0.0008407387011631801, 'n_units_Layer_1': 280, 'n_units_Layer_2': 255, 'n_units_Layer_3': 270}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 11.56% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.71 | sMAPE for Test Set is: 11.85% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:40:22,579]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:40:25,059]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:40:29,662]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:40:32,087]\u001b[0m Trial 1089 finished with value: 6.160445175064343 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008778329040512149, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011567010327396076, 'dropout_rate_Layer_2': 0.02571212615414866, 'dropout_rate_Layer_3': 0.26429986407456435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001824305818965451, 'l1_Layer_2': 1.761300772134141e-05, 'l1_Layer_3': 0.0017921214710290541, 'n_units_Layer_1': 280, 'n_units_Layer_2': 255, 'n_units_Layer_3': 270}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 11.72% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.87 | sMAPE for Test Set is: 12.25% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:40:36,197]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:40:39,585]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:40:44,346]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:40:48,171]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:40:52,968]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:40:57,069]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:40:57,595]\u001b[0m Trial 1104 finished with value: 6.080282733302764 and parameters: {'n_hidden': 3, 'learning_rate': 0.004413053249178032, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15105781886881312, 'dropout_rate_Layer_2': 0.12787271471234157, 'dropout_rate_Layer_3': 0.12803121574607357, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003000741331254314, 'l1_Layer_2': 0.0010085051368322441, 'l1_Layer_3': 0.0008269489940284, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 220}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 11.61% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.41 | sMAPE for Test Set is: 11.11% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:41:13,767]\u001b[0m Trial 1111 finished with value: 6.312887371345606 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012392799865193597, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1540273258740527, 'dropout_rate_Layer_2': 0.2720142102946247, 'dropout_rate_Layer_3': 0.19872137269916446, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.08984645629273e-05, 'l1_Layer_2': 0.003572784726157152, 'l1_Layer_3': 0.00038568334135490935, 'n_units_Layer_1': 105, 'n_units_Layer_2': 265, 'n_units_Layer_3': 145}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 12.10% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 13.54% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:41:14,593]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:41:18,719]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:41:19,994]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:41:23,000]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:41:28,739]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:41:29,042]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:41:34,551]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:41:35,274]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.91 | sMAPE for Test Set is: 12.46% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:41:39,842]\u001b[0m Trial 1108 finished with value: 6.181925581251886 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011472736753111352, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14334464776812614, 'dropout_rate_Layer_2': 0.2752098456958968, 'dropout_rate_Layer_3': 0.20105337360021103, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010097372190867356, 'l1_Layer_2': 0.0010285037189673202, 'l1_Layer_3': 0.0008377892694842199, 'n_units_Layer_1': 95, 'n_units_Layer_2': 280, 'n_units_Layer_3': 145}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:41:41,789]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:41:46,561]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:41:47,750]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:41:49,230]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:41:55,224]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:41:55,478]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:42:35,315]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:42:35,726]\u001b[0m Trial 1126 finished with value: 6.237936045204461 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009096237220574946, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1593154525730533, 'dropout_rate_Layer_2': 0.27103809596019424, 'dropout_rate_Layer_3': 0.19665163012221204, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0069993532127052e-05, 'l1_Layer_2': 0.0008285851808582947, 'l1_Layer_3': 0.0010587210106317543, 'n_units_Layer_1': 90, 'n_units_Layer_2': 285, 'n_units_Layer_3': 155}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 11.95% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.18 | sMAPE for Test Set is: 13.29% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:42:41,129]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:42:57,044]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:43:02,754]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:43:05,046]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:43:12,300]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:43:16,258]\u001b[0m Trial 1117 finished with value: 6.250098839356691 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006583140912773106, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020447415854094673, 'dropout_rate_Layer_2': 0.028779026955636916, 'dropout_rate_Layer_3': 0.24654678134199817, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009853425949336817, 'l1_Layer_2': 1.750405367663127e-05, 'l1_Layer_3': 0.0011006195686131732, 'n_units_Layer_1': 275, 'n_units_Layer_2': 250, 'n_units_Layer_3': 285}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 11.96% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 13.93% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:43:17,442]\u001b[0m Trial 1132 finished with value: 6.180541953445591 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011427429256971888, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15660269680361394, 'dropout_rate_Layer_2': 0.2684643551409571, 'dropout_rate_Layer_3': 0.19961143110000484, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.343432775070547e-05, 'l1_Layer_2': 0.0008044470649205873, 'l1_Layer_3': 0.0011256916913156664, 'n_units_Layer_1': 95, 'n_units_Layer_2': 295, 'n_units_Layer_3': 155}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 11.84% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.17 | sMAPE for Test Set is: 13.15% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:43:23,139]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:43:26,401]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:43:29,150]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:43:32,109]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:43:37,105]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:43:44,057]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:43:48,505]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:43:52,048]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:43:57,192]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:44:00,579]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:44:05,952]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:44:11,468]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:44:15,090]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:44:17,891]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:44:21,886]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:44:23,742]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:44:26,399]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:44:29,804]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:44:34,264]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:44:37,602]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:44:44,270]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:44:47,790]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:44:55,089]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:44:58,093]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:44:58,225]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:44:59,571]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:06,198]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:09,809]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:12,846]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:14,616]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:17,273]\u001b[0m Trial 1149 finished with value: 6.144300529037774 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008864677356110476, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007246690270722365, 'dropout_rate_Layer_2': 0.020394782120221038, 'dropout_rate_Layer_3': 0.28898930415651525, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002677230861923983, 'l1_Layer_2': 3.2431778420085844e-05, 'l1_Layer_3': 0.0008180683812296231, 'n_units_Layer_1': 300, 'n_units_Layer_2': 275, 'n_units_Layer_3': 260}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 11.69% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.76 | sMAPE for Test Set is: 12.07% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:45:18,107]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:28,122]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:28,261]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:28,507]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:37,744]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:38,108]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:41,994]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:45,544]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:47,663]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:51,971]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:56,096]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:57,777]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:59,449]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:45:59,767]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:07,870]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:09,279]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:10,404]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:10,553]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:19,433]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:20,521]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:23,314]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:23,866]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:26,710]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:28,688]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:37,393]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:37,868]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:38,467]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:38,986]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:45,133]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:46,583]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:49,165]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:46:59,500]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:47:01,109]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:47:03,939]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:47:05,227]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:47:06,273]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:47:13,697]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:47:15,098]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:47:19,776]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:47:20,396]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:47:21,010]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:47:21,321]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:47:30,276]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:47:40,489]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:47:41,257]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 12.23% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 14.67% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:47:44,841]\u001b[0m Trial 1210 finished with value: 6.355846459807853 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010079696213999602, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1333154380068674, 'dropout_rate_Layer_2': 0.2684834719749423, 'dropout_rate_Layer_3': 0.19222045668080798, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5508998054678674e-05, 'l1_Layer_2': 0.00022861841518831825, 'l1_Layer_3': 0.0004970558061309922, 'n_units_Layer_1': 105, 'n_units_Layer_2': 260, 'n_units_Layer_3': 160}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:47:56,504]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:48:00,904]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:48:04,513]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:48:10,917]\u001b[0m Trial 1213 finished with value: 6.268635888596933 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010903567841980065, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13429562635692052, 'dropout_rate_Layer_2': 0.26962657166895926, 'dropout_rate_Layer_3': 0.19157621726421153, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7571231163089025e-05, 'l1_Layer_2': 0.0009376578331168515, 'l1_Layer_3': 0.0005139861730082167, 'n_units_Layer_1': 105, 'n_units_Layer_2': 290, 'n_units_Layer_3': 160}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 12.04% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.24 | sMAPE for Test Set is: 13.49% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:48:18,081]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:48:23,394]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 12.07% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 13.36% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:48:26,384]\u001b[0m Trial 1218 finished with value: 6.281869360454922 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009716130597380252, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14787146003632354, 'dropout_rate_Layer_2': 0.27721965777967195, 'dropout_rate_Layer_3': 0.19478596501477585, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.6104008568725647e-05, 'l1_Layer_2': 0.0004383193018432387, 'l1_Layer_3': 0.0003404238259385105, 'n_units_Layer_1': 90, 'n_units_Layer_2': 260, 'n_units_Layer_3': 170}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:48:26,660]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:48:32,788]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:48:36,499]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:48:39,177]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:48:39,420]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:48:44,637]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:48:48,594]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:49:02,522]\u001b[0m Trial 1228 finished with value: 6.389557796385923 and parameters: {'n_hidden': 3, 'learning_rate': 0.001061509824994612, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1345494014438644, 'dropout_rate_Layer_2': 0.307900786852229, 'dropout_rate_Layer_3': 0.20215992546106976, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9378122831203352e-05, 'l1_Layer_2': 0.00034412320091798965, 'l1_Layer_3': 0.0005018179660647644, 'n_units_Layer_1': 80, 'n_units_Layer_2': 250, 'n_units_Layer_3': 175}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 12.27% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 15.73% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:49:07,558]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:49:13,727]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:49:17,982]\u001b[0m Trial 1220 finished with value: 6.144709329090083 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009481125617361678, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01838959783186886, 'dropout_rate_Layer_2': 0.013056856239195246, 'dropout_rate_Layer_3': 0.2950441835645734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001710960005362196, 'l1_Layer_2': 3.507717565810925e-05, 'l1_Layer_3': 0.0016316841535576477, 'n_units_Layer_1': 280, 'n_units_Layer_2': 280, 'n_units_Layer_3': 280}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 11.71% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.86 | sMAPE for Test Set is: 12.22% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:49:23,231]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:49:26,884]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:49:27,465]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:49:28,974]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:49:32,680]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:49:35,916]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:49:55,493]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:49:55,703]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:50:03,158]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:50:07,460]\u001b[0m Trial 1226 finished with value: 6.1430600179196295 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009291824788313681, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04122089878734653, 'dropout_rate_Layer_2': 0.013959101390567885, 'dropout_rate_Layer_3': 0.31602214006122176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002660082814936633, 'l1_Layer_2': 2.057137197335925e-05, 'l1_Layer_3': 0.0017291483214813413, 'n_units_Layer_1': 265, 'n_units_Layer_2': 255, 'n_units_Layer_3': 275}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.79 | sMAPE for Test Set is: 12.09% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:50:10,084]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:50:13,763]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:50:18,045]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:50:25,280]\u001b[0m Trial 1238 finished with value: 6.124347518311755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009500567928140143, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022752666594824274, 'dropout_rate_Layer_2': 0.025635863930815888, 'dropout_rate_Layer_3': 0.2326057306674888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013748504528683888, 'l1_Layer_2': 1.4631786500240062e-05, 'l1_Layer_3': 0.002080809136510326, 'n_units_Layer_1': 270, 'n_units_Layer_2': 280, 'n_units_Layer_3': 280}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 11.68% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.94 | sMAPE for Test Set is: 12.49% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:50:29,179]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:50:36,460]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:50:40,345]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:50:44,471]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 12.09% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.12 | sMAPE for Test Set is: 13.01% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:50:45,147]\u001b[0m Trial 1245 finished with value: 6.294355897184192 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008520375501405727, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15695851832944616, 'dropout_rate_Layer_2': 0.3047288023032226, 'dropout_rate_Layer_3': 0.20101879781546395, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7612861451177184e-05, 'l1_Layer_2': 0.0002358862596771697, 'l1_Layer_3': 0.0004352851473961807, 'n_units_Layer_1': 105, 'n_units_Layer_2': 245, 'n_units_Layer_3': 170}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:50:51,533]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:50:52,928]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:50:53,060]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:50:56,520]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:50:58,832]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:51:04,227]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:51:10,511]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:51:11,281]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:51:17,136]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:51:17,862]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:51:24,522]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:51:29,342]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:51:35,280]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:51:42,636]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:51:46,761]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:51:52,735]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:51:56,783]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:52:01,754]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:52:06,346]\u001b[0m Trial 1266 finished with value: 6.308637911283327 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011553179871718318, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12658906658488792, 'dropout_rate_Layer_2': 0.2764034635160776, 'dropout_rate_Layer_3': 0.2169475054666758, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.698340182675639e-05, 'l1_Layer_2': 0.0002780678545061048, 'l1_Layer_3': 0.0003960003904890274, 'n_units_Layer_1': 95, 'n_units_Layer_2': 255, 'n_units_Layer_3': 165}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 12.06% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.56 | sMAPE for Test Set is: 14.43% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:52:09,584]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:52:13,848]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:52:14,111]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:52:20,738]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:52:21,434]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:52:27,291]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:52:27,418]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:52:35,991]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:52:36,734]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:52:43,473]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:52:47,483]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:52:47,611]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:52:53,258]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:52:53,738]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:52:59,604]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:53:00,452]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:53:06,696]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:53:07,845]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:53:10,714]\u001b[0m Trial 1271 finished with value: 6.109092902870818 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008567252134166513, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05187440556899542, 'dropout_rate_Layer_2': 0.014970464145662336, 'dropout_rate_Layer_3': 0.2915475387991633, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001453383491752552, 'l1_Layer_2': 2.343850726873098e-05, 'l1_Layer_3': 0.0021407563912715223, 'n_units_Layer_1': 275, 'n_units_Layer_2': 275, 'n_units_Layer_3': 290}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.11 | sMAPE for Validation Set is: 11.63% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.74 | sMAPE for Test Set is: 11.96% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:53:12,491]\u001b[0m Trial 1265 finished with value: 6.090450977426667 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005700854022096117, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025723482931080614, 'dropout_rate_Layer_2': 0.000846983128460297, 'dropout_rate_Layer_3': 0.22594835636977065, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022223908945180563, 'l1_Layer_2': 1.5481513621603717e-05, 'l1_Layer_3': 0.0019638986638947295, 'n_units_Layer_1': 265, 'n_units_Layer_2': 270, 'n_units_Layer_3': 270}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 11.57% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.89 | sMAPE for Test Set is: 12.28% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:53:14,041]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:53:20,757]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:53:26,477]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:53:27,592]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:53:35,281]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:53:35,779]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:53:44,636]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:53:45,689]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:53:52,304]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:53:55,729]\u001b[0m Trial 1289 finished with value: 6.265379472196213 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008530376142923769, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1488310642171559, 'dropout_rate_Layer_2': 0.28627183973098863, 'dropout_rate_Layer_3': 0.22658557792922146, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.926659904159228e-05, 'l1_Layer_2': 0.00027692909629229643, 'l1_Layer_3': 0.0006514772205609149, 'n_units_Layer_1': 105, 'n_units_Layer_2': 275, 'n_units_Layer_3': 150}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 12.02% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.22 | sMAPE for Test Set is: 13.41% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:53:57,752]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:54:05,223]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:54:11,028]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:54:15,359]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:54:27,459]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:54:27,956]\u001b[0m Trial 1303 finished with value: 6.2351687561599904 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008549376972929423, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16097166262229198, 'dropout_rate_Layer_2': 0.30048044929741197, 'dropout_rate_Layer_3': 0.21348183436612747, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8418569491901552e-05, 'l1_Layer_2': 0.00027763425895002653, 'l1_Layer_3': 0.0007167569411428505, 'n_units_Layer_1': 100, 'n_units_Layer_2': 280, 'n_units_Layer_3': 155}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 11.95% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.69 | sMAPE for Test Set is: 14.78% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:54:28,522]\u001b[0m Trial 1304 finished with value: 6.2540297628825385 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010951296825228733, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09787120959396986, 'dropout_rate_Layer_2': 0.2779313269290329, 'dropout_rate_Layer_3': 0.2219161742535717, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2661005877730324e-05, 'l1_Layer_2': 0.00026442573907941696, 'l1_Layer_3': 0.0005603680696029276, 'n_units_Layer_1': 95, 'n_units_Layer_2': 285, 'n_units_Layer_3': 180}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 11.98% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.39 | sMAPE for Test Set is: 14.00% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:54:37,040]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:54:41,091]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:54:41,917]\u001b[0m Trial 1306 finished with value: 6.398277731243681 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010042832572901919, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13592510193509724, 'dropout_rate_Layer_2': 0.27321966068994263, 'dropout_rate_Layer_3': 0.2434706464337965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2401092078420083e-05, 'l1_Layer_2': 0.00019441982839667586, 'l1_Layer_3': 0.0004745330935901083, 'n_units_Layer_1': 105, 'n_units_Layer_2': 265, 'n_units_Layer_3': 150}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 12.37% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 5.99 | sMAPE for Test Set is: 15.90% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:54:48,211]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:54:49,513]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:54:53,289]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:54:58,635]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:55:01,427]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:55:06,153]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:55:10,742]\u001b[0m Trial 1313 finished with value: 6.177150962863334 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010513692368747966, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10880213102516323, 'dropout_rate_Layer_2': 0.27361240053506214, 'dropout_rate_Layer_3': 0.25255210014007146, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2029052953618298e-05, 'l1_Layer_2': 0.0002015071989996785, 'l1_Layer_3': 0.0001778476842761337, 'n_units_Layer_1': 80, 'n_units_Layer_2': 280, 'n_units_Layer_3': 180}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.99 | sMAPE for Test Set is: 12.72% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:55:17,621]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:55:22,570]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:55:25,882]\u001b[0m Trial 1308 finished with value: 6.179794532564544 and parameters: {'n_hidden': 3, 'learning_rate': 0.000755291419494625, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11403991036492446, 'dropout_rate_Layer_2': 0.2748228216677783, 'dropout_rate_Layer_3': 0.24451118076031725, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2701076395598283e-05, 'l1_Layer_2': 0.00019383339212772393, 'l1_Layer_3': 0.0008398225901783593, 'n_units_Layer_1': 80, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 11.84% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.13 | sMAPE for Test Set is: 13.07% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:55:29,642]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:55:35,287]\u001b[0m Trial 1316 finished with value: 6.204868026241466 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010139221650207336, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13369320707642854, 'dropout_rate_Layer_2': 0.27456986545098366, 'dropout_rate_Layer_3': 0.22765145604333872, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0010691658652245e-05, 'l1_Layer_2': 0.00014765960016823042, 'l1_Layer_3': 0.0005101076987683159, 'n_units_Layer_1': 100, 'n_units_Layer_2': 290, 'n_units_Layer_3': 220}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 11.90% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.27 | sMAPE for Test Set is: 13.52% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:55:39,152]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:55:43,621]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:55:51,285]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:55:56,350]\u001b[0m Trial 1321 finished with value: 6.277712558341427 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010314116431553925, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11986754254515344, 'dropout_rate_Layer_2': 0.2986085733350432, 'dropout_rate_Layer_3': 0.2543648294383863, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2829267854659052e-05, 'l1_Layer_2': 0.00019932315419372366, 'l1_Layer_3': 0.00014684747162724672, 'n_units_Layer_1': 70, 'n_units_Layer_2': 290, 'n_units_Layer_3': 190}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 12.06% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.21 | sMAPE for Test Set is: 13.25% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:55:57,461]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:56:02,274]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:56:04,830]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:56:05,018]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:56:06,614]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:56:12,397]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:56:14,640]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:56:15,685]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:56:20,578]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:56:23,291]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:56:28,037]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:56:32,178]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:56:32,755]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:56:33,345]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:56:41,763]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:56:46,418]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:56:49,712]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:56:55,422]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:57:00,339]\u001b[0m Trial 1337 finished with value: 6.231830190013906 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012210843035025982, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10768518771568691, 'dropout_rate_Layer_2': 0.285733171102639, 'dropout_rate_Layer_3': 0.23749028990525214, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2053920522083707e-05, 'l1_Layer_2': 0.00019636211644237246, 'l1_Layer_3': 0.0008730118416885722, 'n_units_Layer_1': 60, 'n_units_Layer_2': 300, 'n_units_Layer_3': 215}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 11.95% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 13.65% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:57:09,294]\u001b[0m Trial 1345 finished with value: 6.177021025785521 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012020047750487001, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11825301721388237, 'dropout_rate_Layer_2': 0.26105979524098866, 'dropout_rate_Layer_3': 0.23951769778140974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.562061234864457e-05, 'l1_Layer_2': 0.00012120580050386128, 'l1_Layer_3': 0.00022505056114298594, 'n_units_Layer_1': 70, 'n_units_Layer_2': 285, 'n_units_Layer_3': 210}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 11.85% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.36 | sMAPE for Test Set is: 13.83% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:57:12,625]\u001b[0m Trial 1346 finished with value: 6.313689163756771 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012357484292878803, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11619834445985679, 'dropout_rate_Layer_2': 0.27782476824425634, 'dropout_rate_Layer_3': 0.22945061184720209, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.159603163513377e-05, 'l1_Layer_2': 0.0001136999275917166, 'l1_Layer_3': 0.00032946483609583733, 'n_units_Layer_1': 60, 'n_units_Layer_2': 285, 'n_units_Layer_3': 225}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 12.11% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.41 | sMAPE for Test Set is: 17.13% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:57:17,453]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:57:18,221]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:57:19,365]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:57:27,236]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:57:30,142]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:57:34,363]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:57:37,205]\u001b[0m Trial 1347 finished with value: 6.160675163784063 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011905008486392922, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09493358181198279, 'dropout_rate_Layer_2': 0.29898685724137697, 'dropout_rate_Layer_3': 0.23865246494892436, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1515934405996838e-05, 'l1_Layer_2': 0.00012244047879179611, 'l1_Layer_3': 0.000868779422102287, 'n_units_Layer_1': 55, 'n_units_Layer_2': 290, 'n_units_Layer_3': 220}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 11.79% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.11 | sMAPE for Test Set is: 13.10% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:57:38,365]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:57:38,517]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:57:44,800]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:57:47,627]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:57:49,183]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:57:49,228]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:57:54,003]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:57:58,613]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:58:02,736]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:58:05,075]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:58:12,004]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:58:18,659]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.31 | sMAPE for Test Set is: 13.81% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:58:19,873]\u001b[0m Trial 1364 finished with value: 6.172885137288042 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011807305550482798, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0946904212856477, 'dropout_rate_Layer_2': 0.2822289482433354, 'dropout_rate_Layer_3': 0.22964205973037363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0363314617060778e-05, 'l1_Layer_2': 0.00013735278257612978, 'l1_Layer_3': 0.00012052347861983843, 'n_units_Layer_1': 55, 'n_units_Layer_2': 290, 'n_units_Layer_3': 230}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 12.85% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:58:22,301]\u001b[0m Trial 1363 finished with value: 6.214577916498736 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007185733948628817, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11445038337328135, 'dropout_rate_Layer_2': 0.2829060158020805, 'dropout_rate_Layer_3': 0.22972435569849364, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1610503719745818e-05, 'l1_Layer_2': 0.0001568002983676352, 'l1_Layer_3': 0.00023194538692282256, 'n_units_Layer_1': 55, 'n_units_Layer_2': 290, 'n_units_Layer_3': 225}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:58:29,282]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:58:30,226]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:58:35,585]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:58:41,563]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:58:44,702]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:58:50,701]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:58:56,990]\u001b[0m Trial 1374 finished with value: 6.107892076831512 and parameters: {'n_hidden': 3, 'learning_rate': 0.001362035811235485, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08877024916044603, 'dropout_rate_Layer_2': 0.28575596080728183, 'dropout_rate_Layer_3': 0.23211258733403034, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0215120800390886e-05, 'l1_Layer_2': 0.0001343926542409776, 'l1_Layer_3': 0.00017878619710254236, 'n_units_Layer_1': 55, 'n_units_Layer_2': 285, 'n_units_Layer_3': 225}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.11 | sMAPE for Validation Set is: 11.69% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.02 | sMAPE for Test Set is: 12.90% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:59:00,059]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:59:01,389]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:59:07,617]\u001b[0m Trial 1365 finished with value: 6.0673317709715 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009174575869535784, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05828216418661547, 'dropout_rate_Layer_2': 0.00014669894618031531, 'dropout_rate_Layer_3': 0.213846410360971, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017966347108781967, 'l1_Layer_2': 1.944832090458913e-05, 'l1_Layer_3': 0.0013365785870980214, 'n_units_Layer_1': 280, 'n_units_Layer_2': 285, 'n_units_Layer_3': 240}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 11.56% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.83 | sMAPE for Test Set is: 12.21% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:59:10,703]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:59:14,495]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:59:19,269]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:59:28,420]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:59:32,168]\u001b[0m Trial 1373 finished with value: 6.111295666685763 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012959614143352213, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023085999702191964, 'dropout_rate_Layer_2': 0.0008791619966002813, 'dropout_rate_Layer_3': 0.2128520402545741, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008505760792941246, 'l1_Layer_2': 2.7459649742732825e-05, 'l1_Layer_3': 0.0008763944150879925, 'n_units_Layer_1': 275, 'n_units_Layer_2': 275, 'n_units_Layer_3': 260}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.11 | sMAPE for Validation Set is: 11.64% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.88 | sMAPE for Test Set is: 12.39% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:59:36,471]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 20:59:54,958]\u001b[0m Trial 1378 finished with value: 6.034793520089191 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006818825690551372, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03703967287888331, 'dropout_rate_Layer_2': 0.04761822203006369, 'dropout_rate_Layer_3': 0.010213448072807225, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.403810704587125e-05, 'l1_Layer_2': 0.0018273203477119496, 'l1_Layer_3': 4.811730037398726e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 275, 'n_units_Layer_3': 145}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.03 | sMAPE for Validation Set is: 11.56% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.23 | sMAPE for Test Set is: 13.55% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 20:59:56,376]\u001b[0m Trial 1384 finished with value: 6.100479573999259 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011790162392631687, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09489733058451699, 'dropout_rate_Layer_2': 0.2853785208294009, 'dropout_rate_Layer_3': 0.23824047986668792, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.179659540283886e-05, 'l1_Layer_2': 0.00014938748092003723, 'l1_Layer_3': 0.00022309447941089663, 'n_units_Layer_1': 55, 'n_units_Layer_2': 285, 'n_units_Layer_3': 225}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.99 | sMAPE for Test Set is: 12.77% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:00:00,820]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:00:05,043]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:00:09,698]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:00:13,935]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:00:21,337]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:00:21,352]\u001b[0m Trial 1380 finished with value: 6.108369689698104 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007537437987163734, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028978741461213292, 'dropout_rate_Layer_2': 0.1584124012245521, 'dropout_rate_Layer_3': 0.21404184882391153, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002624983014660873, 'l1_Layer_2': 3.827772185114807e-05, 'l1_Layer_3': 0.0005739689181705941, 'n_units_Layer_1': 285, 'n_units_Layer_2': 170, 'n_units_Layer_3': 270}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.11 | sMAPE for Validation Set is: 11.63% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.99 | sMAPE for Test Set is: 12.48% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:00:21,515]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:00:33,447]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:00:34,051]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:00:39,529]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:00:45,230]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:00:48,902]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:00:53,416]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:00:54,612]\u001b[0m Trial 1388 finished with value: 6.017629173951886 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011450842847891382, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03568309029605166, 'dropout_rate_Layer_2': 0.014970495462201364, 'dropout_rate_Layer_3': 0.00661234985403714, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.6142539316790318e-05, 'l1_Layer_2': 0.0022425616105091603, 'l1_Layer_3': 5.309062803781732e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 290, 'n_units_Layer_3': 135}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.02 | sMAPE for Validation Set is: 11.46% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.29 | sMAPE for Test Set is: 13.12% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:00:59,148]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:01:01,304]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:01:04,512]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:01:06,919]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:01:11,211]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:01:11,750]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:01:18,792]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:01:19,668]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:01:26,498]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:01:27,363]\u001b[0m Trial 1401 finished with value: 6.188485662515382 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008050754496830811, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10351757112782262, 'dropout_rate_Layer_2': 0.29121883186799746, 'dropout_rate_Layer_3': 0.23786344515806482, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5931577508517845e-05, 'l1_Layer_2': 9.482019333187504e-05, 'l1_Layer_3': 0.0002283338797850891, 'n_units_Layer_1': 70, 'n_units_Layer_2': 280, 'n_units_Layer_3': 225}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 11.91% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.15 | sMAPE for Test Set is: 13.36% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:01:27,429]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:01:36,434]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:01:37,254]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:01:42,468]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:01:48,640]\u001b[0m Trial 1394 finished with value: 6.028018862468571 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008355663817913965, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03948757995460702, 'dropout_rate_Layer_2': 0.02585582050890648, 'dropout_rate_Layer_3': 0.0008042858513916205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.676509387553131e-05, 'l1_Layer_2': 0.0016058579659149468, 'l1_Layer_3': 4.501704810157053e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 280, 'n_units_Layer_3': 65}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.03 | sMAPE for Validation Set is: 11.50% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 4.93 | sMAPE for Test Set is: 12.48% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:01:55,559]\u001b[0m Trial 1413 finished with value: 6.182729827678405 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008325109710431573, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08254964916474385, 'dropout_rate_Layer_2': 0.29875108236743264, 'dropout_rate_Layer_3': 0.22117704910279176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7949361247597378e-05, 'l1_Layer_2': 6.0080434617664944e-05, 'l1_Layer_3': 0.0002612674000205268, 'n_units_Layer_1': 70, 'n_units_Layer_2': 285, 'n_units_Layer_3': 235}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 11.84% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 12.57% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:02:00,815]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:02:06,737]\u001b[0m Trial 1415 finished with value: 6.094104373592683 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007096963294577382, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0774935851906611, 'dropout_rate_Layer_2': 0.2981989999824166, 'dropout_rate_Layer_3': 0.2820168818628628, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7865742309133818e-05, 'l1_Layer_2': 0.00015506647509652482, 'l1_Layer_3': 0.00020733490748818363, 'n_units_Layer_1': 70, 'n_units_Layer_2': 285, 'n_units_Layer_3': 235}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.79 | sMAPE for Test Set is: 12.20% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:02:10,625]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:02:11,326]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:02:17,023]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:02:22,068]\u001b[0m Trial 1419 finished with value: 6.125915778184958 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008185241267245554, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09373451997469753, 'dropout_rate_Layer_2': 0.31262140730787513, 'dropout_rate_Layer_3': 0.23114272089443957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4247406731010018e-05, 'l1_Layer_2': 7.562662902547271e-05, 'l1_Layer_3': 0.00019590208516588213, 'n_units_Layer_1': 60, 'n_units_Layer_2': 285, 'n_units_Layer_3': 230}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 11.72% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.18 | sMAPE for Test Set is: 13.43% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:02:22,873]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:02:25,265]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:02:30,757]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:02:31,753]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:02:39,449]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:02:39,785]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:02:41,358]\u001b[0m Trial 1416 finished with value: 6.093646693762454 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008209675104035159, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09308248605318169, 'dropout_rate_Layer_2': 0.28916972445173816, 'dropout_rate_Layer_3': 0.22099035437885364, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3963839191319112e-05, 'l1_Layer_2': 0.0002611421946943236, 'l1_Layer_3': 0.00022247403503009727, 'n_units_Layer_1': 60, 'n_units_Layer_2': 295, 'n_units_Layer_3': 215}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 11.66% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.83 | sMAPE for Test Set is: 12.44% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:02:49,912]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:02:50,269]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:02:51,496]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:03:02,519]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:03:11,358]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:03:12,983]\u001b[0m Trial 1431 finished with value: 6.159391627125235 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006761731282627744, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0784568503359788, 'dropout_rate_Layer_2': 0.32117413545430307, 'dropout_rate_Layer_3': 0.23091912452181, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.305089170357297e-05, 'l1_Layer_2': 6.0926157794999566e-05, 'l1_Layer_3': 0.0001632884238219524, 'n_units_Layer_1': 65, 'n_units_Layer_2': 290, 'n_units_Layer_3': 235}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 11.85% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.87 | sMAPE for Test Set is: 12.50% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:03:20,846]\u001b[0m Trial 1433 finished with value: 6.078844588428903 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007375278412268975, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0854461724592668, 'dropout_rate_Layer_2': 0.30401396051043467, 'dropout_rate_Layer_3': 0.2236628360881363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2962910624844936e-05, 'l1_Layer_2': 7.580024403570618e-05, 'l1_Layer_3': 0.00014647354358671751, 'n_units_Layer_1': 60, 'n_units_Layer_2': 290, 'n_units_Layer_3': 235}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 11.69% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.89 | sMAPE for Test Set is: 12.54% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:03:23,091]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:03:24,939]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:03:29,299]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:03:30,434]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:03:35,331]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:03:36,699]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:03:42,152]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:03:57,193]\u001b[0m Trial 1434 finished with value: 6.102490021361096 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007268412699253366, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08542291094023342, 'dropout_rate_Layer_2': 0.3143995437841867, 'dropout_rate_Layer_3': 0.22439683555394868, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.323073265706949e-05, 'l1_Layer_2': 6.279400435423515e-05, 'l1_Layer_3': 0.00020576125940864352, 'n_units_Layer_1': 65, 'n_units_Layer_2': 290, 'n_units_Layer_3': 235}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 11.71% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.92 | sMAPE for Test Set is: 12.45% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:03:58,350]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:03:58,437]\u001b[0m Trial 1438 finished with value: 6.0842133930319955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005466459202050851, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08868214943311219, 'dropout_rate_Layer_2': 0.32152575373721937, 'dropout_rate_Layer_3': 0.2284737984520447, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2052861569914124e-05, 'l1_Layer_2': 7.043031453637049e-05, 'l1_Layer_3': 0.00017423825515315602, 'n_units_Layer_1': 65, 'n_units_Layer_2': 300, 'n_units_Layer_3': 240}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 11.64% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.68 | sMAPE for Test Set is: 11.87% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:04:10,298]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:04:14,288]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:04:20,073]\u001b[0m Trial 1444 finished with value: 6.165100475085737 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005020111607804341, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0677901475961056, 'dropout_rate_Layer_2': 0.3243644364638839, 'dropout_rate_Layer_3': 0.22950174596396541, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0069365002334404e-05, 'l1_Layer_2': 6.659764548692583e-05, 'l1_Layer_3': 0.00016805169768546613, 'n_units_Layer_1': 65, 'n_units_Layer_2': 300, 'n_units_Layer_3': 240}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 11.82% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.96 | sMAPE for Test Set is: 12.70% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:04:23,079]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:04:27,460]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:04:27,780]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:04:37,113]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:04:44,093]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:04:44,860]\u001b[0m Trial 1446 finished with value: 6.110876547522164 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005064823613927492, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09015014982000963, 'dropout_rate_Layer_2': 0.305615917985519, 'dropout_rate_Layer_3': 0.22958324872713337, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2130770064077862e-05, 'l1_Layer_2': 6.80325099505381e-05, 'l1_Layer_3': 0.00017508133810999928, 'n_units_Layer_1': 65, 'n_units_Layer_2': 300, 'n_units_Layer_3': 240}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.11 | sMAPE for Validation Set is: 11.72% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.92 | sMAPE for Test Set is: 12.53% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:04:51,074]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:04:55,415]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:05:00,130]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:05:06,108]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:05:10,934]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:05:14,550]\u001b[0m Trial 1454 finished with value: 6.154736636852641 and parameters: {'n_hidden': 3, 'learning_rate': 0.000550182738877516, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07731172398888592, 'dropout_rate_Layer_2': 0.3441879738648196, 'dropout_rate_Layer_3': 0.24147353353436063, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1745054932562161e-05, 'l1_Layer_2': 6.250126947844777e-05, 'l1_Layer_3': 0.00020460908012841046, 'n_units_Layer_1': 65, 'n_units_Layer_2': 300, 'n_units_Layer_3': 230}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 11.79% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.93 | sMAPE for Test Set is: 12.58% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:05:18,872]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:05:22,850]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:05:27,506]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:05:32,739]\u001b[0m Trial 1459 finished with value: 6.182059449421405 and parameters: {'n_hidden': 3, 'learning_rate': 0.000576521136546078, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0793266254973139, 'dropout_rate_Layer_2': 0.341225009400572, 'dropout_rate_Layer_3': 0.24165268852846097, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1921494505626373e-05, 'l1_Layer_2': 6.398639925806833e-05, 'l1_Layer_3': 0.0001758807791546213, 'n_units_Layer_1': 70, 'n_units_Layer_2': 300, 'n_units_Layer_3': 240}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 11.82% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.22 | sMAPE for Test Set is: 13.40% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:05:39,968]\u001b[0m Trial 1461 finished with value: 6.271254972727828 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008273318624483233, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029583328722536356, 'dropout_rate_Layer_2': 0.18667345472989294, 'dropout_rate_Layer_3': 0.0011426786952506162, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.9596499960696525e-05, 'l1_Layer_2': 0.0014845933448750684, 'l1_Layer_3': 0.0006560595092362682, 'n_units_Layer_1': 200, 'n_units_Layer_2': 140, 'n_units_Layer_3': 110}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 4.93 | sMAPE for Test Set is: 12.58% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:05:40,759]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:05:56,607]\u001b[0m Trial 1466 finished with value: 6.1496135266000325 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005007849588164682, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06589575849867657, 'dropout_rate_Layer_2': 0.3272765796233512, 'dropout_rate_Layer_3': 0.24785781430625733, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0104249478240641e-05, 'l1_Layer_2': 7.497039056610154e-05, 'l1_Layer_3': 0.00017856594103945884, 'n_units_Layer_1': 75, 'n_units_Layer_2': 295, 'n_units_Layer_3': 230}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.22 | sMAPE for Test Set is: 13.53% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:06:01,516]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:06:06,782]\u001b[0m Trial 1465 finished with value: 6.142728036670934 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005777591705640121, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06063471514308875, 'dropout_rate_Layer_2': 0.3265688384873461, 'dropout_rate_Layer_3': 0.24842294732066145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5037370028743654e-05, 'l1_Layer_2': 5.2170960876876266e-05, 'l1_Layer_3': 0.00016824291437150246, 'n_units_Layer_1': 75, 'n_units_Layer_2': 295, 'n_units_Layer_3': 230}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 11.80% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.88 | sMAPE for Test Set is: 12.45% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:06:11,687]\u001b[0m Trial 1468 finished with value: 6.092294055540912 and parameters: {'n_hidden': 3, 'learning_rate': 0.000534403655492195, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06166493435671139, 'dropout_rate_Layer_2': 0.3244807422473982, 'dropout_rate_Layer_3': 0.24864376391813278, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0112332628738878e-05, 'l1_Layer_2': 5.3705017586163884e-05, 'l1_Layer_3': 0.00011176551246480426, 'n_units_Layer_1': 75, 'n_units_Layer_2': 295, 'n_units_Layer_3': 245}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 11.68% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.72 | sMAPE for Test Set is: 11.96% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:06:31,382]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:06:34,992]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:06:35,812]\u001b[0m Trial 1469 finished with value: 6.080955664547685 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005013829483389264, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06064819581722, 'dropout_rate_Layer_2': 0.3613020042594647, 'dropout_rate_Layer_3': 0.24925013367881882, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0122795727216561e-05, 'l1_Layer_2': 5.1758786657320096e-05, 'l1_Layer_3': 0.00010977130697022752, 'n_units_Layer_1': 75, 'n_units_Layer_2': 295, 'n_units_Layer_3': 245}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 11.65% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.88 | sMAPE for Test Set is: 12.55% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:06:41,650]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:06:45,814]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:06:49,190]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:06:51,314]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:06:53,640]\u001b[0m Trial 1471 finished with value: 6.2000810334669145 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011406738080424837, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0256847947736946, 'dropout_rate_Layer_2': 0.18648738278907973, 'dropout_rate_Layer_3': 0.0001271671763768854, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.858094795596991e-05, 'l1_Layer_2': 0.0018144592221862113, 'l1_Layer_3': 0.0006621961754352091, 'n_units_Layer_1': 200, 'n_units_Layer_2': 150, 'n_units_Layer_3': 110}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.79 | sMAPE for Test Set is: 12.02% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:06:57,372]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:07:03,484]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:07:09,692]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:07:13,539]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:07:17,287]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:07:30,558]\u001b[0m Trial 1482 finished with value: 6.160575334124505 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005121704413244339, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06258163726123579, 'dropout_rate_Layer_2': 0.37303343718399823, 'dropout_rate_Layer_3': 0.24859117891585664, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0043286629155244e-05, 'l1_Layer_2': 4.747006172451004e-05, 'l1_Layer_3': 0.00012032316467315279, 'n_units_Layer_1': 75, 'n_units_Layer_2': 300, 'n_units_Layer_3': 240}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 11.80% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.06 | sMAPE for Test Set is: 13.05% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:07:34,404]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:07:37,259]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:07:37,992]\u001b[0m Trial 1474 finished with value: 6.0802206185054954 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005336877795883853, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07158766539772601, 'dropout_rate_Layer_2': 0.3480030909028687, 'dropout_rate_Layer_3': 0.25064503155410217, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3717098002548892e-05, 'l1_Layer_2': 3.44226533929359e-05, 'l1_Layer_3': 0.0001032319933779674, 'n_units_Layer_1': 75, 'n_units_Layer_2': 300, 'n_units_Layer_3': 245}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 11.64% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.82 | sMAPE for Test Set is: 12.33% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:07:42,452]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:07:48,160]\u001b[0m Trial 1483 finished with value: 6.071963177721815 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005034076441411402, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06270964088606029, 'dropout_rate_Layer_2': 0.3685956777567137, 'dropout_rate_Layer_3': 0.2493224975928696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0236304836331751e-05, 'l1_Layer_2': 4.584862791990397e-05, 'l1_Layer_3': 0.00010738353803205847, 'n_units_Layer_1': 75, 'n_units_Layer_2': 295, 'n_units_Layer_3': 245}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 11.63% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 4.89 | sMAPE for Test Set is: 12.58% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:07:48,432]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:07:51,071]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:07:53,715]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:07:56,600]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:08:01,015]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:08:01,086]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:08:08,622]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:08:09,330]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:08:12,395]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 21:08:18,918]\u001b[0m Trial 1496 finished with value: 6.163270140617698 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006132491862162098, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07095146360151568, 'dropout_rate_Layer_2': 0.3565212838614061, 'dropout_rate_Layer_3': 0.25214363063964906, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0037815055672962e-05, 'l1_Layer_2': 4.099695946700393e-05, 'l1_Layer_3': 0.00013889656777369886, 'n_units_Layer_1': 65, 'n_units_Layer_2': 295, 'n_units_Layer_3': 250}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 11.80% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.89 | sMAPE for Test Set is: 12.43% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 21:08:25,934]\u001b[0m Trial 1493 finished with value: 6.188399376966878 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011691451664932438, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03723425825834715, 'dropout_rate_Layer_2': 0.18720067633598553, 'dropout_rate_Layer_3': 0.0090016278606651, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.017442608676289e-05, 'l1_Layer_2': 0.0026662582403569708, 'l1_Layer_3': 0.0007381416514552015, 'n_units_Layer_1': 210, 'n_units_Layer_2': 140, 'n_units_Layer_3': 110}. Best is trial 1069 with value: 5.935980201113824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 4.85 | sMAPE for Test Set is: 12.13% | rMAE for Test Set is: 0.79\n",
      "for 2019-01-01, MAE is:9.09 & sMAPE is:18.24% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :9.09 & 18.24% & 1.16\n",
      "for 2019-01-02, MAE is:7.42 & sMAPE is:13.91% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 16.07% & 1.23\n",
      "for 2019-01-03, MAE is:7.41 & sMAPE is:11.92% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 14.69% & 1.51\n",
      "for 2019-01-04, MAE is:11.83 & sMAPE is:18.85% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.94 & 15.73% & 1.55\n",
      "for 2019-01-05, MAE is:8.23 & sMAPE is:14.55% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :8.80 & 15.49% & 1.47\n",
      "for 2019-01-06, MAE is:3.08 & sMAPE is:6.02% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 13.91% & 1.32\n",
      "for 2019-01-07, MAE is:9.68 & sMAPE is:16.93% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 14.35% & 1.39\n",
      "for 2019-01-08, MAE is:6.80 & sMAPE is:13.43% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 14.23% & 1.33\n",
      "for 2019-01-09, MAE is:7.04 & sMAPE is:13.11% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 14.11% & 1.29\n",
      "for 2019-01-10, MAE is:17.16 & sMAPE is:28.42% & rMAE is:3.10 ||| daily mean of MAE & sMAPE & rMAE till now are :8.77 & 15.54% & 1.48\n",
      "for 2019-01-11, MAE is:6.54 & sMAPE is:11.63% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :8.57 & 15.18% & 1.40\n",
      "for 2019-01-12, MAE is:6.39 & sMAPE is:13.08% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 15.01% & 1.33\n",
      "for 2019-01-13, MAE is:6.22 & sMAPE is:13.47% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 14.89% & 1.28\n",
      "for 2019-01-14, MAE is:8.66 & sMAPE is:16.75% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 15.02% & 1.28\n",
      "for 2019-01-15, MAE is:5.78 & sMAPE is:10.76% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 14.74% & 1.29\n",
      "for 2019-01-16, MAE is:5.46 & sMAPE is:10.70% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 14.49% & 1.29\n",
      "for 2019-01-17, MAE is:10.06 & sMAPE is:19.56% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :8.05 & 14.79% & 1.26\n",
      "for 2019-01-18, MAE is:16.32 & sMAPE is:29.12% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 15.58% & 1.28\n",
      "for 2019-01-19, MAE is:7.16 & sMAPE is:13.23% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 15.46% & 1.25\n",
      "for 2019-01-20, MAE is:6.23 & sMAPE is:11.66% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 15.27% & 1.22\n",
      "for 2019-01-21, MAE is:8.74 & sMAPE is:12.85% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.35 & 15.15% & 1.19\n",
      "for 2019-01-22, MAE is:12.69 & sMAPE is:20.38% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.55 & 15.39% & 1.17\n",
      "for 2019-01-23, MAE is:20.00 & sMAPE is:29.76% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :9.04 & 16.02% & 1.16\n",
      "for 2019-01-24, MAE is:25.76 & sMAPE is:33.45% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :9.74 & 16.74% & 1.15\n",
      "for 2019-01-25, MAE is:10.80 & sMAPE is:17.05% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :9.78 & 16.75% & 1.15\n",
      "for 2019-01-26, MAE is:5.56 & sMAPE is:11.27% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.62 & 16.54% & 1.13\n",
      "for 2019-01-27, MAE is:6.85 & sMAPE is:17.17% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :9.52 & 16.57% & 1.11\n",
      "for 2019-01-28, MAE is:5.90 & sMAPE is:11.77% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 16.40% & 1.08\n",
      "for 2019-01-29, MAE is:7.31 & sMAPE is:12.99% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :9.32 & 16.28% & 1.09\n",
      "for 2019-01-30, MAE is:12.56 & sMAPE is:19.66% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 16.39% & 1.09\n",
      "for 2019-01-31, MAE is:7.39 & sMAPE is:12.71% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 16.27% & 1.07\n",
      "for 2019-02-01, MAE is:14.46 & sMAPE is:25.25% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :9.52 & 16.55% & 1.08\n",
      "for 2019-02-02, MAE is:3.94 & sMAPE is:8.28% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 16.30% & 1.09\n",
      "for 2019-02-03, MAE is:5.53 & sMAPE is:12.41% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :9.24 & 16.19% & 1.09\n",
      "for 2019-02-04, MAE is:7.24 & sMAPE is:16.11% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :9.18 & 16.18% & 1.09\n",
      "for 2019-02-05, MAE is:9.55 & sMAPE is:18.71% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :9.19 & 16.25% & 1.11\n",
      "for 2019-02-06, MAE is:6.15 & sMAPE is:13.52% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :9.11 & 16.18% & 1.09\n",
      "for 2019-02-07, MAE is:5.64 & sMAPE is:12.59% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.02 & 16.09% & 1.07\n",
      "for 2019-02-08, MAE is:4.94 & sMAPE is:10.68% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :8.91 & 15.95% & 1.05\n",
      "for 2019-02-09, MAE is:4.02 & sMAPE is:9.49% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.79 & 15.79% & 1.04\n",
      "for 2019-02-10, MAE is:5.72 & sMAPE is:13.39% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.72 & 15.73% & 1.06\n",
      "for 2019-02-11, MAE is:11.12 & sMAPE is:19.46% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :8.77 & 15.82% & 1.05\n",
      "for 2019-02-12, MAE is:5.70 & sMAPE is:11.14% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :8.70 & 15.71% & 1.05\n",
      "for 2019-02-13, MAE is:4.31 & sMAPE is:8.65% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :8.60 & 15.55% & 1.05\n",
      "for 2019-02-14, MAE is:7.66 & sMAPE is:16.32% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 15.56% & 1.05\n",
      "for 2019-02-15, MAE is:6.24 & sMAPE is:13.46% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :8.53 & 15.52% & 1.06\n",
      "for 2019-02-16, MAE is:5.96 & sMAPE is:13.10% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 15.47% & 1.06\n",
      "for 2019-02-17, MAE is:3.33 & sMAPE is:8.77% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 15.33% & 1.04\n",
      "for 2019-02-18, MAE is:5.27 & sMAPE is:11.66% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.30 & 15.25% & 1.03\n",
      "for 2019-02-19, MAE is:5.08 & sMAPE is:12.21% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 15.19% & 1.03\n",
      "for 2019-02-20, MAE is:5.44 & sMAPE is:12.75% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.18 & 15.14% & 1.04\n",
      "for 2019-02-21, MAE is:4.32 & sMAPE is:10.01% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 15.05% & 1.04\n",
      "for 2019-02-22, MAE is:6.98 & sMAPE is:15.88% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 15.06% & 1.06\n",
      "for 2019-02-23, MAE is:4.11 & sMAPE is:10.19% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 14.97% & 1.06\n",
      "for 2019-02-24, MAE is:5.18 & sMAPE is:13.49% & rMAE is:3.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 14.94% & 1.10\n",
      "for 2019-02-25, MAE is:5.40 & sMAPE is:11.79% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 14.89% & 1.12\n",
      "for 2019-02-26, MAE is:5.46 & sMAPE is:12.36% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.87 & 14.84% & 1.12\n",
      "for 2019-02-27, MAE is:5.79 & sMAPE is:13.34% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 14.82% & 1.13\n",
      "for 2019-02-28, MAE is:8.51 & sMAPE is:21.25% & rMAE is:3.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 14.93% & 1.18\n",
      "for 2019-03-01, MAE is:6.95 & sMAPE is:16.34% & rMAE is:2.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 14.95% & 1.20\n",
      "for 2019-03-02, MAE is:8.36 & sMAPE is:21.71% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 15.06% & 1.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-03-03, MAE is:10.47 & sMAPE is:28.95% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.89 & 15.29% & 1.22\n",
      "for 2019-03-04, MAE is:6.52 & sMAPE is:16.82% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 15.31% & 1.22\n",
      "for 2019-03-05, MAE is:5.23 & sMAPE is:11.86% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 15.26% & 1.23\n",
      "for 2019-03-06, MAE is:5.56 & sMAPE is:12.87% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 15.22% & 1.22\n",
      "for 2019-03-07, MAE is:3.83 & sMAPE is:9.73% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 15.14% & 1.22\n",
      "for 2019-03-08, MAE is:7.19 & sMAPE is:17.61% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 15.17% & 1.22\n",
      "for 2019-03-09, MAE is:8.97 & sMAPE is:23.70% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 15.30% & 1.22\n",
      "for 2019-03-10, MAE is:8.91 & sMAPE is:20.27% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.76 & 15.37% & 1.21\n",
      "for 2019-03-11, MAE is:4.17 & sMAPE is:9.72% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 15.29% & 1.21\n",
      "for 2019-03-12, MAE is:4.82 & sMAPE is:10.82% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 15.23% & 1.21\n",
      "for 2019-03-13, MAE is:4.08 & sMAPE is:9.97% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 15.15% & 1.20\n",
      "for 2019-03-14, MAE is:4.20 & sMAPE is:10.84% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 15.09% & 1.21\n",
      "for 2019-03-15, MAE is:3.84 & sMAPE is:9.77% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 15.02% & 1.20\n",
      "for 2019-03-16, MAE is:5.10 & sMAPE is:14.52% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 15.02% & 1.19\n",
      "for 2019-03-17, MAE is:6.94 & sMAPE is:26.71% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 15.17% & 1.19\n",
      "for 2019-03-18, MAE is:6.59 & sMAPE is:17.20% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 15.20% & 1.20\n",
      "for 2019-03-19, MAE is:4.74 & sMAPE is:10.51% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 15.14% & 1.20\n",
      "for 2019-03-20, MAE is:4.03 & sMAPE is:9.48% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 15.06% & 1.20\n",
      "for 2019-03-21, MAE is:4.76 & sMAPE is:12.11% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 15.03% & 1.20\n",
      "for 2019-03-22, MAE is:5.82 & sMAPE is:15.00% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 15.03% & 1.20\n",
      "for 2019-03-23, MAE is:3.18 & sMAPE is:9.08% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 14.95% & 1.20\n",
      "for 2019-03-24, MAE is:4.10 & sMAPE is:12.65% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 14.93% & 1.19\n",
      "for 2019-03-25, MAE is:3.48 & sMAPE is:10.61% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 14.88% & 1.18\n",
      "for 2019-03-26, MAE is:4.66 & sMAPE is:13.26% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 14.86% & 1.18\n",
      "for 2019-03-27, MAE is:5.96 & sMAPE is:16.57% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 14.88% & 1.19\n",
      "for 2019-03-28, MAE is:7.13 & sMAPE is:18.73% & rMAE is:2.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 14.92% & 1.21\n",
      "for 2019-03-29, MAE is:7.61 & sMAPE is:20.60% & rMAE is:4.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 14.98% & 1.25\n",
      "for 2019-03-30, MAE is:6.50 & sMAPE is:19.29% & rMAE is:3.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 15.03% & 1.26\n",
      "for 2019-03-31, MAE is:6.69 & sMAPE is:22.60% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 15.12% & 1.27\n",
      "for 2019-04-01, MAE is:5.64 & sMAPE is:14.84% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 15.11% & 1.27\n",
      "for 2019-04-02, MAE is:6.06 & sMAPE is:16.56% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 15.13% & 1.27\n",
      "for 2019-04-03, MAE is:9.87 & sMAPE is:26.18% & rMAE is:2.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 15.25% & 1.29\n",
      "for 2019-04-04, MAE is:7.28 & sMAPE is:18.27% & rMAE is:2.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 15.28% & 1.30\n",
      "for 2019-04-05, MAE is:12.01 & sMAPE is:33.09% & rMAE is:3.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 15.47% & 1.32\n",
      "for 2019-04-06, MAE is:7.72 & sMAPE is:20.16% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 15.52% & 1.32\n",
      "for 2019-04-07, MAE is:4.80 & sMAPE is:13.28% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 15.49% & 1.32\n",
      "for 2019-04-08, MAE is:6.93 & sMAPE is:16.38% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 15.50% & 1.31\n",
      "for 2019-04-09, MAE is:6.11 & sMAPE is:15.97% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 15.51% & 1.32\n",
      "for 2019-04-10, MAE is:7.44 & sMAPE is:19.56% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 15.55% & 1.32\n",
      "for 2019-04-11, MAE is:7.68 & sMAPE is:18.99% & rMAE is:2.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 15.58% & 1.33\n",
      "for 2019-04-12, MAE is:7.64 & sMAPE is:18.54% & rMAE is:2.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 15.61% & 1.34\n",
      "for 2019-04-13, MAE is:5.34 & sMAPE is:14.01% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 15.60% & 1.35\n",
      "for 2019-04-14, MAE is:3.62 & sMAPE is:9.62% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 15.54% & 1.35\n",
      "for 2019-04-15, MAE is:6.04 & sMAPE is:13.72% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 15.52% & 1.36\n",
      "for 2019-04-16, MAE is:4.56 & sMAPE is:11.22% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 15.48% & 1.36\n",
      "for 2019-04-17, MAE is:4.69 & sMAPE is:11.61% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 15.44% & 1.36\n",
      "for 2019-04-18, MAE is:5.84 & sMAPE is:14.80% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 15.44% & 1.37\n",
      "for 2019-04-19, MAE is:8.54 & sMAPE is:23.27% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 15.51% & 1.37\n",
      "for 2019-04-20, MAE is:6.54 & sMAPE is:18.91% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 15.54% & 1.37\n",
      "for 2019-04-21, MAE is:7.28 & sMAPE is:26.85% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 15.64% & 1.37\n",
      "for 2019-04-22, MAE is:7.78 & sMAPE is:24.40% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 15.72% & 1.36\n",
      "for 2019-04-23, MAE is:4.91 & sMAPE is:12.59% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 15.69% & 1.36\n",
      "for 2019-04-24, MAE is:4.98 & sMAPE is:13.05% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 15.67% & 1.36\n",
      "for 2019-04-25, MAE is:4.75 & sMAPE is:11.35% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 15.63% & 1.36\n",
      "for 2019-04-26, MAE is:6.43 & sMAPE is:15.60% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 15.63% & 1.36\n",
      "for 2019-04-27, MAE is:5.70 & sMAPE is:18.19% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 15.65% & 1.36\n",
      "for 2019-04-28, MAE is:13.49 & sMAPE is:43.04% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 15.89% & 1.36\n",
      "for 2019-04-29, MAE is:5.91 & sMAPE is:14.19% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 15.87% & 1.35\n",
      "for 2019-04-30, MAE is:4.12 & sMAPE is:9.79% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 15.82% & 1.35\n",
      "for 2019-05-01, MAE is:4.99 & sMAPE is:12.26% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 15.79% & 1.34\n",
      "for 2019-05-02, MAE is:4.52 & sMAPE is:11.90% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 15.76% & 1.34\n",
      "for 2019-05-03, MAE is:5.18 & sMAPE is:13.70% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 15.74% & 1.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-05-04, MAE is:7.75 & sMAPE is:21.73% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 15.79% & 1.35\n",
      "for 2019-05-05, MAE is:4.68 & sMAPE is:12.09% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 15.76% & 1.34\n",
      "for 2019-05-06, MAE is:5.44 & sMAPE is:12.78% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 15.74% & 1.34\n",
      "for 2019-05-07, MAE is:9.42 & sMAPE is:19.92% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 15.77% & 1.34\n",
      "for 2019-05-08, MAE is:3.77 & sMAPE is:9.51% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 15.72% & 1.34\n",
      "for 2019-05-09, MAE is:15.17 & sMAPE is:39.33% & rMAE is:2.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 15.91% & 1.35\n",
      "for 2019-05-10, MAE is:6.99 & sMAPE is:16.62% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 15.91% & 1.35\n",
      "for 2019-05-11, MAE is:2.85 & sMAPE is:6.92% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 15.84% & 1.34\n",
      "for 2019-05-12, MAE is:4.36 & sMAPE is:10.68% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 15.80% & 1.34\n",
      "for 2019-05-13, MAE is:5.34 & sMAPE is:13.21% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 15.78% & 1.34\n",
      "for 2019-05-14, MAE is:4.72 & sMAPE is:11.36% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 15.75% & 1.33\n",
      "for 2019-05-15, MAE is:4.12 & sMAPE is:10.57% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 15.71% & 1.33\n",
      "for 2019-05-16, MAE is:5.85 & sMAPE is:16.08% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 15.72% & 1.33\n",
      "for 2019-05-17, MAE is:7.59 & sMAPE is:19.60% & rMAE is:2.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 15.74% & 1.34\n",
      "for 2019-05-18, MAE is:3.39 & sMAPE is:9.66% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 15.70% & 1.33\n",
      "for 2019-05-19, MAE is:3.64 & sMAPE is:11.06% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 15.67% & 1.33\n",
      "for 2019-05-20, MAE is:9.83 & sMAPE is:22.94% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 15.72% & 1.33\n",
      "for 2019-05-21, MAE is:7.03 & sMAPE is:17.27% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 15.73% & 1.33\n",
      "for 2019-05-22, MAE is:4.14 & sMAPE is:10.73% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 15.69% & 1.33\n",
      "for 2019-05-23, MAE is:5.58 & sMAPE is:14.10% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 15.68% & 1.33\n",
      "for 2019-05-24, MAE is:3.75 & sMAPE is:9.86% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 15.64% & 1.32\n",
      "for 2019-05-25, MAE is:4.06 & sMAPE is:12.56% & rMAE is:3.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 15.62% & 1.34\n",
      "for 2019-05-26, MAE is:7.55 & sMAPE is:32.46% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 15.74% & 1.33\n",
      "for 2019-05-27, MAE is:4.99 & sMAPE is:14.12% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 15.73% & 1.33\n",
      "for 2019-05-28, MAE is:4.90 & sMAPE is:11.86% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 15.70% & 1.33\n",
      "for 2019-05-29, MAE is:7.91 & sMAPE is:21.14% & rMAE is:3.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 15.74% & 1.35\n",
      "for 2019-05-30, MAE is:3.93 & sMAPE is:13.02% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 15.72% & 1.34\n",
      "for 2019-05-31, MAE is:6.76 & sMAPE is:20.94% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 15.75% & 1.34\n",
      "for 2019-06-01, MAE is:2.65 & sMAPE is:8.01% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 15.70% & 1.34\n",
      "for 2019-06-02, MAE is:8.66 & sMAPE is:49.06% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 15.92% & 1.34\n",
      "for 2019-06-03, MAE is:9.13 & sMAPE is:27.09% & rMAE is:3.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 15.99% & 1.35\n",
      "for 2019-06-04, MAE is:4.36 & sMAPE is:11.76% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 15.96% & 1.35\n",
      "for 2019-06-05, MAE is:5.95 & sMAPE is:16.28% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 15.97% & 1.35\n",
      "for 2019-06-06, MAE is:7.48 & sMAPE is:20.84% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 16.00% & 1.35\n",
      "for 2019-06-07, MAE is:5.36 & sMAPE is:15.28% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 15.99% & 1.35\n",
      "for 2019-06-08, MAE is:4.32 & sMAPE is:15.62% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 15.99% & 1.34\n",
      "for 2019-06-09, MAE is:10.58 & sMAPE is:35.81% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 16.11% & 1.34\n",
      "for 2019-06-10, MAE is:3.12 & sMAPE is:9.23% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 16.07% & 1.33\n",
      "for 2019-06-11, MAE is:11.71 & sMAPE is:28.60% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 16.15% & 1.33\n",
      "for 2019-06-12, MAE is:6.41 & sMAPE is:15.23% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 16.14% & 1.33\n",
      "for 2019-06-13, MAE is:7.53 & sMAPE is:18.46% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 16.16% & 1.34\n",
      "for 2019-06-14, MAE is:6.76 & sMAPE is:15.92% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 16.16% & 1.33\n",
      "for 2019-06-15, MAE is:4.31 & sMAPE is:12.26% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 16.13% & 1.33\n",
      "for 2019-06-16, MAE is:5.87 & sMAPE is:19.25% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 16.15% & 1.33\n",
      "for 2019-06-17, MAE is:8.29 & sMAPE is:19.48% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 16.17% & 1.32\n",
      "for 2019-06-18, MAE is:5.97 & sMAPE is:13.13% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 16.15% & 1.32\n",
      "for 2019-06-19, MAE is:6.26 & sMAPE is:16.44% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 16.15% & 1.32\n",
      "for 2019-06-20, MAE is:4.98 & sMAPE is:13.93% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 16.14% & 1.32\n",
      "for 2019-06-21, MAE is:4.91 & sMAPE is:13.65% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 16.13% & 1.32\n",
      "for 2019-06-22, MAE is:3.69 & sMAPE is:11.96% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 16.10% & 1.32\n",
      "for 2019-06-23, MAE is:7.22 & sMAPE is:26.16% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 16.16% & 1.32\n",
      "for 2019-06-24, MAE is:5.81 & sMAPE is:15.86% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 16.16% & 1.31\n",
      "for 2019-06-25, MAE is:9.72 & sMAPE is:20.63% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 16.18% & 1.32\n",
      "for 2019-06-26, MAE is:7.13 & sMAPE is:17.79% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 16.19% & 1.32\n",
      "for 2019-06-27, MAE is:4.18 & sMAPE is:12.01% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 16.17% & 1.32\n",
      "for 2019-06-28, MAE is:7.48 & sMAPE is:17.32% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 16.18% & 1.32\n",
      "for 2019-06-29, MAE is:3.47 & sMAPE is:9.97% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 16.14% & 1.32\n",
      "for 2019-06-30, MAE is:6.43 & sMAPE is:26.38% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 16.20% & 1.31\n",
      "for 2019-07-01, MAE is:3.80 & sMAPE is:11.05% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 16.17% & 1.31\n",
      "for 2019-07-02, MAE is:4.16 & sMAPE is:12.03% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 16.15% & 1.31\n",
      "for 2019-07-03, MAE is:4.31 & sMAPE is:11.76% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 16.12% & 1.30\n",
      "for 2019-07-04, MAE is:4.12 & sMAPE is:11.75% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 16.10% & 1.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-07-05, MAE is:3.14 & sMAPE is:9.05% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 16.06% & 1.30\n",
      "for 2019-07-06, MAE is:3.73 & sMAPE is:12.40% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 16.04% & 1.30\n",
      "for 2019-07-07, MAE is:2.96 & sMAPE is:9.55% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 16.01% & 1.29\n",
      "for 2019-07-08, MAE is:3.29 & sMAPE is:9.67% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 15.97% & 1.29\n",
      "for 2019-07-09, MAE is:4.15 & sMAPE is:11.76% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 15.95% & 1.29\n",
      "for 2019-07-10, MAE is:6.93 & sMAPE is:18.24% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 15.96% & 1.29\n",
      "for 2019-07-11, MAE is:12.03 & sMAPE is:29.95% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 16.04% & 1.29\n",
      "for 2019-07-12, MAE is:9.70 & sMAPE is:24.09% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 16.08% & 1.29\n",
      "for 2019-07-13, MAE is:4.62 & sMAPE is:13.29% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 16.06% & 1.28\n",
      "for 2019-07-14, MAE is:5.80 & sMAPE is:17.75% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 16.07% & 1.28\n",
      "for 2019-07-15, MAE is:3.92 & sMAPE is:9.84% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 16.04% & 1.28\n",
      "for 2019-07-16, MAE is:5.24 & sMAPE is:13.19% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 16.03% & 1.28\n",
      "for 2019-07-17, MAE is:7.75 & sMAPE is:18.64% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 16.04% & 1.28\n",
      "for 2019-07-18, MAE is:5.97 & sMAPE is:15.01% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 16.04% & 1.28\n",
      "for 2019-07-19, MAE is:5.26 & sMAPE is:12.59% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 16.02% & 1.28\n",
      "for 2019-07-20, MAE is:3.83 & sMAPE is:10.61% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 15.99% & 1.28\n",
      "for 2019-07-21, MAE is:2.99 & sMAPE is:9.60% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 15.96% & 1.28\n",
      "for 2019-07-22, MAE is:3.52 & sMAPE is:8.46% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 15.92% & 1.28\n",
      "for 2019-07-23, MAE is:5.76 & sMAPE is:12.99% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 15.91% & 1.28\n",
      "for 2019-07-24, MAE is:10.62 & sMAPE is:23.23% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 15.94% & 1.28\n",
      "for 2019-07-25, MAE is:4.95 & sMAPE is:10.06% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 15.92% & 1.28\n",
      "for 2019-07-26, MAE is:2.96 & sMAPE is:6.67% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 15.87% & 1.28\n",
      "for 2019-07-27, MAE is:4.35 & sMAPE is:11.04% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 15.85% & 1.29\n",
      "for 2019-07-28, MAE is:3.34 & sMAPE is:10.67% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 15.82% & 1.28\n",
      "for 2019-07-29, MAE is:7.52 & sMAPE is:18.62% & rMAE is:2.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 15.84% & 1.29\n",
      "for 2019-07-30, MAE is:2.99 & sMAPE is:6.91% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 15.79% & 1.29\n",
      "for 2019-07-31, MAE is:4.01 & sMAPE is:9.61% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 15.76% & 1.28\n",
      "for 2019-08-01, MAE is:6.47 & sMAPE is:15.00% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 15.76% & 1.28\n",
      "for 2019-08-02, MAE is:2.39 & sMAPE is:5.87% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 15.71% & 1.28\n",
      "for 2019-08-03, MAE is:3.51 & sMAPE is:9.03% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 15.68% & 1.28\n",
      "for 2019-08-04, MAE is:3.33 & sMAPE is:9.97% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 15.66% & 1.28\n",
      "for 2019-08-05, MAE is:3.81 & sMAPE is:9.21% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 15.63% & 1.28\n",
      "for 2019-08-06, MAE is:5.43 & sMAPE is:14.45% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 15.62% & 1.28\n",
      "for 2019-08-07, MAE is:5.89 & sMAPE is:17.19% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 15.63% & 1.28\n",
      "for 2019-08-08, MAE is:3.51 & sMAPE is:10.21% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 15.60% & 1.28\n",
      "for 2019-08-09, MAE is:5.39 & sMAPE is:14.42% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 15.60% & 1.27\n",
      "for 2019-08-10, MAE is:4.55 & sMAPE is:17.05% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 15.61% & 1.27\n",
      "for 2019-08-11, MAE is:7.78 & sMAPE is:31.16% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 15.68% & 1.27\n",
      "for 2019-08-12, MAE is:5.15 & sMAPE is:11.65% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 15.66% & 1.27\n",
      "for 2019-08-13, MAE is:4.78 & sMAPE is:13.22% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 15.65% & 1.27\n",
      "for 2019-08-14, MAE is:4.55 & sMAPE is:11.57% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 15.63% & 1.26\n",
      "for 2019-08-15, MAE is:2.75 & sMAPE is:8.64% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 15.60% & 1.26\n",
      "for 2019-08-16, MAE is:4.80 & sMAPE is:13.56% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 15.59% & 1.26\n",
      "for 2019-08-17, MAE is:4.61 & sMAPE is:19.16% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 15.60% & 1.26\n",
      "for 2019-08-18, MAE is:7.53 & sMAPE is:27.46% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 15.66% & 1.26\n",
      "for 2019-08-19, MAE is:4.69 & sMAPE is:14.89% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 15.65% & 1.25\n",
      "for 2019-08-20, MAE is:3.44 & sMAPE is:8.94% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 15.62% & 1.25\n",
      "for 2019-08-21, MAE is:5.92 & sMAPE is:13.85% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 15.62% & 1.25\n",
      "for 2019-08-22, MAE is:3.98 & sMAPE is:10.78% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 15.60% & 1.25\n",
      "for 2019-08-23, MAE is:4.23 & sMAPE is:11.00% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 15.58% & 1.25\n",
      "for 2019-08-24, MAE is:4.57 & sMAPE is:15.39% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 15.57% & 1.25\n",
      "for 2019-08-25, MAE is:3.13 & sMAPE is:9.93% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 15.55% & 1.25\n",
      "for 2019-08-26, MAE is:8.83 & sMAPE is:20.12% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 15.57% & 1.25\n",
      "for 2019-08-27, MAE is:5.61 & sMAPE is:12.75% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 15.56% & 1.25\n",
      "for 2019-08-28, MAE is:11.01 & sMAPE is:23.02% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 15.59% & 1.25\n",
      "for 2019-08-29, MAE is:3.36 & sMAPE is:7.35% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 15.56% & 1.24\n",
      "for 2019-08-30, MAE is:4.52 & sMAPE is:11.06% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 15.54% & 1.24\n",
      "for 2019-08-31, MAE is:3.17 & sMAPE is:9.24% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 15.51% & 1.24\n",
      "for 2019-09-01, MAE is:3.98 & sMAPE is:14.54% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 15.51% & 1.24\n",
      "for 2019-09-02, MAE is:7.13 & sMAPE is:19.27% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 15.52% & 1.24\n",
      "for 2019-09-03, MAE is:5.50 & sMAPE is:16.09% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 15.52% & 1.24\n",
      "for 2019-09-04, MAE is:4.20 & sMAPE is:13.58% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 15.52% & 1.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-09-05, MAE is:4.22 & sMAPE is:14.32% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 15.51% & 1.23\n",
      "for 2019-09-06, MAE is:3.64 & sMAPE is:11.81% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 15.50% & 1.23\n",
      "for 2019-09-07, MAE is:5.07 & sMAPE is:14.90% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 15.49% & 1.23\n",
      "for 2019-09-08, MAE is:8.77 & sMAPE is:26.66% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 15.54% & 1.23\n",
      "for 2019-09-09, MAE is:8.18 & sMAPE is:18.83% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 15.55% & 1.23\n",
      "for 2019-09-10, MAE is:4.09 & sMAPE is:10.67% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 15.53% & 1.23\n",
      "for 2019-09-11, MAE is:3.31 & sMAPE is:10.61% & rMAE is:2.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 15.51% & 1.23\n",
      "for 2019-09-12, MAE is:4.96 & sMAPE is:13.52% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 15.51% & 1.23\n",
      "for 2019-09-13, MAE is:8.99 & sMAPE is:25.47% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 15.54% & 1.23\n",
      "for 2019-09-14, MAE is:4.34 & sMAPE is:12.23% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 15.53% & 1.23\n",
      "for 2019-09-15, MAE is:4.64 & sMAPE is:15.83% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 15.53% & 1.23\n",
      "for 2019-09-16, MAE is:9.73 & sMAPE is:22.43% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 15.56% & 1.23\n",
      "for 2019-09-17, MAE is:7.85 & sMAPE is:21.59% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 15.58% & 1.24\n",
      "for 2019-09-18, MAE is:7.39 & sMAPE is:20.62% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 15.60% & 1.24\n",
      "for 2019-09-19, MAE is:10.41 & sMAPE is:25.64% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 15.64% & 1.24\n",
      "for 2019-09-20, MAE is:6.62 & sMAPE is:16.38% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 15.64% & 1.24\n",
      "for 2019-09-21, MAE is:3.33 & sMAPE is:10.00% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 15.62% & 1.24\n",
      "for 2019-09-22, MAE is:3.08 & sMAPE is:10.62% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 15.60% & 1.24\n",
      "for 2019-09-23, MAE is:6.51 & sMAPE is:15.86% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 15.60% & 1.24\n",
      "for 2019-09-24, MAE is:9.76 & sMAPE is:24.10% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 15.64% & 1.23\n",
      "for 2019-09-25, MAE is:9.13 & sMAPE is:23.73% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 15.67% & 1.24\n",
      "for 2019-09-26, MAE is:6.14 & sMAPE is:16.44% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 15.67% & 1.23\n",
      "for 2019-09-27, MAE is:7.60 & sMAPE is:21.88% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 15.69% & 1.24\n",
      "for 2019-09-28, MAE is:3.67 & sMAPE is:12.39% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 15.68% & 1.23\n",
      "for 2019-09-29, MAE is:4.49 & sMAPE is:17.56% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 15.69% & 1.23\n",
      "for 2019-09-30, MAE is:8.57 & sMAPE is:23.03% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 15.71% & 1.23\n",
      "for 2019-10-01, MAE is:8.69 & sMAPE is:22.90% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 15.74% & 1.24\n",
      "for 2019-10-02, MAE is:5.00 & sMAPE is:13.14% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 15.73% & 1.24\n",
      "for 2019-10-03, MAE is:9.71 & sMAPE is:25.47% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 15.77% & 1.24\n",
      "for 2019-10-04, MAE is:10.10 & sMAPE is:26.10% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 15.80% & 1.24\n",
      "for 2019-10-05, MAE is:6.72 & sMAPE is:19.31% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 15.82% & 1.24\n",
      "for 2019-10-06, MAE is:4.16 & sMAPE is:13.41% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 15.81% & 1.24\n",
      "for 2019-10-07, MAE is:12.64 & sMAPE is:30.85% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 15.86% & 1.24\n",
      "for 2019-10-08, MAE is:3.76 & sMAPE is:10.90% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 15.84% & 1.24\n",
      "for 2019-10-09, MAE is:4.87 & sMAPE is:14.11% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 15.84% & 1.24\n",
      "for 2019-10-10, MAE is:4.99 & sMAPE is:15.03% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 15.83% & 1.23\n",
      "for 2019-10-11, MAE is:4.16 & sMAPE is:15.59% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 15.83% & 1.23\n",
      "for 2019-10-12, MAE is:11.87 & sMAPE is:43.65% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 15.93% & 1.23\n",
      "for 2019-10-13, MAE is:3.25 & sMAPE is:12.13% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 15.92% & 1.23\n",
      "for 2019-10-14, MAE is:10.92 & sMAPE is:30.12% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 15.97% & 1.23\n",
      "for 2019-10-15, MAE is:13.65 & sMAPE is:35.08% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 16.03% & 1.24\n",
      "for 2019-10-16, MAE is:9.83 & sMAPE is:29.84% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 16.08% & 1.24\n",
      "for 2019-10-17, MAE is:6.14 & sMAPE is:14.32% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 16.07% & 1.24\n",
      "for 2019-10-18, MAE is:4.96 & sMAPE is:14.92% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 16.07% & 1.23\n",
      "for 2019-10-19, MAE is:10.20 & sMAPE is:35.59% & rMAE is:3.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 16.14% & 1.24\n",
      "for 2019-10-20, MAE is:4.42 & sMAPE is:12.56% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 16.13% & 1.24\n",
      "for 2019-10-21, MAE is:9.68 & sMAPE is:23.26% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 16.15% & 1.24\n",
      "for 2019-10-22, MAE is:10.53 & sMAPE is:25.55% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 16.18% & 1.25\n",
      "for 2019-10-23, MAE is:4.61 & sMAPE is:10.47% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 16.16% & 1.25\n",
      "for 2019-10-24, MAE is:6.10 & sMAPE is:16.13% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 16.16% & 1.24\n",
      "for 2019-10-25, MAE is:7.07 & sMAPE is:20.19% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 16.18% & 1.25\n",
      "for 2019-10-26, MAE is:2.62 & sMAPE is:9.31% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 16.15% & 1.24\n",
      "for 2019-10-27, MAE is:3.46 & sMAPE is:11.74% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 16.14% & 1.24\n",
      "for 2019-10-28, MAE is:10.83 & sMAPE is:27.76% & rMAE is:2.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 16.18% & 1.25\n",
      "for 2019-10-29, MAE is:6.99 & sMAPE is:16.05% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 16.18% & 1.25\n",
      "for 2019-10-30, MAE is:8.44 & sMAPE is:20.15% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 16.19% & 1.25\n",
      "for 2019-10-31, MAE is:5.25 & sMAPE is:13.64% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 16.18% & 1.25\n",
      "for 2019-11-01, MAE is:7.23 & sMAPE is:19.49% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 16.19% & 1.25\n",
      "for 2019-11-02, MAE is:4.23 & sMAPE is:14.05% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 16.18% & 1.25\n",
      "for 2019-11-03, MAE is:6.68 & sMAPE is:22.71% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 16.21% & 1.25\n",
      "for 2019-11-04, MAE is:6.07 & sMAPE is:16.83% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 16.21% & 1.25\n",
      "for 2019-11-05, MAE is:6.97 & sMAPE is:16.67% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 16.21% & 1.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-11-06, MAE is:18.14 & sMAPE is:41.49% & rMAE is:2.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 16.29% & 1.25\n",
      "for 2019-11-07, MAE is:5.26 & sMAPE is:13.36% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 16.28% & 1.25\n",
      "for 2019-11-08, MAE is:11.23 & sMAPE is:26.11% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 16.31% & 1.25\n",
      "for 2019-11-09, MAE is:6.67 & sMAPE is:17.54% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 16.32% & 1.25\n",
      "for 2019-11-10, MAE is:3.86 & sMAPE is:9.45% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 16.30% & 1.25\n",
      "for 2019-11-11, MAE is:4.98 & sMAPE is:12.29% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 16.28% & 1.25\n",
      "for 2019-11-12, MAE is:5.76 & sMAPE is:15.07% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 16.28% & 1.25\n",
      "for 2019-11-13, MAE is:7.98 & sMAPE is:17.46% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 16.28% & 1.25\n",
      "for 2019-11-14, MAE is:8.33 & sMAPE is:20.33% & rMAE is:2.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 16.30% & 1.25\n",
      "for 2019-11-15, MAE is:3.76 & sMAPE is:8.88% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 16.27% & 1.25\n",
      "for 2019-11-16, MAE is:4.61 & sMAPE is:12.40% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 16.26% & 1.25\n",
      "for 2019-11-17, MAE is:5.37 & sMAPE is:15.64% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 16.26% & 1.25\n",
      "for 2019-11-18, MAE is:7.38 & sMAPE is:18.27% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 16.26% & 1.25\n",
      "for 2019-11-19, MAE is:11.93 & sMAPE is:25.79% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 16.29% & 1.25\n",
      "for 2019-11-20, MAE is:12.03 & sMAPE is:25.85% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 16.32% & 1.26\n",
      "for 2019-11-21, MAE is:6.33 & sMAPE is:13.20% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 16.31% & 1.26\n",
      "for 2019-11-22, MAE is:6.77 & sMAPE is:17.18% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 16.32% & 1.26\n",
      "for 2019-11-23, MAE is:10.18 & sMAPE is:25.52% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 16.34% & 1.26\n",
      "for 2019-11-24, MAE is:6.19 & sMAPE is:15.61% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 16.34% & 1.26\n",
      "for 2019-11-25, MAE is:9.77 & sMAPE is:20.59% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 16.36% & 1.26\n",
      "for 2019-11-26, MAE is:4.76 & sMAPE is:10.63% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 16.34% & 1.26\n",
      "for 2019-11-27, MAE is:4.30 & sMAPE is:10.72% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 16.32% & 1.25\n",
      "for 2019-11-28, MAE is:7.14 & sMAPE is:16.51% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 16.32% & 1.25\n",
      "for 2019-11-29, MAE is:8.15 & sMAPE is:18.99% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 16.33% & 1.26\n",
      "for 2019-11-30, MAE is:2.74 & sMAPE is:6.56% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 16.30% & 1.25\n",
      "for 2019-12-01, MAE is:4.37 & sMAPE is:10.72% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 16.28% & 1.25\n",
      "for 2019-12-02, MAE is:5.93 & sMAPE is:12.47% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 16.27% & 1.25\n",
      "for 2019-12-03, MAE is:8.93 & sMAPE is:17.26% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 16.27% & 1.25\n",
      "for 2019-12-04, MAE is:8.89 & sMAPE is:17.75% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 16.28% & 1.25\n",
      "for 2019-12-05, MAE is:4.77 & sMAPE is:11.21% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 16.26% & 1.25\n",
      "for 2019-12-06, MAE is:6.64 & sMAPE is:19.10% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 16.27% & 1.25\n",
      "for 2019-12-07, MAE is:8.44 & sMAPE is:25.38% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 16.30% & 1.25\n",
      "for 2019-12-08, MAE is:9.90 & sMAPE is:55.92% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 16.42% & 1.25\n",
      "for 2019-12-09, MAE is:8.37 & sMAPE is:41.79% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 16.49% & 1.25\n",
      "for 2019-12-10, MAE is:11.38 & sMAPE is:31.80% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.53% & 1.25\n",
      "for 2019-12-11, MAE is:15.38 & sMAPE is:41.82% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.61% & 1.25\n",
      "for 2019-12-12, MAE is:10.04 & sMAPE is:25.27% & rMAE is:2.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 16.63% & 1.25\n",
      "for 2019-12-13, MAE is:4.08 & sMAPE is:11.80% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.62% & 1.25\n",
      "for 2019-12-14, MAE is:5.07 & sMAPE is:16.21% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.62% & 1.25\n",
      "for 2019-12-15, MAE is:11.63 & sMAPE is:41.45% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 16.69% & 1.25\n",
      "for 2019-12-16, MAE is:7.06 & sMAPE is:19.01% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 16.69% & 1.25\n",
      "for 2019-12-17, MAE is:4.38 & sMAPE is:11.25% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 16.68% & 1.25\n",
      "for 2019-12-18, MAE is:9.13 & sMAPE is:23.76% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 16.70% & 1.25\n",
      "for 2019-12-19, MAE is:3.79 & sMAPE is:12.03% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 16.69% & 1.25\n",
      "for 2019-12-20, MAE is:6.19 & sMAPE is:17.81% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 16.69% & 1.25\n",
      "for 2019-12-21, MAE is:5.93 & sMAPE is:20.74% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 16.70% & 1.25\n",
      "for 2019-12-22, MAE is:6.75 & sMAPE is:23.02% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 16.72% & 1.25\n",
      "for 2019-12-23, MAE is:3.76 & sMAPE is:15.63% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.72% & 1.25\n",
      "for 2019-12-24, MAE is:5.43 & sMAPE is:19.33% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.72% & 1.25\n",
      "for 2019-12-25, MAE is:6.43 & sMAPE is:26.15% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.75% & 1.25\n",
      "for 2019-12-26, MAE is:9.69 & sMAPE is:33.37% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.80% & 1.25\n",
      "for 2019-12-27, MAE is:6.62 & sMAPE is:20.05% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 16.80% & 1.25\n",
      "for 2019-12-28, MAE is:2.22 & sMAPE is:6.38% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 16.78% & 1.25\n",
      "for 2019-12-29, MAE is:4.48 & sMAPE is:13.71% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 16.77% & 1.25\n",
      "for 2019-12-30, MAE is:5.69 & sMAPE is:15.80% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 16.76% & 1.24\n",
      "for 2019-12-31, MAE is:8.08 & sMAPE is:24.50% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 16.79% & 1.24\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:42:51,340]\u001b[0m A new study created in RDB with name: NL_2020\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:43:14,860]\u001b[0m Trial 1 finished with value: 6.207364698797186 and parameters: {'n_hidden': 4, 'learning_rate': 0.003648345709712053, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23781358256707774, 'dropout_rate_Layer_2': 0.09615902244659376, 'dropout_rate_Layer_3': 0.13824600256239622, 'dropout_rate_Layer_4': 0.14280983233698158, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0016705459664196132, 'l1_Layer_2': 1.796205701234518e-05, 'l1_Layer_3': 1.6903497553949593e-05, 'l1_Layer_4': 0.01995655246316817, 'n_units_Layer_1': 160, 'n_units_Layer_2': 140, 'n_units_Layer_3': 265, 'n_units_Layer_4': 120}. Best is trial 1 with value: 6.207364698797186.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 15.38% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 11.29 | sMAPE for Test Set is: 36.73% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:43:15,175]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 22.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:43:23,475]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:43:28,288]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:43:33,151]\u001b[0m Trial 0 finished with value: 5.362546412079027 and parameters: {'n_hidden': 4, 'learning_rate': 0.03199571914889029, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1967515468432009, 'dropout_rate_Layer_2': 0.3510509609685235, 'dropout_rate_Layer_3': 0.17071246703933005, 'dropout_rate_Layer_4': 0.31095780602856427, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.268999200153944e-05, 'l1_Layer_2': 0.07320720446968136, 'l1_Layer_3': 0.014026984568564294, 'l1_Layer_4': 0.052944687228709694, 'n_units_Layer_1': 220, 'n_units_Layer_2': 105, 'n_units_Layer_3': 70, 'n_units_Layer_4': 75}. Best is trial 0 with value: 5.362546412079027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 13.39% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 8.02 | sMAPE for Test Set is: 28.85% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:43:35,817]\u001b[0m Trial 5 finished with value: 7.002133552872713 and parameters: {'n_hidden': 4, 'learning_rate': 0.06666384822033784, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10075804878686015, 'dropout_rate_Layer_2': 0.06595431881755238, 'dropout_rate_Layer_3': 0.3646109374935501, 'dropout_rate_Layer_4': 0.15343549660137124, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0008400395711194861, 'l1_Layer_2': 0.00020607998791710648, 'l1_Layer_3': 4.653897159109297e-05, 'l1_Layer_4': 2.6345679198259313e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 180, 'n_units_Layer_3': 210, 'n_units_Layer_4': 175}. Best is trial 0 with value: 5.362546412079027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.00 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 1.13\n",
      "MAE for Test Set is: 12.53 | sMAPE for Test Set is: 39.44% | rMAE for Test Set is: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:43:39,282]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:43:39,839]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:43:46,300]\u001b[0m Trial 8 finished with value: 5.699473472609423 and parameters: {'n_hidden': 3, 'learning_rate': 0.06445296993489685, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3049427584782306, 'dropout_rate_Layer_2': 0.08630232266054692, 'dropout_rate_Layer_3': 0.1346861353474063, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026158248103576444, 'l1_Layer_2': 0.0022785757043510112, 'l1_Layer_3': 0.0007996472674254148, 'n_units_Layer_1': 70, 'n_units_Layer_2': 220, 'n_units_Layer_3': 80}. Best is trial 0 with value: 5.362546412079027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 14.31% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 8.80 | sMAPE for Test Set is: 30.76% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:43:50,304]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:43:52,699]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:43:55,220]\u001b[0m Trial 2 finished with value: 5.735270974924667 and parameters: {'n_hidden': 4, 'learning_rate': 0.003434987295548948, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38074342048903986, 'dropout_rate_Layer_2': 0.3525454527419132, 'dropout_rate_Layer_3': 0.16475866211334586, 'dropout_rate_Layer_4': 0.003963721458341496, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.9900872343299886e-05, 'l1_Layer_2': 0.0008040683018767182, 'l1_Layer_3': 0.00565987979096827, 'l1_Layer_4': 0.013122196383489878, 'n_units_Layer_1': 205, 'n_units_Layer_2': 235, 'n_units_Layer_3': 75, 'n_units_Layer_4': 280}. Best is trial 0 with value: 5.362546412079027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 14.27% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 10.64 | sMAPE for Test Set is: 35.22% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:43:57,130]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:43:57,299]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:43:57,446]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:43:57,783]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:44:05,472]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:44:10,580]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:44:11,918]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:44:13,031]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:44:20,703]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:44:26,996]\u001b[0m Trial 19 finished with value: 7.26858836607338 and parameters: {'n_hidden': 4, 'learning_rate': 0.007551654171541142, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27889214650009736, 'dropout_rate_Layer_2': 0.3258354851322051, 'dropout_rate_Layer_3': 0.09101828818683178, 'dropout_rate_Layer_4': 0.05735898966270075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.014640902786731469, 'l1_Layer_2': 0.02452260866716737, 'l1_Layer_3': 0.00032009002272436057, 'l1_Layer_4': 1.124414090865593e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 130, 'n_units_Layer_3': 140, 'n_units_Layer_4': 155}. Best is trial 0 with value: 5.362546412079027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.27 | sMAPE for Validation Set is: 17.83% | rMAE for Validation Set is: 1.18\n",
      "MAE for Test Set is: 13.72 | sMAPE for Test Set is: 41.88% | rMAE for Test Set is: 1.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:44:31,762]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:44:34,808]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:44:38,594]\u001b[0m Trial 21 finished with value: 5.445366581467499 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031497224737297618, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21038717716992206, 'dropout_rate_Layer_2': 0.2843926332537741, 'dropout_rate_Layer_3': 0.28057996150515835, 'dropout_rate_Layer_4': 0.3389347499266843, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.051882100266310315, 'l1_Layer_2': 0.002321403749796249, 'l1_Layer_3': 4.018117745780506e-05, 'l1_Layer_4': 2.1078835347977026e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 155, 'n_units_Layer_3': 75, 'n_units_Layer_4': 290}. Best is trial 0 with value: 5.362546412079027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 13.65% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 8.86 | sMAPE for Test Set is: 30.84% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:44:39,057]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:44:41,157]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:44:46,877]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:44:47,185]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:44:54,445]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:44:54,534]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:44:55,848]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:45:02,203]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:45:05,116]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:45:09,360]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:45:11,333]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:45:13,796]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:45:15,186]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:45:19,491]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:45:19,775]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:45:24,101]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:45:27,079]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:45:30,555]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:45:33,510]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:45:38,434]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:45:42,789]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:45:46,347]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:45:51,872]\u001b[0m Trial 45 finished with value: 8.425596697654582 and parameters: {'n_hidden': 4, 'learning_rate': 0.052823159327960424, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06703958989392067, 'dropout_rate_Layer_2': 0.03654133880801349, 'dropout_rate_Layer_3': 0.08357750303896157, 'dropout_rate_Layer_4': 0.1235556743135684, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.04677273781247791, 'l1_Layer_2': 0.0002519065904135921, 'l1_Layer_3': 0.014549579971602444, 'l1_Layer_4': 2.71623608977722e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 185, 'n_units_Layer_3': 195, 'n_units_Layer_4': 275}. Best is trial 0 with value: 5.362546412079027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.43 | sMAPE for Validation Set is: 20.13% | rMAE for Validation Set is: 1.36\n",
      "MAE for Test Set is: 13.61 | sMAPE for Test Set is: 41.73% | rMAE for Test Set is: 1.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:45:52,239]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.22 | sMAPE for Validation Set is: 13.10% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 8.47 | sMAPE for Test Set is: 30.05% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:45:52,432]\u001b[0m Trial 36 finished with value: 5.219667500854649 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012234213675371818, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39645305949640436, 'dropout_rate_Layer_2': 0.24463712319949957, 'dropout_rate_Layer_3': 0.2673988218281906, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8860674138469625e-05, 'l1_Layer_2': 0.011289309276538196, 'l1_Layer_3': 9.320099514451863e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 275, 'n_units_Layer_3': 60}. Best is trial 36 with value: 5.219667500854649.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:45:56,667]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:46:01,750]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:46:03,121]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:46:03,798]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:46:03,824]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:46:08,763]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:46:15,727]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:46:20,857]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:46:25,280]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:46:29,442]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:46:38,509]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:46:41,369]\u001b[0m Trial 58 finished with value: 5.66451750273145 and parameters: {'n_hidden': 3, 'learning_rate': 0.013034558255909934, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20418828735334707, 'dropout_rate_Layer_2': 0.21129489345681304, 'dropout_rate_Layer_3': 0.2755668680590786, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.008286794526435957, 'l1_Layer_2': 0.00012709125158443928, 'l1_Layer_3': 0.0006054132243654499, 'n_units_Layer_1': 175, 'n_units_Layer_2': 200, 'n_units_Layer_3': 220}. Best is trial 36 with value: 5.219667500854649.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 14.38% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 9.53 | sMAPE for Test Set is: 32.41% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:46:42,107]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:46:44,223]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:46:49,881]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:46:53,389]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:46:56,331]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:47:02,907]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:47:07,903]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:47:11,851]\u001b[0m Trial 66 finished with value: 5.2827503933098505 and parameters: {'n_hidden': 3, 'learning_rate': 0.005841609207675626, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3646513824617518, 'dropout_rate_Layer_2': 0.37234742861260844, 'dropout_rate_Layer_3': 0.03846741647252717, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00012349606349336975, 'l1_Layer_2': 1.0389688071216532e-05, 'l1_Layer_3': 6.913238414278235e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 235, 'n_units_Layer_3': 295}. Best is trial 36 with value: 5.219667500854649.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 13.28% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 9.08 | sMAPE for Test Set is: 31.62% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:47:15,199]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:47:18,447]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:47:19,535]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:47:23,129]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:47:23,442]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:47:29,168]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:47:29,401]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:47:30,023]\u001b[0m Trial 60 finished with value: 4.973794446062553 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014447258467350677, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3053926010930697, 'dropout_rate_Layer_2': 0.38710443145250506, 'dropout_rate_Layer_3': 0.2958628371583322, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010832922380966212, 'l1_Layer_2': 0.0005130433691348509, 'l1_Layer_3': 0.003231310239718546, 'n_units_Layer_1': 225, 'n_units_Layer_2': 215, 'n_units_Layer_3': 90}. Best is trial 60 with value: 4.973794446062553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 12.49% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 8.35 | sMAPE for Test Set is: 29.72% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:47:37,144]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:47:40,841]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:47:43,492]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:47:57,890]\u001b[0m Trial 76 finished with value: 4.961345759112963 and parameters: {'n_hidden': 3, 'learning_rate': 0.005408908125747241, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06726265513137207, 'dropout_rate_Layer_2': 0.1458907494633786, 'dropout_rate_Layer_3': 0.015309622394426459, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0007056010945074564, 'l1_Layer_2': 0.002650328452295037, 'l1_Layer_3': 0.0013705848009017167, 'n_units_Layer_1': 85, 'n_units_Layer_2': 130, 'n_units_Layer_3': 145}. Best is trial 76 with value: 4.961345759112963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 12.35% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 8.41 | sMAPE for Test Set is: 29.99% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:48:04,382]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:48:10,006]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:48:14,964]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:48:20,207]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:48:33,005]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:48:37,326]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:48:44,711]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:48:46,170]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:48:50,844]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:48:52,615]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:48:58,011]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:48:58,633]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:02,823]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:03,925]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:08,313]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:09,291]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:15,657]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:16,075]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:16,873]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:23,050]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:25,711]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:28,184]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:31,716]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:32,448]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:34,265]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:39,408]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:45,523]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:50,535]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:57,114]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:49:57,377]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:50:02,803]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:50:03,440]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:50:06,330]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:50:09,740]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:50:12,959]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:50:15,650]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:50:18,500]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:50:21,821]\u001b[0m Trial 117 finished with value: 5.519295190974543 and parameters: {'n_hidden': 3, 'learning_rate': 0.0204222803938236, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29832061604117677, 'dropout_rate_Layer_2': 0.0723681831489791, 'dropout_rate_Layer_3': 0.012756503793638185, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.000581452956127244, 'l1_Layer_2': 0.019999253568884157, 'l1_Layer_3': 0.00013969839478343658, 'n_units_Layer_1': 190, 'n_units_Layer_2': 285, 'n_units_Layer_3': 145}. Best is trial 76 with value: 4.961345759112963.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:50:21,939]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 13.75% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 9.32 | sMAPE for Test Set is: 32.16% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:50:29,221]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:50:34,883]\u001b[0m Trial 122 finished with value: 5.7840787148786434 and parameters: {'n_hidden': 3, 'learning_rate': 0.019200905497890264, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29643229653842873, 'dropout_rate_Layer_2': 0.09767554748767329, 'dropout_rate_Layer_3': 0.15509576612489462, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0005437372243123727, 'l1_Layer_2': 0.025106353437687978, 'l1_Layer_3': 0.00019772634231679956, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 140}. Best is trial 76 with value: 4.961345759112963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 14.36% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 9.55 | sMAPE for Test Set is: 32.68% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:50:38,204]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:50:54,277]\u001b[0m Trial 81 finished with value: 5.476690686907848 and parameters: {'n_hidden': 3, 'learning_rate': 0.00422930036674328, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2502567451394482, 'dropout_rate_Layer_2': 0.07831083816067969, 'dropout_rate_Layer_3': 0.13156227267057807, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0059309183418329425, 'l1_Layer_2': 4.2884125843559794e-05, 'l1_Layer_3': 0.051734033361093196, 'n_units_Layer_1': 205, 'n_units_Layer_2': 130, 'n_units_Layer_3': 295}. Best is trial 76 with value: 4.961345759112963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 13.73% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 8.96 | sMAPE for Test Set is: 31.23% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:50:57,322]\u001b[0m Trial 123 finished with value: 5.244144565246625 and parameters: {'n_hidden': 4, 'learning_rate': 0.0049021370147014475, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3962824438554807, 'dropout_rate_Layer_2': 0.1882681774185712, 'dropout_rate_Layer_3': 0.01301250089558862, 'dropout_rate_Layer_4': 0.2205102196500687, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006827159990462709, 'l1_Layer_2': 0.008011492023361141, 'l1_Layer_3': 0.004907577927862949, 'l1_Layer_4': 0.0011788441386201558, 'n_units_Layer_1': 165, 'n_units_Layer_2': 280, 'n_units_Layer_3': 145, 'n_units_Layer_4': 265}. Best is trial 76 with value: 4.961345759112963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 13.19% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 8.84 | sMAPE for Test Set is: 30.96% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:51:00,605]\u001b[0m Trial 126 finished with value: 5.231486053005056 and parameters: {'n_hidden': 4, 'learning_rate': 0.011170084533132221, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33113629702321506, 'dropout_rate_Layer_2': 0.07358451210796302, 'dropout_rate_Layer_3': 0.07236789817151314, 'dropout_rate_Layer_4': 0.08909374754985096, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.2606308862661444e-05, 'l1_Layer_2': 0.004870341625058754, 'l1_Layer_3': 0.000489832726524121, 'l1_Layer_4': 7.186282025665491e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 230, 'n_units_Layer_3': 200, 'n_units_Layer_4': 205}. Best is trial 76 with value: 4.961345759112963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 13.18% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 9.10 | sMAPE for Test Set is: 31.75% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:51:04,431]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:51:07,714]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:51:15,145]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:51:15,757]\u001b[0m Trial 127 finished with value: 5.2249440027570815 and parameters: {'n_hidden': 4, 'learning_rate': 0.00450827735818327, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3984448262348887, 'dropout_rate_Layer_2': 0.36336785936418703, 'dropout_rate_Layer_3': 0.12689381678174694, 'dropout_rate_Layer_4': 0.23063452925601857, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00029857930693035964, 'l1_Layer_2': 0.002705255805246083, 'l1_Layer_3': 0.005189405579087686, 'l1_Layer_4': 0.0012156776771111801, 'n_units_Layer_1': 205, 'n_units_Layer_2': 230, 'n_units_Layer_3': 135, 'n_units_Layer_4': 265}. Best is trial 76 with value: 4.961345759112963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.22 | sMAPE for Validation Set is: 13.14% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 8.98 | sMAPE for Test Set is: 31.35% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:51:19,304]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:51:23,047]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:51:26,216]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:51:27,075]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:51:31,171]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:51:34,805]\u001b[0m Trial 128 finished with value: 5.2498248022583835 and parameters: {'n_hidden': 4, 'learning_rate': 0.0054462578716025015, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3990294440809128, 'dropout_rate_Layer_2': 0.35740248173437666, 'dropout_rate_Layer_3': 0.05132766431482315, 'dropout_rate_Layer_4': 0.21544661508264848, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.3546361013073037e-05, 'l1_Layer_2': 0.008213340409585556, 'l1_Layer_3': 0.005741786838701325, 'l1_Layer_4': 0.000836085077918165, 'n_units_Layer_1': 200, 'n_units_Layer_2': 230, 'n_units_Layer_3': 105, 'n_units_Layer_4': 265}. Best is trial 76 with value: 4.961345759112963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 13.22% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 9.17 | sMAPE for Test Set is: 31.83% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:51:35,268]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:51:35,830]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:51:42,225]\u001b[0m Trial 133 finished with value: 5.028517825146182 and parameters: {'n_hidden': 3, 'learning_rate': 0.015653648393172112, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06631496374668483, 'dropout_rate_Layer_2': 0.3069571026389346, 'dropout_rate_Layer_3': 0.029604880523706106, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002775025633929607, 'l1_Layer_2': 0.04875105975974509, 'l1_Layer_3': 0.007675258430914481, 'n_units_Layer_1': 50, 'n_units_Layer_2': 70, 'n_units_Layer_3': 55}. Best is trial 76 with value: 4.961345759112963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 12.70% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 9.38 | sMAPE for Test Set is: 32.51% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:51:46,169]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:51:46,376]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:51:48,182]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:51:52,911]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:51:53,096]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:52:01,124]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:52:01,404]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:52:06,861]\u001b[0m Trial 145 finished with value: 5.313182289666969 and parameters: {'n_hidden': 4, 'learning_rate': 0.00669502121459699, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22372556733958976, 'dropout_rate_Layer_2': 0.09150387107864703, 'dropout_rate_Layer_3': 0.07494868328233958, 'dropout_rate_Layer_4': 0.10802997241050011, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.0633039337949696e-05, 'l1_Layer_2': 0.005847630686305804, 'l1_Layer_3': 1.9943036291397095e-05, 'l1_Layer_4': 0.00046669109928130093, 'n_units_Layer_1': 225, 'n_units_Layer_2': 50, 'n_units_Layer_3': 135, 'n_units_Layer_4': 80}. Best is trial 76 with value: 4.961345759112963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 13.33% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 8.77 | sMAPE for Test Set is: 30.73% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:52:07,898]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:52:16,647]\u001b[0m Trial 141 finished with value: 5.318250397268398 and parameters: {'n_hidden': 4, 'learning_rate': 0.010665352321839234, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3710005521324538, 'dropout_rate_Layer_2': 0.07105670738979086, 'dropout_rate_Layer_3': 0.29633752337746827, 'dropout_rate_Layer_4': 0.08532634507022863, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.605913607898127e-05, 'l1_Layer_2': 0.0011931796851312436, 'l1_Layer_3': 0.0005064630247455032, 'l1_Layer_4': 6.510365912185496e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 225, 'n_units_Layer_3': 200, 'n_units_Layer_4': 270}. Best is trial 76 with value: 4.961345759112963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 13.42% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 9.07 | sMAPE for Test Set is: 31.60% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:52:19,588]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:52:23,822]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:52:23,954]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:52:25,165]\u001b[0m Trial 149 finished with value: 4.96239193736952 and parameters: {'n_hidden': 3, 'learning_rate': 0.003626834787964924, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3414698808974969, 'dropout_rate_Layer_2': 0.08913726302937887, 'dropout_rate_Layer_3': 0.06021510345909098, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019487680473384095, 'l1_Layer_2': 0.004425307101388365, 'l1_Layer_3': 6.825092748279554e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 255, 'n_units_Layer_3': 165}. Best is trial 76 with value: 4.961345759112963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 12.41% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 7.86 | sMAPE for Test Set is: 28.38% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:52:33,405]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:52:34,042]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:52:35,430]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:52:43,890]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:52:47,473]\u001b[0m Trial 155 finished with value: 5.242409402778029 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032459726585320993, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3346721622338399, 'dropout_rate_Layer_2': 0.09725649356219943, 'dropout_rate_Layer_3': 0.008329490365071428, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019359958249841518, 'l1_Layer_2': 0.09743575555400569, 'l1_Layer_3': 6.212456396101986e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 265, 'n_units_Layer_3': 180}. Best is trial 76 with value: 4.961345759112963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 13.15% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 8.07 | sMAPE for Test Set is: 28.84% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:52:50,811]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:52:54,595]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:52:56,942]\u001b[0m Trial 158 finished with value: 5.2254684166579715 and parameters: {'n_hidden': 4, 'learning_rate': 0.012039440008680057, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36323110374366496, 'dropout_rate_Layer_2': 0.044059263582731434, 'dropout_rate_Layer_3': 0.011875108904969428, 'dropout_rate_Layer_4': 0.18114710534299905, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.7523604519647476e-05, 'l1_Layer_2': 0.0063404288379063445, 'l1_Layer_3': 0.0032383339886968717, 'l1_Layer_4': 9.757503428310886e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 225, 'n_units_Layer_3': 165, 'n_units_Layer_4': 75}. Best is trial 76 with value: 4.961345759112963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 13.15% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 9.30 | sMAPE for Test Set is: 32.26% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:52:59,318]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:02,591]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:07,455]\u001b[0m Trial 159 finished with value: 5.1256951770391765 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027922206728178693, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3465033357838765, 'dropout_rate_Layer_2': 0.22047587332593332, 'dropout_rate_Layer_3': 0.0009361918174884409, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019737621391751413, 'l1_Layer_2': 0.007556986547456806, 'l1_Layer_3': 5.48591906422784e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 260, 'n_units_Layer_3': 185}. Best is trial 76 with value: 4.961345759112963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 12.76% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 7.46 | sMAPE for Test Set is: 27.14% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:53:07,719]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:10,688]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:14,896]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:16,206]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:20,585]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:23,338]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 13.97% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 7.46 | sMAPE for Test Set is: 27.12% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:53:25,689]\u001b[0m Trial 168 finished with value: 5.585693353949534 and parameters: {'n_hidden': 3, 'learning_rate': 0.003734701410194898, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3856233512423436, 'dropout_rate_Layer_2': 0.2145450437781417, 'dropout_rate_Layer_3': 0.11749321087580225, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1118676777844185e-05, 'l1_Layer_2': 0.0009175942606454653, 'l1_Layer_3': 1.1114186343255651e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 145, 'n_units_Layer_3': 210}. Best is trial 76 with value: 4.961345759112963.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:28,056]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:30,256]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:33,959]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:35,942]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:38,810]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:40,757]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:43,950]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:46,344]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:50,592]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:51,526]\u001b[0m Trial 166 finished with value: 4.808641269690941 and parameters: {'n_hidden': 3, 'learning_rate': 0.009189421994824924, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10101676227930911, 'dropout_rate_Layer_2': 0.18680529878949825, 'dropout_rate_Layer_3': 0.06917781708033718, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005847156674934371, 'l1_Layer_2': 0.008059974668577717, 'l1_Layer_3': 0.002754231646361573, 'n_units_Layer_1': 100, 'n_units_Layer_2': 85, 'n_units_Layer_3': 50}. Best is trial 166 with value: 4.808641269690941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 12.07% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 7.57 | sMAPE for Test Set is: 27.67% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:53:51,782]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:52,976]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:53:55,549]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:54:01,149]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:54:01,251]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:54:01,973]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:54:08,585]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:54:09,892]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:54:10,953]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:54:17,501]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:54:19,283]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:54:41,865]\u001b[0m Trial 192 finished with value: 4.96099255450833 and parameters: {'n_hidden': 3, 'learning_rate': 0.001983262178708503, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3354957369571063, 'dropout_rate_Layer_2': 0.18881521564197642, 'dropout_rate_Layer_3': 0.00044582853727792354, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0024671848857344045, 'l1_Layer_2': 0.008873809460015059, 'l1_Layer_3': 6.61507251964066e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 265, 'n_units_Layer_3': 175}. Best is trial 166 with value: 4.808641269690941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 12.42% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 8.44 | sMAPE for Test Set is: 30.00% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:54:42,474]\u001b[0m Trial 196 finished with value: 4.932379589178487 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018716894768794768, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3389841770272587, 'dropout_rate_Layer_2': 0.18645412787342677, 'dropout_rate_Layer_3': 0.041362597566428946, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013395427463829968, 'l1_Layer_2': 0.016148199931354645, 'l1_Layer_3': 4.949254983974958e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 265, 'n_units_Layer_3': 170}. Best is trial 166 with value: 4.808641269690941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 12.37% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 8.40 | sMAPE for Test Set is: 29.91% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:54:47,369]\u001b[0m Trial 195 finished with value: 5.028040583511083 and parameters: {'n_hidden': 3, 'learning_rate': 0.0171185921376816, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3295986791912958, 'dropout_rate_Layer_2': 0.018055235307668647, 'dropout_rate_Layer_3': 0.1373876145378065, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.7520239322247125e-05, 'l1_Layer_2': 0.0023640824090395075, 'l1_Layer_3': 0.0009892019605087026, 'n_units_Layer_1': 280, 'n_units_Layer_2': 235, 'n_units_Layer_3': 130}. Best is trial 166 with value: 4.808641269690941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 12.64% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 8.45 | sMAPE for Test Set is: 29.99% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:54:49,545]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:54:50,613]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:54:52,652]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:54:58,638]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:55:00,294]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:55:03,811]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:55:08,547]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:55:15,324]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:55:16,801]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:55:17,551]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:55:21,468]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:55:24,021]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:55:24,268]\u001b[0m Trial 193 finished with value: 4.8019461080881465 and parameters: {'n_hidden': 3, 'learning_rate': 0.007463826748682067, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28924544274203845, 'dropout_rate_Layer_2': 0.027510622570593637, 'dropout_rate_Layer_3': 0.25980052953572136, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.2009257163677354e-05, 'l1_Layer_2': 0.007925737372750744, 'l1_Layer_3': 0.001080327170257415, 'n_units_Layer_1': 280, 'n_units_Layer_2': 290, 'n_units_Layer_3': 135}. Best is trial 193 with value: 4.8019461080881465.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 12.08% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 8.13 | sMAPE for Test Set is: 29.17% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:55:24,879]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:55:30,778]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:55:31,105]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:55:37,838]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:55:41,510]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:55:56,549]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:56:00,431]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:56:06,449]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:56:11,449]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:56:15,407]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:56:20,025]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:56:22,354]\u001b[0m Trial 214 finished with value: 4.760751076898983 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015319670016860814, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2555917060377401, 'dropout_rate_Layer_2': 0.17917254261550414, 'dropout_rate_Layer_3': 0.048120127948062474, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006358328833640663, 'l1_Layer_2': 0.013819640128990528, 'l1_Layer_3': 3.063461706715164e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 280, 'n_units_Layer_3': 160}. Best is trial 214 with value: 4.760751076898983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 11.93% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 8.10 | sMAPE for Test Set is: 29.04% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:56:27,548]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:56:31,160]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:56:34,663]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:56:38,111]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:56:38,704]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:56:43,709]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:56:48,959]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:56:49,396]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:56:55,144]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:01,188]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:09,823]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:13,309]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:14,434]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:15,255]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:20,777]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:24,382]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:27,299]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:32,661]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:33,318]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:40,856]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:43,295]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:44,438]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:47,113]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:52,401]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:52,683]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:53,453]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:57,563]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:57:59,985]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:00,027]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:01,262]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:08,023]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:11,432]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:15,133]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:17,006]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:19,941]\u001b[0m Trial 255 finished with value: 7.25408588757506 and parameters: {'n_hidden': 3, 'learning_rate': 0.005581631414388061, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00036300673109268544, 'dropout_rate_Layer_2': 0.2522875628301291, 'dropout_rate_Layer_3': 0.25617956497911437, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00019972182209936776, 'l1_Layer_2': 0.00618389084505581, 'l1_Layer_3': 9.556636085167651e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 170, 'n_units_Layer_3': 105}. Best is trial 214 with value: 4.760751076898983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.25 | sMAPE for Validation Set is: 17.84% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 13.80 | sMAPE for Test Set is: 42.26% | rMAE for Test Set is: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 23:58:20,138]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:22,020]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:26,941]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:31,176]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:34,435]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:34,635]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:42,353]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:47,733]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:48,095]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:53,721]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:55,082]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:58:57,849]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:00,234]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:05,633]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:09,049]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:10,086]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:14,187]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:16,744]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:18,986]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:24,148]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:28,653]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:30,928]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:34,511]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:35,279]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:40,864]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:41,122]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:41,141]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:48,437]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:52,002]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 23:59:55,925]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:03,239]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:07,339]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:13,428]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:16,029]\u001b[0m Trial 260 finished with value: 4.579152852152535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009136564730427754, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1195993701128077, 'dropout_rate_Layer_2': 0.016360325382507618, 'dropout_rate_Layer_3': 0.06758301021561727, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0024334423141878798, 'l1_Layer_2': 0.0005067611070634063, 'l1_Layer_3': 0.0027945052174338497, 'n_units_Layer_1': 145, 'n_units_Layer_2': 110, 'n_units_Layer_3': 215}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 11.49% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 7.63 | sMAPE for Test Set is: 27.87% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:00:20,222]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:24,414]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:24,697]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:25,072]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:35,773]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:36,234]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:36,849]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:41,510]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:47,568]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:47,934]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:48,858]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:52,307]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:55,058]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:56,211]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:57,789]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:00:58,641]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:01:00,254]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:01:02,215]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:01:04,120]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:01:09,518]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:01:10,093]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:01:15,367]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:01:19,844]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:01:23,281]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:01:25,459]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:01:28,223]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:01:30,962]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:01:39,524]\u001b[0m Trial 311 finished with value: 5.109555662845988 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006891647422719979, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39582302778019596, 'dropout_rate_Layer_2': 0.28974868727248865, 'dropout_rate_Layer_3': 0.06525913260913821, 'dropout_rate_Layer_4': 0.25152007839448515, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01079769372750314, 'l1_Layer_2': 0.0005349730763803702, 'l1_Layer_3': 7.989902707342514e-05, 'l1_Layer_4': 1.629217863059091e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 250, 'n_units_Layer_3': 95, 'n_units_Layer_4': 55}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 12.86% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 7.79 | sMAPE for Test Set is: 28.03% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:01:50,877]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:01:51,344]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:01:56,803]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:01:57,756]\u001b[0m Trial 315 finished with value: 4.92280798159942 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014850788012876562, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3134327542634512, 'dropout_rate_Layer_2': 0.19601786996104043, 'dropout_rate_Layer_3': 0.06403053979141249, 'dropout_rate_Layer_4': 0.39227558593749967, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009389925337835309, 'l1_Layer_2': 0.0005707865835382369, 'l1_Layer_3': 2.1079561851110226e-05, 'l1_Layer_4': 2.5683333258665484e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 245, 'n_units_Layer_3': 80, 'n_units_Layer_4': 50}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 12.38% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 8.42 | sMAPE for Test Set is: 29.85% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:01:59,548]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:02,327]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:06,662]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:06,768]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:07,024]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:07,260]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:15,769]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:16,529]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:22,798]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:26,368]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:26,968]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:29,016]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:29,741]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:36,702]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:40,964]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:44,418]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:47,789]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:51,422]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:54,354]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:55,854]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:02:59,852]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:00,001]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:00,783]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:07,988]\u001b[0m Trial 337 finished with value: 5.227706950141509 and parameters: {'n_hidden': 4, 'learning_rate': 0.005483852003696036, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.391921257527739, 'dropout_rate_Layer_2': 0.13892072474039102, 'dropout_rate_Layer_3': 0.11136586998639436, 'dropout_rate_Layer_4': 0.3697697423879612, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010287307357888023, 'l1_Layer_2': 0.005184499209973344, 'l1_Layer_3': 0.00813081438788636, 'l1_Layer_4': 0.0003722471097335787, 'n_units_Layer_1': 65, 'n_units_Layer_2': 295, 'n_units_Layer_3': 110, 'n_units_Layer_4': 275}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 13.14% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 9.17 | sMAPE for Test Set is: 31.75% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:03:10,817]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:12,762]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:15,335]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:17,214]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:19,070]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:21,522]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:27,506]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:27,833]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:33,926]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:34,180]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:34,397]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:41,147]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:43,111]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:43,365]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:45,513]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:47,096]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:53,958]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:54,145]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:03:56,246]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:02,472]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:06,788]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:10,543]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:13,539]\u001b[0m Trial 363 finished with value: 4.9488075085503205 and parameters: {'n_hidden': 3, 'learning_rate': 0.007544629110233726, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.093799785052578, 'dropout_rate_Layer_2': 0.05659483944371313, 'dropout_rate_Layer_3': 0.007986101347835783, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00394851253759585, 'l1_Layer_2': 0.0003128194290445312, 'l1_Layer_3': 0.0009209193333806015, 'n_units_Layer_1': 130, 'n_units_Layer_2': 135, 'n_units_Layer_3': 135}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 12.46% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 8.48 | sMAPE for Test Set is: 30.09% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:04:14,594]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:19,814]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:21,450]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:25,338]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:30,175]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:30,862]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:34,405]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:37,417]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:41,307]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:45,591]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:49,239]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:49,930]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:54,293]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:56,800]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:59,165]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:04:59,747]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:05:00,428]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:05:08,097]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:05:08,320]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:05:14,407]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:05:18,284]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:05:22,949]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:05:26,490]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:05:30,725]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:05:34,500]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:05:38,209]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:05:42,204]\u001b[0m Trial 366 finished with value: 5.269769378161297 and parameters: {'n_hidden': 4, 'learning_rate': 0.003424153199949828, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.394506751502133, 'dropout_rate_Layer_2': 0.14360494848770994, 'dropout_rate_Layer_3': 0.03708013131471123, 'dropout_rate_Layer_4': 0.37903154254739285, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009763797043512911, 'l1_Layer_2': 0.012208129082814538, 'l1_Layer_3': 0.011167337362941515, 'l1_Layer_4': 0.0005464768779838965, 'n_units_Layer_1': 150, 'n_units_Layer_2': 290, 'n_units_Layer_3': 195, 'n_units_Layer_4': 270}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 13.24% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 9.09 | sMAPE for Test Set is: 31.54% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:05:45,670]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:05:45,982]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:05:46,835]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:05:53,390]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:05:53,778]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:05:58,784]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:06:01,821]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:06:04,565]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:06:09,018]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:06:25,568]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:06:29,876]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:06:30,251]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:06:35,660]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:06:38,868]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:06:39,327]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:06:45,472]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:06:45,717]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:06:52,169]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:06:53,056]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:06:57,423]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:01,613]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:04,338]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:08,874]\u001b[0m Trial 400 finished with value: 4.634263061083007 and parameters: {'n_hidden': 4, 'learning_rate': 0.000683008870579555, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.367647099755497, 'dropout_rate_Layer_2': 0.2133558465054947, 'dropout_rate_Layer_3': 0.3823071004660207, 'dropout_rate_Layer_4': 0.33789330934330253, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0023743931108421963, 'l1_Layer_2': 0.0008748173434813838, 'l1_Layer_3': 4.764015260752901e-05, 'l1_Layer_4': 0.0002308778690544261, 'n_units_Layer_1': 230, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170, 'n_units_Layer_4': 235}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 11.62% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.82 | sMAPE for Test Set is: 28.34% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:07:09,775]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:11,330]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:15,187]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:16,871]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:18,609]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:25,767]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:29,337]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:29,477]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:34,428]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:35,406]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:35,537]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:40,329]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:42,870]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:48,571]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:56,995]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:07:59,229]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:08:06,545]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:08:18,832]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:08:22,245]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:08:26,606]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:08:33,355]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:08:33,859]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:08:34,693]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:08:42,299]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:08:46,790]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:08:53,331]\u001b[0m Trial 438 finished with value: 4.820093447855731 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023066209186420384, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22013213306455212, 'dropout_rate_Layer_2': 0.044915568883009085, 'dropout_rate_Layer_3': 0.07901593880152513, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0587354947585915e-05, 'l1_Layer_2': 0.0002073906603466788, 'l1_Layer_3': 0.0020456503131990665, 'n_units_Layer_1': 225, 'n_units_Layer_2': 280, 'n_units_Layer_3': 125}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 12.05% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 7.47 | sMAPE for Test Set is: 27.40% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:08:58,358]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:09:00,537]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:09:05,299]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:09:05,435]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:09:10,870]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:09:11,907]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:09:13,094]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:09:13,272]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:09:17,961]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:09:22,049]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:09:28,438]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:09:33,265]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:09:42,775]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:09:56,955]\u001b[0m Trial 456 finished with value: 4.742522360270693 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012109795283984119, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2991340221023353, 'dropout_rate_Layer_2': 0.20685022903874853, 'dropout_rate_Layer_3': 0.29980928385265027, 'dropout_rate_Layer_4': 0.2992502996106196, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0030632560534500303, 'l1_Layer_2': 0.0011198711409439168, 'l1_Layer_3': 2.3753466198440577e-05, 'l1_Layer_4': 7.785857783372363e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 260, 'n_units_Layer_3': 165, 'n_units_Layer_4': 150}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 11.90% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 8.06 | sMAPE for Test Set is: 28.97% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:10:03,261]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:10:11,937]\u001b[0m Trial 457 finished with value: 4.894783467172022 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015622637753489128, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39856207603034827, 'dropout_rate_Layer_2': 0.2088687690905754, 'dropout_rate_Layer_3': 0.019418529643125734, 'dropout_rate_Layer_4': 0.29746313482785997, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007496941270665445, 'l1_Layer_2': 0.01457732690893741, 'l1_Layer_3': 2.6911975590573655e-05, 'l1_Layer_4': 7.604521918671894e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 265, 'n_units_Layer_3': 205, 'n_units_Layer_4': 150}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 12.27% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.89 | sMAPE for Test Set is: 28.35% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:10:20,554]\u001b[0m Trial 461 finished with value: 4.856062652793899 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012092885638013556, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3987196324270914, 'dropout_rate_Layer_2': 0.08206960517050564, 'dropout_rate_Layer_3': 0.2802927904407065, 'dropout_rate_Layer_4': 0.30327698171026984, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007278613791796938, 'l1_Layer_2': 0.0007543780284951054, 'l1_Layer_3': 2.2286969731825506e-05, 'l1_Layer_4': 8.179627897788204e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 265, 'n_units_Layer_3': 205, 'n_units_Layer_4': 170}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 12.26% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.96 | sMAPE for Test Set is: 28.73% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:10:22,838]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:10:30,260]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:10:55,922]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:11:01,891]\u001b[0m Trial 464 finished with value: 4.786064372293554 and parameters: {'n_hidden': 4, 'learning_rate': 0.001235671290837589, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29485278070861715, 'dropout_rate_Layer_2': 0.20734138658479626, 'dropout_rate_Layer_3': 0.3107812300468712, 'dropout_rate_Layer_4': 0.30229529410384526, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006803835959677321, 'l1_Layer_2': 0.015707082729992435, 'l1_Layer_3': 2.7163672782044536e-05, 'l1_Layer_4': 6.652451195350796e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 265, 'n_units_Layer_3': 210, 'n_units_Layer_4': 155}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.79 | sMAPE for Validation Set is: 12.05% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 22.98% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:11:21,805]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:11:25,120]\u001b[0m Trial 466 finished with value: 4.600178933774071 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036698860106752157, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23740152413390905, 'dropout_rate_Layer_2': 0.016447364877333528, 'dropout_rate_Layer_3': 0.06336938420508735, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.982755097654424e-05, 'l1_Layer_2': 0.00020320465617891994, 'l1_Layer_3': 0.0034673914753650804, 'n_units_Layer_1': 235, 'n_units_Layer_2': 280, 'n_units_Layer_3': 135}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 11.56% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 7.61 | sMAPE for Test Set is: 27.79% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:11:28,676]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:11:29,578]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:11:34,132]\u001b[0m Trial 465 finished with value: 5.160371101057952 and parameters: {'n_hidden': 4, 'learning_rate': 0.005536881176211969, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03883978823864428, 'dropout_rate_Layer_2': 0.12103817292847671, 'dropout_rate_Layer_3': 0.08359039354247497, 'dropout_rate_Layer_4': 0.18390722469972376, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001245553116102689, 'l1_Layer_2': 0.06193828908828671, 'l1_Layer_3': 0.014678334253837837, 'l1_Layer_4': 0.0008166977092358153, 'n_units_Layer_1': 165, 'n_units_Layer_2': 240, 'n_units_Layer_3': 155, 'n_units_Layer_4': 255}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 12.96% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 9.24 | sMAPE for Test Set is: 31.97% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:11:34,428]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:11:38,827]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:11:39,829]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:11:41,979]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:11:47,236]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:11:52,469]\u001b[0m Trial 471 finished with value: 4.698446817415831 and parameters: {'n_hidden': 3, 'learning_rate': 0.005882586483575473, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07086771992908611, 'dropout_rate_Layer_2': 0.24191119150720553, 'dropout_rate_Layer_3': 0.023034948315268505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0009807149393199009, 'l1_Layer_2': 0.003912979864484505, 'l1_Layer_3': 0.0015373339998690297, 'n_units_Layer_1': 90, 'n_units_Layer_2': 130, 'n_units_Layer_3': 195}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 11.85% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 8.33 | sMAPE for Test Set is: 29.80% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:11:59,933]\u001b[0m Trial 476 finished with value: 4.796259589532678 and parameters: {'n_hidden': 3, 'learning_rate': 0.005691666724019505, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23500775147642478, 'dropout_rate_Layer_2': 0.0040075009958218805, 'dropout_rate_Layer_3': 0.26312215532879185, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.685324813185277e-05, 'l1_Layer_2': 0.0003796574303909976, 'l1_Layer_3': 6.202586006832486e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 265, 'n_units_Layer_3': 145}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 12.12% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 8.02 | sMAPE for Test Set is: 28.85% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:12:03,782]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:12:09,000]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:12:13,767]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:12:17,933]\u001b[0m Trial 480 finished with value: 4.97498227973668 and parameters: {'n_hidden': 3, 'learning_rate': 0.008297269606173172, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14488952551958728, 'dropout_rate_Layer_2': 0.24589609266134496, 'dropout_rate_Layer_3': 0.0012916628729260863, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0012008886485315028, 'l1_Layer_2': 0.012558473169266218, 'l1_Layer_3': 0.004749221121907949, 'n_units_Layer_1': 110, 'n_units_Layer_2': 145, 'n_units_Layer_3': 195}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 12.50% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 8.58 | sMAPE for Test Set is: 30.42% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:12:21,511]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:12:26,626]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:12:36,338]\u001b[0m Trial 482 finished with value: 4.65535522500008 and parameters: {'n_hidden': 3, 'learning_rate': 0.003892238312581431, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24047110742685987, 'dropout_rate_Layer_2': 0.008243359091003915, 'dropout_rate_Layer_3': 0.2667146899767949, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.147868027505455e-05, 'l1_Layer_2': 0.0007041481458915767, 'l1_Layer_3': 2.614934331579451e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 270, 'n_units_Layer_3': 145}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.66 | sMAPE for Validation Set is: 11.67% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.92 | sMAPE for Test Set is: 28.69% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:12:42,109]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:12:46,092]\u001b[0m Trial 487 finished with value: 4.745828933236319 and parameters: {'n_hidden': 3, 'learning_rate': 0.005620772680744389, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23654078897445344, 'dropout_rate_Layer_2': 0.016176072201046998, 'dropout_rate_Layer_3': 0.29097816986160074, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.503125368692807e-05, 'l1_Layer_2': 0.00020655575153955268, 'l1_Layer_3': 8.60247429701557e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 275, 'n_units_Layer_3': 120}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:12:46,214]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 8.64 | sMAPE for Test Set is: 30.55% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:12:50,845]\u001b[0m Trial 489 finished with value: 6.672706905325921 and parameters: {'n_hidden': 3, 'learning_rate': 0.04332269051911865, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012422087993521347, 'dropout_rate_Layer_2': 0.28906542484087133, 'dropout_rate_Layer_3': 0.043122567668761116, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 7.938008761595642e-05, 'l1_Layer_2': 0.004798052110474046, 'l1_Layer_3': 0.0023683741057517766, 'n_units_Layer_1': 130, 'n_units_Layer_2': 135, 'n_units_Layer_3': 165}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 16.77% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 9.12 | sMAPE for Test Set is: 31.30% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:12:53,993]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:12:58,051]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:13:01,445]\u001b[0m Trial 492 finished with value: 5.92924082210832 and parameters: {'n_hidden': 4, 'learning_rate': 0.02268414442910531, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17127801985752583, 'dropout_rate_Layer_2': 0.33869694559692864, 'dropout_rate_Layer_3': 0.09218814969177752, 'dropout_rate_Layer_4': 0.14161203217618068, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0001582096098625147, 'l1_Layer_2': 0.0003255566524452495, 'l1_Layer_3': 0.009618153823643394, 'l1_Layer_4': 1.950403015840748e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 120, 'n_units_Layer_3': 225, 'n_units_Layer_4': 300}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 14.94% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 9.38 | sMAPE for Test Set is: 32.18% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:13:04,455]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:13:09,467]\u001b[0m Trial 491 finished with value: 4.710241524618209 and parameters: {'n_hidden': 3, 'learning_rate': 0.005750011297772752, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2464876746146742, 'dropout_rate_Layer_2': 0.0007322721608268509, 'dropout_rate_Layer_3': 0.2903675692522282, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.0322875648576804e-05, 'l1_Layer_2': 0.00036730342573927655, 'l1_Layer_3': 7.808151934165582e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 11.90% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.94 | sMAPE for Test Set is: 28.68% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:13:13,370]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:13:14,477]\u001b[0m Trial 493 finished with value: 4.687048783870606 and parameters: {'n_hidden': 3, 'learning_rate': 0.005545431587592895, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23578095314915629, 'dropout_rate_Layer_2': 0.0013359748186155228, 'dropout_rate_Layer_3': 0.28909965594188536, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.37281281514805e-05, 'l1_Layer_2': 0.00036806378099409705, 'l1_Layer_3': 7.871238118753457e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 11.78% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.93 | sMAPE for Test Set is: 28.68% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:13:14,815]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:13:27,222]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:13:33,233]\u001b[0m Trial 500 finished with value: 4.76589752236336 and parameters: {'n_hidden': 3, 'learning_rate': 0.00569926768785177, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23768194122145814, 'dropout_rate_Layer_2': 0.0021313493701311252, 'dropout_rate_Layer_3': 0.28857244734815, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010114025846657995, 'l1_Layer_2': 0.00035890037877060575, 'l1_Layer_3': 6.214483857831664e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 270, 'n_units_Layer_3': 130}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.77 | sMAPE for Validation Set is: 11.99% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 7.78 | sMAPE for Test Set is: 28.21% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:13:36,826]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:13:45,993]\u001b[0m Trial 497 finished with value: 4.861041969409424 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013037337526225605, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3083673162175377, 'dropout_rate_Layer_2': 0.19374379693783475, 'dropout_rate_Layer_3': 0.33020249818467623, 'dropout_rate_Layer_4': 0.310190532677209, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0012672347562430058, 'l1_Layer_2': 0.013677263680881348, 'l1_Layer_3': 1.3379297192943396e-05, 'l1_Layer_4': 6.596218631732689e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 275, 'n_units_Layer_3': 200, 'n_units_Layer_4': 145}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 12.21% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 6.42 | sMAPE for Test Set is: 24.21% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:13:51,119]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:14:02,172]\u001b[0m Trial 503 finished with value: 4.697337504436628 and parameters: {'n_hidden': 3, 'learning_rate': 0.005326898270811858, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23427128193331795, 'dropout_rate_Layer_2': 0.001439815034282057, 'dropout_rate_Layer_3': 0.2909406950918458, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.861390144572616e-05, 'l1_Layer_2': 0.00041150228271298167, 'l1_Layer_3': 0.00013473020486088572, 'n_units_Layer_1': 215, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 11.80% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.95 | sMAPE for Test Set is: 28.72% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:14:08,688]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:14:12,320]\u001b[0m Trial 504 finished with value: 4.641943285958061 and parameters: {'n_hidden': 3, 'learning_rate': 0.005733130750193762, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2337438751260848, 'dropout_rate_Layer_2': 0.002557745675392662, 'dropout_rate_Layer_3': 0.2894404265416723, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010150812668937177, 'l1_Layer_2': 0.00035891287823108884, 'l1_Layer_3': 0.00010146603539939576, 'n_units_Layer_1': 215, 'n_units_Layer_2': 270, 'n_units_Layer_3': 160}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 11.63% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.89 | sMAPE for Test Set is: 28.58% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:14:16,195]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:14:19,558]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:14:27,450]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:14:32,499]\u001b[0m Trial 506 finished with value: 4.808703212045424 and parameters: {'n_hidden': 3, 'learning_rate': 0.005537546007801935, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2350210767155297, 'dropout_rate_Layer_2': 0.0003809434237357339, 'dropout_rate_Layer_3': 0.3054676936419148, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.77359838857424e-05, 'l1_Layer_2': 0.00035837000402870386, 'l1_Layer_3': 0.00013373978208312647, 'n_units_Layer_1': 215, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 12.08% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 8.23 | sMAPE for Test Set is: 29.47% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:14:36,169]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:14:36,910]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:14:41,508]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:14:45,361]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:14:56,963]\u001b[0m Trial 514 finished with value: 4.7348486887365295 and parameters: {'n_hidden': 3, 'learning_rate': 0.005427295639568538, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2349009833383597, 'dropout_rate_Layer_2': 0.0002269286144408766, 'dropout_rate_Layer_3': 0.2918576295095846, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.360094275921595e-05, 'l1_Layer_2': 0.00036578412559949036, 'l1_Layer_3': 0.0001289425545343136, 'n_units_Layer_1': 215, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 11.82% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 8.32 | sMAPE for Test Set is: 29.74% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:14:59,380]\u001b[0m Trial 511 finished with value: 4.72245578666417 and parameters: {'n_hidden': 3, 'learning_rate': 0.005275173038961268, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23513682984312406, 'dropout_rate_Layer_2': 0.0028864131174661735, 'dropout_rate_Layer_3': 0.28841829238512584, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.401330282038866e-05, 'l1_Layer_2': 0.00040741649949262957, 'l1_Layer_3': 0.00011958366258581538, 'n_units_Layer_1': 215, 'n_units_Layer_2': 270, 'n_units_Layer_3': 160}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 8.08 | sMAPE for Test Set is: 29.10% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:15:01,638]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:15:06,063]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:15:09,990]\u001b[0m Trial 516 finished with value: 4.691367533824075 and parameters: {'n_hidden': 3, 'learning_rate': 0.005326776407406799, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2471545231585984, 'dropout_rate_Layer_2': 0.002280417525244908, 'dropout_rate_Layer_3': 0.28757709112871704, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010029544542881154, 'l1_Layer_2': 0.00035553777443317363, 'l1_Layer_3': 0.00013036139645354256, 'n_units_Layer_1': 215, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 11.76% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 8.29 | sMAPE for Test Set is: 29.71% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:15:15,595]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:15:15,813]\u001b[0m Trial 498 finished with value: 4.975524183900219 and parameters: {'n_hidden': 4, 'learning_rate': 0.002967606185011413, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04867791965761163, 'dropout_rate_Layer_2': 0.141987782214062, 'dropout_rate_Layer_3': 0.05957350643026109, 'dropout_rate_Layer_4': 0.18825387083066272, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006598249086911397, 'l1_Layer_2': 0.0028635572593376755, 'l1_Layer_3': 0.023725445145753372, 'l1_Layer_4': 0.0007762148398527248, 'n_units_Layer_1': 170, 'n_units_Layer_2': 235, 'n_units_Layer_3': 155, 'n_units_Layer_4': 255}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 12.49% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 7.85 | sMAPE for Test Set is: 28.33% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:15:21,811]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:15:30,242]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:15:33,774]\u001b[0m Trial 519 finished with value: 4.717462697695087 and parameters: {'n_hidden': 3, 'learning_rate': 0.005180551907769096, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2477955543052715, 'dropout_rate_Layer_2': 0.001533268731775609, 'dropout_rate_Layer_3': 0.29090995366649547, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012267765525834722, 'l1_Layer_2': 0.00036718640082557025, 'l1_Layer_3': 0.00011761845834379527, 'n_units_Layer_1': 215, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.53 | sMAPE for Test Set is: 27.56% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:15:39,167]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:15:43,193]\u001b[0m Trial 524 finished with value: 4.641179899396843 and parameters: {'n_hidden': 3, 'learning_rate': 0.00519258833138823, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24759031115063673, 'dropout_rate_Layer_2': 0.0011632021313200958, 'dropout_rate_Layer_3': 0.28986751766212504, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011795605963956979, 'l1_Layer_2': 0.00038002915381692083, 'l1_Layer_3': 0.0001390433473090539, 'n_units_Layer_1': 220, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 11.64% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 8.24 | sMAPE for Test Set is: 29.47% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:15:53,327]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:16:11,620]\u001b[0m Trial 527 finished with value: 4.762943350909143 and parameters: {'n_hidden': 3, 'learning_rate': 0.00550570509428039, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.236720483586509, 'dropout_rate_Layer_2': 0.0016330938285825458, 'dropout_rate_Layer_3': 0.28972972974808403, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012270712961798066, 'l1_Layer_2': 0.0003736667116443683, 'l1_Layer_3': 0.000137981260571129, 'n_units_Layer_1': 220, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 11.98% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 7.83 | sMAPE for Test Set is: 28.34% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:16:19,266]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:16:31,598]\u001b[0m Trial 528 finished with value: 4.7673050447016445 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007847756463586443, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3996449739287137, 'dropout_rate_Layer_2': 0.2541988606878332, 'dropout_rate_Layer_3': 0.33993185292482037, 'dropout_rate_Layer_4': 0.28221165637353485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007995865906384835, 'l1_Layer_2': 0.012540072145630897, 'l1_Layer_3': 3.488065440756521e-05, 'l1_Layer_4': 2.9633871825637605e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 260, 'n_units_Layer_3': 210, 'n_units_Layer_4': 185}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.77 | sMAPE for Validation Set is: 12.00% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 22.62% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:16:33,260]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:16:37,762]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:16:41,846]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:16:45,469]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:16:46,959]\u001b[0m Trial 531 finished with value: 4.6374729363567555 and parameters: {'n_hidden': 3, 'learning_rate': 0.004977360744914256, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2478380779447405, 'dropout_rate_Layer_2': 0.0007230324951222455, 'dropout_rate_Layer_3': 0.29319573424230844, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012346303181285647, 'l1_Layer_2': 0.0004471968015834668, 'l1_Layer_3': 0.00011016204170405977, 'n_units_Layer_1': 215, 'n_units_Layer_2': 260, 'n_units_Layer_3': 160}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 11.65% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.81 | sMAPE for Test Set is: 28.40% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:16:54,996]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:16:58,178]\u001b[0m Trial 529 finished with value: 5.302934731185103 and parameters: {'n_hidden': 4, 'learning_rate': 0.0045324227080159605, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02198104649997086, 'dropout_rate_Layer_2': 0.14287135266309053, 'dropout_rate_Layer_3': 0.05094994519470242, 'dropout_rate_Layer_4': 0.31093397523341415, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005553692146748435, 'l1_Layer_2': 0.04987518991837681, 'l1_Layer_3': 0.049642112437643764, 'l1_Layer_4': 0.0009548843102878454, 'n_units_Layer_1': 165, 'n_units_Layer_2': 225, 'n_units_Layer_3': 145, 'n_units_Layer_4': 265}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 13.30% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 9.03 | sMAPE for Test Set is: 31.45% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:17:03,112]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:17:03,635]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:17:04,035]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:17:11,325]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:17:11,961]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:17:17,652]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:17:18,057]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:17:23,874]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:17:26,975]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:17:32,176]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:17:32,195]\u001b[0m Trial 541 finished with value: 4.617643508795697 and parameters: {'n_hidden': 3, 'learning_rate': 0.004566566278869153, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26284650080592525, 'dropout_rate_Layer_2': 0.014031847868549698, 'dropout_rate_Layer_3': 0.2870394494879812, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016015780347932766, 'l1_Layer_2': 0.00029224670624385416, 'l1_Layer_3': 0.0001488237539569968, 'n_units_Layer_1': 220, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 11.58% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 8.14 | sMAPE for Test Set is: 29.25% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:17:40,956]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:17:45,406]\u001b[0m Trial 547 finished with value: 4.6735701657229525 and parameters: {'n_hidden': 3, 'learning_rate': 0.005543361543822631, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24974304053539764, 'dropout_rate_Layer_2': 0.0010053702581199024, 'dropout_rate_Layer_3': 0.2814448287350815, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.61020250968313e-05, 'l1_Layer_2': 0.0003266308144864183, 'l1_Layer_3': 0.0001338790415830145, 'n_units_Layer_1': 205, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 11.75% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 8.08 | sMAPE for Test Set is: 29.04% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:17:46,898]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:17:53,219]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:17:55,290]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:18:04,056]\u001b[0m Trial 551 finished with value: 4.6830417837821345 and parameters: {'n_hidden': 3, 'learning_rate': 0.005125298605047171, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2519736920259272, 'dropout_rate_Layer_2': 0.02082289953668493, 'dropout_rate_Layer_3': 0.2834044801352597, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001542206848303909, 'l1_Layer_2': 0.0005072636606377386, 'l1_Layer_3': 0.00014258006331922766, 'n_units_Layer_1': 210, 'n_units_Layer_2': 275, 'n_units_Layer_3': 160}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 11.71% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 8.04 | sMAPE for Test Set is: 28.99% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:18:08,308]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:18:10,692]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:18:13,634]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:18:15,455]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:18:18,465]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:18:21,771]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:18:24,555]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:18:27,928]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:18:41,907]\u001b[0m Trial 562 finished with value: 4.711412607935331 and parameters: {'n_hidden': 3, 'learning_rate': 0.006277758040798341, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2568593960897173, 'dropout_rate_Layer_2': 0.012068114617661307, 'dropout_rate_Layer_3': 0.3096756360252725, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.53768486997047e-05, 'l1_Layer_2': 0.0005995697998176123, 'l1_Layer_3': 9.672351202429478e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 260, 'n_units_Layer_3': 160}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 11.79% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 8.16 | sMAPE for Test Set is: 29.30% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:18:49,379]\u001b[0m Trial 536 finished with value: 5.146822592000055 and parameters: {'n_hidden': 4, 'learning_rate': 0.004148400892786806, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030687954711558885, 'dropout_rate_Layer_2': 0.09359380315865555, 'dropout_rate_Layer_3': 0.054300489235469596, 'dropout_rate_Layer_4': 0.1901459082779842, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004989334074421591, 'l1_Layer_2': 0.06581455947426751, 'l1_Layer_3': 0.028145534191719373, 'l1_Layer_4': 0.006591405348583408, 'n_units_Layer_1': 160, 'n_units_Layer_2': 245, 'n_units_Layer_3': 295, 'n_units_Layer_4': 245}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:18:49,537]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 12.93% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 8.28 | sMAPE for Test Set is: 29.50% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:18:57,983]\u001b[0m Trial 563 finished with value: 4.811480628782587 and parameters: {'n_hidden': 3, 'learning_rate': 0.005964146636116382, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25440523723026126, 'dropout_rate_Layer_2': 0.011335481727232177, 'dropout_rate_Layer_3': 0.3126389535888175, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001886211299202577, 'l1_Layer_2': 0.0006141713245854062, 'l1_Layer_3': 0.00018714503801553256, 'n_units_Layer_1': 210, 'n_units_Layer_2': 260, 'n_units_Layer_3': 160}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:18:58,128]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 12.14% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 7.77 | sMAPE for Test Set is: 28.25% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:19:03,096]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:19:08,645]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:19:08,707]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:19:09,134]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:19:16,887]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:19:24,373]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:19:35,262]\u001b[0m Trial 571 finished with value: 4.67535399781481 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037360576169730994, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24501561809238007, 'dropout_rate_Layer_2': 0.019408064425674554, 'dropout_rate_Layer_3': 0.26945046297541336, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.973053298164059e-05, 'l1_Layer_2': 0.00023966070644131215, 'l1_Layer_3': 7.871051462390562e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 275, 'n_units_Layer_3': 165}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.86 | sMAPE for Test Set is: 28.54% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:19:35,535]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:19:36,691]\u001b[0m Trial 572 finished with value: 4.72513254631831 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037017854996794592, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24542732389391542, 'dropout_rate_Layer_2': 0.01951372039450164, 'dropout_rate_Layer_3': 0.2697870393670967, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.140095501811906e-05, 'l1_Layer_2': 0.00023773812053288788, 'l1_Layer_3': 8.015417510285697e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 275, 'n_units_Layer_3': 170}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 11.86% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 8.28 | sMAPE for Test Set is: 29.53% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:19:44,234]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:19:48,307]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:19:53,478]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:20:03,411]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:20:09,507]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:20:12,520]\u001b[0m Trial 576 finished with value: 4.740853970934336 and parameters: {'n_hidden': 3, 'learning_rate': 0.003864883665400726, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2500421485520635, 'dropout_rate_Layer_2': 0.025838927229803525, 'dropout_rate_Layer_3': 0.26955304729276625, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.540283041759785e-05, 'l1_Layer_2': 0.0002941255515692717, 'l1_Layer_3': 0.00016073289084665541, 'n_units_Layer_1': 205, 'n_units_Layer_2': 255, 'n_units_Layer_3': 170}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 11.82% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 7.85 | sMAPE for Test Set is: 28.44% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:20:14,877]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:20:18,081]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:20:23,133]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:20:31,590]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:20:32,156]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:20:32,277]\u001b[0m Trial 564 finished with value: 5.296096029254977 and parameters: {'n_hidden': 4, 'learning_rate': 0.00431106704719897, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07902234584229302, 'dropout_rate_Layer_2': 0.09084346314424577, 'dropout_rate_Layer_3': 2.7757831430724397e-05, 'dropout_rate_Layer_4': 0.20227089976978896, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000470575474553465, 'l1_Layer_2': 0.002415241973652541, 'l1_Layer_3': 0.009568858690753137, 'l1_Layer_4': 0.0008283166911213146, 'n_units_Layer_1': 160, 'n_units_Layer_2': 225, 'n_units_Layer_3': 115, 'n_units_Layer_4': 255}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 13.34% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 8.43 | sMAPE for Test Set is: 29.92% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:20:38,357]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:20:41,583]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:20:50,608]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:20:51,075]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:20:52,345]\u001b[0m Trial 587 finished with value: 4.6696659809251075 and parameters: {'n_hidden': 3, 'learning_rate': 0.004321255769101935, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2595862512843422, 'dropout_rate_Layer_2': 0.008968868235175608, 'dropout_rate_Layer_3': 0.2791037467912277, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010080885233446813, 'l1_Layer_2': 0.00042361693271681977, 'l1_Layer_3': 0.0001026572418125249, 'n_units_Layer_1': 215, 'n_units_Layer_2': 265, 'n_units_Layer_3': 150}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 11.76% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.72 | sMAPE for Test Set is: 28.12% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:20:58,157]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:20:58,499]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:20:59,265]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:21:05,022]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:21:05,543]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:21:05,544]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:21:11,237]\u001b[0m Trial 591 finished with value: 4.740965703443886 and parameters: {'n_hidden': 3, 'learning_rate': 0.004860000876839084, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2599716939853524, 'dropout_rate_Layer_2': 0.009940033162823212, 'dropout_rate_Layer_3': 0.3201080790009375, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012951315884319965, 'l1_Layer_2': 0.0005527998736815883, 'l1_Layer_3': 9.80837786618288e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 280, 'n_units_Layer_3': 160}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 11.97% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 7.72 | sMAPE for Test Set is: 28.08% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:21:11,540]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:21:17,490]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:21:17,934]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:21:23,121]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:21:27,125]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:21:30,689]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:21:31,313]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:21:33,667]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:21:44,213]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:21:48,884]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:21:56,493]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 11.73% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 8.35 | sMAPE for Test Set is: 29.83% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:22:02,456]\u001b[0m Trial 610 finished with value: 4.6908984974553904 and parameters: {'n_hidden': 3, 'learning_rate': 0.004295001004500004, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2594889512949114, 'dropout_rate_Layer_2': 0.009008435059196815, 'dropout_rate_Layer_3': 0.29698877156046327, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018491236537802457, 'l1_Layer_2': 0.00018255815224607478, 'l1_Layer_3': 0.0001682328168557658, 'n_units_Layer_1': 230, 'n_units_Layer_2': 265, 'n_units_Layer_3': 165}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:22:04,482]\u001b[0m Trial 600 finished with value: 5.115830949937831 and parameters: {'n_hidden': 4, 'learning_rate': 0.0044234161692458035, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06379725464422588, 'dropout_rate_Layer_2': 0.10846144098480298, 'dropout_rate_Layer_3': 0.03395582488330519, 'dropout_rate_Layer_4': 0.27902979729190314, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0144873514564861e-05, 'l1_Layer_2': 0.011055802057324225, 'l1_Layer_3': 0.030531050598406155, 'l1_Layer_4': 0.0013063172173336433, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 120, 'n_units_Layer_4': 225}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 12.85% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 8.42 | sMAPE for Test Set is: 29.82% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:22:07,583]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:22:09,697]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:22:13,058]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:22:15,755]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:22:16,444]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:22:21,799]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:22:26,094]\u001b[0m Trial 613 finished with value: 4.706153138105651 and parameters: {'n_hidden': 3, 'learning_rate': 0.004379266143789669, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2586344812389446, 'dropout_rate_Layer_2': 0.008900780169088112, 'dropout_rate_Layer_3': 0.29686204955226353, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001518809040923302, 'l1_Layer_2': 0.0002346319855795878, 'l1_Layer_3': 0.0001675290406226427, 'n_units_Layer_1': 230, 'n_units_Layer_2': 265, 'n_units_Layer_3': 165}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 11.76% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 8.10 | sMAPE for Test Set is: 29.10% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:22:29,180]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:22:29,625]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:22:35,439]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:22:40,130]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:22:41,777]\u001b[0m Trial 618 finished with value: 4.645655287462017 and parameters: {'n_hidden': 3, 'learning_rate': 0.0042893649595445935, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2589559303577473, 'dropout_rate_Layer_2': 0.008896826523912037, 'dropout_rate_Layer_3': 0.2984439278345257, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014712468115123068, 'l1_Layer_2': 0.00017569831066426508, 'l1_Layer_3': 0.000206736374079893, 'n_units_Layer_1': 210, 'n_units_Layer_2': 265, 'n_units_Layer_3': 165}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 11.66% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 8.30 | sMAPE for Test Set is: 29.72% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:22:45,446]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:22:46,135]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:22:46,305]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:22:51,746]\u001b[0m Trial 621 finished with value: 4.723287736494892 and parameters: {'n_hidden': 3, 'learning_rate': 0.004999995995199156, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26062213265093004, 'dropout_rate_Layer_2': 0.007522382791561394, 'dropout_rate_Layer_3': 0.3028288897972999, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013452836486810198, 'l1_Layer_2': 0.00012733552518794236, 'l1_Layer_3': 0.00020758778056024065, 'n_units_Layer_1': 210, 'n_units_Layer_2': 265, 'n_units_Layer_3': 165}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 11.84% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 8.07 | sMAPE for Test Set is: 29.09% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:22:54,842]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:22:56,720]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:22:57,326]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:04,870]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:05,288]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:13,110]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:13,967]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:18,972]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:20,037]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:20,038]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:25,415]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:29,209]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:29,938]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:32,022]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:34,400]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:36,471]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:39,773]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:39,918]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:41,259]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:46,080]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:48,201]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:50,266]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:58,105]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:23:58,367]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:24:06,067]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:24:09,096]\u001b[0m Trial 652 finished with value: 4.750695972513664 and parameters: {'n_hidden': 3, 'learning_rate': 0.006785111545681078, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2681262613282071, 'dropout_rate_Layer_2': 0.012981138299927645, 'dropout_rate_Layer_3': 0.2796686318626151, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011286639113743962, 'l1_Layer_2': 0.00021537071584863056, 'l1_Layer_3': 0.00014842964904867364, 'n_units_Layer_1': 225, 'n_units_Layer_2': 280, 'n_units_Layer_3': 145}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 11.86% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 7.86 | sMAPE for Test Set is: 28.46% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:24:15,707]\u001b[0m Trial 643 finished with value: 4.982318304628411 and parameters: {'n_hidden': 3, 'learning_rate': 0.005274457080397674, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05102851453138517, 'dropout_rate_Layer_2': 0.20534460502104246, 'dropout_rate_Layer_3': 0.022016229385884337, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0009103818276477306, 'l1_Layer_2': 0.008147229598186735, 'l1_Layer_3': 0.000739490725517832, 'n_units_Layer_1': 90, 'n_units_Layer_2': 115, 'n_units_Layer_3': 155}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 12.36% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 7.92 | sMAPE for Test Set is: 28.61% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:24:20,172]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:24:23,603]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:24:27,351]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:24:30,594]\u001b[0m Trial 655 finished with value: 4.740039728615759 and parameters: {'n_hidden': 3, 'learning_rate': 0.006249380306796647, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25366427846913675, 'dropout_rate_Layer_2': 0.015589787849690648, 'dropout_rate_Layer_3': 0.27932008977022027, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014689003155242964, 'l1_Layer_2': 0.00023478774431374017, 'l1_Layer_3': 0.0001415927435813907, 'n_units_Layer_1': 220, 'n_units_Layer_2': 260, 'n_units_Layer_3': 155}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 11.82% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 8.30 | sMAPE for Test Set is: 29.71% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:24:36,587]\u001b[0m Trial 658 finished with value: 4.682321185959117 and parameters: {'n_hidden': 3, 'learning_rate': 0.004680584386750337, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2525311984612417, 'dropout_rate_Layer_2': 0.02401365436616853, 'dropout_rate_Layer_3': 0.3141733202495883, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001547126159910737, 'l1_Layer_2': 0.00013465228203422575, 'l1_Layer_3': 0.00010333660353902193, 'n_units_Layer_1': 210, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:24:36,661]\u001b[0m Trial 657 finished with value: 4.694957900908627 and parameters: {'n_hidden': 3, 'learning_rate': 0.004664990395715108, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25307186820011907, 'dropout_rate_Layer_2': 0.022307161773461613, 'dropout_rate_Layer_3': 0.3161790516410578, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029004076139992595, 'l1_Layer_2': 0.0005416986744301508, 'l1_Layer_3': 0.00011647501300097474, 'n_units_Layer_1': 210, 'n_units_Layer_2': 270, 'n_units_Layer_3': 175}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.68 | sMAPE for Validation Set is: 11.75% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 8.10 | sMAPE for Test Set is: 29.10% | rMAE for Test Set is: 1.02\n",
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 11.77% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 8.20 | sMAPE for Test Set is: 29.40% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:24:36,882]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:24:44,363]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:24:44,552]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:24:46,960]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:25:00,358]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:25:01,087]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:25:06,802]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:25:22,037]\u001b[0m Trial 661 finished with value: 4.644916207572823 and parameters: {'n_hidden': 3, 'learning_rate': 0.006516864248391223, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11019127194050757, 'dropout_rate_Layer_2': 0.16352075908823507, 'dropout_rate_Layer_3': 0.04009803908336575, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0014285344565181557, 'l1_Layer_2': 0.001851855123179568, 'l1_Layer_3': 0.0011290565090058273, 'n_units_Layer_1': 130, 'n_units_Layer_2': 125, 'n_units_Layer_3': 185}. Best is trial 260 with value: 4.579152852152535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 11.65% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 8.01 | sMAPE for Test Set is: 28.89% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:25:25,925]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:25:29,593]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:25:33,427]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:25:38,796]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:25:44,844]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:25:47,529]\u001b[0m Trial 666 finished with value: 4.547109999274852 and parameters: {'n_hidden': 3, 'learning_rate': 0.004181737369862029, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1043914061118883, 'dropout_rate_Layer_2': 0.1595267709673235, 'dropout_rate_Layer_3': 0.039468632424130096, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002730041575130321, 'l1_Layer_2': 0.0022387659464285586, 'l1_Layer_3': 0.0013435422581529006, 'n_units_Layer_1': 65, 'n_units_Layer_2': 125, 'n_units_Layer_3': 125}. Best is trial 666 with value: 4.547109999274852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 11.40% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 7.43 | sMAPE for Test Set is: 27.25% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:25:50,854]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:25:53,754]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:25:58,871]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:25:59,512]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:26:03,153]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:26:07,169]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:26:12,723]\u001b[0m Trial 674 finished with value: 4.758538338254506 and parameters: {'n_hidden': 3, 'learning_rate': 0.011559711502277328, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16528775284241964, 'dropout_rate_Layer_2': 0.16645279137609129, 'dropout_rate_Layer_3': 0.04376888563844992, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0013970055674863064, 'l1_Layer_2': 0.0015984255334031742, 'l1_Layer_3': 0.0017748997438063949, 'n_units_Layer_1': 130, 'n_units_Layer_2': 90, 'n_units_Layer_3': 190}. Best is trial 666 with value: 4.547109999274852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 8.15 | sMAPE for Test Set is: 29.26% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:26:17,936]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:26:22,357]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:26:24,769]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:26:31,412]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:26:31,942]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:26:32,049]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:26:32,192]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:26:40,002]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:26:42,434]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:26:42,687]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:26:52,884]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:26:58,599]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:26:58,833]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:27:02,489]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:27:05,839]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:27:06,520]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:27:06,752]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:27:14,308]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:27:18,559]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:27:18,819]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:27:18,995]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:27:29,439]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:27:31,882]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:27:36,584]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:27:41,334]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:27:44,029]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:27:49,496]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:27:53,170]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:27:53,331]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:28:00,627]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:28:01,139]\u001b[0m Trial 706 finished with value: 4.661372883217738 and parameters: {'n_hidden': 3, 'learning_rate': 0.003925608670123204, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2056954674104094, 'dropout_rate_Layer_2': 0.10777171259285581, 'dropout_rate_Layer_3': 0.30279860973458916, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0024498817294638093, 'l1_Layer_2': 0.0008656744570036267, 'l1_Layer_3': 0.001167953841770111, 'n_units_Layer_1': 125, 'n_units_Layer_2': 90, 'n_units_Layer_3': 170}. Best is trial 666 with value: 4.547109999274852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.66 | sMAPE for Validation Set is: 11.64% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.25 | sMAPE for Test Set is: 26.72% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:28:09,838]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:28:12,901]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:28:14,809]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:28:19,299]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:28:23,375]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:28:28,610]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:28:40,518]\u001b[0m Trial 716 finished with value: 5.216551012539997 and parameters: {'n_hidden': 4, 'learning_rate': 0.004201395586031735, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016537993846078763, 'dropout_rate_Layer_2': 0.12365233172276203, 'dropout_rate_Layer_3': 0.14698028366909566, 'dropout_rate_Layer_4': 0.18284357849650454, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.694657430234681e-05, 'l1_Layer_2': 0.026437989912031862, 'l1_Layer_3': 0.006308788261901912, 'l1_Layer_4': 0.0008101492109540986, 'n_units_Layer_1': 150, 'n_units_Layer_2': 220, 'n_units_Layer_3': 295, 'n_units_Layer_4': 280}. Best is trial 666 with value: 4.547109999274852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.22 | sMAPE for Validation Set is: 13.04% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 9.22 | sMAPE for Test Set is: 31.81% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:28:45,431]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:28:52,031]\u001b[0m Trial 710 finished with value: 5.185310788305556 and parameters: {'n_hidden': 4, 'learning_rate': 0.004347534247766952, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.035598273379961146, 'dropout_rate_Layer_2': 0.12452788336696369, 'dropout_rate_Layer_3': 0.30679587692927485, 'dropout_rate_Layer_4': 0.08211442586710536, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005582688923997509, 'l1_Layer_2': 0.012825945684592844, 'l1_Layer_3': 0.05050761171360444, 'l1_Layer_4': 0.0006920581514892025, 'n_units_Layer_1': 205, 'n_units_Layer_2': 215, 'n_units_Layer_3': 125, 'n_units_Layer_4': 290}. Best is trial 666 with value: 4.547109999274852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 13.06% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 9.31 | sMAPE for Test Set is: 32.09% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:28:57,334]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:29:00,039]\u001b[0m Trial 722 finished with value: 4.687129412469917 and parameters: {'n_hidden': 3, 'learning_rate': 0.003441538555922682, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2805163236324176, 'dropout_rate_Layer_2': 0.014838150589057192, 'dropout_rate_Layer_3': 0.2754894291185971, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.544632559708312e-05, 'l1_Layer_2': 0.0003227960283076171, 'l1_Layer_3': 0.00016156293704681755, 'n_units_Layer_1': 200, 'n_units_Layer_2': 250, 'n_units_Layer_3': 140}. Best is trial 666 with value: 4.547109999274852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 11.78% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.88 | sMAPE for Test Set is: 28.49% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:29:03,422]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:29:09,080]\u001b[0m Trial 719 finished with value: 4.482586912895714 and parameters: {'n_hidden': 3, 'learning_rate': 0.005710054778561373, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2541892421138335, 'dropout_rate_Layer_2': 0.15739004125674033, 'dropout_rate_Layer_3': 0.3603820122592959, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0010100406032979416, 'l1_Layer_2': 0.0015567910269988234, 'l1_Layer_3': 0.002000341254730467, 'n_units_Layer_1': 110, 'n_units_Layer_2': 80, 'n_units_Layer_3': 165}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.48 | sMAPE for Validation Set is: 11.24% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 24.49% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:29:15,130]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:29:18,813]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:29:32,470]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:29:34,082]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:29:35,035]\u001b[0m Trial 728 finished with value: 4.656682162444684 and parameters: {'n_hidden': 3, 'learning_rate': 0.00348037662937063, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2782199259250219, 'dropout_rate_Layer_2': 0.017391510031111383, 'dropout_rate_Layer_3': 0.27472645375862154, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015309290807877365, 'l1_Layer_2': 0.00030920577675295547, 'l1_Layer_3': 0.0001607942212563974, 'n_units_Layer_1': 215, 'n_units_Layer_2': 250, 'n_units_Layer_3': 140}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.66 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.73 | sMAPE for Test Set is: 28.14% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:29:36,611]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:29:40,634]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:29:43,278]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:29:44,677]\u001b[0m Trial 727 finished with value: 4.698746381312109 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035975208227447264, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2760732432437276, 'dropout_rate_Layer_2': 0.02129602989806234, 'dropout_rate_Layer_3': 0.2536460613530824, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00038106098697699125, 'l1_Layer_2': 0.0003075517828170013, 'l1_Layer_3': 0.00023753558947567664, 'n_units_Layer_1': 215, 'n_units_Layer_2': 250, 'n_units_Layer_3': 140}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 11.79% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.52 | sMAPE for Test Set is: 27.52% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:29:49,372]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:29:49,548]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:29:51,598]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:29:56,977]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:29:58,108]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:29:58,180]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:30:01,852]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:30:02,424]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:30:05,889]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:30:09,251]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:30:10,418]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:30:17,711]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:30:21,416]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:30:25,695]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:30:34,380]\u001b[0m Trial 744 finished with value: 4.692896019591077 and parameters: {'n_hidden': 3, 'learning_rate': 0.006376936459881151, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26979747336925025, 'dropout_rate_Layer_2': 0.19024838249982162, 'dropout_rate_Layer_3': 0.3271569097507114, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0009126588676775336, 'l1_Layer_2': 0.0025700838007783403, 'l1_Layer_3': 0.0009954747188605378, 'n_units_Layer_1': 105, 'n_units_Layer_2': 60, 'n_units_Layer_3': 120}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 11.72% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 25.61% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:30:37,926]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:30:41,881]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:30:41,906]\u001b[0m Trial 747 finished with value: 4.645853790437709 and parameters: {'n_hidden': 3, 'learning_rate': 0.006164790495862132, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27332033076701145, 'dropout_rate_Layer_2': 0.11598477723608688, 'dropout_rate_Layer_3': 0.3623720180498243, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0009835521671625396, 'l1_Layer_2': 0.0004417468535142443, 'l1_Layer_3': 0.000634448448599747, 'n_units_Layer_1': 105, 'n_units_Layer_2': 60, 'n_units_Layer_3': 170}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 11.69% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.69 | sMAPE for Test Set is: 27.99% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:30:46,824]\u001b[0m Trial 749 finished with value: 4.665899537155748 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034300290170944095, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2760829149070033, 'dropout_rate_Layer_2': 0.02263585683768384, 'dropout_rate_Layer_3': 0.2737997507036547, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010729334441900053, 'l1_Layer_2': 0.00031336306767350026, 'l1_Layer_3': 0.00021409799751884406, 'n_units_Layer_1': 210, 'n_units_Layer_2': 250, 'n_units_Layer_3': 140}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 8.03 | sMAPE for Test Set is: 28.97% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:30:50,415]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:30:54,075]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:31:01,583]\u001b[0m Trial 752 finished with value: 4.645082910598101 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031092992240697457, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27845527419536487, 'dropout_rate_Layer_2': 0.022820955143077158, 'dropout_rate_Layer_3': 0.2638400446501182, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010608844499511276, 'l1_Layer_2': 0.0003104422631253898, 'l1_Layer_3': 0.00020463665461858675, 'n_units_Layer_1': 210, 'n_units_Layer_2': 255, 'n_units_Layer_3': 140}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 11.64% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.83 | sMAPE for Test Set is: 28.41% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:31:02,091]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:31:07,801]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:31:11,466]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:31:19,279]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:31:30,445]\u001b[0m Trial 760 finished with value: 4.59887117567897 and parameters: {'n_hidden': 3, 'learning_rate': 0.003601913425532252, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26598271446918903, 'dropout_rate_Layer_2': 0.015477360806634425, 'dropout_rate_Layer_3': 0.27351650599941346, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010710968028334588, 'l1_Layer_2': 0.0004339707947812938, 'l1_Layer_3': 0.00014801788369617094, 'n_units_Layer_1': 215, 'n_units_Layer_2': 245, 'n_units_Layer_3': 145}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 11.56% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 7.96 | sMAPE for Test Set is: 28.81% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:31:31,246]\u001b[0m Trial 763 finished with value: 4.665562340027793 and parameters: {'n_hidden': 3, 'learning_rate': 0.003535636796220006, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2668826835838385, 'dropout_rate_Layer_2': 0.014693839435895304, 'dropout_rate_Layer_3': 0.2836928326374033, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.235636461413859e-05, 'l1_Layer_2': 0.00032893832099767617, 'l1_Layer_3': 0.0002901717087307055, 'n_units_Layer_1': 200, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 8.17 | sMAPE for Test Set is: 29.35% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:31:35,421]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:31:36,116]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:31:46,656]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:31:49,848]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:31:54,700]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:32:00,567]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:32:04,386]\u001b[0m Trial 762 finished with value: 4.896004709735707 and parameters: {'n_hidden': 4, 'learning_rate': 0.005325394331114896, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.048297242141846636, 'dropout_rate_Layer_2': 0.11935915371425235, 'dropout_rate_Layer_3': 0.14988000138781038, 'dropout_rate_Layer_4': 0.0555921597103225, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004286882115072303, 'l1_Layer_2': 0.011483650308523923, 'l1_Layer_3': 0.004280199644921635, 'l1_Layer_4': 0.00011618762505582777, 'n_units_Layer_1': 175, 'n_units_Layer_2': 220, 'n_units_Layer_3': 115, 'n_units_Layer_4': 270}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 12.29% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 8.22 | sMAPE for Test Set is: 29.43% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:32:04,582]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:32:06,071]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:32:06,569]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:32:12,602]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:32:13,199]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:32:22,283]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:32:24,398]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:32:31,080]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:32:38,236]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:32:41,676]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:32:45,951]\u001b[0m Trial 776 finished with value: 4.7501144311503545 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036881672567318836, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2654073686026563, 'dropout_rate_Layer_2': 0.014594240238827034, 'dropout_rate_Layer_3': 0.27522132328069737, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.204153244368507e-05, 'l1_Layer_2': 0.0003373601529844768, 'l1_Layer_3': 0.0002785233758669873, 'n_units_Layer_1': 195, 'n_units_Layer_2': 245, 'n_units_Layer_3': 140}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 8.06 | sMAPE for Test Set is: 29.03% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:32:49,490]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:32:51,665]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:32:58,233]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:32:58,980]\u001b[0m Trial 773 finished with value: 4.893598595331501 and parameters: {'n_hidden': 4, 'learning_rate': 0.0057651953768298025, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05948803245591401, 'dropout_rate_Layer_2': 0.1145611101540148, 'dropout_rate_Layer_3': 0.16453411616528923, 'dropout_rate_Layer_4': 0.38806688658448135, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00017554990938743766, 'l1_Layer_2': 0.010397398744810438, 'l1_Layer_3': 0.0032489581087033824, 'l1_Layer_4': 6.091818396203007e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 215, 'n_units_Layer_3': 105, 'n_units_Layer_4': 265}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 12.26% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 8.27 | sMAPE for Test Set is: 29.55% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:33:03,228]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:33:03,700]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:33:04,832]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:33:10,413]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:33:10,738]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:33:11,951]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:33:17,977]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:33:20,020]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:33:23,223]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:33:28,446]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:33:36,920]\u001b[0m Trial 793 finished with value: 4.781143052129551 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018937782318029566, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29538370359793426, 'dropout_rate_Layer_2': 0.09016845927668939, 'dropout_rate_Layer_3': 0.3075187233190107, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.001873299666700334, 'l1_Layer_2': 7.678836211513345e-05, 'l1_Layer_3': 0.0005431619415022186, 'n_units_Layer_1': 105, 'n_units_Layer_2': 85, 'n_units_Layer_3': 145}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 7.32 | sMAPE for Test Set is: 26.86% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:33:37,451]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:33:38,466]\u001b[0m Trial 790 finished with value: 4.694906306320061 and parameters: {'n_hidden': 3, 'learning_rate': 0.004427504707527732, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2871848670404974, 'dropout_rate_Layer_2': 0.025161045733417268, 'dropout_rate_Layer_3': 0.2840337675353533, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010506622442182817, 'l1_Layer_2': 0.000525598936195588, 'l1_Layer_3': 0.00017992689103160875, 'n_units_Layer_1': 210, 'n_units_Layer_2': 265, 'n_units_Layer_3': 150}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 11.79% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 8.30 | sMAPE for Test Set is: 29.63% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:33:45,173]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:33:45,975]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:33:46,724]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:33:52,310]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:33:57,376]\u001b[0m Trial 798 finished with value: 4.6903065850970025 and parameters: {'n_hidden': 3, 'learning_rate': 0.0039169387137104284, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2721883727242115, 'dropout_rate_Layer_2': 0.022721687836486964, 'dropout_rate_Layer_3': 0.28669701746929976, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011305474294023488, 'l1_Layer_2': 0.000144640394323354, 'l1_Layer_3': 0.00017358168510236984, 'n_units_Layer_1': 210, 'n_units_Layer_2': 265, 'n_units_Layer_3': 150}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.69 | sMAPE for Validation Set is: 11.77% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.74 | sMAPE for Test Set is: 28.17% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:33:57,831]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:34:00,255]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:34:09,930]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:34:12,837]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:34:14,917]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:34:15,780]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:34:19,868]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:34:20,479]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:34:26,576]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:34:31,502]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:34:32,165]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:34:36,929]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:34:40,507]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:34:47,322]\u001b[0m Trial 812 finished with value: 4.734416136128942 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037923290901619674, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26160263338006257, 'dropout_rate_Layer_2': 0.014991924577306205, 'dropout_rate_Layer_3': 0.2841997618325986, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.761948621305143e-05, 'l1_Layer_2': 0.00010693946756035911, 'l1_Layer_3': 0.00014688455024398743, 'n_units_Layer_1': 200, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 11.95% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 7.90 | sMAPE for Test Set is: 28.52% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:34:49,351]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:34:53,557]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:34:59,451]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:34:59,940]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:35:06,033]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:35:09,643]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:35:14,546]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:35:15,361]\u001b[0m Trial 817 finished with value: 4.751036327502359 and parameters: {'n_hidden': 3, 'learning_rate': 0.004499056374808032, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2783258307327224, 'dropout_rate_Layer_2': 0.016728161523087773, 'dropout_rate_Layer_3': 0.2863972561042616, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010354206410167933, 'l1_Layer_2': 0.0004616279062120096, 'l1_Layer_3': 0.00019395857214085419, 'n_units_Layer_1': 205, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 11.91% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 7.85 | sMAPE for Test Set is: 28.46% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:35:16,280]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:35:22,460]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:35:26,465]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:35:31,719]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 11.64% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.49 | sMAPE for Test Set is: 27.40% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:35:32,984]\u001b[0m Trial 824 finished with value: 4.617957948217623 and parameters: {'n_hidden': 3, 'learning_rate': 0.0062769921116937934, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2837050214400569, 'dropout_rate_Layer_2': 0.1451998334807841, 'dropout_rate_Layer_3': 0.3321609752533441, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0008046945640234905, 'l1_Layer_2': 0.002736105705292074, 'l1_Layer_3': 0.0009110986038028586, 'n_units_Layer_1': 105, 'n_units_Layer_2': 60, 'n_units_Layer_3': 125}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:35:38,879]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:35:45,482]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:35:47,924]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:35:53,054]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:36:03,410]\u001b[0m Trial 831 finished with value: 4.7158786370190375 and parameters: {'n_hidden': 3, 'learning_rate': 0.003498568546804475, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28816311586947324, 'dropout_rate_Layer_2': 0.031749237388347465, 'dropout_rate_Layer_3': 0.27301874038593105, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012250608527458192, 'l1_Layer_2': 0.0003403224507417458, 'l1_Layer_3': 0.00023362967817481688, 'n_units_Layer_1': 220, 'n_units_Layer_2': 265, 'n_units_Layer_3': 155}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 11.79% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.96 | sMAPE for Test Set is: 28.73% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:36:04,882]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:36:08,422]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:36:14,662]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:36:18,972]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:36:22,687]\u001b[0m Trial 835 finished with value: 4.611603085865966 and parameters: {'n_hidden': 3, 'learning_rate': 0.003435560594167524, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2888877558215752, 'dropout_rate_Layer_2': 0.03134135223202146, 'dropout_rate_Layer_3': 0.27372075559856024, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011711244869395234, 'l1_Layer_2': 0.0003622791224713504, 'l1_Layer_3': 0.0002672237270496499, 'n_units_Layer_1': 220, 'n_units_Layer_2': 265, 'n_units_Layer_3': 155}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 11.56% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.96 | sMAPE for Test Set is: 28.78% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:36:26,707]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:36:27,196]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:36:33,570]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:36:33,812]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:36:38,087]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:36:39,398]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:36:43,053]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:36:43,981]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:36:50,393]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:36:51,818]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:36:56,976]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:37:00,257]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:37:09,210]\u001b[0m Trial 849 finished with value: 4.70018300829875 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029164582778622625, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29656841940873396, 'dropout_rate_Layer_2': 0.0074605827478468195, 'dropout_rate_Layer_3': 0.2919891702213945, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.858880495647573e-05, 'l1_Layer_2': 0.000265032488094656, 'l1_Layer_3': 0.00010963591646569404, 'n_units_Layer_1': 225, 'n_units_Layer_2': 260, 'n_units_Layer_3': 165}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 11.80% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.72 | sMAPE for Test Set is: 28.06% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:37:12,323]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:37:15,493]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:37:19,698]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:37:20,027]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:37:20,579]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:37:28,581]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:37:29,204]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:37:29,711]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:37:37,713]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:37:41,775]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:37:44,114]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:37:45,295]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:37:51,508]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:37:52,359]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:37:52,917]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:38:00,349]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:38:01,531]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:38:07,263]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:38:09,799]\u001b[0m Trial 855 finished with value: 4.767451442713178 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011313679504574821, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3145311181512589, 'dropout_rate_Layer_2': 0.10342490867146872, 'dropout_rate_Layer_3': 0.2997016679708112, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015723134898757987, 'l1_Layer_2': 0.008522967198329172, 'l1_Layer_3': 0.00011860405482768524, 'n_units_Layer_1': 105, 'n_units_Layer_2': 250, 'n_units_Layer_3': 50}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.77 | sMAPE for Validation Set is: 11.95% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.70 | sMAPE for Test Set is: 24.86% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:38:10,302]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:38:17,015]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:38:20,753]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:38:20,893]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:38:28,814]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:38:29,349]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:38:33,842]\u001b[0m Trial 874 finished with value: 4.730385970145852 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033649823818800023, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22187341556006854, 'dropout_rate_Layer_2': 0.13557237887841514, 'dropout_rate_Layer_3': 0.39802911624710685, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012216352689794268, 'l1_Layer_2': 0.0005599848778541426, 'l1_Layer_3': 0.00018409100529882613, 'n_units_Layer_1': 115, 'n_units_Layer_2': 65, 'n_units_Layer_3': 180}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.73 | sMAPE for Validation Set is: 11.90% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 24.37% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:38:37,281]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:38:43,310]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:38:48,271]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:38:52,668]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:39:02,449]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:39:08,924]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:39:14,022]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:39:18,123]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:39:18,909]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:39:23,453]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:39:26,642]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:39:30,056]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:39:30,846]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:39:31,269]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:39:42,259]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:39:46,052]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:39:49,242]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:39:54,097]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:39:56,873]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:00,350]\u001b[0m Trial 894 finished with value: 4.715441409293944 and parameters: {'n_hidden': 3, 'learning_rate': 0.005857514456464213, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24013002153023377, 'dropout_rate_Layer_2': 0.00826644167558208, 'dropout_rate_Layer_3': 0.28802664979723275, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017428182682512432, 'l1_Layer_2': 0.00014057868332067682, 'l1_Layer_3': 0.00015185168727931958, 'n_units_Layer_1': 220, 'n_units_Layer_2': 250, 'n_units_Layer_3': 160}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 11.77% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 8.55 | sMAPE for Test Set is: 30.36% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:40:00,541]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:00,896]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:01,989]\u001b[0m Trial 896 finished with value: 4.624425547997601 and parameters: {'n_hidden': 3, 'learning_rate': 0.004317736297678735, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2565572890229485, 'dropout_rate_Layer_2': 0.018531548693655444, 'dropout_rate_Layer_3': 0.2774813023454864, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.0024222907589434e-05, 'l1_Layer_2': 0.0006953851850364092, 'l1_Layer_3': 0.0002508023072118169, 'n_units_Layer_1': 220, 'n_units_Layer_2': 250, 'n_units_Layer_3': 160}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 11.60% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 8.19 | sMAPE for Test Set is: 29.48% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:40:09,820]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:09,977]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:10,375]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:10,637]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:18,601]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:19,491]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:19,717]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:26,433]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:29,025]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:31,519]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:36,620]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:37,215]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:42,284]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:43,028]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:47,868]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:51,865]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:55,000]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:40:59,477]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:41:04,384]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:41:09,502]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:41:14,678]\u001b[0m Trial 919 finished with value: 4.5978879661933005 and parameters: {'n_hidden': 3, 'learning_rate': 0.005835743481732637, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1115940177674573, 'dropout_rate_Layer_2': 0.19302796742175207, 'dropout_rate_Layer_3': 0.3163407961079872, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0009967657976406746, 'l1_Layer_2': 0.002999443610630441, 'l1_Layer_3': 0.0012567967739749708, 'n_units_Layer_1': 105, 'n_units_Layer_2': 55, 'n_units_Layer_3': 120}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.60 | sMAPE for Validation Set is: 11.53% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 7.22 | sMAPE for Test Set is: 26.62% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:41:17,606]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:41:18,470]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:41:22,948]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:41:26,951]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:41:29,376]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:41:31,713]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:41:32,948]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:41:39,359]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:41:39,870]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:41:45,956]\u001b[0m Trial 923 finished with value: 4.541237509414914 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012881819586133712, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04542160928935163, 'dropout_rate_Layer_2': 0.1938483612003635, 'dropout_rate_Layer_3': 0.3379785974703065, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00194071081772891, 'l1_Layer_2': 0.017661575168729658, 'l1_Layer_3': 3.343982383358395e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 255, 'n_units_Layer_3': 215}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:41:45,967]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.54 | sMAPE for Validation Set is: 11.43% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.37 | sMAPE for Test Set is: 23.87% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:41:46,355]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:41:55,754]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:41:56,031]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:02,705]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:02,920]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:04,858]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:11,327]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:13,033]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:17,475]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:20,533]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:21,291]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:26,939]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:31,289]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:31,778]\u001b[0m Trial 934 finished with value: 4.577098739533451 and parameters: {'n_hidden': 3, 'learning_rate': 0.005548602351921207, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11215801458794804, 'dropout_rate_Layer_2': 0.21713985630758073, 'dropout_rate_Layer_3': 0.3191032859624063, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0015446170188347964, 'l1_Layer_2': 0.0032815023243923996, 'l1_Layer_3': 0.0013151828430211445, 'n_units_Layer_1': 85, 'n_units_Layer_2': 55, 'n_units_Layer_3': 125}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 11.46% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 7.07 | sMAPE for Test Set is: 26.21% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:42:32,596]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:37,318]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:41,067]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:44,250]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:50,001]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:50,336]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:53,075]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:42:56,212]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:00,896]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:03,356]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:05,854]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:08,420]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:09,603]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:12,466]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:16,580]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:17,154]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:17,691]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:17,928]\u001b[0m Trial 943 finished with value: 4.560689548664698 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011851629769584278, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0601046627053608, 'dropout_rate_Layer_2': 0.1758047718805278, 'dropout_rate_Layer_3': 0.3251098080592154, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013164681016557597, 'l1_Layer_2': 0.01572696057288574, 'l1_Layer_3': 2.0344607300270575e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 275, 'n_units_Layer_3': 230}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.56 | sMAPE for Validation Set is: 11.44% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 23.22% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:43:28,066]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:29,878]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:30,565]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:30,966]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:33,940]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:37,370]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:41,071]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:45,636]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:46,004]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:47,820]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:54,305]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:54,438]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:43:58,459]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:44:00,208]\u001b[0m Trial 972 finished with value: 4.878925809300811 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012553182722370713, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024729040675506242, 'dropout_rate_Layer_2': 0.2623398350266786, 'dropout_rate_Layer_3': 0.3213931696906448, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018035855500620117, 'l1_Layer_2': 0.016283846903157106, 'l1_Layer_3': 2.211990435857982e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 275, 'n_units_Layer_3': 240}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 12.36% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 6.68 | sMAPE for Test Set is: 26.46% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:44:04,946]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:44:08,022]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:44:10,022]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:44:11,794]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:44:13,747]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:44:19,430]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:44:23,224]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:44:32,291]\u001b[0m Trial 980 finished with value: 4.775900726460434 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012433396671953088, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02405178665611722, 'dropout_rate_Layer_2': 0.20581745643375454, 'dropout_rate_Layer_3': 0.3235125898119323, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019482725796265512, 'l1_Layer_2': 0.01870041515490851, 'l1_Layer_3': 2.2733356823817476e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 275, 'n_units_Layer_3': 225}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 12.03% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.19 | sMAPE for Test Set is: 23.38% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:44:37,704]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:44:42,154]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:44:46,752]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:44:50,849]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:44:55,493]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:45:00,293]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:45:05,689]\u001b[0m Trial 983 finished with value: 4.63578762975263 and parameters: {'n_hidden': 3, 'learning_rate': 0.000970012215610541, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02771518186673983, 'dropout_rate_Layer_2': 0.25954733569596433, 'dropout_rate_Layer_3': 0.3232227621484385, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017706550021130433, 'l1_Layer_2': 0.016922146037369246, 'l1_Layer_3': 2.2151535470073672e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 275, 'n_units_Layer_3': 240}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 11.61% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 22.74% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:45:09,763]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:45:13,637]\u001b[0m Trial 992 finished with value: 4.721881405006352 and parameters: {'n_hidden': 3, 'learning_rate': 0.004098670471613544, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2646764948924326, 'dropout_rate_Layer_2': 0.03151897242268698, 'dropout_rate_Layer_3': 0.3076824150975076, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.526258654365264e-05, 'l1_Layer_2': 0.00030530912452882955, 'l1_Layer_3': 0.00011101395184621074, 'n_units_Layer_1': 210, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.87 | sMAPE for Test Set is: 28.51% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:45:18,389]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:45:23,355]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:45:29,180]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:45:34,892]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:45:37,145]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:45:38,056]\u001b[0m Trial 990 finished with value: 4.575288650106007 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010279523664439, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02371990965909338, 'dropout_rate_Layer_2': 0.21056855299804308, 'dropout_rate_Layer_3': 0.328537352529763, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016284654703413518, 'l1_Layer_2': 0.016663414082258077, 'l1_Layer_3': 1.2863727279356605e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 275, 'n_units_Layer_3': 250}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 11.48% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 23.19% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:45:38,399]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:45:51,520]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:45:54,414]\u001b[0m Trial 997 finished with value: 4.7396703106065035 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012443077948738215, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05544523051014819, 'dropout_rate_Layer_2': 0.26149372561849266, 'dropout_rate_Layer_3': 0.3225104555202533, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018196559581733535, 'l1_Layer_2': 0.02153303711059157, 'l1_Layer_3': 2.227229672232549e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 275, 'n_units_Layer_3': 240}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 11.90% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.09 | sMAPE for Test Set is: 22.90% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:45:58,535]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:46:01,510]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:46:06,065]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:46:09,570]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:46:09,784]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:46:16,908]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:46:20,342]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:46:21,742]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:46:25,804]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:46:31,474]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:46:37,349]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:46:42,102]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:46:47,644]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:46:54,468]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:46:55,065]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:46:58,824]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:47:03,803]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:47:07,753]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:47:10,571]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:47:14,838]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:47:21,296]\u001b[0m Trial 1010 finished with value: 4.758041331523845 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008917967790726302, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05014186919150002, 'dropout_rate_Layer_2': 0.25839047033075446, 'dropout_rate_Layer_3': 0.3362947529594724, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0024581102282274217, 'l1_Layer_2': 0.02949309044399035, 'l1_Layer_3': 1.7156445906397943e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 290, 'n_units_Layer_3': 260}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 11.93% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 23.02% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:47:26,196]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:47:32,213]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:47:36,152]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:47:37,189]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:47:48,247]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:47:53,961]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:47:59,304]\u001b[0m Trial 1026 finished with value: 4.999933988191118 and parameters: {'n_hidden': 4, 'learning_rate': 0.004566348701042542, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05104519270071246, 'dropout_rate_Layer_2': 0.10809490845832859, 'dropout_rate_Layer_3': 0.008251467923725664, 'dropout_rate_Layer_4': 0.21884915841281694, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002707452675819924, 'l1_Layer_2': 0.07325851822968853, 'l1_Layer_3': 0.007057519960707876, 'l1_Layer_4': 0.000544631541403741, 'n_units_Layer_1': 120, 'n_units_Layer_2': 235, 'n_units_Layer_3': 150, 'n_units_Layer_4': 260}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 12.56% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 8.07 | sMAPE for Test Set is: 28.87% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:48:02,481]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:48:05,191]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:48:07,514]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:48:08,133]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:48:09,139]\u001b[0m Trial 1034 finished with value: 4.701858740909583 and parameters: {'n_hidden': 3, 'learning_rate': 0.003674637683641793, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2612219055422676, 'dropout_rate_Layer_2': 0.014727743045745588, 'dropout_rate_Layer_3': 0.2863406176482025, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010902127155082752, 'l1_Layer_2': 0.00039073979247091905, 'l1_Layer_3': 0.00020318966454219387, 'n_units_Layer_1': 220, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.89 | sMAPE for Test Set is: 28.59% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:48:11,591]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:48:15,179]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:48:21,404]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:48:22,043]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:48:22,276]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:48:22,654]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:48:35,108]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:48:35,314]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:48:35,367]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:48:35,889]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:48:46,121]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:48:50,794]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:48:53,961]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:48:57,839]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:49:00,752]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:49:04,864]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:49:08,229]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:49:19,490]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:49:22,090]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:49:24,833]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:49:30,240]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:49:31,309]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:49:36,670]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:49:42,468]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:49:48,980]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:49:49,120]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:49:49,401]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:49:57,906]\u001b[0m Trial 1061 finished with value: 4.626687868143148 and parameters: {'n_hidden': 3, 'learning_rate': 0.005915511218669232, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15960321304750763, 'dropout_rate_Layer_2': 0.18353007228446297, 'dropout_rate_Layer_3': 0.3079761353447003, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0020553734478859146, 'l1_Layer_2': 0.0008637919734550438, 'l1_Layer_3': 0.001193696721284345, 'n_units_Layer_1': 135, 'n_units_Layer_2': 90, 'n_units_Layer_3': 110}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 11.57% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.22 | sMAPE for Test Set is: 26.58% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:50:02,314]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:50:02,358]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:50:08,220]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:50:12,785]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:50:12,822]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:50:24,277]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:50:30,886]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:50:34,996]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:50:38,358]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:50:38,487]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:50:49,734]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:51:00,324]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:51:02,838]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:51:08,904]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:51:11,826]\u001b[0m Trial 1080 finished with value: 4.63463597182233 and parameters: {'n_hidden': 3, 'learning_rate': 0.00797111021890873, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10531252479507562, 'dropout_rate_Layer_2': 0.2121041378444038, 'dropout_rate_Layer_3': 0.3669415676632653, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.001960410418586046, 'l1_Layer_2': 2.0896132133043545e-05, 'l1_Layer_3': 0.0007988232748488453, 'n_units_Layer_1': 145, 'n_units_Layer_2': 55, 'n_units_Layer_3': 85}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 11.62% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.75 | sMAPE for Test Set is: 28.08% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:51:13,076]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:51:19,677]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:51:24,520]\u001b[0m Trial 1079 finished with value: 4.6394696060638845 and parameters: {'n_hidden': 3, 'learning_rate': 0.0076820941955929355, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08681229216458972, 'dropout_rate_Layer_2': 0.232276157105057, 'dropout_rate_Layer_3': 0.362795760267821, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0020041683956977157, 'l1_Layer_2': 0.0012825975340646461, 'l1_Layer_3': 0.0008154667193381943, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 90}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.64 | sMAPE for Validation Set is: 11.65% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.18 | sMAPE for Test Set is: 26.54% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:51:28,254]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:51:33,179]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:51:37,760]\u001b[0m Trial 1085 finished with value: 4.735471991684627 and parameters: {'n_hidden': 3, 'learning_rate': 0.004749977995727236, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23518519800445545, 'dropout_rate_Layer_2': 0.01592974403640999, 'dropout_rate_Layer_3': 0.2933870633086265, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.300419023445816e-05, 'l1_Layer_2': 0.0003079909780266392, 'l1_Layer_3': 0.0001836702589635067, 'n_units_Layer_1': 205, 'n_units_Layer_2': 270, 'n_units_Layer_3': 145}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 11.90% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 8.30 | sMAPE for Test Set is: 29.65% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:51:39,970]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:51:44,298]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:51:44,583]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:51:48,614]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:51:54,596]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:51:57,606]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:51:57,841]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:51:58,207]\u001b[0m Trial 1086 finished with value: 4.699753420934552 and parameters: {'n_hidden': 3, 'learning_rate': 0.0047972048967168624, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23611804420195226, 'dropout_rate_Layer_2': 0.018665956737612663, 'dropout_rate_Layer_3': 0.2939114438429993, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.31074456705525e-05, 'l1_Layer_2': 0.0003142552614841737, 'l1_Layer_3': 0.00018082377488142125, 'n_units_Layer_1': 205, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 11.79% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.80 | sMAPE for Test Set is: 28.35% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:51:59,295]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:52:07,816]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:52:11,594]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:52:12,915]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:52:18,993]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:52:21,400]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:52:22,664]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:52:25,795]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:52:36,157]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:52:37,785]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:52:42,467]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:52:43,717]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:52:48,851]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:52:52,397]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:52:54,974]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:52:56,243]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:52:57,204]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:53:00,955]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:53:03,321]\u001b[0m Trial 1105 finished with value: 4.75211844440723 and parameters: {'n_hidden': 3, 'learning_rate': 0.004062243234404838, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24902666976702312, 'dropout_rate_Layer_2': 0.007990439888801345, 'dropout_rate_Layer_3': 0.28054917959155184, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.878060288475065e-05, 'l1_Layer_2': 0.00037556163643008203, 'l1_Layer_3': 0.00010058044316275159, 'n_units_Layer_1': 215, 'n_units_Layer_2': 250, 'n_units_Layer_3': 145}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 12.02% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.90 | sMAPE for Test Set is: 25.73% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:53:04,581]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:53:11,408]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:53:13,584]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:53:15,134]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:53:18,657]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:53:19,905]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:53:27,875]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:53:28,232]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:53:29,672]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:53:36,888]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:53:40,435]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:53:42,321]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:53:47,424]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:53:50,161]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:53:51,819]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:53:55,672]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:54:00,075]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:54:07,917]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:54:13,253]\u001b[0m Trial 1133 finished with value: 4.7750077312174675 and parameters: {'n_hidden': 3, 'learning_rate': 0.007655893783085742, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24292210820768007, 'dropout_rate_Layer_2': 0.013594872359651327, 'dropout_rate_Layer_3': 0.1964942583007725, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010333880174783473, 'l1_Layer_2': 0.00023121152447808902, 'l1_Layer_3': 5.2251764856103215e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 280, 'n_units_Layer_3': 150}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 12.06% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 8.25 | sMAPE for Test Set is: 29.60% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:54:13,622]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:54:25,444]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:54:26,060]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:54:32,062]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:54:34,911]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:54:37,385]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:54:42,128]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:54:43,137]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:54:50,555]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:54:55,675]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:03,904]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:08,315]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:10,974]\u001b[0m Trial 1137 finished with value: 5.121972146655817 and parameters: {'n_hidden': 4, 'learning_rate': 0.0060654247658478, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07144407028174135, 'dropout_rate_Layer_2': 0.14068084025444055, 'dropout_rate_Layer_3': 0.27644881207979616, 'dropout_rate_Layer_4': 0.19933776497970915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009130650238279552, 'l1_Layer_2': 0.07746639365210678, 'l1_Layer_3': 0.006298426096585872, 'l1_Layer_4': 0.0008153378583774433, 'n_units_Layer_1': 125, 'n_units_Layer_2': 230, 'n_units_Layer_3': 110, 'n_units_Layer_4': 265}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 12.87% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 8.29 | sMAPE for Test Set is: 29.54% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:55:14,012]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:15,324]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:18,271]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:23,181]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:26,465]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:27,434]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:30,520]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:33,527]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:36,912]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:38,309]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:42,246]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:44,915]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:47,109]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:49,612]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:50,446]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:55:52,845]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:56:00,745]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:56:04,597]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:56:06,961]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:56:09,316]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:56:13,265]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:56:16,737]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:56:18,160]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:56:23,067]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:56:28,412]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:56:32,977]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:56:33,325]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:56:40,150]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:56:43,078]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:56:46,180]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:56:50,074]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:56:53,172]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:56:53,207]\u001b[0m Trial 1170 finished with value: 5.187538828521245 and parameters: {'n_hidden': 4, 'learning_rate': 0.004064325987774135, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1811440297068233, 'dropout_rate_Layer_2': 0.10684210285519083, 'dropout_rate_Layer_3': 0.1509558211543517, 'dropout_rate_Layer_4': 0.22956807435918303, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00014193517903901198, 'l1_Layer_2': 0.09569683562416191, 'l1_Layer_3': 0.010726124484396778, 'l1_Layer_4': 0.0008179122441999959, 'n_units_Layer_1': 250, 'n_units_Layer_2': 235, 'n_units_Layer_3': 230, 'n_units_Layer_4': 265}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 13.03% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 7.71 | sMAPE for Test Set is: 27.87% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:56:54,014]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:57:01,319]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:57:04,213]\u001b[0m Trial 1173 finished with value: 4.760520331979464 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012686818410251343, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04035969144916392, 'dropout_rate_Layer_2': 0.2668573063319617, 'dropout_rate_Layer_3': 0.3403092553024058, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00164132208780285, 'l1_Layer_2': 0.021132089594914662, 'l1_Layer_3': 1.914135835881626e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 270, 'n_units_Layer_3': 245}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 11.97% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 23.21% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:57:04,834]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:57:04,867]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:57:05,770]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:57:14,246]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:57:16,045]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:57:17,757]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:57:23,770]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:57:24,944]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:57:31,360]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:57:32,578]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:57:36,842]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:57:39,575]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:57:46,231]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:57:51,266]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:57:54,600]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:58:02,667]\u001b[0m Trial 1187 finished with value: 4.756209068209543 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011092437820879473, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03793132037035563, 'dropout_rate_Layer_2': 0.2917346200512987, 'dropout_rate_Layer_3': 0.3389835505917379, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001552144944424049, 'l1_Layer_2': 0.02480035117247142, 'l1_Layer_3': 1.9132746913719346e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 270, 'n_units_Layer_3': 225}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 11.93% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 23.20% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:58:09,022]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:58:11,496]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:58:13,661]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:58:16,268]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:58:19,026]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:58:21,600]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:58:24,426]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:58:25,924]\u001b[0m Trial 1196 finished with value: 5.122942675656225 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032744359619787584, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10811905961844968, 'dropout_rate_Layer_2': 0.12210193487730206, 'dropout_rate_Layer_3': 0.32522735197505215, 'dropout_rate_Layer_4': 0.20791123279354784, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0001282812240551117, 'l1_Layer_2': 0.04652796751991566, 'l1_Layer_3': 0.006647704050971186, 'l1_Layer_4': 0.001150140241268727, 'n_units_Layer_1': 255, 'n_units_Layer_2': 235, 'n_units_Layer_3': 280, 'n_units_Layer_4': 275}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 8.18 | sMAPE for Test Set is: 29.24% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:58:29,375]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:58:31,324]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:58:34,292]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:58:37,819]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:58:43,671]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:58:44,047]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:58:50,766]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:58:51,150]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:58:51,242]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:59:00,335]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:59:01,274]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:59:02,155]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:59:09,262]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:59:12,952]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:59:17,394]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:59:18,166]\u001b[0m Trial 1205 finished with value: 4.695156735885521 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008161822272665747, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012837826246281252, 'dropout_rate_Layer_2': 0.27020778184976524, 'dropout_rate_Layer_3': 0.39990746258883797, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016226574184474043, 'l1_Layer_2': 0.019378605429129624, 'l1_Layer_3': 1.878727806950756e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 270, 'n_units_Layer_3': 225}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 11.78% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.08 | sMAPE for Test Set is: 22.85% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:59:23,949]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:59:28,532]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:59:29,954]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:59:35,567]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:59:38,860]\u001b[0m Trial 1223 finished with value: 4.782198616690255 and parameters: {'n_hidden': 3, 'learning_rate': 0.005739122469768726, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23019070066250918, 'dropout_rate_Layer_2': 0.023168403225493822, 'dropout_rate_Layer_3': 0.28902921703362083, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.944309306291923e-05, 'l1_Layer_2': 9.298167056087046e-05, 'l1_Layer_3': 8.399822747635324e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 275, 'n_units_Layer_3': 155}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 11.98% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 8.31 | sMAPE for Test Set is: 29.73% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 00:59:47,465]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:59:53,272]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 00:59:59,932]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:00:20,542]\u001b[0m Trial 1226 finished with value: 4.7165837703825595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005915572448233566, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02936360577025544, 'dropout_rate_Layer_2': 0.31325625636787613, 'dropout_rate_Layer_3': 0.38870188841685377, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023902960850963285, 'l1_Layer_2': 0.019068742033891695, 'l1_Layer_3': 3.0666874991128124e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 280, 'n_units_Layer_3': 235}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 11.85% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.26 | sMAPE for Test Set is: 23.40% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:00:20,869]\u001b[0m Trial 1228 finished with value: 4.742401785486458 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006267967262838687, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030708071998720488, 'dropout_rate_Layer_2': 0.27069010145967404, 'dropout_rate_Layer_3': 0.3879209271813859, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002403493558792294, 'l1_Layer_2': 0.03625559245278264, 'l1_Layer_3': 1.4375508195374251e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 280, 'n_units_Layer_3': 235}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 11.90% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.19 | sMAPE for Test Set is: 23.22% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:00:30,776]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:00:33,527]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:00:39,380]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:00:44,425]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:00:50,468]\u001b[0m Trial 1231 finished with value: 5.058015750098273 and parameters: {'n_hidden': 4, 'learning_rate': 0.0030502597900438637, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3919589764075495, 'dropout_rate_Layer_2': 0.10992022792400118, 'dropout_rate_Layer_3': 0.1804154513827348, 'dropout_rate_Layer_4': 0.24107845230837702, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.6917517913666825e-05, 'l1_Layer_2': 0.004685488587518451, 'l1_Layer_3': 0.007746459736939947, 'l1_Layer_4': 0.0013084737812411578, 'n_units_Layer_1': 245, 'n_units_Layer_2': 240, 'n_units_Layer_3': 275, 'n_units_Layer_4': 265}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 12.62% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 7.80 | sMAPE for Test Set is: 28.24% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:00:50,913]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:00:59,330]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:01:05,941]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:01:12,455]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:01:16,917]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:01:17,097]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:01:17,942]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:01:22,113]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:01:25,821]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:01:31,268]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:01:31,464]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:01:35,950]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:01:40,326]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:01:40,585]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:01:44,579]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:01:46,687]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:01:53,921]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:01:54,500]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:02:02,025]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:02:06,484]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:02:23,317]\u001b[0m Trial 1259 finished with value: 4.61675700722238 and parameters: {'n_hidden': 3, 'learning_rate': 0.0044557530975090085, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1250197830222504, 'dropout_rate_Layer_2': 0.19856817730894358, 'dropout_rate_Layer_3': 0.0138207303676312, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002798036699394692, 'l1_Layer_2': 0.001614641888779865, 'l1_Layer_3': 0.0019015337806424233, 'n_units_Layer_1': 155, 'n_units_Layer_2': 125, 'n_units_Layer_3': 125}. Best is trial 719 with value: 4.482586912895714.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.62 | sMAPE for Validation Set is: 11.55% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.36 | sMAPE for Test Set is: 27.00% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:02:28,823]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:02:32,966]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:02:38,002]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.43 | sMAPE for Validation Set is: 11.15% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 24.99% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:02:39,983]\u001b[0m Trial 1254 finished with value: 4.433290079958611 and parameters: {'n_hidden': 3, 'learning_rate': 0.004368978981971515, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12402517817942012, 'dropout_rate_Layer_2': 0.20285460583438608, 'dropout_rate_Layer_3': 0.34303659414499044, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002262942315496491, 'l1_Layer_2': 0.0012128504616132762, 'l1_Layer_3': 0.0016797042921972438, 'n_units_Layer_1': 130, 'n_units_Layer_2': 125, 'n_units_Layer_3': 115}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:02:44,818]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:02:46,284]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:02:47,356]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:02:51,710]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:02:56,425]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:00,745]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:03,236]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:07,270]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:10,563]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:12,694]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:17,791]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:20,611]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:23,573]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:26,810]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:28,229]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:35,240]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:36,106]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:40,430]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:45,220]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:47,070]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:48,611]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:48,776]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:03:51,405]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:01,162]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:01,836]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:03,907]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:05,464]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:05,977]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:11,930]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:19,778]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:22,413]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:24,122]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:24,418]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:34,731]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:34,844]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:41,365]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:44,574]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:44,708]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:47,765]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:53,638]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:56,577]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:04:59,771]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:05:00,794]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:05:09,746]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:05:13,457]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:05:16,167]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:05:16,238]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:05:17,567]\u001b[0m Trial 1300 finished with value: 4.585874492016584 and parameters: {'n_hidden': 3, 'learning_rate': 0.002524027343928468, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11831180842107329, 'dropout_rate_Layer_2': 0.14980697734650728, 'dropout_rate_Layer_3': 0.07732162525621966, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0006251651536694058, 'l1_Layer_2': 0.0005979235423452481, 'l1_Layer_3': 0.0010001449478830708, 'n_units_Layer_1': 140, 'n_units_Layer_2': 120, 'n_units_Layer_3': 125}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.59 | sMAPE for Validation Set is: 11.54% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.88 | sMAPE for Test Set is: 25.45% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:05:26,596]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:05:27,218]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:05:28,220]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:05:31,829]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:05:34,714]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:05:42,036]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:05:42,843]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:05:44,250]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:05:47,405]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:05:51,870]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:05:58,681]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:05:59,960]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:06:05,173]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:06:08,242]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:06:10,251]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:06:14,953]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:06:20,940]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:06:29,468]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:06:41,664]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:06:48,212]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:06:53,879]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:07:06,419]\u001b[0m Trial 1324 finished with value: 4.7249806985020415 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009087005974359748, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04669950817956179, 'dropout_rate_Layer_2': 0.24260488382609605, 'dropout_rate_Layer_3': 0.3482444649368621, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013928883440411685, 'l1_Layer_2': 0.016686834104422416, 'l1_Layer_3': 1.9492352359758852e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 285, 'n_units_Layer_3': 250}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 24.93% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:07:11,522]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:07:16,960]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:07:20,084]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:07:25,150]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:07:29,797]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:07:29,951]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:07:37,575]\u001b[0m Trial 1318 finished with value: 4.952600939100681 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033510277440929243, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3879847047948469, 'dropout_rate_Layer_2': 0.0958557503031983, 'dropout_rate_Layer_3': 0.1323729284575274, 'dropout_rate_Layer_4': 0.2017677053860445, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 9.057051894082301e-05, 'l1_Layer_2': 0.005151628125603123, 'l1_Layer_3': 0.007050480651653007, 'l1_Layer_4': 0.00034806597026775107, 'n_units_Layer_1': 175, 'n_units_Layer_2': 225, 'n_units_Layer_3': 110, 'n_units_Layer_4': 250}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 12.43% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 8.84 | sMAPE for Test Set is: 31.07% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:07:37,868]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:07:37,870]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:07:51,768]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:07:53,622]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:07:58,241]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:08:00,959]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:08:07,391]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:08:48,780]\u001b[0m Trial 1348 finished with value: 4.612706234512826 and parameters: {'n_hidden': 3, 'learning_rate': 0.001594233365602392, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13718846190036146, 'dropout_rate_Layer_2': 0.14867791324572996, 'dropout_rate_Layer_3': 0.07741742681766454, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0010932783021617284, 'l1_Layer_2': 1.0156632171721845e-05, 'l1_Layer_3': 0.0006843999582426727, 'n_units_Layer_1': 100, 'n_units_Layer_2': 120, 'n_units_Layer_3': 130}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.61 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.31 | sMAPE for Test Set is: 26.87% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:08:54,816]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:08:58,996]\u001b[0m Trial 1350 finished with value: 5.135677588363378 and parameters: {'n_hidden': 4, 'learning_rate': 0.0034617470840853396, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38487418317252475, 'dropout_rate_Layer_2': 0.09977022400516364, 'dropout_rate_Layer_3': 0.11644435668758155, 'dropout_rate_Layer_4': 0.20042634376073273, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 7.18281010416691e-05, 'l1_Layer_2': 0.003843876610997535, 'l1_Layer_3': 0.007506388619171791, 'l1_Layer_4': 0.0004013015131668465, 'n_units_Layer_1': 170, 'n_units_Layer_2': 265, 'n_units_Layer_3': 95, 'n_units_Layer_4': 240}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 12.89% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 30.13% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:09:01,696]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:09:06,632]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:09:06,654]\u001b[0m Trial 1344 finished with value: 5.098528256043376 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027698938227379024, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38056923699247447, 'dropout_rate_Layer_2': 0.0870839473564703, 'dropout_rate_Layer_3': 0.131729312841815, 'dropout_rate_Layer_4': 0.3593260028008721, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 8.502430834162744e-05, 'l1_Layer_2': 0.004108284597896517, 'l1_Layer_3': 0.0069515521232696685, 'l1_Layer_4': 0.00022633337662820261, 'n_units_Layer_1': 185, 'n_units_Layer_2': 225, 'n_units_Layer_3': 100, 'n_units_Layer_4': 245}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 12.83% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 8.55 | sMAPE for Test Set is: 30.23% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:09:07,214]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:09:18,958]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:09:21,517]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:09:22,961]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:09:29,386]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:09:29,640]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:09:42,812]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:09:52,031]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:09:56,397]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:09:59,493]\u001b[0m Trial 1343 finished with value: 4.986449840685952 and parameters: {'n_hidden': 4, 'learning_rate': 0.0029132373067222964, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36357623565132496, 'dropout_rate_Layer_2': 0.08437333812138052, 'dropout_rate_Layer_3': 0.13297132586413438, 'dropout_rate_Layer_4': 0.1936132982824878, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 7.119648071100201e-05, 'l1_Layer_2': 0.005116372603901235, 'l1_Layer_3': 0.006695748580301389, 'l1_Layer_4': 0.0002435164307180895, 'n_units_Layer_1': 185, 'n_units_Layer_2': 260, 'n_units_Layer_3': 100, 'n_units_Layer_4': 245}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 12.47% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 8.51 | sMAPE for Test Set is: 30.19% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:10:02,443]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:10:49,499]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:10:54,460]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:10:57,609]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:11:05,892]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:11:06,576]\u001b[0m Trial 1359 finished with value: 5.166851275166986 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025607113318278332, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35554079978292025, 'dropout_rate_Layer_2': 0.07801585458461602, 'dropout_rate_Layer_3': 0.11606293054904493, 'dropout_rate_Layer_4': 0.3760960039805147, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0001328404069848893, 'l1_Layer_2': 0.0032461476853769466, 'l1_Layer_3': 0.007250783291132042, 'l1_Layer_4': 0.0002495628553213018, 'n_units_Layer_1': 175, 'n_units_Layer_2': 270, 'n_units_Layer_3': 90, 'n_units_Layer_4': 235}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.17 | sMAPE for Validation Set is: 12.98% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 8.50 | sMAPE for Test Set is: 30.08% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:11:16,232]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:11:20,079]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:11:25,705]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:11:33,387]\u001b[0m Trial 1361 finished with value: 5.163567889788962 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026145020105429, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3780423915658726, 'dropout_rate_Layer_2': 0.08963426187009654, 'dropout_rate_Layer_3': 0.11374218926018734, 'dropout_rate_Layer_4': 0.3528866015209262, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.655436277167968e-05, 'l1_Layer_2': 0.004441647121577946, 'l1_Layer_3': 0.00721671842573994, 'l1_Layer_4': 0.0003129958904501445, 'n_units_Layer_1': 185, 'n_units_Layer_2': 225, 'n_units_Layer_3': 100, 'n_units_Layer_4': 240}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 12.94% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 8.55 | sMAPE for Test Set is: 30.22% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:11:35,544]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:11:48,559]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:11:51,329]\u001b[0m Trial 1369 finished with value: 4.719577600063558 and parameters: {'n_hidden': 3, 'learning_rate': 0.001443258565462241, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13681862809120687, 'dropout_rate_Layer_2': 0.14277130472220909, 'dropout_rate_Layer_3': 0.08816890397082996, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0010595919369447745, 'l1_Layer_2': 0.0009379384120515366, 'l1_Layer_3': 0.0005589176401108084, 'n_units_Layer_1': 100, 'n_units_Layer_2': 115, 'n_units_Layer_3': 130}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 8.03 | sMAPE for Test Set is: 28.92% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:11:54,781]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:12:00,875]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:12:08,321]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:12:19,734]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:12:36,914]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:12:39,901]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:12:57,725]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:13:11,958]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:13:13,142]\u001b[0m Trial 1384 finished with value: 4.741371569784437 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008350458219442114, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04837535445053748, 'dropout_rate_Layer_2': 0.3010986654162535, 'dropout_rate_Layer_3': 0.18348896512063184, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019235378139636939, 'l1_Layer_2': 0.022452388747135888, 'l1_Layer_3': 2.2134191871666218e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 275, 'n_units_Layer_3': 255}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 23.22% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:13:25,082]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:13:30,669]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:13:36,498]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:13:37,977]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:13:45,064]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:13:48,134]\u001b[0m Trial 1386 finished with value: 4.653814205546174 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018879637267686837, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07669467003787975, 'dropout_rate_Layer_2': 0.15873562294920873, 'dropout_rate_Layer_3': 0.07689956463585787, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002526254373063437, 'l1_Layer_2': 0.0015824321013415753, 'l1_Layer_3': 0.0019366260096129447, 'n_units_Layer_1': 125, 'n_units_Layer_2': 100, 'n_units_Layer_3': 120}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.65 | sMAPE for Validation Set is: 11.67% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.64 | sMAPE for Test Set is: 24.72% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:13:54,990]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:13:59,853]\u001b[0m Trial 1388 finished with value: 4.714222628009163 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018393749562645755, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11632687344535293, 'dropout_rate_Layer_2': 0.013409113955347919, 'dropout_rate_Layer_3': 0.07794578648864708, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003077648078736542, 'l1_Layer_2': 0.0003747868852179275, 'l1_Layer_3': 0.0020078269501164507, 'n_units_Layer_1': 115, 'n_units_Layer_2': 100, 'n_units_Layer_3': 140}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 11.86% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 24.21% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:14:02,857]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:14:07,460]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:14:12,656]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:14:14,103]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:14:20,224]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:14:26,602]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:14:37,643]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:14:57,769]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:15:01,923]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:15:13,550]\u001b[0m Trial 1396 finished with value: 5.15616026144898 and parameters: {'n_hidden': 4, 'learning_rate': 0.0029103831211547203, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3664362448761916, 'dropout_rate_Layer_2': 0.08703907198807423, 'dropout_rate_Layer_3': 0.1334200139596052, 'dropout_rate_Layer_4': 0.3810469373827354, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00012475988935043407, 'l1_Layer_2': 0.0058292231126705315, 'l1_Layer_3': 0.005539378941973763, 'l1_Layer_4': 0.0002884612902602717, 'n_units_Layer_1': 175, 'n_units_Layer_2': 265, 'n_units_Layer_3': 90, 'n_units_Layer_4': 240}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 12.91% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 8.68 | sMAPE for Test Set is: 30.53% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:15:27,605]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:15:33,716]\u001b[0m Trial 1403 finished with value: 5.296297438530949 and parameters: {'n_hidden': 4, 'learning_rate': 0.003013754813733952, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3575657490769861, 'dropout_rate_Layer_2': 0.09080816117398242, 'dropout_rate_Layer_3': 0.10065512508133669, 'dropout_rate_Layer_4': 0.36936473540070186, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 9.819310273767606e-05, 'l1_Layer_2': 0.0037374818760646726, 'l1_Layer_3': 0.005549936956771598, 'l1_Layer_4': 0.0004027350345062691, 'n_units_Layer_1': 185, 'n_units_Layer_2': 280, 'n_units_Layer_3': 90, 'n_units_Layer_4': 235}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 13.29% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 9.03 | sMAPE for Test Set is: 31.31% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:15:37,921]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:15:44,141]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:15:52,943]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:15:59,365]\u001b[0m Trial 1405 finished with value: 4.758574906754094 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009226107305591992, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014824043055293326, 'dropout_rate_Layer_2': 0.33150406171195546, 'dropout_rate_Layer_3': 0.3856055666850762, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023249647681381994, 'l1_Layer_2': 0.016135505555439977, 'l1_Layer_3': 2.8323167993960834e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 280, 'n_units_Layer_3': 255}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 23.22% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:16:03,587]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:16:15,439]\u001b[0m Trial 1401 finished with value: 4.914880605871673 and parameters: {'n_hidden': 4, 'learning_rate': 0.0030287525005021224, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35149325470758824, 'dropout_rate_Layer_2': 0.08985832978877728, 'dropout_rate_Layer_3': 0.12777402479104627, 'dropout_rate_Layer_4': 0.35056263191721404, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 9.72797115194952e-05, 'l1_Layer_2': 0.0031682390445685825, 'l1_Layer_3': 0.006645095894525732, 'l1_Layer_4': 0.00037178676817891315, 'n_units_Layer_1': 180, 'n_units_Layer_2': 265, 'n_units_Layer_3': 95, 'n_units_Layer_4': 245}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 12.33% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 8.43 | sMAPE for Test Set is: 30.01% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:16:47,523]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:16:56,828]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:17:02,707]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:17:05,663]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:17:10,650]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:17:13,198]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:17:18,598]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:17:18,950]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:17:27,695]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:17:34,010]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:17:46,007]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:17:55,763]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:18:00,325]\u001b[0m Trial 1408 finished with value: 4.963518854821416 and parameters: {'n_hidden': 4, 'learning_rate': 0.003022677663109121, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37938479792109703, 'dropout_rate_Layer_2': 0.07629341016428928, 'dropout_rate_Layer_3': 0.13250925625667104, 'dropout_rate_Layer_4': 0.36981302351176376, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 7.796880187546286e-05, 'l1_Layer_2': 0.00660213441718816, 'l1_Layer_3': 0.005098899732554015, 'l1_Layer_4': 0.0003278346241242255, 'n_units_Layer_1': 175, 'n_units_Layer_2': 260, 'n_units_Layer_3': 90, 'n_units_Layer_4': 240}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 12.44% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 8.51 | sMAPE for Test Set is: 30.23% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:18:04,198]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:18:12,215]\u001b[0m Trial 1413 finished with value: 4.890126225402235 and parameters: {'n_hidden': 4, 'learning_rate': 0.003157606425734022, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37833546442930566, 'dropout_rate_Layer_2': 0.09161113970683837, 'dropout_rate_Layer_3': 0.12854970863591578, 'dropout_rate_Layer_4': 0.3796934311743808, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 7.179919699355125e-05, 'l1_Layer_2': 0.005327814390269551, 'l1_Layer_3': 0.005093615215499269, 'l1_Layer_4': 0.00027977391621566815, 'n_units_Layer_1': 175, 'n_units_Layer_2': 255, 'n_units_Layer_3': 85, 'n_units_Layer_4': 235}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 12.24% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 8.48 | sMAPE for Test Set is: 30.16% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:18:12,462]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:18:19,698]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:18:25,273]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:18:32,253]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:18:38,010]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:18:53,823]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:19:03,471]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:19:16,200]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:19:42,905]\u001b[0m Trial 1431 finished with value: 5.1782327911707275 and parameters: {'n_hidden': 4, 'learning_rate': 0.003012089521491238, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3692957898488215, 'dropout_rate_Layer_2': 0.07100009923793552, 'dropout_rate_Layer_3': 0.13147093360844325, 'dropout_rate_Layer_4': 0.3654165972124759, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.867881933418908e-05, 'l1_Layer_2': 0.004318662714299652, 'l1_Layer_3': 0.006196828995983378, 'l1_Layer_4': 0.00023295298477168624, 'n_units_Layer_1': 180, 'n_units_Layer_2': 255, 'n_units_Layer_3': 80, 'n_units_Layer_4': 225}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 12.98% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 8.82 | sMAPE for Test Set is: 30.92% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:19:56,352]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:20:03,968]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:20:09,156]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:20:13,467]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 8.69 | sMAPE for Test Set is: 30.59% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:20:15,018]\u001b[0m Trial 1436 finished with value: 5.140187554119685 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023149892774498044, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3652116683173567, 'dropout_rate_Layer_2': 0.08487960697394002, 'dropout_rate_Layer_3': 0.12260790117511502, 'dropout_rate_Layer_4': 0.3668882614795973, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.184335476936505e-05, 'l1_Layer_2': 0.0040224310293674945, 'l1_Layer_3': 0.007559575670959515, 'l1_Layer_4': 0.00023198781253486465, 'n_units_Layer_1': 185, 'n_units_Layer_2': 255, 'n_units_Layer_3': 90, 'n_units_Layer_4': 230}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:20:20,991]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:20:21,679]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:20:28,052]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:21:08,139]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 12.94% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 8.37 | sMAPE for Test Set is: 29.70% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:21:10,839]\u001b[0m Trial 1439 finished with value: 5.148692488679228 and parameters: {'n_hidden': 4, 'learning_rate': 0.002304521776885496, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36028859505892646, 'dropout_rate_Layer_2': 0.060843708591617494, 'dropout_rate_Layer_3': 0.14340592463211593, 'dropout_rate_Layer_4': 0.3641432022985685, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.82063709284842e-05, 'l1_Layer_2': 0.003529318514231876, 'l1_Layer_3': 0.003911297572517587, 'l1_Layer_4': 0.0002093039363500775, 'n_units_Layer_1': 185, 'n_units_Layer_2': 255, 'n_units_Layer_3': 80, 'n_units_Layer_4': 215}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:21:20,508]\u001b[0m Trial 1444 finished with value: 5.191803396365274 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026392512434376264, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3623310627784738, 'dropout_rate_Layer_2': 0.06682640107487361, 'dropout_rate_Layer_3': 0.14221830241624667, 'dropout_rate_Layer_4': 0.361422472569848, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.0261357712191816e-05, 'l1_Layer_2': 0.004805544976733899, 'l1_Layer_3': 0.007552185390838174, 'l1_Layer_4': 0.00023019168176326778, 'n_units_Layer_1': 180, 'n_units_Layer_2': 255, 'n_units_Layer_3': 80, 'n_units_Layer_4': 225}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 13.02% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 8.60 | sMAPE for Test Set is: 30.32% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:21:30,652]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:21:31,585]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:21:43,402]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:21:46,484]\u001b[0m Trial 1448 finished with value: 4.724411919068134 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038028570768033607, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22714412816824947, 'dropout_rate_Layer_2': 0.014936952631404725, 'dropout_rate_Layer_3': 0.27798642811255325, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010863615309316882, 'l1_Layer_2': 0.0002665516792403892, 'l1_Layer_3': 0.00020880668397496588, 'n_units_Layer_1': 205, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 11.75% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 7.92 | sMAPE for Test Set is: 28.62% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:21:50,909]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:21:51,344]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:21:57,789]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:22:00,756]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:22:06,259]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:22:12,698]\u001b[0m Trial 1446 finished with value: 5.0892329220620836 and parameters: {'n_hidden': 4, 'learning_rate': 0.002312934924470091, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.345104172780874, 'dropout_rate_Layer_2': 0.06785693426610698, 'dropout_rate_Layer_3': 0.1408799572628235, 'dropout_rate_Layer_4': 0.3693576501440696, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.094419008953085e-05, 'l1_Layer_2': 0.004452631893645302, 'l1_Layer_3': 0.007814210328554791, 'l1_Layer_4': 0.0002049196958369289, 'n_units_Layer_1': 180, 'n_units_Layer_2': 255, 'n_units_Layer_3': 75, 'n_units_Layer_4': 225}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 12.80% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 8.13 | sMAPE for Test Set is: 29.13% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:22:14,043]\u001b[0m Trial 1450 finished with value: 4.723420621713891 and parameters: {'n_hidden': 3, 'learning_rate': 0.001113385934709032, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023445112008757856, 'dropout_rate_Layer_2': 0.30941820524406194, 'dropout_rate_Layer_3': 0.317480431248541, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017463433753801562, 'l1_Layer_2': 0.02051155749731817, 'l1_Layer_3': 2.180025846198173e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 275, 'n_units_Layer_3': 230}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 11.89% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 23.58% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:22:16,492]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:22:23,794]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:22:27,357]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:22:28,108]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:22:33,541]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:22:37,539]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:22:54,913]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:23:01,225]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:23:02,109]\u001b[0m Trial 1457 finished with value: 5.183867189782069 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022157971472937534, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35349114316415325, 'dropout_rate_Layer_2': 0.05882451181922491, 'dropout_rate_Layer_3': 0.11888128210412116, 'dropout_rate_Layer_4': 0.37071772011340304, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.101150403673491e-05, 'l1_Layer_2': 0.003186072983946025, 'l1_Layer_3': 0.0045358886209050505, 'l1_Layer_4': 0.00015054701261745884, 'n_units_Layer_1': 175, 'n_units_Layer_2': 255, 'n_units_Layer_3': 75, 'n_units_Layer_4': 225}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 13.00% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 8.43 | sMAPE for Test Set is: 29.85% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:23:09,392]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:23:11,831]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:23:19,819]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:23:24,038]\u001b[0m Trial 1465 finished with value: 4.720242302067009 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023178014581468525, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11239368134641653, 'dropout_rate_Layer_2': 0.18783678404491685, 'dropout_rate_Layer_3': 0.0710845010522495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005542350349061464, 'l1_Layer_2': 2.3402947241356317e-05, 'l1_Layer_3': 0.0010149475890221312, 'n_units_Layer_1': 110, 'n_units_Layer_2': 125, 'n_units_Layer_3': 130}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.72 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.43 | sMAPE for Test Set is: 27.24% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:23:24,401]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:23:33,927]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:23:37,993]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:23:51,644]\u001b[0m Trial 1463 finished with value: 5.195117939757235 and parameters: {'n_hidden': 4, 'learning_rate': 0.002461619183242517, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35359966664461984, 'dropout_rate_Layer_2': 0.051570644292156076, 'dropout_rate_Layer_3': 0.14186391890952496, 'dropout_rate_Layer_4': 0.349606950970573, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 5.210450389582781e-05, 'l1_Layer_2': 0.004455518700246002, 'l1_Layer_3': 0.0028113401175758742, 'l1_Layer_4': 0.00018584147525570755, 'n_units_Layer_1': 180, 'n_units_Layer_2': 260, 'n_units_Layer_3': 80, 'n_units_Layer_4': 230}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 13.03% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 8.76 | sMAPE for Test Set is: 30.77% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:23:58,303]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:24:07,265]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:24:14,643]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:24:18,907]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:24:24,914]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:24:49,567]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:25:03,721]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:25:14,164]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:25:22,735]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:25:36,934]\u001b[0m Trial 1477 finished with value: 5.147702225058216 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026374691183727672, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34530537096118086, 'dropout_rate_Layer_2': 0.05825598873588285, 'dropout_rate_Layer_3': 0.13391149994324889, 'dropout_rate_Layer_4': 0.35372344798069255, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 6.000401404043082e-05, 'l1_Layer_2': 0.004613479584166208, 'l1_Layer_3': 0.004941247918281346, 'l1_Layer_4': 0.00020820270838144467, 'n_units_Layer_1': 190, 'n_units_Layer_2': 255, 'n_units_Layer_3': 75, 'n_units_Layer_4': 210}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 12.91% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 8.34 | sMAPE for Test Set is: 29.72% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:25:47,132]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:25:51,136]\u001b[0m Trial 1481 finished with value: 5.1354510833608815 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027090673308723325, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34448139991192, 'dropout_rate_Layer_2': 0.05943976779099619, 'dropout_rate_Layer_3': 0.10775994933545761, 'dropout_rate_Layer_4': 0.3588959274984797, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 9.155476233872005e-05, 'l1_Layer_2': 0.005109312579995479, 'l1_Layer_3': 0.005789534769807062, 'l1_Layer_4': 0.00024432379059718766, 'n_units_Layer_1': 170, 'n_units_Layer_2': 250, 'n_units_Layer_3': 85, 'n_units_Layer_4': 210}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 12.87% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 8.37 | sMAPE for Test Set is: 29.77% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:25:57,168]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:26:06,236]\u001b[0m Trial 1482 finished with value: 5.152988050343604 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027773854223991754, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3553773312956618, 'dropout_rate_Layer_2': 0.050181421181725194, 'dropout_rate_Layer_3': 0.10841266379849533, 'dropout_rate_Layer_4': 0.3590853610821957, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 8.704564829990141e-05, 'l1_Layer_2': 0.003115431475208205, 'l1_Layer_3': 0.005198396731994452, 'l1_Layer_4': 0.00026145286592439216, 'n_units_Layer_1': 175, 'n_units_Layer_2': 265, 'n_units_Layer_3': 85, 'n_units_Layer_4': 235}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 12.91% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 8.30 | sMAPE for Test Set is: 29.60% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:26:18,179]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:26:51,682]\u001b[0m Trial 1488 finished with value: 5.130220713650935 and parameters: {'n_hidden': 4, 'learning_rate': 0.002859116797763054, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3708395294724348, 'dropout_rate_Layer_2': 0.06937930430237439, 'dropout_rate_Layer_3': 0.1443136122648377, 'dropout_rate_Layer_4': 0.3544090538820574, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 7.324836676456635e-05, 'l1_Layer_2': 0.0046811567800409465, 'l1_Layer_3': 0.005801390352406705, 'l1_Layer_4': 0.00025965117549012304, 'n_units_Layer_1': 190, 'n_units_Layer_2': 270, 'n_units_Layer_3': 90, 'n_units_Layer_4': 235}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 12.91% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 8.28 | sMAPE for Test Set is: 29.48% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:27:14,074]\u001b[0m Trial 1491 finished with value: 5.1464885161842036 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028871747377366267, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3463490189927743, 'dropout_rate_Layer_2': 0.056156878067820805, 'dropout_rate_Layer_3': 0.10401785984100978, 'dropout_rate_Layer_4': 0.35042761153426544, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 7.436864332474241e-05, 'l1_Layer_2': 0.006273241398818303, 'l1_Layer_3': 0.00347611031016856, 'l1_Layer_4': 0.0003249725276718318, 'n_units_Layer_1': 190, 'n_units_Layer_2': 260, 'n_units_Layer_3': 85, 'n_units_Layer_4': 235}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 12.88% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 8.24 | sMAPE for Test Set is: 29.41% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:27:24,394]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:27:31,114]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:27:38,513]\u001b[0m Trial 1490 finished with value: 5.0806331297982785 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028468422782425167, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3293390782891196, 'dropout_rate_Layer_2': 0.07950788739107735, 'dropout_rate_Layer_3': 0.11198555605890947, 'dropout_rate_Layer_4': 0.35058699672016613, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 7.619379656646582e-05, 'l1_Layer_2': 0.0062646956062255435, 'l1_Layer_3': 0.005759724641318185, 'l1_Layer_4': 0.00031403113890625286, 'n_units_Layer_1': 190, 'n_units_Layer_2': 250, 'n_units_Layer_3': 90, 'n_units_Layer_4': 200}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 12.76% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 8.31 | sMAPE for Test Set is: 29.60% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:27:42,593]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:27:42,995]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:27:54,229]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 01:28:19,393]\u001b[0m Trial 1493 finished with value: 5.091631483791926 and parameters: {'n_hidden': 4, 'learning_rate': 0.0030809618129004385, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32362009650800005, 'dropout_rate_Layer_2': 0.032879659508731965, 'dropout_rate_Layer_3': 0.14027327910338408, 'dropout_rate_Layer_4': 0.34380545058442635, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 9.5580815758958e-05, 'l1_Layer_2': 0.005228059193114137, 'l1_Layer_3': 0.0037453069715002282, 'l1_Layer_4': 0.00020426336275772386, 'n_units_Layer_1': 190, 'n_units_Layer_2': 260, 'n_units_Layer_3': 85, 'n_units_Layer_4': 205}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 12.77% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 8.08 | sMAPE for Test Set is: 28.96% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:28:24,008]\u001b[0m Trial 1498 finished with value: 4.580349102180097 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007346710427535626, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007675398905610108, 'dropout_rate_Layer_2': 0.004130458647006147, 'dropout_rate_Layer_3': 0.31515276315072227, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001275455460218694, 'l1_Layer_2': 0.010695959580824069, 'l1_Layer_3': 2.971275450810604e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 270, 'n_units_Layer_3': 270}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 11.52% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.11 | sMAPE for Test Set is: 22.90% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 01:28:29,847]\u001b[0m Trial 1492 finished with value: 4.911741673995219 and parameters: {'n_hidden': 4, 'learning_rate': 0.002742789637734381, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3314995067011465, 'dropout_rate_Layer_2': 0.03745929162739924, 'dropout_rate_Layer_3': 0.10249491858542702, 'dropout_rate_Layer_4': 0.34741089266433056, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 7.150227742035762e-05, 'l1_Layer_2': 0.006213707299355995, 'l1_Layer_3': 0.003504340922366784, 'l1_Layer_4': 0.0002992989761881092, 'n_units_Layer_1': 185, 'n_units_Layer_2': 250, 'n_units_Layer_3': 85, 'n_units_Layer_4': 205}. Best is trial 1254 with value: 4.433290079958611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 12.29% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 7.74 | sMAPE for Test Set is: 28.12% | rMAE for Test Set is: 0.97\n",
      "for 2020-01-01, MAE is:5.04 & sMAPE is:14.85% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 14.85% & 0.61\n",
      "for 2020-01-02, MAE is:7.03 & sMAPE is:18.70% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 16.78% & 0.88\n",
      "for 2020-01-03, MAE is:4.44 & sMAPE is:12.03% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 15.19% & 0.98\n",
      "for 2020-01-04, MAE is:3.74 & sMAPE is:10.68% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 14.07% & 1.07\n",
      "for 2020-01-05, MAE is:3.54 & sMAPE is:9.73% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 13.20% & 1.01\n",
      "for 2020-01-06, MAE is:3.11 & sMAPE is:8.22% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 12.37% & 1.03\n",
      "for 2020-01-07, MAE is:6.68 & sMAPE is:16.96% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 13.02% & 1.04\n",
      "for 2020-01-08, MAE is:8.53 & sMAPE is:22.46% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 14.20% & 1.00\n",
      "for 2020-01-09, MAE is:5.12 & sMAPE is:13.37% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 14.11% & 1.04\n",
      "for 2020-01-10, MAE is:5.64 & sMAPE is:13.78% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 14.08% & 1.11\n",
      "for 2020-01-11, MAE is:3.24 & sMAPE is:9.47% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 13.66% & 1.08\n",
      "for 2020-01-12, MAE is:4.19 & sMAPE is:12.88% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 13.59% & 1.05\n",
      "for 2020-01-13, MAE is:6.60 & sMAPE is:17.94% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 13.93% & 1.09\n",
      "for 2020-01-14, MAE is:7.54 & sMAPE is:27.69% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 14.91% & 1.06\n",
      "for 2020-01-15, MAE is:5.29 & sMAPE is:17.42% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 15.08% & 1.03\n",
      "for 2020-01-16, MAE is:4.59 & sMAPE is:12.44% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 14.91% & 1.05\n",
      "for 2020-01-17, MAE is:3.20 & sMAPE is:8.76% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.15 & 14.55% & 1.05\n",
      "for 2020-01-18, MAE is:2.42 & sMAPE is:7.19% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 14.14% & 1.02\n",
      "for 2020-01-19, MAE is:2.42 & sMAPE is:7.01% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 13.77% & 1.00\n",
      "for 2020-01-20, MAE is:6.17 & sMAPE is:14.21% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.93 & 13.79% & 1.00\n",
      "for 2020-01-21, MAE is:6.92 & sMAPE is:14.62% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.83% & 0.97\n",
      "for 2020-01-22, MAE is:10.63 & sMAPE is:22.34% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 14.22% & 0.95\n",
      "for 2020-01-23, MAE is:9.31 & sMAPE is:18.90% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 14.42% & 0.94\n",
      "for 2020-01-24, MAE is:7.90 & sMAPE is:16.00% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 14.49% & 0.93\n",
      "for 2020-01-25, MAE is:6.49 & sMAPE is:17.98% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 14.63% & 0.95\n",
      "for 2020-01-26, MAE is:4.50 & sMAPE is:13.60% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 14.59% & 0.95\n",
      "for 2020-01-27, MAE is:5.64 & sMAPE is:16.47% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 14.66% & 0.93\n",
      "for 2020-01-28, MAE is:5.80 & sMAPE is:16.71% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 14.73% & 0.92\n",
      "for 2020-01-29, MAE is:3.86 & sMAPE is:11.67% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 14.62% & 0.89\n",
      "for 2020-01-30, MAE is:4.05 & sMAPE is:10.86% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 14.50% & 0.87\n",
      "for 2020-01-31, MAE is:7.89 & sMAPE is:25.32% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 14.85% & 0.86\n",
      "for 2020-02-01, MAE is:4.25 & sMAPE is:15.40% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 14.87% & 0.85\n",
      "for 2020-02-02, MAE is:7.47 & sMAPE is:26.49% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 15.22% & 0.85\n",
      "for 2020-02-03, MAE is:6.01 & sMAPE is:25.38% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 15.52% & 0.85\n",
      "for 2020-02-04, MAE is:5.19 & sMAPE is:20.09% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 15.65% & 0.85\n",
      "for 2020-02-05, MAE is:5.27 & sMAPE is:14.81% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 15.62% & 0.88\n",
      "for 2020-02-06, MAE is:2.98 & sMAPE is:8.54% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 15.43% & 0.88\n",
      "for 2020-02-07, MAE is:5.22 & sMAPE is:14.45% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 15.41% & 0.88\n",
      "for 2020-02-08, MAE is:6.16 & sMAPE is:20.04% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 15.53% & 0.90\n",
      "for 2020-02-09, MAE is:8.97 & sMAPE is:41.33% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 16.17% & 0.90\n",
      "for 2020-02-10, MAE is:8.26 & sMAPE is:41.55% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 16.79% & 0.92\n",
      "for 2020-02-11, MAE is:6.40 & sMAPE is:24.84% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 16.98% & 0.94\n",
      "for 2020-02-12, MAE is:7.03 & sMAPE is:24.92% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 17.17% & 0.94\n",
      "for 2020-02-13, MAE is:5.98 & sMAPE is:15.83% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 17.14% & 0.97\n",
      "for 2020-02-14, MAE is:5.44 & sMAPE is:15.89% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 17.11% & 1.00\n",
      "for 2020-02-15, MAE is:4.77 & sMAPE is:17.15% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 17.11% & 0.99\n",
      "for 2020-02-16, MAE is:10.13 & sMAPE is:55.88% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 17.93% & 1.00\n",
      "for 2020-02-17, MAE is:6.41 & sMAPE is:30.71% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 18.20% & 1.02\n",
      "for 2020-02-18, MAE is:6.84 & sMAPE is:25.91% & rMAE is:2.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 18.36% & 1.05\n",
      "for 2020-02-19, MAE is:3.72 & sMAPE is:12.38% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 18.24% & 1.05\n",
      "for 2020-02-20, MAE is:6.28 & sMAPE is:19.16% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 18.26% & 1.04\n",
      "for 2020-02-21, MAE is:5.48 & sMAPE is:18.35% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 18.26% & 1.04\n",
      "for 2020-02-22, MAE is:4.04 & sMAPE is:14.03% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 18.18% & 1.03\n",
      "for 2020-02-23, MAE is:4.54 & sMAPE is:15.43% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 18.13% & 1.02\n",
      "for 2020-02-24, MAE is:5.50 & sMAPE is:16.45% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 18.10% & 1.01\n",
      "for 2020-02-25, MAE is:4.40 & sMAPE is:15.33% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 18.05% & 1.02\n",
      "for 2020-02-26, MAE is:3.34 & sMAPE is:10.19% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 17.91% & 1.03\n",
      "for 2020-02-27, MAE is:6.81 & sMAPE is:18.33% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 17.92% & 1.03\n",
      "for 2020-02-28, MAE is:6.26 & sMAPE is:19.52% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 17.94% & 1.05\n",
      "for 2020-02-29, MAE is:8.36 & sMAPE is:33.58% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 18.20% & 1.05\n",
      "for 2020-03-01, MAE is:7.46 & sMAPE is:37.92% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 18.53% & 1.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-03-02, MAE is:3.78 & sMAPE is:11.72% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 18.42% & 1.04\n",
      "for 2020-03-03, MAE is:5.45 & sMAPE is:14.77% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 18.36% & 1.03\n",
      "for 2020-03-04, MAE is:6.02 & sMAPE is:14.28% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 18.30% & 1.03\n",
      "for 2020-03-05, MAE is:4.79 & sMAPE is:13.14% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 18.22% & 1.03\n",
      "for 2020-03-06, MAE is:3.25 & sMAPE is:10.92% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 18.11% & 1.02\n",
      "for 2020-03-07, MAE is:3.61 & sMAPE is:12.13% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 18.02% & 1.02\n",
      "for 2020-03-08, MAE is:9.74 & sMAPE is:45.61% & rMAE is:2.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 18.42% & 1.04\n",
      "for 2020-03-09, MAE is:5.51 & sMAPE is:14.58% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 18.37% & 1.05\n",
      "for 2020-03-10, MAE is:10.50 & sMAPE is:34.65% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 18.60% & 1.05\n",
      "for 2020-03-11, MAE is:5.21 & sMAPE is:19.35% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.75 & 18.61% & 1.04\n",
      "for 2020-03-12, MAE is:9.22 & sMAPE is:43.85% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 18.96% & 1.03\n",
      "for 2020-03-13, MAE is:5.86 & sMAPE is:22.26% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 19.01% & 1.04\n",
      "for 2020-03-14, MAE is:4.77 & sMAPE is:15.94% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 18.96% & 1.05\n",
      "for 2020-03-15, MAE is:9.81 & sMAPE is:46.42% & rMAE is:4.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 19.33% & 1.10\n",
      "for 2020-03-16, MAE is:6.34 & sMAPE is:19.93% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 19.34% & 1.10\n",
      "for 2020-03-17, MAE is:5.22 & sMAPE is:18.02% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 19.32% & 1.09\n",
      "for 2020-03-18, MAE is:6.69 & sMAPE is:23.31% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 19.37% & 1.10\n",
      "for 2020-03-19, MAE is:4.72 & sMAPE is:15.68% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 19.33% & 1.09\n",
      "for 2020-03-20, MAE is:7.84 & sMAPE is:28.60% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 19.44% & 1.09\n",
      "for 2020-03-21, MAE is:14.32 & sMAPE is:78.00% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 20.16% & 1.09\n",
      "for 2020-03-22, MAE is:18.93 & sMAPE is:116.73% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 21.34% & 1.09\n",
      "for 2020-03-23, MAE is:9.08 & sMAPE is:46.98% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 21.65% & 1.09\n",
      "for 2020-03-24, MAE is:6.32 & sMAPE is:28.04% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 21.73% & 1.09\n",
      "for 2020-03-25, MAE is:6.35 & sMAPE is:24.80% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 21.76% & 1.10\n",
      "for 2020-03-26, MAE is:5.91 & sMAPE is:24.61% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 21.80% & 1.10\n",
      "for 2020-03-27, MAE is:7.27 & sMAPE is:29.17% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 21.88% & 1.11\n",
      "for 2020-03-28, MAE is:11.37 & sMAPE is:66.90% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 22.39% & 1.11\n",
      "for 2020-03-29, MAE is:20.36 & sMAPE is:133.05% & rMAE is:4.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 23.64% & 1.15\n",
      "for 2020-03-30, MAE is:4.88 & sMAPE is:20.72% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 23.60% & 1.14\n",
      "for 2020-03-31, MAE is:6.20 & sMAPE is:24.10% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 23.61% & 1.15\n",
      "for 2020-04-01, MAE is:6.01 & sMAPE is:23.61% & rMAE is:2.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 23.61% & 1.17\n",
      "for 2020-04-02, MAE is:4.72 & sMAPE is:19.58% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 23.57% & 1.17\n",
      "for 2020-04-03, MAE is:3.88 & sMAPE is:17.12% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 23.50% & 1.18\n",
      "for 2020-04-04, MAE is:5.60 & sMAPE is:27.49% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 23.54% & 1.18\n",
      "for 2020-04-05, MAE is:15.93 & sMAPE is:108.43% & rMAE is:2.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 24.42% & 1.19\n",
      "for 2020-04-06, MAE is:9.93 & sMAPE is:59.53% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 24.79% & 1.20\n",
      "for 2020-04-07, MAE is:7.15 & sMAPE is:29.45% & rMAE is:3.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 24.83% & 1.22\n",
      "for 2020-04-08, MAE is:5.64 & sMAPE is:20.93% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 24.79% & 1.22\n",
      "for 2020-04-09, MAE is:6.28 & sMAPE is:25.16% & rMAE is:3.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 24.80% & 1.24\n",
      "for 2020-04-10, MAE is:7.13 & sMAPE is:30.71% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 24.86% & 1.25\n",
      "for 2020-04-11, MAE is:5.75 & sMAPE is:31.08% & rMAE is:2.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 24.92% & 1.26\n",
      "for 2020-04-12, MAE is:10.29 & sMAPE is:72.97% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 25.38% & 1.26\n",
      "for 2020-04-13, MAE is:29.92 & sMAPE is:148.20% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 26.56% & 1.26\n",
      "for 2020-04-14, MAE is:4.65 & sMAPE is:19.69% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 26.50% & 1.26\n",
      "for 2020-04-15, MAE is:8.21 & sMAPE is:37.47% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 26.60% & 1.27\n",
      "for 2020-04-16, MAE is:5.22 & sMAPE is:22.28% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 26.56% & 1.28\n",
      "for 2020-04-17, MAE is:5.04 & sMAPE is:20.37% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 26.50% & 1.27\n",
      "for 2020-04-18, MAE is:5.15 & sMAPE is:24.11% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 26.48% & 1.28\n",
      "for 2020-04-19, MAE is:10.14 & sMAPE is:71.43% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 26.89% & 1.29\n",
      "for 2020-04-20, MAE is:12.86 & sMAPE is:97.00% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 27.52% & 1.28\n",
      "for 2020-04-21, MAE is:17.30 & sMAPE is:109.87% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 28.26% & 1.28\n",
      "for 2020-04-22, MAE is:12.19 & sMAPE is:83.96% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 28.75% & 1.28\n",
      "for 2020-04-23, MAE is:7.07 & sMAPE is:27.42% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 28.74% & 1.29\n",
      "for 2020-04-24, MAE is:6.55 & sMAPE is:29.72% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 28.75% & 1.29\n",
      "for 2020-04-25, MAE is:5.61 & sMAPE is:30.52% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 28.76% & 1.29\n",
      "for 2020-04-26, MAE is:4.12 & sMAPE is:24.02% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 28.72% & 1.28\n",
      "for 2020-04-27, MAE is:4.59 & sMAPE is:18.51% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 28.64% & 1.28\n",
      "for 2020-04-28, MAE is:3.89 & sMAPE is:15.37% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 28.52% & 1.27\n",
      "for 2020-04-29, MAE is:4.01 & sMAPE is:17.30% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 28.43% & 1.26\n",
      "for 2020-04-30, MAE is:7.10 & sMAPE is:36.24% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 28.50% & 1.26\n",
      "for 2020-05-01, MAE is:9.13 & sMAPE is:65.30% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 28.80% & 1.25\n",
      "for 2020-05-02, MAE is:7.88 & sMAPE is:57.22% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 29.03% & 1.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-05-03, MAE is:7.58 & sMAPE is:49.54% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 29.19% & 1.26\n",
      "for 2020-05-04, MAE is:4.63 & sMAPE is:20.52% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 29.12% & 1.26\n",
      "for 2020-05-05, MAE is:7.21 & sMAPE is:31.52% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 29.14% & 1.26\n",
      "for 2020-05-06, MAE is:5.02 & sMAPE is:22.17% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 29.09% & 1.27\n",
      "for 2020-05-07, MAE is:5.99 & sMAPE is:27.33% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 29.07% & 1.27\n",
      "for 2020-05-08, MAE is:4.13 & sMAPE is:18.91% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 29.00% & 1.26\n",
      "for 2020-05-09, MAE is:5.47 & sMAPE is:24.78% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 28.96% & 1.26\n",
      "for 2020-05-10, MAE is:10.71 & sMAPE is:66.54% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 29.25% & 1.26\n",
      "for 2020-05-11, MAE is:10.54 & sMAPE is:72.16% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 29.58% & 1.26\n",
      "for 2020-05-12, MAE is:3.32 & sMAPE is:14.61% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 29.46% & 1.26\n",
      "for 2020-05-13, MAE is:5.99 & sMAPE is:25.68% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 29.43% & 1.27\n",
      "for 2020-05-14, MAE is:5.67 & sMAPE is:23.75% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 29.39% & 1.27\n",
      "for 2020-05-15, MAE is:5.93 & sMAPE is:25.21% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 29.36% & 1.28\n",
      "for 2020-05-16, MAE is:4.77 & sMAPE is:25.80% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 29.34% & 1.28\n",
      "for 2020-05-17, MAE is:12.36 & sMAPE is:72.18% & rMAE is:2.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 29.65% & 1.29\n",
      "for 2020-05-18, MAE is:6.36 & sMAPE is:31.60% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 29.66% & 1.29\n",
      "for 2020-05-19, MAE is:4.22 & sMAPE is:18.30% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 29.58% & 1.29\n",
      "for 2020-05-20, MAE is:5.36 & sMAPE is:22.87% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 29.53% & 1.29\n",
      "for 2020-05-21, MAE is:6.50 & sMAPE is:30.77% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 29.54% & 1.29\n",
      "for 2020-05-22, MAE is:8.01 & sMAPE is:39.56% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 29.61% & 1.30\n",
      "for 2020-05-23, MAE is:18.33 & sMAPE is:102.32% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 30.12% & 1.30\n",
      "for 2020-05-24, MAE is:20.98 & sMAPE is:149.76% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 30.94% & 1.30\n",
      "for 2020-05-25, MAE is:4.14 & sMAPE is:22.48% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 30.88% & 1.30\n",
      "for 2020-05-26, MAE is:4.56 & sMAPE is:17.97% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 30.79% & 1.30\n",
      "for 2020-05-27, MAE is:5.12 & sMAPE is:20.57% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 30.73% & 1.30\n",
      "for 2020-05-28, MAE is:5.94 & sMAPE is:27.32% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 30.70% & 1.31\n",
      "for 2020-05-29, MAE is:5.18 & sMAPE is:24.24% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 30.66% & 1.31\n",
      "for 2020-05-30, MAE is:9.62 & sMAPE is:62.00% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 30.87% & 1.30\n",
      "for 2020-05-31, MAE is:15.84 & sMAPE is:119.47% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 31.45% & 1.30\n",
      "for 2020-06-01, MAE is:9.28 & sMAPE is:81.69% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 31.78% & 1.30\n",
      "for 2020-06-02, MAE is:6.13 & sMAPE is:23.78% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 31.73% & 1.31\n",
      "for 2020-06-03, MAE is:3.04 & sMAPE is:10.28% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 31.59% & 1.30\n",
      "for 2020-06-04, MAE is:6.00 & sMAPE is:22.63% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 31.53% & 1.30\n",
      "for 2020-06-05, MAE is:4.08 & sMAPE is:17.53% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 31.44% & 1.30\n",
      "for 2020-06-06, MAE is:13.89 & sMAPE is:120.71% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 32.01% & 1.30\n",
      "for 2020-06-07, MAE is:4.32 & sMAPE is:25.18% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 31.96% & 1.29\n",
      "for 2020-06-08, MAE is:6.67 & sMAPE is:23.24% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 31.91% & 1.29\n",
      "for 2020-06-09, MAE is:7.85 & sMAPE is:22.48% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 31.85% & 1.28\n",
      "for 2020-06-10, MAE is:4.89 & sMAPE is:15.95% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 31.75% & 1.28\n",
      "for 2020-06-11, MAE is:3.76 & sMAPE is:14.67% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 31.65% & 1.28\n",
      "for 2020-06-12, MAE is:2.70 & sMAPE is:12.94% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 31.53% & 1.28\n",
      "for 2020-06-13, MAE is:2.11 & sMAPE is:10.64% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 31.41% & 1.27\n",
      "for 2020-06-14, MAE is:4.67 & sMAPE is:20.67% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 31.34% & 1.27\n",
      "for 2020-06-15, MAE is:6.03 & sMAPE is:20.88% & rMAE is:2.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 31.28% & 1.28\n",
      "for 2020-06-16, MAE is:4.69 & sMAPE is:14.30% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 31.18% & 1.28\n",
      "for 2020-06-17, MAE is:7.79 & sMAPE is:22.42% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 31.13% & 1.28\n",
      "for 2020-06-18, MAE is:3.58 & sMAPE is:11.56% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 31.01% & 1.27\n",
      "for 2020-06-19, MAE is:2.88 & sMAPE is:9.69% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 30.89% & 1.27\n",
      "for 2020-06-20, MAE is:2.77 & sMAPE is:12.03% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 30.78% & 1.27\n",
      "for 2020-06-21, MAE is:5.36 & sMAPE is:30.35% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 30.77% & 1.26\n",
      "for 2020-06-22, MAE is:3.89 & sMAPE is:13.78% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 30.68% & 1.26\n",
      "for 2020-06-23, MAE is:3.87 & sMAPE is:11.90% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 30.57% & 1.26\n",
      "for 2020-06-24, MAE is:3.05 & sMAPE is:8.68% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 30.45% & 1.26\n",
      "for 2020-06-25, MAE is:3.10 & sMAPE is:9.52% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 30.33% & 1.26\n",
      "for 2020-06-26, MAE is:3.92 & sMAPE is:11.46% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 30.22% & 1.26\n",
      "for 2020-06-27, MAE is:2.76 & sMAPE is:10.70% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 30.11% & 1.25\n",
      "for 2020-06-28, MAE is:8.95 & sMAPE is:58.50% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 30.27% & 1.26\n",
      "for 2020-06-29, MAE is:5.43 & sMAPE is:22.71% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 30.23% & 1.26\n",
      "for 2020-06-30, MAE is:7.03 & sMAPE is:30.64% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 30.23% & 1.26\n",
      "for 2020-07-01, MAE is:4.64 & sMAPE is:14.58% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 30.14% & 1.26\n",
      "for 2020-07-02, MAE is:4.79 & sMAPE is:13.17% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 30.05% & 1.25\n",
      "for 2020-07-03, MAE is:5.91 & sMAPE is:18.02% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 29.99% & 1.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-07-04, MAE is:5.67 & sMAPE is:25.92% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 29.97% & 1.25\n",
      "for 2020-07-05, MAE is:23.03 & sMAPE is:140.98% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 30.56% & 1.25\n",
      "for 2020-07-06, MAE is:8.47 & sMAPE is:61.01% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 30.72% & 1.25\n",
      "for 2020-07-07, MAE is:6.49 & sMAPE is:23.07% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 30.68% & 1.25\n",
      "for 2020-07-08, MAE is:8.36 & sMAPE is:22.10% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 30.64% & 1.25\n",
      "for 2020-07-09, MAE is:7.10 & sMAPE is:18.26% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 30.57% & 1.25\n",
      "for 2020-07-10, MAE is:7.95 & sMAPE is:24.00% & rMAE is:2.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 30.54% & 1.25\n",
      "for 2020-07-11, MAE is:3.42 & sMAPE is:12.88% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 30.45% & 1.25\n",
      "for 2020-07-12, MAE is:4.46 & sMAPE is:18.92% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 30.39% & 1.25\n",
      "for 2020-07-13, MAE is:6.42 & sMAPE is:20.21% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 30.33% & 1.24\n",
      "for 2020-07-14, MAE is:3.50 & sMAPE is:9.79% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 30.23% & 1.24\n",
      "for 2020-07-15, MAE is:4.47 & sMAPE is:11.46% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 30.13% & 1.24\n",
      "for 2020-07-16, MAE is:5.66 & sMAPE is:13.17% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 30.05% & 1.24\n",
      "for 2020-07-17, MAE is:2.01 & sMAPE is:5.34% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 29.92% & 1.23\n",
      "for 2020-07-18, MAE is:3.82 & sMAPE is:14.79% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 29.85% & 1.24\n",
      "for 2020-07-19, MAE is:2.60 & sMAPE is:10.01% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 29.75% & 1.24\n",
      "for 2020-07-20, MAE is:4.90 & sMAPE is:16.70% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 29.68% & 1.24\n",
      "for 2020-07-21, MAE is:6.93 & sMAPE is:25.24% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 29.66% & 1.24\n",
      "for 2020-07-22, MAE is:4.80 & sMAPE is:15.53% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 29.59% & 1.23\n",
      "for 2020-07-23, MAE is:7.14 & sMAPE is:23.63% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 29.56% & 1.23\n",
      "for 2020-07-24, MAE is:8.07 & sMAPE is:29.29% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 29.56% & 1.23\n",
      "for 2020-07-25, MAE is:4.59 & sMAPE is:20.02% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 29.52% & 1.23\n",
      "for 2020-07-26, MAE is:12.18 & sMAPE is:73.83% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 29.73% & 1.23\n",
      "for 2020-07-27, MAE is:6.03 & sMAPE is:21.48% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 29.69% & 1.23\n",
      "for 2020-07-28, MAE is:11.94 & sMAPE is:55.91% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 29.82% & 1.23\n",
      "for 2020-07-29, MAE is:8.41 & sMAPE is:42.55% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 29.88% & 1.23\n",
      "for 2020-07-30, MAE is:8.96 & sMAPE is:31.28% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 29.88% & 1.23\n",
      "for 2020-07-31, MAE is:6.59 & sMAPE is:20.96% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 29.84% & 1.23\n",
      "for 2020-08-01, MAE is:6.91 & sMAPE is:28.46% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 29.83% & 1.23\n",
      "for 2020-08-02, MAE is:2.84 & sMAPE is:12.38% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 29.75% & 1.23\n",
      "for 2020-08-03, MAE is:5.55 & sMAPE is:15.80% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 29.69% & 1.22\n",
      "for 2020-08-04, MAE is:3.64 & sMAPE is:11.17% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 29.60% & 1.22\n",
      "for 2020-08-05, MAE is:9.16 & sMAPE is:32.93% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 29.62% & 1.22\n",
      "for 2020-08-06, MAE is:7.36 & sMAPE is:23.97% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 29.59% & 1.22\n",
      "for 2020-08-07, MAE is:5.27 & sMAPE is:16.11% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 29.53% & 1.22\n",
      "for 2020-08-08, MAE is:3.65 & sMAPE is:12.30% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 29.45% & 1.22\n",
      "for 2020-08-09, MAE is:2.66 & sMAPE is:9.37% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 29.36% & 1.22\n",
      "for 2020-08-10, MAE is:7.68 & sMAPE is:22.58% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 29.33% & 1.22\n",
      "for 2020-08-11, MAE is:6.15 & sMAPE is:19.61% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 29.29% & 1.22\n",
      "for 2020-08-12, MAE is:7.16 & sMAPE is:22.37% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 29.26% & 1.22\n",
      "for 2020-08-13, MAE is:11.57 & sMAPE is:35.57% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 29.29% & 1.22\n",
      "for 2020-08-14, MAE is:5.54 & sMAPE is:16.65% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 29.23% & 1.22\n",
      "for 2020-08-15, MAE is:3.92 & sMAPE is:12.15% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 29.16% & 1.22\n",
      "for 2020-08-16, MAE is:5.04 & sMAPE is:17.49% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 29.10% & 1.23\n",
      "for 2020-08-17, MAE is:6.95 & sMAPE is:17.45% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 29.05% & 1.23\n",
      "for 2020-08-18, MAE is:11.92 & sMAPE is:31.25% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 29.06% & 1.23\n",
      "for 2020-08-19, MAE is:4.51 & sMAPE is:12.20% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 28.99% & 1.23\n",
      "for 2020-08-20, MAE is:8.89 & sMAPE is:23.91% & rMAE is:2.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 28.97% & 1.24\n",
      "for 2020-08-21, MAE is:4.84 & sMAPE is:16.80% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 28.92% & 1.23\n",
      "for 2020-08-22, MAE is:8.17 & sMAPE is:36.77% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 28.95% & 1.23\n",
      "for 2020-08-23, MAE is:6.45 & sMAPE is:34.86% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 28.98% & 1.23\n",
      "for 2020-08-24, MAE is:13.81 & sMAPE is:33.17% & rMAE is:2.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 28.99% & 1.24\n",
      "for 2020-08-25, MAE is:6.61 & sMAPE is:17.28% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 28.94% & 1.24\n",
      "for 2020-08-26, MAE is:9.83 & sMAPE is:45.18% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 29.01% & 1.23\n",
      "for 2020-08-27, MAE is:22.02 & sMAPE is:52.31% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 29.11% & 1.24\n",
      "for 2020-08-28, MAE is:4.31 & sMAPE is:11.38% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 29.04% & 1.23\n",
      "for 2020-08-29, MAE is:7.55 & sMAPE is:22.35% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 29.01% & 1.23\n",
      "for 2020-08-30, MAE is:4.01 & sMAPE is:12.88% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 28.94% & 1.23\n",
      "for 2020-08-31, MAE is:17.60 & sMAPE is:35.15% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 28.97% & 1.23\n",
      "for 2020-09-01, MAE is:4.89 & sMAPE is:9.64% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 28.89% & 1.23\n",
      "for 2020-09-02, MAE is:7.66 & sMAPE is:15.70% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 28.83% & 1.22\n",
      "for 2020-09-03, MAE is:7.94 & sMAPE is:19.47% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 28.80% & 1.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-09-04, MAE is:9.37 & sMAPE is:25.22% & rMAE is:3.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 28.78% & 1.23\n",
      "for 2020-09-05, MAE is:5.84 & sMAPE is:18.09% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 28.74% & 1.23\n",
      "for 2020-09-06, MAE is:5.62 & sMAPE is:16.13% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 28.69% & 1.23\n",
      "for 2020-09-07, MAE is:6.82 & sMAPE is:15.67% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 28.64% & 1.23\n",
      "for 2020-09-08, MAE is:5.65 & sMAPE is:12.94% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 28.57% & 1.23\n",
      "for 2020-09-09, MAE is:7.45 & sMAPE is:18.89% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 28.54% & 1.23\n",
      "for 2020-09-10, MAE is:8.94 & sMAPE is:18.73% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 28.50% & 1.23\n",
      "for 2020-09-11, MAE is:8.73 & sMAPE is:19.64% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 28.46% & 1.23\n",
      "for 2020-09-12, MAE is:7.14 & sMAPE is:22.80% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 28.44% & 1.23\n",
      "for 2020-09-13, MAE is:11.77 & sMAPE is:52.61% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 28.53% & 1.23\n",
      "for 2020-09-14, MAE is:15.39 & sMAPE is:28.54% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 28.53% & 1.23\n",
      "for 2020-09-15, MAE is:22.20 & sMAPE is:28.82% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 28.54% & 1.23\n",
      "for 2020-09-16, MAE is:14.42 & sMAPE is:26.64% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 28.53% & 1.23\n",
      "for 2020-09-17, MAE is:8.62 & sMAPE is:18.61% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 28.49% & 1.23\n",
      "for 2020-09-18, MAE is:9.40 & sMAPE is:22.22% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 28.47% & 1.23\n",
      "for 2020-09-19, MAE is:4.98 & sMAPE is:14.53% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 28.41% & 1.23\n",
      "for 2020-09-20, MAE is:5.59 & sMAPE is:16.04% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 28.37% & 1.23\n",
      "for 2020-09-21, MAE is:20.23 & sMAPE is:31.35% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 28.38% & 1.23\n",
      "for 2020-09-22, MAE is:12.47 & sMAPE is:26.00% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 28.37% & 1.23\n",
      "for 2020-09-23, MAE is:14.40 & sMAPE is:37.33% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 28.40% & 1.23\n",
      "for 2020-09-24, MAE is:8.83 & sMAPE is:24.58% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 28.39% & 1.23\n",
      "for 2020-09-25, MAE is:6.22 & sMAPE is:16.79% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 28.35% & 1.23\n",
      "for 2020-09-26, MAE is:3.44 & sMAPE is:10.32% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 28.28% & 1.22\n",
      "for 2020-09-27, MAE is:8.07 & sMAPE is:28.61% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 28.28% & 1.22\n",
      "for 2020-09-28, MAE is:11.39 & sMAPE is:25.39% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 28.27% & 1.22\n",
      "for 2020-09-29, MAE is:13.67 & sMAPE is:22.73% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 28.25% & 1.22\n",
      "for 2020-09-30, MAE is:6.33 & sMAPE is:12.74% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 28.19% & 1.22\n",
      "for 2020-10-01, MAE is:5.44 & sMAPE is:13.33% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 28.14% & 1.22\n",
      "for 2020-10-02, MAE is:4.89 & sMAPE is:13.96% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 28.09% & 1.21\n",
      "for 2020-10-03, MAE is:4.75 & sMAPE is:13.94% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 28.04% & 1.21\n",
      "for 2020-10-04, MAE is:8.11 & sMAPE is:34.53% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 28.06% & 1.21\n",
      "for 2020-10-05, MAE is:7.81 & sMAPE is:31.12% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 28.07% & 1.21\n",
      "for 2020-10-06, MAE is:3.88 & sMAPE is:13.65% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 28.02% & 1.21\n",
      "for 2020-10-07, MAE is:8.67 & sMAPE is:24.19% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 28.00% & 1.21\n",
      "for 2020-10-08, MAE is:5.99 & sMAPE is:15.64% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 27.96% & 1.20\n",
      "for 2020-10-09, MAE is:4.91 & sMAPE is:11.59% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 27.90% & 1.20\n",
      "for 2020-10-10, MAE is:3.86 & sMAPE is:9.63% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 27.84% & 1.20\n",
      "for 2020-10-11, MAE is:3.21 & sMAPE is:9.62% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 27.77% & 1.20\n",
      "for 2020-10-12, MAE is:14.26 & sMAPE is:33.76% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 27.80% & 1.20\n",
      "for 2020-10-13, MAE is:6.21 & sMAPE is:14.88% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 27.75% & 1.20\n",
      "for 2020-10-14, MAE is:6.42 & sMAPE is:18.16% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 27.72% & 1.20\n",
      "for 2020-10-15, MAE is:6.78 & sMAPE is:17.84% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 27.68% & 1.19\n",
      "for 2020-10-16, MAE is:6.51 & sMAPE is:14.80% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 27.64% & 1.20\n",
      "for 2020-10-17, MAE is:3.36 & sMAPE is:8.84% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 27.57% & 1.19\n",
      "for 2020-10-18, MAE is:7.86 & sMAPE is:20.75% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 27.55% & 1.19\n",
      "for 2020-10-19, MAE is:6.89 & sMAPE is:15.35% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 27.51% & 1.19\n",
      "for 2020-10-20, MAE is:5.35 & sMAPE is:13.43% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 27.46% & 1.19\n",
      "for 2020-10-21, MAE is:5.05 & sMAPE is:12.80% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 27.41% & 1.19\n",
      "for 2020-10-22, MAE is:5.00 & sMAPE is:13.30% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 27.36% & 1.19\n",
      "for 2020-10-23, MAE is:7.19 & sMAPE is:16.94% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 27.33% & 1.19\n",
      "for 2020-10-24, MAE is:6.77 & sMAPE is:19.32% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 27.30% & 1.19\n",
      "for 2020-10-25, MAE is:14.15 & sMAPE is:74.65% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 27.46% & 1.19\n",
      "for 2020-10-26, MAE is:6.69 & sMAPE is:18.83% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 27.43% & 1.19\n",
      "for 2020-10-27, MAE is:6.46 & sMAPE is:16.00% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 27.39% & 1.19\n",
      "for 2020-10-28, MAE is:7.02 & sMAPE is:18.66% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 27.36% & 1.19\n",
      "for 2020-10-29, MAE is:8.36 & sMAPE is:24.95% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 27.36% & 1.19\n",
      "for 2020-10-30, MAE is:6.55 & sMAPE is:27.76% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 27.36% & 1.19\n",
      "for 2020-10-31, MAE is:4.37 & sMAPE is:13.94% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 27.31% & 1.18\n",
      "for 2020-11-01, MAE is:10.61 & sMAPE is:40.22% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 27.36% & 1.18\n",
      "for 2020-11-02, MAE is:9.99 & sMAPE is:51.16% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 27.43% & 1.18\n",
      "for 2020-11-03, MAE is:4.87 & sMAPE is:14.17% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 27.39% & 1.18\n",
      "for 2020-11-04, MAE is:6.36 & sMAPE is:16.26% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 27.35% & 1.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-11-05, MAE is:3.52 & sMAPE is:8.75% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 27.29% & 1.18\n",
      "for 2020-11-06, MAE is:5.10 & sMAPE is:13.34% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 27.25% & 1.18\n",
      "for 2020-11-07, MAE is:4.26 & sMAPE is:11.43% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 27.20% & 1.18\n",
      "for 2020-11-08, MAE is:4.29 & sMAPE is:12.25% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 27.15% & 1.18\n",
      "for 2020-11-09, MAE is:4.61 & sMAPE is:9.99% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 27.10% & 1.17\n",
      "for 2020-11-10, MAE is:5.81 & sMAPE is:11.70% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 27.05% & 1.17\n",
      "for 2020-11-11, MAE is:4.60 & sMAPE is:9.91% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 26.99% & 1.17\n",
      "for 2020-11-12, MAE is:3.72 & sMAPE is:9.24% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 26.94% & 1.17\n",
      "for 2020-11-13, MAE is:3.18 & sMAPE is:7.62% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 26.88% & 1.17\n",
      "for 2020-11-14, MAE is:4.74 & sMAPE is:12.47% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 26.83% & 1.17\n",
      "for 2020-11-15, MAE is:14.89 & sMAPE is:75.30% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 26.98% & 1.17\n",
      "for 2020-11-16, MAE is:9.23 & sMAPE is:51.85% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 27.06% & 1.17\n",
      "for 2020-11-17, MAE is:3.73 & sMAPE is:10.42% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 27.01% & 1.17\n",
      "for 2020-11-18, MAE is:3.93 & sMAPE is:9.77% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 26.96% & 1.16\n",
      "for 2020-11-19, MAE is:8.05 & sMAPE is:31.59% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 26.97% & 1.16\n",
      "for 2020-11-20, MAE is:6.63 & sMAPE is:16.09% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 26.94% & 1.17\n",
      "for 2020-11-21, MAE is:4.86 & sMAPE is:11.81% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 26.89% & 1.16\n",
      "for 2020-11-22, MAE is:8.87 & sMAPE is:23.99% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 26.88% & 1.16\n",
      "for 2020-11-23, MAE is:6.24 & sMAPE is:14.13% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 26.84% & 1.16\n",
      "for 2020-11-24, MAE is:4.95 & sMAPE is:11.96% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 26.80% & 1.16\n",
      "for 2020-11-25, MAE is:7.06 & sMAPE is:16.15% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 26.76% & 1.16\n",
      "for 2020-11-26, MAE is:15.68 & sMAPE is:27.23% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 26.77% & 1.16\n",
      "for 2020-11-27, MAE is:12.10 & sMAPE is:17.46% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 26.74% & 1.16\n",
      "for 2020-11-28, MAE is:10.19 & sMAPE is:19.44% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 26.72% & 1.16\n",
      "for 2020-11-29, MAE is:3.14 & sMAPE is:6.91% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 26.66% & 1.15\n",
      "for 2020-11-30, MAE is:8.00 & sMAPE is:16.24% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 26.63% & 1.15\n",
      "for 2020-12-01, MAE is:7.73 & sMAPE is:14.62% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 26.59% & 1.15\n",
      "for 2020-12-02, MAE is:19.95 & sMAPE is:27.09% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 26.59% & 1.15\n",
      "for 2020-12-03, MAE is:13.10 & sMAPE is:25.71% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 26.59% & 1.15\n",
      "for 2020-12-04, MAE is:7.19 & sMAPE is:16.39% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 26.56% & 1.15\n",
      "for 2020-12-05, MAE is:3.52 & sMAPE is:7.05% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 26.50% & 1.15\n",
      "for 2020-12-06, MAE is:4.65 & sMAPE is:9.74% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 26.45% & 1.15\n",
      "for 2020-12-07, MAE is:19.25 & sMAPE is:30.18% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 26.46% & 1.15\n",
      "for 2020-12-08, MAE is:18.04 & sMAPE is:24.03% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 26.46% & 1.15\n",
      "for 2020-12-09, MAE is:21.80 & sMAPE is:30.47% & rMAE is:2.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 26.47% & 1.15\n",
      "for 2020-12-10, MAE is:19.65 & sMAPE is:30.74% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 26.48% & 1.15\n",
      "for 2020-12-11, MAE is:8.93 & sMAPE is:18.61% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 26.46% & 1.15\n",
      "for 2020-12-12, MAE is:4.89 & sMAPE is:10.83% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 26.41% & 1.15\n",
      "for 2020-12-13, MAE is:2.96 & sMAPE is:6.77% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 26.36% & 1.15\n",
      "for 2020-12-14, MAE is:8.88 & sMAPE is:19.86% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 26.34% & 1.15\n",
      "for 2020-12-15, MAE is:5.49 & sMAPE is:10.89% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 26.29% & 1.14\n",
      "for 2020-12-16, MAE is:8.57 & sMAPE is:17.03% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 26.27% & 1.14\n",
      "for 2020-12-17, MAE is:7.10 & sMAPE is:13.91% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 26.23% & 1.14\n",
      "for 2020-12-18, MAE is:5.81 & sMAPE is:12.47% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 26.19% & 1.14\n",
      "for 2020-12-19, MAE is:5.24 & sMAPE is:12.83% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 26.15% & 1.14\n",
      "for 2020-12-20, MAE is:5.02 & sMAPE is:12.02% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 26.12% & 1.14\n",
      "for 2020-12-21, MAE is:4.18 & sMAPE is:9.33% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 26.07% & 1.14\n",
      "for 2020-12-22, MAE is:7.88 & sMAPE is:28.36% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 26.07% & 1.14\n",
      "for 2020-12-23, MAE is:5.97 & sMAPE is:14.23% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 26.04% & 1.14\n",
      "for 2020-12-24, MAE is:8.00 & sMAPE is:27.13% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 26.04% & 1.14\n",
      "for 2020-12-25, MAE is:7.00 & sMAPE is:23.10% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 26.04% & 1.13\n",
      "for 2020-12-26, MAE is:10.28 & sMAPE is:28.07% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 26.04% & 1.13\n",
      "for 2020-12-27, MAE is:15.06 & sMAPE is:50.84% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 26.11% & 1.13\n",
      "for 2020-12-28, MAE is:4.63 & sMAPE is:11.58% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 26.07% & 1.13\n",
      "for 2020-12-29, MAE is:5.02 & sMAPE is:10.38% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 26.03% & 1.13\n",
      "for 2020-12-30, MAE is:5.43 & sMAPE is:10.86% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 25.99% & 1.13\n",
      "for 2020-12-31, MAE is:4.81 & sMAPE is:9.72% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 25.94% & 1.13\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 02:58:35,464]\u001b[0m A new study created in RDB with name: NL_2021\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 02:58:55,541]\u001b[0m Trial 3 finished with value: 8.348630214202371 and parameters: {'n_hidden': 3, 'learning_rate': 0.07601585531900086, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08533009303123125, 'dropout_rate_Layer_2': 0.2725385756816871, 'dropout_rate_Layer_3': 0.048267716015013784, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.6153991356812936e-05, 'l1_Layer_2': 7.813847164000113e-05, 'l1_Layer_3': 0.00012905622344828825, 'n_units_Layer_1': 65, 'n_units_Layer_2': 215, 'n_units_Layer_3': 55}. Best is trial 3 with value: 8.348630214202371.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.35 | sMAPE for Validation Set is: 29.73% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 51.10 | sMAPE for Test Set is: 50.57% | rMAE for Test Set is: 1.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 02:58:58,840]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 02:59:03,323]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 02:59:12,152]\u001b[0m Trial 0 finished with value: 7.598132017909538 and parameters: {'n_hidden': 4, 'learning_rate': 0.001317093861672966, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10590080467487835, 'dropout_rate_Layer_2': 0.0009740900453393043, 'dropout_rate_Layer_3': 0.21997091865030757, 'dropout_rate_Layer_4': 0.12522606715959425, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00037470306636019874, 'l1_Layer_2': 3.830640556754226e-05, 'l1_Layer_3': 0.0015590628539706925, 'l1_Layer_4': 0.012029341145527062, 'n_units_Layer_1': 165, 'n_units_Layer_2': 90, 'n_units_Layer_3': 300, 'n_units_Layer_4': 85}. Best is trial 0 with value: 7.598132017909538.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 02:59:12,287]\u001b[0m Trial 2 finished with value: 7.021658168454468 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011039787893076863, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.276459939841868, 'dropout_rate_Layer_2': 0.3448059093967233, 'dropout_rate_Layer_3': 0.3837131667221123, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03498735463885271, 'l1_Layer_2': 0.013597615509530335, 'l1_Layer_3': 0.0005444591008783601, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 260}. Best is trial 2 with value: 7.021658168454468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.60 | sMAPE for Validation Set is: 27.38% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 49.72 | sMAPE for Test Set is: 48.79% | rMAE for Test Set is: 1.81\n",
      "MAE for Validation Set is: 7.02 | sMAPE for Validation Set is: 25.61% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 50.00 | sMAPE for Test Set is: 47.98% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 02:59:17,702]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 02:59:21,615]\u001b[0m Trial 1 finished with value: 8.66725972690954 and parameters: {'n_hidden': 3, 'learning_rate': 0.02544513951393306, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0840541680238792, 'dropout_rate_Layer_2': 0.21305365459405046, 'dropout_rate_Layer_3': 0.16700447262749565, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.060057897829757075, 'l1_Layer_2': 0.0002383762612462339, 'l1_Layer_3': 2.006288656923001e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 80, 'n_units_Layer_3': 120}. Best is trial 2 with value: 7.021658168454468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.67 | sMAPE for Validation Set is: 30.20% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 52.42 | sMAPE for Test Set is: 51.60% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 02:59:24,753]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 02:59:29,963]\u001b[0m Trial 9 finished with value: 8.424003920559542 and parameters: {'n_hidden': 3, 'learning_rate': 0.00506934393130998, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.140842702950915, 'dropout_rate_Layer_2': 0.17300919702641032, 'dropout_rate_Layer_3': 0.07132447113088798, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04666481785177778, 'l1_Layer_2': 0.07340472587902021, 'l1_Layer_3': 1.5326314033150373e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 205, 'n_units_Layer_3': 85}. Best is trial 2 with value: 7.021658168454468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.42 | sMAPE for Validation Set is: 29.60% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 50.72 | sMAPE for Test Set is: 48.52% | rMAE for Test Set is: 1.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 02:59:32,071]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 02:59:33,716]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 02:59:34,090]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 02:59:38,696]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 02:59:39,215]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 02:59:44,660]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 02:59:47,819]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 02:59:49,879]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 02:59:54,937]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 02:59:59,437]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:03,465]\u001b[0m Trial 20 finished with value: 8.186681345140038 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023798701434788313, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29064000352416197, 'dropout_rate_Layer_2': 0.2500872578029457, 'dropout_rate_Layer_3': 0.34830744064931185, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00014788804839433494, 'l1_Layer_2': 0.0003632614685102319, 'l1_Layer_3': 0.00012260741468306783, 'n_units_Layer_1': 245, 'n_units_Layer_2': 230, 'n_units_Layer_3': 195}. Best is trial 2 with value: 7.021658168454468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.19 | sMAPE for Validation Set is: 28.99% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 62.03 | sMAPE for Test Set is: 65.91% | rMAE for Test Set is: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:00:07,621]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:08,194]\u001b[0m Trial 7 finished with value: 8.1840476943612 and parameters: {'n_hidden': 3, 'learning_rate': 0.005021038934311543, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09927713086987647, 'dropout_rate_Layer_2': 0.21831257900783416, 'dropout_rate_Layer_3': 0.25857997244356024, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06417556317648473, 'l1_Layer_2': 0.0007550565229594536, 'l1_Layer_3': 0.05941575571169364, 'n_units_Layer_1': 85, 'n_units_Layer_2': 55, 'n_units_Layer_3': 265}. Best is trial 2 with value: 7.021658168454468.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.18 | sMAPE for Validation Set is: 29.11% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 46.12 | sMAPE for Test Set is: 43.04% | rMAE for Test Set is: 1.68\n",
      "MAE for Validation Set is: 10.06 | sMAPE for Validation Set is: 33.90% | rMAE for Validation Set is: 1.27\n",
      "MAE for Test Set is: 55.19 | sMAPE for Test Set is: 55.45% | rMAE for Test Set is: 2.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:00:11,611]\u001b[0m Trial 15 finished with value: 10.06427261927223 and parameters: {'n_hidden': 3, 'learning_rate': 0.04850840828355581, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17708673064045677, 'dropout_rate_Layer_2': 0.27060098471160204, 'dropout_rate_Layer_3': 0.1039363674524953, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00016296859661165455, 'l1_Layer_2': 0.0006412181806589299, 'l1_Layer_3': 0.05701838992872287, 'n_units_Layer_1': 160, 'n_units_Layer_2': 120, 'n_units_Layer_3': 150}. Best is trial 2 with value: 7.021658168454468.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:16,581]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:17,731]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:22,377]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:29,084]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:32,345]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:34,369]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:37,496]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:39,179]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:43,830]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:44,007]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:47,792]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:49,806]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:52,889]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:54,005]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:57,103]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:00:57,956]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:00,281]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:01,663]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:04,956]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:05,408]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:10,864]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:13,858]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:14,996]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:19,464]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:20,800]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:21,887]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:24,683]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:29,914]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:30,413]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:31,185]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:39,848]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:40,256]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:43,025]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.24 | sMAPE for Validation Set is: 29.39% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 51.77 | sMAPE for Test Set is: 50.15% | rMAE for Test Set is: 1.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:01:44,219]\u001b[0m Trial 48 finished with value: 8.244862444876738 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025499960363853037, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33229918335642344, 'dropout_rate_Layer_2': 0.36925364219935936, 'dropout_rate_Layer_3': 0.29379170551010436, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 3.70156242204447e-05, 'l1_Layer_2': 0.00010391080405516629, 'l1_Layer_3': 0.0006206540146773393, 'n_units_Layer_1': 230, 'n_units_Layer_2': 290, 'n_units_Layer_3': 190}. Best is trial 2 with value: 7.021658168454468.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:49,001]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:52,111]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:55,833]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:01:57,638]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:02:00,787]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:02:04,125]\u001b[0m Trial 59 finished with value: 7.004295491393008 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021059404346497252, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19136469101711626, 'dropout_rate_Layer_2': 0.31774407955073064, 'dropout_rate_Layer_3': 0.010463209018416658, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.469841309341792e-05, 'l1_Layer_2': 3.821021204347995e-05, 'l1_Layer_3': 0.00018902685094713203, 'n_units_Layer_1': 120, 'n_units_Layer_2': 65, 'n_units_Layer_3': 275}. Best is trial 59 with value: 7.004295491393008.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.00 | sMAPE for Validation Set is: 25.68% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 50.04 | sMAPE for Test Set is: 48.50% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:02:12,219]\u001b[0m Trial 62 finished with value: 5.859292707972318 and parameters: {'n_hidden': 3, 'learning_rate': 0.007077486282174457, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.197481314368781, 'dropout_rate_Layer_2': 0.1989479074761974, 'dropout_rate_Layer_3': 0.12271264943908304, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3673837107255954e-05, 'l1_Layer_2': 0.0014689341507869065, 'l1_Layer_3': 0.035918593415902436, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 195}. Best is trial 62 with value: 5.859292707972318.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 22.05% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 20.32 | sMAPE for Test Set is: 21.88% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:02:16,350]\u001b[0m Trial 66 finished with value: 11.295533490282802 and parameters: {'n_hidden': 4, 'learning_rate': 0.00207469035523594, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1571501013034324, 'dropout_rate_Layer_2': 0.3184266937260504, 'dropout_rate_Layer_3': 0.3332003928295254, 'dropout_rate_Layer_4': 0.021819882785063572, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00017601156879418502, 'l1_Layer_2': 0.005570646220440956, 'l1_Layer_3': 0.000676968502218836, 'l1_Layer_4': 0.0017699221078488014, 'n_units_Layer_1': 290, 'n_units_Layer_2': 220, 'n_units_Layer_3': 90, 'n_units_Layer_4': 165}. Best is trial 62 with value: 5.859292707972318.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.30 | sMAPE for Validation Set is: 37.68% | rMAE for Validation Set is: 1.42\n",
      "MAE for Test Set is: 76.00 | sMAPE for Test Set is: 95.30% | rMAE for Test Set is: 2.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:02:18,428]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:02:22,836]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:02:27,979]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:02:38,830]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:02:42,329]\u001b[0m Trial 65 finished with value: 8.81983151759942 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013384567596787466, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10262837864120807, 'dropout_rate_Layer_2': 0.2179073916889195, 'dropout_rate_Layer_3': 0.3262595335578986, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001253533432209828, 'l1_Layer_2': 0.0010724089240228072, 'l1_Layer_3': 0.03691494649331516, 'n_units_Layer_1': 135, 'n_units_Layer_2': 285, 'n_units_Layer_3': 75}. Best is trial 62 with value: 5.859292707972318.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.82 | sMAPE for Validation Set is: 30.90% | rMAE for Validation Set is: 1.11\n",
      "MAE for Test Set is: 52.28 | sMAPE for Test Set is: 50.80% | rMAE for Test Set is: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:02:44,024]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:02:58,124]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:03:01,574]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:03:03,978]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:03:06,227]\u001b[0m Trial 73 finished with value: 8.841547686347502 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018360880142329855, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.268776633627584, 'dropout_rate_Layer_2': 0.16199639735695232, 'dropout_rate_Layer_3': 0.286751722206695, 'dropout_rate_Layer_4': 0.07250049592385968, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.398687575253353e-05, 'l1_Layer_2': 0.059653956553464504, 'l1_Layer_3': 4.216303759470731e-05, 'l1_Layer_4': 0.01897588563408121, 'n_units_Layer_1': 200, 'n_units_Layer_2': 120, 'n_units_Layer_3': 85, 'n_units_Layer_4': 235}. Best is trial 62 with value: 5.859292707972318.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.84 | sMAPE for Validation Set is: 30.80% | rMAE for Validation Set is: 1.11\n",
      "MAE for Test Set is: 55.02 | sMAPE for Test Set is: 54.88% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:03:09,487]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:03:12,227]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:03:15,497]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:03:15,725]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:03:25,277]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:03:30,745]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:03:33,865]\u001b[0m Trial 78 finished with value: 6.213347075030332 and parameters: {'n_hidden': 4, 'learning_rate': 0.009022603692168446, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008704682143956833, 'dropout_rate_Layer_2': 0.20948797977712005, 'dropout_rate_Layer_3': 0.3646209957196473, 'dropout_rate_Layer_4': 0.38670310228594174, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.3831054885072278e-05, 'l1_Layer_2': 1.639995308483447e-05, 'l1_Layer_3': 0.0035061374352004645, 'l1_Layer_4': 4.193660380066859e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 195, 'n_units_Layer_3': 190, 'n_units_Layer_4': 65}. Best is trial 62 with value: 5.859292707972318.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 23.32% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 21.05 | sMAPE for Test Set is: 23.14% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:03:37,584]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:03:50,413]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:03:53,936]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:03:57,150]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:03:57,862]\u001b[0m Trial 69 finished with value: 7.594392990946438 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007582977999677431, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07794287823149953, 'dropout_rate_Layer_2': 0.10796616368547834, 'dropout_rate_Layer_3': 0.32917797659546233, 'dropout_rate_Layer_4': 0.24888755488794945, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.051937799075453435, 'l1_Layer_2': 0.0004883183354160671, 'l1_Layer_3': 0.041014581786619535, 'l1_Layer_4': 5.084291551364775e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 280, 'n_units_Layer_3': 130, 'n_units_Layer_4': 170}. Best is trial 62 with value: 5.859292707972318.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.59 | sMAPE for Validation Set is: 27.43% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 49.21 | sMAPE for Test Set is: 46.64% | rMAE for Test Set is: 1.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:04:01,940]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:02,728]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:08,763]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:10,449]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:14,385]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:15,481]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:21,869]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:22,048]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:27,685]\u001b[0m Trial 95 finished with value: 11.473300267027392 and parameters: {'n_hidden': 4, 'learning_rate': 0.00693356596918541, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3691227712304472, 'dropout_rate_Layer_2': 0.09851545950626775, 'dropout_rate_Layer_3': 0.04666854339864619, 'dropout_rate_Layer_4': 0.04540323929683039, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0002576166993484524, 'l1_Layer_2': 2.0086853643130474e-05, 'l1_Layer_3': 3.657891087264513e-05, 'l1_Layer_4': 0.006553418184976493, 'n_units_Layer_1': 55, 'n_units_Layer_2': 300, 'n_units_Layer_3': 255, 'n_units_Layer_4': 140}. Best is trial 62 with value: 5.859292707972318.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.47 | sMAPE for Validation Set is: 38.19% | rMAE for Validation Set is: 1.44\n",
      "MAE for Test Set is: 75.82 | sMAPE for Test Set is: 94.77% | rMAE for Test Set is: 2.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:04:29,563]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:29,897]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:35,378]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:39,142]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:39,806]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:39,823]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:46,314]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 22.16% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 20.45 | sMAPE for Test Set is: 22.39% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:04:48,645]\u001b[0m Trial 85 finished with value: 5.781443910036053 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006295708256816871, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39073294376736, 'dropout_rate_Layer_2': 0.015131759104203418, 'dropout_rate_Layer_3': 0.05510786832181691, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016065191471585245, 'l1_Layer_2': 1.5250750729099011e-05, 'l1_Layer_3': 0.0030399887403883977, 'n_units_Layer_1': 300, 'n_units_Layer_2': 225, 'n_units_Layer_3': 275}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:51,299]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:51,813]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:55,443]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:56,654]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:58,732]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:04:59,100]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:02,287]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:05,440]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:07,269]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:10,200]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:11,997]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:16,201]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:17,938]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:20,357]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:21,412]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:22,558]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:27,779]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:28,117]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:28,184]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:33,584]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:36,425]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:39,289]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:39,475]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:41,902]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:46,224]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:49,316]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:53,192]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:53,690]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:05:57,885]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:06:13,088]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:06:18,238]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:06:21,975]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:06:22,908]\u001b[0m Trial 129 finished with value: 6.73712305810126 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008082931271617034, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2864562000437304, 'dropout_rate_Layer_2': 0.1608329884038252, 'dropout_rate_Layer_3': 0.3407832018837733, 'dropout_rate_Layer_4': 0.07219647146609695, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0018632095128946775, 'l1_Layer_2': 4.4715266774532005e-05, 'l1_Layer_3': 0.0005745204649972931, 'l1_Layer_4': 0.0010476732929130164, 'n_units_Layer_1': 155, 'n_units_Layer_2': 105, 'n_units_Layer_3': 195, 'n_units_Layer_4': 85}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.74 | sMAPE for Validation Set is: 24.96% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 43.56 | sMAPE for Test Set is: 40.64% | rMAE for Test Set is: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:06:28,514]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:06:32,786]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:06:40,254]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:06:42,549]\u001b[0m Trial 136 finished with value: 6.64113902293872 and parameters: {'n_hidden': 4, 'learning_rate': 0.015446927463155907, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022379895700608943, 'dropout_rate_Layer_2': 0.033741729894178035, 'dropout_rate_Layer_3': 0.39285021870366077, 'dropout_rate_Layer_4': 0.37124581005926033, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00466739577312997, 'l1_Layer_2': 0.00010057429742615696, 'l1_Layer_3': 0.005269633974684027, 'l1_Layer_4': 1.2173692531165779e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 170, 'n_units_Layer_3': 200, 'n_units_Layer_4': 65}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.64 | sMAPE for Validation Set is: 24.57% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 46.47 | sMAPE for Test Set is: 43.86% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:06:43,391]\u001b[0m Trial 135 finished with value: 6.756522773022771 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036085142564598062, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13203781586510618, 'dropout_rate_Layer_2': 0.35046841043777033, 'dropout_rate_Layer_3': 0.2894413371436758, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.062174198283016686, 'l1_Layer_2': 8.347074436852892e-05, 'l1_Layer_3': 0.004647709905089028, 'n_units_Layer_1': 215, 'n_units_Layer_2': 255, 'n_units_Layer_3': 270}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.76 | sMAPE for Validation Set is: 24.62% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 22.30 | sMAPE for Test Set is: 24.15% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:06:43,579]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:06:47,094]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:06:47,881]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:06:51,237]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:06:54,258]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:07:00,868]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:07:08,783]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:07:12,224]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:07:15,518]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:07:15,685]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:07:19,546]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:07:22,219]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:07:33,538]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:07:33,777]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:07:36,956]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:07:41,421]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:07:41,881]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:07:49,347]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:07:50,698]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:07:54,500]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:07:57,964]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:07:58,206]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 23.19% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 20.30 | sMAPE for Test Set is: 22.01% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:07:59,216]\u001b[0m Trial 156 finished with value: 6.247464912148018 and parameters: {'n_hidden': 3, 'learning_rate': 0.006549109851751563, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07000461177543221, 'dropout_rate_Layer_2': 0.3524335048131114, 'dropout_rate_Layer_3': 0.24570899253495443, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.050608402581251405, 'l1_Layer_2': 0.00010078275714903794, 'l1_Layer_3': 0.0027303760656242574, 'n_units_Layer_1': 195, 'n_units_Layer_2': 300, 'n_units_Layer_3': 250}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:04,111]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:04,899]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:08,163]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:11,583]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:13,417]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:18,414]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:20,657]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:21,097]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:21,244]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:25,783]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:28,402]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:28,551]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:33,100]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:33,942]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:37,237]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:38,513]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:42,109]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:42,278]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:48,801]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:08:51,546]\u001b[0m Trial 171 finished with value: 8.669270312788315 and parameters: {'n_hidden': 3, 'learning_rate': 0.027246704135005795, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2358596534224899, 'dropout_rate_Layer_2': 0.1982709027467761, 'dropout_rate_Layer_3': 0.3223137702687881, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.012709042225361424, 'l1_Layer_2': 0.002353297376463262, 'l1_Layer_3': 0.0011307793135404349, 'n_units_Layer_1': 300, 'n_units_Layer_2': 200, 'n_units_Layer_3': 155}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.67 | sMAPE for Validation Set is: 30.48% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 54.06 | sMAPE for Test Set is: 53.82% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:08:57,159]\u001b[0m Trial 180 finished with value: 6.604437540834881 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008240803762920415, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3307036112737704, 'dropout_rate_Layer_2': 0.3054719471810952, 'dropout_rate_Layer_3': 0.345025782327824, 'dropout_rate_Layer_4': 0.036118038477354, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.02709026404979853, 'l1_Layer_2': 0.00014588992952937373, 'l1_Layer_3': 0.0003003158412862869, 'l1_Layer_4': 0.00012262484510860993, 'n_units_Layer_1': 155, 'n_units_Layer_2': 100, 'n_units_Layer_3': 70, 'n_units_Layer_4': 105}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 24.47% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 39.37 | sMAPE for Test Set is: 36.98% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:09:02,008]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:09:04,187]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:09:06,881]\u001b[0m Trial 185 finished with value: 6.588232496676892 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007446667586178161, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32617991953810255, 'dropout_rate_Layer_2': 0.32284218148716665, 'dropout_rate_Layer_3': 0.3393287115422258, 'dropout_rate_Layer_4': 0.000837118932236619, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.027435272433538316, 'l1_Layer_2': 0.00014813576929641447, 'l1_Layer_3': 0.0003246002484573064, 'l1_Layer_4': 0.000126599286857884, 'n_units_Layer_1': 160, 'n_units_Layer_2': 95, 'n_units_Layer_3': 70, 'n_units_Layer_4': 105}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 24.56% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 41.04 | sMAPE for Test Set is: 39.11% | rMAE for Test Set is: 1.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:09:11,539]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:09:12,726]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:09:17,966]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:09:18,236]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:09:18,413]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:09:18,959]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:09:27,509]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:09:28,876]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:09:29,938]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:09:35,363]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:09:37,773]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:09:42,217]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:09:44,808]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:09:50,222]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:09:53,134]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:09:59,499]\u001b[0m Trial 198 finished with value: 6.589349759145257 and parameters: {'n_hidden': 4, 'learning_rate': 0.08753137705014845, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12637040247148063, 'dropout_rate_Layer_2': 0.10541674794810418, 'dropout_rate_Layer_3': 0.35159298388825644, 'dropout_rate_Layer_4': 0.1521679691932786, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001611848877737869, 'l1_Layer_2': 4.022197448763826e-05, 'l1_Layer_3': 0.0013110692232154947, 'l1_Layer_4': 0.0004879396089992057, 'n_units_Layer_1': 275, 'n_units_Layer_2': 260, 'n_units_Layer_3': 125, 'n_units_Layer_4': 100}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 24.30% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 36.95 | sMAPE for Test Set is: 36.17% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:10:00,824]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:01,440]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:07,151]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:07,294]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:07,519]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:16,275]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:16,816]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:17,570]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:21,901]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:25,924]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:28,869]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:29,073]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:33,975]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:34,313]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:39,406]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:42,477]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:42,807]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.68 | sMAPE for Validation Set is: 24.52% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 44.81 | sMAPE for Test Set is: 42.67% | rMAE for Test Set is: 1.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:10:46,522]\u001b[0m Trial 201 finished with value: 6.682876245681069 and parameters: {'n_hidden': 4, 'learning_rate': 0.000683616452697528, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39684555243969427, 'dropout_rate_Layer_2': 0.3015197760424655, 'dropout_rate_Layer_3': 0.3222852800479468, 'dropout_rate_Layer_4': 0.04200029827187109, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.04921948290544041, 'l1_Layer_2': 4.909594478814686e-05, 'l1_Layer_3': 0.0007769176988283226, 'l1_Layer_4': 0.0006266851970355508, 'n_units_Layer_1': 145, 'n_units_Layer_2': 185, 'n_units_Layer_3': 65, 'n_units_Layer_4': 140}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:50,958]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:53,065]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:10:54,694]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:11:11,413]\u001b[0m Trial 218 finished with value: 6.680412823175433 and parameters: {'n_hidden': 4, 'learning_rate': 0.08727797342189554, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11909023025405178, 'dropout_rate_Layer_2': 0.0001819938232175411, 'dropout_rate_Layer_3': 0.28734312175169197, 'dropout_rate_Layer_4': 0.12281610176485683, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0015149837400449757, 'l1_Layer_2': 0.00021909047153551007, 'l1_Layer_3': 0.00046022414106265593, 'l1_Layer_4': 4.125161721572064e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 260, 'n_units_Layer_3': 120, 'n_units_Layer_4': 90}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.68 | sMAPE for Validation Set is: 24.52% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 23.55 | sMAPE for Test Set is: 25.59% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:11:20,295]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:11:22,898]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:11:26,938]\u001b[0m Trial 229 finished with value: 6.341957762358692 and parameters: {'n_hidden': 4, 'learning_rate': 0.0899127069752205, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12809130862316712, 'dropout_rate_Layer_2': 0.13216844281444148, 'dropout_rate_Layer_3': 0.28225183545766286, 'dropout_rate_Layer_4': 0.11191419247353274, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0011296862101732748, 'l1_Layer_2': 3.132267722201257e-05, 'l1_Layer_3': 0.0003128911256375237, 'l1_Layer_4': 4.9533483903041974e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 195, 'n_units_Layer_3': 135, 'n_units_Layer_4': 85}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.34 | sMAPE for Validation Set is: 23.50% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 30.09 | sMAPE for Test Set is: 29.61% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:11:30,018]\u001b[0m Trial 228 finished with value: 6.6013686289959965 and parameters: {'n_hidden': 4, 'learning_rate': 0.09169348691561054, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12849982443431002, 'dropout_rate_Layer_2': 0.14922047887399095, 'dropout_rate_Layer_3': 0.2952038881345272, 'dropout_rate_Layer_4': 0.13119728915895132, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0013437188107410486, 'l1_Layer_2': 0.0002261225601233559, 'l1_Layer_3': 0.00046209091231183937, 'l1_Layer_4': 3.980039523573781e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 190, 'n_units_Layer_3': 115, 'n_units_Layer_4': 95}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 24.58% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 31.95 | sMAPE for Test Set is: 34.56% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:11:33,783]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:11:36,683]\u001b[0m Trial 227 finished with value: 6.25539116922306 and parameters: {'n_hidden': 4, 'learning_rate': 0.061173550053829975, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13760912517230356, 'dropout_rate_Layer_2': 0.1440086398294229, 'dropout_rate_Layer_3': 0.2860846418670219, 'dropout_rate_Layer_4': 0.10693868102078309, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0016347345999544842, 'l1_Layer_2': 0.00020082490748839346, 'l1_Layer_3': 0.00044663813931706154, 'l1_Layer_4': 4.537550761186595e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 260, 'n_units_Layer_3': 125, 'n_units_Layer_4': 90}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 23.14% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 23.69 | sMAPE for Test Set is: 24.43% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:11:40,881]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:11:45,176]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:11:50,935]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:11:57,254]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:12:00,208]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:12:01,438]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:12:11,830]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:12:14,875]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:12:24,203]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:12:27,813]\u001b[0m Trial 233 finished with value: 6.577302740352953 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006205138902163103, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26142950716618424, 'dropout_rate_Layer_2': 0.25247181764296794, 'dropout_rate_Layer_3': 0.2989885374160818, 'dropout_rate_Layer_4': 0.06119231540631773, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.03240992685774642, 'l1_Layer_2': 0.00019265187949676487, 'l1_Layer_3': 0.001298624168134577, 'l1_Layer_4': 2.1631412338054583e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 200, 'n_units_Layer_3': 125, 'n_units_Layer_4': 100}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 24.32% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 41.72 | sMAPE for Test Set is: 38.97% | rMAE for Test Set is: 1.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:12:32,531]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:12:47,716]\u001b[0m Trial 243 finished with value: 6.509874303572246 and parameters: {'n_hidden': 4, 'learning_rate': 0.04456496290529714, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29236412835373554, 'dropout_rate_Layer_2': 0.22719679012886626, 'dropout_rate_Layer_3': 0.2644113438192377, 'dropout_rate_Layer_4': 0.0868670560585457, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004953329953586961, 'l1_Layer_2': 2.788765483590673e-05, 'l1_Layer_3': 0.00019349171529354505, 'l1_Layer_4': 0.00024143756096722623, 'n_units_Layer_1': 220, 'n_units_Layer_2': 200, 'n_units_Layer_3': 90, 'n_units_Layer_4': 140}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 24.36% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 23.21 | sMAPE for Test Set is: 26.39% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:12:47,901]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:12:53,444]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:12:54,131]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:12:58,587]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:01,335]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:07,556]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:12,361]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:14,949]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:17,176]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:17,676]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:22,040]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:22,882]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:27,404]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:30,218]\u001b[0m Trial 247 finished with value: 6.295904825558348 and parameters: {'n_hidden': 4, 'learning_rate': 0.05195065554824641, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28088843857036594, 'dropout_rate_Layer_2': 0.20827129794021298, 'dropout_rate_Layer_3': 0.2568149667870403, 'dropout_rate_Layer_4': 0.09431785810734748, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0003035937044068178, 'l1_Layer_2': 3.0320875699235078e-05, 'l1_Layer_3': 0.0001659113600642558, 'l1_Layer_4': 0.00022151124551656747, 'n_units_Layer_1': 215, 'n_units_Layer_2': 205, 'n_units_Layer_3': 90, 'n_units_Layer_4': 140}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 24.67% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 33.35 | sMAPE for Test Set is: 34.43% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:13:30,631]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:35,231]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:37,961]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:38,365]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:38,610]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:39,187]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:47,690]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:47,789]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:47,977]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:47,999]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:56,072]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:13:56,198]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:14:01,741]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:14:04,900]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:14:05,194]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:14:10,142]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:14:14,312]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:14:17,474]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:14:23,583]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:14:28,063]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:14:42,200]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:14:49,448]\u001b[0m Trial 282 finished with value: 7.060691036783996 and parameters: {'n_hidden': 3, 'learning_rate': 0.004340056162766094, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15131173254149782, 'dropout_rate_Layer_2': 0.29598530385602434, 'dropout_rate_Layer_3': 0.1985744133974119, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2268547597392586e-05, 'l1_Layer_2': 0.00044375948619722723, 'l1_Layer_3': 0.0007356876188958506, 'n_units_Layer_1': 175, 'n_units_Layer_2': 55, 'n_units_Layer_3': 265}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.06 | sMAPE for Validation Set is: 25.94% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 46.86 | sMAPE for Test Set is: 44.27% | rMAE for Test Set is: 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:14:56,991]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:14:57,120]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:03,489]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:03,913]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:08,781]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:09,108]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:09,995]\u001b[0m Trial 272 finished with value: 6.576891629658259 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005647616318360278, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27318585169179915, 'dropout_rate_Layer_2': 0.24290465292724986, 'dropout_rate_Layer_3': 0.33088507325929917, 'dropout_rate_Layer_4': 0.043630361080912505, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0438828359203624, 'l1_Layer_2': 0.00010342190084558226, 'l1_Layer_3': 0.0028497057775162577, 'l1_Layer_4': 0.00027257789315097427, 'n_units_Layer_1': 130, 'n_units_Layer_2': 275, 'n_units_Layer_3': 65, 'n_units_Layer_4': 180}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 24.23% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 41.21 | sMAPE for Test Set is: 38.17% | rMAE for Test Set is: 1.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:15:17,101]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:20,229]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:20,354]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:21,664]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:21,841]\u001b[0m Trial 269 finished with value: 6.536925732910135 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005218553100592161, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3438179516089513, 'dropout_rate_Layer_2': 0.19561659526412808, 'dropout_rate_Layer_3': 0.32635255177127565, 'dropout_rate_Layer_4': 0.04780690783493627, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.044951767918231605, 'l1_Layer_2': 0.00011310947873902468, 'l1_Layer_3': 0.0038824070378058535, 'l1_Layer_4': 3.056695275285381e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 300, 'n_units_Layer_3': 65, 'n_units_Layer_4': 165}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 24.02% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 38.72 | sMAPE for Test Set is: 35.54% | rMAE for Test Set is: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:15:28,969]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:29,380]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:30,334]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:37,566]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:37,800]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:38,056]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:45,777]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:48,401]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:51,566]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:55,076]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:55,140]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:15:59,524]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:00,335]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:03,808]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:04,499]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:06,657]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:13,261]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:13,513]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:13,638]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:14,002]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:26,276]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:26,467]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:26,521]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:26,801]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:38,595]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:38,955]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:39,013]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:46,846]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:47,329]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:47,894]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:53,483]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:54,264]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:57,755]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:16:58,161]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:02,815]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:04,717]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:07,966]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:10,722]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:12,172]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:16,361]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:19,149]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:19,829]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:23,627]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:26,726]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:27,306]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:29,002]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:31,353]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:33,051]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:34,532]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:36,911]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:40,700]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:43,104]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:48,785]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:17:53,774]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:18:02,590]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:18:09,261]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:18:13,282]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:18:15,325]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:18:20,537]\u001b[0m Trial 344 finished with value: 6.084860375841791 and parameters: {'n_hidden': 4, 'learning_rate': 0.000798699871818622, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2844254116601605, 'dropout_rate_Layer_2': 0.25991319285555686, 'dropout_rate_Layer_3': 0.29732780955430577, 'dropout_rate_Layer_4': 0.04786986227216409, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.02216556039189835, 'l1_Layer_2': 8.185416110592144e-05, 'l1_Layer_3': 0.0018844290957826565, 'l1_Layer_4': 4.3786224447561926e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 280, 'n_units_Layer_3': 65, 'n_units_Layer_4': 135}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 22.80% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 41.02 | sMAPE for Test Set is: 38.39% | rMAE for Test Set is: 1.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:18:21,301]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:18:26,167]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:18:28,566]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:18:31,860]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:18:34,379]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:18:36,406]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:18:39,452]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:18:43,702]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:18:44,777]\u001b[0m Trial 354 finished with value: 7.334437257169903 and parameters: {'n_hidden': 4, 'learning_rate': 0.0368078363571748, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05395960936499443, 'dropout_rate_Layer_2': 0.2415889787538532, 'dropout_rate_Layer_3': 0.3126983041606117, 'dropout_rate_Layer_4': 0.1608406567695444, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0008769495389351152, 'l1_Layer_2': 2.2001844092330972e-05, 'l1_Layer_3': 0.0002487142528521995, 'l1_Layer_4': 2.818444399774103e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 185, 'n_units_Layer_3': 105, 'n_units_Layer_4': 75}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.33 | sMAPE for Validation Set is: 26.75% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 41.63 | sMAPE for Test Set is: 39.71% | rMAE for Test Set is: 1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:18:49,523]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:18:52,398]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:18:52,877]\u001b[0m Trial 362 finished with value: 7.0402569298624655 and parameters: {'n_hidden': 3, 'learning_rate': 0.004301186971565197, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1600102593283802, 'dropout_rate_Layer_2': 0.15202745653945193, 'dropout_rate_Layer_3': 0.2524508978954655, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.724590658671529e-05, 'l1_Layer_2': 0.00012075647276688599, 'l1_Layer_3': 0.00020824517982749195, 'n_units_Layer_1': 165, 'n_units_Layer_2': 65, 'n_units_Layer_3': 300}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 25.65% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 50.18 | sMAPE for Test Set is: 48.88% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:18:52,965]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:18:53,945]\u001b[0m Trial 339 finished with value: 6.56887289192019 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006372694138264074, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2841170627159709, 'dropout_rate_Layer_2': 0.3999660067671134, 'dropout_rate_Layer_3': 0.3356972626366527, 'dropout_rate_Layer_4': 0.05386625868573052, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.037858070448748546, 'l1_Layer_2': 0.00011375377280113533, 'l1_Layer_3': 0.0026890791830273602, 'l1_Layer_4': 0.00015951785785895965, 'n_units_Layer_1': 130, 'n_units_Layer_2': 270, 'n_units_Layer_3': 60, 'n_units_Layer_4': 130}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 24.14% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 43.33 | sMAPE for Test Set is: 40.42% | rMAE for Test Set is: 1.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:19:03,552]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:03,617]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:03,890]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:10,394]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:13,015]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:13,262]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:16,862]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:17,193]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:18,258]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:19,023]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:26,345]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:28,876]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:32,027]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:36,474]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:41,134]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:41,345]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:48,245]\u001b[0m Trial 381 finished with value: 10.487740676414115 and parameters: {'n_hidden': 4, 'learning_rate': 0.05458586711742006, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15158514179176652, 'dropout_rate_Layer_2': 0.3005706269079101, 'dropout_rate_Layer_3': 0.3624903862288983, 'dropout_rate_Layer_4': 0.010930684567780027, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0003153636503600827, 'l1_Layer_2': 0.000743210021634854, 'l1_Layer_3': 1.8788196729672954e-05, 'l1_Layer_4': 0.00010383519682744532, 'n_units_Layer_1': 290, 'n_units_Layer_2': 215, 'n_units_Layer_3': 140, 'n_units_Layer_4': 120}. Best is trial 85 with value: 5.781443910036053.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.49 | sMAPE for Validation Set is: 34.59% | rMAE for Validation Set is: 1.32\n",
      "MAE for Test Set is: 49.55 | sMAPE for Test Set is: 47.58% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:19:52,876]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:52,914]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:19:53,638]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:20:02,612]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:20:02,656]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:20:08,067]\u001b[0m Trial 385 finished with value: 5.672530541738759 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038286636188547976, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12918886160991, 'dropout_rate_Layer_2': 0.056359643960773795, 'dropout_rate_Layer_3': 0.0031980827616721556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001314156453186042, 'l1_Layer_2': 0.00010360840086042389, 'l1_Layer_3': 0.0002825509545730959, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 220}. Best is trial 385 with value: 5.672530541738759.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 21.51% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 19.29 | sMAPE for Test Set is: 20.89% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:20:12,392]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:20:12,911]\u001b[0m Trial 387 finished with value: 6.005922193429818 and parameters: {'n_hidden': 3, 'learning_rate': 0.003974275636507906, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16268864344747622, 'dropout_rate_Layer_2': 0.026016700533620804, 'dropout_rate_Layer_3': 0.04135635896045188, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9032360547712762e-05, 'l1_Layer_2': 4.6271728689119995e-05, 'l1_Layer_3': 0.0002813537037531828, 'n_units_Layer_1': 185, 'n_units_Layer_2': 50, 'n_units_Layer_3': 245}. Best is trial 385 with value: 5.672530541738759.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 22.41% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 19.76 | sMAPE for Test Set is: 21.69% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:20:23,572]\u001b[0m Trial 391 finished with value: 5.849508370872218 and parameters: {'n_hidden': 3, 'learning_rate': 0.00382519526958592, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15862417947210483, 'dropout_rate_Layer_2': 0.0029000256371930957, 'dropout_rate_Layer_3': 0.0038007657148297356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0273235316075287e-05, 'l1_Layer_2': 9.726605727479408e-05, 'l1_Layer_3': 0.0007852304404757544, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 220}. Best is trial 385 with value: 5.672530541738759.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 22.26% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 19.66 | sMAPE for Test Set is: 22.00% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:20:27,078]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:20:28,107]\u001b[0m Trial 393 finished with value: 5.922194458836191 and parameters: {'n_hidden': 3, 'learning_rate': 0.004096782018650976, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1636401700188914, 'dropout_rate_Layer_2': 0.03024834208187978, 'dropout_rate_Layer_3': 0.009066328459039284, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010662742138794633, 'l1_Layer_2': 0.00010588735315601373, 'l1_Layer_3': 0.00030117775326295496, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 190}. Best is trial 385 with value: 5.672530541738759.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.92 | sMAPE for Validation Set is: 22.19% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 20.46 | sMAPE for Test Set is: 22.50% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:20:37,268]\u001b[0m Trial 392 finished with value: 5.635854975619355 and parameters: {'n_hidden': 3, 'learning_rate': 0.003948222779464873, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13411273565281534, 'dropout_rate_Layer_2': 0.0469404267586169, 'dropout_rate_Layer_3': 0.006086899901806355, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0024951203297062805, 'l1_Layer_2': 0.00010673782225993311, 'l1_Layer_3': 0.0002984768808378326, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 220}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 21.40% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 19.42 | sMAPE for Test Set is: 21.07% | rMAE for Test Set is: 0.71\n",
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 22.95% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 20.71 | sMAPE for Test Set is: 22.25% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:20:38,990]\u001b[0m Trial 394 finished with value: 6.177352121060051 and parameters: {'n_hidden': 4, 'learning_rate': 0.03246072975436389, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3174271716838552, 'dropout_rate_Layer_2': 0.2636812463924547, 'dropout_rate_Layer_3': 0.2080356223856993, 'dropout_rate_Layer_4': 0.09785948158656013, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001683432497430473, 'l1_Layer_2': 1.635338945924267e-05, 'l1_Layer_3': 0.00012793151349965414, 'l1_Layer_4': 2.9734642769272243e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 215, 'n_units_Layer_3': 70, 'n_units_Layer_4': 155}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:20:49,967]\u001b[0m Trial 397 finished with value: 5.729214540014914 and parameters: {'n_hidden': 3, 'learning_rate': 0.004206917930487329, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16137363876713787, 'dropout_rate_Layer_2': 0.025928972669299753, 'dropout_rate_Layer_3': 0.01603365035898914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009963075855028123, 'l1_Layer_2': 0.00010272195060670003, 'l1_Layer_3': 5.836566892416721e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 200}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 21.77% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 19.21 | sMAPE for Test Set is: 20.77% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:20:51,002]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.97 | sMAPE for Validation Set is: 22.54% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 19.46 | sMAPE for Test Set is: 21.47% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:20:52,312]\u001b[0m Trial 396 finished with value: 5.967654209052841 and parameters: {'n_hidden': 3, 'learning_rate': 0.004545551237693123, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13173586666688453, 'dropout_rate_Layer_2': 0.04438879833051912, 'dropout_rate_Layer_3': 0.017796808754878022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004098919994041856, 'l1_Layer_2': 9.873465486741926e-05, 'l1_Layer_3': 0.00038982247964684075, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 185}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:20:56,825]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:21:01,519]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:21:03,932]\u001b[0m Trial 398 finished with value: 5.810755017239846 and parameters: {'n_hidden': 3, 'learning_rate': 0.00446597514374888, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13496518819593264, 'dropout_rate_Layer_2': 0.033073223623373255, 'dropout_rate_Layer_3': 0.017452354903504053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012884423804361716, 'l1_Layer_2': 0.00010330044166369739, 'l1_Layer_3': 0.0001419232870479529, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 195}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 21.91% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 21.55 | sMAPE for Test Set is: 23.07% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:21:04,720]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:21:10,913]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:21:12,473]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:21:17,885]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:21:28,643]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:21:29,611]\u001b[0m Trial 407 finished with value: 6.116612450507579 and parameters: {'n_hidden': 3, 'learning_rate': 0.004356081951733203, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13436978626496907, 'dropout_rate_Layer_2': 0.05201534556086914, 'dropout_rate_Layer_3': 0.01893712677238139, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011768892861482893, 'l1_Layer_2': 0.00011452473603194834, 'l1_Layer_3': 0.00040913648989478055, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 190}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 22.93% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 21.62 | sMAPE for Test Set is: 23.67% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:21:31,436]\u001b[0m Trial 403 finished with value: 5.701885080268899 and parameters: {'n_hidden': 3, 'learning_rate': 0.004130513943090883, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13450142769404166, 'dropout_rate_Layer_2': 0.03132115613942058, 'dropout_rate_Layer_3': 0.01864505508178841, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001037019317179045, 'l1_Layer_2': 0.00010423954577099658, 'l1_Layer_3': 0.00037549286848089956, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 185}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 21.61% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 20.56 | sMAPE for Test Set is: 22.52% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:21:34,496]\u001b[0m Trial 406 finished with value: 5.916865134363166 and parameters: {'n_hidden': 3, 'learning_rate': 0.004302709902997783, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1315119617748044, 'dropout_rate_Layer_2': 0.029479690323716612, 'dropout_rate_Layer_3': 0.02328208685937906, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001426141082208937, 'l1_Layer_2': 0.0001038851397915535, 'l1_Layer_3': 0.00043691666509824317, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 185}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.92 | sMAPE for Validation Set is: 22.37% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 19.59 | sMAPE for Test Set is: 21.49% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:21:36,473]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:21:42,794]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:21:46,687]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:21:46,824]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:21:55,718]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:22:03,157]\u001b[0m Trial 413 finished with value: 6.121686381465767 and parameters: {'n_hidden': 3, 'learning_rate': 0.004459534575021271, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13063977441066701, 'dropout_rate_Layer_2': 0.026015000142674348, 'dropout_rate_Layer_3': 0.019370476653624798, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012896911748775885, 'l1_Layer_2': 0.0001106776915255989, 'l1_Layer_3': 0.0003779779969680198, 'n_units_Layer_1': 205, 'n_units_Layer_2': 50, 'n_units_Layer_3': 185}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 22.93% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 19.71 | sMAPE for Test Set is: 21.24% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:22:10,371]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:22:11,527]\u001b[0m Trial 416 finished with value: 5.936529530101942 and parameters: {'n_hidden': 3, 'learning_rate': 0.004623380863756492, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12990826209320924, 'dropout_rate_Layer_2': 0.015410227555358511, 'dropout_rate_Layer_3': 0.02576205698591731, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008231100382326308, 'l1_Layer_2': 0.00010578301104226411, 'l1_Layer_3': 0.00025461249462694957, 'n_units_Layer_1': 190, 'n_units_Layer_2': 55, 'n_units_Layer_3': 185}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.94 | sMAPE for Validation Set is: 22.21% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 20.08 | sMAPE for Test Set is: 21.90% | rMAE for Test Set is: 0.73\n",
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 21.73% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 20.14 | sMAPE for Test Set is: 21.94% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:22:16,369]\u001b[0m Trial 415 finished with value: 5.717053385197064 and parameters: {'n_hidden': 3, 'learning_rate': 0.004322910836868757, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12329064131415664, 'dropout_rate_Layer_2': 0.03029513996480319, 'dropout_rate_Layer_3': 0.012505141915284245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013698621505181302, 'l1_Layer_2': 0.00010315434086033863, 'l1_Layer_3': 0.0004048532214322943, 'n_units_Layer_1': 205, 'n_units_Layer_2': 50, 'n_units_Layer_3': 185}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:22:21,671]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:22:22,916]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:22:28,296]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:22:33,144]\u001b[0m Trial 418 finished with value: 5.872368493757541 and parameters: {'n_hidden': 3, 'learning_rate': 0.0049442317884681114, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14761183662270821, 'dropout_rate_Layer_2': 0.04926882218197738, 'dropout_rate_Layer_3': 0.005354729360329608, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013216437506099338, 'l1_Layer_2': 9.157917920852447e-05, 'l1_Layer_3': 0.00036834295877438564, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 195}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 22.25% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 19.61 | sMAPE for Test Set is: 21.83% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:22:37,870]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:22:41,667]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:22:47,609]\u001b[0m Trial 420 finished with value: 5.960371869236869 and parameters: {'n_hidden': 3, 'learning_rate': 0.004715176542825056, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14523956866057902, 'dropout_rate_Layer_2': 0.046294391763665656, 'dropout_rate_Layer_3': 0.018186433780042043, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015077569983001171, 'l1_Layer_2': 0.00014052589385196498, 'l1_Layer_3': 0.0005775298596928136, 'n_units_Layer_1': 205, 'n_units_Layer_2': 50, 'n_units_Layer_3': 180}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 22.31% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 25.25 | sMAPE for Test Set is: 27.62% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:22:53,966]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:22:57,635]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:23:01,605]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:23:05,920]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:23:10,022]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:23:10,666]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:23:13,101]\u001b[0m Trial 428 finished with value: 5.850883691888666 and parameters: {'n_hidden': 3, 'learning_rate': 0.00417773021936961, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1462220698057173, 'dropout_rate_Layer_2': 0.05956737841541711, 'dropout_rate_Layer_3': 0.02676777762916888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001620769722693812, 'l1_Layer_2': 9.155487658679702e-05, 'l1_Layer_3': 0.00015037610697192283, 'n_units_Layer_1': 190, 'n_units_Layer_2': 50, 'n_units_Layer_3': 195}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 22.15% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 20.82 | sMAPE for Test Set is: 22.89% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:23:15,352]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:23:20,706]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:23:22,589]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:23:26,309]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:23:27,135]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:23:27,280]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:23:30,105]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:23:38,377]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:23:38,475]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:23:50,472]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:23:57,550]\u001b[0m Trial 443 finished with value: 5.824702458403789 and parameters: {'n_hidden': 3, 'learning_rate': 0.004754759021965087, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1278558501102503, 'dropout_rate_Layer_2': 0.0144998773068237, 'dropout_rate_Layer_3': 0.007073063868995439, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011766836058801076, 'l1_Layer_2': 9.611205848381808e-05, 'l1_Layer_3': 0.0006035270116549653, 'n_units_Layer_1': 200, 'n_units_Layer_2': 50, 'n_units_Layer_3': 180}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 21.95% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 20.24 | sMAPE for Test Set is: 21.79% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:24:04,541]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:24:07,212]\u001b[0m Trial 445 finished with value: 5.773236758086895 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038873106218714447, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13490944073274908, 'dropout_rate_Layer_2': 0.004743454465736015, 'dropout_rate_Layer_3': 0.0004920467138710936, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0032848976826613955, 'l1_Layer_2': 9.969928884030021e-05, 'l1_Layer_3': 0.00019752270323077732, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 180}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 21.89% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 21.30 | sMAPE for Test Set is: 22.90% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:24:08,259]\u001b[0m Trial 444 finished with value: 5.900460488107765 and parameters: {'n_hidden': 3, 'learning_rate': 0.003203937299901979, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13741901245815116, 'dropout_rate_Layer_2': 0.03689536455287486, 'dropout_rate_Layer_3': 0.0001930628108706544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019143234965890567, 'l1_Layer_2': 0.0001043473218121828, 'l1_Layer_3': 0.00012169508711204884, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 180}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 22.26% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 21.79 | sMAPE for Test Set is: 23.70% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:24:14,949]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:24:18,915]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:24:30,476]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:24:30,930]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:24:37,519]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:24:37,781]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:24:39,062]\u001b[0m Trial 448 finished with value: 6.7225471925215246 and parameters: {'n_hidden': 4, 'learning_rate': 0.06711705569290145, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3201813591442557, 'dropout_rate_Layer_2': 0.1725858586576111, 'dropout_rate_Layer_3': 0.2076215378782238, 'dropout_rate_Layer_4': 0.1037976091777426, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006878069430105583, 'l1_Layer_2': 1.969877155513185e-05, 'l1_Layer_3': 0.0003291530780485381, 'l1_Layer_4': 6.6108470117915e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 150, 'n_units_Layer_3': 105, 'n_units_Layer_4': 165}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.72 | sMAPE for Validation Set is: 25.66% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 30.61 | sMAPE for Test Set is: 31.75% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:24:48,219]\u001b[0m Trial 449 finished with value: 5.768884593468634 and parameters: {'n_hidden': 3, 'learning_rate': 0.003953602500993563, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13472454982252452, 'dropout_rate_Layer_2': 0.035518899605923096, 'dropout_rate_Layer_3': 0.00496676104143922, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0037012024222508994, 'l1_Layer_2': 0.00010853452657798471, 'l1_Layer_3': 0.00011155286835056614, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 165}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 21.87% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 20.43 | sMAPE for Test Set is: 22.10% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:24:48,425]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:24:54,687]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:24:59,137]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:25:04,492]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:25:08,563]\u001b[0m Trial 457 finished with value: 5.729820880358598 and parameters: {'n_hidden': 3, 'learning_rate': 0.003929197502920174, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15097157299306058, 'dropout_rate_Layer_2': 0.03744246000180522, 'dropout_rate_Layer_3': 0.007309741319191198, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019938472709341575, 'l1_Layer_2': 0.00011526604261931203, 'l1_Layer_3': 0.0003576536625673936, 'n_units_Layer_1': 190, 'n_units_Layer_2': 60, 'n_units_Layer_3': 180}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 21.65% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 21.57 | sMAPE for Test Set is: 23.87% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:25:14,772]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:25:18,915]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:25:25,507]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:25:29,567]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:25:33,930]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:25:37,212]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:25:42,274]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:25:46,281]\u001b[0m Trial 458 finished with value: 5.782081523419755 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006639044615915078, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30308615752158324, 'dropout_rate_Layer_2': 0.017422984309482942, 'dropout_rate_Layer_3': 0.350407369240822, 'dropout_rate_Layer_4': 0.07993617796028141, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.009797412425953627, 'l1_Layer_2': 6.825300816545296e-05, 'l1_Layer_3': 0.00023124723498183723, 'l1_Layer_4': 0.0003314968673654436, 'n_units_Layer_1': 110, 'n_units_Layer_2': 285, 'n_units_Layer_3': 205, 'n_units_Layer_4': 175}. Best is trial 392 with value: 5.635854975619355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 21.88% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 43.55 | sMAPE for Test Set is: 40.42% | rMAE for Test Set is: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:25:51,300]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:25:55,240]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:25:59,398]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:26:00,383]\u001b[0m Trial 467 finished with value: 5.614024068890839 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029744824933848613, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11845139902093331, 'dropout_rate_Layer_2': 0.0010138527224689267, 'dropout_rate_Layer_3': 0.00025904194658627616, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023898751009265662, 'l1_Layer_2': 9.35300834902825e-05, 'l1_Layer_3': 0.00014242661940572823, 'n_units_Layer_1': 220, 'n_units_Layer_2': 55, 'n_units_Layer_3': 180}. Best is trial 467 with value: 5.614024068890839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 21.44% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 19.18 | sMAPE for Test Set is: 21.08% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:26:08,421]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:26:09,257]\u001b[0m Trial 470 finished with value: 6.344744319354592 and parameters: {'n_hidden': 4, 'learning_rate': 0.07089549115900153, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27594670345454303, 'dropout_rate_Layer_2': 0.19881364700111204, 'dropout_rate_Layer_3': 0.2653553417221842, 'dropout_rate_Layer_4': 0.04396374845347593, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.8141111710763725e-05, 'l1_Layer_2': 0.009943799380142808, 'l1_Layer_3': 0.00016839941549469265, 'l1_Layer_4': 2.338427439678736e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 185, 'n_units_Layer_3': 75, 'n_units_Layer_4': 155}. Best is trial 467 with value: 5.614024068890839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.34 | sMAPE for Validation Set is: 23.46% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 25.09 | sMAPE for Test Set is: 25.51% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:26:14,572]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:26:23,728]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:26:26,914]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:26:28,105]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:26:33,853]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:26:38,767]\u001b[0m Trial 474 finished with value: 5.627815464988504 and parameters: {'n_hidden': 3, 'learning_rate': 0.003873693346132134, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017296002226755036, 'dropout_rate_Layer_2': 0.028574043303508077, 'dropout_rate_Layer_3': 0.0013108871180359735, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002840530759715029, 'l1_Layer_2': 9.806571634763635e-05, 'l1_Layer_3': 0.0005000386670947803, 'n_units_Layer_1': 210, 'n_units_Layer_2': 60, 'n_units_Layer_3': 185}. Best is trial 467 with value: 5.614024068890839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 21.48% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 19.93 | sMAPE for Test Set is: 21.83% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:26:39,550]\u001b[0m Trial 477 finished with value: 5.571245036616632 and parameters: {'n_hidden': 3, 'learning_rate': 0.002970833429594629, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11897128595858067, 'dropout_rate_Layer_2': 0.010624588026775872, 'dropout_rate_Layer_3': 0.005764543726322197, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019075018625808878, 'l1_Layer_2': 0.00020695537734881993, 'l1_Layer_3': 0.00013373680785026495, 'n_units_Layer_1': 190, 'n_units_Layer_2': 60, 'n_units_Layer_3': 185}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 21.21% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 19.77 | sMAPE for Test Set is: 21.68% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:26:42,001]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:26:42,146]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:26:43,184]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:26:53,102]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:26:55,881]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:27:00,411]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:27:08,550]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:27:14,356]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:27:18,047]\u001b[0m Trial 485 finished with value: 6.254976518609619 and parameters: {'n_hidden': 4, 'learning_rate': 0.03590632632428979, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19697246907771418, 'dropout_rate_Layer_2': 0.14250192233613165, 'dropout_rate_Layer_3': 0.2725750174104423, 'dropout_rate_Layer_4': 0.1255881582083454, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0024217859431457287, 'l1_Layer_2': 1.929762212275251e-05, 'l1_Layer_3': 2.2946316842458517e-05, 'l1_Layer_4': 5.115751804979039e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 210, 'n_units_Layer_3': 95, 'n_units_Layer_4': 150}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 23.60% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 24.39 | sMAPE for Test Set is: 25.73% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:27:22,552]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:27:22,839]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:27:29,006]\u001b[0m Trial 487 finished with value: 5.92597728607493 and parameters: {'n_hidden': 3, 'learning_rate': 0.002771926939189838, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14421073671790266, 'dropout_rate_Layer_2': 0.05332362141697225, 'dropout_rate_Layer_3': 0.008019030963926517, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005251848354085674, 'l1_Layer_2': 0.00017055128893587554, 'l1_Layer_3': 0.0005830846005891299, 'n_units_Layer_1': 210, 'n_units_Layer_2': 60, 'n_units_Layer_3': 175}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 22.34% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 20.35 | sMAPE for Test Set is: 22.22% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:27:32,478]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:27:32,908]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:27:38,647]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:27:39,263]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:27:45,772]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:27:47,776]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:27:54,363]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:05,875]\u001b[0m Trial 499 finished with value: 6.038889871909869 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036015014778059914, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14747246796619462, 'dropout_rate_Layer_2': 0.03885761366286601, 'dropout_rate_Layer_3': 0.0007192090644255649, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016812412770165553, 'l1_Layer_2': 0.00015501560524341755, 'l1_Layer_3': 0.0006166405570166803, 'n_units_Layer_1': 210, 'n_units_Layer_2': 55, 'n_units_Layer_3': 180}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 22.75% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 20.23 | sMAPE for Test Set is: 22.30% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:28:11,180]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:12,071]\u001b[0m Trial 502 finished with value: 5.812999609404398 and parameters: {'n_hidden': 3, 'learning_rate': 0.003655485204342042, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1321691697521394, 'dropout_rate_Layer_2': 0.008659754930868124, 'dropout_rate_Layer_3': 5.5975455191466705e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001742884373212343, 'l1_Layer_2': 0.0002758082913249236, 'l1_Layer_3': 0.0006211356809946658, 'n_units_Layer_1': 220, 'n_units_Layer_2': 55, 'n_units_Layer_3': 170}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 21.99% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 20.24 | sMAPE for Test Set is: 22.18% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:28:12,413]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:18,603]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:20,596]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:21,976]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:23,278]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:25,557]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:33,470]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:33,864]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:36,630]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:42,052]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:42,168]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:43,187]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:47,748]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:50,874]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:52,857]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:55,244]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:28:58,112]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:29:04,439]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:29:11,104]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:29:11,178]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 23.12% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 19.48 | sMAPE for Test Set is: 21.25% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:29:15,541]\u001b[0m Trial 518 finished with value: 6.121043625431362 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035755117072319874, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.109582736085183, 'dropout_rate_Layer_2': 0.04596096969816765, 'dropout_rate_Layer_3': 0.02578128051738108, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011102777391498292, 'l1_Layer_2': 0.00012552708338645722, 'l1_Layer_3': 6.180868841976167e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 65, 'n_units_Layer_3': 180}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:29:21,964]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:29:26,278]\u001b[0m Trial 522 finished with value: 5.94436262787772 and parameters: {'n_hidden': 3, 'learning_rate': 0.004019116524035874, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15408433940058403, 'dropout_rate_Layer_2': 0.016088462859339424, 'dropout_rate_Layer_3': 0.0006926981483456858, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000822954597657112, 'l1_Layer_2': 7.344884922761436e-05, 'l1_Layer_3': 0.00030019302755715987, 'n_units_Layer_1': 195, 'n_units_Layer_2': 65, 'n_units_Layer_3': 160}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.94 | sMAPE for Validation Set is: 22.48% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 22.42 | sMAPE for Test Set is: 24.76% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:29:28,587]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:29:31,598]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:29:31,965]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:29:32,131]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:29:32,881]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:29:43,975]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:29:46,717]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:29:53,582]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:29:57,435]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:29:57,907]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:30:00,686]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:30:03,641]\u001b[0m Trial 532 finished with value: 5.797954149252856 and parameters: {'n_hidden': 3, 'learning_rate': 0.004162373412523601, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14814474274971087, 'dropout_rate_Layer_2': 0.012809359244530017, 'dropout_rate_Layer_3': 0.0005835063834061975, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000980712442738569, 'l1_Layer_2': 7.030574388546679e-05, 'l1_Layer_3': 3.972098138692724e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 55, 'n_units_Layer_3': 150}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 21.91% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 22.43 | sMAPE for Test Set is: 24.43% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:30:05,838]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:30:10,161]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:30:12,385]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:30:17,000]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:30:20,318]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:30:24,166]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:30:27,935]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:30:33,478]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:30:36,038]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:30:36,812]\u001b[0m Trial 543 finished with value: 5.780917465755425 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027646045687801865, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11757393477877312, 'dropout_rate_Layer_2': 3.437937880825274e-05, 'dropout_rate_Layer_3': 0.007912252202287574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001160661401843428, 'l1_Layer_2': 7.329584909740007e-05, 'l1_Layer_3': 0.0002112556590831632, 'n_units_Layer_1': 220, 'n_units_Layer_2': 55, 'n_units_Layer_3': 190}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 21.91% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 22.38 | sMAPE for Test Set is: 23.66% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:30:40,692]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:30:44,504]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:30:45,253]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:30:47,601]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:30:54,867]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:30:55,129]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:31:04,178]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:31:08,152]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:31:35,041]\u001b[0m Trial 549 finished with value: 5.709630951143062 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007080320323347371, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3786163900793339, 'dropout_rate_Layer_2': 0.03283923444713476, 'dropout_rate_Layer_3': 0.019239543585696284, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016807727819692747, 'l1_Layer_2': 3.187172903160911e-05, 'l1_Layer_3': 0.0034571497173952826, 'n_units_Layer_1': 290, 'n_units_Layer_2': 225, 'n_units_Layer_3': 285}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 21.98% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 23.33 | sMAPE for Test Set is: 25.78% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:31:35,407]\u001b[0m Trial 559 finished with value: 5.988301491932174 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027780749828502896, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13270716012588563, 'dropout_rate_Layer_2': 0.025249997530510635, 'dropout_rate_Layer_3': 0.021308303420067273, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0024805454658899037, 'l1_Layer_2': 9.072594240945796e-05, 'l1_Layer_3': 0.0001629835330554886, 'n_units_Layer_1': 235, 'n_units_Layer_2': 50, 'n_units_Layer_3': 220}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.99 | sMAPE for Validation Set is: 22.40% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 20.48 | sMAPE for Test Set is: 22.65% | rMAE for Test Set is: 0.74\n",
      "MAE for Validation Set is: 7.07 | sMAPE for Validation Set is: 25.95% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 35.16 | sMAPE for Test Set is: 34.71% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:31:39,566]\u001b[0m Trial 554 finished with value: 7.067168487125563 and parameters: {'n_hidden': 4, 'learning_rate': 0.035523906479896894, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2840811471911047, 'dropout_rate_Layer_2': 0.21215212675558381, 'dropout_rate_Layer_3': 0.30128791347884937, 'dropout_rate_Layer_4': 0.07285146039731052, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002808454002341982, 'l1_Layer_2': 4.7209290696214965e-05, 'l1_Layer_3': 6.668920725275418e-05, 'l1_Layer_4': 0.07381810688624371, 'n_units_Layer_1': 155, 'n_units_Layer_2': 180, 'n_units_Layer_3': 95, 'n_units_Layer_4': 225}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:31:43,236]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:31:47,599]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:31:49,703]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:31:50,507]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:31:57,726]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:32:01,873]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:32:07,605]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:32:11,940]\u001b[0m Trial 556 finished with value: 6.5851725277285285 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006156186398298089, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2782558395446301, 'dropout_rate_Layer_2': 0.17863124698936747, 'dropout_rate_Layer_3': 0.31212993319283183, 'dropout_rate_Layer_4': 0.01960673916853306, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.03318512353558907, 'l1_Layer_2': 9.643556255059868e-05, 'l1_Layer_3': 0.004690189065049547, 'l1_Layer_4': 0.00045037369911565383, 'n_units_Layer_1': 135, 'n_units_Layer_2': 290, 'n_units_Layer_3': 65, 'n_units_Layer_4': 125}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 24.30% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 42.62 | sMAPE for Test Set is: 40.47% | rMAE for Test Set is: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:32:19,352]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:32:23,650]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:32:26,502]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:32:31,628]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:32:35,191]\u001b[0m Trial 570 finished with value: 5.839681382013231 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032310297834157306, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10323083338782864, 'dropout_rate_Layer_2': 0.019457094756745338, 'dropout_rate_Layer_3': 0.013259627621617826, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002150730196589337, 'l1_Layer_2': 0.0001345489454537114, 'l1_Layer_3': 4.4182334370254485e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 60, 'n_units_Layer_3': 225}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 22.09% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 20.88 | sMAPE for Test Set is: 23.08% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:32:35,783]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:32:43,521]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:33:01,553]\u001b[0m Trial 575 finished with value: 5.9606760499337925 and parameters: {'n_hidden': 3, 'learning_rate': 0.003268090612416832, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10213107942061217, 'dropout_rate_Layer_2': 0.026793431692473214, 'dropout_rate_Layer_3': 0.007064870376371595, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022081394450014346, 'l1_Layer_2': 0.0003523844123344442, 'l1_Layer_3': 3.085622034896612e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 22.38% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 20.38 | sMAPE for Test Set is: 22.78% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:33:05,991]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:33:09,067]\u001b[0m Trial 577 finished with value: 5.977837090943848 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027863669805979377, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10387306127101928, 'dropout_rate_Layer_2': 0.02778781947305135, 'dropout_rate_Layer_3': 0.008097112215158232, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002264918524470577, 'l1_Layer_2': 0.00017768770294163247, 'l1_Layer_3': 5.038150926611752e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.98 | sMAPE for Validation Set is: 22.56% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 19.77 | sMAPE for Test Set is: 21.95% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:33:11,268]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:33:14,489]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:33:19,186]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:33:23,615]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:33:27,843]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:33:31,981]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:33:46,616]\u001b[0m Trial 584 finished with value: 5.738347866860605 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027545912076956825, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14684013742656138, 'dropout_rate_Layer_2': 0.00619192353570476, 'dropout_rate_Layer_3': 0.015653925253096238, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00344075992889423, 'l1_Layer_2': 5.222907424398754e-05, 'l1_Layer_3': 0.0001043323627275513, 'n_units_Layer_1': 220, 'n_units_Layer_2': 50, 'n_units_Layer_3': 175}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 21.80% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 22.99 | sMAPE for Test Set is: 25.00% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:33:51,841]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:33:55,809]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:34:00,460]\u001b[0m Trial 580 finished with value: 5.710117304106084 and parameters: {'n_hidden': 3, 'learning_rate': 0.001017407527541535, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31731506569969503, 'dropout_rate_Layer_2': 0.057015987617084804, 'dropout_rate_Layer_3': 0.027620952007788024, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.230231115613695e-05, 'l1_Layer_2': 6.0252084215252785e-05, 'l1_Layer_3': 0.0026029809277568557, 'n_units_Layer_1': 255, 'n_units_Layer_2': 235, 'n_units_Layer_3': 290}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 21.82% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 20.62 | sMAPE for Test Set is: 22.27% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:34:01,447]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:34:03,622]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:34:10,699]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:34:15,380]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:34:15,768]\u001b[0m Trial 586 finished with value: 6.055676857322703 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005924034160149669, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13777958826587106, 'dropout_rate_Layer_2': 0.1954869775905411, 'dropout_rate_Layer_3': 0.3298220910593928, 'dropout_rate_Layer_4': 0.05191725700335814, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.026937509324441337, 'l1_Layer_2': 5.1657445784843064e-05, 'l1_Layer_3': 0.0026739611584082144, 'l1_Layer_4': 3.347627444158482e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 270, 'n_units_Layer_3': 60, 'n_units_Layer_4': 180}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.06 | sMAPE for Validation Set is: 22.74% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 41.58 | sMAPE for Test Set is: 39.04% | rMAE for Test Set is: 1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:34:22,389]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:34:26,338]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:34:28,255]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:34:32,615]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:34:32,770]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:34:40,074]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:34:44,494]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:34:49,192]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:34:54,807]\u001b[0m Trial 592 finished with value: 5.637015449533909 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007044329969316932, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27165907535391703, 'dropout_rate_Layer_2': 0.06381462901980436, 'dropout_rate_Layer_3': 0.022111158392646428, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.591053810117121e-05, 'l1_Layer_2': 3.373177323041915e-05, 'l1_Layer_3': 0.0007561888130817097, 'n_units_Layer_1': 255, 'n_units_Layer_2': 215, 'n_units_Layer_3': 285}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 21.72% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 20.84 | sMAPE for Test Set is: 23.02% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:34:59,999]\u001b[0m Trial 591 finished with value: 5.693357021702435 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006931277553471497, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26135060830622087, 'dropout_rate_Layer_2': 0.060640178915558465, 'dropout_rate_Layer_3': 0.012381015416489394, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.582304690554159e-05, 'l1_Layer_2': 2.6263981294365968e-05, 'l1_Layer_3': 0.002745333554917151, 'n_units_Layer_1': 255, 'n_units_Layer_2': 250, 'n_units_Layer_3': 285}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 22.02% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 22.34 | sMAPE for Test Set is: 24.70% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:35:03,265]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:35:04,117]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:35:09,596]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:35:10,578]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:35:15,712]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:35:16,239]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:35:21,688]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:35:22,209]\u001b[0m Trial 603 finished with value: 5.848231067759303 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009946077486203868, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30851455321467397, 'dropout_rate_Layer_2': 0.08164921594458419, 'dropout_rate_Layer_3': 0.0700341094226846, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.999900721032616e-05, 'l1_Layer_2': 1.769837770656011e-05, 'l1_Layer_3': 0.0007891993566989789, 'n_units_Layer_1': 260, 'n_units_Layer_2': 200, 'n_units_Layer_3': 245}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 22.23% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 19.44 | sMAPE for Test Set is: 21.42% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:35:22,313]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:35:31,317]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:35:31,523]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:35:37,843]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:35:38,737]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:35:40,028]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:35:47,261]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:35:56,892]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:36:00,324]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:36:05,007]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:36:05,103]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:36:11,846]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:36:16,287]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:36:16,907]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:36:23,606]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:36:29,809]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:36:34,133]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:36:35,040]\u001b[0m Trial 599 finished with value: 6.00947505775379 and parameters: {'n_hidden': 3, 'learning_rate': 0.002383269728735114, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.308866950045693, 'dropout_rate_Layer_2': 0.020382702901572815, 'dropout_rate_Layer_3': 0.0672200102637916, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013497444380231163, 'l1_Layer_2': 0.00016170388081250816, 'l1_Layer_3': 0.0007351355001511277, 'n_units_Layer_1': 255, 'n_units_Layer_2': 165, 'n_units_Layer_3': 265}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 22.65% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 21.66 | sMAPE for Test Set is: 23.74% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:36:49,009]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 22.80% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 19.84 | sMAPE for Test Set is: 22.35% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:36:50,953]\u001b[0m Trial 627 finished with value: 6.00793584916585 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006927214244368536, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27509529226498375, 'dropout_rate_Layer_2': 0.062017398137625274, 'dropout_rate_Layer_3': 0.030675881976655557, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012695518321101124, 'l1_Layer_2': 3.408016270977622e-05, 'l1_Layer_3': 0.0006656720621813666, 'n_units_Layer_1': 275, 'n_units_Layer_2': 220, 'n_units_Layer_3': 270}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:36:55,971]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:37:02,698]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:37:03,216]\u001b[0m Trial 632 finished with value: 11.42749936718352 and parameters: {'n_hidden': 4, 'learning_rate': 0.05004699452144103, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14850356934590822, 'dropout_rate_Layer_2': 0.15068430395859372, 'dropout_rate_Layer_3': 0.2121290316791054, 'dropout_rate_Layer_4': 0.2501313746647277, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.002641066937980115, 'l1_Layer_2': 5.949396529908823e-05, 'l1_Layer_3': 5.8373492731628744e-05, 'l1_Layer_4': 3.805934582089943e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 250, 'n_units_Layer_3': 185, 'n_units_Layer_4': 125}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.43 | sMAPE for Validation Set is: 38.40% | rMAE for Validation Set is: 1.44\n",
      "MAE for Test Set is: 77.22 | sMAPE for Test Set is: 98.43% | rMAE for Test Set is: 2.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:37:03,772]\u001b[0m Trial 626 finished with value: 5.899702164737185 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007025052972233698, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2724432869281014, 'dropout_rate_Layer_2': 0.06682410409281923, 'dropout_rate_Layer_3': 0.02945406607961041, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001341381318925656, 'l1_Layer_2': 3.653223960727103e-05, 'l1_Layer_3': 0.0013314243346545611, 'n_units_Layer_1': 290, 'n_units_Layer_2': 225, 'n_units_Layer_3': 245}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 22.72% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 19.26 | sMAPE for Test Set is: 21.48% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:37:15,593]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:37:21,977]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:37:26,982]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:37:31,043]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:37:37,354]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:37:42,609]\u001b[0m Trial 635 finished with value: 6.237499060706618 and parameters: {'n_hidden': 4, 'learning_rate': 0.03114153963319901, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11326188828145287, 'dropout_rate_Layer_2': 0.12761931180470296, 'dropout_rate_Layer_3': 0.2808670971176467, 'dropout_rate_Layer_4': 0.11735739255296868, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0012239259191901154, 'l1_Layer_2': 3.575265050237576e-05, 'l1_Layer_3': 0.0001423163031682211, 'l1_Layer_4': 6.320373270897949e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 195, 'n_units_Layer_3': 130, 'n_units_Layer_4': 60}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 23.25% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 23.82 | sMAPE for Test Set is: 25.11% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:37:47,206]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:37:52,057]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:37:54,848]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:37:55,889]\u001b[0m Trial 640 finished with value: 5.928079458367748 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038314859980750522, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1029148159414525, 'dropout_rate_Layer_2': 0.028009163779455795, 'dropout_rate_Layer_3': 6.986631881669486e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001364339084436751, 'l1_Layer_2': 0.000101901965610774, 'l1_Layer_3': 0.0002252392943399531, 'n_units_Layer_1': 190, 'n_units_Layer_2': 60, 'n_units_Layer_3': 175}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 22.33% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 23.86 | sMAPE for Test Set is: 26.44% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:38:03,717]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:38:04,136]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:38:10,909]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:38:11,214]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:38:13,595]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:38:18,622]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:38:23,193]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:38:26,119]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:38:30,036]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:38:36,255]\u001b[0m Trial 631 finished with value: 5.913902087674278 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007278101852279462, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2626838820601145, 'dropout_rate_Layer_2': 0.06451517489558847, 'dropout_rate_Layer_3': 0.07287342067587645, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.761847258678453e-05, 'l1_Layer_2': 3.439793070770385e-05, 'l1_Layer_3': 0.001213273823716793, 'n_units_Layer_1': 270, 'n_units_Layer_2': 175, 'n_units_Layer_3': 270}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 22.31% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 19.20 | sMAPE for Test Set is: 20.70% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:38:37,110]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:38:43,554]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:38:47,795]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:38:50,945]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:38:56,148]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:39:09,122]\u001b[0m Trial 656 finished with value: 6.065110114430984 and parameters: {'n_hidden': 4, 'learning_rate': 0.02942955591535536, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04032768949210025, 'dropout_rate_Layer_2': 0.11896380882856522, 'dropout_rate_Layer_3': 0.23434751760704112, 'dropout_rate_Layer_4': 0.05869759092257321, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004753054788851968, 'l1_Layer_2': 9.292092632904117e-05, 'l1_Layer_3': 0.0001393913246231902, 'l1_Layer_4': 7.657637893524345e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 205, 'n_units_Layer_3': 115, 'n_units_Layer_4': 70}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 22.83% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 33.72 | sMAPE for Test Set is: 32.78% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:39:12,558]\u001b[0m Trial 655 finished with value: 6.154609660906381 and parameters: {'n_hidden': 4, 'learning_rate': 0.03437459750297995, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.036231838182454304, 'dropout_rate_Layer_2': 0.12574678355311286, 'dropout_rate_Layer_3': 0.24216632876082575, 'dropout_rate_Layer_4': 0.056982609242794774, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005678708418709391, 'l1_Layer_2': 1.0407145324199715e-05, 'l1_Layer_3': 0.00017186620078961528, 'l1_Layer_4': 7.441622418548516e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 205, 'n_units_Layer_3': 115, 'n_units_Layer_4': 65}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 23.12% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 23.12 | sMAPE for Test Set is: 24.88% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:39:13,423]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:39:19,073]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:39:19,333]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:39:19,572]\u001b[0m Trial 662 finished with value: 6.024955279386586 and parameters: {'n_hidden': 3, 'learning_rate': 0.000744419186451101, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28547460499892924, 'dropout_rate_Layer_2': 0.031038702405702653, 'dropout_rate_Layer_3': 0.015453298229750414, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.369506162472634e-05, 'l1_Layer_2': 4.06866652631145e-05, 'l1_Layer_3': 0.0009550285566538742, 'n_units_Layer_1': 265, 'n_units_Layer_2': 175, 'n_units_Layer_3': 275}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.02 | sMAPE for Validation Set is: 23.03% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 19.54 | sMAPE for Test Set is: 22.06% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:39:29,393]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:39:30,217]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:39:35,865]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:39:40,203]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:39:43,667]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:39:48,587]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:39:50,034]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:39:55,666]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:39:56,434]\u001b[0m Trial 667 finished with value: 6.1721323606739915 and parameters: {'n_hidden': 4, 'learning_rate': 0.031903293286300996, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0321753701020525, 'dropout_rate_Layer_2': 0.12315547231615856, 'dropout_rate_Layer_3': 0.22251444864619332, 'dropout_rate_Layer_4': 0.05529174216030405, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000575604927530899, 'l1_Layer_2': 1.0102530533342888e-05, 'l1_Layer_3': 3.436779691009751e-05, 'l1_Layer_4': 7.434799908373898e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 225, 'n_units_Layer_3': 215, 'n_units_Layer_4': 65}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 23.22% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 21.69 | sMAPE for Test Set is: 23.68% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:40:01,645]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:40:05,009]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:40:05,116]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:40:05,809]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:40:13,212]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:40:15,226]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:40:15,727]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:40:21,820]\u001b[0m Trial 672 finished with value: 6.24379647415882 and parameters: {'n_hidden': 4, 'learning_rate': 0.012414103139913917, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03368644352063435, 'dropout_rate_Layer_2': 0.119205270844831, 'dropout_rate_Layer_3': 0.1748447069781333, 'dropout_rate_Layer_4': 0.05752715295482791, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006189896587147776, 'l1_Layer_2': 1.0360106087481843e-05, 'l1_Layer_3': 3.538444916642604e-05, 'l1_Layer_4': 7.178253411630053e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 175, 'n_units_Layer_3': 115, 'n_units_Layer_4': 70}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 23.45% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 23.50 | sMAPE for Test Set is: 25.28% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:40:23,342]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:40:25,594]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:40:29,476]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:40:33,545]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:40:43,437]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:40:47,745]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:40:52,049]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:40:57,614]\u001b[0m Trial 688 finished with value: 5.681815657952147 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028601442306162884, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13764883941180966, 'dropout_rate_Layer_2': 0.0005392146085983346, 'dropout_rate_Layer_3': 0.013760017042503129, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018614873534801805, 'l1_Layer_2': 0.0001554651093181929, 'l1_Layer_3': 0.0001308146721272412, 'n_units_Layer_1': 190, 'n_units_Layer_2': 65, 'n_units_Layer_3': 180}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 21.65% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 21.33 | sMAPE for Test Set is: 22.93% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:41:01,628]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:41:07,277]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:41:08,343]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:41:14,764]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:41:17,429]\u001b[0m Trial 690 finished with value: 5.6648842577217025 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029943717881945314, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13857833570480776, 'dropout_rate_Layer_2': 0.02929242110169197, 'dropout_rate_Layer_3': 0.01322641397536604, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018315221778540899, 'l1_Layer_2': 0.00014221832613609746, 'l1_Layer_3': 0.0001138461688585714, 'n_units_Layer_1': 190, 'n_units_Layer_2': 70, 'n_units_Layer_3': 180}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 21.53% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 20.58 | sMAPE for Test Set is: 22.18% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:41:28,074]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:41:31,396]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:41:32,213]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:41:40,347]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:41:43,471]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:41:47,965]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:41:55,921]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:42:00,659]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:42:06,469]\u001b[0m Trial 701 finished with value: 5.616234193209043 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027813978647797956, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14325253052938586, 'dropout_rate_Layer_2': 0.009294815332723924, 'dropout_rate_Layer_3': 0.0068146280011241265, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017767431290726732, 'l1_Layer_2': 0.00017126524687214752, 'l1_Layer_3': 0.00013917602903815653, 'n_units_Layer_1': 180, 'n_units_Layer_2': 70, 'n_units_Layer_3': 175}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 21.39% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 18.93 | sMAPE for Test Set is: 20.63% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:42:11,579]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:42:14,115]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:42:17,365]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:42:22,092]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:42:25,978]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:42:29,223]\u001b[0m Trial 704 finished with value: 5.601786613643667 and parameters: {'n_hidden': 3, 'learning_rate': 0.002776960843665016, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14688475589052008, 'dropout_rate_Layer_2': 0.008909349618392796, 'dropout_rate_Layer_3': 0.011240106158812851, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017625580453754168, 'l1_Layer_2': 0.0001656313004525262, 'l1_Layer_3': 8.941236649628584e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 75, 'n_units_Layer_3': 175}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 21.21% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 18.46 | sMAPE for Test Set is: 20.20% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:42:34,781]\u001b[0m Trial 695 finished with value: 6.592089181756575 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005444035859163192, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28197578825261177, 'dropout_rate_Layer_2': 0.18801617016726316, 'dropout_rate_Layer_3': 0.3218250946123634, 'dropout_rate_Layer_4': 0.33826617929386216, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.04110090154484312, 'l1_Layer_2': 7.253442750855355e-05, 'l1_Layer_3': 0.004286380513539164, 'l1_Layer_4': 0.00030647044172456566, 'n_units_Layer_1': 120, 'n_units_Layer_2': 280, 'n_units_Layer_3': 85, 'n_units_Layer_4': 135}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 24.25% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 43.09 | sMAPE for Test Set is: 40.16% | rMAE for Test Set is: 1.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:42:39,501]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:42:40,537]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:42:45,558]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:42:45,845]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:42:55,451]\u001b[0m Trial 711 finished with value: 5.640652056483063 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026310397611298136, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1255948232927408, 'dropout_rate_Layer_2': 0.010130587213689292, 'dropout_rate_Layer_3': 0.007849721418116816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015789908447636208, 'l1_Layer_2': 0.00017135899338347767, 'l1_Layer_3': 0.00021967744464045493, 'n_units_Layer_1': 190, 'n_units_Layer_2': 75, 'n_units_Layer_3': 220}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 21.73% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 19.68 | sMAPE for Test Set is: 21.63% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:42:58,912]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:43:02,885]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:43:03,713]\u001b[0m Trial 717 finished with value: 8.353867181425526 and parameters: {'n_hidden': 4, 'learning_rate': 0.023305252136449055, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007910420881991224, 'dropout_rate_Layer_2': 0.09035009768826929, 'dropout_rate_Layer_3': 0.3804261809497901, 'dropout_rate_Layer_4': 0.06927942369001558, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00010930935304177353, 'l1_Layer_2': 2.385386348454159e-05, 'l1_Layer_3': 0.00025375430919483426, 'l1_Layer_4': 3.3150718215734755e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 195, 'n_units_Layer_3': 245, 'n_units_Layer_4': 50}. Best is trial 477 with value: 5.571245036616632.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.35 | sMAPE for Validation Set is: 29.60% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 54.15 | sMAPE for Test Set is: 54.77% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:43:04,009]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:43:09,753]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:43:16,266]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:43:22,752]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:43:26,041]\u001b[0m Trial 719 finished with value: 5.5651459089898365 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022729174079211822, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12517356365466084, 'dropout_rate_Layer_2': 0.005878460910894293, 'dropout_rate_Layer_3': 0.018264761837349486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023960351555208665, 'l1_Layer_2': 0.00021506048411207786, 'l1_Layer_3': 7.303135670694846e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 70, 'n_units_Layer_3': 230}. Best is trial 719 with value: 5.5651459089898365.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 21.35% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 20.20 | sMAPE for Test Set is: 22.18% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:43:27,772]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:43:32,831]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:43:37,595]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:43:41,807]\u001b[0m Trial 725 finished with value: 5.583157202165882 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024548541767543826, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10664827314252927, 'dropout_rate_Layer_2': 0.019320522806345285, 'dropout_rate_Layer_3': 0.013788104073083953, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001687405933760485, 'l1_Layer_2': 0.00016602429980582453, 'l1_Layer_3': 0.00014080899369061818, 'n_units_Layer_1': 190, 'n_units_Layer_2': 70, 'n_units_Layer_3': 175}. Best is trial 719 with value: 5.5651459089898365.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 21.36% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 20.81 | sMAPE for Test Set is: 22.72% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:43:46,205]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:43:46,566]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:43:52,292]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:43:53,110]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:43:53,712]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:43:57,781]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:44:04,755]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:44:12,339]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:44:16,372]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:44:16,751]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:44:22,163]\u001b[0m Trial 735 finished with value: 5.623607264663073 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024689969110021216, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1197947402225115, 'dropout_rate_Layer_2': 0.008337248153165729, 'dropout_rate_Layer_3': 0.03551409994302085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011674717614992569, 'l1_Layer_2': 0.00016771130120433623, 'l1_Layer_3': 8.369395431638517e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 70, 'n_units_Layer_3': 155}. Best is trial 719 with value: 5.5651459089898365.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 21.40% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 19.01 | sMAPE for Test Set is: 20.89% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:44:26,023]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:44:30,680]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:44:36,079]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:44:41,046]\u001b[0m Trial 724 finished with value: 5.653964450071836 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005770118859667502, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25650121062535813, 'dropout_rate_Layer_2': 0.014923045513184947, 'dropout_rate_Layer_3': 0.06925516641256117, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001842623930099344, 'l1_Layer_2': 5.315013347660585e-05, 'l1_Layer_3': 0.005438060746800148, 'n_units_Layer_1': 250, 'n_units_Layer_2': 195, 'n_units_Layer_3': 250}. Best is trial 719 with value: 5.5651459089898365.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 21.64% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 20.92 | sMAPE for Test Set is: 23.03% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:44:41,364]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:44:43,660]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:44:49,432]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:44:53,165]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:44:56,927]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:44:57,209]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:45:03,746]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:45:04,315]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:45:11,037]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:45:15,526]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:45:15,808]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:45:22,136]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:45:22,713]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:45:26,981]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:45:28,073]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:45:36,110]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:45:36,731]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:45:42,840]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:45:43,906]\u001b[0m Trial 754 finished with value: 6.129934990385006 and parameters: {'n_hidden': 4, 'learning_rate': 0.012109469305984753, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.033712759100261766, 'dropout_rate_Layer_2': 0.11444898099430939, 'dropout_rate_Layer_3': 0.17263865353989855, 'dropout_rate_Layer_4': 0.05849699234500196, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007533473651142475, 'l1_Layer_2': 1.5271227193757392e-05, 'l1_Layer_3': 2.8469336296923734e-05, 'l1_Layer_4': 7.542277428460392e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 170, 'n_units_Layer_3': 115, 'n_units_Layer_4': 70}. Best is trial 719 with value: 5.5651459089898365.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 23.02% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 24.00 | sMAPE for Test Set is: 25.22% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:45:53,396]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:45:57,510]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:46:01,501]\u001b[0m Trial 760 finished with value: 5.550472411460753 and parameters: {'n_hidden': 3, 'learning_rate': 0.002589604335065913, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.116976637657867, 'dropout_rate_Layer_2': 0.007527534888218071, 'dropout_rate_Layer_3': 0.0003078806400950826, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015351049122554995, 'l1_Layer_2': 0.0001890632066227563, 'l1_Layer_3': 0.0001696385201854826, 'n_units_Layer_1': 195, 'n_units_Layer_2': 65, 'n_units_Layer_3': 145}. Best is trial 760 with value: 5.550472411460753.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 21.12% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 19.36 | sMAPE for Test Set is: 21.06% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:46:03,480]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:46:08,988]\u001b[0m Trial 763 finished with value: 5.656066705500957 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026660083361074484, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12489088484846225, 'dropout_rate_Layer_2': 0.0070817233638722325, 'dropout_rate_Layer_3': 0.03126617250626778, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014372224099148114, 'l1_Layer_2': 0.0001270327537759911, 'l1_Layer_3': 0.0001099043513609785, 'n_units_Layer_1': 195, 'n_units_Layer_2': 85, 'n_units_Layer_3': 170}. Best is trial 760 with value: 5.550472411460753.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 21.61% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 19.73 | sMAPE for Test Set is: 21.27% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:46:09,883]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:46:14,331]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:46:21,568]\u001b[0m Trial 764 finished with value: 5.943355551889735 and parameters: {'n_hidden': 4, 'learning_rate': 0.013251656384965848, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03040382043345714, 'dropout_rate_Layer_2': 0.11444989725002824, 'dropout_rate_Layer_3': 0.18282153594226633, 'dropout_rate_Layer_4': 0.05753229807241861, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011888869451925647, 'l1_Layer_2': 1.5418880518045995e-05, 'l1_Layer_3': 3.28942998812575e-05, 'l1_Layer_4': 7.863332022314331e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 175, 'n_units_Layer_3': 185, 'n_units_Layer_4': 85}. Best is trial 760 with value: 5.550472411460753.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.94 | sMAPE for Validation Set is: 22.85% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 23.13 | sMAPE for Test Set is: 24.83% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:46:26,644]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:46:30,868]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:46:34,833]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:46:46,578]\u001b[0m Trial 772 finished with value: 6.04711191569973 and parameters: {'n_hidden': 4, 'learning_rate': 0.012771229250216832, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06765070581945637, 'dropout_rate_Layer_2': 0.12250381423308765, 'dropout_rate_Layer_3': 0.18938725691170633, 'dropout_rate_Layer_4': 0.033385230360721524, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010933624758816954, 'l1_Layer_2': 1.4252803360938452e-05, 'l1_Layer_3': 2.913040421056737e-05, 'l1_Layer_4': 7.664846046001054e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 175, 'n_units_Layer_3': 185, 'n_units_Layer_4': 105}. Best is trial 760 with value: 5.550472411460753.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.05 | sMAPE for Validation Set is: 22.77% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 21.72 | sMAPE for Test Set is: 23.66% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:46:50,053]\u001b[0m Trial 773 finished with value: 6.101968174591703 and parameters: {'n_hidden': 4, 'learning_rate': 0.008309407919266276, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02587590084481225, 'dropout_rate_Layer_2': 0.11569227395898013, 'dropout_rate_Layer_3': 0.13396049931249793, 'dropout_rate_Layer_4': 0.04186366507198827, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00034823683286119546, 'l1_Layer_2': 1.4787093273099353e-05, 'l1_Layer_3': 1.0001979596999495e-05, 'l1_Layer_4': 0.00010813211999344709, 'n_units_Layer_1': 210, 'n_units_Layer_2': 175, 'n_units_Layer_3': 185, 'n_units_Layer_4': 100}. Best is trial 760 with value: 5.550472411460753.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 22.99% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 24.58 | sMAPE for Test Set is: 24.38% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:46:53,015]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:46:53,402]\u001b[0m Trial 768 finished with value: 5.54535410377945 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018750592604984304, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10529902249661073, 'dropout_rate_Layer_2': 0.007799985818506562, 'dropout_rate_Layer_3': 0.006171642254125297, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001770491029964411, 'l1_Layer_2': 0.00019382343050968102, 'l1_Layer_3': 0.0001568668295941546, 'n_units_Layer_1': 185, 'n_units_Layer_2': 80, 'n_units_Layer_3': 140}. Best is trial 768 with value: 5.54535410377945.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 21.37% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 21.67 | sMAPE for Test Set is: 23.62% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:47:00,460]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:47:03,916]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:47:04,690]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 21.59% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 18.61 | sMAPE for Test Set is: 20.27% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:47:07,479]\u001b[0m Trial 776 finished with value: 5.700018220981626 and parameters: {'n_hidden': 3, 'learning_rate': 0.002115482934629451, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11743020933014209, 'dropout_rate_Layer_2': 0.0004185771646832173, 'dropout_rate_Layer_3': 0.022148282438723056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008508157765569134, 'l1_Layer_2': 0.00011885013338596884, 'l1_Layer_3': 0.00013024023297616042, 'n_units_Layer_1': 185, 'n_units_Layer_2': 75, 'n_units_Layer_3': 160}. Best is trial 768 with value: 5.54535410377945.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:47:10,366]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:47:15,363]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:47:17,740]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:47:33,536]\u001b[0m Trial 785 finished with value: 6.312477712563706 and parameters: {'n_hidden': 4, 'learning_rate': 0.008200494807838259, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022432880033226067, 'dropout_rate_Layer_2': 0.11779153918596408, 'dropout_rate_Layer_3': 0.1289698669485733, 'dropout_rate_Layer_4': 0.036480216581165924, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003928627665410257, 'l1_Layer_2': 2.282756591039572e-05, 'l1_Layer_3': 1.4949192165409152e-05, 'l1_Layer_4': 0.00016237891782104342, 'n_units_Layer_1': 220, 'n_units_Layer_2': 175, 'n_units_Layer_3': 185, 'n_units_Layer_4': 105}. Best is trial 768 with value: 5.54535410377945.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 23.73% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 22.97 | sMAPE for Test Set is: 25.07% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:47:40,456]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 21.72% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 22.25 | sMAPE for Test Set is: 24.33% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:47:45,307]\u001b[0m Trial 786 finished with value: 5.629330499840066 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008802569660970229, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32646277835542803, 'dropout_rate_Layer_2': 0.012527506064590918, 'dropout_rate_Layer_3': 0.04523925770048823, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.7667489187744685e-05, 'l1_Layer_2': 4.228803868383869e-05, 'l1_Layer_3': 0.0007802890181474166, 'n_units_Layer_1': 295, 'n_units_Layer_2': 210, 'n_units_Layer_3': 260}. Best is trial 768 with value: 5.54535410377945.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:47:45,904]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:47:52,239]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:47:53,270]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 21.42% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 18.68 | sMAPE for Test Set is: 20.38% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:47:56,462]\u001b[0m Trial 787 finished with value: 5.54526532988307 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019037873122212609, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11046706089583282, 'dropout_rate_Layer_2': 0.0007916467143197624, 'dropout_rate_Layer_3': 0.026552851831397658, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003813173518597985, 'l1_Layer_2': 0.00012689016466931673, 'l1_Layer_3': 0.00012887028710450445, 'n_units_Layer_1': 185, 'n_units_Layer_2': 75, 'n_units_Layer_3': 165}. Best is trial 787 with value: 5.54526532988307.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:47:57,852]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:48:01,802]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:48:05,580]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:48:06,150]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:48:18,805]\u001b[0m Trial 783 finished with value: 5.623413972264795 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008956236293029417, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32757224091247517, 'dropout_rate_Layer_2': 0.00981773481462795, 'dropout_rate_Layer_3': 0.04877918394815543, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002978979315708206, 'l1_Layer_2': 3.9288803662562226e-05, 'l1_Layer_3': 0.0007858748323998244, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 260}. Best is trial 787 with value: 5.54526532988307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 21.72% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 20.51 | sMAPE for Test Set is: 22.60% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:48:23,981]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:48:30,311]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:48:34,612]\u001b[0m Trial 798 finished with value: 5.552269451474718 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013548180796666845, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08752900171825324, 'dropout_rate_Layer_2': 0.02348181673207283, 'dropout_rate_Layer_3': 0.042302892449203135, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0030602912862858927, 'l1_Layer_2': 0.00016304418928186825, 'l1_Layer_3': 0.00013043050473829018, 'n_units_Layer_1': 190, 'n_units_Layer_2': 70, 'n_units_Layer_3': 155}. Best is trial 787 with value: 5.54526532988307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 21.43% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 20.17 | sMAPE for Test Set is: 22.15% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:48:34,792]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:48:44,180]\u001b[0m Trial 796 finished with value: 5.679397276922604 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008693425597018992, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3507146232627243, 'dropout_rate_Layer_2': 0.05152518365444259, 'dropout_rate_Layer_3': 0.052813587866132175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003255293618395504, 'l1_Layer_2': 4.823328239112889e-05, 'l1_Layer_3': 0.004703876798785999, 'n_units_Layer_1': 295, 'n_units_Layer_2': 260, 'n_units_Layer_3': 245}. Best is trial 787 with value: 5.54526532988307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 21.73% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 21.57 | sMAPE for Test Set is: 23.54% | rMAE for Test Set is: 0.78\n",
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 21.52% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 21.10 | sMAPE for Test Set is: 23.06% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:48:46,545]\u001b[0m Trial 797 finished with value: 5.546277056545048 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018478465446688575, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08271788983298542, 'dropout_rate_Layer_2': 0.02385959436648939, 'dropout_rate_Layer_3': 0.03814638457504246, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004946195654714187, 'l1_Layer_2': 0.00015200179762705351, 'l1_Layer_3': 0.00012332130192563116, 'n_units_Layer_1': 190, 'n_units_Layer_2': 80, 'n_units_Layer_3': 155}. Best is trial 787 with value: 5.54526532988307.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:48:50,195]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:48:52,778]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:48:56,853]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:49:09,220]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:49:14,276]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:49:18,014]\u001b[0m Trial 807 finished with value: 5.760255224034329 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018543292734287222, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07086464641470872, 'dropout_rate_Layer_2': 0.014818118347614623, 'dropout_rate_Layer_3': 0.03582256525157374, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0058142595273347085, 'l1_Layer_2': 0.00016878636796360678, 'l1_Layer_3': 7.098991168304326e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 80, 'n_units_Layer_3': 145}. Best is trial 787 with value: 5.54526532988307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 21.98% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 19.71 | sMAPE for Test Set is: 21.46% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:49:18,476]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:49:23,143]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:49:27,900]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:49:31,430]\u001b[0m Trial 802 finished with value: 5.485399755449514 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019792156159989037, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10657861864762778, 'dropout_rate_Layer_2': 0.02967234949028808, 'dropout_rate_Layer_3': 0.03430818938106575, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002320980798207071, 'l1_Layer_2': 0.0001914609460262653, 'l1_Layer_3': 0.00012852013319032077, 'n_units_Layer_1': 190, 'n_units_Layer_2': 85, 'n_units_Layer_3': 145}. Best is trial 802 with value: 5.485399755449514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 21.15% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.96 | sMAPE for Test Set is: 21.88% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:49:35,130]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:49:35,650]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:49:41,523]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:49:44,069]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:49:48,884]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:49:51,522]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:49:54,785]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:50:01,513]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:50:08,120]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:50:15,309]\u001b[0m Trial 814 finished with value: 5.571487859119224 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021139455075314395, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09793195107408176, 'dropout_rate_Layer_2': 0.020773603331866876, 'dropout_rate_Layer_3': 0.03521977436832861, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017763011089322136, 'l1_Layer_2': 0.00019324793937955848, 'l1_Layer_3': 0.00014527690945286033, 'n_units_Layer_1': 195, 'n_units_Layer_2': 70, 'n_units_Layer_3': 140}. Best is trial 802 with value: 5.485399755449514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 21.50% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 20.70 | sMAPE for Test Set is: 22.15% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:50:18,373]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:50:22,160]\u001b[0m Trial 821 finished with value: 5.527392905478192 and parameters: {'n_hidden': 3, 'learning_rate': 0.001705379957078508, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09159449404593686, 'dropout_rate_Layer_2': 0.037057975691354335, 'dropout_rate_Layer_3': 0.027828926035350636, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001498312731636475, 'l1_Layer_2': 0.00013536944350746945, 'l1_Layer_3': 8.864138675575262e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 85, 'n_units_Layer_3': 145}. Best is trial 802 with value: 5.485399755449514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 21.35% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 20.91 | sMAPE for Test Set is: 22.48% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:50:27,493]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:50:28,543]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:50:34,783]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:50:34,956]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:50:42,938]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:50:48,761]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:50:49,482]\u001b[0m Trial 824 finished with value: 5.491681321149168 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020891962550331393, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07831046730676067, 'dropout_rate_Layer_2': 0.022159168398372377, 'dropout_rate_Layer_3': 0.026749406946403313, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014899988580021556, 'l1_Layer_2': 0.00012377737715794435, 'l1_Layer_3': 0.00017842482049741702, 'n_units_Layer_1': 195, 'n_units_Layer_2': 85, 'n_units_Layer_3': 155}. Best is trial 802 with value: 5.485399755449514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 21.34% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.57 | sMAPE for Test Set is: 22.69% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:50:55,218]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:51:09,153]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:51:10,062]\u001b[0m Trial 831 finished with value: 5.809626793372156 and parameters: {'n_hidden': 4, 'learning_rate': 0.011784036887748517, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07094850243279949, 'dropout_rate_Layer_2': 0.1579517365005312, 'dropout_rate_Layer_3': 0.16104220759460008, 'dropout_rate_Layer_4': 0.02253485030396294, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009504711246374332, 'l1_Layer_2': 1.5094100493059202e-05, 'l1_Layer_3': 2.8865697997030636e-05, 'l1_Layer_4': 9.517114660688759e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 95, 'n_units_Layer_3': 205, 'n_units_Layer_4': 95}. Best is trial 802 with value: 5.485399755449514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 21.99% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 25.06 | sMAPE for Test Set is: 26.30% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:51:15,365]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:51:17,527]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:51:21,177]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:51:22,874]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 21.68% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 20.32 | sMAPE for Test Set is: 22.54% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:51:27,771]\u001b[0m Trial 832 finished with value: 5.570880921532711 and parameters: {'n_hidden': 3, 'learning_rate': 0.001960716650611358, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09263816165939452, 'dropout_rate_Layer_2': 0.02369208101517917, 'dropout_rate_Layer_3': 0.03366224090183979, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001617973073803982, 'l1_Layer_2': 0.0002035520153237455, 'l1_Layer_3': 8.977064215107293e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 80, 'n_units_Layer_3': 145}. Best is trial 802 with value: 5.485399755449514.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:51:34,977]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:51:35,644]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:51:42,124]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:51:42,726]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:51:48,396]\u001b[0m Trial 833 finished with value: 5.686532231647533 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009955458203797648, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36839052465240535, 'dropout_rate_Layer_2': 0.010594687159496843, 'dropout_rate_Layer_3': 0.05795659861735169, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000324779618165851, 'l1_Layer_2': 4.698217643402969e-05, 'l1_Layer_3': 0.0022814616770333498, 'n_units_Layer_1': 300, 'n_units_Layer_2': 245, 'n_units_Layer_3': 255}. Best is trial 802 with value: 5.485399755449514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 21.85% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 22.16 | sMAPE for Test Set is: 24.19% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:52:14,675]\u001b[0m Trial 846 finished with value: 5.507028014567389 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016202822635687255, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0755068132400543, 'dropout_rate_Layer_2': 0.007681439804788909, 'dropout_rate_Layer_3': 0.06432916389345603, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002351025300964811, 'l1_Layer_2': 0.00018553267125963327, 'l1_Layer_3': 8.510654464397117e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 95, 'n_units_Layer_3': 140}. Best is trial 802 with value: 5.485399755449514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 21.39% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.07 | sMAPE for Test Set is: 20.99% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:52:19,851]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:52:30,311]\u001b[0m Trial 841 finished with value: 5.468485217167199 and parameters: {'n_hidden': 3, 'learning_rate': 0.001385335393976607, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07658021344452098, 'dropout_rate_Layer_2': 6.101304658170416e-05, 'dropout_rate_Layer_3': 0.04712753478880972, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013056545255837263, 'l1_Layer_2': 0.00017570098602748017, 'l1_Layer_3': 9.24523894135345e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 95, 'n_units_Layer_3': 155}. Best is trial 841 with value: 5.468485217167199.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 21.34% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.41 | sMAPE for Test Set is: 22.67% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:52:43,175]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:52:49,706]\u001b[0m Trial 847 finished with value: 5.4867030876122245 and parameters: {'n_hidden': 3, 'learning_rate': 0.00162495362663486, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09681458410303564, 'dropout_rate_Layer_2': 0.001194789647999973, 'dropout_rate_Layer_3': 0.05207085099017468, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022549280763884075, 'l1_Layer_2': 0.00017697550732464248, 'l1_Layer_3': 8.46994094963918e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 85, 'n_units_Layer_3': 135}. Best is trial 841 with value: 5.468485217167199.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 21.16% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.40 | sMAPE for Test Set is: 21.99% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:52:49,983]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:52:57,923]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:53:02,950]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 20.80% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 18.67 | sMAPE for Test Set is: 20.63% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:53:05,320]\u001b[0m Trial 845 finished with value: 5.356130822667006 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015572096894258267, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07529569688664067, 'dropout_rate_Layer_2': 0.007962099572433464, 'dropout_rate_Layer_3': 0.046459614054323466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002324816089196622, 'l1_Layer_2': 0.00018687848244913635, 'l1_Layer_3': 7.82912181273576e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 95, 'n_units_Layer_3': 140}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:53:05,872]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:53:08,108]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:53:16,779]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:53:23,074]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:53:27,491]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:53:33,460]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:53:33,746]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:53:41,937]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:53:44,732]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:53:50,154]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:54:01,606]\u001b[0m Trial 853 finished with value: 5.447304669908607 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015240043381221718, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07372344111293143, 'dropout_rate_Layer_2': 0.00983999702645843, 'dropout_rate_Layer_3': 0.049343562476087705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0027893647871468892, 'l1_Layer_2': 0.0002594051906007416, 'l1_Layer_3': 8.214704982845677e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 95, 'n_units_Layer_3': 140}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:54:01,728]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 21.08% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.08 | sMAPE for Test Set is: 20.80% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:54:08,453]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:54:14,742]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:54:19,018]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:54:23,648]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:54:30,327]\u001b[0m Trial 868 finished with value: 5.880047069564253 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010052945200363628, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3864494820811178, 'dropout_rate_Layer_2': 0.021574835299187058, 'dropout_rate_Layer_3': 0.03996693804274698, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000292244313008455, 'l1_Layer_2': 7.445092993007303e-05, 'l1_Layer_3': 0.006527634649417348, 'n_units_Layer_1': 300, 'n_units_Layer_2': 275, 'n_units_Layer_3': 265}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 22.47% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 21.04 | sMAPE for Test Set is: 22.84% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:54:36,905]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:54:42,711]\u001b[0m Trial 864 finished with value: 5.438076267697077 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013474387646842784, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06369917839433453, 'dropout_rate_Layer_2': 0.00023439647446374823, 'dropout_rate_Layer_3': 0.06811897244700224, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00216951340821272, 'l1_Layer_2': 0.00020880316027721945, 'l1_Layer_3': 8.933525274382108e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 90, 'n_units_Layer_3': 135}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 21.29% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 18.67 | sMAPE for Test Set is: 20.70% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:54:54,469]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:54:59,651]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:55:04,793]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:55:09,566]\u001b[0m Trial 876 finished with value: 7.0140822282895625 and parameters: {'n_hidden': 4, 'learning_rate': 0.00999160243018152, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0943936975944076, 'dropout_rate_Layer_2': 0.109501330918461, 'dropout_rate_Layer_3': 0.14113189176269864, 'dropout_rate_Layer_4': 0.04509865740059714, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001207025605575008, 'l1_Layer_2': 0.00039609622117157473, 'l1_Layer_3': 1.6836377138191112e-05, 'l1_Layer_4': 0.0009922373400871785, 'n_units_Layer_1': 280, 'n_units_Layer_2': 100, 'n_units_Layer_3': 150, 'n_units_Layer_4': 80}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.01 | sMAPE for Validation Set is: 25.90% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 24.39 | sMAPE for Test Set is: 27.06% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:55:11,866]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:55:17,227]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:55:24,616]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:55:29,130]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:55:41,412]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:55:46,752]\u001b[0m Trial 873 finished with value: 5.445765126802187 and parameters: {'n_hidden': 3, 'learning_rate': 0.001529926135095328, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06642600992941639, 'dropout_rate_Layer_2': 7.557086180306344e-05, 'dropout_rate_Layer_3': 0.0462693276177116, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003470372013716974, 'l1_Layer_2': 0.00018981835556069047, 'l1_Layer_3': 6.304057751341234e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 105, 'n_units_Layer_3': 145}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 21.04% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.34 | sMAPE for Test Set is: 22.16% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:55:49,985]\u001b[0m Trial 872 finished with value: 5.4586031144648475 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014614013537323028, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07125311171597158, 'dropout_rate_Layer_2': 0.01826487496185669, 'dropout_rate_Layer_3': 0.06716518749167205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00332118139831933, 'l1_Layer_2': 0.00019972140366239003, 'l1_Layer_3': 5.486892372581498e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 90, 'n_units_Layer_3': 145}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 21.15% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.62 | sMAPE for Test Set is: 22.29% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:55:54,339]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:55:57,319]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:55:57,582]\u001b[0m Trial 880 finished with value: 5.601898033584199 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017491612439879357, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06403672160257304, 'dropout_rate_Layer_2': 0.0003577435750602148, 'dropout_rate_Layer_3': 0.08256906137873332, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004770041637190802, 'l1_Layer_2': 0.0002925048818335722, 'l1_Layer_3': 5.509516733958796e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 135}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 21.83% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 21.84 | sMAPE for Test Set is: 23.56% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:56:05,011]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:56:10,345]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:56:11,298]\u001b[0m Trial 884 finished with value: 6.00792960836944 and parameters: {'n_hidden': 4, 'learning_rate': 0.014573581794720715, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06074529169102656, 'dropout_rate_Layer_2': 0.12668870609397354, 'dropout_rate_Layer_3': 0.1838501035190351, 'dropout_rate_Layer_4': 0.05277059621333492, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006937553191074565, 'l1_Layer_2': 1.8871046399151597e-05, 'l1_Layer_3': 3.0043632217519175e-05, 'l1_Layer_4': 9.368968187974098e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 50, 'n_units_Layer_3': 185, 'n_units_Layer_4': 95}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 22.82% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 23.33 | sMAPE for Test Set is: 25.30% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:56:19,068]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:56:23,232]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:56:41,932]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:56:48,040]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:57:19,974]\u001b[0m Trial 887 finished with value: 5.7987055567092325 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005409813359379671, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3092736342647785, 'dropout_rate_Layer_2': 0.016073018567124134, 'dropout_rate_Layer_3': 0.34392190802989203, 'dropout_rate_Layer_4': 0.07975645316979138, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0062892658882527696, 'l1_Layer_2': 0.0011221829879160808, 'l1_Layer_3': 0.0034544582387713387, 'l1_Layer_4': 0.000126129232893113, 'n_units_Layer_1': 105, 'n_units_Layer_2': 75, 'n_units_Layer_3': 205, 'n_units_Layer_4': 175}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 21.92% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 43.47 | sMAPE for Test Set is: 40.25% | rMAE for Test Set is: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:57:27,474]\u001b[0m Trial 893 finished with value: 5.74525547291243 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006527535611867076, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2880445217209161, 'dropout_rate_Layer_2': 0.022304129366541428, 'dropout_rate_Layer_3': 0.3428047625027836, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004314579828820323, 'l1_Layer_2': 3.7120250551011074e-05, 'l1_Layer_3': 0.004656288127019277, 'n_units_Layer_1': 95, 'n_units_Layer_2': 70, 'n_units_Layer_3': 210}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 21.94% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 47.99 | sMAPE for Test Set is: 46.01% | rMAE for Test Set is: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:57:28,208]\u001b[0m Trial 894 finished with value: 5.8851841393287465 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005919974353070123, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3230909726159849, 'dropout_rate_Layer_2': 0.25803537206812255, 'dropout_rate_Layer_3': 0.3473463176945879, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01019858832914903, 'l1_Layer_2': 6.457420177058281e-05, 'l1_Layer_3': 0.003860005740369384, 'n_units_Layer_1': 130, 'n_units_Layer_2': 90, 'n_units_Layer_3': 205}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.89 | sMAPE for Validation Set is: 22.23% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 44.53 | sMAPE for Test Set is: 42.43% | rMAE for Test Set is: 1.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:57:34,827]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:57:37,348]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:58:07,771]\u001b[0m Trial 896 finished with value: 5.435851295312578 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013157697509577652, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.058857920829215926, 'dropout_rate_Layer_2': 0.006344667600186862, 'dropout_rate_Layer_3': 0.08535528758972298, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006270472579813351, 'l1_Layer_2': 0.0003459521683930061, 'l1_Layer_3': 6.590417321671565e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 90, 'n_units_Layer_3': 145}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 21.05% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.35 | sMAPE for Test Set is: 20.93% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:58:10,037]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:58:25,873]\u001b[0m Trial 899 finished with value: 5.4662612671877575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012871799664864014, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06017406535022988, 'dropout_rate_Layer_2': 0.0073686135513558355, 'dropout_rate_Layer_3': 0.07871473292094906, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0038722221703069216, 'l1_Layer_2': 0.0002131231703335084, 'l1_Layer_3': 4.7033379408375006e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 145}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 21.14% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.96 | sMAPE for Test Set is: 21.62% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:58:30,510]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:58:37,213]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 21.36% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 19.14 | sMAPE for Test Set is: 20.61% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 03:58:39,902]\u001b[0m Trial 902 finished with value: 5.564432371889442 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013807571958562633, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04274708617205458, 'dropout_rate_Layer_2': 0.0059487963865521, 'dropout_rate_Layer_3': 0.08112468368914294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010313816107190408, 'l1_Layer_2': 0.00036104225337037677, 'l1_Layer_3': 5.249200172472924e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 100, 'n_units_Layer_3': 145}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:58:45,244]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:58:49,514]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:58:53,510]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:58:56,743]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:58:59,792]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:59:05,409]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:59:08,402]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:59:13,004]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:59:16,893]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:59:18,329]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:59:20,278]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:59:24,524]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:59:28,264]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:59:28,607]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:59:35,487]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:59:36,477]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:59:42,670]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:59:47,816]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 03:59:55,304]\u001b[0m Trial 901 finished with value: 5.441512990002291 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012762413371018352, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05756398744304608, 'dropout_rate_Layer_2': 0.006277046917905644, 'dropout_rate_Layer_3': 0.057311710109507065, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004589984523265661, 'l1_Layer_2': 0.00034258861272609974, 'l1_Layer_3': 6.297039410435606e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 90, 'n_units_Layer_3': 145}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 20.97% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.89 | sMAPE for Test Set is: 22.18% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:00:21,886]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:00:28,987]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:00:33,469]\u001b[0m Trial 919 finished with value: 5.454040424101809 and parameters: {'n_hidden': 3, 'learning_rate': 0.001460904443953549, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03587041127366794, 'dropout_rate_Layer_2': 0.013461070376708972, 'dropout_rate_Layer_3': 0.05502275512256767, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0039366241748141646, 'l1_Layer_2': 0.0002351557446426947, 'l1_Layer_3': 4.6463715518272824e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 90, 'n_units_Layer_3': 150}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 21.17% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.08 | sMAPE for Test Set is: 20.89% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:00:39,065]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:00:46,520]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:00:51,145]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:00:56,001]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 21.75% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 41.06 | sMAPE for Test Set is: 37.95% | rMAE for Test Set is: 1.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:00:58,862]\u001b[0m Trial 923 finished with value: 5.720207521401712 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005549141723298884, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30107107916412224, 'dropout_rate_Layer_2': 0.26710371742783234, 'dropout_rate_Layer_3': 0.28312215139930824, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008623289942419189, 'l1_Layer_2': 4.3689773365618515e-05, 'l1_Layer_3': 0.0011312760967548251, 'n_units_Layer_1': 130, 'n_units_Layer_2': 65, 'n_units_Layer_3': 220}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:01:02,430]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:01:06,482]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:01:09,486]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:01:12,220]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:01:17,193]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:01:22,223]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:01:23,115]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:01:29,221]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:01:32,682]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:01:56,532]\u001b[0m Trial 930 finished with value: 5.967199473832642 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006076932608026807, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31700261318287076, 'dropout_rate_Layer_2': 0.2735564521740848, 'dropout_rate_Layer_3': 0.354282118143096, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001436086004359338, 'l1_Layer_2': 0.001004138993919368, 'l1_Layer_3': 0.0009132705771606369, 'n_units_Layer_1': 230, 'n_units_Layer_2': 70, 'n_units_Layer_3': 180}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.97 | sMAPE for Validation Set is: 22.34% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 20.57 | sMAPE for Test Set is: 22.70% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:02:08,813]\u001b[0m Trial 942 finished with value: 5.551973719849298 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012177695455258635, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04868653637638594, 'dropout_rate_Layer_2': 0.000569410467381664, 'dropout_rate_Layer_3': 0.04830198390458776, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006138970163512059, 'l1_Layer_2': 0.00032523712426389884, 'l1_Layer_3': 3.88968642735337e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 100, 'n_units_Layer_3': 145}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 21.40% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 19.07 | sMAPE for Test Set is: 21.02% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:02:13,290]\u001b[0m Trial 937 finished with value: 5.63489221833667 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005537926416820972, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.328238893956593, 'dropout_rate_Layer_2': 0.27930554893515697, 'dropout_rate_Layer_3': 0.341855318355812, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017020665836150566, 'l1_Layer_2': 4.2706664177121214e-05, 'l1_Layer_3': 0.0013210460293722375, 'n_units_Layer_1': 100, 'n_units_Layer_2': 95, 'n_units_Layer_3': 230}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 21.51% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 49.95 | sMAPE for Test Set is: 48.28% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:02:15,727]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:02:32,291]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:02:40,335]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:02:45,355]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:02:52,848]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:02:59,285]\u001b[0m Trial 943 finished with value: 5.5158334270747815 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012443442130702072, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.058294853938560966, 'dropout_rate_Layer_2': 0.014681330246246209, 'dropout_rate_Layer_3': 0.0590458194288686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004065642608534293, 'l1_Layer_2': 0.00032329630641302396, 'l1_Layer_3': 3.836742643353843e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 100, 'n_units_Layer_3': 145}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 21.32% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.15 | sMAPE for Test Set is: 20.73% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:03:03,520]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:03:04,091]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:03:08,096]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:03:23,440]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:03:28,897]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:03:38,447]\u001b[0m Trial 955 finished with value: 6.094816277438884 and parameters: {'n_hidden': 4, 'learning_rate': 0.011108258497499206, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04052581047375661, 'dropout_rate_Layer_2': 0.13880427920334468, 'dropout_rate_Layer_3': 0.10543185712323197, 'dropout_rate_Layer_4': 0.08024138081677984, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0037704548523629366, 'l1_Layer_2': 1.9201772813229082e-05, 'l1_Layer_3': 7.471844297449506e-05, 'l1_Layer_4': 0.0001864819456967262, 'n_units_Layer_1': 250, 'n_units_Layer_2': 135, 'n_units_Layer_3': 165, 'n_units_Layer_4': 110}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 22.90% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 27.13 | sMAPE for Test Set is: 27.41% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:03:43,593]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:03:47,317]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:03:50,771]\u001b[0m Trial 953 finished with value: 5.543126888967907 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013533054887198018, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06383633729063744, 'dropout_rate_Layer_2': 0.000595805528640597, 'dropout_rate_Layer_3': 0.06671893820443464, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004136527983225361, 'l1_Layer_2': 0.0004971186231191178, 'l1_Layer_3': 3.5322594293458146e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 85, 'n_units_Layer_3': 155}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 21.41% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 19.34 | sMAPE for Test Set is: 21.52% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:03:53,736]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:04:12,293]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:04:13,454]\u001b[0m Trial 959 finished with value: 5.562243813327483 and parameters: {'n_hidden': 3, 'learning_rate': 0.001339030360298698, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06700457591421326, 'dropout_rate_Layer_2': 0.015922032317404328, 'dropout_rate_Layer_3': 0.07323887171269715, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00736993550016731, 'l1_Layer_2': 0.0004048838957444305, 'l1_Layer_3': 3.681827301148278e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 90, 'n_units_Layer_3': 150}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 21.41% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 22.76 | sMAPE for Test Set is: 24.60% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:04:19,626]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:04:22,091]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:04:30,872]\u001b[0m Trial 962 finished with value: 5.716104748199176 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008524912670857832, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3987910356812051, 'dropout_rate_Layer_2': 0.051262084284074805, 'dropout_rate_Layer_3': 0.025404842581604414, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.633931969097224e-05, 'l1_Layer_2': 2.985706198640786e-05, 'l1_Layer_3': 0.0008445654501311367, 'n_units_Layer_1': 260, 'n_units_Layer_2': 220, 'n_units_Layer_3': 245}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 21.82% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 21.57 | sMAPE for Test Set is: 23.23% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:04:35,896]\u001b[0m Trial 957 finished with value: 5.655751403106053 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008250153966309608, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3991536515334598, 'dropout_rate_Layer_2': 0.05195377204494052, 'dropout_rate_Layer_3': 0.023717122193839583, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003379679172811268, 'l1_Layer_2': 3.0308271103046115e-05, 'l1_Layer_3': 0.0008197725382219618, 'n_units_Layer_1': 260, 'n_units_Layer_2': 260, 'n_units_Layer_3': 245}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 21.63% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 20.24 | sMAPE for Test Set is: 22.06% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:04:36,080]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:04:44,701]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:04:53,529]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:05:02,024]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:05:05,552]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:05:10,309]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:05:14,976]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:05:17,819]\u001b[0m Trial 967 finished with value: 5.97889513302093 and parameters: {'n_hidden': 4, 'learning_rate': 0.010842065801519201, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08654286310671631, 'dropout_rate_Layer_2': 0.10568793128680781, 'dropout_rate_Layer_3': 0.10594958747797971, 'dropout_rate_Layer_4': 0.07712485782403534, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0034763252225644744, 'l1_Layer_2': 1.9290621762877014e-05, 'l1_Layer_3': 7.527738592750006e-05, 'l1_Layer_4': 0.00018781792784616102, 'n_units_Layer_1': 250, 'n_units_Layer_2': 75, 'n_units_Layer_3': 180, 'n_units_Layer_4': 100}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.98 | sMAPE for Validation Set is: 22.57% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 24.71 | sMAPE for Test Set is: 25.63% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:05:20,513]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:05:23,972]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:05:36,482]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:05:50,536]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:05:55,929]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:06:00,783]\u001b[0m Trial 977 finished with value: 5.65310042911191 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008563154482847941, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.398447432834527, 'dropout_rate_Layer_2': 0.05126618143099376, 'dropout_rate_Layer_3': 0.022262105743906812, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028686330836872806, 'l1_Layer_2': 3.931163606746192e-05, 'l1_Layer_3': 0.0010548025174436473, 'n_units_Layer_1': 250, 'n_units_Layer_2': 260, 'n_units_Layer_3': 215}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 21.72% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 21.01 | sMAPE for Test Set is: 22.87% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:06:01,678]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:06:10,806]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:06:12,649]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:06:17,291]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:06:22,038]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:06:28,204]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:06:43,643]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:06:47,525]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:06:52,727]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:06:57,202]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:07:01,884]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:07:12,258]\u001b[0m Trial 979 finished with value: 5.413261700867499 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016251737360825531, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0317418413185858, 'dropout_rate_Layer_2': 0.014150019260730373, 'dropout_rate_Layer_3': 0.04883285765745036, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004145632753230416, 'l1_Layer_2': 0.0007567665041883031, 'l1_Layer_3': 4.751122076193423e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 95, 'n_units_Layer_3': 135}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 21.03% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.51 | sMAPE for Test Set is: 21.38% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:07:13,219]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:07:16,421]\u001b[0m Trial 978 finished with value: 5.39844887299292 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016064046470772948, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03573019222655062, 'dropout_rate_Layer_2': 0.012680265352766997, 'dropout_rate_Layer_3': 0.04786352251870581, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004128987491791047, 'l1_Layer_2': 0.0003540161971088532, 'l1_Layer_3': 5.04231559232733e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 95, 'n_units_Layer_3': 135}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 20.95% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.51 | sMAPE for Test Set is: 21.36% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:07:23,939]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:07:30,687]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:07:46,167]\u001b[0m Trial 985 finished with value: 5.537245636060487 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006228977126980144, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3358264673790901, 'dropout_rate_Layer_2': 0.020077617527113262, 'dropout_rate_Layer_3': 0.28924180469205835, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012043997801362946, 'l1_Layer_2': 0.0008338683908381176, 'l1_Layer_3': 0.0018220787381169614, 'n_units_Layer_1': 300, 'n_units_Layer_2': 90, 'n_units_Layer_3': 270}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 21.15% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 49.56 | sMAPE for Test Set is: 48.16% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:07:47,182]\u001b[0m Trial 996 finished with value: 6.093204012629935 and parameters: {'n_hidden': 4, 'learning_rate': 0.015160076217472084, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10008542707278865, 'dropout_rate_Layer_2': 0.1827967228874049, 'dropout_rate_Layer_3': 0.06551895404626876, 'dropout_rate_Layer_4': 0.02385790045220569, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005364862584737708, 'l1_Layer_2': 3.127916170861243e-05, 'l1_Layer_3': 4.6003370778764435e-05, 'l1_Layer_4': 0.00043284136250531423, 'n_units_Layer_1': 255, 'n_units_Layer_2': 65, 'n_units_Layer_3': 175, 'n_units_Layer_4': 110}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 22.79% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 28.93 | sMAPE for Test Set is: 29.29% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:07:53,695]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:07:57,858]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:08:00,994]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:08:05,806]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:08:05,896]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:08:12,920]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:08:15,540]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:08:22,196]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:08:26,874]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:08:30,773]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:08:34,056]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:08:34,629]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:08:41,069]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:08:44,420]\u001b[0m Trial 1003 finished with value: 5.5303630406965025 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015768473452157925, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029206919723386383, 'dropout_rate_Layer_2': 0.028638456182312942, 'dropout_rate_Layer_3': 0.04266631561843119, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004276984906093065, 'l1_Layer_2': 0.0002451828512607257, 'l1_Layer_3': 4.8475082838426324e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 95, 'n_units_Layer_3': 135}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 21.34% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 20.40 | sMAPE for Test Set is: 22.25% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:08:47,386]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:08:58,850]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:09:14,816]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:09:18,710]\u001b[0m Trial 1015 finished with value: 5.661354215013671 and parameters: {'n_hidden': 3, 'learning_rate': 0.001240358729879765, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36560052816289407, 'dropout_rate_Layer_2': 0.04177776373565266, 'dropout_rate_Layer_3': 0.03677933082539576, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005595709923747478, 'l1_Layer_2': 8.98602627566337e-05, 'l1_Layer_3': 0.001502660638646592, 'n_units_Layer_1': 230, 'n_units_Layer_2': 280, 'n_units_Layer_3': 200}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 21.62% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 20.23 | sMAPE for Test Set is: 21.93% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:09:23,286]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:09:34,599]\u001b[0m Trial 1010 finished with value: 5.505419401190518 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006592833092100753, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2089827588047447, 'dropout_rate_Layer_2': 0.023742282894791987, 'dropout_rate_Layer_3': 0.3499595453005086, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012063132133174372, 'l1_Layer_2': 0.00048742726349729497, 'l1_Layer_3': 0.00027304407976534663, 'n_units_Layer_1': 220, 'n_units_Layer_2': 100, 'n_units_Layer_3': 285}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 21.04% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 48.32 | sMAPE for Test Set is: 46.15% | rMAE for Test Set is: 1.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:09:38,668]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:09:43,530]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:09:48,102]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:09:54,303]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:09:57,557]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:10:04,947]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:10:05,647]\u001b[0m Trial 1014 finished with value: 5.69207943353591 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006632372471276947, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3366822280822095, 'dropout_rate_Layer_2': 0.3802071362601752, 'dropout_rate_Layer_3': 0.2516275689959776, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002436252597002745, 'l1_Layer_2': 0.0009113368693511166, 'l1_Layer_3': 0.0017366630441216782, 'n_units_Layer_1': 200, 'n_units_Layer_2': 110, 'n_units_Layer_3': 265}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 21.47% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 46.09 | sMAPE for Test Set is: 43.25% | rMAE for Test Set is: 1.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:10:05,820]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:10:16,151]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:10:19,426]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:10:24,855]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:10:25,532]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:10:26,256]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:10:26,749]\u001b[0m Trial 1019 finished with value: 5.455869548805854 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014748181666499516, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02128127562149685, 'dropout_rate_Layer_2': 0.00010934704343660705, 'dropout_rate_Layer_3': 0.05493718135782035, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0041949526461088505, 'l1_Layer_2': 0.0003414504472072654, 'l1_Layer_3': 3.926462365485033e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 95, 'n_units_Layer_3': 135}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 21.04% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.39 | sMAPE for Test Set is: 21.27% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:10:35,511]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:10:38,264]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:10:41,807]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:10:42,507]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:10:45,752]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:10:51,710]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:10:58,519]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:11:02,733]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:11:11,476]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:11:21,350]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:11:25,630]\u001b[0m Trial 1037 finished with value: 6.4384396645573405 and parameters: {'n_hidden': 4, 'learning_rate': 0.007781792041377118, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0703910501859448, 'dropout_rate_Layer_2': 0.15487004343550947, 'dropout_rate_Layer_3': 0.13998499715346402, 'dropout_rate_Layer_4': 0.07597846312311213, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.010100061017143664, 'l1_Layer_2': 1.8122646523988666e-05, 'l1_Layer_3': 2.351491677214852e-05, 'l1_Layer_4': 0.00018746916205636876, 'n_units_Layer_1': 255, 'n_units_Layer_2': 65, 'n_units_Layer_3': 190, 'n_units_Layer_4': 90}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 24.03% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 23.20 | sMAPE for Test Set is: 24.60% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:11:34,503]\u001b[0m Trial 1042 finished with value: 5.505732046118493 and parameters: {'n_hidden': 3, 'learning_rate': 0.00161363463636574, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08029936892243744, 'dropout_rate_Layer_2': 0.007167352001685058, 'dropout_rate_Layer_3': 0.06407286934417068, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029737723500192935, 'l1_Layer_2': 0.0001938093425920984, 'l1_Layer_3': 7.538680592482945e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 95, 'n_units_Layer_3': 135}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 21.29% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 21.35 | sMAPE for Test Set is: 23.34% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:11:40,032]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:11:41,778]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:11:47,746]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:11:48,098]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:12:01,238]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:12:09,582]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:12:10,293]\u001b[0m Trial 1045 finished with value: 5.470984979550958 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014936142058432841, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030283496642514354, 'dropout_rate_Layer_2': 0.022225692954874726, 'dropout_rate_Layer_3': 0.057142536298126614, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004499199551815212, 'l1_Layer_2': 0.00019781095146845622, 'l1_Layer_3': 4.643570733095005e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 85, 'n_units_Layer_3': 150}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 21.12% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 21.09 | sMAPE for Test Set is: 23.02% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:12:32,428]\u001b[0m Trial 1049 finished with value: 5.72819819155067 and parameters: {'n_hidden': 3, 'learning_rate': 0.000980031103652808, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3532514350115798, 'dropout_rate_Layer_2': 0.25041762508404775, 'dropout_rate_Layer_3': 0.3459233919515072, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004103187341502765, 'l1_Layer_2': 0.0008048040926243556, 'l1_Layer_3': 0.001340229657502369, 'n_units_Layer_1': 215, 'n_units_Layer_2': 105, 'n_units_Layer_3': 270}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 21.65% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 49.43 | sMAPE for Test Set is: 47.94% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:12:32,599]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:12:41,496]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:12:43,344]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:12:48,769]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:12:48,913]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:12:49,252]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:12:57,805]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:13:02,449]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:13:02,636]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:13:03,853]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:13:11,472]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:13:14,178]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:13:17,442]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:13:21,046]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:13:24,225]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:13:28,765]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:13:33,749]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:13:38,440]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:13:41,723]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:13:45,575]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:13:46,345]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:13:46,683]\u001b[0m Trial 1051 finished with value: 5.710488412621515 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007490252196872733, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.331049183042486, 'dropout_rate_Layer_2': 0.0225481929988658, 'dropout_rate_Layer_3': 0.28518680500163535, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015386322257903296, 'l1_Layer_2': 0.0003666926129261188, 'l1_Layer_3': 0.001730485170823396, 'n_units_Layer_1': 220, 'n_units_Layer_2': 95, 'n_units_Layer_3': 270}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 21.65% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 49.58 | sMAPE for Test Set is: 47.67% | rMAE for Test Set is: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:13:57,186]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:13:57,432]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:14:05,967]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:14:09,772]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:14:31,387]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:14:36,871]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:14:41,610]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:14:47,961]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:14:53,512]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:14:56,927]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:15:01,218]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:15:04,462]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:15:09,917]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:15:10,091]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:15:17,106]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:15:17,951]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:15:26,350]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:15:33,200]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:15:37,580]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:15:38,221]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:15:41,389]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 21.33% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.43 | sMAPE for Test Set is: 21.16% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:15:45,016]\u001b[0m Trial 1083 finished with value: 5.486839409821158 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011633950570417077, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06774892979261156, 'dropout_rate_Layer_2': 0.0004473677790757897, 'dropout_rate_Layer_3': 0.051825041829752234, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004579049042329873, 'l1_Layer_2': 0.0004760863960849992, 'l1_Layer_3': 9.43491480256431e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 80, 'n_units_Layer_3': 145}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:15:53,488]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:15:53,803]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:15:55,223]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:15:55,290]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:16:07,248]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:16:17,827]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:16:18,077]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:16:18,962]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:16:26,921]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:16:27,869]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:16:30,556]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:16:36,360]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:16:39,055]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:16:49,915]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:16:55,582]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:17:00,877]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:17:05,551]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:17:10,561]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:17:15,090]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:17:27,114]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:17:38,798]\u001b[0m Trial 1107 finished with value: 5.604229814675304 and parameters: {'n_hidden': 3, 'learning_rate': 0.000721456901519746, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3407139894081352, 'dropout_rate_Layer_2': 0.03201871948859306, 'dropout_rate_Layer_3': 0.29453024634263447, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006125299030676185, 'l1_Layer_2': 0.0011970736303115992, 'l1_Layer_3': 0.0004345776377883285, 'n_units_Layer_1': 195, 'n_units_Layer_2': 100, 'n_units_Layer_3': 250}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 21.35% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 46.36 | sMAPE for Test Set is: 44.10% | rMAE for Test Set is: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:17:44,107]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:17:44,185]\u001b[0m Trial 1110 finished with value: 5.6779116534500504 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007217568332231308, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33903449603810704, 'dropout_rate_Layer_2': 0.03633131216988866, 'dropout_rate_Layer_3': 0.2972800683410644, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0023219161582287476, 'l1_Layer_2': 0.001397960427525105, 'l1_Layer_3': 0.0014181975406828598, 'n_units_Layer_1': 220, 'n_units_Layer_2': 95, 'n_units_Layer_3': 245}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 21.54% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 47.85 | sMAPE for Test Set is: 45.35% | rMAE for Test Set is: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:17:52,463]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:17:53,507]\u001b[0m Trial 1118 finished with value: 5.73268810965681 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008781757351237394, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3995581636698574, 'dropout_rate_Layer_2': 0.0392193176520075, 'dropout_rate_Layer_3': 0.01800755576672758, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001450589985091841, 'l1_Layer_2': 2.95053027871625e-05, 'l1_Layer_3': 0.0004702077151917698, 'n_units_Layer_1': 260, 'n_units_Layer_2': 220, 'n_units_Layer_3': 245}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 21.99% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 20.17 | sMAPE for Test Set is: 21.98% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:17:56,720]\u001b[0m Trial 1117 finished with value: 5.7038764493312675 and parameters: {'n_hidden': 3, 'learning_rate': 0.000863491646065081, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39731166832921394, 'dropout_rate_Layer_2': 0.039930546504603905, 'dropout_rate_Layer_3': 0.019892916851279974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001306146854516471, 'l1_Layer_2': 2.9331689134797913e-05, 'l1_Layer_3': 0.000784075654086914, 'n_units_Layer_1': 260, 'n_units_Layer_2': 220, 'n_units_Layer_3': 245}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 21.92% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 21.81 | sMAPE for Test Set is: 23.86% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:18:21,583]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:18:29,768]\u001b[0m Trial 1124 finished with value: 5.56993519427094 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015351404050631444, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04961686622407009, 'dropout_rate_Layer_2': 0.018562382846467187, 'dropout_rate_Layer_3': 0.09262480420983775, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004817749124683472, 'l1_Layer_2': 0.00027129123056576874, 'l1_Layer_3': 6.0903601260325256e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 100, 'n_units_Layer_3': 135}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 21.69% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 20.48 | sMAPE for Test Set is: 22.57% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:18:31,718]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:18:37,594]\u001b[0m Trial 1122 finished with value: 6.17493117514427 and parameters: {'n_hidden': 4, 'learning_rate': 0.0115393148638687, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014205985070864038, 'dropout_rate_Layer_2': 0.1144016443757133, 'dropout_rate_Layer_3': 0.18828412285561077, 'dropout_rate_Layer_4': 0.04925811533019844, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001354813241875775, 'l1_Layer_2': 0.0014047283522858247, 'l1_Layer_3': 3.2599565225280525e-05, 'l1_Layer_4': 0.00014847666417764353, 'n_units_Layer_1': 235, 'n_units_Layer_2': 165, 'n_units_Layer_3': 160, 'n_units_Layer_4': 75}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 23.10% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 26.40 | sMAPE for Test Set is: 27.75% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:18:37,977]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:18:45,474]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:18:46,198]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:18:46,293]\u001b[0m Trial 1123 finished with value: 6.124375402760538 and parameters: {'n_hidden': 4, 'learning_rate': 0.012197951252494985, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014214057852562472, 'dropout_rate_Layer_2': 0.11203084299406667, 'dropout_rate_Layer_3': 0.15700783860218298, 'dropout_rate_Layer_4': 0.050686528476247494, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014515371989020796, 'l1_Layer_2': 1.6684629359529127e-05, 'l1_Layer_3': 3.083194766856869e-05, 'l1_Layer_4': 8.085487392871071e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 165, 'n_units_Layer_3': 160, 'n_units_Layer_4': 75}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 23.99% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 23.86 | sMAPE for Test Set is: 25.54% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:18:46,397]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:19:00,801]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:19:00,954]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:19:42,458]\u001b[0m Trial 1130 finished with value: 5.676733144089621 and parameters: {'n_hidden': 3, 'learning_rate': 0.000642989991467265, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3582044841137866, 'dropout_rate_Layer_2': 0.03352852394459943, 'dropout_rate_Layer_3': 0.30405800383255627, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006209831813659334, 'l1_Layer_2': 0.0014575855253729905, 'l1_Layer_3': 0.001931620080871553, 'n_units_Layer_1': 220, 'n_units_Layer_2': 95, 'n_units_Layer_3': 245}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 21.62% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 44.07 | sMAPE for Test Set is: 41.35% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:19:47,806]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:20:02,391]\u001b[0m Trial 1135 finished with value: 5.6165219351288185 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006206630234110949, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3461381676510573, 'dropout_rate_Layer_2': 0.02906418805091599, 'dropout_rate_Layer_3': 0.30409513319652914, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004396494277134235, 'l1_Layer_2': 0.0012944174230516577, 'l1_Layer_3': 0.0012832743735143662, 'n_units_Layer_1': 225, 'n_units_Layer_2': 95, 'n_units_Layer_3': 240}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 21.44% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 44.99 | sMAPE for Test Set is: 42.49% | rMAE for Test Set is: 1.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:20:07,374]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:20:13,812]\u001b[0m Trial 1132 finished with value: 5.613185131145829 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006441880002989336, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3530809985356325, 'dropout_rate_Layer_2': 0.035012199860158556, 'dropout_rate_Layer_3': 0.2993957185158277, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025406436441445363, 'l1_Layer_2': 0.0018746310058908521, 'l1_Layer_3': 0.0013428383463984447, 'n_units_Layer_1': 220, 'n_units_Layer_2': 95, 'n_units_Layer_3': 240}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 21.33% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 47.64 | sMAPE for Test Set is: 45.51% | rMAE for Test Set is: 1.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:20:21,814]\u001b[0m Trial 1134 finished with value: 5.623442538893655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006241128249935171, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3588225441003823, 'dropout_rate_Layer_2': 0.03318825490075614, 'dropout_rate_Layer_3': 0.29624071837381416, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005505874774437394, 'l1_Layer_2': 0.0013051663295238819, 'l1_Layer_3': 0.0013270520064730706, 'n_units_Layer_1': 220, 'n_units_Layer_2': 95, 'n_units_Layer_3': 245}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 21.35% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 45.14 | sMAPE for Test Set is: 42.49% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:20:23,477]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:20:28,378]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:20:32,807]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:20:51,947]\u001b[0m Trial 1139 finished with value: 5.5780559882621255 and parameters: {'n_hidden': 3, 'learning_rate': 0.001806436362020667, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07180494718737421, 'dropout_rate_Layer_2': 0.08876662426082543, 'dropout_rate_Layer_3': 0.04730595997429724, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004687770150572188, 'l1_Layer_2': 0.0003068928056507344, 'l1_Layer_3': 4.882844203751527e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 110, 'n_units_Layer_3': 120}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 21.49% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 22.09 | sMAPE for Test Set is: 24.03% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:21:07,576]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:21:12,644]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 21.82% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 23.02 | sMAPE for Test Set is: 24.74% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:21:15,711]\u001b[0m Trial 1142 finished with value: 5.721594998566029 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006863456374723018, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3847052021601462, 'dropout_rate_Layer_2': 0.07275591877148056, 'dropout_rate_Layer_3': 0.011963975270988771, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2859106923183296e-05, 'l1_Layer_2': 3.78918887925773e-05, 'l1_Layer_3': 0.0010063586852703406, 'n_units_Layer_1': 280, 'n_units_Layer_2': 260, 'n_units_Layer_3': 250}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:21:19,422]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:21:22,731]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:21:26,352]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:21:31,855]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:21:33,087]\u001b[0m Trial 1137 finished with value: 5.639714873350651 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006322032104051329, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.352746544716839, 'dropout_rate_Layer_2': 0.03457451481303478, 'dropout_rate_Layer_3': 0.29664654000844937, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005792584076493181, 'l1_Layer_2': 0.0018104497594464987, 'l1_Layer_3': 0.0020332187243589724, 'n_units_Layer_1': 220, 'n_units_Layer_2': 95, 'n_units_Layer_3': 240}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 21.38% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 45.29 | sMAPE for Test Set is: 42.42% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:21:51,123]\u001b[0m Trial 1151 finished with value: 6.057866158267913 and parameters: {'n_hidden': 3, 'learning_rate': 0.009322926401209675, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.047960080731323046, 'dropout_rate_Layer_2': 0.09920867073475513, 'dropout_rate_Layer_3': 0.15888684152007176, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016325532058141775, 'l1_Layer_2': 2.2859793697264666e-05, 'l1_Layer_3': 5.380659813828937e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 185, 'n_units_Layer_3': 180}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.06 | sMAPE for Validation Set is: 22.80% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 25.84 | sMAPE for Test Set is: 26.62% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:21:54,569]\u001b[0m Trial 1152 finished with value: 6.13001391358722 and parameters: {'n_hidden': 3, 'learning_rate': 0.007083883122542499, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.042369730417940496, 'dropout_rate_Layer_2': 0.06974266737874005, 'dropout_rate_Layer_3': 0.1376064237149539, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011084044456239489, 'l1_Layer_2': 2.1909901399257373e-05, 'l1_Layer_3': 5.011047134801992e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 155, 'n_units_Layer_3': 170}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 23.00% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 22.14 | sMAPE for Test Set is: 24.01% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:21:59,565]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:22:08,196]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:22:12,188]\u001b[0m Trial 1154 finished with value: 6.095155620426355 and parameters: {'n_hidden': 3, 'learning_rate': 0.007382694971937864, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04231887506105, 'dropout_rate_Layer_2': 0.06506793385487489, 'dropout_rate_Layer_3': 0.14198803637297253, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003348650701851281, 'l1_Layer_2': 0.004928260052259848, 'l1_Layer_3': 0.00011040218450812504, 'n_units_Layer_1': 250, 'n_units_Layer_2': 185, 'n_units_Layer_3': 180}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 23.34% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 24.89 | sMAPE for Test Set is: 26.80% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:22:17,341]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:22:17,915]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:22:24,937]\u001b[0m Trial 1144 finished with value: 5.638749444296543 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006290924316065821, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.366412316606574, 'dropout_rate_Layer_2': 0.04790913587077951, 'dropout_rate_Layer_3': 0.3009752381099876, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004484997012344972, 'l1_Layer_2': 0.001271210226862146, 'l1_Layer_3': 0.0017924396407346407, 'n_units_Layer_1': 225, 'n_units_Layer_2': 90, 'n_units_Layer_3': 250}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 21.40% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 44.66 | sMAPE for Test Set is: 41.78% | rMAE for Test Set is: 1.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:22:31,479]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:22:37,370]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:22:45,904]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:22:50,508]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:22:55,512]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:23:01,397]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:23:04,165]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:23:09,537]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:23:09,950]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:23:16,602]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:23:20,512]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:23:27,530]\u001b[0m Trial 1156 finished with value: 5.616749664830631 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006523248946167344, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35096051709723985, 'dropout_rate_Layer_2': 0.04443218357952815, 'dropout_rate_Layer_3': 0.2900827823745757, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004390860791038236, 'l1_Layer_2': 0.0014749528213198952, 'l1_Layer_3': 0.0018329706626179446, 'n_units_Layer_1': 215, 'n_units_Layer_2': 85, 'n_units_Layer_3': 245}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 21.26% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 45.72 | sMAPE for Test Set is: 43.11% | rMAE for Test Set is: 1.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:23:42,222]\u001b[0m Trial 1170 finished with value: 5.482783811789702 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017385765364651847, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06645569620313035, 'dropout_rate_Layer_2': 0.006677118882677711, 'dropout_rate_Layer_3': 0.061193183536663566, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0034186795039150377, 'l1_Layer_2': 0.00015483459953134936, 'l1_Layer_3': 4.485364081360246e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 105, 'n_units_Layer_3': 160}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 21.23% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.18 | sMAPE for Test Set is: 21.09% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:23:46,762]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:23:51,409]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:23:55,824]\u001b[0m Trial 1164 finished with value: 5.455239147587352 and parameters: {'n_hidden': 3, 'learning_rate': 0.001564644343026426, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04341317010741824, 'dropout_rate_Layer_2': 0.027576158247880816, 'dropout_rate_Layer_3': 0.055257562535015424, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00432165864574317, 'l1_Layer_2': 0.00020024459515252896, 'l1_Layer_3': 5.725487118797064e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 135, 'n_units_Layer_3': 155}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 21.06% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.44 | sMAPE for Test Set is: 21.09% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:23:58,480]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:24:02,525]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:24:02,849]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:24:04,705]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:24:12,363]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:24:17,089]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:24:21,695]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:24:27,073]\u001b[0m Trial 1172 finished with value: 5.427399621749903 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017076110566049162, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03431876921182852, 'dropout_rate_Layer_2': 0.014279108062828588, 'dropout_rate_Layer_3': 0.05511689383835347, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005879772507240328, 'l1_Layer_2': 0.00014854598581373835, 'l1_Layer_3': 4.613607209818222e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 105, 'n_units_Layer_3': 160}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 21.02% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 18.85 | sMAPE for Test Set is: 20.60% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:24:31,599]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:24:35,296]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:24:39,864]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:24:40,246]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:24:47,643]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:25:05,019]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:25:10,430]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:25:15,326]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:25:26,463]\u001b[0m Trial 1182 finished with value: 5.6108637860154476 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006506183358044023, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34829345031653147, 'dropout_rate_Layer_2': 0.026417178417198393, 'dropout_rate_Layer_3': 0.2749922113808517, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026206499162071692, 'l1_Layer_2': 0.0017539396336963536, 'l1_Layer_3': 0.001647039428164249, 'n_units_Layer_1': 215, 'n_units_Layer_2': 90, 'n_units_Layer_3': 235}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 21.29% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 46.76 | sMAPE for Test Set is: 44.15% | rMAE for Test Set is: 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:25:30,668]\u001b[0m Trial 1181 finished with value: 5.663492552876583 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006593331924948263, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3460526267063974, 'dropout_rate_Layer_2': 0.045508358089218715, 'dropout_rate_Layer_3': 0.28067449037562214, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025477196170304566, 'l1_Layer_2': 0.0015810575682060875, 'l1_Layer_3': 0.0017580002168078482, 'n_units_Layer_1': 215, 'n_units_Layer_2': 90, 'n_units_Layer_3': 235}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 21.44% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 46.00 | sMAPE for Test Set is: 43.24% | rMAE for Test Set is: 1.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:25:36,283]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:25:36,510]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:25:52,007]\u001b[0m Trial 1188 finished with value: 5.603434364402056 and parameters: {'n_hidden': 3, 'learning_rate': 0.000655696837877037, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3450797016492829, 'dropout_rate_Layer_2': 0.02558754951264964, 'dropout_rate_Layer_3': 0.27963450230985765, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002458562140668398, 'l1_Layer_2': 0.0015526891627412277, 'l1_Layer_3': 0.0017732443965228794, 'n_units_Layer_1': 225, 'n_units_Layer_2': 90, 'n_units_Layer_3': 235}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 21.32% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 46.67 | sMAPE for Test Set is: 44.17% | rMAE for Test Set is: 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:26:05,243]\u001b[0m Trial 1197 finished with value: 5.563630730608892 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016729021102543865, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06962622670673976, 'dropout_rate_Layer_2': 0.007192604524156985, 'dropout_rate_Layer_3': 0.04749080789227773, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002225708257176336, 'l1_Layer_2': 0.00019833895808748492, 'l1_Layer_3': 8.726997383947805e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 105, 'n_units_Layer_3': 145}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 21.73% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 20.40 | sMAPE for Test Set is: 22.57% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:26:07,792]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:26:11,251]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:26:12,625]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:26:19,026]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:26:19,376]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:26:20,128]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:26:29,824]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:26:36,982]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:26:42,731]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:26:47,494]\u001b[0m Trial 1203 finished with value: 6.598016365639236 and parameters: {'n_hidden': 3, 'learning_rate': 0.022843689356954567, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04988915057643076, 'dropout_rate_Layer_2': 0.05728486186883636, 'dropout_rate_Layer_3': 0.14421144437455846, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020844508076470382, 'l1_Layer_2': 0.01397721722921696, 'l1_Layer_3': 0.00021726502670691412, 'n_units_Layer_1': 300, 'n_units_Layer_2': 190, 'n_units_Layer_3': 195}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 24.52% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 25.60 | sMAPE for Test Set is: 26.27% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:26:48,289]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:26:53,611]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:26:54,034]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:26:55,449]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:27:03,358]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:27:10,365]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:27:15,344]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:27:15,606]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:27:17,535]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:27:25,048]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:27:25,653]\u001b[0m Trial 1206 finished with value: 5.686539461056227 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006801682290287296, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3465268097764036, 'dropout_rate_Layer_2': 0.02559661975856968, 'dropout_rate_Layer_3': 0.2817114009642042, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0031619377240940127, 'l1_Layer_2': 0.0015927826227126265, 'l1_Layer_3': 0.0011622629969414544, 'n_units_Layer_1': 220, 'n_units_Layer_2': 80, 'n_units_Layer_3': 230}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 21.67% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 46.25 | sMAPE for Test Set is: 43.95% | rMAE for Test Set is: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:27:33,247]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:27:35,925]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:27:41,308]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:27:41,958]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:27:45,319]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:27:50,720]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:27:57,235]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:28:02,123]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:28:06,213]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:28:08,950]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:28:13,770]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:28:17,947]\u001b[0m Trial 1226 finished with value: 6.0977915010711286 and parameters: {'n_hidden': 3, 'learning_rate': 0.010405841354317361, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027256466979335682, 'dropout_rate_Layer_2': 0.14600214304349377, 'dropout_rate_Layer_3': 0.13059261261941393, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00036496883137871546, 'l1_Layer_2': 0.0009244688370860529, 'l1_Layer_3': 4.1122313297436155e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 160, 'n_units_Layer_3': 180}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 23.06% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 23.89 | sMAPE for Test Set is: 25.47% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:28:21,576]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:28:24,716]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:28:27,330]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:28:31,302]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:28:31,586]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:28:32,657]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:28:41,388]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:28:42,158]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:28:42,528]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:28:48,507]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:28:52,682]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:28:57,762]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:29:01,354]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:29:02,884]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:29:04,414]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:29:07,122]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:29:14,842]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:29:18,478]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:29:22,277]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:29:27,789]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:29:42,299]\u001b[0m Trial 1240 finished with value: 5.743434009758018 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012183287233705669, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36780779303786815, 'dropout_rate_Layer_2': 0.07964293080540004, 'dropout_rate_Layer_3': 0.047891073169263734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3652924571079497e-05, 'l1_Layer_2': 3.377923713147707e-05, 'l1_Layer_3': 0.0025843223938599876, 'n_units_Layer_1': 255, 'n_units_Layer_2': 240, 'n_units_Layer_3': 275}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 22.06% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 21.36 | sMAPE for Test Set is: 23.43% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:29:44,941]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:29:54,278]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:30:27,092]\u001b[0m Trial 1246 finished with value: 5.70470807028791 and parameters: {'n_hidden': 3, 'learning_rate': 0.000736912602907919, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38365828585278816, 'dropout_rate_Layer_2': 0.04545772895871052, 'dropout_rate_Layer_3': 0.27001572940597746, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0031984129004277227, 'l1_Layer_2': 0.0017199696809178477, 'l1_Layer_3': 0.00123882783517797, 'n_units_Layer_1': 205, 'n_units_Layer_2': 85, 'n_units_Layer_3': 240}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 21.52% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 47.37 | sMAPE for Test Set is: 45.30% | rMAE for Test Set is: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:30:32,225]\u001b[0m Trial 1250 finished with value: 5.6359036203095405 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005479972204234827, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3826479439449013, 'dropout_rate_Layer_2': 0.05093320268307864, 'dropout_rate_Layer_3': 0.27046603558697924, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005174903846613389, 'l1_Layer_2': 0.001774531883183147, 'l1_Layer_3': 0.0010565709651067148, 'n_units_Layer_1': 205, 'n_units_Layer_2': 85, 'n_units_Layer_3': 240}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 21.50% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 42.74 | sMAPE for Test Set is: 39.78% | rMAE for Test Set is: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:30:39,656]\u001b[0m Trial 1254 finished with value: 5.641787339064847 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007061194611121974, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3620786150878522, 'dropout_rate_Layer_2': 0.01912526828052194, 'dropout_rate_Layer_3': 0.2947800738122343, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022707952188202865, 'l1_Layer_2': 0.0012320965242584212, 'l1_Layer_3': 0.001969042967933967, 'n_units_Layer_1': 215, 'n_units_Layer_2': 90, 'n_units_Layer_3': 235}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 21.38% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 46.56 | sMAPE for Test Set is: 43.88% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:30:41,194]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:30:48,079]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:30:49,308]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:30:51,529]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:30:55,677]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 21.26% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 21.33 | sMAPE for Test Set is: 23.15% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:30:58,602]\u001b[0m Trial 1255 finished with value: 5.525318656031911 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019989305440844328, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07242437629227104, 'dropout_rate_Layer_2': 0.007778893862050591, 'dropout_rate_Layer_3': 0.03639408861035223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0030783736302346042, 'l1_Layer_2': 0.00021215097530848424, 'l1_Layer_3': 5.03432719307382e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 110, 'n_units_Layer_3': 140}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:30:59,948]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:31:10,229]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:31:14,894]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:31:19,227]\u001b[0m Trial 1261 finished with value: 6.096192287263931 and parameters: {'n_hidden': 3, 'learning_rate': 0.010212120331070747, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03680436171608594, 'dropout_rate_Layer_2': 0.14519689160901086, 'dropout_rate_Layer_3': 0.2025351741218684, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003041173770269224, 'l1_Layer_2': 0.0011422905186343577, 'l1_Layer_3': 4.42991263893545e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 180, 'n_units_Layer_3': 180}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 24.28% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 26.22 | sMAPE for Test Set is: 28.12% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:31:19,989]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:31:27,273]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:31:27,591]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:31:27,809]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:31:28,586]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:31:38,341]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:31:44,791]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:31:45,491]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:31:54,728]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:31:58,964]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:32:02,740]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:32:06,536]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:32:07,841]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:32:08,891]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:32:17,704]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:32:19,062]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:32:19,865]\u001b[0m Trial 1275 finished with value: 6.365441032655834 and parameters: {'n_hidden': 3, 'learning_rate': 0.016435145026110758, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04960483222391787, 'dropout_rate_Layer_2': 0.13437340962768193, 'dropout_rate_Layer_3': 0.20624928645902546, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029771351287484195, 'l1_Layer_2': 2.593908620404972e-05, 'l1_Layer_3': 6.912258355386547e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 180, 'n_units_Layer_3': 170}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 23.85% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 23.76 | sMAPE for Test Set is: 25.88% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:32:25,895]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:32:31,158]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:32:32,127]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:32:45,562]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:32:52,850]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:33:00,393]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:33:19,028]\u001b[0m Trial 1289 finished with value: 5.494663031218001 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015923979249547516, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05949371978175933, 'dropout_rate_Layer_2': 0.021075474963602188, 'dropout_rate_Layer_3': 0.07122183339056891, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00235527149972492, 'l1_Layer_2': 0.00016255747623685623, 'l1_Layer_3': 5.1477262689599526e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 90, 'n_units_Layer_3': 160}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 21.44% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.63 | sMAPE for Test Set is: 21.71% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:33:22,500]\u001b[0m Trial 1291 finished with value: 6.198566360715759 and parameters: {'n_hidden': 3, 'learning_rate': 0.020619917211030316, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08825051657404312, 'dropout_rate_Layer_2': 0.007403955130190647, 'dropout_rate_Layer_3': 0.21764554535824326, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014685823349037655, 'l1_Layer_2': 0.0005010683609055705, 'l1_Layer_3': 4.20712463566418e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 200, 'n_units_Layer_3': 190}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 23.35% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 28.63 | sMAPE for Test Set is: 29.31% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:33:29,786]\u001b[0m Trial 1287 finished with value: 5.709990754711235 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007392374061099273, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38291698269935814, 'dropout_rate_Layer_2': 0.07405947991428034, 'dropout_rate_Layer_3': 0.01293211011299069, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1074554097435716e-05, 'l1_Layer_2': 4.341895671896273e-05, 'l1_Layer_3': 0.0010620997995867763, 'n_units_Layer_1': 280, 'n_units_Layer_2': 265, 'n_units_Layer_3': 250}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 22.01% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 21.15 | sMAPE for Test Set is: 23.13% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:33:35,132]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:33:35,271]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:33:37,504]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:33:46,607]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:33:46,867]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:33:54,569]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:34:01,048]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:34:08,208]\u001b[0m Trial 1299 finished with value: 6.037580263305563 and parameters: {'n_hidden': 3, 'learning_rate': 0.010517032253801378, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04240315797411281, 'dropout_rate_Layer_2': 0.06711828534684638, 'dropout_rate_Layer_3': 0.23294724948064266, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00048115596100827685, 'l1_Layer_2': 0.0002833485679794461, 'l1_Layer_3': 5.522740261215093e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 80, 'n_units_Layer_3': 195}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 22.90% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 20.46 | sMAPE for Test Set is: 22.59% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:34:17,152]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:34:21,706]\u001b[0m Trial 1293 finished with value: 5.68883727236586 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006940569964476381, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3912966441070104, 'dropout_rate_Layer_2': 0.07052685634319547, 'dropout_rate_Layer_3': 0.00867146627082064, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3058691348898076e-05, 'l1_Layer_2': 4.072359366300836e-05, 'l1_Layer_3': 0.0008632572483071461, 'n_units_Layer_1': 265, 'n_units_Layer_2': 260, 'n_units_Layer_3': 250}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 21.93% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 21.48 | sMAPE for Test Set is: 23.23% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:34:22,011]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:34:28,395]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:34:29,397]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:34:31,970]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:34:35,605]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:34:41,484]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:34:41,936]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:34:49,946]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:34:55,251]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:34:59,967]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:35:03,384]\u001b[0m Trial 1295 finished with value: 5.434609973527208 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012902818332105634, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.045876623272667005, 'dropout_rate_Layer_2': 0.029391028124908493, 'dropout_rate_Layer_3': 0.06922517480011134, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0024324693338560886, 'l1_Layer_2': 0.0001247652574109806, 'l1_Layer_3': 6.585902410555885e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 85, 'n_units_Layer_3': 160}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 21.02% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.22 | sMAPE for Test Set is: 22.18% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:35:10,785]\u001b[0m Trial 1310 finished with value: 5.961811692367689 and parameters: {'n_hidden': 3, 'learning_rate': 0.006417054581144929, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13891698534883617, 'dropout_rate_Layer_2': 0.06602874386629845, 'dropout_rate_Layer_3': 0.23349728600904854, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005696482244280263, 'l1_Layer_2': 6.190913012606718e-05, 'l1_Layer_3': 0.0001135786284357571, 'n_units_Layer_1': 220, 'n_units_Layer_2': 105, 'n_units_Layer_3': 215}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 22.62% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 22.07 | sMAPE for Test Set is: 24.05% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:35:16,655]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:35:20,000]\u001b[0m Trial 1314 finished with value: 6.298153009135743 and parameters: {'n_hidden': 3, 'learning_rate': 0.00642991913437105, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13891197198223074, 'dropout_rate_Layer_2': 0.08508917097617438, 'dropout_rate_Layer_3': 0.2335086204461137, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00047713012944693666, 'l1_Layer_2': 0.0002963381898709215, 'l1_Layer_3': 8.788002896814881e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 105, 'n_units_Layer_3': 215}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 23.60% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 22.11 | sMAPE for Test Set is: 23.21% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:35:27,745]\u001b[0m Trial 1315 finished with value: 6.072627136107386 and parameters: {'n_hidden': 3, 'learning_rate': 0.012782621868491523, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12475958902258479, 'dropout_rate_Layer_2': 0.08735647206009033, 'dropout_rate_Layer_3': 0.19046901767640312, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005064706652709477, 'l1_Layer_2': 0.00015371083219242325, 'l1_Layer_3': 8.243073431705604e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 105, 'n_units_Layer_3': 215}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 22.92% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 23.54 | sMAPE for Test Set is: 25.42% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:35:31,808]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:35:36,962]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:35:39,733]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:35:42,856]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:35:52,148]\u001b[0m Trial 1318 finished with value: 6.15379973696965 and parameters: {'n_hidden': 3, 'learning_rate': 0.012779416352885717, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07557014305145107, 'dropout_rate_Layer_2': 0.05190582544695153, 'dropout_rate_Layer_3': 0.22913360947637335, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008720037983789862, 'l1_Layer_2': 0.00018985380041784737, 'l1_Layer_3': 3.441434794646984e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 85, 'n_units_Layer_3': 220}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 23.39% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 27.00 | sMAPE for Test Set is: 27.51% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:35:56,854]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:36:02,525]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:36:13,584]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:36:30,224]\u001b[0m Trial 1319 finished with value: 5.610130779905351 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007235687348671644, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39951326456830755, 'dropout_rate_Layer_2': 0.034845783554783245, 'dropout_rate_Layer_3': 0.2766712400057994, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005358534399904878, 'l1_Layer_2': 0.0013840743059400167, 'l1_Layer_3': 0.001512358890843115, 'n_units_Layer_1': 210, 'n_units_Layer_2': 100, 'n_units_Layer_3': 240}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 21.38% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 45.45 | sMAPE for Test Set is: 43.03% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:36:35,926]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:36:44,775]\u001b[0m Trial 1322 finished with value: 5.548345219746938 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006541084908971347, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33935837760695803, 'dropout_rate_Layer_2': 0.0353527475939685, 'dropout_rate_Layer_3': 0.2974355043488685, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029144776281069674, 'l1_Layer_2': 0.0008392746590325659, 'l1_Layer_3': 0.001231471750848556, 'n_units_Layer_1': 220, 'n_units_Layer_2': 85, 'n_units_Layer_3': 245}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 21.13% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 45.72 | sMAPE for Test Set is: 43.13% | rMAE for Test Set is: 1.66\n",
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 21.69% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 19.01 | sMAPE for Test Set is: 20.87% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:36:44,867]\u001b[0m Trial 1327 finished with value: 5.645348049277715 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005672803608472476, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37812554227821843, 'dropout_rate_Layer_2': 0.07456913218490825, 'dropout_rate_Layer_3': 0.2123927007264304, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9226687329239777e-05, 'l1_Layer_2': 8.032959068974524e-05, 'l1_Layer_3': 0.0005626323390146478, 'n_units_Layer_1': 280, 'n_units_Layer_2': 275, 'n_units_Layer_3': 255}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:36:45,070]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:36:54,186]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:36:54,318]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:37:03,659]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:37:03,891]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:37:11,614]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:37:14,583]\u001b[0m Trial 1332 finished with value: 6.186768247866476 and parameters: {'n_hidden': 3, 'learning_rate': 0.0055327454186297744, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11741959920586316, 'dropout_rate_Layer_2': 0.1045341922298696, 'dropout_rate_Layer_3': 0.19118418015021457, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007768812035415854, 'l1_Layer_2': 5.951895790404439e-05, 'l1_Layer_3': 0.00012695864454841295, 'n_units_Layer_1': 215, 'n_units_Layer_2': 90, 'n_units_Layer_3': 195}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 23.36% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 23.73 | sMAPE for Test Set is: 25.80% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:37:17,323]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:37:21,316]\u001b[0m Trial 1323 finished with value: 5.6478147550102955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006549592876524395, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39990398784091125, 'dropout_rate_Layer_2': 0.03328453079417215, 'dropout_rate_Layer_3': 0.30165354855497606, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029558326035938817, 'l1_Layer_2': 0.00223932995855533, 'l1_Layer_3': 0.002159373456118325, 'n_units_Layer_1': 220, 'n_units_Layer_2': 95, 'n_units_Layer_3': 235}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 21.36% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 46.92 | sMAPE for Test Set is: 44.45% | rMAE for Test Set is: 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:37:22,421]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:37:24,104]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:37:30,878]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:37:33,337]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:37:38,826]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:37:43,808]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:37:44,598]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:37:44,825]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:37:55,308]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:38:00,203]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:38:03,716]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:38:04,007]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:38:13,341]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:38:18,893]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:38:25,111]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:38:34,083]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:38:40,167]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:38:45,921]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:38:57,580]\u001b[0m Trial 1351 finished with value: 6.4378993851605015 and parameters: {'n_hidden': 3, 'learning_rate': 0.01133064170488418, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09973830143279497, 'dropout_rate_Layer_2': 0.12222338822280417, 'dropout_rate_Layer_3': 0.252882397832028, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003848358567426259, 'l1_Layer_2': 0.00016510465552917934, 'l1_Layer_3': 7.97642626254361e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 75, 'n_units_Layer_3': 210}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 24.11% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 28.34 | sMAPE for Test Set is: 28.81% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:39:03,305]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:39:08,405]\u001b[0m Trial 1346 finished with value: 5.802164027564705 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008078919016570635, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.397457849245961, 'dropout_rate_Layer_2': 0.036786026013618495, 'dropout_rate_Layer_3': 0.2924550224300619, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0027111067445509673, 'l1_Layer_2': 0.0020397659978277248, 'l1_Layer_3': 0.0023225276511900294, 'n_units_Layer_1': 220, 'n_units_Layer_2': 95, 'n_units_Layer_3': 250}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 21.93% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 49.81 | sMAPE for Test Set is: 48.08% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:39:08,879]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:39:15,138]\u001b[0m Trial 1350 finished with value: 5.734719562416164 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006185993384475786, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3817976645174216, 'dropout_rate_Layer_2': 0.059235787729945116, 'dropout_rate_Layer_3': 0.20756151819905036, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8541381811173055e-05, 'l1_Layer_2': 9.185353935895962e-05, 'l1_Layer_3': 0.002344751088755691, 'n_units_Layer_1': 265, 'n_units_Layer_2': 260, 'n_units_Layer_3': 250}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 21.92% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 20.66 | sMAPE for Test Set is: 22.48% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:39:15,360]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:39:17,547]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:39:26,522]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:39:26,812]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:39:27,709]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:39:30,929]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:39:38,150]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:39:43,421]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:39:43,546]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:39:50,236]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:39:52,342]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:40:02,196]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:40:07,285]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:40:12,601]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:40:17,513]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:40:20,926]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:40:24,784]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:40:29,573]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:40:30,284]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:40:30,993]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:40:37,777]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:40:39,519]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:40:44,046]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:40:46,478]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:40:49,901]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:40:58,504]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:41:02,369]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:41:15,117]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:41:19,888]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:41:26,009]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:41:30,381]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:41:31,405]\u001b[0m Trial 1372 finished with value: 5.677449928729094 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007122775043483944, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34009078755123956, 'dropout_rate_Layer_2': 0.02778069904085536, 'dropout_rate_Layer_3': 0.27081959318589804, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0054238299971726385, 'l1_Layer_2': 0.0016959928192057847, 'l1_Layer_3': 0.0008628779994785545, 'n_units_Layer_1': 230, 'n_units_Layer_2': 80, 'n_units_Layer_3': 230}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 21.56% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 46.42 | sMAPE for Test Set is: 44.13% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:41:36,109]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:41:39,002]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:41:43,377]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:41:50,670]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:41:55,212]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:41:57,431]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:42:03,197]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:42:04,178]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:42:12,025]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:42:18,121]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:42:33,520]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:42:42,746]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:42:51,298]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:42:59,685]\u001b[0m Trial 1402 finished with value: 5.473909411964144 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012616802938932737, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07660609986957813, 'dropout_rate_Layer_2': 1.0744128758592361e-05, 'dropout_rate_Layer_3': 0.04877678605889769, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019814177133986406, 'l1_Layer_2': 0.00023776912554571524, 'l1_Layer_3': 3.113319436881459e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 245, 'n_units_Layer_3': 140}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 21.17% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 18.93 | sMAPE for Test Set is: 20.87% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:43:04,566]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:43:10,509]\u001b[0m Trial 1407 finished with value: 5.8123834097249825 and parameters: {'n_hidden': 3, 'learning_rate': 0.012953449947028135, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12456370429685984, 'dropout_rate_Layer_2': 0.08629318518714554, 'dropout_rate_Layer_3': 0.062211730638914255, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001010364111557031, 'l1_Layer_2': 7.086407075100424e-05, 'l1_Layer_3': 2.1826787266922877e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 130, 'n_units_Layer_3': 245}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:43:10,601]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 22.35% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 20.46 | sMAPE for Test Set is: 22.21% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:43:18,895]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:43:19,503]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:43:25,389]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:43:26,699]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 22.39% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 21.04 | sMAPE for Test Set is: 22.94% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:43:31,158]\u001b[0m Trial 1409 finished with value: 5.73248488550454 and parameters: {'n_hidden': 3, 'learning_rate': 0.01053666190082353, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1466308134057552, 'dropout_rate_Layer_2': 0.09067890644664106, 'dropout_rate_Layer_3': 0.1830162190622184, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009950621115302903, 'l1_Layer_2': 6.627623801839274e-05, 'l1_Layer_3': 3.807416168173245e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 130, 'n_units_Layer_3': 195}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:43:32,678]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:43:34,140]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:43:39,040]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:43:43,692]\u001b[0m Trial 1403 finished with value: 5.7092968154219195 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006987416616727895, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3684508077454501, 'dropout_rate_Layer_2': 0.0592211223104891, 'dropout_rate_Layer_3': 0.2783007064910032, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005049973848791219, 'l1_Layer_2': 0.0011613798087949949, 'l1_Layer_3': 0.0025385394029391545, 'n_units_Layer_1': 215, 'n_units_Layer_2': 95, 'n_units_Layer_3': 230}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 21.55% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 46.80 | sMAPE for Test Set is: 44.66% | rMAE for Test Set is: 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:43:44,247]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:43:51,152]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:43:54,491]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:43:55,624]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:44:00,089]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:44:01,363]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:44:01,543]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:44:10,511]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:44:10,789]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:44:40,256]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:44:53,771]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:44:58,903]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:45:03,167]\u001b[0m Trial 1426 finished with value: 5.481003740881619 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010690069563330155, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06924332051974372, 'dropout_rate_Layer_2': 0.006745606430626616, 'dropout_rate_Layer_3': 0.04697896850184321, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00350877407602353, 'l1_Layer_2': 0.000211563552373059, 'l1_Layer_3': 3.6752490839843606e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 260, 'n_units_Layer_3': 155}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 21.19% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.20 | sMAPE for Test Set is: 20.90% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:45:06,271]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:45:09,953]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:45:18,632]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 21.58% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 44.57 | sMAPE for Test Set is: 41.78% | rMAE for Test Set is: 1.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:45:20,102]\u001b[0m Trial 1427 finished with value: 5.697003381336412 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008015476200097246, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3531546885646399, 'dropout_rate_Layer_2': 0.0485689473304526, 'dropout_rate_Layer_3': 0.23222235109858544, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006223400158018995, 'l1_Layer_2': 0.0015951170094391474, 'l1_Layer_3': 0.0009957467311984393, 'n_units_Layer_1': 220, 'n_units_Layer_2': 110, 'n_units_Layer_3': 235}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:45:38,434]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:45:44,247]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:46:07,139]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:46:08,419]\u001b[0m Trial 1435 finished with value: 5.5035481454600825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009178823818773132, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010817325479856945, 'dropout_rate_Layer_2': 0.011750155057815634, 'dropout_rate_Layer_3': 0.04036948400669187, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005085775223229067, 'l1_Layer_2': 0.0003451983053359187, 'l1_Layer_3': 2.8738341152348628e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 230, 'n_units_Layer_3': 160}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 21.42% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.24 | sMAPE for Test Set is: 21.18% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:46:15,125]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:46:24,737]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:46:30,133]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:46:30,659]\u001b[0m Trial 1431 finished with value: 5.644380248016856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005978423036056398, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3406073022434972, 'dropout_rate_Layer_2': 0.03705558710228201, 'dropout_rate_Layer_3': 0.28699018581844604, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0032211180228879505, 'l1_Layer_2': 0.0020171542669743118, 'l1_Layer_3': 0.0014426080411952303, 'n_units_Layer_1': 230, 'n_units_Layer_2': 100, 'n_units_Layer_3': 225}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 21.40% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 48.71 | sMAPE for Test Set is: 47.02% | rMAE for Test Set is: 1.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:46:40,100]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:46:44,868]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:46:45,286]\u001b[0m Trial 1443 finished with value: 5.945389072917187 and parameters: {'n_hidden': 3, 'learning_rate': 0.01561100277971693, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1254446106545906, 'dropout_rate_Layer_2': 0.06533229408639929, 'dropout_rate_Layer_3': 0.18630786939501442, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011707158771147258, 'l1_Layer_2': 5.245740945173894e-05, 'l1_Layer_3': 3.331637062358129e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 80, 'n_units_Layer_3': 200}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.95 | sMAPE for Validation Set is: 22.55% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 20.13 | sMAPE for Test Set is: 22.17% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:46:51,442]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:46:55,638]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:47:00,773]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:47:06,677]\u001b[0m Trial 1440 finished with value: 5.818880264070596 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007766394322878576, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3413225342405743, 'dropout_rate_Layer_2': 0.0383855505157702, 'dropout_rate_Layer_3': 0.2533190527065811, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007173178845785886, 'l1_Layer_2': 0.002056390701041243, 'l1_Layer_3': 0.0007621152384399841, 'n_units_Layer_1': 230, 'n_units_Layer_2': 115, 'n_units_Layer_3': 240}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 21.89% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 46.22 | sMAPE for Test Set is: 43.41% | rMAE for Test Set is: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:47:07,827]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:47:17,157]\u001b[0m Trial 1449 finished with value: 6.052170552986024 and parameters: {'n_hidden': 3, 'learning_rate': 0.016923855992923623, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15000715808161819, 'dropout_rate_Layer_2': 0.06153271191849436, 'dropout_rate_Layer_3': 0.18509785724688815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001307353757443715, 'l1_Layer_2': 5.0644325016915486e-05, 'l1_Layer_3': 3.6478744816390074e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 95, 'n_units_Layer_3': 195}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.05 | sMAPE for Validation Set is: 22.76% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 20.29 | sMAPE for Test Set is: 22.09% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:47:22,945]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:47:41,389]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:47:45,626]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:47:46,446]\u001b[0m Trial 1456 finished with value: 5.935492987758381 and parameters: {'n_hidden': 3, 'learning_rate': 0.015583859885811789, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13224603176869426, 'dropout_rate_Layer_2': 0.0610699673122303, 'dropout_rate_Layer_3': 0.16862994765454126, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012408288354481486, 'l1_Layer_2': 5.419575587776789e-05, 'l1_Layer_3': 3.667154952922027e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 95, 'n_units_Layer_3': 265}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.94 | sMAPE for Validation Set is: 22.76% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 20.09 | sMAPE for Test Set is: 22.50% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:47:51,200]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:47:56,114]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:48:02,343]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:48:22,175]\u001b[0m Trial 1459 finished with value: 5.707290357523559 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008841061162282791, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3977457461998315, 'dropout_rate_Layer_2': 0.054119992174729105, 'dropout_rate_Layer_3': 0.02760245582582616, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.96419448665654e-05, 'l1_Layer_2': 3.091144413557162e-05, 'l1_Layer_3': 0.0008507591503733774, 'n_units_Layer_1': 265, 'n_units_Layer_2': 225, 'n_units_Layer_3': 245}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 22.06% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 19.59 | sMAPE for Test Set is: 21.67% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:48:22,388]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:48:31,355]\u001b[0m Trial 1458 finished with value: 5.711063015634262 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008606930589957871, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39526402455515264, 'dropout_rate_Layer_2': 0.05321015499474406, 'dropout_rate_Layer_3': 0.026678158470724737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019557276344003174, 'l1_Layer_2': 4.694367096424808e-05, 'l1_Layer_3': 0.0008785125602053434, 'n_units_Layer_1': 265, 'n_units_Layer_2': 225, 'n_units_Layer_3': 245}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 21.97% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 19.48 | sMAPE for Test Set is: 21.43% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:48:40,457]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:48:53,180]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:48:58,407]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:49:02,372]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:49:02,534]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:49:03,007]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:49:10,660]\u001b[0m Trial 1462 finished with value: 5.484888495688595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009678220396525559, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05248255722998766, 'dropout_rate_Layer_2': 0.00018682328212288237, 'dropout_rate_Layer_3': 0.030173915269520377, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004830474628212222, 'l1_Layer_2': 0.00040072588623865565, 'l1_Layer_3': 3.424475624457513e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 245, 'n_units_Layer_3': 145}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 21.17% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.95 | sMAPE for Test Set is: 22.78% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:49:13,591]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:49:13,824]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:49:20,921]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:49:23,449]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:49:27,819]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:49:29,416]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:49:32,092]\u001b[0m Trial 1471 finished with value: 5.880604450081717 and parameters: {'n_hidden': 3, 'learning_rate': 0.02118726905640836, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14896130956917947, 'dropout_rate_Layer_2': 0.041512632046025975, 'dropout_rate_Layer_3': 0.1736043951249736, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012057753907776189, 'l1_Layer_2': 6.509044999357486e-05, 'l1_Layer_3': 3.631058420297182e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 80, 'n_units_Layer_3': 275}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 22.11% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 24.95 | sMAPE for Test Set is: 24.12% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:49:39,559]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:49:45,288]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:49:45,430]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:49:56,374]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:50:00,510]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:50:04,270]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:50:07,815]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:50:08,381]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:50:13,258]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:50:16,830]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:50:20,827]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:50:25,418]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:50:26,788]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:50:33,465]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:50:39,954]\u001b[0m Trial 1489 finished with value: 6.074900973602481 and parameters: {'n_hidden': 3, 'learning_rate': 0.019899471724465722, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1438932916587108, 'dropout_rate_Layer_2': 0.05030550036611291, 'dropout_rate_Layer_3': 0.16736595000976, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008846689489314619, 'l1_Layer_2': 6.503863844719094e-05, 'l1_Layer_3': 2.0549832991998017e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 95, 'n_units_Layer_3': 295}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 23.48% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 27.19 | sMAPE for Test Set is: 25.18% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:50:45,229]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:50:48,037]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:50:48,335]\u001b[0m Trial 1492 finished with value: 5.865468643606817 and parameters: {'n_hidden': 3, 'learning_rate': 0.020603809822969856, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14912731341496924, 'dropout_rate_Layer_2': 0.029759886535450506, 'dropout_rate_Layer_3': 0.16966482642289663, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009019724379070806, 'l1_Layer_2': 6.267510435447879e-05, 'l1_Layer_3': 2.242996698173728e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 95, 'n_units_Layer_3': 275}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 22.88% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 21.12 | sMAPE for Test Set is: 22.57% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:51:12,069]\u001b[0m Trial 1495 finished with value: 5.7352441053250205 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009559635262350001, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3997307660958603, 'dropout_rate_Layer_2': 0.06330218774655356, 'dropout_rate_Layer_3': 0.03758026073907128, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0334702201576057e-05, 'l1_Layer_2': 3.7924145368978395e-05, 'l1_Layer_3': 0.00041659751831291597, 'n_units_Layer_1': 250, 'n_units_Layer_2': 260, 'n_units_Layer_3': 255}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 21.90% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 20.65 | sMAPE for Test Set is: 22.33% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 04:51:17,804]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:51:30,156]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:51:32,985]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:51:33,297]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 04:51:39,000]\u001b[0m Trial 1490 finished with value: 5.57826382058798 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006780803439744188, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3454255698978812, 'dropout_rate_Layer_2': 0.023487279720627995, 'dropout_rate_Layer_3': 0.28961647636750565, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0023608539793555016, 'l1_Layer_2': 0.001354004199026298, 'l1_Layer_3': 0.0009215535507673064, 'n_units_Layer_1': 220, 'n_units_Layer_2': 110, 'n_units_Layer_3': 235}. Best is trial 845 with value: 5.356130822667006.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 21.16% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 47.42 | sMAPE for Test Set is: 45.12% | rMAE for Test Set is: 1.72\n",
      "for 2021-01-01, MAE is:5.28 & sMAPE is:11.06% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 11.06% & 0.42\n",
      "for 2021-01-02, MAE is:5.79 & sMAPE is:11.63% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 11.34% & 0.41\n",
      "for 2021-01-03, MAE is:7.51 & sMAPE is:15.00% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 12.56% & 0.41\n",
      "for 2021-01-04, MAE is:7.96 & sMAPE is:16.08% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 13.44% & 0.55\n",
      "for 2021-01-05, MAE is:8.26 & sMAPE is:17.17% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 14.19% & 0.73\n",
      "for 2021-01-06, MAE is:6.37 & sMAPE is:12.77% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 13.95% & 0.79\n",
      "for 2021-01-07, MAE is:17.50 & sMAPE is:27.50% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :8.38 & 15.88% & 0.83\n",
      "for 2021-01-08, MAE is:24.40 & sMAPE is:33.21% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :10.38 & 18.05% & 0.83\n",
      "for 2021-01-09, MAE is:3.08 & sMAPE is:5.37% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :9.57 & 16.64% & 0.78\n",
      "for 2021-01-10, MAE is:4.41 & sMAPE is:8.45% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :9.06 & 15.82% & 0.77\n",
      "for 2021-01-11, MAE is:8.09 & sMAPE is:17.55% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :8.97 & 15.98% & 0.78\n",
      "for 2021-01-12, MAE is:12.35 & sMAPE is:26.08% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :9.25 & 16.82% & 0.80\n",
      "for 2021-01-13, MAE is:10.68 & sMAPE is:17.90% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 16.90% & 0.82\n",
      "for 2021-01-14, MAE is:10.26 & sMAPE is:13.97% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 16.69% & 0.83\n",
      "for 2021-01-15, MAE is:11.07 & sMAPE is:15.16% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :9.53 & 16.59% & 0.82\n",
      "for 2021-01-16, MAE is:4.25 & sMAPE is:7.66% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :9.20 & 16.03% & 0.83\n",
      "for 2021-01-17, MAE is:3.83 & sMAPE is:7.23% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :8.89 & 15.52% & 0.84\n",
      "for 2021-01-18, MAE is:7.72 & sMAPE is:14.10% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 15.44% & 0.86\n",
      "for 2021-01-19, MAE is:3.91 & sMAPE is:8.27% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :8.56 & 15.06% & 0.83\n",
      "for 2021-01-20, MAE is:5.87 & sMAPE is:14.02% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.43 & 15.01% & 0.81\n",
      "for 2021-01-21, MAE is:13.94 & sMAPE is:43.05% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :8.69 & 16.34% & 0.79\n",
      "for 2021-01-22, MAE is:8.36 & sMAPE is:15.75% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 16.32% & 0.77\n",
      "for 2021-01-23, MAE is:4.81 & sMAPE is:9.32% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 16.01% & 0.79\n",
      "for 2021-01-24, MAE is:4.08 & sMAPE is:8.13% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :8.32 & 15.68% & 0.80\n",
      "for 2021-01-25, MAE is:8.44 & sMAPE is:14.26% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 15.63% & 0.81\n",
      "for 2021-01-26, MAE is:10.08 & sMAPE is:18.43% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 15.73% & 0.81\n",
      "for 2021-01-27, MAE is:4.52 & sMAPE is:8.20% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 15.46% & 0.80\n",
      "for 2021-01-28, MAE is:4.68 & sMAPE is:8.39% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :8.13 & 15.20% & 0.78\n",
      "for 2021-01-29, MAE is:2.78 & sMAPE is:5.84% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 14.88% & 0.77\n",
      "for 2021-01-30, MAE is:3.89 & sMAPE is:7.81% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.81 & 14.64% & 0.78\n",
      "for 2021-01-31, MAE is:4.86 & sMAPE is:9.90% & rMAE is:2.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 14.49% & 0.83\n",
      "for 2021-02-01, MAE is:5.81 & sMAPE is:10.10% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 14.35% & 0.83\n",
      "for 2021-02-02, MAE is:8.35 & sMAPE is:14.68% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 14.36% & 0.84\n",
      "for 2021-02-03, MAE is:4.46 & sMAPE is:10.23% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 14.24% & 0.83\n",
      "for 2021-02-04, MAE is:12.57 & sMAPE is:26.38% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 14.59% & 0.86\n",
      "for 2021-02-05, MAE is:7.43 & sMAPE is:15.88% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 14.63% & 0.89\n",
      "for 2021-02-06, MAE is:7.12 & sMAPE is:15.96% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 14.66% & 0.89\n",
      "for 2021-02-07, MAE is:17.10 & sMAPE is:68.00% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 16.07% & 0.89\n",
      "for 2021-02-08, MAE is:6.84 & sMAPE is:25.19% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 16.30% & 0.88\n",
      "for 2021-02-09, MAE is:16.84 & sMAPE is:30.46% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 16.65% & 0.89\n",
      "for 2021-02-10, MAE is:19.04 & sMAPE is:28.08% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 16.93% & 0.89\n",
      "for 2021-02-11, MAE is:18.73 & sMAPE is:22.41% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.65 & 17.06% & 0.89\n",
      "for 2021-02-12, MAE is:9.47 & sMAPE is:15.87% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :8.67 & 17.03% & 0.89\n",
      "for 2021-02-13, MAE is:6.91 & sMAPE is:13.33% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.63 & 16.95% & 0.89\n",
      "for 2021-02-14, MAE is:3.56 & sMAPE is:7.67% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.52 & 16.74% & 0.87\n",
      "for 2021-02-15, MAE is:3.58 & sMAPE is:7.36% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.41 & 16.54% & 0.86\n",
      "for 2021-02-16, MAE is:5.30 & sMAPE is:10.21% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.34 & 16.41% & 0.85\n",
      "for 2021-02-17, MAE is:4.36 & sMAPE is:8.22% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 16.24% & 0.84\n",
      "for 2021-02-18, MAE is:12.87 & sMAPE is:22.84% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.35 & 16.37% & 0.83\n",
      "for 2021-02-19, MAE is:4.82 & sMAPE is:10.12% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.28 & 16.24% & 0.82\n",
      "for 2021-02-20, MAE is:5.86 & sMAPE is:17.11% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 16.26% & 0.81\n",
      "for 2021-02-21, MAE is:9.15 & sMAPE is:29.95% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 16.52% & 0.81\n",
      "for 2021-02-22, MAE is:9.17 & sMAPE is:19.75% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 16.59% & 0.83\n",
      "for 2021-02-23, MAE is:6.86 & sMAPE is:14.19% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 16.54% & 0.83\n",
      "for 2021-02-24, MAE is:7.99 & sMAPE is:23.29% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 16.66% & 0.83\n",
      "for 2021-02-25, MAE is:7.72 & sMAPE is:17.29% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :8.23 & 16.68% & 0.84\n",
      "for 2021-02-26, MAE is:6.05 & sMAPE is:13.16% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 16.61% & 0.85\n",
      "for 2021-02-27, MAE is:5.34 & sMAPE is:11.67% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 16.53% & 0.84\n",
      "for 2021-02-28, MAE is:5.95 & sMAPE is:14.38% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 16.49% & 0.84\n",
      "for 2021-03-01, MAE is:6.53 & sMAPE is:13.09% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.08 & 16.44% & 0.85\n",
      "for 2021-03-02, MAE is:10.45 & sMAPE is:20.45% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.12 & 16.50% & 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-03-03, MAE is:6.66 & sMAPE is:12.92% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :8.10 & 16.44% & 0.85\n",
      "for 2021-03-04, MAE is:8.76 & sMAPE is:17.28% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 16.46% & 0.85\n",
      "for 2021-03-05, MAE is:7.23 & sMAPE is:14.85% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 16.43% & 0.87\n",
      "for 2021-03-06, MAE is:3.24 & sMAPE is:7.04% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 16.29% & 0.87\n",
      "for 2021-03-07, MAE is:6.95 & sMAPE is:16.09% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 16.28% & 0.88\n",
      "for 2021-03-08, MAE is:12.26 & sMAPE is:19.87% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :8.07 & 16.34% & 0.88\n",
      "for 2021-03-09, MAE is:10.92 & sMAPE is:18.29% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 16.37% & 0.89\n",
      "for 2021-03-10, MAE is:11.93 & sMAPE is:23.47% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 16.47% & 0.90\n",
      "for 2021-03-11, MAE is:18.87 & sMAPE is:64.95% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.32 & 17.16% & 0.90\n",
      "for 2021-03-12, MAE is:21.25 & sMAPE is:51.46% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 17.64% & 0.91\n",
      "for 2021-03-13, MAE is:17.54 & sMAPE is:77.48% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :8.62 & 18.48% & 0.91\n",
      "for 2021-03-14, MAE is:16.16 & sMAPE is:63.09% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :8.73 & 19.09% & 0.91\n",
      "for 2021-03-15, MAE is:6.48 & sMAPE is:12.74% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.70 & 19.00% & 0.91\n",
      "for 2021-03-16, MAE is:5.72 & sMAPE is:10.26% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 18.88% & 0.91\n",
      "for 2021-03-17, MAE is:7.12 & sMAPE is:12.12% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 18.80% & 0.91\n",
      "for 2021-03-18, MAE is:10.03 & sMAPE is:16.70% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :8.65 & 18.77% & 0.90\n",
      "for 2021-03-19, MAE is:11.15 & sMAPE is:21.67% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.69 & 18.81% & 0.90\n",
      "for 2021-03-20, MAE is:6.66 & sMAPE is:13.63% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 18.74% & 0.89\n",
      "for 2021-03-21, MAE is:7.31 & sMAPE is:18.29% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 18.73% & 0.88\n",
      "for 2021-03-22, MAE is:11.40 & sMAPE is:19.94% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 18.75% & 0.89\n",
      "for 2021-03-23, MAE is:7.87 & sMAPE is:13.73% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :8.67 & 18.69% & 0.90\n",
      "for 2021-03-24, MAE is:9.30 & sMAPE is:16.93% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 18.67% & 0.91\n",
      "for 2021-03-25, MAE is:9.14 & sMAPE is:16.20% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 18.64% & 0.91\n",
      "for 2021-03-26, MAE is:8.37 & sMAPE is:17.47% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 18.62% & 0.92\n",
      "for 2021-03-27, MAE is:23.96 & sMAPE is:69.04% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.86 & 19.21% & 0.92\n",
      "for 2021-03-28, MAE is:15.81 & sMAPE is:66.83% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :8.94 & 19.76% & 0.91\n",
      "for 2021-03-29, MAE is:12.63 & sMAPE is:36.87% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.98 & 19.95% & 0.91\n",
      "for 2021-03-30, MAE is:7.93 & sMAPE is:14.90% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.97 & 19.89% & 0.91\n",
      "for 2021-03-31, MAE is:8.24 & sMAPE is:15.51% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :8.96 & 19.85% & 0.92\n",
      "for 2021-04-01, MAE is:6.24 & sMAPE is:12.34% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.93 & 19.76% & 0.91\n",
      "for 2021-04-02, MAE is:7.56 & sMAPE is:18.53% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.91 & 19.75% & 0.91\n",
      "for 2021-04-03, MAE is:7.94 & sMAPE is:23.56% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.90 & 19.79% & 0.91\n",
      "for 2021-04-04, MAE is:9.14 & sMAPE is:44.12% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :8.90 & 20.05% & 0.91\n",
      "for 2021-04-05, MAE is:22.22 & sMAPE is:97.39% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :9.04 & 20.86% & 0.91\n",
      "for 2021-04-06, MAE is:14.77 & sMAPE is:38.55% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :9.10 & 21.05% & 0.91\n",
      "for 2021-04-07, MAE is:11.04 & sMAPE is:22.70% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.12 & 21.07% & 0.91\n",
      "for 2021-04-08, MAE is:13.32 & sMAPE is:24.57% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :9.17 & 21.10% & 0.92\n",
      "for 2021-04-09, MAE is:15.40 & sMAPE is:29.50% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :9.23 & 21.19% & 0.92\n",
      "for 2021-04-10, MAE is:9.40 & sMAPE is:17.42% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :9.23 & 21.15% & 0.91\n",
      "for 2021-04-11, MAE is:7.30 & sMAPE is:15.65% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :9.21 & 21.09% & 0.91\n",
      "for 2021-04-12, MAE is:16.20 & sMAPE is:29.26% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :9.28 & 21.17% & 0.90\n",
      "for 2021-04-13, MAE is:7.64 & sMAPE is:13.61% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :9.27 & 21.10% & 0.90\n",
      "for 2021-04-14, MAE is:16.76 & sMAPE is:24.93% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :9.34 & 21.14% & 0.90\n",
      "for 2021-04-15, MAE is:11.20 & sMAPE is:16.71% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 21.10% & 0.90\n",
      "for 2021-04-16, MAE is:10.11 & sMAPE is:17.17% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 21.06% & 0.90\n",
      "for 2021-04-17, MAE is:8.39 & sMAPE is:14.20% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 20.99% & 0.90\n",
      "for 2021-04-18, MAE is:7.24 & sMAPE is:12.18% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :9.33 & 20.91% & 0.90\n",
      "for 2021-04-19, MAE is:12.54 & sMAPE is:16.67% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 20.87% & 0.90\n",
      "for 2021-04-20, MAE is:16.58 & sMAPE is:23.21% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :9.43 & 20.89% & 0.90\n",
      "for 2021-04-21, MAE is:16.15 & sMAPE is:27.21% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :9.49 & 20.95% & 0.90\n",
      "for 2021-04-22, MAE is:10.55 & sMAPE is:19.39% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :9.50 & 20.94% & 0.90\n",
      "for 2021-04-23, MAE is:10.76 & sMAPE is:17.56% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :9.51 & 20.91% & 0.91\n",
      "for 2021-04-24, MAE is:8.41 & sMAPE is:18.57% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :9.50 & 20.89% & 0.91\n",
      "for 2021-04-25, MAE is:16.05 & sMAPE is:55.19% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.56 & 21.19% & 0.91\n",
      "for 2021-04-26, MAE is:7.52 & sMAPE is:12.67% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :9.54 & 21.11% & 0.90\n",
      "for 2021-04-27, MAE is:11.66 & sMAPE is:19.20% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :9.56 & 21.10% & 0.90\n",
      "for 2021-04-28, MAE is:9.33 & sMAPE is:16.14% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :9.56 & 21.05% & 0.90\n",
      "for 2021-04-29, MAE is:7.56 & sMAPE is:13.44% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :9.54 & 20.99% & 0.90\n",
      "for 2021-04-30, MAE is:14.40 & sMAPE is:23.40% & rMAE is:2.29 ||| daily mean of MAE & sMAPE & rMAE till now are :9.58 & 21.01% & 0.92\n",
      "for 2021-05-01, MAE is:2.74 & sMAPE is:4.63% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.52 & 20.87% & 0.91\n",
      "for 2021-05-02, MAE is:9.49 & sMAPE is:32.78% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :9.52 & 20.97% & 0.91\n",
      "for 2021-05-03, MAE is:7.82 & sMAPE is:12.45% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :9.51 & 20.90% & 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-05-04, MAE is:17.53 & sMAPE is:63.91% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :9.57 & 21.25% & 0.91\n",
      "for 2021-05-05, MAE is:18.41 & sMAPE is:52.37% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :9.64 & 21.50% & 0.91\n",
      "for 2021-05-06, MAE is:15.63 & sMAPE is:25.64% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :9.69 & 21.53% & 0.91\n",
      "for 2021-05-07, MAE is:5.11 & sMAPE is:7.07% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :9.66 & 21.42% & 0.91\n",
      "for 2021-05-08, MAE is:8.36 & sMAPE is:16.50% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :9.65 & 21.38% & 0.92\n",
      "for 2021-05-09, MAE is:42.24 & sMAPE is:140.69% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :9.90 & 22.30% & 0.92\n",
      "for 2021-05-10, MAE is:20.00 & sMAPE is:40.53% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :9.98 & 22.44% & 0.93\n",
      "for 2021-05-11, MAE is:13.88 & sMAPE is:21.83% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.01 & 22.44% & 0.92\n",
      "for 2021-05-12, MAE is:5.09 & sMAPE is:7.58% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :9.97 & 22.33% & 0.92\n",
      "for 2021-05-13, MAE is:6.18 & sMAPE is:10.02% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :9.94 & 22.23% & 0.91\n",
      "for 2021-05-14, MAE is:8.52 & sMAPE is:12.38% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :9.93 & 22.16% & 0.92\n",
      "for 2021-05-15, MAE is:4.97 & sMAPE is:8.25% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :9.89 & 22.06% & 0.91\n",
      "for 2021-05-16, MAE is:18.03 & sMAPE is:52.91% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.95 & 22.28% & 0.91\n",
      "for 2021-05-17, MAE is:20.18 & sMAPE is:31.62% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :10.03 & 22.35% & 0.91\n",
      "for 2021-05-18, MAE is:6.80 & sMAPE is:9.23% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :10.00 & 22.26% & 0.92\n",
      "for 2021-05-19, MAE is:5.36 & sMAPE is:7.03% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :9.97 & 22.15% & 0.92\n",
      "for 2021-05-20, MAE is:6.96 & sMAPE is:9.94% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :9.95 & 22.06% & 0.92\n",
      "for 2021-05-21, MAE is:30.18 & sMAPE is:83.85% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :10.09 & 22.50% & 0.92\n",
      "for 2021-05-22, MAE is:27.03 & sMAPE is:105.88% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :10.21 & 23.09% & 0.92\n",
      "for 2021-05-23, MAE is:27.82 & sMAPE is:86.49% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 23.53% & 0.92\n",
      "for 2021-05-24, MAE is:14.13 & sMAPE is:36.63% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 23.62% & 0.92\n",
      "for 2021-05-25, MAE is:6.21 & sMAPE is:10.16% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 23.53% & 0.92\n",
      "for 2021-05-26, MAE is:9.15 & sMAPE is:13.99% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :10.32 & 23.46% & 0.92\n",
      "for 2021-05-27, MAE is:13.56 & sMAPE is:20.13% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 23.44% & 0.92\n",
      "for 2021-05-28, MAE is:10.89 & sMAPE is:15.95% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 23.39% & 0.92\n",
      "for 2021-05-29, MAE is:9.20 & sMAPE is:20.65% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :10.34 & 23.37% & 0.91\n",
      "for 2021-05-30, MAE is:17.59 & sMAPE is:60.88% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :10.39 & 23.62% & 0.92\n",
      "for 2021-05-31, MAE is:14.04 & sMAPE is:23.92% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :10.41 & 23.62% & 0.91\n",
      "for 2021-06-01, MAE is:5.82 & sMAPE is:8.40% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :10.38 & 23.52% & 0.91\n",
      "for 2021-06-02, MAE is:6.41 & sMAPE is:9.58% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 23.43% & 0.91\n",
      "for 2021-06-03, MAE is:9.13 & sMAPE is:13.58% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 23.37% & 0.92\n",
      "for 2021-06-04, MAE is:6.44 & sMAPE is:9.09% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 23.28% & 0.92\n",
      "for 2021-06-05, MAE is:5.65 & sMAPE is:7.88% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :10.30 & 23.18% & 0.92\n",
      "for 2021-06-06, MAE is:5.07 & sMAPE is:7.69% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :10.26 & 23.08% & 0.91\n",
      "for 2021-06-07, MAE is:9.25 & sMAPE is:12.54% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :10.26 & 23.01% & 0.91\n",
      "for 2021-06-08, MAE is:6.18 & sMAPE is:7.99% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :10.23 & 22.92% & 0.91\n",
      "for 2021-06-09, MAE is:8.21 & sMAPE is:11.16% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :10.22 & 22.84% & 0.91\n",
      "for 2021-06-10, MAE is:7.94 & sMAPE is:10.25% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :10.20 & 22.77% & 0.91\n",
      "for 2021-06-11, MAE is:8.32 & sMAPE is:11.05% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :10.19 & 22.69% & 0.91\n",
      "for 2021-06-12, MAE is:23.27 & sMAPE is:50.74% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :10.27 & 22.87% & 0.91\n",
      "for 2021-06-13, MAE is:37.82 & sMAPE is:85.82% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :10.44 & 23.25% & 0.91\n",
      "for 2021-06-14, MAE is:12.00 & sMAPE is:16.91% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 23.21% & 0.91\n",
      "for 2021-06-15, MAE is:7.03 & sMAPE is:8.74% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 23.12% & 0.92\n",
      "for 2021-06-16, MAE is:14.68 & sMAPE is:17.11% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 23.09% & 0.92\n",
      "for 2021-06-17, MAE is:12.83 & sMAPE is:16.36% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :10.47 & 23.05% & 0.93\n",
      "for 2021-06-18, MAE is:6.05 & sMAPE is:7.40% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :10.44 & 22.95% & 0.93\n",
      "for 2021-06-19, MAE is:4.59 & sMAPE is:6.45% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :10.41 & 22.86% & 0.92\n",
      "for 2021-06-20, MAE is:9.45 & sMAPE is:18.55% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :10.40 & 22.83% & 0.92\n",
      "for 2021-06-21, MAE is:11.38 & sMAPE is:15.73% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :10.41 & 22.79% & 0.92\n",
      "for 2021-06-22, MAE is:11.98 & sMAPE is:15.24% & rMAE is:2.88 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 22.75% & 0.94\n",
      "for 2021-06-23, MAE is:13.40 & sMAPE is:14.48% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 22.70% & 0.94\n",
      "for 2021-06-24, MAE is:11.86 & sMAPE is:12.99% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :10.44 & 22.64% & 0.94\n",
      "for 2021-06-25, MAE is:8.16 & sMAPE is:9.43% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 22.57% & 0.94\n",
      "for 2021-06-26, MAE is:8.03 & sMAPE is:10.19% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 22.50% & 0.94\n",
      "for 2021-06-27, MAE is:10.45 & sMAPE is:19.16% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 22.48% & 0.95\n",
      "for 2021-06-28, MAE is:13.50 & sMAPE is:16.30% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 22.45% & 0.95\n",
      "for 2021-06-29, MAE is:10.50 & sMAPE is:12.09% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 22.39% & 0.95\n",
      "for 2021-06-30, MAE is:7.27 & sMAPE is:8.02% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 22.31% & 0.95\n",
      "for 2021-07-01, MAE is:4.22 & sMAPE is:4.81% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :10.38 & 22.21% & 0.95\n",
      "for 2021-07-02, MAE is:8.22 & sMAPE is:8.82% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :10.37 & 22.14% & 0.95\n",
      "for 2021-07-03, MAE is:7.15 & sMAPE is:8.57% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 22.07% & 0.95\n",
      "for 2021-07-04, MAE is:5.37 & sMAPE is:6.29% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 21.98% & 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-07-05, MAE is:6.74 & sMAPE is:7.30% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :10.31 & 21.90% & 0.95\n",
      "for 2021-07-06, MAE is:12.90 & sMAPE is:17.66% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :10.32 & 21.88% & 0.95\n",
      "for 2021-07-07, MAE is:9.99 & sMAPE is:10.46% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :10.32 & 21.82% & 0.95\n",
      "for 2021-07-08, MAE is:6.42 & sMAPE is:6.47% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :10.30 & 21.74% & 0.94\n",
      "for 2021-07-09, MAE is:7.49 & sMAPE is:8.73% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 21.67% & 0.94\n",
      "for 2021-07-10, MAE is:4.73 & sMAPE is:5.72% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :10.25 & 21.59% & 0.95\n",
      "for 2021-07-11, MAE is:5.20 & sMAPE is:6.37% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :10.23 & 21.51% & 0.95\n",
      "for 2021-07-12, MAE is:6.45 & sMAPE is:6.96% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :10.21 & 21.43% & 0.95\n",
      "for 2021-07-13, MAE is:10.77 & sMAPE is:12.05% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :10.21 & 21.38% & 0.95\n",
      "for 2021-07-14, MAE is:5.52 & sMAPE is:6.40% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :10.19 & 21.31% & 0.95\n",
      "for 2021-07-15, MAE is:7.54 & sMAPE is:9.01% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :10.17 & 21.24% & 0.94\n",
      "for 2021-07-16, MAE is:7.87 & sMAPE is:9.57% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :10.16 & 21.18% & 0.95\n",
      "for 2021-07-17, MAE is:14.03 & sMAPE is:24.53% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :10.18 & 21.20% & 0.94\n",
      "for 2021-07-18, MAE is:30.06 & sMAPE is:67.05% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 21.43% & 0.94\n",
      "for 2021-07-19, MAE is:18.82 & sMAPE is:23.20% & rMAE is:3.09 ||| daily mean of MAE & sMAPE & rMAE till now are :10.32 & 21.44% & 0.96\n",
      "for 2021-07-20, MAE is:5.77 & sMAPE is:6.24% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :10.30 & 21.36% & 0.95\n",
      "for 2021-07-21, MAE is:9.51 & sMAPE is:10.65% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :10.30 & 21.31% & 0.95\n",
      "for 2021-07-22, MAE is:5.95 & sMAPE is:6.74% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 21.24% & 0.95\n",
      "for 2021-07-23, MAE is:4.93 & sMAPE is:5.55% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :10.25 & 21.16% & 0.95\n",
      "for 2021-07-24, MAE is:6.77 & sMAPE is:7.99% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :10.23 & 21.10% & 0.95\n",
      "for 2021-07-25, MAE is:17.67 & sMAPE is:26.99% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :10.27 & 21.13% & 0.95\n",
      "for 2021-07-26, MAE is:13.56 & sMAPE is:16.23% & rMAE is:2.94 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 21.10% & 0.96\n",
      "for 2021-07-27, MAE is:6.23 & sMAPE is:6.97% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :10.27 & 21.03% & 0.96\n",
      "for 2021-07-28, MAE is:11.72 & sMAPE is:14.44% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :10.27 & 21.00% & 0.96\n",
      "for 2021-07-29, MAE is:31.76 & sMAPE is:72.93% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :10.37 & 21.25% & 0.96\n",
      "for 2021-07-30, MAE is:31.16 & sMAPE is:36.80% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :10.47 & 21.32% & 0.96\n",
      "for 2021-07-31, MAE is:24.61 & sMAPE is:47.65% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :10.54 & 21.45% & 0.96\n",
      "for 2021-08-01, MAE is:21.17 & sMAPE is:27.31% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :10.59 & 21.48% & 0.96\n",
      "for 2021-08-02, MAE is:11.35 & sMAPE is:12.86% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :10.59 & 21.44% & 0.96\n",
      "for 2021-08-03, MAE is:10.80 & sMAPE is:11.33% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :10.59 & 21.39% & 0.96\n",
      "for 2021-08-04, MAE is:13.65 & sMAPE is:14.57% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :10.61 & 21.36% & 0.96\n",
      "for 2021-08-05, MAE is:13.13 & sMAPE is:14.09% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :10.62 & 21.32% & 0.96\n",
      "for 2021-08-06, MAE is:15.50 & sMAPE is:20.51% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :10.64 & 21.32% & 0.96\n",
      "for 2021-08-07, MAE is:5.97 & sMAPE is:9.91% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.62 & 21.27% & 0.96\n",
      "for 2021-08-08, MAE is:45.33 & sMAPE is:147.89% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :10.78 & 21.84% & 0.95\n",
      "for 2021-08-09, MAE is:21.76 & sMAPE is:35.19% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.83 & 21.90% & 0.95\n",
      "for 2021-08-10, MAE is:20.50 & sMAPE is:25.02% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :10.87 & 21.92% & 0.96\n",
      "for 2021-08-11, MAE is:15.41 & sMAPE is:15.58% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :10.89 & 21.89% & 0.96\n",
      "for 2021-08-12, MAE is:16.34 & sMAPE is:15.97% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :10.92 & 21.86% & 0.96\n",
      "for 2021-08-13, MAE is:8.60 & sMAPE is:9.01% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :10.91 & 21.81% & 0.96\n",
      "for 2021-08-14, MAE is:20.14 & sMAPE is:31.35% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :10.95 & 21.85% & 0.96\n",
      "for 2021-08-15, MAE is:13.53 & sMAPE is:25.08% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :10.96 & 21.86% & 0.96\n",
      "for 2021-08-16, MAE is:8.30 & sMAPE is:11.31% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :10.95 & 21.82% & 0.96\n",
      "for 2021-08-17, MAE is:19.29 & sMAPE is:22.08% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :10.98 & 21.82% & 0.96\n",
      "for 2021-08-18, MAE is:11.35 & sMAPE is:13.14% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :10.99 & 21.78% & 0.96\n",
      "for 2021-08-19, MAE is:20.33 & sMAPE is:19.75% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :11.03 & 21.77% & 0.96\n",
      "for 2021-08-20, MAE is:11.74 & sMAPE is:11.79% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :11.03 & 21.73% & 0.96\n",
      "for 2021-08-21, MAE is:7.28 & sMAPE is:8.17% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :11.01 & 21.67% & 0.96\n",
      "for 2021-08-22, MAE is:5.93 & sMAPE is:7.27% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.99 & 21.61% & 0.96\n",
      "for 2021-08-23, MAE is:13.57 & sMAPE is:15.35% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :11.00 & 21.58% & 0.95\n",
      "for 2021-08-24, MAE is:9.07 & sMAPE is:9.44% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :10.99 & 21.53% & 0.95\n",
      "for 2021-08-25, MAE is:14.92 & sMAPE is:14.47% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :11.01 & 21.50% & 0.95\n",
      "for 2021-08-26, MAE is:5.92 & sMAPE is:6.26% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :10.99 & 21.44% & 0.95\n",
      "for 2021-08-27, MAE is:5.50 & sMAPE is:5.71% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :10.97 & 21.37% & 0.95\n",
      "for 2021-08-28, MAE is:4.87 & sMAPE is:5.70% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :10.94 & 21.30% & 0.95\n",
      "for 2021-08-29, MAE is:3.90 & sMAPE is:4.72% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :10.91 & 21.24% & 0.95\n",
      "for 2021-08-30, MAE is:24.02 & sMAPE is:23.51% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :10.97 & 21.25% & 0.95\n",
      "for 2021-08-31, MAE is:7.40 & sMAPE is:6.59% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :10.95 & 21.19% & 0.95\n",
      "for 2021-09-01, MAE is:18.25 & sMAPE is:16.52% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :10.98 & 21.17% & 0.95\n",
      "for 2021-09-02, MAE is:22.38 & sMAPE is:18.98% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :11.03 & 21.16% & 0.95\n",
      "for 2021-09-03, MAE is:16.59 & sMAPE is:15.01% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :11.05 & 21.13% & 0.95\n",
      "for 2021-09-04, MAE is:9.80 & sMAPE is:9.15% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :11.04 & 21.08% & 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-09-05, MAE is:15.61 & sMAPE is:15.46% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :11.06 & 21.06% & 0.94\n",
      "for 2021-09-06, MAE is:18.24 & sMAPE is:13.61% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :11.09 & 21.03% & 0.94\n",
      "for 2021-09-07, MAE is:15.31 & sMAPE is:11.68% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 20.99% & 0.94\n",
      "for 2021-09-08, MAE is:15.22 & sMAPE is:12.39% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 20.96% & 0.94\n",
      "for 2021-09-09, MAE is:16.70 & sMAPE is:12.71% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :11.15 & 20.93% & 0.95\n",
      "for 2021-09-10, MAE is:20.02 & sMAPE is:15.31% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :11.18 & 20.90% & 0.95\n",
      "for 2021-09-11, MAE is:9.60 & sMAPE is:7.57% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :11.18 & 20.85% & 0.94\n",
      "for 2021-09-12, MAE is:27.40 & sMAPE is:21.68% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 20.86% & 0.94\n",
      "for 2021-09-13, MAE is:19.76 & sMAPE is:13.77% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :11.27 & 20.83% & 0.95\n",
      "for 2021-09-14, MAE is:17.93 & sMAPE is:12.11% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :11.30 & 20.79% & 0.95\n",
      "for 2021-09-15, MAE is:35.24 & sMAPE is:22.98% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :11.39 & 20.80% & 0.95\n",
      "for 2021-09-16, MAE is:17.26 & sMAPE is:10.79% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :11.41 & 20.76% & 0.94\n",
      "for 2021-09-17, MAE is:12.56 & sMAPE is:7.92% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :11.42 & 20.71% & 0.94\n",
      "for 2021-09-18, MAE is:16.55 & sMAPE is:11.69% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :11.44 & 20.68% & 0.94\n",
      "for 2021-09-19, MAE is:38.52 & sMAPE is:34.58% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :11.54 & 20.73% & 0.95\n",
      "for 2021-09-20, MAE is:25.22 & sMAPE is:16.83% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :11.59 & 20.72% & 0.95\n",
      "for 2021-09-21, MAE is:12.99 & sMAPE is:8.30% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :11.60 & 20.67% & 0.95\n",
      "for 2021-09-22, MAE is:24.88 & sMAPE is:15.77% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :11.65 & 20.65% & 0.95\n",
      "for 2021-09-23, MAE is:34.67 & sMAPE is:27.56% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :11.74 & 20.68% & 0.95\n",
      "for 2021-09-24, MAE is:30.61 & sMAPE is:20.73% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :11.81 & 20.68% & 0.95\n",
      "for 2021-09-25, MAE is:20.24 & sMAPE is:13.66% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :11.84 & 20.65% & 0.95\n",
      "for 2021-09-26, MAE is:23.03 & sMAPE is:18.03% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :11.88 & 20.64% & 0.95\n",
      "for 2021-09-27, MAE is:18.99 & sMAPE is:13.64% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :11.91 & 20.62% & 0.95\n",
      "for 2021-09-28, MAE is:25.14 & sMAPE is:16.40% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :11.95 & 20.60% & 0.95\n",
      "for 2021-09-29, MAE is:28.32 & sMAPE is:21.34% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :12.01 & 20.60% & 0.95\n",
      "for 2021-09-30, MAE is:38.71 & sMAPE is:28.53% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :12.11 & 20.63% & 0.95\n",
      "for 2021-10-01, MAE is:39.89 & sMAPE is:35.45% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :12.21 & 20.69% & 0.95\n",
      "for 2021-10-02, MAE is:38.87 & sMAPE is:34.23% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :12.31 & 20.74% & 0.95\n",
      "for 2021-10-03, MAE is:71.07 & sMAPE is:98.09% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :12.52 & 21.02% & 0.95\n",
      "for 2021-10-04, MAE is:44.92 & sMAPE is:30.93% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :12.64 & 21.05% & 0.96\n",
      "for 2021-10-05, MAE is:30.08 & sMAPE is:18.86% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :12.70 & 21.04% & 0.96\n",
      "for 2021-10-06, MAE is:70.54 & sMAPE is:43.87% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :12.91 & 21.13% & 0.96\n",
      "for 2021-10-07, MAE is:127.31 & sMAPE is:52.89% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :13.32 & 21.24% & 0.96\n",
      "for 2021-10-08, MAE is:41.14 & sMAPE is:19.86% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :13.42 & 21.23% & 0.96\n",
      "for 2021-10-09, MAE is:37.46 & sMAPE is:23.40% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :13.50 & 21.24% & 0.95\n",
      "for 2021-10-10, MAE is:35.19 & sMAPE is:24.05% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :13.58 & 21.25% & 0.95\n",
      "for 2021-10-11, MAE is:25.44 & sMAPE is:13.85% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :13.62 & 21.23% & 0.95\n",
      "for 2021-10-12, MAE is:23.42 & sMAPE is:13.33% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :13.66 & 21.20% & 0.95\n",
      "for 2021-10-13, MAE is:19.90 & sMAPE is:10.21% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :13.68 & 21.16% & 0.95\n",
      "for 2021-10-14, MAE is:29.43 & sMAPE is:16.25% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :13.73 & 21.14% & 0.95\n",
      "for 2021-10-15, MAE is:51.30 & sMAPE is:30.55% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :13.86 & 21.18% & 0.95\n",
      "for 2021-10-16, MAE is:26.58 & sMAPE is:14.02% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :13.91 & 21.15% & 0.95\n",
      "for 2021-10-17, MAE is:28.19 & sMAPE is:17.28% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :13.96 & 21.14% & 0.95\n",
      "for 2021-10-18, MAE is:31.56 & sMAPE is:17.10% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :14.02 & 21.12% & 0.95\n",
      "for 2021-10-19, MAE is:32.41 & sMAPE is:22.30% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :14.08 & 21.13% & 0.95\n",
      "for 2021-10-20, MAE is:61.38 & sMAPE is:67.88% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :14.24 & 21.29% & 0.95\n",
      "for 2021-10-21, MAE is:58.08 & sMAPE is:45.91% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :14.39 & 21.37% & 0.95\n",
      "for 2021-10-22, MAE is:36.01 & sMAPE is:25.45% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :14.46 & 21.38% & 0.95\n",
      "for 2021-10-23, MAE is:44.47 & sMAPE is:23.83% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :14.57 & 21.39% & 0.95\n",
      "for 2021-10-24, MAE is:46.79 & sMAPE is:34.61% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :14.67 & 21.44% & 0.95\n",
      "for 2021-10-25, MAE is:38.04 & sMAPE is:23.87% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :14.75 & 21.45% & 0.95\n",
      "for 2021-10-26, MAE is:26.15 & sMAPE is:14.46% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :14.79 & 21.42% & 0.95\n",
      "for 2021-10-27, MAE is:41.55 & sMAPE is:28.47% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :14.88 & 21.45% & 0.95\n",
      "for 2021-10-28, MAE is:30.46 & sMAPE is:18.09% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :14.93 & 21.43% & 0.95\n",
      "for 2021-10-29, MAE is:41.75 & sMAPE is:31.29% & rMAE is:2.88 ||| daily mean of MAE & sMAPE & rMAE till now are :15.02 & 21.47% & 0.96\n",
      "for 2021-10-30, MAE is:38.27 & sMAPE is:28.82% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :15.10 & 21.49% & 0.96\n",
      "for 2021-10-31, MAE is:69.00 & sMAPE is:65.54% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :15.27 & 21.64% & 0.96\n",
      "for 2021-11-01, MAE is:34.62 & sMAPE is:38.58% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :15.34 & 21.69% & 0.96\n",
      "for 2021-11-02, MAE is:76.17 & sMAPE is:43.76% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :15.54 & 21.76% & 0.96\n",
      "for 2021-11-03, MAE is:16.60 & sMAPE is:8.61% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :15.54 & 21.72% & 0.96\n",
      "for 2021-11-04, MAE is:13.17 & sMAPE is:7.67% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :15.53 & 21.68% & 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-11-05, MAE is:18.15 & sMAPE is:10.66% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :15.54 & 21.64% & 0.96\n",
      "for 2021-11-06, MAE is:25.44 & sMAPE is:18.29% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :15.57 & 21.63% & 0.95\n",
      "for 2021-11-07, MAE is:46.56 & sMAPE is:46.24% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :15.67 & 21.71% & 0.95\n",
      "for 2021-11-08, MAE is:83.44 & sMAPE is:49.58% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :15.89 & 21.80% & 0.95\n",
      "for 2021-11-09, MAE is:27.88 & sMAPE is:15.41% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :15.93 & 21.78% & 0.95\n",
      "for 2021-11-10, MAE is:39.70 & sMAPE is:23.06% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :16.00 & 21.78% & 0.95\n",
      "for 2021-11-11, MAE is:24.28 & sMAPE is:13.07% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :16.03 & 21.75% & 0.95\n",
      "for 2021-11-12, MAE is:21.46 & sMAPE is:13.51% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :16.05 & 21.73% & 0.95\n",
      "for 2021-11-13, MAE is:30.76 & sMAPE is:21.34% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :16.09 & 21.73% & 0.96\n",
      "for 2021-11-14, MAE is:31.40 & sMAPE is:19.79% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :16.14 & 21.72% & 0.95\n",
      "for 2021-11-15, MAE is:54.45 & sMAPE is:25.11% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :16.26 & 21.73% & 0.96\n",
      "for 2021-11-16, MAE is:38.68 & sMAPE is:17.06% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :16.33 & 21.72% & 0.96\n",
      "for 2021-11-17, MAE is:17.29 & sMAPE is:8.96% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :16.33 & 21.68% & 0.95\n",
      "for 2021-11-18, MAE is:32.87 & sMAPE is:16.53% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :16.39 & 21.66% & 0.95\n",
      "for 2021-11-19, MAE is:23.35 & sMAPE is:11.72% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :16.41 & 21.63% & 0.95\n",
      "for 2021-11-20, MAE is:25.84 & sMAPE is:14.02% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :16.44 & 21.61% & 0.95\n",
      "for 2021-11-21, MAE is:45.66 & sMAPE is:32.28% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :16.53 & 21.64% & 0.95\n",
      "for 2021-11-22, MAE is:32.99 & sMAPE is:17.13% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :16.58 & 21.63% & 0.95\n",
      "for 2021-11-23, MAE is:34.28 & sMAPE is:14.17% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :16.63 & 21.60% & 0.95\n",
      "for 2021-11-24, MAE is:58.30 & sMAPE is:22.36% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :16.76 & 21.60% & 0.95\n",
      "for 2021-11-25, MAE is:30.47 & sMAPE is:14.70% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :16.80 & 21.58% & 0.95\n",
      "for 2021-11-26, MAE is:25.11 & sMAPE is:12.58% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :16.83 & 21.56% & 0.95\n",
      "for 2021-11-27, MAE is:25.37 & sMAPE is:12.50% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :16.85 & 21.53% & 0.95\n",
      "for 2021-11-28, MAE is:17.81 & sMAPE is:9.10% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :16.85 & 21.49% & 0.95\n",
      "for 2021-11-29, MAE is:75.87 & sMAPE is:29.48% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :17.03 & 21.52% & 0.95\n",
      "for 2021-11-30, MAE is:46.71 & sMAPE is:28.12% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :17.12 & 21.54% & 0.95\n",
      "for 2021-12-01, MAE is:43.57 & sMAPE is:24.31% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :17.20 & 21.54% & 0.95\n",
      "for 2021-12-02, MAE is:46.64 & sMAPE is:23.38% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :17.29 & 21.55% & 0.95\n",
      "for 2021-12-03, MAE is:36.79 & sMAPE is:19.12% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :17.34 & 21.54% & 0.95\n",
      "for 2021-12-04, MAE is:32.27 & sMAPE is:16.90% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :17.39 & 21.53% & 0.95\n",
      "for 2021-12-05, MAE is:35.73 & sMAPE is:21.39% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :17.44 & 21.53% & 0.95\n",
      "for 2021-12-06, MAE is:73.98 & sMAPE is:30.81% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :17.61 & 21.55% & 0.95\n",
      "for 2021-12-07, MAE is:32.93 & sMAPE is:18.31% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :17.65 & 21.55% & 0.95\n",
      "for 2021-12-08, MAE is:35.49 & sMAPE is:20.32% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :17.71 & 21.54% & 0.96\n",
      "for 2021-12-09, MAE is:99.16 & sMAPE is:40.57% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :17.94 & 21.60% & 0.96\n",
      "for 2021-12-10, MAE is:30.09 & sMAPE is:13.34% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :17.98 & 21.57% & 0.96\n",
      "for 2021-12-11, MAE is:37.03 & sMAPE is:17.42% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :18.03 & 21.56% & 0.96\n",
      "for 2021-12-12, MAE is:56.96 & sMAPE is:32.18% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :18.15 & 21.59% & 0.96\n",
      "for 2021-12-13, MAE is:46.53 & sMAPE is:20.22% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :18.23 & 21.59% & 0.96\n",
      "for 2021-12-14, MAE is:84.95 & sMAPE is:32.40% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :18.42 & 21.62% & 0.96\n",
      "for 2021-12-15, MAE is:38.52 & sMAPE is:13.85% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :18.48 & 21.60% & 0.96\n",
      "for 2021-12-16, MAE is:85.10 & sMAPE is:27.08% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :18.67 & 21.61% & 0.96\n",
      "for 2021-12-17, MAE is:72.62 & sMAPE is:22.84% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :18.82 & 21.62% & 0.96\n",
      "for 2021-12-18, MAE is:28.24 & sMAPE is:9.87% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :18.85 & 21.58% & 0.96\n",
      "for 2021-12-19, MAE is:43.97 & sMAPE is:15.82% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :18.92 & 21.57% & 0.95\n",
      "for 2021-12-20, MAE is:93.77 & sMAPE is:28.42% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :19.13 & 21.59% & 0.95\n",
      "for 2021-12-21, MAE is:115.09 & sMAPE is:28.07% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :19.40 & 21.60% & 0.95\n",
      "for 2021-12-22, MAE is:57.97 & sMAPE is:14.19% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :19.51 & 21.58% & 0.95\n",
      "for 2021-12-23, MAE is:48.59 & sMAPE is:15.70% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :19.59 & 21.57% & 0.95\n",
      "for 2021-12-24, MAE is:51.98 & sMAPE is:19.48% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :19.68 & 21.56% & 0.95\n",
      "for 2021-12-25, MAE is:66.46 & sMAPE is:30.24% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :19.81 & 21.58% & 0.95\n",
      "for 2021-12-26, MAE is:35.16 & sMAPE is:18.26% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :19.85 & 21.58% & 0.95\n",
      "for 2021-12-27, MAE is:57.89 & sMAPE is:31.35% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :19.96 & 21.60% & 0.95\n",
      "for 2021-12-28, MAE is:90.27 & sMAPE is:62.58% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :20.15 & 21.72% & 0.95\n",
      "for 2021-12-29, MAE is:32.30 & sMAPE is:21.71% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :20.19 & 21.72% & 0.94\n",
      "for 2021-12-30, MAE is:66.58 & sMAPE is:58.68% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :20.32 & 21.82% & 0.94\n",
      "for 2021-12-31, MAE is:58.14 & sMAPE is:72.75% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :20.42 & 21.96% & 0.94\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:36:14,978]\u001b[0m A new study created in RDB with name: NL_2022\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:36:32,135]\u001b[0m Trial 3 finished with value: 67.8218688674124 and parameters: {'n_hidden': 3, 'learning_rate': 0.0736406768570719, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38181199441409197, 'dropout_rate_Layer_2': 0.17180355348103174, 'dropout_rate_Layer_3': 0.32539616335194976, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.015022217785617993, 'l1_Layer_2': 0.0002502743418216574, 'l1_Layer_3': 0.0003103235442652197, 'n_units_Layer_1': 210, 'n_units_Layer_2': 60, 'n_units_Layer_3': 160}. Best is trial 3 with value: 67.8218688674124.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 67.82 | sMAPE for Validation Set is: 77.66% | rMAE for Validation Set is: 2.46\n",
      "MAE for Test Set is: 207.55 | sMAPE for Test Set is: 137.00% | rMAE for Test Set is: 2.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:36:32,418]\u001b[0m Trial 0 pruned. Trial was pruned at epoch 16.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:36:40,343]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:36:43,128]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:36:46,963]\u001b[0m Trial 1 finished with value: 53.885767052022665 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014427980083451379, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3724923239256069, 'dropout_rate_Layer_2': 0.39715039199939317, 'dropout_rate_Layer_3': 0.33135890247171135, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0008859897813041205, 'l1_Layer_2': 1.5113657769410444e-05, 'l1_Layer_3': 0.0001393300084210668, 'n_units_Layer_1': 290, 'n_units_Layer_2': 95, 'n_units_Layer_3': 95}. Best is trial 1 with value: 53.885767052022665.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.89 | sMAPE for Validation Set is: 53.76% | rMAE for Validation Set is: 1.96\n",
      "MAE for Test Set is: 187.22 | sMAPE for Test Set is: 112.65% | rMAE for Test Set is: 2.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:36:50,386]\u001b[0m Trial 2 finished with value: 55.69773779914366 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010602897838953896, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3233672796459166, 'dropout_rate_Layer_2': 0.17690131159035094, 'dropout_rate_Layer_3': 0.38134023877821693, 'dropout_rate_Layer_4': 0.35333902987423527, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.279702194659611e-05, 'l1_Layer_2': 2.6373120097096398e-05, 'l1_Layer_3': 0.007222505765958641, 'l1_Layer_4': 0.0005764759523144506, 'n_units_Layer_1': 65, 'n_units_Layer_2': 160, 'n_units_Layer_3': 90, 'n_units_Layer_4': 210}. Best is trial 1 with value: 53.885767052022665.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.70 | sMAPE for Validation Set is: 56.45% | rMAE for Validation Set is: 2.02\n",
      "MAE for Test Set is: 191.44 | sMAPE for Test Set is: 117.52% | rMAE for Test Set is: 2.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:36:50,814]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:36:58,134]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:36:58,412]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:37:04,409]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:37:08,023]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:37:32,112]\u001b[0m Trial 14 finished with value: 46.81082388900512 and parameters: {'n_hidden': 3, 'learning_rate': 0.0632403621280732, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008554610139820973, 'dropout_rate_Layer_2': 0.3599913285055661, 'dropout_rate_Layer_3': 0.2658777832692391, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.9779622948513274e-05, 'l1_Layer_2': 0.00011259547722029887, 'l1_Layer_3': 4.727193269388365e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 250, 'n_units_Layer_3': 80}. Best is trial 14 with value: 46.81082388900512.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.81 | sMAPE for Validation Set is: 45.83% | rMAE for Validation Set is: 1.70\n",
      "MAE for Test Set is: 169.89 | sMAPE for Test Set is: 95.46% | rMAE for Test Set is: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:37:35,524]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:37:38,858]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:37:42,003]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:37:45,638]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:37:49,831]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:37:52,934]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:37:57,291]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:38:00,962]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:38:03,790]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:38:09,045]\u001b[0m Trial 12 finished with value: 19.828195113354333 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007456842585106627, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1860040546218496, 'dropout_rate_Layer_2': 0.005054057491798325, 'dropout_rate_Layer_3': 0.0970589602301331, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.330839854844693e-05, 'l1_Layer_2': 0.004914848807921683, 'l1_Layer_3': 0.011060668164694476, 'n_units_Layer_1': 75, 'n_units_Layer_2': 55, 'n_units_Layer_3': 110}. Best is trial 12 with value: 19.828195113354333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.83 | sMAPE for Validation Set is: 21.97% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 52.55 | sMAPE for Test Set is: 26.29% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:38:16,024]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:38:20,639]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:38:22,521]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:38:27,027]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:38:27,839]\u001b[0m Trial 23 finished with value: 53.153375489538604 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010975076077149488, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3527796604613896, 'dropout_rate_Layer_2': 0.14473833894382315, 'dropout_rate_Layer_3': 0.341312904661282, 'dropout_rate_Layer_4': 0.306702400014109, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.343075728953657e-05, 'l1_Layer_2': 0.0005057704197333756, 'l1_Layer_3': 0.00019719542381938556, 'l1_Layer_4': 0.0006977549521674075, 'n_units_Layer_1': 300, 'n_units_Layer_2': 80, 'n_units_Layer_3': 125, 'n_units_Layer_4': 205}. Best is trial 12 with value: 19.828195113354333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.15 | sMAPE for Validation Set is: 53.36% | rMAE for Validation Set is: 1.93\n",
      "MAE for Test Set is: 185.48 | sMAPE for Test Set is: 110.97% | rMAE for Test Set is: 2.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:38:32,395]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:38:37,490]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:38:41,153]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:38:41,523]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:38:47,353]\u001b[0m Trial 8 finished with value: 52.24070452482341 and parameters: {'n_hidden': 3, 'learning_rate': 0.005287622893552571, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1910516315162346, 'dropout_rate_Layer_2': 0.09006300363987174, 'dropout_rate_Layer_3': 0.03577691564314924, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017329005539365246, 'l1_Layer_2': 0.0069931568036796215, 'l1_Layer_3': 1.6967106796008715e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 90, 'n_units_Layer_3': 250}. Best is trial 12 with value: 19.828195113354333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.24 | sMAPE for Validation Set is: 50.97% | rMAE for Validation Set is: 1.90\n",
      "MAE for Test Set is: 184.86 | sMAPE for Test Set is: 109.98% | rMAE for Test Set is: 2.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:38:49,129]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:38:49,582]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:38:56,681]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:38:59,282]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:39:02,376]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:39:08,905]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.54 | sMAPE for Validation Set is: 42.13% | rMAE for Validation Set is: 1.62\n",
      "MAE for Test Set is: 165.23 | sMAPE for Test Set is: 91.72% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:39:10,831]\u001b[0m Trial 27 finished with value: 44.5393370188992 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009922882797428368, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3555954960383358, 'dropout_rate_Layer_2': 0.15133229726381614, 'dropout_rate_Layer_3': 0.33616662843493283, 'dropout_rate_Layer_4': 0.3051773927099105, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0781089358714186, 'l1_Layer_2': 0.0006108212863538184, 'l1_Layer_3': 0.0001392060208050414, 'l1_Layer_4': 0.000286270488229425, 'n_units_Layer_1': 300, 'n_units_Layer_2': 80, 'n_units_Layer_3': 125, 'n_units_Layer_4': 195}. Best is trial 12 with value: 19.828195113354333.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:39:15,550]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:39:19,069]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:39:23,810]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:39:24,320]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:39:28,825]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:39:29,924]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:39:35,158]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:39:35,269]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:39:42,058]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:39:44,835]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:39:52,892]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.06 | sMAPE for Validation Set is: 42.24% | rMAE for Validation Set is: 1.64\n",
      "MAE for Test Set is: 167.98 | sMAPE for Test Set is: 94.01% | rMAE for Test Set is: 2.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:39:52,988]\u001b[0m Trial 48 finished with value: 45.06475567610792 and parameters: {'n_hidden': 4, 'learning_rate': 0.003185098626776678, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34708276916148245, 'dropout_rate_Layer_2': 0.04844529901910341, 'dropout_rate_Layer_3': 0.16253992798731862, 'dropout_rate_Layer_4': 0.3456249582719597, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.035546114428196794, 'l1_Layer_2': 0.0006112900118350857, 'l1_Layer_3': 0.0013312091548872394, 'l1_Layer_4': 0.0001752160835075828, 'n_units_Layer_1': 300, 'n_units_Layer_2': 50, 'n_units_Layer_3': 75, 'n_units_Layer_4': 240}. Best is trial 12 with value: 19.828195113354333.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:39:58,193]\u001b[0m Trial 49 finished with value: 19.290137251102724 and parameters: {'n_hidden': 3, 'learning_rate': 0.008450012579661772, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38825560080772775, 'dropout_rate_Layer_2': 0.13247162366201898, 'dropout_rate_Layer_3': 0.29971909024996574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0027057770099916433, 'l1_Layer_2': 0.004806556805290754, 'l1_Layer_3': 9.824283685900053e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 50, 'n_units_Layer_3': 250}. Best is trial 49 with value: 19.290137251102724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.29 | sMAPE for Validation Set is: 20.98% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 50.67 | sMAPE for Test Set is: 25.39% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:40:01,220]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:40:01,797]\u001b[0m Trial 51 finished with value: 42.054883529540554 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015994699063696844, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.290520173564532, 'dropout_rate_Layer_2': 0.14959367225694079, 'dropout_rate_Layer_3': 0.2769946226320567, 'dropout_rate_Layer_4': 0.35570268926659976, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.043869324847139096, 'l1_Layer_2': 0.0005851505749673089, 'l1_Layer_3': 2.2935601762028336e-05, 'l1_Layer_4': 2.4114477423330927e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 170, 'n_units_Layer_3': 185, 'n_units_Layer_4': 235}. Best is trial 49 with value: 19.290137251102724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.05 | sMAPE for Validation Set is: 38.79% | rMAE for Validation Set is: 1.53\n",
      "MAE for Test Set is: 161.78 | sMAPE for Test Set is: 88.42% | rMAE for Test Set is: 2.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:40:03,421]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:40:08,497]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:40:10,648]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:40:14,079]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:40:17,655]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:40:17,802]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:40:29,220]\u001b[0m Trial 61 finished with value: 31.7172733903242 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012636434318222772, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3651891039412647, 'dropout_rate_Layer_2': 0.033928852474476426, 'dropout_rate_Layer_3': 0.1731130464699272, 'dropout_rate_Layer_4': 0.35831294411155895, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04852312050822707, 'l1_Layer_2': 0.0008892382957528523, 'l1_Layer_3': 1.635165500429185e-05, 'l1_Layer_4': 0.00016514516048810366, 'n_units_Layer_1': 250, 'n_units_Layer_2': 50, 'n_units_Layer_3': 185, 'n_units_Layer_4': 230}. Best is trial 49 with value: 19.290137251102724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.72 | sMAPE for Validation Set is: 29.42% | rMAE for Validation Set is: 1.15\n",
      "MAE for Test Set is: 130.45 | sMAPE for Test Set is: 63.94% | rMAE for Test Set is: 1.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:40:34,015]\u001b[0m Trial 57 finished with value: 47.12999645939087 and parameters: {'n_hidden': 4, 'learning_rate': 0.001506860504502496, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28361855903139477, 'dropout_rate_Layer_2': 0.14788834239101298, 'dropout_rate_Layer_3': 0.2919847933579878, 'dropout_rate_Layer_4': 0.3597617854726443, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.046312642410246185, 'l1_Layer_2': 0.0009785827878496065, 'l1_Layer_3': 1.892195696567316e-05, 'l1_Layer_4': 1.162201892397003e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 50, 'n_units_Layer_3': 180, 'n_units_Layer_4': 230}. Best is trial 49 with value: 19.290137251102724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.13 | sMAPE for Validation Set is: 44.76% | rMAE for Validation Set is: 1.71\n",
      "MAE for Test Set is: 171.07 | sMAPE for Test Set is: 96.78% | rMAE for Test Set is: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:40:36,496]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:40:37,350]\u001b[0m Trial 63 finished with value: 37.984450725736565 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013324878096071522, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3664933193562681, 'dropout_rate_Layer_2': 0.04473534914962809, 'dropout_rate_Layer_3': 0.28738221546868215, 'dropout_rate_Layer_4': 0.35820085723268674, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04704642622988858, 'l1_Layer_2': 0.0008652587220652912, 'l1_Layer_3': 1.0502994945265724e-05, 'l1_Layer_4': 1.0443464296595609e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 50, 'n_units_Layer_3': 175, 'n_units_Layer_4': 235}. Best is trial 49 with value: 19.290137251102724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.98 | sMAPE for Validation Set is: 35.00% | rMAE for Validation Set is: 1.38\n",
      "MAE for Test Set is: 149.22 | sMAPE for Test Set is: 78.01% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:40:46,249]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:40:50,430]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:40:50,978]\u001b[0m Trial 64 finished with value: 18.987066364679034 and parameters: {'n_hidden': 3, 'learning_rate': 0.006294553511114129, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2701317283120081, 'dropout_rate_Layer_2': 0.08028663159511218, 'dropout_rate_Layer_3': 0.22879663160738103, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.465805169226133e-05, 'l1_Layer_2': 0.010250045239016159, 'l1_Layer_3': 5.218201721388832e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 135, 'n_units_Layer_3': 265}. Best is trial 64 with value: 18.987066364679034.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:40:51,013]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.99 | sMAPE for Validation Set is: 20.21% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 51.28 | sMAPE for Test Set is: 25.27% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:40:58,175]\u001b[0m Trial 67 finished with value: 22.081186298959967 and parameters: {'n_hidden': 4, 'learning_rate': 0.001321901127470813, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3700358921686999, 'dropout_rate_Layer_2': 0.022516962293356025, 'dropout_rate_Layer_3': 0.24530462958354757, 'dropout_rate_Layer_4': 0.3982858719640595, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.06269927376433002, 'l1_Layer_2': 0.00024717652969998883, 'l1_Layer_3': 1.078906022990926e-05, 'l1_Layer_4': 2.6920185875091787e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 235, 'n_units_Layer_4': 280}. Best is trial 64 with value: 18.987066364679034.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.08 | sMAPE for Validation Set is: 23.67% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 62.07 | sMAPE for Test Set is: 30.34% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:41:02,184]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:02,945]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:06,825]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:06,870]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:09,876]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:09,954]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:13,362]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:15,893]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:20,676]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:23,871]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:24,660]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:30,636]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:30,904]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:37,055]\u001b[0m Trial 78 finished with value: 20.25738736381744 and parameters: {'n_hidden': 4, 'learning_rate': 0.001417498688385685, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31797911417211816, 'dropout_rate_Layer_2': 0.02046811159319765, 'dropout_rate_Layer_3': 0.23044420875995722, 'dropout_rate_Layer_4': 0.3605901839165528, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009906156407974799, 'l1_Layer_2': 0.0003336131799825273, 'l1_Layer_3': 2.2827022891396227e-05, 'l1_Layer_4': 1.842788010831519e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 260, 'n_units_Layer_3': 230, 'n_units_Layer_4': 280}. Best is trial 64 with value: 18.987066364679034.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.26 | sMAPE for Validation Set is: 22.50% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 53.20 | sMAPE for Test Set is: 26.71% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:41:37,588]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:37,853]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:45,778]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:50,470]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:50,655]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:41:58,418]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:42:01,406]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:42:07,572]\u001b[0m Trial 87 finished with value: 19.290553796073798 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019447309923832333, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06756673768363694, 'dropout_rate_Layer_2': 0.05134228536753216, 'dropout_rate_Layer_3': 0.26228127413189506, 'dropout_rate_Layer_4': 0.39986143229393206, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011378396222062428, 'l1_Layer_2': 0.00028960137194517454, 'l1_Layer_3': 1.0107753655072056e-05, 'l1_Layer_4': 3.543774094181291e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 270, 'n_units_Layer_3': 200, 'n_units_Layer_4': 265}. Best is trial 64 with value: 18.987066364679034.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.29 | sMAPE for Validation Set is: 20.60% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 51.33 | sMAPE for Test Set is: 25.37% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:42:11,879]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:42:12,117]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:42:17,580]\u001b[0m Trial 86 finished with value: 18.1669046512618 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034100442111234443, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013854090058977331, 'dropout_rate_Layer_2': 0.3451419056693532, 'dropout_rate_Layer_3': 0.1947469060344009, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002452629388141963, 'l1_Layer_2': 5.348304067020415e-05, 'l1_Layer_3': 0.0019170921640696045, 'n_units_Layer_1': 145, 'n_units_Layer_2': 90, 'n_units_Layer_3': 80}. Best is trial 86 with value: 18.1669046512618.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.17 | sMAPE for Validation Set is: 19.86% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 46.69 | sMAPE for Test Set is: 23.88% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:42:22,100]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:42:27,389]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:42:33,692]\u001b[0m Trial 97 finished with value: 18.805801715229254 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037330759028969267, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07790759028794679, 'dropout_rate_Layer_2': 0.01742677184086491, 'dropout_rate_Layer_3': 0.05674971892948194, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012904168523516139, 'l1_Layer_2': 0.00026498592219973874, 'l1_Layer_3': 5.106728108893096e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 300, 'n_units_Layer_3': 250}. Best is trial 86 with value: 18.1669046512618.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.81 | sMAPE for Validation Set is: 20.20% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 51.48 | sMAPE for Test Set is: 25.33% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:42:34,718]\u001b[0m Trial 95 finished with value: 18.272564016951307 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020349426458096923, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01644531257939505, 'dropout_rate_Layer_2': 0.01867364228395027, 'dropout_rate_Layer_3': 0.028579072004066203, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012763841687183884, 'l1_Layer_2': 7.022764913234959e-05, 'l1_Layer_3': 5.644956708842535e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 300, 'n_units_Layer_3': 255}. Best is trial 86 with value: 18.1669046512618.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.27 | sMAPE for Validation Set is: 19.65% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 49.16 | sMAPE for Test Set is: 24.60% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:42:37,354]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:42:38,791]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.60 | sMAPE for Validation Set is: 20.10% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 51.90 | sMAPE for Test Set is: 25.38% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:42:41,402]\u001b[0m Trial 98 finished with value: 18.601246563682345 and parameters: {'n_hidden': 3, 'learning_rate': 0.004129658879561154, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08577130403967935, 'dropout_rate_Layer_2': 0.017233681774949706, 'dropout_rate_Layer_3': 0.009194104970661698, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001953474946136628, 'l1_Layer_2': 0.0002785740882935366, 'l1_Layer_3': 4.4114087098161696e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 280, 'n_units_Layer_3': 255}. Best is trial 86 with value: 18.1669046512618.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:42:45,361]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:42:47,312]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:42:49,751]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:42:51,457]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:42:56,494]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:43:02,188]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:43:05,645]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:43:10,519]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:43:15,360]\u001b[0m Trial 108 finished with value: 18.516393341085767 and parameters: {'n_hidden': 3, 'learning_rate': 0.003504537643727897, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11321130854453812, 'dropout_rate_Layer_2': 0.020266387067773423, 'dropout_rate_Layer_3': 0.005205647398030662, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006460267268661034, 'l1_Layer_2': 2.7757108474090105e-05, 'l1_Layer_3': 2.599912717057082e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 250, 'n_units_Layer_3': 285}. Best is trial 86 with value: 18.1669046512618.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.52 | sMAPE for Validation Set is: 20.02% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 51.64 | sMAPE for Test Set is: 25.40% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:43:15,672]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:43:16,026]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:43:16,608]\u001b[0m Trial 106 finished with value: 18.17827095979197 and parameters: {'n_hidden': 3, 'learning_rate': 0.010424219612716576, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03182790658430304, 'dropout_rate_Layer_2': 0.004457827820824609, 'dropout_rate_Layer_3': 0.037986250119415296, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00688922021353626, 'l1_Layer_2': 2.2282655199213533e-05, 'l1_Layer_3': 2.6964394143509647e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 300, 'n_units_Layer_3': 290}. Best is trial 86 with value: 18.1669046512618.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.18 | sMAPE for Validation Set is: 19.72% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 50.98 | sMAPE for Test Set is: 25.32% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:43:27,208]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:43:28,613]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:43:34,710]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:43:35,494]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:43:40,513]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:43:41,239]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:43:49,266]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:43:49,596]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.87 | sMAPE for Validation Set is: 19.31% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 46.84 | sMAPE for Test Set is: 23.79% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:43:52,710]\u001b[0m Trial 116 finished with value: 17.871539245442083 and parameters: {'n_hidden': 3, 'learning_rate': 0.003346837146027114, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028871478071313905, 'dropout_rate_Layer_2': 0.07985999211394773, 'dropout_rate_Layer_3': 0.034442800969438525, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003798781444542269, 'l1_Layer_2': 1.446834636353784e-05, 'l1_Layer_3': 0.00012832290345874718, 'n_units_Layer_1': 120, 'n_units_Layer_2': 275, 'n_units_Layer_3': 300}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:43:59,868]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:44:00,290]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:44:05,679]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:44:07,142]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:44:10,248]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:44:13,108]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:44:14,861]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:44:18,343]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:44:22,929]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:44:26,590]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:44:31,477]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:44:32,703]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:44:37,743]\u001b[0m Trial 132 finished with value: 19.15611016747672 and parameters: {'n_hidden': 3, 'learning_rate': 0.019335068507733554, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14613551986449472, 'dropout_rate_Layer_2': 0.05954770950702603, 'dropout_rate_Layer_3': 0.2629086382309456, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023428638891067263, 'l1_Layer_2': 0.008910504633482046, 'l1_Layer_3': 1.734914330838459e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 90, 'n_units_Layer_3': 255}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.16 | sMAPE for Validation Set is: 20.69% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 51.03 | sMAPE for Test Set is: 25.43% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:44:38,315]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:44:45,378]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:44:46,175]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:44:51,687]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:44:57,392]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:45:00,879]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:45:01,040]\u001b[0m Trial 141 finished with value: 19.607222639013713 and parameters: {'n_hidden': 3, 'learning_rate': 0.01007513783671209, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15733869596629296, 'dropout_rate_Layer_2': 0.3880562408464043, 'dropout_rate_Layer_3': 0.19074491503282792, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000475792400542285, 'l1_Layer_2': 0.00018024803929217337, 'l1_Layer_3': 3.524068325109478e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 100, 'n_units_Layer_3': 285}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:45:01,074]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.61 | sMAPE for Validation Set is: 22.49% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 52.33 | sMAPE for Test Set is: 25.57% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:45:11,575]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:45:16,462]\u001b[0m Trial 144 finished with value: 19.915745225503237 and parameters: {'n_hidden': 3, 'learning_rate': 0.005285779828978733, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0831775453747844, 'dropout_rate_Layer_2': 0.057507806538636, 'dropout_rate_Layer_3': 0.010118068733425259, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.7891885261201624e-05, 'l1_Layer_2': 0.0001373058978092364, 'l1_Layer_3': 1.4123394904194913e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 115, 'n_units_Layer_3': 285}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.92 | sMAPE for Validation Set is: 21.57% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 57.56 | sMAPE for Test Set is: 27.13% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:45:18,397]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:45:19,547]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:45:26,594]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.85 | sMAPE for Validation Set is: 20.05% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 51.87 | sMAPE for Test Set is: 25.50% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:45:29,083]\u001b[0m Trial 146 finished with value: 18.852826192232488 and parameters: {'n_hidden': 3, 'learning_rate': 0.004521234462904099, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04647347758955071, 'dropout_rate_Layer_2': 0.006901475176242613, 'dropout_rate_Layer_3': 0.02066944674889512, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009515701077477708, 'l1_Layer_2': 0.0004537854123595624, 'l1_Layer_3': 2.4474435351855416e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 260, 'n_units_Layer_3': 245}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:45:32,430]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:45:36,763]\u001b[0m Trial 148 finished with value: 19.735883274078372 and parameters: {'n_hidden': 3, 'learning_rate': 0.024508537384532864, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07936603066628871, 'dropout_rate_Layer_2': 0.05415445945557634, 'dropout_rate_Layer_3': 0.13839187950846105, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.2869172894902124e-05, 'l1_Layer_2': 0.0001509165070165927, 'l1_Layer_3': 1.2931974788117525e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 120, 'n_units_Layer_3': 285}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.74 | sMAPE for Validation Set is: 21.83% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 54.17 | sMAPE for Test Set is: 26.02% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:45:40,169]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:45:45,063]\u001b[0m Trial 152 finished with value: 19.534160766557164 and parameters: {'n_hidden': 3, 'learning_rate': 0.024199139214990048, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06657389915113529, 'dropout_rate_Layer_2': 0.07438589032649323, 'dropout_rate_Layer_3': 0.00980878016888712, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.368401765684448e-05, 'l1_Layer_2': 0.0001458014487780903, 'l1_Layer_3': 2.8749657456674516e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 120, 'n_units_Layer_3': 285}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:45:45,107]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.53 | sMAPE for Validation Set is: 21.80% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 56.96 | sMAPE for Test Set is: 26.60% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:45:46,429]\u001b[0m Trial 149 finished with value: 18.53542733470377 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019158072651948336, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.045983960202279274, 'dropout_rate_Layer_2': 0.0255110551629598, 'dropout_rate_Layer_3': 0.046621191507441775, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014778937375800978, 'l1_Layer_2': 4.818564242714578e-05, 'l1_Layer_3': 6.03547605335536e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 290, 'n_units_Layer_3': 245}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.54 | sMAPE for Validation Set is: 19.97% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 49.97 | sMAPE for Test Set is: 24.88% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:45:52,663]\u001b[0m Trial 154 finished with value: 19.504645277827812 and parameters: {'n_hidden': 3, 'learning_rate': 0.006484195394917481, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07740876120412513, 'dropout_rate_Layer_2': 0.07168438661642593, 'dropout_rate_Layer_3': 0.0001745973181704174, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.626653075416358e-05, 'l1_Layer_2': 0.00013956255626075854, 'l1_Layer_3': 1.469350246124606e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 125, 'n_units_Layer_3': 285}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.50 | sMAPE for Validation Set is: 21.38% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 50.73 | sMAPE for Test Set is: 25.19% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:45:53,323]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:45:58,081]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:46:00,633]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:46:05,310]\u001b[0m Trial 156 finished with value: 20.0750281773466 and parameters: {'n_hidden': 3, 'learning_rate': 0.02331245653658412, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06987135189264432, 'dropout_rate_Layer_2': 0.07434610439693551, 'dropout_rate_Layer_3': 0.15751499177252432, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.449442955192416e-05, 'l1_Layer_2': 4.4645529777462774e-05, 'l1_Layer_3': 2.658854219544665e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 120, 'n_units_Layer_3': 285}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.08 | sMAPE for Validation Set is: 22.16% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 54.67 | sMAPE for Test Set is: 26.11% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:46:07,076]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:46:08,854]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:46:11,592]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:46:15,612]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:46:19,935]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:46:21,426]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:46:27,145]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:46:27,418]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:46:29,293]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:46:34,635]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:46:39,512]\u001b[0m Trial 163 finished with value: 18.4004424288375 and parameters: {'n_hidden': 3, 'learning_rate': 0.002671486717297318, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08474015137764809, 'dropout_rate_Layer_2': 0.04161444428733, 'dropout_rate_Layer_3': 0.03490211464790533, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002387592375338779, 'l1_Layer_2': 1.7831317195113114e-05, 'l1_Layer_3': 5.039532391084161e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 270, 'n_units_Layer_3': 250}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.40 | sMAPE for Validation Set is: 19.92% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 50.66 | sMAPE for Test Set is: 25.01% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:46:43,149]\u001b[0m Trial 171 finished with value: 19.664657777043917 and parameters: {'n_hidden': 3, 'learning_rate': 0.0062903506161211134, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04045162134129514, 'dropout_rate_Layer_2': 0.023919588538588818, 'dropout_rate_Layer_3': 0.016522362389062302, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.747386975595833e-05, 'l1_Layer_2': 0.0001082917946379829, 'l1_Layer_3': 3.237444621872526e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 95, 'n_units_Layer_3': 270}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.66 | sMAPE for Validation Set is: 21.09% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 55.90 | sMAPE for Test Set is: 26.66% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:46:45,441]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:46:48,612]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:46:49,284]\u001b[0m Trial 172 finished with value: 20.207475454998196 and parameters: {'n_hidden': 3, 'learning_rate': 0.0061231543626036975, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023557122931241112, 'dropout_rate_Layer_2': 0.020547553228437765, 'dropout_rate_Layer_3': 0.0013407925936903848, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.3141383739251855e-05, 'l1_Layer_2': 0.0002940800870152406, 'l1_Layer_3': 2.914725324309655e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 165, 'n_units_Layer_3': 270}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.21 | sMAPE for Validation Set is: 22.11% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 55.51 | sMAPE for Test Set is: 26.42% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:46:51,734]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:46:55,790]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:47:01,777]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:47:02,132]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:47:09,035]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:47:10,368]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:47:16,620]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:47:20,186]\u001b[0m Trial 178 finished with value: 18.491746185718302 and parameters: {'n_hidden': 3, 'learning_rate': 0.002893603863613614, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07463959284092474, 'dropout_rate_Layer_2': 0.02504502927087667, 'dropout_rate_Layer_3': 0.06472074548340752, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0033676685180712377, 'l1_Layer_2': 3.0641865902492876e-05, 'l1_Layer_3': 6.344119901321107e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 275, 'n_units_Layer_3': 155}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.49 | sMAPE for Validation Set is: 19.85% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 51.75 | sMAPE for Test Set is: 25.36% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:47:22,196]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:47:25,751]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:47:28,818]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:47:31,570]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:47:34,146]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:47:36,287]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:47:38,284]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:47:41,149]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:47:46,261]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:47:46,294]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:47:53,294]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:47:53,643]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:48:00,048]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:48:00,595]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:48:07,722]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:48:11,535]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:48:12,338]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:48:18,274]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:48:22,399]\u001b[0m Trial 183 finished with value: 17.984835172756203 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011533621476793622, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027514180872837742, 'dropout_rate_Layer_2': 0.18554508582495602, 'dropout_rate_Layer_3': 0.019960342591824574, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005637589604715472, 'l1_Layer_2': 0.00013954795636005081, 'l1_Layer_3': 1.9889317857043128e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 275, 'n_units_Layer_3': 220}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.98 | sMAPE for Validation Set is: 19.67% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 47.43 | sMAPE for Test Set is: 24.03% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:48:24,468]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:48:30,396]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:48:32,415]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:48:36,578]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:48:41,710]\u001b[0m Trial 194 finished with value: 28.130473237108692 and parameters: {'n_hidden': 3, 'learning_rate': 0.001927527058444188, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3036833306042384, 'dropout_rate_Layer_2': 0.37518468238938746, 'dropout_rate_Layer_3': 0.39759995850105806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00046013752936651775, 'l1_Layer_2': 0.09493865411014336, 'l1_Layer_3': 0.09518909134159288, 'n_units_Layer_1': 65, 'n_units_Layer_2': 50, 'n_units_Layer_3': 160}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.13 | sMAPE for Validation Set is: 27.97% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 87.83 | sMAPE for Test Set is: 42.54% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:48:46,139]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:48:51,039]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:48:51,544]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:48:58,252]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:49:08,154]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:49:09,655]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:49:16,080]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:49:20,361]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:49:30,010]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:49:34,240]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:49:38,318]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:49:43,329]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:49:47,388]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:49:51,161]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:49:53,972]\u001b[0m Trial 206 finished with value: 20.949080454171035 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005454088322251694, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32301192163657855, 'dropout_rate_Layer_2': 0.362139809789421, 'dropout_rate_Layer_3': 0.38561475611158863, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00043747850412313493, 'l1_Layer_2': 0.0584308629051618, 'l1_Layer_3': 0.06368796620176369, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 160}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.95 | sMAPE for Validation Set is: 22.60% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 59.26 | sMAPE for Test Set is: 28.91% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:49:56,024]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:49:59,793]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:03,768]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:04,293]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:10,444]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:10,503]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:10,868]\u001b[0m Trial 209 finished with value: 20.763580823557337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005547643488160423, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10291295236340287, 'dropout_rate_Layer_2': 0.3413830713836949, 'dropout_rate_Layer_3': 0.3772055072565924, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00041276247354266006, 'l1_Layer_2': 0.045787498720693764, 'l1_Layer_3': 0.0976105476097131, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 165}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.76 | sMAPE for Validation Set is: 21.84% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 55.86 | sMAPE for Test Set is: 27.39% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:50:19,549]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:21,415]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:22,136]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:24,720]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:29,030]\u001b[0m Trial 217 finished with value: 21.685917399608886 and parameters: {'n_hidden': 3, 'learning_rate': 0.000510311652155511, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10147502520436147, 'dropout_rate_Layer_2': 0.36512248117833646, 'dropout_rate_Layer_3': 0.0014975298853373564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000285505590135781, 'l1_Layer_2': 0.09526620250776566, 'l1_Layer_3': 0.0993318094158846, 'n_units_Layer_1': 120, 'n_units_Layer_2': 50, 'n_units_Layer_3': 170}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.69 | sMAPE for Validation Set is: 23.25% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 64.49 | sMAPE for Test Set is: 30.73% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:50:30,984]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:31,375]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:32,402]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:38,855]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:43,018]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:43,653]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:44,574]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:45,208]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:53,117]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:53,352]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:54,339]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:50:59,699]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:01,838]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:03,381]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:06,189]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:09,907]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:13,525]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:19,026]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:19,095]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:20,620]\u001b[0m Trial 244 finished with value: 18.635653718543452 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034594250705960133, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07116954143652526, 'dropout_rate_Layer_2': 0.013207693962683509, 'dropout_rate_Layer_3': 0.27204213947186046, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009573582386374235, 'l1_Layer_2': 0.000283812759367844, 'l1_Layer_3': 8.715528067635152e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 75, 'n_units_Layer_3': 115}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.64 | sMAPE for Validation Set is: 19.76% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 47.34 | sMAPE for Test Set is: 24.09% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:51:26,967]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:28,336]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:32,504]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:32,943]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:36,832]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:42,059]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:42,210]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:43,295]\u001b[0m Trial 252 finished with value: 18.440073195764693 and parameters: {'n_hidden': 3, 'learning_rate': 0.003383051340749669, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08533968926837747, 'dropout_rate_Layer_2': 0.30010082562122403, 'dropout_rate_Layer_3': 0.22375391028565844, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.15680969179445e-05, 'l1_Layer_2': 0.015126436425611114, 'l1_Layer_3': 0.0005503497034329044, 'n_units_Layer_1': 125, 'n_units_Layer_2': 120, 'n_units_Layer_3': 215}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.44 | sMAPE for Validation Set is: 20.05% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 46.53 | sMAPE for Test Set is: 23.85% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:51:48,483]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:50,831]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:52,273]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:54,555]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:56,813]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:51:59,760]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:52:01,716]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:52:03,947]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:52:10,250]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:52:10,546]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:52:17,401]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:52:17,810]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:52:18,948]\u001b[0m Trial 262 finished with value: 18.319228729216082 and parameters: {'n_hidden': 3, 'learning_rate': 0.003605177982945313, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08913781462391324, 'dropout_rate_Layer_2': 0.3009558366478868, 'dropout_rate_Layer_3': 0.06656702455683534, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.138905340395348e-05, 'l1_Layer_2': 0.015724447845260597, 'l1_Layer_3': 0.0006495405624499491, 'n_units_Layer_1': 120, 'n_units_Layer_2': 115, 'n_units_Layer_3': 210}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.32 | sMAPE for Validation Set is: 19.89% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 49.86 | sMAPE for Test Set is: 24.78% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:52:23,919]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:52:27,266]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:52:30,460]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:52:33,950]\u001b[0m Trial 271 finished with value: 18.64483960281315 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033153028891322427, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0388547537104818, 'dropout_rate_Layer_2': 0.03186294061212103, 'dropout_rate_Layer_3': 0.2687826460899956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004583848164017681, 'l1_Layer_2': 0.00025295881021118066, 'l1_Layer_3': 0.0003255378614188654, 'n_units_Layer_1': 135, 'n_units_Layer_2': 75, 'n_units_Layer_3': 110}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.64 | sMAPE for Validation Set is: 20.21% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 46.62 | sMAPE for Test Set is: 23.90% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:52:37,608]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:52:38,495]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:52:44,203]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:52:48,106]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:52:48,517]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:52:54,389]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:52:55,123]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:52:59,877]\u001b[0m Trial 281 finished with value: 18.611877691545967 and parameters: {'n_hidden': 3, 'learning_rate': 0.003313432346351627, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03814572121597349, 'dropout_rate_Layer_2': 0.0029702580402229464, 'dropout_rate_Layer_3': 0.26693754221639093, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004318472676915878, 'l1_Layer_2': 0.00025672768262697344, 'l1_Layer_3': 0.00029770522596740033, 'n_units_Layer_1': 155, 'n_units_Layer_2': 80, 'n_units_Layer_3': 110}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.61 | sMAPE for Validation Set is: 20.08% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 48.43 | sMAPE for Test Set is: 24.43% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:53:00,481]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:53:05,901]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:53:09,705]\u001b[0m Trial 282 finished with value: 18.230412748059745 and parameters: {'n_hidden': 3, 'learning_rate': 0.003019226782389886, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07806957195951145, 'dropout_rate_Layer_2': 0.014746694670924597, 'dropout_rate_Layer_3': 0.2682641093204793, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00385528136290064, 'l1_Layer_2': 0.0002519909147682702, 'l1_Layer_3': 0.00024416473691219186, 'n_units_Layer_1': 195, 'n_units_Layer_2': 90, 'n_units_Layer_3': 110}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.23 | sMAPE for Validation Set is: 19.80% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 46.92 | sMAPE for Test Set is: 23.98% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:53:10,454]\u001b[0m Trial 289 finished with value: 19.547248961263975 and parameters: {'n_hidden': 3, 'learning_rate': 0.005556721942351981, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09294692554367452, 'dropout_rate_Layer_2': 0.08177608452024841, 'dropout_rate_Layer_3': 0.062037925854880216, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.9427849860116925e-05, 'l1_Layer_2': 0.00012784633075693297, 'l1_Layer_3': 1.2644253111711211e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 105, 'n_units_Layer_3': 290}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.55 | sMAPE for Validation Set is: 21.37% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 51.79 | sMAPE for Test Set is: 25.33% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:53:19,237]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:53:23,457]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:53:26,594]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:53:29,173]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.58 | sMAPE for Validation Set is: 20.24% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 49.13 | sMAPE for Test Set is: 24.67% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:53:31,556]\u001b[0m Trial 294 finished with value: 18.580439622637503 and parameters: {'n_hidden': 4, 'learning_rate': 0.00337526322005705, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07441272091550918, 'dropout_rate_Layer_2': 0.29733417188525013, 'dropout_rate_Layer_3': 0.2310533173393647, 'dropout_rate_Layer_4': 0.022160000686866604, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4070962010036667e-05, 'l1_Layer_2': 0.013823895453464515, 'l1_Layer_3': 0.0005161773175215987, 'l1_Layer_4': 1.1057569264396682e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 125, 'n_units_Layer_3': 250, 'n_units_Layer_4': 70}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:53:32,287]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:53:34,500]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:53:41,185]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:53:41,593]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:53:46,410]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:53:49,074]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:53:53,769]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:53:57,389]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:53:58,789]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:53:59,971]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:54:04,123]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:54:05,711]\u001b[0m Trial 292 finished with value: 18.78831156529972 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011598445158075635, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08338189436284082, 'dropout_rate_Layer_2': 0.003956722161983466, 'dropout_rate_Layer_3': 0.20828155601540335, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013004498230552575, 'l1_Layer_2': 0.0020095713133814735, 'l1_Layer_3': 0.0010072730401283942, 'n_units_Layer_1': 195, 'n_units_Layer_2': 75, 'n_units_Layer_3': 70}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.79 | sMAPE for Validation Set is: 20.36% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 48.02 | sMAPE for Test Set is: 24.45% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:54:08,284]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:54:10,597]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:54:11,361]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:54:16,836]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:54:21,549]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:54:24,121]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:54:24,474]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:54:26,380]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:54:32,561]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:54:32,999]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:54:37,765]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:54:41,577]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:54:42,165]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:54:48,008]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:54:51,581]\u001b[0m Trial 316 finished with value: 19.331481883468133 and parameters: {'n_hidden': 4, 'learning_rate': 0.012976761867756629, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14064746541003612, 'dropout_rate_Layer_2': 0.1811605318118721, 'dropout_rate_Layer_3': 0.05471067842441546, 'dropout_rate_Layer_4': 0.02019993112946314, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.0929907751551357e-05, 'l1_Layer_2': 0.0017646167717356713, 'l1_Layer_3': 0.0016423529951286567, 'l1_Layer_4': 0.08023266129624072, 'n_units_Layer_1': 160, 'n_units_Layer_2': 105, 'n_units_Layer_3': 215, 'n_units_Layer_4': 175}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.33 | sMAPE for Validation Set is: 21.03% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 52.88 | sMAPE for Test Set is: 25.81% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:54:55,928]\u001b[0m Trial 324 finished with value: 20.593747401850187 and parameters: {'n_hidden': 3, 'learning_rate': 0.01033584447684327, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23125933422971226, 'dropout_rate_Layer_2': 0.01233921927081401, 'dropout_rate_Layer_3': 0.042330494415347045, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.928473222255728e-05, 'l1_Layer_2': 0.006731348215022299, 'l1_Layer_3': 5.080728721507471e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 105, 'n_units_Layer_3': 280}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.59 | sMAPE for Validation Set is: 22.15% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 63.82 | sMAPE for Test Set is: 28.60% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:54:56,422]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:54:57,324]\u001b[0m Trial 321 finished with value: 19.04783522912244 and parameters: {'n_hidden': 3, 'learning_rate': 0.010252988020907669, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06240429902496336, 'dropout_rate_Layer_2': 0.043498392142450104, 'dropout_rate_Layer_3': 0.29925245406955003, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.0286402299025484e-05, 'l1_Layer_2': 9.903830954367881e-05, 'l1_Layer_3': 5.033416227507723e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 105, 'n_units_Layer_3': 280}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.05 | sMAPE for Validation Set is: 21.02% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 52.19 | sMAPE for Test Set is: 25.72% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:54:57,536]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:03,026]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:06,557]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:09,039]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:09,426]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:15,854]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:19,133]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:19,431]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:21,942]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:27,298]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:28,242]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:30,079]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:33,355]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:38,102]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:39,873]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:43,373]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:47,579]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:51,074]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:51,661]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:56,748]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:55:57,852]\u001b[0m Trial 331 finished with value: 18.274719398283647 and parameters: {'n_hidden': 4, 'learning_rate': 0.0035402633916441595, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07808694502374577, 'dropout_rate_Layer_2': 0.2431387474862749, 'dropout_rate_Layer_3': 0.25052599303282713, 'dropout_rate_Layer_4': 0.02048633865603603, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.1463365632190276e-05, 'l1_Layer_2': 0.012437868212599497, 'l1_Layer_3': 0.0005330520390915395, 'l1_Layer_4': 1.483249654359626e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 245, 'n_units_Layer_4': 55}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.27 | sMAPE for Validation Set is: 20.00% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.84 | sMAPE for Test Set is: 24.57% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:56:05,397]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:56:06,416]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:56:11,386]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:56:11,872]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:56:16,658]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:56:17,589]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:56:20,165]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:56:26,081]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:56:30,416]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:56:30,660]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:56:36,453]\u001b[0m Trial 354 finished with value: 18.620622578892625 and parameters: {'n_hidden': 3, 'learning_rate': 0.005416103349038918, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25647650958165413, 'dropout_rate_Layer_2': 0.2079899530549971, 'dropout_rate_Layer_3': 0.289386834315543, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00045262903586336243, 'l1_Layer_2': 0.00011514853567629736, 'l1_Layer_3': 5.2122958281131205e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 95, 'n_units_Layer_3': 85}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.62 | sMAPE for Validation Set is: 20.01% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 45.85 | sMAPE for Test Set is: 23.72% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:56:38,047]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:56:42,683]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:56:44,261]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:56:44,865]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.75 | sMAPE for Validation Set is: 20.61% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 50.74 | sMAPE for Test Set is: 25.31% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:56:46,139]\u001b[0m Trial 355 finished with value: 18.752790657812437 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033327428598526575, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1343572026509767, 'dropout_rate_Layer_2': 0.2327349419056971, 'dropout_rate_Layer_3': 0.2382657829912439, 'dropout_rate_Layer_4': 0.1305262217898667, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.36603658464269e-05, 'l1_Layer_2': 0.008205479282845147, 'l1_Layer_3': 0.000690281231307306, 'l1_Layer_4': 1.1232885691491153e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 165, 'n_units_Layer_3': 250, 'n_units_Layer_4': 110}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:56:49,816]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:56:54,348]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:00,497]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:03,164]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:04,009]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:06,758]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:08,402]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:12,139]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:12,801]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:14,406]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:21,666]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:22,549]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:24,046]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:27,007]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:32,549]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:33,197]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:33,998]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:39,279]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:41,412]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.11 | sMAPE for Validation Set is: 20.50% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 50.01 | sMAPE for Test Set is: 25.06% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:57:42,237]\u001b[0m Trial 372 finished with value: 19.112066399567176 and parameters: {'n_hidden': 3, 'learning_rate': 0.008845414076437045, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11708381018575599, 'dropout_rate_Layer_2': 0.27252682481543894, 'dropout_rate_Layer_3': 0.298300658859803, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012078046506940527, 'l1_Layer_2': 0.0011315287075989288, 'l1_Layer_3': 0.0036396597771239376, 'n_units_Layer_1': 160, 'n_units_Layer_2': 100, 'n_units_Layer_3': 225}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:42,811]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:51,237]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:51,817]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:57:54,518]\u001b[0m Trial 384 finished with value: 19.804571698799702 and parameters: {'n_hidden': 3, 'learning_rate': 0.004894212544469434, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08730539455633825, 'dropout_rate_Layer_2': 0.04143858896741378, 'dropout_rate_Layer_3': 0.0002950386655804848, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.5957197426288095e-05, 'l1_Layer_2': 0.00010065345115089914, 'l1_Layer_3': 1.4503197186790696e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 115, 'n_units_Layer_3': 285}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.80 | sMAPE for Validation Set is: 21.87% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 53.19 | sMAPE for Test Set is: 26.16% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:58:00,073]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:00,799]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:01,414]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:08,454]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:09,080]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:09,296]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:10,281]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:18,634]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:21,490]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:22,146]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:23,768]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:30,978]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:31,105]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:31,914]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:32,111]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:41,686]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:45,626]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:46,130]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:48,655]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:53,599]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:54,655]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:57,688]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:58,638]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:59,415]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:58:59,606]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:59:05,949]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:59:10,227]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:59:12,595]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:59:13,330]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:59:20,644]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:59:20,978]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:59:26,518]\u001b[0m Trial 417 finished with value: 19.105694032008426 and parameters: {'n_hidden': 3, 'learning_rate': 0.005187154871753993, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08803733265244167, 'dropout_rate_Layer_2': 0.048226393074008465, 'dropout_rate_Layer_3': 0.033660130906458224, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.805720694035314e-05, 'l1_Layer_2': 0.0002433667622330498, 'l1_Layer_3': 1.641994738503374e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 120, 'n_units_Layer_3': 285}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.11 | sMAPE for Validation Set is: 20.87% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 52.90 | sMAPE for Test Set is: 25.70% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 06:59:31,988]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:59:32,646]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:59:37,492]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:59:38,287]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:59:39,069]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:59:44,670]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:59:51,084]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:59:51,430]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:59:51,539]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:59:54,696]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 06:59:59,899]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:00:05,398]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:00:05,661]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:00:18,960]\u001b[0m Trial 429 finished with value: 18.23860368547715 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032418346468535914, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027439052368877722, 'dropout_rate_Layer_2': 0.030325696157324448, 'dropout_rate_Layer_3': 0.014147671153009578, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003671261712667846, 'l1_Layer_2': 2.5137065624203578e-05, 'l1_Layer_3': 0.0001405622889719592, 'n_units_Layer_1': 135, 'n_units_Layer_2': 270, 'n_units_Layer_3': 300}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.24 | sMAPE for Validation Set is: 19.63% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 46.12 | sMAPE for Test Set is: 23.55% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:00:23,654]\u001b[0m Trial 433 finished with value: 18.83062592223148 and parameters: {'n_hidden': 4, 'learning_rate': 0.004334553595777136, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06783817746173966, 'dropout_rate_Layer_2': 0.3033165095929958, 'dropout_rate_Layer_3': 0.2144974955890174, 'dropout_rate_Layer_4': 0.06551163238277519, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0166015239651689e-05, 'l1_Layer_2': 0.012683062024361076, 'l1_Layer_3': 0.0009094558406421001, 'l1_Layer_4': 3.845352472807927e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 125, 'n_units_Layer_3': 240, 'n_units_Layer_4': 85}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.83 | sMAPE for Validation Set is: 20.54% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 52.71 | sMAPE for Test Set is: 25.75% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:00:27,152]\u001b[0m Trial 435 finished with value: 18.398988494804232 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027475022393914114, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01026090037684389, 'dropout_rate_Layer_2': 0.02970730036003911, 'dropout_rate_Layer_3': 0.009181311545455994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005759118422612785, 'l1_Layer_2': 1.5956523005788167e-05, 'l1_Layer_3': 1.1692255248644255e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 290, 'n_units_Layer_3': 290}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.40 | sMAPE for Validation Set is: 19.78% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 46.57 | sMAPE for Test Set is: 23.84% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:00:30,287]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:00:30,618]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:00:31,035]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:00:39,641]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:00:39,857]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:00:40,038]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:00:49,099]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:00:50,564]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:00:52,002]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:00:54,951]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:00:57,873]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:00,670]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:02,707]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:08,775]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:10,852]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:11,859]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:13,957]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:19,899]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:20,876]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:27,650]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:28,394]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:31,047]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:36,435]\u001b[0m Trial 449 finished with value: 19.231835412766017 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026508071341765182, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11311185492545138, 'dropout_rate_Layer_2': 0.21603594220637576, 'dropout_rate_Layer_3': 0.2106297423404683, 'dropout_rate_Layer_4': 0.18964923816847845, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.8914347938344076e-05, 'l1_Layer_2': 0.048032403383599064, 'l1_Layer_3': 0.00040988668257066344, 'l1_Layer_4': 3.655763650564902e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 155, 'n_units_Layer_3': 265, 'n_units_Layer_4': 50}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.23 | sMAPE for Validation Set is: 20.91% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 52.67 | sMAPE for Test Set is: 25.75% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:01:37,242]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:42,340]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:42,594]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:43,364]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:50,803]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:56,276]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:01:59,281]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:02,412]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:04,921]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:07,228]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.69 | sMAPE for Validation Set is: 20.47% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 47.48 | sMAPE for Test Set is: 24.07% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:02:09,037]\u001b[0m Trial 460 finished with value: 18.690097888927884 and parameters: {'n_hidden': 3, 'learning_rate': 0.0056261419239861275, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07595029666837431, 'dropout_rate_Layer_2': 0.06191190005474835, 'dropout_rate_Layer_3': 0.008368216907434986, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007913282972167752, 'l1_Layer_2': 0.007781352438311823, 'l1_Layer_3': 3.037225936406138e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 145, 'n_units_Layer_3': 300}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:11,877]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:15,740]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:19,767]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:22,742]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:24,577]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:26,258]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:30,927]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:33,554]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:34,248]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:36,201]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:39,090]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:41,700]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:46,763]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.42 | sMAPE for Validation Set is: 20.18% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 46.82 | sMAPE for Test Set is: 24.17% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:02:49,300]\u001b[0m Trial 476 finished with value: 18.421985264543714 and parameters: {'n_hidden': 3, 'learning_rate': 0.003462244251195055, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30779594867420407, 'dropout_rate_Layer_2': 0.07113151636161058, 'dropout_rate_Layer_3': 0.3158488890457349, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004172576492423947, 'l1_Layer_2': 0.00021289859381041408, 'l1_Layer_3': 0.0002536824886569559, 'n_units_Layer_1': 255, 'n_units_Layer_2': 105, 'n_units_Layer_3': 95}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:50,067]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:50,918]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:02:54,626]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:00,515]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:03,083]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:05,455]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:08,800]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:12,139]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:13,229]\u001b[0m Trial 486 finished with value: 18.9164792365868 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015062403361235169, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35579953601749376, 'dropout_rate_Layer_2': 0.09479684291607338, 'dropout_rate_Layer_3': 0.30933036056715846, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.531755509057006e-05, 'l1_Layer_2': 1.999501319251038e-05, 'l1_Layer_3': 1.0694971961392174e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 105, 'n_units_Layer_3': 55}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.92 | sMAPE for Validation Set is: 20.21% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 47.22 | sMAPE for Test Set is: 24.07% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:03:15,526]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:18,685]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:22,890]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:24,169]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:24,578]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:31,996]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:33,687]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:36,533]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:38,647]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:41,552]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:41,665]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:44,500]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:45,768]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:53,640]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:53,693]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:54,816]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:03:59,767]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:02,526]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:04,564]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:06,105]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:11,673]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:15,785]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:16,095]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:16,181]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:17,144]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:25,186]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:29,066]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:29,868]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:30,321]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:30,594]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:40,338]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:40,558]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:43,412]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:45,951]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:46,580]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:46,937]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:50,206]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:04:55,365]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:01,623]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:02,493]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:03,735]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:10,275]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:11,574]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:11,817]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:13,343]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:14,338]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:20,784]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:21,148]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:24,927]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:28,900]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:30,547]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:30,689]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:35,861]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:38,621]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:40,651]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:42,484]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:45,163]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:48,607]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:49,618]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:54,724]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:55,004]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:05:58,562]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:06:03,174]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:06:06,892]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:06:11,750]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:06:16,649]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:06:20,419]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:06:21,359]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:06:25,586]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:06:32,070]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.89 | sMAPE for Validation Set is: 20.67% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 51.13 | sMAPE for Test Set is: 25.27% | rMAE for Test Set is: 0.67\n",
      "MAE for Validation Set is: 18.73 | sMAPE for Validation Set is: 20.37% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 51.62 | sMAPE for Test Set is: 25.41% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:06:36,962]\u001b[0m Trial 555 finished with value: 18.886274442903602 and parameters: {'n_hidden': 3, 'learning_rate': 0.006357032457453265, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017988346924984248, 'dropout_rate_Layer_2': 0.01735062234583632, 'dropout_rate_Layer_3': 4.368924706196265e-05, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.32374554258702e-05, 'l1_Layer_2': 0.012148965830083956, 'l1_Layer_3': 0.023872653383800513, 'n_units_Layer_1': 100, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:06:37,048]\u001b[0m Trial 557 finished with value: 18.730268435105266 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033866653812881812, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1430664808734333, 'dropout_rate_Layer_2': 0.24362682520129134, 'dropout_rate_Layer_3': 0.23995736400886233, 'dropout_rate_Layer_4': 0.13986393094679153, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.157317287693025e-05, 'l1_Layer_2': 0.00891496272981579, 'l1_Layer_3': 0.0007522111610468203, 'l1_Layer_4': 1.0339840584473325e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 175, 'n_units_Layer_3': 250, 'n_units_Layer_4': 100}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:06:37,868]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:06:38,247]\u001b[0m Trial 564 finished with value: 18.66039630770017 and parameters: {'n_hidden': 3, 'learning_rate': 0.006548323462105995, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03019822403659588, 'dropout_rate_Layer_2': 0.03371026339098898, 'dropout_rate_Layer_3': 0.07757337779591116, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010581487526158723, 'l1_Layer_2': 0.00016722585113155262, 'l1_Layer_3': 1.5577268182179185e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 125, 'n_units_Layer_3': 280}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.66 | sMAPE for Validation Set is: 20.00% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 51.39 | sMAPE for Test Set is: 25.31% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:06:48,787]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:06:52,285]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:06:53,241]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:06:59,326]\u001b[0m Trial 569 finished with value: 18.579990875308074 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032513838390764256, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04872384451536054, 'dropout_rate_Layer_2': 0.3799839748056297, 'dropout_rate_Layer_3': 0.2774725194823078, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009542063417430831, 'l1_Layer_2': 0.00014318477525071232, 'l1_Layer_3': 0.0002690369159715853, 'n_units_Layer_1': 200, 'n_units_Layer_2': 75, 'n_units_Layer_3': 95}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.58 | sMAPE for Validation Set is: 20.19% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 46.77 | sMAPE for Test Set is: 23.97% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:06:59,893]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:07:02,703]\u001b[0m Trial 566 finished with value: 18.449168467681503 and parameters: {'n_hidden': 3, 'learning_rate': 0.003411072495084806, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.048232536354013845, 'dropout_rate_Layer_2': 0.37902036849602305, 'dropout_rate_Layer_3': 0.2792755762823254, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011090127119719147, 'l1_Layer_2': 0.00017896098489006998, 'l1_Layer_3': 0.00030390777423382307, 'n_units_Layer_1': 200, 'n_units_Layer_2': 75, 'n_units_Layer_3': 95}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.45 | sMAPE for Validation Set is: 19.94% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 46.19 | sMAPE for Test Set is: 23.74% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:07:04,685]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:07:08,552]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:07:13,454]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:07:16,954]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:07:19,908]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:07:24,466]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:07:28,435]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.97 | sMAPE for Validation Set is: 20.82% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 53.30 | sMAPE for Test Set is: 25.93% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:07:30,644]\u001b[0m Trial 572 finished with value: 18.972233540590025 and parameters: {'n_hidden': 4, 'learning_rate': 0.0037429873929250225, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08484489185006003, 'dropout_rate_Layer_2': 0.24321368854045686, 'dropout_rate_Layer_3': 0.3116667161055664, 'dropout_rate_Layer_4': 0.13875574513175842, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.599707065754043e-05, 'l1_Layer_2': 0.010271926035174309, 'l1_Layer_3': 0.00013776622017344124, 'l1_Layer_4': 1.0626771183564837e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 180, 'n_units_Layer_3': 250, 'n_units_Layer_4': 85}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:07:33,432]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:07:37,975]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:07:38,402]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:07:44,457]\u001b[0m Trial 576 finished with value: 19.153277327805704 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031037316256031684, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14942121293014124, 'dropout_rate_Layer_2': 0.2490115943654386, 'dropout_rate_Layer_3': 0.28954330294253483, 'dropout_rate_Layer_4': 0.15359180020203128, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.921360266294165e-05, 'l1_Layer_2': 0.008777020943164566, 'l1_Layer_3': 0.00014274566992336754, 'l1_Layer_4': 1.0317494884605844e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 185, 'n_units_Layer_3': 250, 'n_units_Layer_4': 85}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.15 | sMAPE for Validation Set is: 20.95% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 47.73 | sMAPE for Test Set is: 24.33% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:07:44,725]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:07:45,632]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:07:50,648]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:07:54,507]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:07:55,174]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:07:55,641]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:07:55,927]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:08:04,784]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:08:05,399]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:08:06,464]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:08:10,930]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:08:13,707]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:08:16,392]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:08:21,815]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:08:26,419]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:08:29,461]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:08:34,520]\u001b[0m Trial 593 finished with value: 19.518833103916943 and parameters: {'n_hidden': 3, 'learning_rate': 0.005455568169821933, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02719972525566139, 'dropout_rate_Layer_2': 0.06188073405730091, 'dropout_rate_Layer_3': 0.13301346415073126, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0034121185386004876, 'l1_Layer_2': 0.009855211007304897, 'l1_Layer_3': 0.002165127184319805, 'n_units_Layer_1': 105, 'n_units_Layer_2': 125, 'n_units_Layer_3': 280}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:08:34,628]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.52 | sMAPE for Validation Set is: 21.03% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 53.72 | sMAPE for Test Set is: 26.30% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:08:41,729]\u001b[0m Trial 602 finished with value: 20.407405408640816 and parameters: {'n_hidden': 4, 'learning_rate': 0.00763369613576243, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1171796813937, 'dropout_rate_Layer_2': 0.2957422459166808, 'dropout_rate_Layer_3': 0.19845342968219368, 'dropout_rate_Layer_4': 0.09927765192351538, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.003400617410085e-05, 'l1_Layer_2': 0.06656957465076124, 'l1_Layer_3': 0.0006035231839667545, 'l1_Layer_4': 5.250198816515112e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 150, 'n_units_Layer_3': 215, 'n_units_Layer_4': 70}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.41 | sMAPE for Validation Set is: 22.43% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 53.65 | sMAPE for Test Set is: 26.53% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:08:44,962]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:08:48,123]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.94 | sMAPE for Validation Set is: 20.92% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 51.40 | sMAPE for Test Set is: 25.45% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:08:51,201]\u001b[0m Trial 600 finished with value: 18.94084474787366 and parameters: {'n_hidden': 4, 'learning_rate': 0.007232922654892641, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12810046847220202, 'dropout_rate_Layer_2': 0.29876697795763246, 'dropout_rate_Layer_3': 0.24161013634940523, 'dropout_rate_Layer_4': 0.08575249896216273, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00018890337291073571, 'l1_Layer_2': 0.00021220697788047068, 'l1_Layer_3': 0.0012683698915762448, 'l1_Layer_4': 5.496742116721306e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 135, 'n_units_Layer_3': 275, 'n_units_Layer_4': 70}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:08:55,030]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:08:55,606]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:08:57,995]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:09:03,062]\u001b[0m Trial 604 finished with value: 18.209825216662733 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018447735070532764, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010538601456754861, 'dropout_rate_Layer_2': 0.03447042685690706, 'dropout_rate_Layer_3': 0.00039525446689491275, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002541089937429743, 'l1_Layer_2': 1.898116809004108e-05, 'l1_Layer_3': 0.00010237427104474654, 'n_units_Layer_1': 130, 'n_units_Layer_2': 100, 'n_units_Layer_3': 70}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.21 | sMAPE for Validation Set is: 19.79% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 49.69 | sMAPE for Test Set is: 24.75% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:09:06,046]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:09:06,883]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:09:12,591]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:09:13,432]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:09:20,442]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:09:30,636]\u001b[0m Trial 613 finished with value: 19.03545836707067 and parameters: {'n_hidden': 3, 'learning_rate': 0.004366165926949578, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04970152168699372, 'dropout_rate_Layer_2': 0.04181094345005268, 'dropout_rate_Layer_3': 0.007279761919975564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0034044326010320355, 'l1_Layer_2': 0.005275722681253671, 'l1_Layer_3': 0.0020117028443614408, 'n_units_Layer_1': 105, 'n_units_Layer_2': 100, 'n_units_Layer_3': 275}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.04 | sMAPE for Validation Set is: 20.60% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 53.22 | sMAPE for Test Set is: 26.15% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:09:34,812]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:09:37,564]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:09:39,097]\u001b[0m Trial 616 finished with value: 18.168343849288686 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022421852448826847, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016258658626392006, 'dropout_rate_Layer_2': 0.03906351994708712, 'dropout_rate_Layer_3': 0.013213867790981867, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0032011478770520626, 'l1_Layer_2': 2.1845218040313213e-05, 'l1_Layer_3': 9.611159220327908e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 300, 'n_units_Layer_3': 65}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.17 | sMAPE for Validation Set is: 19.84% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 49.63 | sMAPE for Test Set is: 24.73% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:09:47,723]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:09:51,583]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:09:57,034]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:10:01,778]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:10:02,271]\u001b[0m Trial 620 finished with value: 21.550668237506788 and parameters: {'n_hidden': 3, 'learning_rate': 0.004853773454522232, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07599049735645438, 'dropout_rate_Layer_2': 0.2640926880542867, 'dropout_rate_Layer_3': 0.26046932292496205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007819846947798241, 'l1_Layer_2': 0.0025201439805441483, 'l1_Layer_3': 0.0024062998425367073, 'n_units_Layer_1': 135, 'n_units_Layer_2': 95, 'n_units_Layer_3': 225}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.55 | sMAPE for Validation Set is: 23.10% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 58.78 | sMAPE for Test Set is: 28.34% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:10:09,219]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:10:10,858]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:10:18,466]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:10:21,996]\u001b[0m Trial 624 finished with value: 18.3282009460673 and parameters: {'n_hidden': 3, 'learning_rate': 0.002618157424191667, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021833136615704456, 'dropout_rate_Layer_2': 0.053234548295598635, 'dropout_rate_Layer_3': 0.013797475663220524, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0031790336592115377, 'l1_Layer_2': 2.100689814421102e-05, 'l1_Layer_3': 0.0013534714579522234, 'n_units_Layer_1': 135, 'n_units_Layer_2': 300, 'n_units_Layer_3': 65}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.33 | sMAPE for Validation Set is: 19.95% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 51.20 | sMAPE for Test Set is: 25.14% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:10:23,218]\u001b[0m Trial 623 finished with value: 18.033148433784756 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022866974702371204, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019087351743884255, 'dropout_rate_Layer_2': 0.046248609418379764, 'dropout_rate_Layer_3': 0.013856569933244465, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002012018123706595, 'l1_Layer_2': 2.0935824154830067e-05, 'l1_Layer_3': 0.00011245213012350282, 'n_units_Layer_1': 130, 'n_units_Layer_2': 300, 'n_units_Layer_3': 55}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.03 | sMAPE for Validation Set is: 19.90% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 49.78 | sMAPE for Test Set is: 24.58% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:10:23,247]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:10:38,551]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:10:38,632]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.23 | sMAPE for Validation Set is: 19.79% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.68 | sMAPE for Test Set is: 24.48% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:10:43,642]\u001b[0m Trial 631 finished with value: 18.23318096331378 and parameters: {'n_hidden': 3, 'learning_rate': 0.002190169155546606, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02631511978464154, 'dropout_rate_Layer_2': 0.06950482048305975, 'dropout_rate_Layer_3': 0.020464426309900485, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004139525111151568, 'l1_Layer_2': 2.6360428612808655e-05, 'l1_Layer_3': 0.0013126816092989615, 'n_units_Layer_1': 130, 'n_units_Layer_2': 300, 'n_units_Layer_3': 55}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:10:48,783]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:10:53,202]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:10:54,260]\u001b[0m Trial 633 finished with value: 18.453234062292502 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025278770419798957, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014128933298914442, 'dropout_rate_Layer_2': 0.06773411002487036, 'dropout_rate_Layer_3': 0.0214991448873005, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002753954682894619, 'l1_Layer_2': 2.1259557232123177e-05, 'l1_Layer_3': 0.0017151796058781272, 'n_units_Layer_1': 130, 'n_units_Layer_2': 300, 'n_units_Layer_3': 50}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.45 | sMAPE for Validation Set is: 20.11% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 53.13 | sMAPE for Test Set is: 25.73% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:11:06,284]\u001b[0m Trial 635 finished with value: 17.923491612972498 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022662197543474923, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02127210103950971, 'dropout_rate_Layer_2': 0.04445394611325209, 'dropout_rate_Layer_3': 0.022313566469127456, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018793817371356143, 'l1_Layer_2': 2.1278603115902264e-05, 'l1_Layer_3': 0.0013740987430107764, 'n_units_Layer_1': 125, 'n_units_Layer_2': 300, 'n_units_Layer_3': 55}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.92 | sMAPE for Validation Set is: 19.42% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 48.30 | sMAPE for Test Set is: 24.29% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:11:10,338]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:11:13,244]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:11:15,052]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:11:18,194]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:11:20,437]\u001b[0m Trial 638 finished with value: 18.229600497677342 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020185425955832554, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03707079753579469, 'dropout_rate_Layer_2': 0.08373627206617386, 'dropout_rate_Layer_3': 0.021838378294991544, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0027494822759512993, 'l1_Layer_2': 2.029449542161292e-05, 'l1_Layer_3': 0.0013000189830932464, 'n_units_Layer_1': 125, 'n_units_Layer_2': 300, 'n_units_Layer_3': 50}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.23 | sMAPE for Validation Set is: 19.94% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 52.17 | sMAPE for Test Set is: 25.42% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:11:23,812]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:11:26,915]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:11:33,145]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:11:36,440]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:11:41,239]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:11:43,559]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.25 | sMAPE for Validation Set is: 20.00% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 49.21 | sMAPE for Test Set is: 24.58% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:11:45,426]\u001b[0m Trial 642 finished with value: 18.249986185814414 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024525350244427794, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02095792186898149, 'dropout_rate_Layer_2': 0.08398797805081686, 'dropout_rate_Layer_3': 0.02483523596084651, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013327148059849195, 'l1_Layer_2': 2.2622340684580222e-05, 'l1_Layer_3': 0.0022370269209376435, 'n_units_Layer_1': 125, 'n_units_Layer_2': 300, 'n_units_Layer_3': 50}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:11:48,731]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:11:49,497]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:11:52,363]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:11:58,935]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:12:03,970]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:12:09,410]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:12:12,178]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:12:20,672]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:12:21,826]\u001b[0m Trial 655 finished with value: 18.924255794333348 and parameters: {'n_hidden': 4, 'learning_rate': 0.003495564229019762, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10533012515846678, 'dropout_rate_Layer_2': 0.23453408842106327, 'dropout_rate_Layer_3': 0.2394257577683568, 'dropout_rate_Layer_4': 0.23269505276355412, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.507616609439994e-05, 'l1_Layer_2': 0.0073188329027604575, 'l1_Layer_3': 0.000674544800773531, 'l1_Layer_4': 1.841090781163007e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250, 'n_units_Layer_4': 110}. Best is trial 116 with value: 17.871539245442083.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.92 | sMAPE for Validation Set is: 20.84% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 54.10 | sMAPE for Test Set is: 26.15% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:12:28,017]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:12:29,912]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:12:35,922]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:12:40,134]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:12:45,682]\u001b[0m Trial 658 finished with value: 17.843221908255 and parameters: {'n_hidden': 3, 'learning_rate': 0.002616169974124171, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027237522118395675, 'dropout_rate_Layer_2': 0.08850756283479222, 'dropout_rate_Layer_3': 0.01199131420199624, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019450136980892969, 'l1_Layer_2': 2.9822706711123642e-05, 'l1_Layer_3': 0.0014452652933413142, 'n_units_Layer_1': 135, 'n_units_Layer_2': 290, 'n_units_Layer_3': 50}. Best is trial 658 with value: 17.843221908255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.84 | sMAPE for Validation Set is: 19.55% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 48.65 | sMAPE for Test Set is: 24.32% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:12:50,819]\u001b[0m Trial 662 finished with value: 19.226167370647026 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025666258095859837, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19849330886571098, 'dropout_rate_Layer_2': 0.18151669563548886, 'dropout_rate_Layer_3': 0.18643668171259692, 'dropout_rate_Layer_4': 0.16161995750373112, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4944532666094866e-05, 'l1_Layer_2': 0.013794249049854448, 'l1_Layer_3': 0.0010174406421961252, 'l1_Layer_4': 1.011237054914642e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 140, 'n_units_Layer_3': 280, 'n_units_Layer_4': 95}. Best is trial 658 with value: 17.843221908255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.23 | sMAPE for Validation Set is: 21.01% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 49.88 | sMAPE for Test Set is: 25.01% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:12:53,017]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:12:57,851]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:01,947]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:04,926]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:06,009]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:07,055]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:12,739]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:17,051]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:17,575]\u001b[0m Trial 665 finished with value: 18.71628285157614 and parameters: {'n_hidden': 4, 'learning_rate': 0.002510445370527795, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2025902697929355, 'dropout_rate_Layer_2': 0.17497547887450512, 'dropout_rate_Layer_3': 0.1819258217674239, 'dropout_rate_Layer_4': 0.1219798330162458, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4783451202084542e-05, 'l1_Layer_2': 0.01495914781298164, 'l1_Layer_3': 0.0010201866043506327, 'l1_Layer_4': 1.0421015382572912e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 145, 'n_units_Layer_3': 280, 'n_units_Layer_4': 95}. Best is trial 658 with value: 17.843221908255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.72 | sMAPE for Validation Set is: 20.28% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 48.60 | sMAPE for Test Set is: 24.57% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:13:23,675]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:29,254]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:35,163]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:35,376]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:35,826]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:41,521]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:42,862]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:45,059]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:45,717]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:50,868]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:54,542]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:13:59,467]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:14:05,974]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:14:07,497]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:14:12,461]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:14:14,526]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:14:18,847]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:14:24,014]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:14:24,889]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:14:30,116]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:14:33,974]\u001b[0m Trial 689 finished with value: 18.03122126879417 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032286620520815966, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002782015194138631, 'dropout_rate_Layer_2': 0.06579925894601346, 'dropout_rate_Layer_3': 0.0004787674035391584, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028843888238426272, 'l1_Layer_2': 2.772030708271143e-05, 'l1_Layer_3': 0.0008822982606153491, 'n_units_Layer_1': 125, 'n_units_Layer_2': 300, 'n_units_Layer_3': 65}. Best is trial 658 with value: 17.843221908255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.03 | sMAPE for Validation Set is: 19.77% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 47.39 | sMAPE for Test Set is: 24.02% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:14:34,437]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:14:35,443]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:14:41,191]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:14:44,120]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:14:48,951]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:14:49,461]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:14:53,794]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:14:55,723]\u001b[0m Trial 694 finished with value: 18.2206295472328 and parameters: {'n_hidden': 3, 'learning_rate': 0.002878109605867516, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017840686510362583, 'dropout_rate_Layer_2': 0.054831649227686755, 'dropout_rate_Layer_3': 0.00017469334781429133, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015491874067841262, 'l1_Layer_2': 1.5584121844888893e-05, 'l1_Layer_3': 7.463509338490859e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 300, 'n_units_Layer_3': 55}. Best is trial 658 with value: 17.843221908255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.22 | sMAPE for Validation Set is: 19.56% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 49.92 | sMAPE for Test Set is: 24.83% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:14:56,643]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:15:03,930]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:15:07,601]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:15:09,776]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:15:11,324]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:15:16,925]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:15:17,185]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:15:17,452]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:15:25,691]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:15:25,931]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:15:32,580]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:15:33,282]\u001b[0m Trial 707 finished with value: 18.187609749834852 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030542694847488974, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01795683196799756, 'dropout_rate_Layer_2': 0.05843809690541235, 'dropout_rate_Layer_3': 0.009402837239156048, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021405123223277272, 'l1_Layer_2': 2.4286151952055733e-05, 'l1_Layer_3': 6.4365146052762e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 300, 'n_units_Layer_3': 60}. Best is trial 658 with value: 17.843221908255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.19 | sMAPE for Validation Set is: 19.76% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 47.26 | sMAPE for Test Set is: 24.01% | rMAE for Test Set is: 0.62\n",
      "MAE for Validation Set is: 19.04 | sMAPE for Validation Set is: 20.46% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 49.24 | sMAPE for Test Set is: 24.87% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:15:41,737]\u001b[0m Trial 711 finished with value: 19.041422627278546 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034804576717975487, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3036001441044144, 'dropout_rate_Layer_2': 0.3980599038795866, 'dropout_rate_Layer_3': 0.25129968627881677, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005584770389005283, 'l1_Layer_2': 8.382151696719915e-05, 'l1_Layer_3': 0.00032645636374802793, 'n_units_Layer_1': 240, 'n_units_Layer_2': 110, 'n_units_Layer_3': 85}. Best is trial 658 with value: 17.843221908255.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:15:41,746]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:15:48,437]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:15:49,733]\u001b[0m Trial 716 finished with value: 18.538131018626178 and parameters: {'n_hidden': 3, 'learning_rate': 0.004139584246441421, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014942005366589281, 'dropout_rate_Layer_2': 0.06879032529466851, 'dropout_rate_Layer_3': 0.010641726487096976, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001864443239818731, 'l1_Layer_2': 3.0354202354815305e-05, 'l1_Layer_3': 5.449128713945346e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 300, 'n_units_Layer_3': 55}. Best is trial 658 with value: 17.843221908255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.54 | sMAPE for Validation Set is: 20.15% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 52.40 | sMAPE for Test Set is: 25.56% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:15:52,000]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:15:52,034]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:15:57,024]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:15:58,946]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:01,871]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:02,449]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:04,981]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:10,040]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:12,556]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:15,551]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:19,575]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:20,813]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:25,672]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:29,272]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:31,187]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:32,371]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:33,593]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:35,423]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:42,582]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:47,082]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:47,419]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:48,000]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:54,305]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:57,317]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:16:59,324]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:00,238]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:06,820]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:14,672]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:14,877]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:15,305]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:23,047]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:23,299]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:23,891]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:24,397]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:32,196]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:34,447]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:35,050]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:39,451]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:42,046]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:48,034]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:48,243]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:49,369]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:57,255]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:17:57,770]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:18:02,702]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:18:05,301]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:18:10,293]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:18:14,772]\u001b[0m Trial 760 finished with value: 18.568324759126376 and parameters: {'n_hidden': 3, 'learning_rate': 0.006607918027863004, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0886794048389546, 'dropout_rate_Layer_2': 0.37236705949947435, 'dropout_rate_Layer_3': 0.22328528328340064, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014279917449714187, 'l1_Layer_2': 0.00020883672534363688, 'l1_Layer_3': 0.00011038981380252258, 'n_units_Layer_1': 155, 'n_units_Layer_2': 60, 'n_units_Layer_3': 85}. Best is trial 658 with value: 17.843221908255.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:18:14,787]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.57 | sMAPE for Validation Set is: 19.80% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 47.59 | sMAPE for Test Set is: 24.27% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:18:22,388]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:18:23,557]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:18:29,381]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:18:29,799]\u001b[0m Trial 765 finished with value: 18.158872795886392 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013891772123139786, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28380590829841834, 'dropout_rate_Layer_2': 0.0827220456380544, 'dropout_rate_Layer_3': 0.3373491319365368, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003951396397903481, 'l1_Layer_2': 0.00030985039803154053, 'l1_Layer_3': 0.0021919972947681697, 'n_units_Layer_1': 155, 'n_units_Layer_2': 70, 'n_units_Layer_3': 85}. Best is trial 658 with value: 17.843221908255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.16 | sMAPE for Validation Set is: 19.69% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 47.53 | sMAPE for Test Set is: 24.14% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:18:30,450]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:18:30,468]\u001b[0m Trial 767 finished with value: 18.5802541638575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013643580705464378, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21465580061026054, 'dropout_rate_Layer_2': 0.37225143561531093, 'dropout_rate_Layer_3': 0.22173436568805382, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013688520962300964, 'l1_Layer_2': 0.0006390156022423597, 'l1_Layer_3': 0.00011486075694575045, 'n_units_Layer_1': 180, 'n_units_Layer_2': 70, 'n_units_Layer_3': 140}. Best is trial 658 with value: 17.843221908255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.58 | sMAPE for Validation Set is: 20.19% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 47.45 | sMAPE for Test Set is: 24.25% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:18:39,264]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:18:40,355]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:18:41,677]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:18:42,139]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:18:48,974]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:18:51,380]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:18:52,140]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:18:52,550]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:18:56,587]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:05,161]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:05,408]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:05,528]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:06,040]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:17,007]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:18,323]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:19,833]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:23,543]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:25,704]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:27,136]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:33,980]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:35,385]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:42,222]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:42,717]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:43,340]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:48,711]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:54,029]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:19:58,520]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:20:01,805]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:20:03,126]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:20:06,393]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:20:07,696]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:20:14,842]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:20:18,831]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:20:24,716]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:20:29,239]\u001b[0m Trial 805 finished with value: 19.27361043618378 and parameters: {'n_hidden': 4, 'learning_rate': 0.0038378165542826406, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1372143374835172, 'dropout_rate_Layer_2': 0.28307011058372955, 'dropout_rate_Layer_3': 0.25451181772374504, 'dropout_rate_Layer_4': 0.21935024279432436, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.929306560585154e-05, 'l1_Layer_2': 0.020458890170372238, 'l1_Layer_3': 0.0005845262183119594, 'l1_Layer_4': 2.3151703627514214e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 150, 'n_units_Layer_3': 245, 'n_units_Layer_4': 95}. Best is trial 658 with value: 17.843221908255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.27 | sMAPE for Validation Set is: 21.37% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 50.64 | sMAPE for Test Set is: 25.34% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:20:34,935]\u001b[0m Trial 806 finished with value: 18.594214593880228 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009063090442152156, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05536527771957541, 'dropout_rate_Layer_2': 0.3845712636108367, 'dropout_rate_Layer_3': 0.22906571833013337, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003905185758334279, 'l1_Layer_2': 0.00030212540328322586, 'l1_Layer_3': 0.0001511807537538707, 'n_units_Layer_1': 155, 'n_units_Layer_2': 70, 'n_units_Layer_3': 155}. Best is trial 658 with value: 17.843221908255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.59 | sMAPE for Validation Set is: 20.22% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 47.66 | sMAPE for Test Set is: 24.37% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:20:38,447]\u001b[0m Trial 802 finished with value: 17.830233529648524 and parameters: {'n_hidden': 3, 'learning_rate': 0.003046217351588189, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017749401588056827, 'dropout_rate_Layer_2': 0.05824512465453741, 'dropout_rate_Layer_3': 0.00038257713518297445, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005852080805631432, 'l1_Layer_2': 1.9552347563856007e-05, 'l1_Layer_3': 0.0009048036379099044, 'n_units_Layer_1': 105, 'n_units_Layer_2': 285, 'n_units_Layer_3': 300}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.83 | sMAPE for Validation Set is: 19.42% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 49.50 | sMAPE for Test Set is: 24.49% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:20:39,062]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:20:39,573]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:20:44,648]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:20:49,842]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:20:50,523]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:20:51,246]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:20:56,316]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:20:59,664]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:21:02,498]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:21:04,467]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:21:11,048]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:21:11,855]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:21:18,485]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:21:18,700]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:21:20,241]\u001b[0m Trial 810 finished with value: 18.09421819908881 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013560269365525107, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12410930383999114, 'dropout_rate_Layer_2': 0.1017311357925584, 'dropout_rate_Layer_3': 0.17162539644309222, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002239944729537691, 'l1_Layer_2': 0.00020603408420073976, 'l1_Layer_3': 0.00034398338552943836, 'n_units_Layer_1': 170, 'n_units_Layer_2': 85, 'n_units_Layer_3': 90}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.09 | sMAPE for Validation Set is: 19.56% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.16 | sMAPE for Test Set is: 24.32% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:21:25,892]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:21:27,934]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:21:35,825]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:21:39,092]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:21:40,074]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:21:40,239]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:21:47,179]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:21:50,754]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:21:51,590]\u001b[0m Trial 827 finished with value: 18.14440794397777 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025163472497230356, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014844418247946894, 'dropout_rate_Layer_2': 0.05970697080402339, 'dropout_rate_Layer_3': 0.009620661881875742, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002930685826965826, 'l1_Layer_2': 1.7642807907396532e-05, 'l1_Layer_3': 0.0014376259793613087, 'n_units_Layer_1': 110, 'n_units_Layer_2': 290, 'n_units_Layer_3': 60}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.14 | sMAPE for Validation Set is: 19.72% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 49.04 | sMAPE for Test Set is: 24.61% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:21:54,792]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:21:58,577]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:22:04,204]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:22:05,881]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:22:12,636]\u001b[0m Trial 833 finished with value: 20.06802783177552 and parameters: {'n_hidden': 4, 'learning_rate': 0.005812822609125957, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16677382097863605, 'dropout_rate_Layer_2': 0.26531204074826087, 'dropout_rate_Layer_3': 0.22819902129380765, 'dropout_rate_Layer_4': 0.003573522490120884, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0391382734756635e-05, 'l1_Layer_2': 0.00915854492877742, 'l1_Layer_3': 0.00030941823605610657, 'l1_Layer_4': 0.09753498091159733, 'n_units_Layer_1': 65, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265, 'n_units_Layer_4': 290}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:22:12,801]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.07 | sMAPE for Validation Set is: 21.56% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 53.84 | sMAPE for Test Set is: 26.15% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:22:13,564]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:22:13,819]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:22:23,413]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:22:26,003]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:22:31,001]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:22:32,321]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:22:37,579]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:22:40,475]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:22:45,681]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:22:50,918]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:22:52,016]\u001b[0m Trial 848 finished with value: 18.495826563959458 and parameters: {'n_hidden': 3, 'learning_rate': 0.002331778887494148, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.110179678618465, 'dropout_rate_Layer_2': 0.1069687288753993, 'dropout_rate_Layer_3': 0.3242910632597825, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005226642538699287, 'l1_Layer_2': 0.0004527802269443112, 'l1_Layer_3': 0.00035061278081351344, 'n_units_Layer_1': 130, 'n_units_Layer_2': 75, 'n_units_Layer_3': 170}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:22:52,095]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.50 | sMAPE for Validation Set is: 20.06% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 48.31 | sMAPE for Test Set is: 24.56% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:22:52,446]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:22:58,683]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:23:00,905]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:23:10,353]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:23:10,621]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:23:12,481]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:23:17,555]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:23:18,459]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:23:24,579]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:23:28,513]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:23:29,436]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:23:37,747]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:23:38,961]\u001b[0m Trial 864 finished with value: 68.02500587934 and parameters: {'n_hidden': 4, 'learning_rate': 0.005032653398532277, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12120539822400206, 'dropout_rate_Layer_2': 0.3520037626996965, 'dropout_rate_Layer_3': 0.27108718788917896, 'dropout_rate_Layer_4': 0.2850941594548777, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00012417806717377185, 'l1_Layer_2': 0.011659722301629722, 'l1_Layer_3': 0.0005005723237844897, 'l1_Layer_4': 1.4863455209067584e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 160, 'n_units_Layer_3': 240, 'n_units_Layer_4': 195}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 68.03 | sMAPE for Validation Set is: 77.71% | rMAE for Validation Set is: 2.47\n",
      "MAE for Test Set is: 207.78 | sMAPE for Test Set is: 137.11% | rMAE for Test Set is: 2.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:23:41,152]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:23:42,293]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:23:50,887]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:23:52,358]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:23:57,754]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.35 | sMAPE for Validation Set is: 19.75% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 47.36 | sMAPE for Test Set is: 24.18% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:24:00,976]\u001b[0m Trial 862 finished with value: 18.35407568800161 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020477574036554336, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10732321982789642, 'dropout_rate_Layer_2': 0.1099189917209864, 'dropout_rate_Layer_3': 0.33952645653768354, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005234921555786579, 'l1_Layer_2': 0.0004439429468792585, 'l1_Layer_3': 0.0007210930114304556, 'n_units_Layer_1': 95, 'n_units_Layer_2': 110, 'n_units_Layer_3': 200}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:24:08,811]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:24:13,809]\u001b[0m Trial 868 finished with value: 18.577842937865515 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021067614559913492, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13544790088944902, 'dropout_rate_Layer_2': 0.13706840324876252, 'dropout_rate_Layer_3': 0.33388796856510977, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0050105319031353126, 'l1_Layer_2': 0.0004785351567799249, 'l1_Layer_3': 0.0006951683731449129, 'n_units_Layer_1': 110, 'n_units_Layer_2': 80, 'n_units_Layer_3': 175}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.58 | sMAPE for Validation Set is: 19.98% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 47.03 | sMAPE for Test Set is: 24.09% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:24:13,967]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:24:14,104]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:24:15,457]\u001b[0m Trial 873 finished with value: 18.362365946547726 and parameters: {'n_hidden': 3, 'learning_rate': 0.005896616670553525, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07616663548693915, 'dropout_rate_Layer_2': 0.05062060620148315, 'dropout_rate_Layer_3': 0.010321206156232407, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007979634134125823, 'l1_Layer_2': 0.00017873613480412498, 'l1_Layer_3': 4.096780561112583e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 185, 'n_units_Layer_3': 85}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.36 | sMAPE for Validation Set is: 20.07% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 50.74 | sMAPE for Test Set is: 24.95% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:24:27,066]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:24:27,826]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:24:28,504]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:24:28,665]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:24:44,905]\u001b[0m Trial 880 finished with value: 18.834124207678677 and parameters: {'n_hidden': 3, 'learning_rate': 0.005872017538107012, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08686754288098839, 'dropout_rate_Layer_2': 0.03853422501449804, 'dropout_rate_Layer_3': 0.017237157733137567, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006432341634006253, 'l1_Layer_2': 0.0001733289134705714, 'l1_Layer_3': 0.0008929174199465645, 'n_units_Layer_1': 90, 'n_units_Layer_2': 185, 'n_units_Layer_3': 90}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.83 | sMAPE for Validation Set is: 20.50% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 50.30 | sMAPE for Test Set is: 24.98% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:24:48,048]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:24:53,383]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:24:57,211]\u001b[0m Trial 883 finished with value: 19.076952617972037 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032999992484103817, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2071851164124111, 'dropout_rate_Layer_2': 0.2315254973768785, 'dropout_rate_Layer_3': 0.19186683740461588, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.309048376959105e-05, 'l1_Layer_2': 0.022683020976503775, 'l1_Layer_3': 0.003360749165414775, 'n_units_Layer_1': 125, 'n_units_Layer_2': 120, 'n_units_Layer_3': 260}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.08 | sMAPE for Validation Set is: 20.49% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 52.36 | sMAPE for Test Set is: 25.67% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:24:59,324]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:25:04,583]\u001b[0m Trial 881 finished with value: 18.58762055340204 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017743984641111889, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13460772018517955, 'dropout_rate_Layer_2': 0.10740873649130883, 'dropout_rate_Layer_3': 0.38781670257180634, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006824618886823143, 'l1_Layer_2': 0.00024125533251414708, 'l1_Layer_3': 0.0009690001602931002, 'n_units_Layer_1': 75, 'n_units_Layer_2': 85, 'n_units_Layer_3': 200}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.59 | sMAPE for Validation Set is: 19.99% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 48.97 | sMAPE for Test Set is: 24.67% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:25:06,991]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:25:10,904]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:25:11,245]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.35 | sMAPE for Validation Set is: 19.75% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 47.86 | sMAPE for Test Set is: 24.27% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:25:15,309]\u001b[0m Trial 886 finished with value: 18.353125408268507 and parameters: {'n_hidden': 3, 'learning_rate': 0.006042334889152746, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08524989018849176, 'dropout_rate_Layer_2': 0.03961178427247548, 'dropout_rate_Layer_3': 0.01687748233694853, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006614854540878323, 'l1_Layer_2': 0.00017931871060364887, 'l1_Layer_3': 0.0034208639747002985, 'n_units_Layer_1': 90, 'n_units_Layer_2': 175, 'n_units_Layer_3': 90}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:25:20,326]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:25:26,419]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:25:27,330]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:25:33,880]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:25:34,474]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:25:35,322]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:25:40,181]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:25:42,512]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:25:42,753]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:25:43,589]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:25:53,962]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:25:57,038]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:25:59,572]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:26:01,511]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:26:03,729]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:26:09,289]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:26:14,345]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:26:17,117]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:26:20,735]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:26:21,750]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:26:23,115]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:26:31,449]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:26:31,956]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:26:34,877]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:26:40,730]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:26:42,784]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:26:44,403]\u001b[0m Trial 901 finished with value: 18.05799328632639 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024994827939066266, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12086861560688877, 'dropout_rate_Layer_2': 0.14401219384963915, 'dropout_rate_Layer_3': 0.3425584942364967, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0035246970682375235, 'l1_Layer_2': 0.0011467850293665881, 'l1_Layer_3': 0.00045953696843189373, 'n_units_Layer_1': 140, 'n_units_Layer_2': 100, 'n_units_Layer_3': 165}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.06 | sMAPE for Validation Set is: 19.60% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 46.09 | sMAPE for Test Set is: 23.72% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:26:50,022]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:26:52,253]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:27:00,458]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:27:03,923]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:27:04,196]\u001b[0m Trial 920 finished with value: 18.53022637353041 and parameters: {'n_hidden': 3, 'learning_rate': 0.004959521574092712, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08269574248609152, 'dropout_rate_Layer_2': 0.05277925144938351, 'dropout_rate_Layer_3': 0.023302868926096836, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008295930926142672, 'l1_Layer_2': 0.00014080375391918527, 'l1_Layer_3': 0.0030865049057733794, 'n_units_Layer_1': 180, 'n_units_Layer_2': 185, 'n_units_Layer_3': 275}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.53 | sMAPE for Validation Set is: 20.12% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 49.58 | sMAPE for Test Set is: 24.81% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:27:05,266]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:27:13,467]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:27:14,586]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:27:24,851]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:27:28,659]\u001b[0m Trial 928 finished with value: 18.24122223833642 and parameters: {'n_hidden': 3, 'learning_rate': 0.004971073456131496, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08320360383875697, 'dropout_rate_Layer_2': 0.05139361321707668, 'dropout_rate_Layer_3': 0.0001519298721524339, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008577496764123497, 'l1_Layer_2': 0.00014140653733924142, 'l1_Layer_3': 0.0033603016620962003, 'n_units_Layer_1': 100, 'n_units_Layer_2': 185, 'n_units_Layer_3': 90}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.24 | sMAPE for Validation Set is: 19.75% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.74 | sMAPE for Test Set is: 24.49% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:27:31,991]\u001b[0m Trial 922 finished with value: 18.11888287883453 and parameters: {'n_hidden': 3, 'learning_rate': 0.001588495229555472, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11528547358897388, 'dropout_rate_Layer_2': 0.1481335265032479, 'dropout_rate_Layer_3': 0.35227821791343367, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0040043014866767215, 'l1_Layer_2': 0.0015163284601105325, 'l1_Layer_3': 0.0006116362062939033, 'n_units_Layer_1': 120, 'n_units_Layer_2': 90, 'n_units_Layer_3': 195}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.12 | sMAPE for Validation Set is: 19.66% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 46.31 | sMAPE for Test Set is: 23.79% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:27:32,773]\u001b[0m Trial 926 finished with value: 18.533283062371904 and parameters: {'n_hidden': 3, 'learning_rate': 0.0051392320930995355, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08475522542067637, 'dropout_rate_Layer_2': 0.04884506641311697, 'dropout_rate_Layer_3': 0.02271325382368719, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000595642353125837, 'l1_Layer_2': 0.00014325534313387966, 'l1_Layer_3': 0.003081890219216095, 'n_units_Layer_1': 95, 'n_units_Layer_2': 185, 'n_units_Layer_3': 75}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.53 | sMAPE for Validation Set is: 20.14% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 48.62 | sMAPE for Test Set is: 24.44% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:27:37,049]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:27:40,384]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:27:41,982]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:27:43,308]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:27:51,585]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:27:56,193]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:27:56,331]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:28:02,724]\u001b[0m Trial 932 finished with value: 18.00968146748605 and parameters: {'n_hidden': 3, 'learning_rate': 0.004670462261929244, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08370903147810492, 'dropout_rate_Layer_2': 0.05344159962084326, 'dropout_rate_Layer_3': 0.013913891755754769, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007992264242670447, 'l1_Layer_2': 0.00014021817982268572, 'l1_Layer_3': 0.003417987063661531, 'n_units_Layer_1': 95, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.01 | sMAPE for Validation Set is: 19.56% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 47.40 | sMAPE for Test Set is: 24.03% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:28:05,370]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:28:12,986]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:28:21,699]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:28:22,624]\u001b[0m Trial 940 finished with value: 18.695608762131947 and parameters: {'n_hidden': 4, 'learning_rate': 0.0037813312118670723, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08554571297955572, 'dropout_rate_Layer_2': 0.33257438070847256, 'dropout_rate_Layer_3': 0.20494776757581554, 'dropout_rate_Layer_4': 0.08939822180105574, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.514608807948491e-05, 'l1_Layer_2': 0.011113637612312564, 'l1_Layer_3': 0.0017179131868606849, 'l1_Layer_4': 2.9299445542809452e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 150, 'n_units_Layer_3': 240, 'n_units_Layer_4': 120}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.70 | sMAPE for Validation Set is: 20.27% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 50.87 | sMAPE for Test Set is: 25.19% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:28:25,726]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:28:32,418]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:28:37,371]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:28:38,579]\u001b[0m Trial 935 finished with value: 18.09960079876848 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011121386393952088, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1067848856260716, 'dropout_rate_Layer_2': 0.1510793574668827, 'dropout_rate_Layer_3': 0.3729801578365709, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023151976000252376, 'l1_Layer_2': 0.0017084240374432326, 'l1_Layer_3': 0.0003774979542770275, 'n_units_Layer_1': 135, 'n_units_Layer_2': 90, 'n_units_Layer_3': 205}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.10 | sMAPE for Validation Set is: 19.72% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 46.91 | sMAPE for Test Set is: 23.89% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:28:50,064]\u001b[0m Trial 945 finished with value: 18.54118739117457 and parameters: {'n_hidden': 3, 'learning_rate': 0.004587815131837154, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08781982773401009, 'dropout_rate_Layer_2': 0.05175729336134917, 'dropout_rate_Layer_3': 0.02245549410625835, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006117209912800767, 'l1_Layer_2': 0.00013057396130651124, 'l1_Layer_3': 0.0033809546938683398, 'n_units_Layer_1': 100, 'n_units_Layer_2': 185, 'n_units_Layer_3': 70}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.54 | sMAPE for Validation Set is: 20.03% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 51.24 | sMAPE for Test Set is: 25.20% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:28:54,080]\u001b[0m Trial 944 finished with value: 18.096352261014047 and parameters: {'n_hidden': 3, 'learning_rate': 0.004293702636422987, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10812227279210754, 'dropout_rate_Layer_2': 0.04659340871575076, 'dropout_rate_Layer_3': 0.02283592018137317, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010076568807581084, 'l1_Layer_2': 0.00013893740150400832, 'l1_Layer_3': 0.002954065424460602, 'n_units_Layer_1': 100, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.10 | sMAPE for Validation Set is: 19.88% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 47.57 | sMAPE for Test Set is: 24.16% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:28:55,889]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:29:02,062]\u001b[0m Trial 947 finished with value: 18.38426683866334 and parameters: {'n_hidden': 3, 'learning_rate': 0.004220263448772894, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11019376854953786, 'dropout_rate_Layer_2': 0.04577649463537201, 'dropout_rate_Layer_3': 0.023469862285011397, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008233383467920367, 'l1_Layer_2': 0.00013194929271345758, 'l1_Layer_3': 0.0033367411509746788, 'n_units_Layer_1': 100, 'n_units_Layer_2': 185, 'n_units_Layer_3': 75}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.38 | sMAPE for Validation Set is: 19.87% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 49.82 | sMAPE for Test Set is: 24.83% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:29:02,294]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:29:02,436]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.15 | sMAPE for Validation Set is: 19.78% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 50.74 | sMAPE for Test Set is: 24.93% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:29:08,692]\u001b[0m Trial 948 finished with value: 18.153366352113267 and parameters: {'n_hidden': 3, 'learning_rate': 0.004386808769339171, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08465094510130716, 'dropout_rate_Layer_2': 0.04421460234698814, 'dropout_rate_Layer_3': 0.022561666518175632, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007946094486545762, 'l1_Layer_2': 0.00013771270210398572, 'l1_Layer_3': 0.0034047212001635423, 'n_units_Layer_1': 100, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:29:13,604]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:29:15,513]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:29:16,517]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:29:21,488]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:29:29,549]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:29:35,918]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:29:40,890]\u001b[0m Trial 957 finished with value: 18.244315027169453 and parameters: {'n_hidden': 3, 'learning_rate': 0.002180860114325319, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008102741461742734, 'dropout_rate_Layer_2': 0.05327798197242006, 'dropout_rate_Layer_3': 0.028822957542726763, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025663285836060997, 'l1_Layer_2': 2.6421259935668686e-05, 'l1_Layer_3': 3.3750166012137726e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 300, 'n_units_Layer_3': 60}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.24 | sMAPE for Validation Set is: 19.51% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.25 | sMAPE for Test Set is: 24.38% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:29:41,414]\u001b[0m Trial 956 finished with value: 18.329828598361665 and parameters: {'n_hidden': 3, 'learning_rate': 0.002296788188880521, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007323539690947869, 'dropout_rate_Layer_2': 0.05303824594977027, 'dropout_rate_Layer_3': 0.01364076453137017, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025558690675176444, 'l1_Layer_2': 2.5383735896546388e-05, 'l1_Layer_3': 0.0006643148586627075, 'n_units_Layer_1': 135, 'n_units_Layer_2': 270, 'n_units_Layer_3': 60}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.33 | sMAPE for Validation Set is: 19.69% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 48.45 | sMAPE for Test Set is: 24.34% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:29:42,256]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:29:50,600]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:29:51,320]\u001b[0m Trial 958 finished with value: 18.347318920334406 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036484851601367276, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10214706325040457, 'dropout_rate_Layer_2': 0.04940014694561008, 'dropout_rate_Layer_3': 0.030696244897375918, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006362164846353494, 'l1_Layer_2': 0.00014254781824707286, 'l1_Layer_3': 0.003500910590003856, 'n_units_Layer_1': 100, 'n_units_Layer_2': 175, 'n_units_Layer_3': 75}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.35 | sMAPE for Validation Set is: 19.91% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 51.17 | sMAPE for Test Set is: 25.05% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:29:56,405]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:30:01,824]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:30:04,231]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:30:09,655]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:30:14,705]\u001b[0m Trial 965 finished with value: 18.14717949077848 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036488540753731886, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1114629486400763, 'dropout_rate_Layer_2': 0.04605360303810025, 'dropout_rate_Layer_3': 0.0340711754817679, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000767919498277388, 'l1_Layer_2': 0.0001307816337765749, 'l1_Layer_3': 0.00349016672892908, 'n_units_Layer_1': 100, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:30:14,806]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.15 | sMAPE for Validation Set is: 20.16% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 46.51 | sMAPE for Test Set is: 23.82% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:30:19,832]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.29 | sMAPE for Validation Set is: 19.65% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.81 | sMAPE for Test Set is: 24.52% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:30:21,374]\u001b[0m Trial 964 finished with value: 18.28966876900174 and parameters: {'n_hidden': 3, 'learning_rate': 0.003527171481458675, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10301533369492807, 'dropout_rate_Layer_2': 0.04808680483262107, 'dropout_rate_Layer_3': 0.0303680139069728, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007898991072056643, 'l1_Layer_2': 0.0001439154185008985, 'l1_Layer_3': 0.003497586602845851, 'n_units_Layer_1': 100, 'n_units_Layer_2': 175, 'n_units_Layer_3': 75}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:30:30,164]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:30:30,318]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:30:37,941]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:30:44,556]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:30:48,302]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:30:52,097]\u001b[0m Trial 976 finished with value: 18.376770201874844 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036118362997636932, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11644679228794663, 'dropout_rate_Layer_2': 0.045161427598254825, 'dropout_rate_Layer_3': 0.03239619890533182, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009983051241525256, 'l1_Layer_2': 0.00015497248348551174, 'l1_Layer_3': 0.004083689095375349, 'n_units_Layer_1': 100, 'n_units_Layer_2': 175, 'n_units_Layer_3': 80}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.38 | sMAPE for Validation Set is: 20.15% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 48.88 | sMAPE for Test Set is: 24.52% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:30:55,751]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:30:56,413]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:30:57,373]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:31:05,340]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:31:07,087]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:31:12,362]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:31:16,295]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:31:16,605]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:31:16,776]\u001b[0m Trial 974 finished with value: 18.12132311236259 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016424757193982558, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10173335010188166, 'dropout_rate_Layer_2': 0.17189216455955816, 'dropout_rate_Layer_3': 0.1796222600348012, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018162646997030329, 'l1_Layer_2': 0.002425375320442984, 'l1_Layer_3': 0.00033480450662212865, 'n_units_Layer_1': 160, 'n_units_Layer_2': 80, 'n_units_Layer_3': 205}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.12 | sMAPE for Validation Set is: 19.69% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 47.37 | sMAPE for Test Set is: 24.08% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:31:22,279]\u001b[0m Trial 981 finished with value: 18.51185896108048 and parameters: {'n_hidden': 3, 'learning_rate': 0.003423426571335076, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11801480948394867, 'dropout_rate_Layer_2': 0.04394422850402352, 'dropout_rate_Layer_3': 0.032660576924065925, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010268443941964, 'l1_Layer_2': 0.00015960837868349653, 'l1_Layer_3': 0.004343079332064535, 'n_units_Layer_1': 100, 'n_units_Layer_2': 175, 'n_units_Layer_3': 75}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.51 | sMAPE for Validation Set is: 20.01% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 50.80 | sMAPE for Test Set is: 25.05% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:31:34,199]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:31:39,398]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.44 | sMAPE for Validation Set is: 20.01% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 47.81 | sMAPE for Test Set is: 24.24% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:31:42,049]\u001b[0m Trial 989 finished with value: 18.44420513865224 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037114826119804367, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11569667438883924, 'dropout_rate_Layer_2': 0.04369838244280232, 'dropout_rate_Layer_3': 0.03133355500369131, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010785968445117375, 'l1_Layer_2': 0.00015680114713021822, 'l1_Layer_3': 0.004046269403185155, 'n_units_Layer_1': 100, 'n_units_Layer_2': 175, 'n_units_Layer_3': 75}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:31:43,742]\u001b[0m Trial 990 finished with value: 18.202803738769873 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034605706827924537, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1102503025381358, 'dropout_rate_Layer_2': 0.04275874113538979, 'dropout_rate_Layer_3': 0.03153627355304095, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010096432480686509, 'l1_Layer_2': 0.0001663463958713865, 'l1_Layer_3': 0.0045395825862424135, 'n_units_Layer_1': 100, 'n_units_Layer_2': 175, 'n_units_Layer_3': 75}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.20 | sMAPE for Validation Set is: 19.80% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 46.57 | sMAPE for Test Set is: 23.86% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:31:49,854]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:31:54,908]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:31:59,748]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:32:09,051]\u001b[0m Trial 993 finished with value: 20.01006790138046 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017701084608345262, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23764520068239836, 'dropout_rate_Layer_2': 0.3823188589491841, 'dropout_rate_Layer_3': 0.2641432100846322, 'dropout_rate_Layer_4': 0.39436350731836134, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.077092786862347e-05, 'l1_Layer_2': 0.01744350575608582, 'l1_Layer_3': 0.00028246323405968575, 'l1_Layer_4': 1.648392101770258e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 180, 'n_units_Layer_3': 290, 'n_units_Layer_4': 135}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.01 | sMAPE for Validation Set is: 21.79% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 59.22 | sMAPE for Test Set is: 27.40% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:32:12,498]\u001b[0m Trial 992 finished with value: 18.263266482220015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015901100477661689, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10325459265897426, 'dropout_rate_Layer_2': 0.17636526464701086, 'dropout_rate_Layer_3': 0.18064852888307492, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017156408155145353, 'l1_Layer_2': 0.0023991717363803047, 'l1_Layer_3': 0.00033182446738408135, 'n_units_Layer_1': 160, 'n_units_Layer_2': 80, 'n_units_Layer_3': 210}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.26 | sMAPE for Validation Set is: 19.68% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 46.88 | sMAPE for Test Set is: 23.99% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:32:16,920]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:32:16,999]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:32:17,262]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:32:25,992]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:32:32,812]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:32:34,014]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:32:38,498]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:32:45,694]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:32:46,432]\u001b[0m Trial 1001 finished with value: 18.263516619280953 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020307489666618857, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00022538526986808777, 'dropout_rate_Layer_2': 0.055965708152221315, 'dropout_rate_Layer_3': 0.007278795281304828, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00232666244239812, 'l1_Layer_2': 3.848984285307774e-05, 'l1_Layer_3': 0.00035172922631276216, 'n_units_Layer_1': 145, 'n_units_Layer_2': 290, 'n_units_Layer_3': 65}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.26 | sMAPE for Validation Set is: 19.57% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.32 | sMAPE for Test Set is: 24.31% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:32:47,061]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.29 | sMAPE for Validation Set is: 19.68% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.73 | sMAPE for Test Set is: 24.41% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:32:54,271]\u001b[0m Trial 1000 finished with value: 18.291036731473117 and parameters: {'n_hidden': 3, 'learning_rate': 0.002000091040632027, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006159498781136724, 'dropout_rate_Layer_2': 0.05378980036857535, 'dropout_rate_Layer_3': 0.008076887951217188, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002285014358743923, 'l1_Layer_2': 1.817838577769285e-05, 'l1_Layer_3': 0.001625503401980484, 'n_units_Layer_1': 145, 'n_units_Layer_2': 290, 'n_units_Layer_3': 65}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:32:56,733]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:32:59,710]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:33:03,149]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:33:10,015]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:33:15,638]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.23 | sMAPE for Validation Set is: 19.67% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 46.98 | sMAPE for Test Set is: 23.89% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:33:18,126]\u001b[0m Trial 1010 finished with value: 18.225236122577105 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019224073601027485, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0011391311203319352, 'dropout_rate_Layer_2': 0.05211760505591693, 'dropout_rate_Layer_3': 0.009064359576688776, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001250261310606567, 'l1_Layer_2': 1.5891875506002332e-05, 'l1_Layer_3': 0.00038829867748111307, 'n_units_Layer_1': 150, 'n_units_Layer_2': 285, 'n_units_Layer_3': 70}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:33:26,063]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:33:30,645]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:33:31,387]\u001b[0m Trial 1011 finished with value: 18.234927927706273 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015933180783121686, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09497277924057931, 'dropout_rate_Layer_2': 0.1878286469240163, 'dropout_rate_Layer_3': 0.18258299777149598, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011577848099706336, 'l1_Layer_2': 0.004774293791688314, 'l1_Layer_3': 0.0004895160079945405, 'n_units_Layer_1': 160, 'n_units_Layer_2': 80, 'n_units_Layer_3': 210}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.23 | sMAPE for Validation Set is: 19.61% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 46.84 | sMAPE for Test Set is: 23.91% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:33:39,880]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:33:40,571]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:33:42,027]\u001b[0m Trial 1015 finished with value: 18.60016579027727 and parameters: {'n_hidden': 4, 'learning_rate': 0.004224347038529243, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07218140921386175, 'dropout_rate_Layer_2': 0.324825165488421, 'dropout_rate_Layer_3': 0.2199236450224679, 'dropout_rate_Layer_4': 0.10407945363895856, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.657228141087778e-05, 'l1_Layer_2': 0.006415401313106301, 'l1_Layer_3': 0.000627064218426595, 'l1_Layer_4': 3.798883472416736e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 125, 'n_units_Layer_3': 250, 'n_units_Layer_4': 85}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.60 | sMAPE for Validation Set is: 20.29% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 50.31 | sMAPE for Test Set is: 25.11% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:33:51,453]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:33:55,294]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:33:57,251]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:01,314]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:02,788]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:03,754]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:05,374]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:08,479]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:17,558]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:19,730]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:24,131]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:27,841]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:28,988]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.18 | sMAPE for Validation Set is: 19.70% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.02 | sMAPE for Test Set is: 24.27% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:34:33,521]\u001b[0m Trial 1027 finished with value: 18.179391841604282 and parameters: {'n_hidden': 3, 'learning_rate': 0.004279166535809102, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11018254753235875, 'dropout_rate_Layer_2': 0.05250728030900985, 'dropout_rate_Layer_3': 0.021383370841128638, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007331805870262633, 'l1_Layer_2': 0.00017198947697892123, 'l1_Layer_3': 0.003995313213187737, 'n_units_Layer_1': 110, 'n_units_Layer_2': 195, 'n_units_Layer_3': 80}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:34,792]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:41,360]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:42,654]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:46,226]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:48,102]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:49,444]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:57,342]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:57,811]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:34:58,311]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:35:08,222]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:35:11,048]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:35:14,825]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:35:16,639]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:35:23,190]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:35:23,901]\u001b[0m Trial 1042 finished with value: 19.0979707838126 and parameters: {'n_hidden': 4, 'learning_rate': 0.004156048683433527, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11411524732411565, 'dropout_rate_Layer_2': 0.27532956090618904, 'dropout_rate_Layer_3': 0.2188538048459237, 'dropout_rate_Layer_4': 0.20384920925697458, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.3440505081075703e-05, 'l1_Layer_2': 0.010210155565052902, 'l1_Layer_3': 0.00039792649876516626, 'l1_Layer_4': 4.039913296834967e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 110, 'n_units_Layer_3': 255, 'n_units_Layer_4': 105}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.10 | sMAPE for Validation Set is: 20.86% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 55.60 | sMAPE for Test Set is: 26.41% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:35:24,916]\u001b[0m Trial 1044 finished with value: 19.03488202418251 and parameters: {'n_hidden': 4, 'learning_rate': 0.004117014752400013, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19090331974640629, 'dropout_rate_Layer_2': 0.323142746923102, 'dropout_rate_Layer_3': 0.18731568515826524, 'dropout_rate_Layer_4': 0.02347700867111615, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.3051880345937505e-05, 'l1_Layer_2': 0.005099190621709875, 'l1_Layer_3': 0.00042299350836318356, 'l1_Layer_4': 1.2811085098773036e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 110, 'n_units_Layer_3': 255, 'n_units_Layer_4': 105}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.03 | sMAPE for Validation Set is: 20.60% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 53.92 | sMAPE for Test Set is: 25.97% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:35:36,270]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:35:39,847]\u001b[0m Trial 1048 finished with value: 18.282566306941778 and parameters: {'n_hidden': 3, 'learning_rate': 0.003907970225535394, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09499436581770526, 'dropout_rate_Layer_2': 0.047326946562086615, 'dropout_rate_Layer_3': 0.04219040532600803, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00048686947900314435, 'l1_Layer_2': 0.00012236220664819573, 'l1_Layer_3': 0.006896205637833452, 'n_units_Layer_1': 90, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.28 | sMAPE for Validation Set is: 19.85% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.25 | sMAPE for Test Set is: 24.31% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:35:43,312]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:35:46,987]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:35:48,692]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:35:48,936]\u001b[0m Trial 1051 finished with value: 18.185674036583645 and parameters: {'n_hidden': 3, 'learning_rate': 0.004461525122077311, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09836655387785542, 'dropout_rate_Layer_2': 0.04380885062346492, 'dropout_rate_Layer_3': 0.04547278441867056, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000829595954878186, 'l1_Layer_2': 9.579678705856329e-05, 'l1_Layer_3': 0.0029513163062879484, 'n_units_Layer_1': 105, 'n_units_Layer_2': 175, 'n_units_Layer_3': 90}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.19 | sMAPE for Validation Set is: 19.65% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 47.97 | sMAPE for Test Set is: 24.32% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:35:59,535]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:36:00,583]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:36:00,910]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:36:11,105]\u001b[0m Trial 1054 finished with value: 18.268178006008796 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037356615141748103, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09611944441462358, 'dropout_rate_Layer_2': 0.04449358104013728, 'dropout_rate_Layer_3': 0.032991660854378, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008637311248735588, 'l1_Layer_2': 0.00019024132498532054, 'l1_Layer_3': 0.002950393759495209, 'n_units_Layer_1': 100, 'n_units_Layer_2': 175, 'n_units_Layer_3': 60}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.27 | sMAPE for Validation Set is: 19.88% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.92 | sMAPE for Test Set is: 24.49% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:36:14,758]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:36:15,096]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:36:15,968]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:36:22,663]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:36:27,095]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:36:32,203]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:36:37,063]\u001b[0m Trial 1059 finished with value: 18.60173777792485 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022928519776231914, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010899523581787628, 'dropout_rate_Layer_2': 0.058130958263964506, 'dropout_rate_Layer_3': 0.015171090017939846, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003911395709209782, 'l1_Layer_2': 1.6182202952540297e-05, 'l1_Layer_3': 0.0007235551232694013, 'n_units_Layer_1': 120, 'n_units_Layer_2': 290, 'n_units_Layer_3': 85}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.60 | sMAPE for Validation Set is: 19.94% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 48.81 | sMAPE for Test Set is: 24.45% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:36:41,241]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:36:41,649]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:36:48,569]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:36:49,485]\u001b[0m Trial 1066 finished with value: 18.48178876861736 and parameters: {'n_hidden': 3, 'learning_rate': 0.004345668954148115, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09562210787620747, 'dropout_rate_Layer_2': 0.053816948946316716, 'dropout_rate_Layer_3': 0.03509959237803752, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007905480338429122, 'l1_Layer_2': 8.999504360636183e-05, 'l1_Layer_3': 0.0025632361239950425, 'n_units_Layer_1': 90, 'n_units_Layer_2': 180, 'n_units_Layer_3': 75}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:36:49,507]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.48 | sMAPE for Validation Set is: 20.25% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 49.06 | sMAPE for Test Set is: 24.61% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:36:50,177]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:37:02,823]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:37:03,113]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:37:10,980]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:37:12,084]\u001b[0m Trial 1072 finished with value: 18.362247749875603 and parameters: {'n_hidden': 3, 'learning_rate': 0.004471256031224303, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10444237419268229, 'dropout_rate_Layer_2': 0.05425136129697379, 'dropout_rate_Layer_3': 0.03445332715069526, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005379622050888359, 'l1_Layer_2': 9.63633439414318e-05, 'l1_Layer_3': 0.006954569420214371, 'n_units_Layer_1': 90, 'n_units_Layer_2': 185, 'n_units_Layer_3': 85}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.36 | sMAPE for Validation Set is: 19.92% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 50.09 | sMAPE for Test Set is: 24.86% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:37:13,043]\u001b[0m Trial 1075 finished with value: 18.735813430940638 and parameters: {'n_hidden': 3, 'learning_rate': 0.004355629761916469, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11979105795505317, 'dropout_rate_Layer_2': 0.046160668525997726, 'dropout_rate_Layer_3': 0.035948837994924515, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004755635712111309, 'l1_Layer_2': 0.00010014605948485969, 'l1_Layer_3': 0.0030906066155987526, 'n_units_Layer_1': 90, 'n_units_Layer_2': 185, 'n_units_Layer_3': 50}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.74 | sMAPE for Validation Set is: 20.61% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 48.57 | sMAPE for Test Set is: 24.53% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:37:20,919]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:37:21,449]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:37:21,781]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:37:32,015]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:37:35,231]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:37:35,720]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:37:43,734]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:37:44,576]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:37:46,755]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:37:55,658]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:37:56,722]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:38:02,322]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:38:05,378]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:38:07,403]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:38:08,947]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:38:16,762]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:38:21,354]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:38:26,399]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:38:32,048]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:38:43,246]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:38:47,115]\u001b[0m Trial 1094 finished with value: 19.116158288461982 and parameters: {'n_hidden': 4, 'learning_rate': 0.00903868000763796, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023774734958473875, 'dropout_rate_Layer_2': 0.3571233924631791, 'dropout_rate_Layer_3': 0.16869062360517995, 'dropout_rate_Layer_4': 0.10500863140470014, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.245152575789355e-05, 'l1_Layer_2': 0.007625396566181459, 'l1_Layer_3': 0.0006308553360449959, 'l1_Layer_4': 0.0001774430440539504, 'n_units_Layer_1': 135, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265, 'n_units_Layer_4': 55}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.12 | sMAPE for Validation Set is: 21.13% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 47.97 | sMAPE for Test Set is: 24.48% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:38:47,756]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:38:54,790]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:38:55,099]\u001b[0m Trial 1099 finished with value: 18.140171613826436 and parameters: {'n_hidden': 3, 'learning_rate': 0.0040197644876517995, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10445715463505241, 'dropout_rate_Layer_2': 0.05845293209785318, 'dropout_rate_Layer_3': 0.027588231452287143, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005914717410727499, 'l1_Layer_2': 7.244416309519604e-05, 'l1_Layer_3': 0.006818882129502721, 'n_units_Layer_1': 100, 'n_units_Layer_2': 160, 'n_units_Layer_3': 70}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.14 | sMAPE for Validation Set is: 19.85% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.54 | sMAPE for Test Set is: 24.40% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:38:56,746]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:39:05,389]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:39:10,462]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:39:12,429]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:39:14,103]\u001b[0m Trial 1097 finished with value: 18.822287938270712 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020821344470106523, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15480108211063098, 'dropout_rate_Layer_2': 0.2961137402383902, 'dropout_rate_Layer_3': 0.24391896889752546, 'dropout_rate_Layer_4': 0.17734033185791526, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.318477232283033e-05, 'l1_Layer_2': 0.0018041852660992874, 'l1_Layer_3': 0.004832795530300205, 'l1_Layer_4': 1.2642132452668345e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 155, 'n_units_Layer_3': 265, 'n_units_Layer_4': 55}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.82 | sMAPE for Validation Set is: 20.39% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 50.90 | sMAPE for Test Set is: 25.21% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:39:22,566]\u001b[0m Trial 1103 finished with value: 18.48439339401558 and parameters: {'n_hidden': 3, 'learning_rate': 0.0039425217948445375, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10421557960026978, 'dropout_rate_Layer_2': 0.0448396434408993, 'dropout_rate_Layer_3': 0.027519649811640866, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00055319156673922, 'l1_Layer_2': 8.470958768899354e-05, 'l1_Layer_3': 0.011403971492091186, 'n_units_Layer_1': 95, 'n_units_Layer_2': 160, 'n_units_Layer_3': 70}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.48 | sMAPE for Validation Set is: 20.03% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 48.87 | sMAPE for Test Set is: 24.52% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:39:23,181]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:39:23,597]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:39:34,429]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:39:35,604]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:39:42,846]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:39:43,243]\u001b[0m Trial 1108 finished with value: 18.367432938439 and parameters: {'n_hidden': 3, 'learning_rate': 0.0039048458567729418, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1030255435937136, 'dropout_rate_Layer_2': 0.037881846355818566, 'dropout_rate_Layer_3': 0.028668216128019546, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005867197306023817, 'l1_Layer_2': 7.731575434573934e-05, 'l1_Layer_3': 0.006673256955152419, 'n_units_Layer_1': 95, 'n_units_Layer_2': 160, 'n_units_Layer_3': 70}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.37 | sMAPE for Validation Set is: 19.88% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 48.84 | sMAPE for Test Set is: 24.51% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:39:50,272]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:39:56,211]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:39:56,686]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:40:04,525]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:40:08,922]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:40:09,485]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:40:16,278]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:40:21,051]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:40:25,355]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:40:26,482]\u001b[0m Trial 1116 finished with value: 19.27660274869681 and parameters: {'n_hidden': 4, 'learning_rate': 0.003221789308807989, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10950690889772641, 'dropout_rate_Layer_2': 0.30619370807955815, 'dropout_rate_Layer_3': 0.23605129553754917, 'dropout_rate_Layer_4': 0.14208483150001605, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.0620146651051295e-05, 'l1_Layer_2': 0.0011073979366319228, 'l1_Layer_3': 0.012984573675065291, 'l1_Layer_4': 4.4401125435725924e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 155, 'n_units_Layer_3': 50, 'n_units_Layer_4': 90}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.28 | sMAPE for Validation Set is: 21.13% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 52.18 | sMAPE for Test Set is: 25.48% | rMAE for Test Set is: 0.68\n",
      "MAE for Validation Set is: 18.06 | sMAPE for Validation Set is: 19.62% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 46.19 | sMAPE for Test Set is: 23.79% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:40:31,950]\u001b[0m Trial 1113 finished with value: 18.06124551833453 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016437119896143071, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07385448693628903, 'dropout_rate_Layer_2': 0.16886297229673852, 'dropout_rate_Layer_3': 0.1982095265129472, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011838875693012155, 'l1_Layer_2': 0.011320432039382716, 'l1_Layer_3': 0.0011279976396445, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 195}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:40:33,042]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:40:39,220]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:40:39,882]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.58 | sMAPE for Validation Set is: 21.10% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 53.79 | sMAPE for Test Set is: 26.22% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:40:46,556]\u001b[0m Trial 1124 finished with value: 19.578921081855537 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033456783097493936, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10782701281607102, 'dropout_rate_Layer_2': 0.30367730286150985, 'dropout_rate_Layer_3': 0.2337457425031106, 'dropout_rate_Layer_4': 0.1711262490971821, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.482821240163979e-05, 'l1_Layer_2': 0.018937771992046337, 'l1_Layer_3': 0.005026956762222377, 'l1_Layer_4': 1.4169345622384934e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 170, 'n_units_Layer_3': 260, 'n_units_Layer_4': 85}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:40:47,795]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:40:50,952]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:40:58,773]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:41:02,441]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:41:04,553]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:41:09,784]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:41:12,117]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:41:15,961]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:41:18,097]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:41:28,283]\u001b[0m Trial 1132 finished with value: 18.199847997074023 and parameters: {'n_hidden': 3, 'learning_rate': 0.002155254400304061, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030488266064716114, 'dropout_rate_Layer_2': 0.033780590951271845, 'dropout_rate_Layer_3': 0.021293969002926637, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018665333277483164, 'l1_Layer_2': 3.17492030599479e-05, 'l1_Layer_3': 0.0033789834080671147, 'n_units_Layer_1': 140, 'n_units_Layer_2': 295, 'n_units_Layer_3': 50}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.20 | sMAPE for Validation Set is: 19.87% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 51.25 | sMAPE for Test Set is: 25.16% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:41:32,331]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:41:35,811]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:41:40,106]\u001b[0m Trial 1139 finished with value: 18.491458267535133 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028619816648710016, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012364514819074017, 'dropout_rate_Layer_2': 0.04232339033253086, 'dropout_rate_Layer_3': 0.0370936604301072, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008381583647551698, 'l1_Layer_2': 2.6851406794983154e-05, 'l1_Layer_3': 0.00023898645714769687, 'n_units_Layer_1': 115, 'n_units_Layer_2': 275, 'n_units_Layer_3': 55}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.49 | sMAPE for Validation Set is: 20.01% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 51.37 | sMAPE for Test Set is: 25.31% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:41:46,013]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:41:46,945]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:41:53,343]\u001b[0m Trial 1142 finished with value: 18.603919211579438 and parameters: {'n_hidden': 3, 'learning_rate': 0.004453428757710052, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10602299491864775, 'dropout_rate_Layer_2': 0.04890904413516411, 'dropout_rate_Layer_3': 0.02821077997732446, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000919652562382028, 'l1_Layer_2': 9.60625438997502e-05, 'l1_Layer_3': 0.0018837266708317255, 'n_units_Layer_1': 100, 'n_units_Layer_2': 170, 'n_units_Layer_3': 65}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.60 | sMAPE for Validation Set is: 20.32% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 48.08 | sMAPE for Test Set is: 24.30% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:41:58,382]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:42:00,306]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:42:02,227]\u001b[0m Trial 1138 finished with value: 18.294564241119826 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016555329238393864, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0706180435293523, 'dropout_rate_Layer_2': 0.16111345496494991, 'dropout_rate_Layer_3': 0.20056992098663207, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012565081392165848, 'l1_Layer_2': 0.01619179686863358, 'l1_Layer_3': 0.0006049396789169672, 'n_units_Layer_1': 165, 'n_units_Layer_2': 95, 'n_units_Layer_3': 195}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.29 | sMAPE for Validation Set is: 19.78% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 47.20 | sMAPE for Test Set is: 24.05% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:42:02,467]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:42:14,294]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:42:14,737]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:42:14,849]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:42:16,183]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:42:24,972]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:42:28,277]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:42:29,928]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:42:30,362]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:42:40,564]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:42:43,636]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:42:44,512]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:42:51,017]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:42:53,957]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:43:00,139]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:43:00,906]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:43:06,567]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:43:09,435]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:43:16,039]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:43:16,175]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:43:24,140]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:43:24,175]\u001b[0m Trial 1165 finished with value: 20.155571994435192 and parameters: {'n_hidden': 4, 'learning_rate': 0.002106292988480773, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1429831700940804, 'dropout_rate_Layer_2': 0.2899183788667318, 'dropout_rate_Layer_3': 0.25610226157497973, 'dropout_rate_Layer_4': 0.15441836958358535, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.6782215048489822e-05, 'l1_Layer_2': 0.0002427088988198212, 'l1_Layer_3': 0.00033023618228734556, 'l1_Layer_4': 1.0125011096562914e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 220, 'n_units_Layer_4': 130}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.16 | sMAPE for Validation Set is: 21.85% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 67.47 | sMAPE for Test Set is: 29.92% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:43:24,525]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:43:34,794]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:43:37,832]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:43:38,046]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:43:40,453]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:43:50,806]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:43:55,202]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:43:55,514]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:43:59,694]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:44:05,629]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:44:14,418]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:44:18,095]\u001b[0m Trial 1181 finished with value: 18.70816338992874 and parameters: {'n_hidden': 3, 'learning_rate': 0.003932445757725242, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11723073139614866, 'dropout_rate_Layer_2': 0.04157928290158764, 'dropout_rate_Layer_3': 0.030854558821463852, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00046290923358680556, 'l1_Layer_2': 8.641762802358546e-05, 'l1_Layer_3': 0.003268101314766255, 'n_units_Layer_1': 105, 'n_units_Layer_2': 175, 'n_units_Layer_3': 75}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.71 | sMAPE for Validation Set is: 20.68% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 49.72 | sMAPE for Test Set is: 24.87% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:44:21,281]\u001b[0m Trial 1179 finished with value: 18.413226104493027 and parameters: {'n_hidden': 3, 'learning_rate': 0.003957891970952539, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11841330164598587, 'dropout_rate_Layer_2': 0.041746096819217725, 'dropout_rate_Layer_3': 0.031738373712921056, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00042749940929691127, 'l1_Layer_2': 8.768109495704099e-05, 'l1_Layer_3': 0.003022859810679812, 'n_units_Layer_1': 105, 'n_units_Layer_2': 175, 'n_units_Layer_3': 75}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.41 | sMAPE for Validation Set is: 20.03% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 49.79 | sMAPE for Test Set is: 24.72% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:44:22,291]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:44:28,353]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:44:32,931]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:44:36,494]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:44:38,060]\u001b[0m Trial 1177 finished with value: 17.96019408682871 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016571517591382674, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08128813201548628, 'dropout_rate_Layer_2': 0.17961741555493518, 'dropout_rate_Layer_3': 0.17386487681927768, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001800140283077939, 'l1_Layer_2': 0.0019772120532784185, 'l1_Layer_3': 0.0006886267548177459, 'n_units_Layer_1': 140, 'n_units_Layer_2': 165, 'n_units_Layer_3': 205}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.96 | sMAPE for Validation Set is: 19.52% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 46.55 | sMAPE for Test Set is: 23.73% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:44:43,617]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:44:43,830]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:44:51,979]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:44:52,086]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:45:01,522]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:45:01,587]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:45:11,012]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:45:11,214]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:45:11,631]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:45:12,653]\u001b[0m Trial 1188 finished with value: 18.416937433319163 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018718598013855467, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06204056009357759, 'dropout_rate_Layer_2': 0.15693222472284732, 'dropout_rate_Layer_3': 0.1606313411946291, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016447325155624216, 'l1_Layer_2': 0.053625173907394866, 'l1_Layer_3': 0.0006695208960798537, 'n_units_Layer_1': 140, 'n_units_Layer_2': 85, 'n_units_Layer_3': 270}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.42 | sMAPE for Validation Set is: 19.80% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 46.74 | sMAPE for Test Set is: 24.02% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:45:23,531]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:45:26,044]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:45:32,122]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:45:33,745]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:45:39,645]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:45:40,919]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:45:41,039]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:45:41,919]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:45:54,200]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:45:55,289]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:45:58,218]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:46:05,518]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:46:10,838]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:46:14,992]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:46:18,594]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:46:23,454]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:46:23,904]\u001b[0m Trial 1209 finished with value: 18.500542994380222 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036727448832165276, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11221003010374322, 'dropout_rate_Layer_2': 0.02596541883336807, 'dropout_rate_Layer_3': 0.01547743901858347, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012850380795433852, 'l1_Layer_2': 0.00012119529958137061, 'l1_Layer_3': 0.003576249827177892, 'n_units_Layer_1': 110, 'n_units_Layer_2': 175, 'n_units_Layer_3': 95}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.50 | sMAPE for Validation Set is: 19.98% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 48.94 | sMAPE for Test Set is: 24.61% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:46:25,295]\u001b[0m Trial 1210 finished with value: 18.751056082563917 and parameters: {'n_hidden': 4, 'learning_rate': 0.005314442791518868, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06428750329177171, 'dropout_rate_Layer_2': 0.34081415880911786, 'dropout_rate_Layer_3': 0.21403168999562472, 'dropout_rate_Layer_4': 0.03682241037069821, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.2650004382431161e-05, 'l1_Layer_2': 0.01328091913833746, 'l1_Layer_3': 0.0008528772660440785, 'l1_Layer_4': 4.419030041531044e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 130, 'n_units_Layer_3': 245, 'n_units_Layer_4': 80}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.75 | sMAPE for Validation Set is: 20.63% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 47.22 | sMAPE for Test Set is: 24.19% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:46:34,873]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:46:41,158]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:46:46,201]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:46:48,127]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:46:53,228]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:46:54,740]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:47:01,356]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:47:06,012]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:47:06,933]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:47:12,575]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:47:14,428]\u001b[0m Trial 1222 finished with value: 18.353317505705068 and parameters: {'n_hidden': 3, 'learning_rate': 0.003091034021667122, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12107843484413981, 'dropout_rate_Layer_2': 0.0264090728141345, 'dropout_rate_Layer_3': 0.011714183733063937, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014906261328161334, 'l1_Layer_2': 0.00023340454143915956, 'l1_Layer_3': 0.004426549613258003, 'n_units_Layer_1': 100, 'n_units_Layer_2': 170, 'n_units_Layer_3': 90}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.35 | sMAPE for Validation Set is: 19.73% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 47.71 | sMAPE for Test Set is: 24.21% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:47:22,514]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:47:22,703]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:47:30,565]\u001b[0m Trial 1227 finished with value: 18.41468459616826 and parameters: {'n_hidden': 3, 'learning_rate': 0.003982618740969597, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13338273811214302, 'dropout_rate_Layer_2': 0.029709762397794028, 'dropout_rate_Layer_3': 0.012398880696961387, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005163973480163226, 'l1_Layer_2': 0.00022208458100348653, 'l1_Layer_3': 0.0041240654000425135, 'n_units_Layer_1': 115, 'n_units_Layer_2': 160, 'n_units_Layer_3': 70}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.41 | sMAPE for Validation Set is: 20.08% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 49.79 | sMAPE for Test Set is: 24.79% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:47:31,373]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:47:32,105]\u001b[0m Trial 1218 finished with value: 17.93691463018041 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012628880508188678, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08493734899640662, 'dropout_rate_Layer_2': 0.21348542353307104, 'dropout_rate_Layer_3': 0.17003199699258933, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001339202643011183, 'l1_Layer_2': 0.001360304570226025, 'l1_Layer_3': 0.0008723093011264221, 'n_units_Layer_1': 185, 'n_units_Layer_2': 230, 'n_units_Layer_3': 180}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.94 | sMAPE for Validation Set is: 19.49% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 47.28 | sMAPE for Test Set is: 23.94% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:47:32,316]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:47:41,765]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:47:45,146]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:47:48,534]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:47:52,957]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:48:01,162]\u001b[0m Trial 1235 finished with value: 18.639175722283802 and parameters: {'n_hidden': 4, 'learning_rate': 0.005924965143801534, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07929685075475662, 'dropout_rate_Layer_2': 0.18943584404368383, 'dropout_rate_Layer_3': 0.1959419552786929, 'dropout_rate_Layer_4': 0.03861858763838415, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.2287425323027402e-05, 'l1_Layer_2': 0.013372932051005551, 'l1_Layer_3': 0.0014747615752738568, 'l1_Layer_4': 1.9400315833681183e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 130, 'n_units_Layer_3': 260, 'n_units_Layer_4': 75}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.64 | sMAPE for Validation Set is: 20.41% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 49.88 | sMAPE for Test Set is: 24.94% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:48:06,099]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:48:12,988]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:48:17,390]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:48:19,096]\u001b[0m Trial 1233 finished with value: 17.842101208408895 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014343331861190558, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07540518167936566, 'dropout_rate_Layer_2': 0.2134431038098375, 'dropout_rate_Layer_3': 0.1941130614595545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021363865183516534, 'l1_Layer_2': 0.0015056289451023533, 'l1_Layer_3': 0.0004409740001901005, 'n_units_Layer_1': 175, 'n_units_Layer_2': 265, 'n_units_Layer_3': 190}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.84 | sMAPE for Validation Set is: 19.47% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 45.84 | sMAPE for Test Set is: 23.51% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:48:23,392]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:48:30,909]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:48:32,128]\u001b[0m Trial 1238 finished with value: 17.873071743940287 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009557885575179556, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07740411960950494, 'dropout_rate_Layer_2': 0.21514242631353866, 'dropout_rate_Layer_3': 0.19313686082161727, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016171782412048863, 'l1_Layer_2': 0.001820186425431278, 'l1_Layer_3': 0.00041774299708527353, 'n_units_Layer_1': 145, 'n_units_Layer_2': 245, 'n_units_Layer_3': 195}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.87 | sMAPE for Validation Set is: 19.41% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 45.85 | sMAPE for Test Set is: 23.57% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:48:38,434]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:48:38,985]\u001b[0m Trial 1239 finished with value: 17.895146716560067 and parameters: {'n_hidden': 3, 'learning_rate': 0.001438265763831805, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07413465879643073, 'dropout_rate_Layer_2': 0.21086886634158836, 'dropout_rate_Layer_3': 0.18819417245687015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002100452876190724, 'l1_Layer_2': 0.0014693724559238356, 'l1_Layer_3': 0.0004045325116435179, 'n_units_Layer_1': 145, 'n_units_Layer_2': 225, 'n_units_Layer_3': 195}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.90 | sMAPE for Validation Set is: 19.38% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 46.17 | sMAPE for Test Set is: 23.67% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:48:39,528]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:48:49,205]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:48:51,068]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:48:55,273]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:49:00,311]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:49:03,506]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:49:06,895]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:49:10,049]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:49:17,662]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:49:18,873]\u001b[0m Trial 1248 finished with value: 18.076439949991094 and parameters: {'n_hidden': 3, 'learning_rate': 0.00318470350929159, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13089790384666752, 'dropout_rate_Layer_2': 0.059399610750126466, 'dropout_rate_Layer_3': 0.008904532620481595, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006624023263225987, 'l1_Layer_2': 0.00018820534301791514, 'l1_Layer_3': 0.008557726291394516, 'n_units_Layer_1': 100, 'n_units_Layer_2': 170, 'n_units_Layer_3': 65}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.08 | sMAPE for Validation Set is: 19.67% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.35 | sMAPE for Test Set is: 24.30% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:49:19,705]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:49:25,422]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:49:28,531]\u001b[0m Trial 1244 finished with value: 17.84638734458323 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009745861164541075, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08173730578872876, 'dropout_rate_Layer_2': 0.2036760704501771, 'dropout_rate_Layer_3': 0.19159403047463344, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021139804353823726, 'l1_Layer_2': 0.0014125966915544581, 'l1_Layer_3': 0.0004229893935411306, 'n_units_Layer_1': 175, 'n_units_Layer_2': 250, 'n_units_Layer_3': 190}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.85 | sMAPE for Validation Set is: 19.48% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 45.41 | sMAPE for Test Set is: 23.42% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:49:30,381]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:49:35,387]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:49:40,394]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:49:43,582]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:49:50,117]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:49:50,219]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:49:57,369]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:50:00,905]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:50:03,652]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:50:05,157]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:50:12,434]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:50:13,668]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:50:15,668]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:50:17,851]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:50:19,526]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:50:29,157]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:50:31,161]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:50:35,280]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:50:37,960]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:50:44,414]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:50:50,642]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:50:54,561]\u001b[0m Trial 1280 finished with value: 18.949093596327018 and parameters: {'n_hidden': 4, 'learning_rate': 0.00797176975527723, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05747950771073729, 'dropout_rate_Layer_2': 0.16688239834398333, 'dropout_rate_Layer_3': 0.18060832753469294, 'dropout_rate_Layer_4': 0.035381912907145485, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.626049268684965e-05, 'l1_Layer_2': 0.0064898576026990755, 'l1_Layer_3': 0.001507957156810552, 'l1_Layer_4': 4.38442637687821e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 115, 'n_units_Layer_3': 145, 'n_units_Layer_4': 95}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.95 | sMAPE for Validation Set is: 20.61% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 55.74 | sMAPE for Test Set is: 26.45% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:51:00,164]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:51:03,147]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:51:06,438]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:51:11,196]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:51:12,037]\u001b[0m Trial 1282 finished with value: 18.662248231161467 and parameters: {'n_hidden': 4, 'learning_rate': 0.005198878505437965, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06234739917277027, 'dropout_rate_Layer_2': 0.1706247989677569, 'dropout_rate_Layer_3': 0.14976978583925005, 'dropout_rate_Layer_4': 0.03526158990559923, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.6258917421906055e-05, 'l1_Layer_2': 0.02685696888655704, 'l1_Layer_3': 0.0016671407274507406, 'l1_Layer_4': 4.918600469933555e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 125, 'n_units_Layer_3': 255, 'n_units_Layer_4': 95}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.66 | sMAPE for Validation Set is: 20.25% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 49.79 | sMAPE for Test Set is: 24.88% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:51:17,061]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:51:23,433]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:51:25,913]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.01 | sMAPE for Validation Set is: 19.54% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 46.42 | sMAPE for Test Set is: 23.85% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:51:27,461]\u001b[0m Trial 1276 finished with value: 18.011568326967833 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010704591903883645, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07683130644445252, 'dropout_rate_Layer_2': 0.2345835454222326, 'dropout_rate_Layer_3': 0.20326893799344226, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0034729200956564905, 'l1_Layer_2': 0.0017559639167374344, 'l1_Layer_3': 0.0015001982271213032, 'n_units_Layer_1': 145, 'n_units_Layer_2': 265, 'n_units_Layer_3': 190}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:51:34,713]\u001b[0m Trial 1289 finished with value: 18.655641050907047 and parameters: {'n_hidden': 3, 'learning_rate': 0.004106455764056294, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08809446975905366, 'dropout_rate_Layer_2': 0.048150874249345006, 'dropout_rate_Layer_3': 0.03280788923940926, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004725285079036639, 'l1_Layer_2': 0.00018051406198436805, 'l1_Layer_3': 0.005779641588427171, 'n_units_Layer_1': 110, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.66 | sMAPE for Validation Set is: 20.29% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 50.65 | sMAPE for Test Set is: 24.99% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:51:38,441]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:51:42,063]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:51:43,681]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:51:46,731]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:51:49,690]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:51:56,276]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:51:57,111]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:52:04,441]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:52:09,377]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:52:09,416]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:52:09,663]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:52:15,425]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:52:21,119]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:52:24,411]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:52:30,682]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:52:31,251]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:52:39,327]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:52:41,041]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:52:41,978]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:52:45,099]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:52:51,118]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:52:53,001]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:52:54,653]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:53:02,070]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:53:04,546]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:53:06,682]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:53:17,161]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:53:18,910]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:53:25,271]\u001b[0m Trial 1297 finished with value: 17.97686990317908 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007290865590729189, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04080186232934203, 'dropout_rate_Layer_2': 0.24813316124422416, 'dropout_rate_Layer_3': 0.200427228076236, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002006065823240647, 'l1_Layer_2': 0.0015591472573195512, 'l1_Layer_3': 0.0008917154065418854, 'n_units_Layer_1': 120, 'n_units_Layer_2': 270, 'n_units_Layer_3': 200}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:53:25,322]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.98 | sMAPE for Validation Set is: 19.58% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 45.48 | sMAPE for Test Set is: 23.46% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:53:37,557]\u001b[0m Trial 1321 finished with value: 18.820313979456103 and parameters: {'n_hidden': 4, 'learning_rate': 0.011253073930255937, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05258716978590507, 'dropout_rate_Layer_2': 0.189747433523782, 'dropout_rate_Layer_3': 0.15016106615102054, 'dropout_rate_Layer_4': 0.057846949409447734, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.1782402842537336e-05, 'l1_Layer_2': 0.021797784263275867, 'l1_Layer_3': 0.001333436305934381, 'l1_Layer_4': 9.48207274650466e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 105, 'n_units_Layer_3': 175, 'n_units_Layer_4': 65}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.82 | sMAPE for Validation Set is: 20.45% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 52.64 | sMAPE for Test Set is: 25.62% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:53:44,351]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.94 | sMAPE for Validation Set is: 20.29% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 49.63 | sMAPE for Test Set is: 24.92% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:53:47,466]\u001b[0m Trial 1323 finished with value: 18.9398725028189 and parameters: {'n_hidden': 4, 'learning_rate': 0.008120942992821905, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06579738953628855, 'dropout_rate_Layer_2': 0.3359634056163648, 'dropout_rate_Layer_3': 0.21220170492496954, 'dropout_rate_Layer_4': 0.05768147545669497, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.365808970758031e-05, 'l1_Layer_2': 0.012747880353106728, 'l1_Layer_3': 0.0008996490973922754, 'l1_Layer_4': 8.534891558283249e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 100, 'n_units_Layer_3': 285, 'n_units_Layer_4': 240}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:53:52,997]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:53:55,680]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:53:59,810]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:54:01,865]\u001b[0m Trial 1320 finished with value: 17.940125973602026 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014096724311056593, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.038691347039139935, 'dropout_rate_Layer_2': 0.23268467262279424, 'dropout_rate_Layer_3': 0.19933497001698386, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0023458226406750486, 'l1_Layer_2': 0.0012243722737942707, 'l1_Layer_3': 0.0010234080887695433, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 195}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.94 | sMAPE for Validation Set is: 19.42% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 45.96 | sMAPE for Test Set is: 23.66% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:54:02,434]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:54:02,854]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:54:06,160]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:54:19,929]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:54:24,772]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:54:28,296]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:54:30,109]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:54:32,085]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:54:33,553]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:54:40,922]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:54:44,126]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:54:46,691]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:55:07,920]\u001b[0m Trial 1342 finished with value: 18.134535482826625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034738096121429887, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007067774884863306, 'dropout_rate_Layer_2': 0.03488062096281058, 'dropout_rate_Layer_3': 0.015515193724111895, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015259644183431827, 'l1_Layer_2': 3.7283088858820735e-05, 'l1_Layer_3': 3.238082514063732e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 300, 'n_units_Layer_3': 70}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.13 | sMAPE for Validation Set is: 19.83% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.42 | sMAPE for Test Set is: 24.22% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:55:11,956]\u001b[0m Trial 1343 finished with value: 18.552302849696783 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032986357987587586, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03258570944743926, 'dropout_rate_Layer_2': 0.03260386064221442, 'dropout_rate_Layer_3': 0.01459576809446987, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001553782703403421, 'l1_Layer_2': 4.1369696415283944e-05, 'l1_Layer_3': 3.2159697887476936e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 300, 'n_units_Layer_3': 70}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.55 | sMAPE for Validation Set is: 19.75% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 52.15 | sMAPE for Test Set is: 25.38% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:55:17,446]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:55:21,233]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:55:24,551]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.95 | sMAPE for Validation Set is: 19.45% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 45.30 | sMAPE for Test Set is: 23.37% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:55:28,102]\u001b[0m Trial 1332 finished with value: 17.953990162622105 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008926091638281158, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.059839152066372754, 'dropout_rate_Layer_2': 0.23021659956357945, 'dropout_rate_Layer_3': 0.18724756414372223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0030286002639811006, 'l1_Layer_2': 0.001954150484324751, 'l1_Layer_3': 0.0010283830131815168, 'n_units_Layer_1': 120, 'n_units_Layer_2': 230, 'n_units_Layer_3': 205}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:55:34,141]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:55:39,543]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:55:45,157]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.69 | sMAPE for Validation Set is: 20.40% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 45.22 | sMAPE for Test Set is: 23.56% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:55:49,358]\u001b[0m Trial 1347 finished with value: 18.6923501492701 and parameters: {'n_hidden': 4, 'learning_rate': 0.005733429238666752, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07529746288707953, 'dropout_rate_Layer_2': 0.20611284658922935, 'dropout_rate_Layer_3': 0.04146577293937834, 'dropout_rate_Layer_4': 0.03487867324414216, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.7719674924358346e-05, 'l1_Layer_2': 0.008778715466254, 'l1_Layer_3': 0.0007287730071948712, 'l1_Layer_4': 3.175149464611962e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 145, 'n_units_Layer_3': 250, 'n_units_Layer_4': 110}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:55:51,925]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:55:54,007]\u001b[0m Trial 1341 finished with value: 17.963000201060115 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006206626893883656, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028704762252382797, 'dropout_rate_Layer_2': 0.25282478951782306, 'dropout_rate_Layer_3': 0.18702839068854585, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0030572214877621767, 'l1_Layer_2': 0.0011660681380968488, 'l1_Layer_3': 0.0010222913775484051, 'n_units_Layer_1': 140, 'n_units_Layer_2': 290, 'n_units_Layer_3': 205}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.96 | sMAPE for Validation Set is: 19.44% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 45.19 | sMAPE for Test Set is: 23.37% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:55:55,133]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:56:03,329]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:56:09,385]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:56:10,767]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:56:13,968]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:56:16,512]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:56:21,987]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:56:26,095]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:56:29,099]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:56:29,214]\u001b[0m Trial 1348 finished with value: 18.0798767220197 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006853179934647242, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028136397886073014, 'dropout_rate_Layer_2': 0.264348129437781, 'dropout_rate_Layer_3': 0.15337899163843238, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004193581313834293, 'l1_Layer_2': 0.001063349248625021, 'l1_Layer_3': 0.0010318926445829417, 'n_units_Layer_1': 120, 'n_units_Layer_2': 205, 'n_units_Layer_3': 205}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.08 | sMAPE for Validation Set is: 19.72% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 45.84 | sMAPE for Test Set is: 23.64% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:56:30,104]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:56:41,980]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:56:42,129]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:56:42,376]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:56:51,113]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:56:52,895]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:56:53,638]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:57:03,767]\u001b[0m Trial 1366 finished with value: 18.793207727402063 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032458834460592995, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09736735905612899, 'dropout_rate_Layer_2': 0.03883821903569715, 'dropout_rate_Layer_3': 0.0006475685288306315, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003211347462017946, 'l1_Layer_2': 0.00020231483508599546, 'l1_Layer_3': 0.003224402098432593, 'n_units_Layer_1': 105, 'n_units_Layer_2': 180, 'n_units_Layer_3': 100}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.79 | sMAPE for Validation Set is: 20.31% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 53.83 | sMAPE for Test Set is: 25.87% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:57:09,905]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:57:12,734]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:57:17,182]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:57:17,696]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:57:17,811]\u001b[0m Trial 1370 finished with value: 18.384339281962127 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033957884218888063, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11574190009609178, 'dropout_rate_Layer_2': 0.023641837980436387, 'dropout_rate_Layer_3': 0.015120984891592432, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007445196329175011, 'l1_Layer_2': 9.973239388048288e-05, 'l1_Layer_3': 0.002503381924556443, 'n_units_Layer_1': 100, 'n_units_Layer_2': 165, 'n_units_Layer_3': 75}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.38 | sMAPE for Validation Set is: 20.06% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 47.56 | sMAPE for Test Set is: 24.20% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:57:27,454]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:57:28,876]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:57:29,129]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:57:29,319]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:57:41,237]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:57:44,368]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:57:47,315]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:57:50,690]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:57:55,430]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:58:01,599]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:58:04,455]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:58:09,342]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:58:09,868]\u001b[0m Trial 1382 finished with value: 18.267209168945612 and parameters: {'n_hidden': 3, 'learning_rate': 0.002647248705404323, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12842384302117227, 'dropout_rate_Layer_2': 0.03284729465200875, 'dropout_rate_Layer_3': 0.019619172853872203, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008887154229338443, 'l1_Layer_2': 7.274581660148306e-05, 'l1_Layer_3': 0.004336104578415051, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 85}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.27 | sMAPE for Validation Set is: 19.85% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 48.98 | sMAPE for Test Set is: 24.53% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:58:11,045]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:58:11,261]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:58:19,992]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:58:28,887]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:58:28,919]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:58:30,997]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:58:38,031]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:58:40,602]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:58:42,220]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:58:42,623]\u001b[0m Trial 1390 finished with value: 18.461686313130116 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025513012564299634, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1532392001123604, 'dropout_rate_Layer_2': 0.01095507539842517, 'dropout_rate_Layer_3': 0.009082241099328252, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007545749447151968, 'l1_Layer_2': 5.794469690537486e-05, 'l1_Layer_3': 0.005856133097298183, 'n_units_Layer_1': 120, 'n_units_Layer_2': 160, 'n_units_Layer_3': 70}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.46 | sMAPE for Validation Set is: 20.03% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 48.51 | sMAPE for Test Set is: 24.39% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:58:50,501]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:58:57,720]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:58:58,675]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:59:00,750]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:59:07,674]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:59:09,012]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:59:11,162]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:59:19,030]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:59:21,281]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:59:22,799]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:59:22,816]\u001b[0m Trial 1398 finished with value: 18.694556486841908 and parameters: {'n_hidden': 4, 'learning_rate': 0.004610575457280969, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04338580370989811, 'dropout_rate_Layer_2': 0.21202572822301657, 'dropout_rate_Layer_3': 0.0565148432925412, 'dropout_rate_Layer_4': 0.04181545819903934, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0314355074248932e-05, 'l1_Layer_2': 0.019325254218389182, 'l1_Layer_3': 0.0005588725502416648, 'l1_Layer_4': 2.700036539803842e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 145, 'n_units_Layer_3': 245, 'n_units_Layer_4': 75}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.69 | sMAPE for Validation Set is: 20.53% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 53.54 | sMAPE for Test Set is: 25.82% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 07:59:27,052]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:59:32,409]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:59:40,164]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:59:40,297]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:59:41,095]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:59:45,013]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:59:51,340]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:59:54,642]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 07:59:55,652]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:00:02,383]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:00:08,020]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:00:09,729]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:00:11,323]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:00:20,802]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:00:22,389]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:00:24,953]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:00:31,478]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:00:34,067]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:00:41,802]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:00:56,055]\u001b[0m Trial 1430 finished with value: 18.318251052062607 and parameters: {'n_hidden': 3, 'learning_rate': 0.003185202665326029, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12526556032908526, 'dropout_rate_Layer_2': 0.06301979838224941, 'dropout_rate_Layer_3': 0.016192619315435218, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001117555449665034, 'l1_Layer_2': 0.00012981122667452124, 'l1_Layer_3': 0.005027672094363448, 'n_units_Layer_1': 105, 'n_units_Layer_2': 170, 'n_units_Layer_3': 80}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.32 | sMAPE for Validation Set is: 19.97% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 47.96 | sMAPE for Test Set is: 24.25% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 08:01:01,771]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:01:06,316]\u001b[0m Trial 1431 finished with value: 18.22192919659215 and parameters: {'n_hidden': 4, 'learning_rate': 0.0036461031775007436, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03329152885668683, 'dropout_rate_Layer_2': 0.21078474604475417, 'dropout_rate_Layer_3': 0.03221264548551049, 'dropout_rate_Layer_4': 0.04553102437618847, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.775069358175792e-05, 'l1_Layer_2': 0.019428640258150186, 'l1_Layer_3': 0.00037198875400408916, 'l1_Layer_4': 0.005407558315160887, 'n_units_Layer_1': 70, 'n_units_Layer_2': 145, 'n_units_Layer_3': 240, 'n_units_Layer_4': 100}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.22 | sMAPE for Validation Set is: 19.87% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 51.30 | sMAPE for Test Set is: 25.24% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 08:01:09,365]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:01:12,718]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:01:17,105]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:01:20,267]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:01:25,552]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.03 | sMAPE for Validation Set is: 19.52% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 45.89 | sMAPE for Test Set is: 23.59% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 08:01:28,639]\u001b[0m Trial 1426 finished with value: 18.02933842032981 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007220709713943829, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05150593699726796, 'dropout_rate_Layer_2': 0.22838237388944396, 'dropout_rate_Layer_3': 0.1241933223971148, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016393337253237036, 'l1_Layer_2': 0.0011168138826157677, 'l1_Layer_3': 0.0016943816713556046, 'n_units_Layer_1': 145, 'n_units_Layer_2': 285, 'n_units_Layer_3': 200}. Best is trial 802 with value: 17.830233529648524.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:01:32,761]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:01:38,251]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:01:38,669]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:01:47,585]\u001b[0m Trial 1429 finished with value: 17.712942283983782 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005812476990690648, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04327011061839313, 'dropout_rate_Layer_2': 0.23150912081051514, 'dropout_rate_Layer_3': 0.15673911956415768, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014397772632009909, 'l1_Layer_2': 0.000730519649239848, 'l1_Layer_3': 0.0017093901480925388, 'n_units_Layer_1': 145, 'n_units_Layer_2': 200, 'n_units_Layer_3': 200}. Best is trial 1429 with value: 17.712942283983782.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.71 | sMAPE for Validation Set is: 19.23% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 45.02 | sMAPE for Test Set is: 23.24% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 08:01:47,812]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:01:54,256]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:01:54,343]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:01:55,584]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:02:05,711]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:02:10,295]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:02:14,174]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:02:19,229]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:02:19,387]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:02:29,268]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:02:29,727]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:02:36,221]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:02:42,363]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:02:47,031]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:02:47,550]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:02:54,258]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:02:55,974]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:03:01,886]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:03:05,809]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:03:11,717]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:03:17,951]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:03:23,314]\u001b[0m Trial 1447 finished with value: 17.799128145869663 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005770409284764122, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04660752420377076, 'dropout_rate_Layer_2': 0.2617322985919189, 'dropout_rate_Layer_3': 0.17084119119721353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010351570004493828, 'l1_Layer_2': 0.0009729061105001215, 'l1_Layer_3': 0.0014944902181926068, 'n_units_Layer_1': 180, 'n_units_Layer_2': 300, 'n_units_Layer_3': 195}. Best is trial 1429 with value: 17.712942283983782.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.80 | sMAPE for Validation Set is: 19.34% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 45.62 | sMAPE for Test Set is: 23.44% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 08:03:23,386]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.80 | sMAPE for Validation Set is: 19.30% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 45.70 | sMAPE for Test Set is: 23.47% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 08:03:27,482]\u001b[0m Trial 1444 finished with value: 17.797353314811733 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005457823681523111, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04827225529014602, 'dropout_rate_Layer_2': 0.23182127034500494, 'dropout_rate_Layer_3': 0.1260089975404405, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013882102018390715, 'l1_Layer_2': 0.001062639953986149, 'l1_Layer_3': 0.001455137555830807, 'n_units_Layer_1': 140, 'n_units_Layer_2': 220, 'n_units_Layer_3': 185}. Best is trial 1429 with value: 17.712942283983782.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:03:33,547]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:03:34,376]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:03:35,445]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:03:35,985]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:03:47,824]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:03:50,737]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:03:52,023]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:03:58,009]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:04:01,600]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:04:06,915]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:04:08,204]\u001b[0m Trial 1471 finished with value: 18.319413640752185 and parameters: {'n_hidden': 3, 'learning_rate': 0.006036192273037753, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.051032320379785855, 'dropout_rate_Layer_2': 0.20481046087476423, 'dropout_rate_Layer_3': 0.04223840044072874, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0824263467186439e-05, 'l1_Layer_2': 0.016232707132220362, 'l1_Layer_3': 0.00017764098898436417, 'n_units_Layer_1': 225, 'n_units_Layer_2': 145, 'n_units_Layer_3': 225}. Best is trial 1429 with value: 17.712942283983782.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.32 | sMAPE for Validation Set is: 20.11% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 49.71 | sMAPE for Test Set is: 24.79% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 08:04:17,680]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:04:21,854]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:04:24,319]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:04:25,414]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:04:34,414]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:04:34,641]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:04:53,300]\u001b[0m Trial 1485 finished with value: 18.27985290800837 and parameters: {'n_hidden': 3, 'learning_rate': 0.007361752714713805, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03505904720764355, 'dropout_rate_Layer_2': 0.20447575853632194, 'dropout_rate_Layer_3': 0.07939201107187312, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0259901352800128e-05, 'l1_Layer_2': 0.02616450255545981, 'l1_Layer_3': 0.0001411049426467314, 'n_units_Layer_1': 90, 'n_units_Layer_2': 115, 'n_units_Layer_3': 215}. Best is trial 1429 with value: 17.712942283983782.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.28 | sMAPE for Validation Set is: 20.40% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 45.06 | sMAPE for Test Set is: 23.55% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 08:04:56,071]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:04:57,051]\u001b[0m Trial 1476 finished with value: 17.97166711765073 and parameters: {'n_hidden': 3, 'learning_rate': 0.000562899283430786, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.046149091902239134, 'dropout_rate_Layer_2': 0.219138003927191, 'dropout_rate_Layer_3': 0.12193472425610832, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008130765742570556, 'l1_Layer_2': 0.0007025393553773896, 'l1_Layer_3': 0.001521012393846123, 'n_units_Layer_1': 140, 'n_units_Layer_2': 295, 'n_units_Layer_3': 185}. Best is trial 1429 with value: 17.712942283983782.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.97 | sMAPE for Validation Set is: 19.58% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 46.12 | sMAPE for Test Set is: 23.68% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 08:05:04,984]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:05:05,459]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:05:06,212]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:05:14,817]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:05:17,536]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:05:17,608]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:05:23,504]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:05:28,609]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:05:31,315]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:05:35,492]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:05:37,152]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:05:44,757]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:05:45,898]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 08:05:48,896]\u001b[0m Trial 1481 finished with value: 17.98229582711971 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005607959821336679, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04847803689926383, 'dropout_rate_Layer_2': 0.2212371967243891, 'dropout_rate_Layer_3': 0.11694449589025915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014589703133639747, 'l1_Layer_2': 0.0007237036451978325, 'l1_Layer_3': 0.0015514032242534225, 'n_units_Layer_1': 180, 'n_units_Layer_2': 295, 'n_units_Layer_3': 170}. Best is trial 1429 with value: 17.712942283983782.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.98 | sMAPE for Validation Set is: 19.45% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 46.18 | sMAPE for Test Set is: 23.63% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 08:05:50,371]\u001b[0m Trial 1497 finished with value: 18.6282360566173 and parameters: {'n_hidden': 3, 'learning_rate': 0.004223288708045312, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10059414480433734, 'dropout_rate_Layer_2': 0.0522200316705141, 'dropout_rate_Layer_3': 0.023503508870643897, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006463704018645611, 'l1_Layer_2': 0.00017834696004110091, 'l1_Layer_3': 0.0022433791414529967, 'n_units_Layer_1': 90, 'n_units_Layer_2': 185, 'n_units_Layer_3': 70}. Best is trial 1429 with value: 17.712942283983782.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.63 | sMAPE for Validation Set is: 20.41% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 53.25 | sMAPE for Test Set is: 25.68% | rMAE for Test Set is: 0.70\n",
      "for 2022-01-01, MAE is:29.30 & sMAPE is:33.77% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :29.30 & 33.77% & 0.29\n",
      "for 2022-01-02, MAE is:42.85 & sMAPE is:57.66% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :36.08 & 45.71% & 0.31\n",
      "for 2022-01-03, MAE is:55.76 & sMAPE is:89.10% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :42.64 & 60.18% & 0.45\n",
      "for 2022-01-04, MAE is:53.86 & sMAPE is:39.13% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :45.44 & 54.91% & 0.60\n",
      "for 2022-01-05, MAE is:70.95 & sMAPE is:41.97% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :50.54 & 52.32% & 0.87\n",
      "for 2022-01-06, MAE is:81.50 & sMAPE is:44.34% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :55.70 & 50.99% & 0.84\n",
      "for 2022-01-07, MAE is:62.19 & sMAPE is:32.72% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :56.63 & 48.38% & 0.79\n",
      "for 2022-01-08, MAE is:17.70 & sMAPE is:9.59% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :51.77 & 43.53% & 0.72\n",
      "for 2022-01-09, MAE is:52.37 & sMAPE is:38.37% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :51.83 & 42.96% & 0.70\n",
      "for 2022-01-10, MAE is:88.71 & sMAPE is:39.54% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :55.52 & 42.62% & 0.68\n",
      "for 2022-01-11, MAE is:35.01 & sMAPE is:14.83% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :53.66 & 40.09% & 0.66\n",
      "for 2022-01-12, MAE is:34.04 & sMAPE is:14.85% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :52.02 & 37.99% & 0.66\n",
      "for 2022-01-13, MAE is:22.25 & sMAPE is:11.24% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :49.73 & 35.93% & 0.66\n",
      "for 2022-01-14, MAE is:24.71 & sMAPE is:12.80% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :47.94 & 34.28% & 0.65\n",
      "for 2022-01-15, MAE is:36.92 & sMAPE is:18.87% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :47.21 & 33.25% & 0.70\n",
      "for 2022-01-16, MAE is:25.78 & sMAPE is:13.37% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :45.87 & 32.01% & 0.68\n",
      "for 2022-01-17, MAE is:21.41 & sMAPE is:10.15% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :44.43 & 30.72% & 0.67\n",
      "for 2022-01-18, MAE is:36.28 & sMAPE is:16.30% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :43.98 & 29.92% & 0.68\n",
      "for 2022-01-19, MAE is:28.97 & sMAPE is:15.57% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :43.19 & 29.17% & 0.68\n",
      "for 2022-01-20, MAE is:23.20 & sMAPE is:14.41% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :42.19 & 28.43% & 0.68\n",
      "for 2022-01-21, MAE is:19.10 & sMAPE is:11.32% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :41.09 & 27.61% & 0.68\n",
      "for 2022-01-22, MAE is:24.84 & sMAPE is:14.62% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :40.35 & 27.02% & 0.69\n",
      "for 2022-01-23, MAE is:25.19 & sMAPE is:13.97% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :39.69 & 26.46% & 0.72\n",
      "for 2022-01-24, MAE is:61.60 & sMAPE is:27.40% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :40.61 & 26.50% & 0.75\n",
      "for 2022-01-25, MAE is:66.06 & sMAPE is:23.89% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :41.62 & 26.39% & 0.76\n",
      "for 2022-01-26, MAE is:23.01 & sMAPE is:10.38% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :40.91 & 25.78% & 0.75\n",
      "for 2022-01-27, MAE is:35.08 & sMAPE is:18.61% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :40.69 & 25.51% & 0.76\n",
      "for 2022-01-28, MAE is:44.76 & sMAPE is:21.77% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :40.84 & 25.38% & 0.76\n",
      "for 2022-01-29, MAE is:41.16 & sMAPE is:30.37% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :40.85 & 25.55% & 0.77\n",
      "for 2022-01-30, MAE is:40.50 & sMAPE is:24.87% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :40.84 & 25.53% & 0.78\n",
      "for 2022-01-31, MAE is:30.52 & sMAPE is:16.85% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :40.50 & 25.25% & 0.77\n",
      "for 2022-02-01, MAE is:28.29 & sMAPE is:14.75% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :40.12 & 24.92% & 0.76\n",
      "for 2022-02-02, MAE is:29.33 & sMAPE is:17.28% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :39.80 & 24.69% & 0.75\n",
      "for 2022-02-03, MAE is:16.34 & sMAPE is:8.62% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :39.11 & 24.21% & 0.74\n",
      "for 2022-02-04, MAE is:21.56 & sMAPE is:12.50% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :38.60 & 23.88% & 0.74\n",
      "for 2022-02-05, MAE is:32.87 & sMAPE is:24.07% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :38.44 & 23.89% & 0.73\n",
      "for 2022-02-06, MAE is:45.31 & sMAPE is:46.02% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :38.63 & 24.48% & 0.73\n",
      "for 2022-02-07, MAE is:47.09 & sMAPE is:40.60% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :38.85 & 24.91% & 0.74\n",
      "for 2022-02-08, MAE is:28.08 & sMAPE is:16.78% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :38.58 & 24.70% & 0.74\n",
      "for 2022-02-09, MAE is:31.82 & sMAPE is:18.23% & rMAE is:2.66 ||| daily mean of MAE & sMAPE & rMAE till now are :38.41 & 24.54% & 0.79\n",
      "for 2022-02-10, MAE is:28.08 & sMAPE is:15.50% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :38.16 & 24.32% & 0.80\n",
      "for 2022-02-11, MAE is:41.65 & sMAPE is:24.57% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :38.24 & 24.32% & 0.81\n",
      "for 2022-02-12, MAE is:29.86 & sMAPE is:18.68% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :38.04 & 24.19% & 0.81\n",
      "for 2022-02-13, MAE is:37.37 & sMAPE is:28.64% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :38.03 & 24.29% & 0.80\n",
      "for 2022-02-14, MAE is:31.20 & sMAPE is:18.11% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :37.88 & 24.16% & 0.80\n",
      "for 2022-02-15, MAE is:23.75 & sMAPE is:12.16% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :37.57 & 23.89% & 0.79\n",
      "for 2022-02-16, MAE is:28.69 & sMAPE is:17.06% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :37.38 & 23.75% & 0.79\n",
      "for 2022-02-17, MAE is:53.48 & sMAPE is:52.72% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :37.72 & 24.35% & 0.79\n",
      "for 2022-02-18, MAE is:38.86 & sMAPE is:22.80% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :37.74 & 24.32% & 0.80\n",
      "for 2022-02-19, MAE is:64.29 & sMAPE is:66.76% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :38.27 & 25.17% & 0.80\n",
      "for 2022-02-20, MAE is:25.15 & sMAPE is:20.08% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :38.01 & 25.07% & 0.80\n",
      "for 2022-02-21, MAE is:28.89 & sMAPE is:19.24% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :37.84 & 24.96% & 0.80\n",
      "for 2022-02-22, MAE is:31.95 & sMAPE is:19.58% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :37.73 & 24.86% & 0.80\n",
      "for 2022-02-23, MAE is:43.79 & sMAPE is:27.78% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :37.84 & 24.91% & 0.81\n",
      "for 2022-02-24, MAE is:29.36 & sMAPE is:17.55% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :37.68 & 24.78% & 0.80\n",
      "for 2022-02-25, MAE is:72.38 & sMAPE is:34.07% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :38.30 & 24.94% & 0.80\n",
      "for 2022-02-26, MAE is:44.50 & sMAPE is:19.28% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :38.41 & 24.84% & 0.79\n",
      "for 2022-02-27, MAE is:32.52 & sMAPE is:17.99% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :38.31 & 24.73% & 0.79\n",
      "for 2022-02-28, MAE is:49.59 & sMAPE is:22.89% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :38.50 & 24.69% & 0.79\n",
      "for 2022-03-01, MAE is:51.80 & sMAPE is:21.52% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :38.72 & 24.64% & 0.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-03-02, MAE is:33.82 & sMAPE is:14.60% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :38.64 & 24.48% & 0.78\n",
      "for 2022-03-03, MAE is:112.69 & sMAPE is:39.86% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :39.84 & 24.72% & 0.78\n",
      "for 2022-03-04, MAE is:68.80 & sMAPE is:21.47% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :40.30 & 24.67% & 0.77\n",
      "for 2022-03-05, MAE is:66.74 & sMAPE is:21.76% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :40.71 & 24.63% & 0.77\n",
      "for 2022-03-06, MAE is:75.76 & sMAPE is:24.44% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :41.25 & 24.62% & 0.77\n",
      "for 2022-03-07, MAE is:75.03 & sMAPE is:20.23% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :41.76 & 24.56% & 0.76\n",
      "for 2022-03-08, MAE is:151.62 & sMAPE is:37.40% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :43.40 & 24.75% & 0.76\n",
      "for 2022-03-09, MAE is:89.54 & sMAPE is:21.77% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :44.08 & 24.71% & 0.76\n",
      "for 2022-03-10, MAE is:97.05 & sMAPE is:29.30% & rMAE is:3.10 ||| daily mean of MAE & sMAPE & rMAE till now are :44.85 & 24.77% & 0.79\n",
      "for 2022-03-11, MAE is:143.80 & sMAPE is:66.73% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :46.26 & 25.37% & 0.79\n",
      "for 2022-03-12, MAE is:55.29 & sMAPE is:23.45% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :46.39 & 25.34% & 0.79\n",
      "for 2022-03-13, MAE is:70.52 & sMAPE is:35.33% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :46.72 & 25.48% & 0.79\n",
      "for 2022-03-14, MAE is:41.39 & sMAPE is:14.58% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :46.65 & 25.33% & 0.78\n",
      "for 2022-03-15, MAE is:35.32 & sMAPE is:12.24% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :46.50 & 25.16% & 0.77\n",
      "for 2022-03-16, MAE is:29.10 & sMAPE is:10.48% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :46.27 & 24.96% & 0.76\n",
      "for 2022-03-17, MAE is:33.33 & sMAPE is:14.33% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :46.10 & 24.82% & 0.76\n",
      "for 2022-03-18, MAE is:28.99 & sMAPE is:12.54% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :45.87 & 24.66% & 0.76\n",
      "for 2022-03-19, MAE is:71.10 & sMAPE is:57.88% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :46.20 & 25.09% & 0.76\n",
      "for 2022-03-20, MAE is:65.80 & sMAPE is:56.07% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :46.44 & 25.48% & 0.76\n",
      "for 2022-03-21, MAE is:39.66 & sMAPE is:17.96% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :46.36 & 25.39% & 0.76\n",
      "for 2022-03-22, MAE is:33.68 & sMAPE is:14.53% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :46.20 & 25.25% & 0.76\n",
      "for 2022-03-23, MAE is:40.64 & sMAPE is:17.11% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :46.14 & 25.15% & 0.76\n",
      "for 2022-03-24, MAE is:39.33 & sMAPE is:16.47% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :46.05 & 25.05% & 0.77\n",
      "for 2022-03-25, MAE is:43.94 & sMAPE is:18.60% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :46.03 & 24.97% & 0.78\n",
      "for 2022-03-26, MAE is:63.73 & sMAPE is:47.57% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :46.24 & 25.24% & 0.79\n",
      "for 2022-03-27, MAE is:36.27 & sMAPE is:20.98% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :46.12 & 25.19% & 0.79\n",
      "for 2022-03-28, MAE is:27.83 & sMAPE is:12.22% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :45.91 & 25.04% & 0.80\n",
      "for 2022-03-29, MAE is:27.04 & sMAPE is:11.88% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :45.70 & 24.89% & 0.80\n",
      "for 2022-03-30, MAE is:44.90 & sMAPE is:19.56% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :45.69 & 24.83% & 0.80\n",
      "for 2022-03-31, MAE is:54.48 & sMAPE is:22.53% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :45.78 & 24.80% & 0.81\n",
      "for 2022-04-01, MAE is:30.51 & sMAPE is:14.95% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :45.62 & 24.70% & 0.80\n",
      "for 2022-04-02, MAE is:54.78 & sMAPE is:26.11% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :45.72 & 24.71% & 0.81\n",
      "for 2022-04-03, MAE is:38.41 & sMAPE is:15.92% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :45.64 & 24.62% & 0.81\n",
      "for 2022-04-04, MAE is:37.50 & sMAPE is:19.55% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :45.55 & 24.56% & 0.81\n",
      "for 2022-04-05, MAE is:35.28 & sMAPE is:15.19% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :45.44 & 24.46% & 0.82\n",
      "for 2022-04-06, MAE is:23.12 & sMAPE is:12.21% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :45.21 & 24.34% & 0.81\n",
      "for 2022-04-07, MAE is:33.74 & sMAPE is:18.10% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :45.09 & 24.27% & 0.81\n",
      "for 2022-04-08, MAE is:31.23 & sMAPE is:14.17% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :44.95 & 24.17% & 0.81\n",
      "for 2022-04-09, MAE is:67.51 & sMAPE is:51.50% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :45.18 & 24.44% & 0.81\n",
      "for 2022-04-10, MAE is:66.23 & sMAPE is:47.97% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :45.39 & 24.68% & 0.81\n",
      "for 2022-04-11, MAE is:29.44 & sMAPE is:12.69% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :45.23 & 24.56% & 0.81\n",
      "for 2022-04-12, MAE is:38.21 & sMAPE is:19.96% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :45.16 & 24.52% & 0.81\n",
      "for 2022-04-13, MAE is:24.46 & sMAPE is:10.77% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :44.96 & 24.38% & 0.81\n",
      "for 2022-04-14, MAE is:16.62 & sMAPE is:7.09% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :44.69 & 24.22% & 0.80\n",
      "for 2022-04-15, MAE is:29.21 & sMAPE is:13.71% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :44.54 & 24.12% & 0.80\n",
      "for 2022-04-16, MAE is:44.40 & sMAPE is:35.21% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :44.54 & 24.22% & 0.80\n",
      "for 2022-04-17, MAE is:48.30 & sMAPE is:58.08% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :44.58 & 24.54% & 0.80\n",
      "for 2022-04-18, MAE is:53.50 & sMAPE is:42.61% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :44.66 & 24.71% & 0.80\n",
      "for 2022-04-19, MAE is:30.59 & sMAPE is:15.11% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :44.53 & 24.62% & 0.80\n",
      "for 2022-04-20, MAE is:22.82 & sMAPE is:11.91% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :44.33 & 24.50% & 0.80\n",
      "for 2022-04-21, MAE is:16.90 & sMAPE is:8.48% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :44.08 & 24.36% & 0.79\n",
      "for 2022-04-22, MAE is:31.03 & sMAPE is:18.81% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :43.97 & 24.31% & 0.80\n",
      "for 2022-04-23, MAE is:107.15 & sMAPE is:72.42% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :44.53 & 24.73% & 0.80\n",
      "for 2022-04-24, MAE is:54.69 & sMAPE is:72.71% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :44.62 & 25.15% & 0.81\n",
      "for 2022-04-25, MAE is:79.62 & sMAPE is:44.36% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :44.92 & 25.32% & 0.81\n",
      "for 2022-04-26, MAE is:24.80 & sMAPE is:11.66% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :44.75 & 25.20% & 0.81\n",
      "for 2022-04-27, MAE is:14.87 & sMAPE is:6.88% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :44.49 & 25.05% & 0.81\n",
      "for 2022-04-28, MAE is:25.77 & sMAPE is:11.76% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :44.33 & 24.93% & 0.81\n",
      "for 2022-04-29, MAE is:29.12 & sMAPE is:13.74% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :44.21 & 24.84% & 0.80\n",
      "for 2022-04-30, MAE is:33.63 & sMAPE is:19.17% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :44.12 & 24.79% & 0.80\n",
      "for 2022-05-01, MAE is:19.97 & sMAPE is:10.64% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :43.92 & 24.68% & 0.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-05-02, MAE is:17.04 & sMAPE is:8.00% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :43.70 & 24.54% & 0.80\n",
      "for 2022-05-03, MAE is:15.52 & sMAPE is:7.11% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :43.47 & 24.40% & 0.81\n",
      "for 2022-05-04, MAE is:26.59 & sMAPE is:12.21% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :43.33 & 24.30% & 0.81\n",
      "for 2022-05-05, MAE is:16.51 & sMAPE is:7.52% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :43.12 & 24.16% & 0.82\n",
      "for 2022-05-06, MAE is:16.03 & sMAPE is:7.13% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :42.90 & 24.03% & 0.83\n",
      "for 2022-05-07, MAE is:14.80 & sMAPE is:7.42% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :42.68 & 23.90% & 0.84\n",
      "for 2022-05-08, MAE is:25.49 & sMAPE is:18.92% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :42.55 & 23.86% & 0.84\n",
      "for 2022-05-09, MAE is:28.10 & sMAPE is:13.86% & rMAE is:2.87 ||| daily mean of MAE & sMAPE & rMAE till now are :42.44 & 23.78% & 0.85\n",
      "for 2022-05-10, MAE is:50.50 & sMAPE is:38.25% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :42.50 & 23.89% & 0.85\n",
      "for 2022-05-11, MAE is:48.04 & sMAPE is:40.23% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :42.54 & 24.02% & 0.85\n",
      "for 2022-05-12, MAE is:33.36 & sMAPE is:22.23% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :42.47 & 24.01% & 0.85\n",
      "for 2022-05-13, MAE is:52.68 & sMAPE is:45.80% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :42.55 & 24.17% & 0.85\n",
      "for 2022-05-14, MAE is:54.66 & sMAPE is:46.12% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :42.64 & 24.33% & 0.85\n",
      "for 2022-05-15, MAE is:37.34 & sMAPE is:32.37% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :42.60 & 24.39% & 0.86\n",
      "for 2022-05-16, MAE is:31.16 & sMAPE is:16.25% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :42.51 & 24.33% & 0.87\n",
      "for 2022-05-17, MAE is:21.98 & sMAPE is:10.19% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :42.36 & 24.23% & 0.86\n",
      "for 2022-05-18, MAE is:22.45 & sMAPE is:11.02% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :42.22 & 24.13% & 0.86\n",
      "for 2022-05-19, MAE is:21.75 & sMAPE is:10.87% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :42.07 & 24.04% & 0.86\n",
      "for 2022-05-20, MAE is:29.27 & sMAPE is:14.08% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :41.98 & 23.97% & 0.86\n",
      "for 2022-05-21, MAE is:43.02 & sMAPE is:36.91% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :41.99 & 24.06% & 0.86\n",
      "for 2022-05-22, MAE is:18.11 & sMAPE is:11.76% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :41.82 & 23.97% & 0.86\n",
      "for 2022-05-23, MAE is:22.23 & sMAPE is:11.34% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :41.68 & 23.88% & 0.86\n",
      "for 2022-05-24, MAE is:29.57 & sMAPE is:15.78% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :41.60 & 23.83% & 0.86\n",
      "for 2022-05-25, MAE is:40.16 & sMAPE is:25.02% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :41.59 & 23.84% & 0.86\n",
      "for 2022-05-26, MAE is:82.85 & sMAPE is:86.55% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :41.87 & 24.27% & 0.86\n",
      "for 2022-05-27, MAE is:71.31 & sMAPE is:82.02% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :42.07 & 24.66% & 0.85\n",
      "for 2022-05-28, MAE is:87.27 & sMAPE is:90.83% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :42.38 & 25.11% & 0.86\n",
      "for 2022-05-29, MAE is:42.06 & sMAPE is:29.49% & rMAE is:2.52 ||| daily mean of MAE & sMAPE & rMAE till now are :42.38 & 25.13% & 0.87\n",
      "for 2022-05-30, MAE is:36.40 & sMAPE is:18.10% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :42.34 & 25.09% & 0.87\n",
      "for 2022-05-31, MAE is:16.30 & sMAPE is:7.78% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :42.16 & 24.97% & 0.87\n",
      "for 2022-06-01, MAE is:19.98 & sMAPE is:10.19% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :42.02 & 24.88% & 0.86\n",
      "for 2022-06-02, MAE is:16.44 & sMAPE is:8.92% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :41.85 & 24.77% & 0.86\n",
      "for 2022-06-03, MAE is:24.56 & sMAPE is:15.89% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :41.74 & 24.71% & 0.85\n",
      "for 2022-06-04, MAE is:41.78 & sMAPE is:40.50% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :41.74 & 24.82% & 0.85\n",
      "for 2022-06-05, MAE is:17.34 & sMAPE is:11.81% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :41.58 & 24.73% & 0.85\n",
      "for 2022-06-06, MAE is:80.16 & sMAPE is:83.89% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :41.83 & 25.11% & 0.85\n",
      "for 2022-06-07, MAE is:17.11 & sMAPE is:10.42% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :41.67 & 25.02% & 0.85\n",
      "for 2022-06-08, MAE is:21.95 & sMAPE is:11.24% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :41.55 & 24.93% & 0.85\n",
      "for 2022-06-09, MAE is:19.75 & sMAPE is:11.74% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :41.41 & 24.85% & 0.85\n",
      "for 2022-06-10, MAE is:18.61 & sMAPE is:10.95% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :41.27 & 24.76% & 0.85\n",
      "for 2022-06-11, MAE is:61.78 & sMAPE is:71.67% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :41.40 & 25.05% & 0.86\n",
      "for 2022-06-12, MAE is:45.84 & sMAPE is:57.27% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :41.42 & 25.25% & 0.86\n",
      "for 2022-06-13, MAE is:30.94 & sMAPE is:19.89% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :41.36 & 25.22% & 0.85\n",
      "for 2022-06-14, MAE is:22.83 & sMAPE is:11.88% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :41.25 & 25.13% & 0.86\n",
      "for 2022-06-15, MAE is:30.34 & sMAPE is:15.22% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :41.18 & 25.08% & 0.86\n",
      "for 2022-06-16, MAE is:35.68 & sMAPE is:18.04% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :41.15 & 25.03% & 0.86\n",
      "for 2022-06-17, MAE is:48.43 & sMAPE is:19.84% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :41.19 & 25.00% & 0.86\n",
      "for 2022-06-18, MAE is:54.25 & sMAPE is:29.69% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :41.27 & 25.03% & 0.85\n",
      "for 2022-06-19, MAE is:46.87 & sMAPE is:30.21% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :41.30 & 25.06% & 0.85\n",
      "for 2022-06-20, MAE is:40.38 & sMAPE is:17.81% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :41.30 & 25.02% & 0.85\n",
      "for 2022-06-21, MAE is:69.14 & sMAPE is:26.30% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :41.46 & 25.03% & 0.85\n",
      "for 2022-06-22, MAE is:42.95 & sMAPE is:17.14% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :41.47 & 24.98% & 0.85\n",
      "for 2022-06-23, MAE is:51.84 & sMAPE is:19.12% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :41.53 & 24.95% & 0.85\n",
      "for 2022-06-24, MAE is:21.04 & sMAPE is:7.56% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :41.41 & 24.85% & 0.85\n",
      "for 2022-06-25, MAE is:21.83 & sMAPE is:9.04% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :41.30 & 24.76% & 0.85\n",
      "for 2022-06-26, MAE is:44.31 & sMAPE is:20.80% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :41.31 & 24.73% & 0.85\n",
      "for 2022-06-27, MAE is:41.43 & sMAPE is:14.78% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :41.32 & 24.68% & 0.85\n",
      "for 2022-06-28, MAE is:47.34 & sMAPE is:16.00% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :41.35 & 24.63% & 0.85\n",
      "for 2022-06-29, MAE is:27.34 & sMAPE is:9.34% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :41.27 & 24.55% & 0.85\n",
      "for 2022-06-30, MAE is:46.44 & sMAPE is:14.77% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :41.30 & 24.49% & 0.85\n",
      "for 2022-07-01, MAE is:39.94 & sMAPE is:13.30% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :41.29 & 24.43% & 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-07-02, MAE is:54.20 & sMAPE is:26.26% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :41.36 & 24.44% & 0.85\n",
      "for 2022-07-03, MAE is:63.48 & sMAPE is:34.27% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :41.48 & 24.49% & 0.86\n",
      "for 2022-07-04, MAE is:58.85 & sMAPE is:22.58% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :41.58 & 24.48% & 0.87\n",
      "for 2022-07-05, MAE is:53.82 & sMAPE is:18.38% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :41.64 & 24.45% & 0.87\n",
      "for 2022-07-06, MAE is:58.44 & sMAPE is:20.91% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :41.73 & 24.43% & 0.87\n",
      "for 2022-07-07, MAE is:64.39 & sMAPE is:26.02% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :41.85 & 24.44% & 0.87\n",
      "for 2022-07-08, MAE is:37.87 & sMAPE is:12.32% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :41.83 & 24.38% & 0.87\n",
      "for 2022-07-09, MAE is:96.84 & sMAPE is:61.59% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :42.12 & 24.57% & 0.87\n",
      "for 2022-07-10, MAE is:59.68 & sMAPE is:37.14% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :42.21 & 24.64% & 0.88\n",
      "for 2022-07-11, MAE is:78.22 & sMAPE is:23.39% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :42.40 & 24.63% & 0.88\n",
      "for 2022-07-12, MAE is:59.65 & sMAPE is:16.81% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :42.49 & 24.59% & 0.88\n",
      "for 2022-07-13, MAE is:52.74 & sMAPE is:17.20% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :42.54 & 24.55% & 0.88\n",
      "for 2022-07-14, MAE is:43.20 & sMAPE is:12.70% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :42.55 & 24.49% & 0.88\n",
      "for 2022-07-15, MAE is:58.20 & sMAPE is:18.77% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :42.63 & 24.46% & 0.88\n",
      "for 2022-07-16, MAE is:131.47 & sMAPE is:75.91% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :43.08 & 24.72% & 0.89\n",
      "for 2022-07-17, MAE is:76.14 & sMAPE is:42.74% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :43.24 & 24.81% & 0.90\n",
      "for 2022-07-18, MAE is:85.92 & sMAPE is:22.70% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :43.46 & 24.80% & 0.90\n",
      "for 2022-07-19, MAE is:63.43 & sMAPE is:17.27% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :43.56 & 24.77% & 0.90\n",
      "for 2022-07-20, MAE is:42.34 & sMAPE is:13.47% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :43.55 & 24.71% & 0.90\n",
      "for 2022-07-21, MAE is:39.75 & sMAPE is:11.59% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :43.53 & 24.64% & 0.90\n",
      "for 2022-07-22, MAE is:38.61 & sMAPE is:12.16% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :43.51 & 24.58% & 0.91\n",
      "for 2022-07-23, MAE is:56.37 & sMAPE is:20.29% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :43.57 & 24.56% & 0.90\n",
      "for 2022-07-24, MAE is:103.87 & sMAPE is:54.27% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :43.87 & 24.71% & 0.91\n",
      "for 2022-07-25, MAE is:65.83 & sMAPE is:22.75% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :43.97 & 24.70% & 0.91\n",
      "for 2022-07-26, MAE is:39.20 & sMAPE is:13.12% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :43.95 & 24.64% & 0.90\n",
      "for 2022-07-27, MAE is:67.24 & sMAPE is:19.04% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :44.06 & 24.61% & 0.91\n",
      "for 2022-07-28, MAE is:73.10 & sMAPE is:18.65% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :44.20 & 24.59% & 0.91\n",
      "for 2022-07-29, MAE is:55.56 & sMAPE is:15.41% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :44.26 & 24.54% & 0.91\n",
      "for 2022-07-30, MAE is:60.99 & sMAPE is:18.80% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :44.33 & 24.52% & 0.91\n",
      "for 2022-07-31, MAE is:44.98 & sMAPE is:14.25% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :44.34 & 24.47% & 0.90\n",
      "for 2022-08-01, MAE is:43.30 & sMAPE is:11.41% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :44.33 & 24.41% & 0.90\n",
      "for 2022-08-02, MAE is:103.94 & sMAPE is:36.51% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :44.61 & 24.46% & 0.90\n",
      "for 2022-08-03, MAE is:101.28 & sMAPE is:37.63% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :44.87 & 24.52% & 0.91\n",
      "for 2022-08-04, MAE is:71.16 & sMAPE is:21.68% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :45.00 & 24.51% & 0.91\n",
      "for 2022-08-05, MAE is:47.09 & sMAPE is:13.53% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :45.01 & 24.46% & 0.91\n",
      "for 2022-08-06, MAE is:87.86 & sMAPE is:32.38% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :45.20 & 24.50% & 0.91\n",
      "for 2022-08-07, MAE is:96.44 & sMAPE is:47.10% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :45.44 & 24.60% & 0.91\n",
      "for 2022-08-08, MAE is:50.16 & sMAPE is:14.22% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :45.46 & 24.55% & 0.91\n",
      "for 2022-08-09, MAE is:43.96 & sMAPE is:13.18% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :45.45 & 24.50% & 0.91\n",
      "for 2022-08-10, MAE is:40.08 & sMAPE is:12.41% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :45.43 & 24.45% & 0.90\n",
      "for 2022-08-11, MAE is:50.38 & sMAPE is:14.03% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :45.45 & 24.40% & 0.90\n",
      "for 2022-08-12, MAE is:81.80 & sMAPE is:20.90% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :45.61 & 24.38% & 0.91\n",
      "for 2022-08-13, MAE is:75.38 & sMAPE is:24.66% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :45.74 & 24.38% & 0.91\n",
      "for 2022-08-14, MAE is:75.86 & sMAPE is:35.20% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :45.88 & 24.43% & 0.90\n",
      "for 2022-08-15, MAE is:68.92 & sMAPE is:17.57% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :45.98 & 24.40% & 0.90\n",
      "for 2022-08-16, MAE is:61.27 & sMAPE is:13.45% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :46.05 & 24.35% & 0.90\n",
      "for 2022-08-17, MAE is:65.32 & sMAPE is:12.42% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :46.13 & 24.30% & 0.90\n",
      "for 2022-08-18, MAE is:55.37 & sMAPE is:11.29% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :46.17 & 24.25% & 0.90\n",
      "for 2022-08-19, MAE is:44.05 & sMAPE is:8.99% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :46.16 & 24.18% & 0.90\n",
      "for 2022-08-20, MAE is:59.40 & sMAPE is:13.39% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :46.22 & 24.13% & 0.90\n",
      "for 2022-08-21, MAE is:117.08 & sMAPE is:36.51% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :46.52 & 24.19% & 0.90\n",
      "for 2022-08-22, MAE is:90.14 & sMAPE is:17.87% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :46.71 & 24.16% & 0.90\n",
      "for 2022-08-23, MAE is:90.72 & sMAPE is:16.15% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :46.90 & 24.13% & 0.90\n",
      "for 2022-08-24, MAE is:80.12 & sMAPE is:13.68% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :47.04 & 24.08% & 0.90\n",
      "for 2022-08-25, MAE is:66.05 & sMAPE is:11.75% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :47.12 & 24.03% & 0.90\n",
      "for 2022-08-26, MAE is:94.96 & sMAPE is:14.93% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :47.32 & 23.99% & 0.90\n",
      "for 2022-08-27, MAE is:77.95 & sMAPE is:12.87% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :47.45 & 23.94% & 0.89\n",
      "for 2022-08-28, MAE is:189.64 & sMAPE is:56.09% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :48.04 & 24.08% & 0.90\n",
      "for 2022-08-29, MAE is:127.03 & sMAPE is:21.36% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :48.37 & 24.07% & 0.90\n",
      "for 2022-08-30, MAE is:98.42 & sMAPE is:16.41% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :48.57 & 24.04% & 0.90\n",
      "for 2022-08-31, MAE is:73.35 & sMAPE is:13.56% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :48.68 & 23.99% & 0.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-09-01, MAE is:56.37 & sMAPE is:10.91% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :48.71 & 23.94% & 0.90\n",
      "for 2022-09-02, MAE is:129.07 & sMAPE is:28.53% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :49.03 & 23.96% & 0.90\n",
      "for 2022-09-03, MAE is:105.15 & sMAPE is:39.84% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :49.26 & 24.02% & 0.90\n",
      "for 2022-09-04, MAE is:117.88 & sMAPE is:48.22% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :49.54 & 24.12% & 0.90\n",
      "for 2022-09-05, MAE is:88.38 & sMAPE is:24.96% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :49.70 & 24.12% & 0.90\n",
      "for 2022-09-06, MAE is:108.14 & sMAPE is:26.63% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :49.93 & 24.13% & 0.89\n",
      "for 2022-09-07, MAE is:60.80 & sMAPE is:13.98% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :49.98 & 24.09% & 0.89\n",
      "for 2022-09-08, MAE is:40.66 & sMAPE is:9.83% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :49.94 & 24.04% & 0.89\n",
      "for 2022-09-09, MAE is:59.74 & sMAPE is:17.93% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :49.98 & 24.01% & 0.89\n",
      "for 2022-09-10, MAE is:62.29 & sMAPE is:17.00% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :50.03 & 23.98% & 0.89\n",
      "for 2022-09-11, MAE is:43.36 & sMAPE is:11.84% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :50.00 & 23.94% & 0.89\n",
      "for 2022-09-12, MAE is:47.24 & sMAPE is:12.10% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :49.99 & 23.89% & 0.89\n",
      "for 2022-09-13, MAE is:36.88 & sMAPE is:9.15% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :49.94 & 23.83% & 0.89\n",
      "for 2022-09-14, MAE is:41.53 & sMAPE is:10.44% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :49.90 & 23.78% & 0.88\n",
      "for 2022-09-15, MAE is:42.31 & sMAPE is:11.55% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :49.88 & 23.73% & 0.88\n",
      "for 2022-09-16, MAE is:169.06 & sMAPE is:71.58% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :50.34 & 23.92% & 0.88\n",
      "for 2022-09-17, MAE is:119.23 & sMAPE is:85.98% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :50.60 & 24.16% & 0.88\n",
      "for 2022-09-18, MAE is:45.60 & sMAPE is:40.64% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :50.58 & 24.22% & 0.88\n",
      "for 2022-09-19, MAE is:110.93 & sMAPE is:44.39% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :50.81 & 24.30% & 0.88\n",
      "for 2022-09-20, MAE is:83.58 & sMAPE is:26.18% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :50.94 & 24.30% & 0.88\n",
      "for 2022-09-21, MAE is:58.77 & sMAPE is:16.35% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :50.97 & 24.27% & 0.88\n",
      "for 2022-09-22, MAE is:68.98 & sMAPE is:18.40% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :51.03 & 24.25% & 0.88\n",
      "for 2022-09-23, MAE is:34.13 & sMAPE is:9.09% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :50.97 & 24.19% & 0.88\n",
      "for 2022-09-24, MAE is:21.00 & sMAPE is:6.17% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :50.86 & 24.13% & 0.88\n",
      "for 2022-09-25, MAE is:75.99 & sMAPE is:30.95% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :50.95 & 24.15% & 0.88\n",
      "for 2022-09-26, MAE is:73.42 & sMAPE is:30.54% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :51.04 & 24.18% & 0.88\n",
      "for 2022-09-27, MAE is:58.93 & sMAPE is:21.69% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :51.06 & 24.17% & 0.88\n",
      "for 2022-09-28, MAE is:106.64 & sMAPE is:30.63% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :51.27 & 24.19% & 0.89\n",
      "for 2022-09-29, MAE is:80.12 & sMAPE is:20.64% & rMAE is:3.00 ||| daily mean of MAE & sMAPE & rMAE till now are :51.38 & 24.18% & 0.89\n",
      "for 2022-09-30, MAE is:116.86 & sMAPE is:38.52% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :51.62 & 24.23% & 0.89\n",
      "for 2022-10-01, MAE is:85.09 & sMAPE is:69.47% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :51.74 & 24.40% & 0.89\n",
      "for 2022-10-02, MAE is:53.44 & sMAPE is:30.66% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :51.74 & 24.42% & 0.89\n",
      "for 2022-10-03, MAE is:115.82 & sMAPE is:41.89% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :51.98 & 24.48% & 0.89\n",
      "for 2022-10-04, MAE is:85.06 & sMAPE is:34.47% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :52.10 & 24.52% & 0.89\n",
      "for 2022-10-05, MAE is:87.02 & sMAPE is:61.02% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :52.22 & 24.65% & 0.89\n",
      "for 2022-10-06, MAE is:84.54 & sMAPE is:95.74% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :52.34 & 24.90% & 0.89\n",
      "for 2022-10-07, MAE is:49.01 & sMAPE is:39.78% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :52.33 & 24.96% & 0.89\n",
      "for 2022-10-08, MAE is:58.26 & sMAPE is:45.90% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :52.35 & 25.03% & 0.89\n",
      "for 2022-10-09, MAE is:42.14 & sMAPE is:29.29% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :52.31 & 25.05% & 0.89\n",
      "for 2022-10-10, MAE is:32.30 & sMAPE is:19.03% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :52.24 & 25.02% & 0.89\n",
      "for 2022-10-11, MAE is:59.80 & sMAPE is:22.71% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :52.27 & 25.02% & 0.89\n",
      "for 2022-10-12, MAE is:46.61 & sMAPE is:17.14% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :52.25 & 24.99% & 0.88\n",
      "for 2022-10-13, MAE is:34.72 & sMAPE is:14.05% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :52.18 & 24.95% & 0.88\n",
      "for 2022-10-14, MAE is:48.33 & sMAPE is:20.76% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :52.17 & 24.94% & 0.88\n",
      "for 2022-10-15, MAE is:29.15 & sMAPE is:18.54% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :52.09 & 24.91% & 0.88\n",
      "for 2022-10-16, MAE is:27.35 & sMAPE is:28.64% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :52.01 & 24.93% & 0.88\n",
      "for 2022-10-17, MAE is:27.42 & sMAPE is:17.40% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :51.92 & 24.90% & 0.88\n",
      "for 2022-10-18, MAE is:20.87 & sMAPE is:12.50% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :51.81 & 24.86% & 0.88\n",
      "for 2022-10-19, MAE is:24.71 & sMAPE is:17.69% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :51.72 & 24.83% & 0.87\n",
      "for 2022-10-20, MAE is:29.76 & sMAPE is:26.25% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :51.65 & 24.84% & 0.87\n",
      "for 2022-10-21, MAE is:21.65 & sMAPE is:15.17% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :51.54 & 24.81% & 0.87\n",
      "for 2022-10-22, MAE is:46.91 & sMAPE is:44.71% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :51.53 & 24.87% & 0.87\n",
      "for 2022-10-23, MAE is:21.34 & sMAPE is:19.15% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :51.43 & 24.85% & 0.87\n",
      "for 2022-10-24, MAE is:10.06 & sMAPE is:14.32% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :51.29 & 24.82% & 0.87\n",
      "for 2022-10-25, MAE is:25.17 & sMAPE is:26.46% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :51.20 & 24.82% & 0.87\n",
      "for 2022-10-26, MAE is:21.50 & sMAPE is:24.04% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :51.10 & 24.82% & 0.87\n",
      "for 2022-10-27, MAE is:46.17 & sMAPE is:46.36% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :51.08 & 24.89% & 0.87\n",
      "for 2022-10-28, MAE is:15.63 & sMAPE is:17.16% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :50.97 & 24.87% & 0.87\n",
      "for 2022-10-29, MAE is:15.09 & sMAPE is:16.88% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :50.85 & 24.84% & 0.87\n",
      "for 2022-10-30, MAE is:57.56 & sMAPE is:67.37% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :50.87 & 24.98% & 0.87\n",
      "for 2022-10-31, MAE is:29.03 & sMAPE is:22.38% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :50.80 & 24.97% & 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-11-01, MAE is:41.36 & sMAPE is:47.25% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :50.77 & 25.05% & 0.87\n",
      "for 2022-11-02, MAE is:22.64 & sMAPE is:38.60% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :50.68 & 25.09% & 0.87\n",
      "for 2022-11-03, MAE is:26.40 & sMAPE is:30.47% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :50.60 & 25.11% & 0.87\n",
      "for 2022-11-04, MAE is:82.24 & sMAPE is:58.63% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :50.70 & 25.22% & 0.87\n",
      "for 2022-11-05, MAE is:29.95 & sMAPE is:24.04% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :50.63 & 25.21% & 0.87\n",
      "for 2022-11-06, MAE is:21.74 & sMAPE is:27.39% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :50.54 & 25.22% & 0.87\n",
      "for 2022-11-07, MAE is:34.02 & sMAPE is:64.16% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :50.49 & 25.34% & 0.87\n",
      "for 2022-11-08, MAE is:27.42 & sMAPE is:34.44% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :50.41 & 25.37% & 0.87\n",
      "for 2022-11-09, MAE is:47.73 & sMAPE is:50.71% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :50.40 & 25.45% & 0.87\n",
      "for 2022-11-10, MAE is:28.54 & sMAPE is:21.66% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :50.33 & 25.44% & 0.87\n",
      "for 2022-11-11, MAE is:39.06 & sMAPE is:48.93% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :50.30 & 25.52% & 0.87\n",
      "for 2022-11-12, MAE is:61.69 & sMAPE is:46.32% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :50.33 & 25.58% & 0.87\n",
      "for 2022-11-13, MAE is:21.16 & sMAPE is:15.41% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :50.24 & 25.55% & 0.87\n",
      "for 2022-11-14, MAE is:26.68 & sMAPE is:15.60% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :50.17 & 25.52% & 0.87\n",
      "for 2022-11-15, MAE is:21.71 & sMAPE is:12.59% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :50.08 & 25.48% & 0.87\n",
      "for 2022-11-16, MAE is:41.92 & sMAPE is:26.45% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :50.05 & 25.48% & 0.87\n",
      "for 2022-11-17, MAE is:68.34 & sMAPE is:64.80% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :50.11 & 25.60% & 0.87\n",
      "for 2022-11-18, MAE is:41.28 & sMAPE is:21.29% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :50.08 & 25.59% & 0.87\n",
      "for 2022-11-19, MAE is:93.74 & sMAPE is:59.55% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :50.22 & 25.70% & 0.87\n",
      "for 2022-11-20, MAE is:42.50 & sMAPE is:22.22% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :50.19 & 25.69% & 0.87\n",
      "for 2022-11-21, MAE is:30.52 & sMAPE is:13.94% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :50.13 & 25.65% & 0.87\n",
      "for 2022-11-22, MAE is:45.45 & sMAPE is:24.04% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :50.12 & 25.64% & 0.87\n",
      "for 2022-11-23, MAE is:36.38 & sMAPE is:19.26% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :50.08 & 25.63% & 0.87\n",
      "for 2022-11-24, MAE is:65.31 & sMAPE is:29.91% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :50.12 & 25.64% & 0.87\n",
      "for 2022-11-25, MAE is:55.78 & sMAPE is:25.12% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :50.14 & 25.64% & 0.87\n",
      "for 2022-11-26, MAE is:22.51 & sMAPE is:9.36% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :50.06 & 25.59% & 0.87\n",
      "for 2022-11-27, MAE is:49.68 & sMAPE is:23.75% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :50.06 & 25.58% & 0.87\n",
      "for 2022-11-28, MAE is:71.99 & sMAPE is:24.92% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :50.12 & 25.58% & 0.87\n",
      "for 2022-11-29, MAE is:61.12 & sMAPE is:16.31% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :50.15 & 25.55% & 0.87\n",
      "for 2022-11-30, MAE is:81.31 & sMAPE is:21.04% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :50.25 & 25.54% & 0.87\n",
      "for 2022-12-01, MAE is:29.99 & sMAPE is:8.04% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :50.19 & 25.49% & 0.86\n",
      "for 2022-12-02, MAE is:44.60 & sMAPE is:13.45% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :50.17 & 25.45% & 0.86\n",
      "for 2022-12-03, MAE is:44.43 & sMAPE is:16.03% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :50.15 & 25.42% & 0.86\n",
      "for 2022-12-04, MAE is:32.43 & sMAPE is:10.92% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :50.10 & 25.38% & 0.86\n",
      "for 2022-12-05, MAE is:33.01 & sMAPE is:9.60% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :50.05 & 25.33% & 0.86\n",
      "for 2022-12-06, MAE is:37.23 & sMAPE is:10.97% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :50.01 & 25.29% & 0.86\n",
      "for 2022-12-07, MAE is:41.78 & sMAPE is:12.17% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :49.99 & 25.25% & 0.86\n",
      "for 2022-12-08, MAE is:55.28 & sMAPE is:15.84% & rMAE is:2.20 ||| daily mean of MAE & sMAPE & rMAE till now are :50.00 & 25.22% & 0.87\n",
      "for 2022-12-09, MAE is:71.42 & sMAPE is:18.25% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :50.07 & 25.20% & 0.87\n",
      "for 2022-12-10, MAE is:36.29 & sMAPE is:10.15% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :50.03 & 25.16% & 0.86\n",
      "for 2022-12-11, MAE is:34.26 & sMAPE is:10.80% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :49.98 & 25.12% & 0.87\n",
      "for 2022-12-12, MAE is:79.78 & sMAPE is:18.47% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :50.07 & 25.10% & 0.87\n",
      "for 2022-12-13, MAE is:67.24 & sMAPE is:15.20% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :50.12 & 25.07% & 0.87\n",
      "for 2022-12-14, MAE is:84.56 & sMAPE is:19.33% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :50.22 & 25.05% & 0.87\n",
      "for 2022-12-15, MAE is:37.19 & sMAPE is:9.51% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :50.18 & 25.01% & 0.87\n",
      "for 2022-12-16, MAE is:65.40 & sMAPE is:15.80% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :50.22 & 24.98% & 0.87\n",
      "for 2022-12-17, MAE is:43.56 & sMAPE is:14.80% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :50.20 & 24.96% & 0.87\n",
      "for 2022-12-18, MAE is:51.56 & sMAPE is:22.50% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :50.21 & 24.95% & 0.87\n",
      "for 2022-12-19, MAE is:27.20 & sMAPE is:16.39% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :50.14 & 24.92% & 0.87\n",
      "for 2022-12-20, MAE is:21.56 & sMAPE is:13.57% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :50.06 & 24.89% & 0.87\n",
      "for 2022-12-21, MAE is:18.82 & sMAPE is:8.64% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :49.97 & 24.85% & 0.86\n",
      "for 2022-12-22, MAE is:16.37 & sMAPE is:8.03% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :49.88 & 24.80% & 0.86\n",
      "for 2022-12-23, MAE is:18.16 & sMAPE is:9.84% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :49.79 & 24.76% & 0.86\n",
      "for 2022-12-24, MAE is:21.08 & sMAPE is:22.71% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :49.71 & 24.75% & 0.86\n",
      "for 2022-12-25, MAE is:19.61 & sMAPE is:17.93% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :49.63 & 24.73% & 0.85\n",
      "for 2022-12-26, MAE is:57.18 & sMAPE is:67.74% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :49.65 & 24.85% & 0.85\n",
      "for 2022-12-27, MAE is:30.75 & sMAPE is:36.06% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :49.59 & 24.88% & 0.85\n",
      "for 2022-12-28, MAE is:24.53 & sMAPE is:55.51% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :49.52 & 24.97% & 0.85\n",
      "for 2022-12-29, MAE is:25.90 & sMAPE is:86.23% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :49.46 & 25.14% & 0.85\n",
      "for 2022-12-30, MAE is:56.91 & sMAPE is:124.62% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :49.48 & 25.41% & 0.85\n",
      "for 2022-12-31, MAE is:28.23 & sMAPE is:132.95% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :49.42 & 25.70% & 0.85\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:52:14,272]\u001b[0m A new study created in RDB with name: NL_2023\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:52:30,230]\u001b[0m Trial 3 finished with value: 190.93477111299612 and parameters: {'n_hidden': 4, 'learning_rate': 0.04363729407194946, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1992153955936627, 'dropout_rate_Layer_2': 0.031721836423714046, 'dropout_rate_Layer_3': 0.1786747607160907, 'dropout_rate_Layer_4': 0.29234945938797885, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.4391087381558188e-05, 'l1_Layer_2': 0.07225200559391097, 'l1_Layer_3': 0.06381836030501611, 'l1_Layer_4': 9.135191812416873e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 235, 'n_units_Layer_3': 140, 'n_units_Layer_4': 50}. Best is trial 3 with value: 190.93477111299612.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 190.93 | sMAPE for Validation Set is: 116.65% | rMAE for Validation Set is: 2.50\n",
      "MAE for Test Set is: 57.86 | sMAPE for Test Set is: 70.33% | rMAE for Test Set is: 1.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:52:33,770]\u001b[0m Trial 1 finished with value: 47.30242080885605 and parameters: {'n_hidden': 3, 'learning_rate': 0.005762027502019133, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3870016499644003, 'dropout_rate_Layer_2': 0.39065746108180294, 'dropout_rate_Layer_3': 0.10014607425690376, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001980966835022926, 'l1_Layer_2': 0.002093824569201297, 'l1_Layer_3': 0.026070007873363787, 'n_units_Layer_1': 230, 'n_units_Layer_2': 80, 'n_units_Layer_3': 150}. Best is trial 1 with value: 47.30242080885605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.30 | sMAPE for Validation Set is: 24.62% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 26.32 | sMAPE for Test Set is: 33.34% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:52:34,036]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:52:39,359]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:52:42,555]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:52:44,592]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:52:47,493]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:52:51,291]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:52:51,876]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 102.47 | sMAPE for Validation Set is: 45.81% | rMAE for Validation Set is: 1.34\n",
      "MAE for Test Set is: 46.12 | sMAPE for Test Set is: 44.03% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:52:54,412]\u001b[0m Trial 4 finished with value: 102.4660523005593 and parameters: {'n_hidden': 4, 'learning_rate': 0.026808162155271174, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20197280253490557, 'dropout_rate_Layer_2': 0.24343673085815448, 'dropout_rate_Layer_3': 0.3922839740110254, 'dropout_rate_Layer_4': 0.2876174207815167, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.054771210240652735, 'l1_Layer_2': 0.010758179142875562, 'l1_Layer_3': 0.0030241166957389897, 'l1_Layer_4': 0.00015803790064404088, 'n_units_Layer_1': 65, 'n_units_Layer_2': 225, 'n_units_Layer_3': 210, 'n_units_Layer_4': 135}. Best is trial 1 with value: 47.30242080885605.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:52:58,450]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:53:02,296]\u001b[0m Trial 0 finished with value: 80.78649861544869 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013302609831780056, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33180299742376956, 'dropout_rate_Layer_2': 0.05247226533703926, 'dropout_rate_Layer_3': 0.1690051036407236, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003634383586088215, 'l1_Layer_2': 0.0008915010079544572, 'l1_Layer_3': 4.463282391272496e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 95, 'n_units_Layer_3': 200}. Best is trial 1 with value: 47.30242080885605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 80.79 | sMAPE for Validation Set is: 36.06% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 23.22 | sMAPE for Test Set is: 28.11% | rMAE for Test Set is: 0.72\n",
      "MAE for Validation Set is: 83.01 | sMAPE for Validation Set is: 37.19% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 32.16 | sMAPE for Test Set is: 35.40% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:53:03,311]\u001b[0m Trial 12 finished with value: 83.01016369668687 and parameters: {'n_hidden': 3, 'learning_rate': 0.007901121256372287, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32444773144370764, 'dropout_rate_Layer_2': 0.39509860810153785, 'dropout_rate_Layer_3': 0.16119825958236775, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005739625455055012, 'l1_Layer_2': 0.0016309743065009194, 'l1_Layer_3': 0.0001069501914005689, 'n_units_Layer_1': 285, 'n_units_Layer_2': 295, 'n_units_Layer_3': 195}. Best is trial 1 with value: 47.30242080885605.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:53:06,450]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:53:08,221]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:53:10,200]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:53:13,366]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:53:17,246]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:53:20,459]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:53:26,242]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:53:29,803]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:53:54,680]\u001b[0m Trial 14 finished with value: 67.78963667276408 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031973598948066557, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.193512484692992, 'dropout_rate_Layer_2': 0.3055985187314723, 'dropout_rate_Layer_3': 0.39791032947524047, 'dropout_rate_Layer_4': 0.10952976521978114, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.3542390339297868e-05, 'l1_Layer_2': 0.09361427692910902, 'l1_Layer_3': 0.060428868116164984, 'l1_Layer_4': 0.0013983175307695512, 'n_units_Layer_1': 270, 'n_units_Layer_2': 200, 'n_units_Layer_3': 75, 'n_units_Layer_4': 220}. Best is trial 1 with value: 47.30242080885605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 67.79 | sMAPE for Validation Set is: 30.57% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 24.51 | sMAPE for Test Set is: 30.10% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:53:58,312]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:02,372]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:05,871]\u001b[0m Trial 19 finished with value: 95.27069183150707 and parameters: {'n_hidden': 4, 'learning_rate': 0.023904057759534112, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0742394334893306, 'dropout_rate_Layer_2': 0.1477255925408271, 'dropout_rate_Layer_3': 0.32505369353386504, 'dropout_rate_Layer_4': 0.08349996363125288, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0003155879013842153, 'l1_Layer_2': 0.00032734974047368904, 'l1_Layer_3': 0.0004587744159837479, 'l1_Layer_4': 0.04355452446438774, 'n_units_Layer_1': 200, 'n_units_Layer_2': 180, 'n_units_Layer_3': 55, 'n_units_Layer_4': 240}. Best is trial 1 with value: 47.30242080885605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 95.27 | sMAPE for Validation Set is: 42.08% | rMAE for Validation Set is: 1.25\n",
      "MAE for Test Set is: 63.88 | sMAPE for Test Set is: 52.27% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:54:07,111]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:11,220]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:15,290]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:20,070]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:23,358]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:26,476]\u001b[0m Trial 11 finished with value: 65.56653244844361 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005968605839962643, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24660921644713688, 'dropout_rate_Layer_2': 0.11917226594993001, 'dropout_rate_Layer_3': 0.37527619569160703, 'dropout_rate_Layer_4': 0.11493947757792866, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.029417290991713276, 'l1_Layer_2': 0.02622193123090456, 'l1_Layer_3': 1.0597170339687338e-05, 'l1_Layer_4': 6.959244692043087e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 275, 'n_units_Layer_3': 250, 'n_units_Layer_4': 240}. Best is trial 1 with value: 47.30242080885605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 65.57 | sMAPE for Validation Set is: 30.22% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 25.28 | sMAPE for Test Set is: 29.86% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:54:27,047]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:35,083]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:36,938]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:39,543]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:41,728]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:42,686]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:43,862]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:45,732]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:52,235]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:54,066]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:58,382]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:54:58,948]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:01,999]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:05,517]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:09,403]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:09,690]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:15,928]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:16,195]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:22,183]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:25,226]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:27,172]\u001b[0m Trial 45 finished with value: 65.18421216279212 and parameters: {'n_hidden': 3, 'learning_rate': 0.002457438110273469, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35201460812163865, 'dropout_rate_Layer_2': 0.39320780641707953, 'dropout_rate_Layer_3': 0.19555131893192196, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018569133303472127, 'l1_Layer_2': 0.006831950685702772, 'l1_Layer_3': 8.586137853394922e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 240, 'n_units_Layer_3': 165}. Best is trial 1 with value: 47.30242080885605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 65.18 | sMAPE for Validation Set is: 30.53% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 22.80 | sMAPE for Test Set is: 28.28% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:55:30,925]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:34,039]\u001b[0m Trial 24 finished with value: 51.84707442831948 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017877703079252501, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32374410251604413, 'dropout_rate_Layer_2': 0.16471975255527238, 'dropout_rate_Layer_3': 0.15226384071378432, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005748838088944531, 'l1_Layer_2': 0.0003645401439623562, 'l1_Layer_3': 1.3360942165679747e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 80, 'n_units_Layer_3': 280}. Best is trial 1 with value: 47.30242080885605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.85 | sMAPE for Validation Set is: 26.32% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.30 | sMAPE for Test Set is: 27.07% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:55:37,539]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:37,625]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:39,384]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:39,520]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:43,209]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:47,294]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:47,712]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:51,724]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:55,379]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:57,659]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:57,800]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:55:58,917]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:56:05,389]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:56:05,759]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:56:11,822]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:56:16,495]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:56:21,152]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:56:23,342]\u001b[0m Trial 66 finished with value: 64.37123806784716 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014175748009747234, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28409098500645813, 'dropout_rate_Layer_2': 0.1442822840194933, 'dropout_rate_Layer_3': 0.07449273064857172, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010140872053257161, 'l1_Layer_2': 0.0003306495386054492, 'l1_Layer_3': 5.083434953897343e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 240, 'n_units_Layer_3': 130}. Best is trial 1 with value: 47.30242080885605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 64.37 | sMAPE for Validation Set is: 29.86% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 24.27 | sMAPE for Test Set is: 29.36% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:56:23,606]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:56:27,320]\u001b[0m Trial 69 finished with value: 66.89359502565485 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016192109439387018, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29648991890713566, 'dropout_rate_Layer_2': 0.13692043397495324, 'dropout_rate_Layer_3': 0.09446220802174406, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007913281333377292, 'l1_Layer_2': 0.0001962697754018301, 'l1_Layer_3': 6.071372586322172e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 230, 'n_units_Layer_3': 105}. Best is trial 1 with value: 47.30242080885605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 66.89 | sMAPE for Validation Set is: 30.91% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 24.74 | sMAPE for Test Set is: 29.68% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:56:31,220]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:56:31,295]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:56:32,948]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:56:39,602]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:56:43,091]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:56:44,989]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:56:48,121]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:56:48,986]\u001b[0m Trial 79 finished with value: 134.2316563360918 and parameters: {'n_hidden': 4, 'learning_rate': 0.07736473092067322, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07918888371990303, 'dropout_rate_Layer_2': 0.2305903758647801, 'dropout_rate_Layer_3': 0.20628602623729392, 'dropout_rate_Layer_4': 0.14209252150481927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004602841660181739, 'l1_Layer_2': 0.0007021935293918861, 'l1_Layer_3': 0.002713496980772996, 'l1_Layer_4': 0.0014102768573652936, 'n_units_Layer_1': 270, 'n_units_Layer_2': 135, 'n_units_Layer_3': 95, 'n_units_Layer_4': 285}. Best is trial 1 with value: 47.30242080885605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 134.23 | sMAPE for Validation Set is: 67.95% | rMAE for Validation Set is: 1.76\n",
      "MAE for Test Set is: 35.90 | sMAPE for Test Set is: 43.90% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:56:50,740]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:56:59,140]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:57:03,693]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:57:06,481]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:57:09,682]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:57:13,509]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:57:19,527]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:57:23,263]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:57:26,847]\u001b[0m Trial 86 finished with value: 46.87390816445235 and parameters: {'n_hidden': 3, 'learning_rate': 0.003973937299767788, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2560598783892008, 'dropout_rate_Layer_2': 0.1636424575407196, 'dropout_rate_Layer_3': 0.0630393586841204, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07816297282635465, 'l1_Layer_2': 6.795053052687353e-05, 'l1_Layer_3': 0.00040458088343624764, 'n_units_Layer_1': 155, 'n_units_Layer_2': 270, 'n_units_Layer_3': 65}. Best is trial 86 with value: 46.87390816445235.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.87 | sMAPE for Validation Set is: 24.09% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.42 | sMAPE for Test Set is: 26.13% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:57:27,928]\u001b[0m Trial 88 finished with value: 51.77462193941049 and parameters: {'n_hidden': 3, 'learning_rate': 0.003970129697249471, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2404086864393687, 'dropout_rate_Layer_2': 0.17056060443806, 'dropout_rate_Layer_3': 0.050156482993343215, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.08410773056519724, 'l1_Layer_2': 0.005077403219108917, 'l1_Layer_3': 0.00034051795533833603, 'n_units_Layer_1': 165, 'n_units_Layer_2': 270, 'n_units_Layer_3': 55}. Best is trial 86 with value: 46.87390816445235.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.77 | sMAPE for Validation Set is: 25.97% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 24.01 | sMAPE for Test Set is: 29.63% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:57:34,684]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:57:34,855]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:57:36,212]\u001b[0m Trial 92 finished with value: 50.7868732687792 and parameters: {'n_hidden': 3, 'learning_rate': 0.003745608959996711, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2354102192209369, 'dropout_rate_Layer_2': 0.19342859343078017, 'dropout_rate_Layer_3': 0.2292563794658322, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0941985845325975, 'l1_Layer_2': 6.579795405253082e-05, 'l1_Layer_3': 0.0004970676788795315, 'n_units_Layer_1': 160, 'n_units_Layer_2': 270, 'n_units_Layer_3': 60}. Best is trial 86 with value: 46.87390816445235.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.79 | sMAPE for Validation Set is: 25.82% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 25.38 | sMAPE for Test Set is: 31.89% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:57:43,324]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:57:45,154]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:57:45,937]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:57:51,971]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:57:56,767]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:57:56,928]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:58:03,795]\u001b[0m Trial 93 finished with value: 44.19033291322531 and parameters: {'n_hidden': 3, 'learning_rate': 0.003730411714425264, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22560459893729662, 'dropout_rate_Layer_2': 0.1706850156865611, 'dropout_rate_Layer_3': 0.04845703046357569, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015503116889429753, 'l1_Layer_2': 7.067493346994078e-05, 'l1_Layer_3': 0.0006506380148729999, 'n_units_Layer_1': 160, 'n_units_Layer_2': 265, 'n_units_Layer_3': 60}. Best is trial 93 with value: 44.19033291322531.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.19 | sMAPE for Validation Set is: 23.16% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 20.47 | sMAPE for Test Set is: 27.41% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:58:05,906]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:58:18,789]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:58:26,238]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:58:30,375]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:58:34,422]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:58:38,693]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:58:41,972]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:58:45,343]\u001b[0m Trial 104 finished with value: 45.67888165460619 and parameters: {'n_hidden': 3, 'learning_rate': 0.004212314551711213, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23590990442759685, 'dropout_rate_Layer_2': 0.16827774383136454, 'dropout_rate_Layer_3': 0.046690618746051224, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.030135078149772357, 'l1_Layer_2': 1.3361847930270704e-05, 'l1_Layer_3': 0.0004452559884231079, 'n_units_Layer_1': 170, 'n_units_Layer_2': 275, 'n_units_Layer_3': 50}. Best is trial 93 with value: 44.19033291322531.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.68 | sMAPE for Validation Set is: 23.83% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 21.13 | sMAPE for Test Set is: 26.89% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:58:47,620]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:58:49,787]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:58:53,583]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:58:55,376]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:58:57,978]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:59:01,483]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:59:02,849]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:59:12,366]\u001b[0m Trial 111 finished with value: 43.60575917600918 and parameters: {'n_hidden': 3, 'learning_rate': 0.0040664835524249045, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3879012796449348, 'dropout_rate_Layer_2': 0.3004816124944776, 'dropout_rate_Layer_3': 0.37442463266756587, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.469894892854931e-05, 'l1_Layer_2': 0.00047460907464610833, 'l1_Layer_3': 0.012860709241418074, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 225}. Best is trial 111 with value: 43.60575917600918.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.61 | sMAPE for Validation Set is: 23.21% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 23.39 | sMAPE for Test Set is: 29.61% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:59:13,477]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:59:17,191]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:59:26,511]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 09:59:46,205]\u001b[0m Trial 122 finished with value: 44.79735429856142 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031657686990510937, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35281013725202526, 'dropout_rate_Layer_2': 0.020708293774586245, 'dropout_rate_Layer_3': 0.359316994923913, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2622415548208613e-05, 'l1_Layer_2': 0.000702040832855979, 'l1_Layer_3': 0.03773970662814507, 'n_units_Layer_1': 195, 'n_units_Layer_2': 260, 'n_units_Layer_3': 270}. Best is trial 111 with value: 43.60575917600918.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.80 | sMAPE for Validation Set is: 23.73% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 22.47 | sMAPE for Test Set is: 28.78% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 09:59:56,687]\u001b[0m Trial 124 finished with value: 44.099935178144996 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020380907264813046, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1529059779470125, 'dropout_rate_Layer_2': 0.10493998395819001, 'dropout_rate_Layer_3': 0.060736978655035745, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010114437414568804, 'l1_Layer_2': 2.3243339339628206e-05, 'l1_Layer_3': 0.00019137497036307065, 'n_units_Layer_1': 120, 'n_units_Layer_2': 205, 'n_units_Layer_3': 85}. Best is trial 111 with value: 43.60575917600918.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.10 | sMAPE for Validation Set is: 23.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 22.19 | sMAPE for Test Set is: 28.55% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:00:00,862]\u001b[0m Trial 120 finished with value: 82.70421138290142 and parameters: {'n_hidden': 3, 'learning_rate': 0.006885155454035897, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14965529289297286, 'dropout_rate_Layer_2': 0.30275113586360847, 'dropout_rate_Layer_3': 0.1544676729283909, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.2346686734602418e-05, 'l1_Layer_2': 0.0004328296868982981, 'l1_Layer_3': 0.004061032279028555, 'n_units_Layer_1': 175, 'n_units_Layer_2': 130, 'n_units_Layer_3': 230}. Best is trial 111 with value: 43.60575917600918.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 82.70 | sMAPE for Validation Set is: 37.10% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 28.56 | sMAPE for Test Set is: 34.00% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:00:05,400]\u001b[0m Trial 123 finished with value: 82.92078468087443 and parameters: {'n_hidden': 4, 'learning_rate': 0.01675441431701309, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27863709110439283, 'dropout_rate_Layer_2': 0.2914788447710912, 'dropout_rate_Layer_3': 0.29069926656730743, 'dropout_rate_Layer_4': 0.3979129203503394, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.196697373936358e-05, 'l1_Layer_2': 5.832039074174091e-05, 'l1_Layer_3': 0.00020131708684997465, 'l1_Layer_4': 0.0021923562121884425, 'n_units_Layer_1': 155, 'n_units_Layer_2': 55, 'n_units_Layer_3': 250, 'n_units_Layer_4': 200}. Best is trial 111 with value: 43.60575917600918.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 82.92 | sMAPE for Validation Set is: 37.10% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 40.05 | sMAPE for Test Set is: 38.91% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:00:06,016]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:00:10,993]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:00:17,316]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:00:26,485]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:00:30,878]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:00:34,890]\u001b[0m Trial 127 finished with value: 45.77904681983606 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033359383801469136, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3562950680324083, 'dropout_rate_Layer_2': 0.033027477443025754, 'dropout_rate_Layer_3': 0.36882271256176036, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2136481257158413e-05, 'l1_Layer_2': 0.0005055225083881931, 'l1_Layer_3': 0.036411013972322895, 'n_units_Layer_1': 190, 'n_units_Layer_2': 260, 'n_units_Layer_3': 285}. Best is trial 111 with value: 43.60575917600918.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.78 | sMAPE for Validation Set is: 24.02% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.27 | sMAPE for Test Set is: 28.33% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:00:36,672]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:00:40,606]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:00:40,842]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:00:49,053]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:01:01,524]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:01:06,351]\u001b[0m Trial 126 finished with value: 42.289070663185754 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034972174876266057, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3514107200847616, 'dropout_rate_Layer_2': 0.03332251763394418, 'dropout_rate_Layer_3': 0.3581460870273889, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3043147720120789e-05, 'l1_Layer_2': 0.0004869688651762305, 'l1_Layer_3': 0.03818853029518443, 'n_units_Layer_1': 185, 'n_units_Layer_2': 250, 'n_units_Layer_3': 280}. Best is trial 126 with value: 42.289070663185754.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.29 | sMAPE for Validation Set is: 22.86% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 22.24 | sMAPE for Test Set is: 28.43% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:01:14,482]\u001b[0m Trial 131 finished with value: 42.911558189791684 and parameters: {'n_hidden': 3, 'learning_rate': 0.002172326799446831, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33236385057753143, 'dropout_rate_Layer_2': 0.07044510688966463, 'dropout_rate_Layer_3': 0.3230182189717713, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.215817630953845e-05, 'l1_Layer_2': 0.00041633588311567774, 'l1_Layer_3': 0.051851435804127245, 'n_units_Layer_1': 180, 'n_units_Layer_2': 210, 'n_units_Layer_3': 300}. Best is trial 126 with value: 42.289070663185754.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.91 | sMAPE for Validation Set is: 22.90% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 22.13 | sMAPE for Test Set is: 27.12% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:01:22,339]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:01:25,722]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:01:41,721]\u001b[0m Trial 139 finished with value: 43.72406660927962 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037930485896637183, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37203563987998656, 'dropout_rate_Layer_2': 0.01662906647394221, 'dropout_rate_Layer_3': 0.3503253295084831, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7954194866094276e-05, 'l1_Layer_2': 0.000717067065704155, 'l1_Layer_3': 0.03841156161792189, 'n_units_Layer_1': 205, 'n_units_Layer_2': 170, 'n_units_Layer_3': 160}. Best is trial 126 with value: 42.289070663185754.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.72 | sMAPE for Validation Set is: 23.43% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 22.60 | sMAPE for Test Set is: 29.22% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:01:45,539]\u001b[0m Trial 141 finished with value: 42.73679119285314 and parameters: {'n_hidden': 3, 'learning_rate': 0.002255831851123637, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.162574082021119, 'dropout_rate_Layer_2': 0.10946329977477158, 'dropout_rate_Layer_3': 0.11308548313525171, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009427634433508165, 'l1_Layer_2': 2.5262214998285085e-05, 'l1_Layer_3': 0.00019614648762640889, 'n_units_Layer_1': 120, 'n_units_Layer_2': 200, 'n_units_Layer_3': 90}. Best is trial 126 with value: 42.289070663185754.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.74 | sMAPE for Validation Set is: 22.53% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 19.56 | sMAPE for Test Set is: 26.98% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:01:48,194]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:02:02,183]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:02:05,172]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:02:06,336]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:02:10,209]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:02:14,494]\u001b[0m Trial 144 finished with value: 68.44588575638429 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006071202103955685, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26857711732699213, 'dropout_rate_Layer_2': 0.019512971063800594, 'dropout_rate_Layer_3': 0.28114766089034815, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0680863284384815, 'l1_Layer_2': 6.335290072292787e-05, 'l1_Layer_3': 5.252174920543208e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 230, 'n_units_Layer_3': 210}. Best is trial 126 with value: 42.289070663185754.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:02:14,532]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 68.45 | sMAPE for Validation Set is: 31.08% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 26.85 | sMAPE for Test Set is: 31.83% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:02:14,692]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:02:25,255]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:02:25,501]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:02:30,326]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:02:30,494]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:02:36,663]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:02:55,632]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:03:05,946]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:03:15,909]\u001b[0m Trial 143 finished with value: 65.91589438981629 and parameters: {'n_hidden': 3, 'learning_rate': 0.011972015062197338, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3926005906839242, 'dropout_rate_Layer_2': 0.2969005639037735, 'dropout_rate_Layer_3': 0.17776638125245225, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.997813174769271e-05, 'l1_Layer_2': 1.0321608270303683e-05, 'l1_Layer_3': 2.4302686818494844e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 80, 'n_units_Layer_3': 255}. Best is trial 126 with value: 42.289070663185754.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 65.92 | sMAPE for Validation Set is: 32.72% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 32.27 | sMAPE for Test Set is: 39.98% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:03:33,900]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:03:34,297]\u001b[0m Trial 158 finished with value: 41.47461476270297 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010300389223444836, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21286054676383517, 'dropout_rate_Layer_2': 0.11448546861284213, 'dropout_rate_Layer_3': 0.04061907995521974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004527040677783782, 'l1_Layer_2': 1.0989908981302975e-05, 'l1_Layer_3': 0.00028074137457638075, 'n_units_Layer_1': 120, 'n_units_Layer_2': 190, 'n_units_Layer_3': 85}. Best is trial 158 with value: 41.47461476270297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.47 | sMAPE for Validation Set is: 22.14% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 19.32 | sMAPE for Test Set is: 26.46% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:03:39,831]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:03:43,101]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:03:49,783]\u001b[0m Trial 161 finished with value: 42.93972030252274 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010753570802460716, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20994539861423905, 'dropout_rate_Layer_2': 0.10660537883335738, 'dropout_rate_Layer_3': 0.0369977980164695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003908119491563877, 'l1_Layer_2': 1.1933037704885183e-05, 'l1_Layer_3': 0.00021454078121873826, 'n_units_Layer_1': 120, 'n_units_Layer_2': 210, 'n_units_Layer_3': 85}. Best is trial 158 with value: 41.47461476270297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.94 | sMAPE for Validation Set is: 22.83% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.20 | sMAPE for Test Set is: 27.11% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:04:05,732]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:04:13,163]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:04:18,330]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:04:19,189]\u001b[0m Trial 163 finished with value: 43.30158813196908 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010252943530302838, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2057023912726735, 'dropout_rate_Layer_2': 0.11892933104617533, 'dropout_rate_Layer_3': 0.12025449153094854, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004345604496322475, 'l1_Layer_2': 0.00011811033101339529, 'l1_Layer_3': 0.00027181356025686573, 'n_units_Layer_1': 100, 'n_units_Layer_2': 190, 'n_units_Layer_3': 85}. Best is trial 158 with value: 41.47461476270297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.30 | sMAPE for Validation Set is: 23.08% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 20.88 | sMAPE for Test Set is: 28.25% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:04:23,918]\u001b[0m Trial 165 finished with value: 43.65188360193033 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009949697653208222, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08355477593259197, 'dropout_rate_Layer_2': 0.11597529025395992, 'dropout_rate_Layer_3': 0.12068411207891253, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005175095086881527, 'l1_Layer_2': 3.15175687779383e-05, 'l1_Layer_3': 0.0010875530963803826, 'n_units_Layer_1': 95, 'n_units_Layer_2': 190, 'n_units_Layer_3': 110}. Best is trial 158 with value: 41.47461476270297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.65 | sMAPE for Validation Set is: 23.15% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 21.12 | sMAPE for Test Set is: 27.71% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:04:25,306]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:04:28,844]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:04:31,837]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:04:34,861]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:04:51,057]\u001b[0m Trial 175 finished with value: 50.263809059833896 and parameters: {'n_hidden': 3, 'learning_rate': 0.002803318520874309, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33084960550699116, 'dropout_rate_Layer_2': 0.18646983273737772, 'dropout_rate_Layer_3': 0.20712225259083436, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011111147795787302, 'l1_Layer_2': 1.0009618389591714e-05, 'l1_Layer_3': 0.07958448711101133, 'n_units_Layer_1': 95, 'n_units_Layer_2': 95, 'n_units_Layer_3': 240}. Best is trial 158 with value: 41.47461476270297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.26 | sMAPE for Validation Set is: 25.55% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 24.25 | sMAPE for Test Set is: 30.08% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:04:51,286]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:05:04,655]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:05:13,357]\u001b[0m Trial 169 finished with value: 42.98931325559398 and parameters: {'n_hidden': 3, 'learning_rate': 0.000529380705483747, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07348026079256717, 'dropout_rate_Layer_2': 0.11037940321045465, 'dropout_rate_Layer_3': 0.11670934952974647, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005311825601690712, 'l1_Layer_2': 2.365178355826706e-05, 'l1_Layer_3': 0.00021317543167326684, 'n_units_Layer_1': 90, 'n_units_Layer_2': 190, 'n_units_Layer_3': 115}. Best is trial 158 with value: 41.47461476270297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.99 | sMAPE for Validation Set is: 23.07% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.25 | sMAPE for Test Set is: 27.27% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:05:25,349]\u001b[0m Trial 177 finished with value: 51.20594127255445 and parameters: {'n_hidden': 3, 'learning_rate': 0.002749784252981962, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3295678714799771, 'dropout_rate_Layer_2': 0.001463819220155843, 'dropout_rate_Layer_3': 0.2165008718926579, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018913788914683965, 'l1_Layer_2': 0.002252565536046609, 'l1_Layer_3': 0.09459758426880065, 'n_units_Layer_1': 95, 'n_units_Layer_2': 190, 'n_units_Layer_3': 235}. Best is trial 158 with value: 41.47461476270297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.21 | sMAPE for Validation Set is: 25.53% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.25 | sMAPE for Test Set is: 28.55% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:05:35,989]\u001b[0m Trial 178 finished with value: 51.2670072445523 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027535399394145164, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24057652616113834, 'dropout_rate_Layer_2': 0.0008478385161442559, 'dropout_rate_Layer_3': 0.2319807672803341, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008798611620719352, 'l1_Layer_2': 0.003167945853219701, 'l1_Layer_3': 0.09961426737053977, 'n_units_Layer_1': 110, 'n_units_Layer_2': 90, 'n_units_Layer_3': 230}. Best is trial 158 with value: 41.47461476270297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.27 | sMAPE for Validation Set is: 25.64% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.39 | sMAPE for Test Set is: 28.85% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:05:40,191]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:05:44,315]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:05:49,481]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:05:52,547]\u001b[0m Trial 153 finished with value: 40.61046692035912 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009388442224241096, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14826951272027833, 'dropout_rate_Layer_2': 0.10114263645248453, 'dropout_rate_Layer_3': 0.12491920780114245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007536932242011386, 'l1_Layer_2': 2.8958736743636556e-05, 'l1_Layer_3': 0.00020832658975676, 'n_units_Layer_1': 50, 'n_units_Layer_2': 135, 'n_units_Layer_3': 140}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.61 | sMAPE for Validation Set is: 21.95% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.36 | sMAPE for Test Set is: 25.38% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:05:57,912]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:01,436]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:06,424]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:09,284]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:09,896]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:19,107]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:19,754]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:25,179]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:26,950]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:27,577]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:31,707]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:34,841]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:35,128]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:37,426]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:41,176]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:41,512]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:43,597]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:46,416]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:54,551]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:55,002]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:56,701]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:06:58,677]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:07:00,862]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:07:08,023]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:07:08,522]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:07:09,167]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:07:15,244]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:07:20,740]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:07:24,268]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:07:26,037]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:07:32,914]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:07:49,109]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:07:51,461]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:07:54,289]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:07:56,871]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:07:58,913]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:08:01,593]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:08:04,180]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:08:06,027]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:08:09,516]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:08:12,423]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:08:17,560]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:08:21,001]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:08:24,036]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:08:29,388]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:08:29,986]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:08:36,693]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:08:41,808]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:08:46,661]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:08:50,471]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:08:54,510]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:08:57,816]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:08:58,422]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:09:02,248]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:09:04,126]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:09:06,401]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:09:06,917]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:09:07,312]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:09:11,505]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:09:13,542]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:09:20,795]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:09:21,255]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:09:29,534]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:09:33,150]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:09:34,332]\u001b[0m Trial 231 finished with value: 43.00503282361634 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011331417666416454, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20631523208120203, 'dropout_rate_Layer_2': 0.11305740888880411, 'dropout_rate_Layer_3': 0.10326509701026254, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004336536152025722, 'l1_Layer_2': 1.0179305322369658e-05, 'l1_Layer_3': 0.0002744551955090229, 'n_units_Layer_1': 100, 'n_units_Layer_2': 195, 'n_units_Layer_3': 85}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.01 | sMAPE for Validation Set is: 23.24% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.96 | sMAPE for Test Set is: 29.00% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:09:38,111]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:09:42,973]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:09:50,156]\u001b[0m Trial 243 finished with value: 45.493056064158175 and parameters: {'n_hidden': 3, 'learning_rate': 0.002035965231353782, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31381672263663357, 'dropout_rate_Layer_2': 0.16757491195507584, 'dropout_rate_Layer_3': 0.15075010134560024, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007650150075719776, 'l1_Layer_2': 0.0015344504513109863, 'l1_Layer_3': 0.05484623815668036, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 275}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.49 | sMAPE for Validation Set is: 23.63% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 20.22 | sMAPE for Test Set is: 26.50% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:09:52,468]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:09:56,216]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:10:01,260]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:10:04,157]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:10:04,373]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:10:10,934]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:10:12,664]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:10:13,246]\u001b[0m Trial 247 finished with value: 42.5780186791249 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014641342849206255, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19402387707611643, 'dropout_rate_Layer_2': 0.15148150459505536, 'dropout_rate_Layer_3': 0.0670615589661146, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017892364560718774, 'l1_Layer_2': 1.9708333658635875e-05, 'l1_Layer_3': 0.00018099848823494876, 'n_units_Layer_1': 105, 'n_units_Layer_2': 195, 'n_units_Layer_3': 90}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.58 | sMAPE for Validation Set is: 22.46% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.42 | sMAPE for Test Set is: 27.23% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:10:17,655]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:10:19,341]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:10:20,820]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:10:21,106]\u001b[0m Trial 250 finished with value: 44.458985704629775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012088290905459239, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21488373985074583, 'dropout_rate_Layer_2': 0.025643268324069993, 'dropout_rate_Layer_3': 0.3426754369830394, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002068573913118833, 'l1_Layer_2': 0.0002537693333808892, 'l1_Layer_3': 0.04297644899997834, 'n_units_Layer_1': 190, 'n_units_Layer_2': 130, 'n_units_Layer_3': 260}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.46 | sMAPE for Validation Set is: 23.52% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 21.47 | sMAPE for Test Set is: 27.52% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:10:27,755]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:10:27,855]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:10:33,794]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:10:38,565]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:10:43,685]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:10:47,571]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:10:52,132]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:10:58,848]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:10:59,429]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:01,456]\u001b[0m Trial 262 finished with value: 89.88257392453527 and parameters: {'n_hidden': 3, 'learning_rate': 0.01015817923614242, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12665371980377765, 'dropout_rate_Layer_2': 0.395492870543244, 'dropout_rate_Layer_3': 0.2470818643434582, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.818613612759396e-05, 'l1_Layer_2': 0.00012394281126936534, 'l1_Layer_3': 3.8916468674031006e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 260, 'n_units_Layer_3': 300}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 89.88 | sMAPE for Validation Set is: 40.24% | rMAE for Validation Set is: 1.18\n",
      "MAE for Test Set is: 27.31 | sMAPE for Test Set is: 31.65% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:11:01,625]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:03,680]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:09,539]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:12,522]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:12,907]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:13,628]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:18,488]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:22,254]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:22,661]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:27,118]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:30,415]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:34,480]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:35,977]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:39,497]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:44,371]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:46,247]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:46,944]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:11:50,752]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:12:05,919]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:12:09,846]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:12:13,488]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:12:16,842]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:12:24,039]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:12:26,876]\u001b[0m Trial 292 finished with value: 43.05286053611579 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015589555542887038, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26636828892046943, 'dropout_rate_Layer_2': 0.10753018234790027, 'dropout_rate_Layer_3': 0.0648926391250002, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001240441833723213, 'l1_Layer_2': 2.248338486246571e-05, 'l1_Layer_3': 0.0005334873502533091, 'n_units_Layer_1': 125, 'n_units_Layer_2': 180, 'n_units_Layer_3': 250}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.05 | sMAPE for Validation Set is: 22.81% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.87 | sMAPE for Test Set is: 27.45% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:12:29,471]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:12:30,265]\u001b[0m Trial 287 finished with value: 65.46263241938372 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006019589308180456, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32063669835329, 'dropout_rate_Layer_2': 0.035985341247198266, 'dropout_rate_Layer_3': 0.2744464536673801, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06742906601256408, 'l1_Layer_2': 3.8254185171096545e-05, 'l1_Layer_3': 5.029549562671209e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 220, 'n_units_Layer_3': 205}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 65.46 | sMAPE for Validation Set is: 30.00% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 23.76 | sMAPE for Test Set is: 29.33% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:12:31,883]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:12:34,826]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:12:37,097]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:12:39,362]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:12:42,504]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:12:47,635]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:12:55,109]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:13:00,744]\u001b[0m Trial 302 finished with value: 71.26745879560433 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023631425935814725, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3263360090326358, 'dropout_rate_Layer_2': 0.0674018362775421, 'dropout_rate_Layer_3': 0.3473652271455827, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.036937502426279065, 'l1_Layer_2': 1.1209752045828776e-05, 'l1_Layer_3': 1.3623379108093367e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 195, 'n_units_Layer_3': 220}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 71.27 | sMAPE for Validation Set is: 32.05% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 26.53 | sMAPE for Test Set is: 30.50% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:13:05,515]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:13:09,733]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:13:22,399]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:13:28,178]\u001b[0m Trial 308 finished with value: 44.26209090479703 and parameters: {'n_hidden': 3, 'learning_rate': 0.001489256428589857, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32197748735882736, 'dropout_rate_Layer_2': 0.16418897263927357, 'dropout_rate_Layer_3': 0.1516307709725675, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.023745473702336296, 'l1_Layer_2': 0.0004916193677430489, 'l1_Layer_3': 0.005641280506526552, 'n_units_Layer_1': 140, 'n_units_Layer_2': 90, 'n_units_Layer_3': 240}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.26 | sMAPE for Validation Set is: 23.14% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 20.05 | sMAPE for Test Set is: 25.91% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:13:30,904]\u001b[0m Trial 311 finished with value: 45.12251726213558 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015180443930594048, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33024433496252026, 'dropout_rate_Layer_2': 0.1692435263858101, 'dropout_rate_Layer_3': 0.1536220681127143, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007068255109264576, 'l1_Layer_2': 0.0057746750632943974, 'l1_Layer_3': 0.00530463407921587, 'n_units_Layer_1': 135, 'n_units_Layer_2': 140, 'n_units_Layer_3': 245}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.12 | sMAPE for Validation Set is: 23.50% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 20.92 | sMAPE for Test Set is: 27.19% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:13:33,201]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:13:34,971]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:13:38,109]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:13:42,057]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:13:42,750]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:13:46,781]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:13:48,244]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:13:52,574]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:13:55,015]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:13:57,081]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:14:03,343]\u001b[0m Trial 312 finished with value: 43.82119790074546 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014621693197583313, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32644241422713705, 'dropout_rate_Layer_2': 0.17269581312428173, 'dropout_rate_Layer_3': 0.14862084846262638, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008907669593381537, 'l1_Layer_2': 0.005957860279422457, 'l1_Layer_3': 0.001339966742989345, 'n_units_Layer_1': 140, 'n_units_Layer_2': 90, 'n_units_Layer_3': 245}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.82 | sMAPE for Validation Set is: 23.06% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 20.25 | sMAPE for Test Set is: 26.38% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:14:05,844]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:14:13,389]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:14:16,649]\u001b[0m Trial 317 finished with value: 62.714697298532975 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009583139696486293, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22563884695019243, 'dropout_rate_Layer_2': 0.09904310713185337, 'dropout_rate_Layer_3': 0.397341735055276, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010447153598867553, 'l1_Layer_2': 0.00011271369782098112, 'l1_Layer_3': 2.6616172632173002e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 170, 'n_units_Layer_3': 270}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.71 | sMAPE for Validation Set is: 28.98% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 21.86 | sMAPE for Test Set is: 27.22% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:14:20,709]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:14:22,779]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:14:25,727]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:14:27,006]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:14:32,817]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:14:33,280]\u001b[0m Trial 327 finished with value: 65.2672046687483 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031681636654626744, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2259660388496328, 'dropout_rate_Layer_2': 0.1085468456124819, 'dropout_rate_Layer_3': 0.3508164266833934, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01154625291062106, 'l1_Layer_2': 0.00033350930119007425, 'l1_Layer_3': 2.564390152983994e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 165, 'n_units_Layer_3': 85}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 65.27 | sMAPE for Validation Set is: 29.94% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 24.09 | sMAPE for Test Set is: 29.40% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:14:39,370]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:14:48,972]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:14:52,775]\u001b[0m Trial 325 finished with value: 60.46860116239366 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009074212034398319, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24097628567218776, 'dropout_rate_Layer_2': 0.34222666911174615, 'dropout_rate_Layer_3': 0.35524246630705847, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007755341110835296, 'l1_Layer_2': 0.0002897263207485001, 'l1_Layer_3': 2.419135989946038e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 240, 'n_units_Layer_3': 80}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.47 | sMAPE for Validation Set is: 28.32% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 21.92 | sMAPE for Test Set is: 27.57% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:15:00,525]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:15:05,370]\u001b[0m Trial 336 finished with value: 45.648400575408715 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014730514710152814, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2991378687903664, 'dropout_rate_Layer_2': 0.138781927595507, 'dropout_rate_Layer_3': 0.19419166955796596, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005430516303097868, 'l1_Layer_2': 0.02089589531215286, 'l1_Layer_3': 0.002575625616278368, 'n_units_Layer_1': 170, 'n_units_Layer_2': 100, 'n_units_Layer_3': 275}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.65 | sMAPE for Validation Set is: 24.18% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.54 | sMAPE for Test Set is: 29.91% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:15:08,181]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:15:11,840]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:15:15,822]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:15:20,400]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:15:24,630]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:15:32,418]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:15:38,024]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:15:38,390]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:15:44,049]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:15:44,472]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:15:48,840]\u001b[0m Trial 339 finished with value: 43.10994841900367 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010934872092986856, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22804912092936616, 'dropout_rate_Layer_2': 0.11024311816056437, 'dropout_rate_Layer_3': 0.022014363935051545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008394103862265186, 'l1_Layer_2': 1.0198740829904422e-05, 'l1_Layer_3': 0.0003805913528367071, 'n_units_Layer_1': 85, 'n_units_Layer_2': 200, 'n_units_Layer_3': 215}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.11 | sMAPE for Validation Set is: 23.06% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 21.00 | sMAPE for Test Set is: 27.69% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:15:52,065]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:15:57,148]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:16:00,838]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:16:05,699]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:16:13,325]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:16:15,509]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:16:19,558]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:16:23,956]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:16:27,015]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:16:28,984]\u001b[0m Trial 333 finished with value: 45.93772541770721 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006291336780783194, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3567479148649147, 'dropout_rate_Layer_2': 0.006639252726835538, 'dropout_rate_Layer_3': 0.3677372290753081, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001258610468783449, 'l1_Layer_2': 7.116950476322263e-05, 'l1_Layer_3': 0.017362622179154453, 'n_units_Layer_1': 175, 'n_units_Layer_2': 255, 'n_units_Layer_3': 210}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.94 | sMAPE for Validation Set is: 23.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.48 | sMAPE for Test Set is: 30.38% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:16:37,050]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:16:42,982]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:16:46,762]\u001b[0m Trial 348 finished with value: 60.69638093274398 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009965647226257012, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22197974742796464, 'dropout_rate_Layer_2': 0.09468950668957861, 'dropout_rate_Layer_3': 0.3459522555950014, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010089686108227091, 'l1_Layer_2': 0.0002083286945052701, 'l1_Layer_3': 3.2495002098118276e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 115, 'n_units_Layer_3': 100}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.70 | sMAPE for Validation Set is: 28.46% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 20.56 | sMAPE for Test Set is: 26.06% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:16:51,300]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:16:55,489]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:16:58,063]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:17:03,808]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:17:09,361]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:17:13,151]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:17:13,729]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:17:16,600]\u001b[0m Trial 356 finished with value: 43.55593630823662 and parameters: {'n_hidden': 3, 'learning_rate': 0.000846012907333451, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3185060351629257, 'dropout_rate_Layer_2': 0.006556465837211027, 'dropout_rate_Layer_3': 0.19425762061411078, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.256049013505848e-05, 'l1_Layer_2': 0.0008625808850784585, 'l1_Layer_3': 0.0009252702944482675, 'n_units_Layer_1': 170, 'n_units_Layer_2': 220, 'n_units_Layer_3': 190}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.56 | sMAPE for Validation Set is: 23.38% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 23.86 | sMAPE for Test Set is: 31.73% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:17:20,349]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:17:22,338]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:17:27,395]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:17:28,038]\u001b[0m Trial 359 finished with value: 59.6938657252349 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009594614329608179, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22502079381700457, 'dropout_rate_Layer_2': 0.35059340463858857, 'dropout_rate_Layer_3': 0.3472876053973755, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00997660021207105, 'l1_Layer_2': 0.0001768307890513636, 'l1_Layer_3': 2.597399974719413e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 165, 'n_units_Layer_3': 100}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.69 | sMAPE for Validation Set is: 28.01% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 20.62 | sMAPE for Test Set is: 26.26% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:17:33,678]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:17:40,267]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:17:45,896]\u001b[0m Trial 371 finished with value: 58.59426777797038 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009294726833765773, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2268282157746441, 'dropout_rate_Layer_2': 0.3587979160796269, 'dropout_rate_Layer_3': 0.364882625081051, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003998169689211298, 'l1_Layer_2': 0.00013711513999530034, 'l1_Layer_3': 0.000429583927651026, 'n_units_Layer_1': 95, 'n_units_Layer_2': 165, 'n_units_Layer_3': 100}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.59 | sMAPE for Validation Set is: 27.78% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 23.17 | sMAPE for Test Set is: 27.86% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:17:48,394]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:17:57,145]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:17:58,751]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:18:05,923]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:18:14,732]\u001b[0m Trial 374 finished with value: 43.18503276981344 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008482000445232061, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3353823188725276, 'dropout_rate_Layer_2': 0.0036129934226414914, 'dropout_rate_Layer_3': 0.19950161152336315, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3394294432711333e-05, 'l1_Layer_2': 0.0007579722239499529, 'l1_Layer_3': 0.001437949381349645, 'n_units_Layer_1': 175, 'n_units_Layer_2': 225, 'n_units_Layer_3': 220}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.19 | sMAPE for Validation Set is: 23.43% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 22.89 | sMAPE for Test Set is: 30.18% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:18:22,335]\u001b[0m Trial 380 finished with value: 63.30483620032694 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017961090917471994, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2690482743370908, 'dropout_rate_Layer_2': 0.35491146161735976, 'dropout_rate_Layer_3': 0.3382336458408728, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004435385197027504, 'l1_Layer_2': 0.0001859705629955069, 'l1_Layer_3': 8.968449773823191e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 115, 'n_units_Layer_3': 105}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 63.30 | sMAPE for Validation Set is: 29.66% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 21.57 | sMAPE for Test Set is: 27.38% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:18:40,051]\u001b[0m Trial 378 finished with value: 45.586506424163304 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008535444655290535, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3348096709705074, 'dropout_rate_Layer_2': 0.02331417018232304, 'dropout_rate_Layer_3': 0.2053435809976441, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1937351716283423e-05, 'l1_Layer_2': 0.0007611203330511834, 'l1_Layer_3': 0.029006202546069584, 'n_units_Layer_1': 165, 'n_units_Layer_2': 230, 'n_units_Layer_3': 195}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.59 | sMAPE for Validation Set is: 23.65% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.04 | sMAPE for Test Set is: 29.27% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:18:43,900]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:18:49,386]\u001b[0m Trial 382 finished with value: 44.443382984241076 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008048738009192144, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.343621475803207, 'dropout_rate_Layer_2': 0.0012869694556658755, 'dropout_rate_Layer_3': 0.11852197331891207, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2782606023249467e-05, 'l1_Layer_2': 0.0010727510499882662, 'l1_Layer_3': 0.00098945270800988, 'n_units_Layer_1': 180, 'n_units_Layer_2': 230, 'n_units_Layer_3': 200}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.44 | sMAPE for Validation Set is: 23.39% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 22.68 | sMAPE for Test Set is: 29.48% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:18:53,570]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:18:57,097]\u001b[0m Trial 383 finished with value: 43.327881023701785 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009089891686211117, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2929632962675158, 'dropout_rate_Layer_2': 0.0018557503710773316, 'dropout_rate_Layer_3': 0.22161053317141235, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009554771715172154, 'l1_Layer_2': 0.0008171446695106244, 'l1_Layer_3': 0.0008909339574837247, 'n_units_Layer_1': 180, 'n_units_Layer_2': 230, 'n_units_Layer_3': 200}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.33 | sMAPE for Validation Set is: 22.89% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 21.61 | sMAPE for Test Set is: 28.41% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:19:02,191]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:19:36,180]\u001b[0m Trial 385 finished with value: 44.60163347787448 and parameters: {'n_hidden': 3, 'learning_rate': 0.000942294689992195, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30251803409771116, 'dropout_rate_Layer_2': 0.00819392720322007, 'dropout_rate_Layer_3': 0.22015094052645223, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7190236886425958e-05, 'l1_Layer_2': 0.0010436478654509095, 'l1_Layer_3': 0.0006061885621263346, 'n_units_Layer_1': 165, 'n_units_Layer_2': 230, 'n_units_Layer_3': 200}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.60 | sMAPE for Validation Set is: 24.46% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 25.14 | sMAPE for Test Set is: 34.04% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:19:39,996]\u001b[0m Trial 386 finished with value: 44.883501640826715 and parameters: {'n_hidden': 3, 'learning_rate': 0.000996326584726739, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.324161676296338, 'dropout_rate_Layer_2': 0.0013232830883674676, 'dropout_rate_Layer_3': 0.21838087045736176, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010693927827641542, 'l1_Layer_2': 0.0010195550462347843, 'l1_Layer_3': 0.00086805081157933, 'n_units_Layer_1': 160, 'n_units_Layer_2': 230, 'n_units_Layer_3': 215}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.88 | sMAPE for Validation Set is: 23.65% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.22 | sMAPE for Test Set is: 30.17% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:19:46,169]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:19:50,070]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:19:54,610]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:19:58,101]\u001b[0m Trial 388 finished with value: 44.34020216758566 and parameters: {'n_hidden': 3, 'learning_rate': 0.000803139726909085, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3284643212544437, 'dropout_rate_Layer_2': 0.000998635275244407, 'dropout_rate_Layer_3': 0.20183297065140782, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008624722490837943, 'l1_Layer_2': 0.0011680280462357665, 'l1_Layer_3': 0.0008244363839500484, 'n_units_Layer_1': 175, 'n_units_Layer_2': 230, 'n_units_Layer_3': 200}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.34 | sMAPE for Validation Set is: 23.22% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 21.90 | sMAPE for Test Set is: 29.88% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:20:05,498]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:20:17,712]\u001b[0m Trial 395 finished with value: 43.061722898700815 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021405585915787294, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33679775590385713, 'dropout_rate_Layer_2': 0.20115750731159293, 'dropout_rate_Layer_3': 0.1425279588830951, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003414318909151905, 'l1_Layer_2': 2.1521194893989757e-05, 'l1_Layer_3': 0.014613338017908935, 'n_units_Layer_1': 205, 'n_units_Layer_2': 95, 'n_units_Layer_3': 245}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.06 | sMAPE for Validation Set is: 22.93% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 21.46 | sMAPE for Test Set is: 27.50% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:20:29,034]\u001b[0m Trial 396 finished with value: 44.505783204375255 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007960006911377837, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3214355495994342, 'dropout_rate_Layer_2': 0.006384043981514776, 'dropout_rate_Layer_3': 0.22396592963281797, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006322161781062297, 'l1_Layer_2': 0.0013396266744629226, 'l1_Layer_3': 0.0012353559662395376, 'n_units_Layer_1': 180, 'n_units_Layer_2': 220, 'n_units_Layer_3': 195}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.51 | sMAPE for Validation Set is: 23.24% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 21.11 | sMAPE for Test Set is: 27.80% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:20:34,349]\u001b[0m Trial 397 finished with value: 59.3437174154349 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008221861081712279, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2196183250793358, 'dropout_rate_Layer_2': 0.34877101252320025, 'dropout_rate_Layer_3': 0.36831234621223174, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022791578960798028, 'l1_Layer_2': 0.0002849636431400144, 'l1_Layer_3': 0.0006539568124579574, 'n_units_Layer_1': 60, 'n_units_Layer_2': 150, 'n_units_Layer_3': 70}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.34 | sMAPE for Validation Set is: 28.01% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 23.86 | sMAPE for Test Set is: 28.71% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:20:45,445]\u001b[0m Trial 391 finished with value: 43.83325040842791 and parameters: {'n_hidden': 3, 'learning_rate': 0.000800127361456764, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2979901773111387, 'dropout_rate_Layer_2': 0.0017671579875800565, 'dropout_rate_Layer_3': 0.2304704734315243, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008652909184827291, 'l1_Layer_2': 0.001264383077125102, 'l1_Layer_3': 0.0008750087329618642, 'n_units_Layer_1': 180, 'n_units_Layer_2': 225, 'n_units_Layer_3': 195}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.83 | sMAPE for Validation Set is: 22.99% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 20.90 | sMAPE for Test Set is: 28.34% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:20:49,456]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:20:52,814]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:20:57,743]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:21:01,656]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:21:09,398]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:21:13,532]\u001b[0m Trial 398 finished with value: 43.793171763101554 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007808322765229485, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29074660081165715, 'dropout_rate_Layer_2': 0.0008065361258270875, 'dropout_rate_Layer_3': 0.2312321284312273, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007303009981150527, 'l1_Layer_2': 0.0013273268549706724, 'l1_Layer_3': 0.001257553786841661, 'n_units_Layer_1': 150, 'n_units_Layer_2': 220, 'n_units_Layer_3': 190}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.79 | sMAPE for Validation Set is: 22.97% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 20.74 | sMAPE for Test Set is: 27.52% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:21:17,652]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:21:25,040]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:21:25,960]\u001b[0m Trial 399 finished with value: 43.50600363688263 and parameters: {'n_hidden': 3, 'learning_rate': 0.000782347839696116, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31248946218098617, 'dropout_rate_Layer_2': 0.0010504944078695557, 'dropout_rate_Layer_3': 0.2304500980134807, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006356940155151111, 'l1_Layer_2': 0.0012643275510705247, 'l1_Layer_3': 0.0015201355202662686, 'n_units_Layer_1': 180, 'n_units_Layer_2': 220, 'n_units_Layer_3': 195}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.51 | sMAPE for Validation Set is: 23.04% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 22.06 | sMAPE for Test Set is: 29.61% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:21:34,359]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:21:34,878]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:21:36,665]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:21:38,197]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:21:46,956]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:21:49,993]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:21:59,301]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:22:02,450]\u001b[0m Trial 412 finished with value: 58.73246619788406 and parameters: {'n_hidden': 3, 'learning_rate': 0.000832781973653034, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16059630026924926, 'dropout_rate_Layer_2': 0.35237909402628315, 'dropout_rate_Layer_3': 0.3700881784411537, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002069202254869201, 'l1_Layer_2': 7.167458027773357e-05, 'l1_Layer_3': 0.0005135221064087202, 'n_units_Layer_1': 60, 'n_units_Layer_2': 155, 'n_units_Layer_3': 70}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.73 | sMAPE for Validation Set is: 27.84% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 23.81 | sMAPE for Test Set is: 28.63% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:22:09,775]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:22:12,224]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:22:14,969]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:22:17,115]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:22:20,503]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:22:22,049]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:22:26,339]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:22:33,486]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:22:44,390]\u001b[0m Trial 417 finished with value: 44.5890999139221 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008462823966569346, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31279607892011096, 'dropout_rate_Layer_2': 0.0005497196502222077, 'dropout_rate_Layer_3': 0.2476290101496333, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006692132777072433, 'l1_Layer_2': 0.001062466550394862, 'l1_Layer_3': 0.001066623891269926, 'n_units_Layer_1': 165, 'n_units_Layer_2': 220, 'n_units_Layer_3': 190}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.59 | sMAPE for Validation Set is: 23.50% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 23.15 | sMAPE for Test Set is: 30.67% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:22:45,056]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:22:49,662]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:22:53,118]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:22:53,754]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:22:54,984]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:22:57,769]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:23:02,411]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:23:04,482]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:23:04,866]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:23:09,207]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:23:11,942]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:23:17,287]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:23:21,471]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:23:22,086]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:23:33,655]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:23:44,297]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:23:59,656]\u001b[0m Trial 443 finished with value: 60.56594768946841 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015075675944896533, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15497986668067343, 'dropout_rate_Layer_2': 0.2694877996706777, 'dropout_rate_Layer_3': 0.29977275567915335, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002131839517886061, 'l1_Layer_2': 8.510699027674572e-05, 'l1_Layer_3': 0.000414926132539098, 'n_units_Layer_1': 50, 'n_units_Layer_2': 165, 'n_units_Layer_3': 70}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.57 | sMAPE for Validation Set is: 28.58% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 23.25 | sMAPE for Test Set is: 28.62% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:24:06,645]\u001b[0m Trial 434 finished with value: 43.31576409235305 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008717800123731117, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30613065239474746, 'dropout_rate_Layer_2': 0.008943941629104842, 'dropout_rate_Layer_3': 0.1281907574282261, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004378050481463239, 'l1_Layer_2': 0.0013729418822456053, 'l1_Layer_3': 0.0011729565813862906, 'n_units_Layer_1': 155, 'n_units_Layer_2': 230, 'n_units_Layer_3': 190}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.32 | sMAPE for Validation Set is: 22.78% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 21.64 | sMAPE for Test Set is: 29.18% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:24:24,814]\u001b[0m Trial 442 finished with value: 43.559530798767305 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006914819743881193, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2746507669436098, 'dropout_rate_Layer_2': 0.00031486145659334304, 'dropout_rate_Layer_3': 0.09052722683329771, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005375614046786656, 'l1_Layer_2': 0.0008391577705214384, 'l1_Layer_3': 0.0016833022168447932, 'n_units_Layer_1': 170, 'n_units_Layer_2': 220, 'n_units_Layer_3': 200}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.56 | sMAPE for Validation Set is: 23.07% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 21.18 | sMAPE for Test Set is: 28.27% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:24:32,531]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:24:37,953]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:24:45,609]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:24:46,596]\u001b[0m Trial 441 finished with value: 42.98340983605029 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006867602548360051, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32950837988750287, 'dropout_rate_Layer_2': 0.007898877681369721, 'dropout_rate_Layer_3': 0.09497937904898898, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00044632410968204253, 'l1_Layer_2': 0.0014685962283230978, 'l1_Layer_3': 0.0006792503353480072, 'n_units_Layer_1': 170, 'n_units_Layer_2': 220, 'n_units_Layer_3': 200}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.98 | sMAPE for Validation Set is: 22.81% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 22.10 | sMAPE for Test Set is: 30.83% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:24:56,986]\u001b[0m Trial 445 finished with value: 43.927563313973906 and parameters: {'n_hidden': 3, 'learning_rate': 0.000963937195341929, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27493237605661747, 'dropout_rate_Layer_2': 0.016063302058643654, 'dropout_rate_Layer_3': 0.11105486339139792, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005515047008595144, 'l1_Layer_2': 0.0025464292060334596, 'l1_Layer_3': 0.000735454889795081, 'n_units_Layer_1': 160, 'n_units_Layer_2': 220, 'n_units_Layer_3': 175}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.93 | sMAPE for Validation Set is: 23.24% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 22.04 | sMAPE for Test Set is: 29.70% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:25:00,962]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:25:02,080]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:25:10,523]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:25:11,183]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:25:28,535]\u001b[0m Trial 449 finished with value: 61.93484464531726 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008092884524113852, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10971014979271655, 'dropout_rate_Layer_2': 0.3626462936936976, 'dropout_rate_Layer_3': 0.3709724990805107, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00037999834527462236, 'l1_Layer_2': 4.5288339258199954e-05, 'l1_Layer_3': 0.0011936951427157817, 'n_units_Layer_1': 60, 'n_units_Layer_2': 155, 'n_units_Layer_3': 110}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.93 | sMAPE for Validation Set is: 28.89% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 31.15 | sMAPE for Test Set is: 33.26% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:25:34,072]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:25:51,253]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:26:04,459]\u001b[0m Trial 455 finished with value: 42.76125309699296 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009836995653436042, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27190528505152406, 'dropout_rate_Layer_2': 0.01380508984713556, 'dropout_rate_Layer_3': 0.10746963390958127, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00040394637860370836, 'l1_Layer_2': 0.002634531030013711, 'l1_Layer_3': 0.0027550046804347248, 'n_units_Layer_1': 160, 'n_units_Layer_2': 215, 'n_units_Layer_3': 215}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.76 | sMAPE for Validation Set is: 22.87% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.79 | sMAPE for Test Set is: 28.03% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:26:13,067]\u001b[0m Trial 457 finished with value: 43.62405917072721 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010481324383947723, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2728072641070505, 'dropout_rate_Layer_2': 0.01207965260331842, 'dropout_rate_Layer_3': 0.10676276515357977, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00040663162622789735, 'l1_Layer_2': 0.0014081337315976522, 'l1_Layer_3': 0.0006778142459937219, 'n_units_Layer_1': 160, 'n_units_Layer_2': 215, 'n_units_Layer_3': 215}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.62 | sMAPE for Validation Set is: 22.89% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 20.81 | sMAPE for Test Set is: 27.71% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:26:16,385]\u001b[0m Trial 453 finished with value: 42.65044693971646 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009593236548925564, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2819262243198121, 'dropout_rate_Layer_2': 0.011800999338487278, 'dropout_rate_Layer_3': 0.09306890277297833, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00035564031489703147, 'l1_Layer_2': 0.0029462974867352203, 'l1_Layer_3': 0.00085725508721944, 'n_units_Layer_1': 160, 'n_units_Layer_2': 215, 'n_units_Layer_3': 170}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.65 | sMAPE for Validation Set is: 22.75% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 21.18 | sMAPE for Test Set is: 28.83% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:26:19,584]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:26:24,078]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:26:42,998]\u001b[0m Trial 458 finished with value: 43.94486083356251 and parameters: {'n_hidden': 3, 'learning_rate': 0.000992638638805788, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.264121595499174, 'dropout_rate_Layer_2': 0.013967473918046501, 'dropout_rate_Layer_3': 0.09999173873519487, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022890858076394504, 'l1_Layer_2': 0.0011646538939445964, 'l1_Layer_3': 0.002559223598083921, 'n_units_Layer_1': 160, 'n_units_Layer_2': 215, 'n_units_Layer_3': 215}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.94 | sMAPE for Validation Set is: 23.04% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 21.20 | sMAPE for Test Set is: 27.78% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:26:46,757]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:26:50,244]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:26:54,569]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:27:02,073]\u001b[0m Trial 459 finished with value: 44.107462750865864 and parameters: {'n_hidden': 3, 'learning_rate': 0.000982975645891913, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2776446034232756, 'dropout_rate_Layer_2': 0.015074576914482544, 'dropout_rate_Layer_3': 0.10606468593840679, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027068734797323424, 'l1_Layer_2': 0.0027080286492416924, 'l1_Layer_3': 0.003312310097765708, 'n_units_Layer_1': 160, 'n_units_Layer_2': 210, 'n_units_Layer_3': 170}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.11 | sMAPE for Validation Set is: 23.45% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 21.73 | sMAPE for Test Set is: 28.91% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:27:11,192]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:27:15,808]\u001b[0m Trial 462 finished with value: 44.09984382715305 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012242028412540287, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2680980431790777, 'dropout_rate_Layer_2': 0.00891174869241458, 'dropout_rate_Layer_3': 0.10283694563360629, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003967860927393322, 'l1_Layer_2': 0.0029523479777172914, 'l1_Layer_3': 0.0027281916714850312, 'n_units_Layer_1': 140, 'n_units_Layer_2': 210, 'n_units_Layer_3': 160}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.10 | sMAPE for Validation Set is: 23.40% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 21.20 | sMAPE for Test Set is: 28.48% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:27:17,401]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:27:17,980]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:27:22,644]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:27:23,946]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:27:30,514]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:27:31,263]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:27:39,230]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:27:39,512]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:27:45,771]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:27:46,438]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:27:52,481]\u001b[0m Trial 465 finished with value: 44.5477216478483 and parameters: {'n_hidden': 3, 'learning_rate': 0.001169411704681532, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25872693611216113, 'dropout_rate_Layer_2': 0.013933158311805683, 'dropout_rate_Layer_3': 0.11256088884887025, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003725069938484838, 'l1_Layer_2': 0.002587833672919864, 'l1_Layer_3': 0.002256513155824821, 'n_units_Layer_1': 145, 'n_units_Layer_2': 205, 'n_units_Layer_3': 165}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.55 | sMAPE for Validation Set is: 22.96% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 21.13 | sMAPE for Test Set is: 27.68% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:27:56,909]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:28:02,569]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:28:11,278]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:28:24,450]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:28:27,874]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:28:28,268]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:28:28,430]\u001b[0m Trial 474 finished with value: 42.71054907548139 and parameters: {'n_hidden': 3, 'learning_rate': 0.001495532280034308, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2623835045942864, 'dropout_rate_Layer_2': 0.014482630588424725, 'dropout_rate_Layer_3': 0.10867576021918819, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003062048549532809, 'l1_Layer_2': 0.004817911486488121, 'l1_Layer_3': 0.0012061607885658354, 'n_units_Layer_1': 140, 'n_units_Layer_2': 210, 'n_units_Layer_3': 160}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.71 | sMAPE for Validation Set is: 22.95% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 21.74 | sMAPE for Test Set is: 29.26% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:28:36,254]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:28:36,400]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:28:43,563]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:28:46,881]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:28:47,637]\u001b[0m Trial 488 finished with value: 49.60260325351906 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014124873367447174, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004228500330850843, 'dropout_rate_Layer_2': 0.2723883224716467, 'dropout_rate_Layer_3': 0.3297396321654324, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00031180034022136106, 'l1_Layer_2': 0.0013256639369147298, 'l1_Layer_3': 0.00030455905338759245, 'n_units_Layer_1': 50, 'n_units_Layer_2': 200, 'n_units_Layer_3': 65}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.60 | sMAPE for Validation Set is: 25.63% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.32 | sMAPE for Test Set is: 28.55% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:28:51,773]\u001b[0m Trial 482 finished with value: 43.99513004015472 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011185612259856361, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2461600154721828, 'dropout_rate_Layer_2': 0.024600948072606918, 'dropout_rate_Layer_3': 0.11966736726893928, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020850535191593313, 'l1_Layer_2': 0.0021207893518033175, 'l1_Layer_3': 0.004070338649175611, 'n_units_Layer_1': 130, 'n_units_Layer_2': 205, 'n_units_Layer_3': 160}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.00 | sMAPE for Validation Set is: 22.80% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 20.95 | sMAPE for Test Set is: 27.22% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:28:54,364]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:28:56,134]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:28:58,170]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:29:01,503]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:29:04,596]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:29:07,198]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:29:19,417]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:29:24,249]\u001b[0m Trial 499 finished with value: 74.42995046291493 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014318740821557287, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0014310600174219463, 'dropout_rate_Layer_2': 0.28011785097146824, 'dropout_rate_Layer_3': 0.3263317695710307, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002799635902634737, 'l1_Layer_2': 0.0014896756579789218, 'l1_Layer_3': 0.00031184296208076765, 'n_units_Layer_1': 50, 'n_units_Layer_2': 205, 'n_units_Layer_3': 70}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.43 | sMAPE for Validation Set is: 34.02% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 22.81 | sMAPE for Test Set is: 27.69% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:29:24,661]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:29:30,587]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:29:30,854]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:29:35,474]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:29:36,410]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:29:41,589]\u001b[0m Trial 491 finished with value: 42.47642961020354 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007605139880557978, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2744014803810132, 'dropout_rate_Layer_2': 0.006700227766994801, 'dropout_rate_Layer_3': 0.10517601848827914, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002793486591712372, 'l1_Layer_2': 0.0014238915095086072, 'l1_Layer_3': 0.00076303532596714, 'n_units_Layer_1': 135, 'n_units_Layer_2': 210, 'n_units_Layer_3': 160}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.48 | sMAPE for Validation Set is: 22.71% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.63 | sMAPE for Test Set is: 27.72% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:29:41,768]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:29:49,349]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:29:53,228]\u001b[0m Trial 507 finished with value: 49.91201749876223 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038161173745775083, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04513275835624733, 'dropout_rate_Layer_2': 0.32786394242338024, 'dropout_rate_Layer_3': 0.04937854130214975, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017254809329519694, 'l1_Layer_2': 0.0009441295834079521, 'l1_Layer_3': 0.0008990367088829702, 'n_units_Layer_1': 65, 'n_units_Layer_2': 70, 'n_units_Layer_3': 120}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.91 | sMAPE for Validation Set is: 25.46% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.53 | sMAPE for Test Set is: 26.67% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:29:58,283]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:30:03,824]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:30:10,112]\u001b[0m Trial 503 finished with value: 43.2143224298954 and parameters: {'n_hidden': 3, 'learning_rate': 0.00160057428984068, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23870191039675356, 'dropout_rate_Layer_2': 0.019115261547173634, 'dropout_rate_Layer_3': 0.1068034589986818, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003238734149629005, 'l1_Layer_2': 0.002254036880193195, 'l1_Layer_3': 0.0025329957889997554, 'n_units_Layer_1': 155, 'n_units_Layer_2': 200, 'n_units_Layer_3': 160}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.21 | sMAPE for Validation Set is: 22.64% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 20.95 | sMAPE for Test Set is: 27.95% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:30:13,554]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:30:13,986]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:30:14,796]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:30:20,557]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:30:25,836]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:30:26,417]\u001b[0m Trial 516 finished with value: 55.138276114259575 and parameters: {'n_hidden': 3, 'learning_rate': 0.003994226293888409, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0616003952079844, 'dropout_rate_Layer_2': 0.3296666543222043, 'dropout_rate_Layer_3': 0.05099864672784596, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00045278999670900243, 'l1_Layer_2': 0.0008555886774484477, 'l1_Layer_3': 0.0008156018762155756, 'n_units_Layer_1': 60, 'n_units_Layer_2': 50, 'n_units_Layer_3': 120}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.14 | sMAPE for Validation Set is: 27.41% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 23.80 | sMAPE for Test Set is: 29.11% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:30:36,658]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:30:41,152]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:30:49,965]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:30:53,021]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:30:56,757]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:30:57,328]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:31:03,394]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:31:06,331]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:31:09,059]\u001b[0m Trial 517 finished with value: 43.56429730592049 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018704473872947593, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2513402107789557, 'dropout_rate_Layer_2': 0.024392142043415978, 'dropout_rate_Layer_3': 0.055759756182112305, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017913703923312752, 'l1_Layer_2': 0.003317174846243575, 'l1_Layer_3': 0.0033444536977424552, 'n_units_Layer_1': 150, 'n_units_Layer_2': 210, 'n_units_Layer_3': 165}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.56 | sMAPE for Validation Set is: 22.82% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 20.76 | sMAPE for Test Set is: 27.14% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:31:11,458]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:31:15,268]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:31:18,074]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:31:24,423]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:31:26,310]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:31:29,690]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:31:33,149]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:31:37,090]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:31:37,649]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:31:45,852]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:31:49,622]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:31:51,422]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:31:54,806]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:31:56,751]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:00,501]\u001b[0m Trial 525 finished with value: 42.643210438662514 and parameters: {'n_hidden': 3, 'learning_rate': 0.001296198242103576, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2821287869436704, 'dropout_rate_Layer_2': 0.015143299756999408, 'dropout_rate_Layer_3': 0.10809178240050468, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000521241400601693, 'l1_Layer_2': 0.0022481163968142664, 'l1_Layer_3': 0.0006482946762428404, 'n_units_Layer_1': 160, 'n_units_Layer_2': 225, 'n_units_Layer_3': 150}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.64 | sMAPE for Validation Set is: 22.97% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 21.62 | sMAPE for Test Set is: 28.92% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:32:00,899]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:09,561]\u001b[0m Trial 537 finished with value: 43.40513158452799 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016767471602673481, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29187311304056784, 'dropout_rate_Layer_2': 0.1598033112041978, 'dropout_rate_Layer_3': 0.20085474308695098, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013320539691399687, 'l1_Layer_2': 1.5560639568950186e-05, 'l1_Layer_3': 0.0017431408087529268, 'n_units_Layer_1': 205, 'n_units_Layer_2': 65, 'n_units_Layer_3': 220}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.41 | sMAPE for Validation Set is: 22.95% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 20.45 | sMAPE for Test Set is: 26.77% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:32:09,791]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:10,091]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:17,645]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:18,124]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:21,982]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:25,552]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:26,229]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:26,423]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:32,748]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:33,851]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:36,514]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:39,306]\u001b[0m Trial 543 finished with value: 44.714210697714385 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019361499180740676, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27616641601411834, 'dropout_rate_Layer_2': 0.00805180674912486, 'dropout_rate_Layer_3': 0.012691284290389682, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002539566883920076, 'l1_Layer_2': 0.003494092836797189, 'l1_Layer_3': 0.0011664916260461535, 'n_units_Layer_1': 160, 'n_units_Layer_2': 220, 'n_units_Layer_3': 160}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.71 | sMAPE for Validation Set is: 23.72% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 22.88 | sMAPE for Test Set is: 30.65% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:32:39,678]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:40,484]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:45,668]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:48,630]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:50,484]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:52,352]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:55,922]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:56,282]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:32:57,100]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:33:03,269]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:33:03,882]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:33:04,182]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:33:09,005]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:33:12,528]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:33:12,585]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:33:17,222]\u001b[0m Trial 565 finished with value: 47.917901562578855 and parameters: {'n_hidden': 3, 'learning_rate': 0.0057006031886419496, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06059286702011356, 'dropout_rate_Layer_2': 0.28364748442666876, 'dropout_rate_Layer_3': 0.06714238338155062, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.150106141390351e-05, 'l1_Layer_2': 0.0013063469883130626, 'l1_Layer_3': 0.00029263263151282085, 'n_units_Layer_1': 65, 'n_units_Layer_2': 75, 'n_units_Layer_3': 90}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.92 | sMAPE for Validation Set is: 24.99% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.12 | sMAPE for Test Set is: 28.16% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:33:19,317]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:33:22,927]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:33:29,695]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:33:32,555]\u001b[0m Trial 575 finished with value: 46.93647186846706 and parameters: {'n_hidden': 3, 'learning_rate': 0.0072144406899684425, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05859489244902763, 'dropout_rate_Layer_2': 0.22973206733708235, 'dropout_rate_Layer_3': 0.06420486671608475, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.552494413992021e-05, 'l1_Layer_2': 0.0032936417801552637, 'l1_Layer_3': 0.0016699075647085828, 'n_units_Layer_1': 120, 'n_units_Layer_2': 80, 'n_units_Layer_3': 135}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.94 | sMAPE for Validation Set is: 24.32% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 25.55 | sMAPE for Test Set is: 29.14% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:33:33,324]\u001b[0m Trial 573 finished with value: 44.438313141908054 and parameters: {'n_hidden': 3, 'learning_rate': 0.004820867680077191, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.060161071941927234, 'dropout_rate_Layer_2': 0.22974169387863191, 'dropout_rate_Layer_3': 0.08188149741833312, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004391498752019903, 'l1_Layer_2': 0.0014039165817251143, 'l1_Layer_3': 0.0002714132319683233, 'n_units_Layer_1': 120, 'n_units_Layer_2': 80, 'n_units_Layer_3': 140}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.44 | sMAPE for Validation Set is: 23.34% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 25.60 | sMAPE for Test Set is: 29.26% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:33:37,449]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:33:38,018]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:33:43,068]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:33:43,322]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:33:44,816]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:33:50,107]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:33:52,859]\u001b[0m Trial 571 finished with value: 45.05436879146475 and parameters: {'n_hidden': 3, 'learning_rate': 0.006427918416479962, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10932023002902255, 'dropout_rate_Layer_2': 0.19014631435094778, 'dropout_rate_Layer_3': 0.16070641002289263, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011565155886683469, 'l1_Layer_2': 2.125023411188379e-05, 'l1_Layer_3': 0.00034033379306531216, 'n_units_Layer_1': 210, 'n_units_Layer_2': 185, 'n_units_Layer_3': 155}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.05 | sMAPE for Validation Set is: 24.02% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.72 | sMAPE for Test Set is: 31.20% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:33:53,150]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:33:57,312]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:00,466]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:01,041]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:01,490]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:04,395]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:11,322]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:11,560]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:12,072]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:12,217]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:20,794]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:23,701]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:25,330]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:29,495]\u001b[0m Trial 596 finished with value: 47.20632011647109 and parameters: {'n_hidden': 3, 'learning_rate': 0.006090697566705204, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06819444170354005, 'dropout_rate_Layer_2': 0.227906769302336, 'dropout_rate_Layer_3': 0.09906270622713903, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015855267052515808, 'l1_Layer_2': 0.0016882352824663894, 'l1_Layer_3': 0.0002668202468405948, 'n_units_Layer_1': 115, 'n_units_Layer_2': 75, 'n_units_Layer_3': 150}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.21 | sMAPE for Validation Set is: 24.73% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 21.76 | sMAPE for Test Set is: 27.08% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:34:31,098]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:33,630]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:33,984]\u001b[0m Trial 594 finished with value: 44.89484352274312 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034390581315827387, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33625092927237554, 'dropout_rate_Layer_2': 0.19741403538864, 'dropout_rate_Layer_3': 0.1558266260139396, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011330564340734964, 'l1_Layer_2': 1.7068804100132643e-05, 'l1_Layer_3': 0.013429683275221664, 'n_units_Layer_1': 145, 'n_units_Layer_2': 95, 'n_units_Layer_3': 235}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.89 | sMAPE for Validation Set is: 23.48% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 21.41 | sMAPE for Test Set is: 27.12% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:34:34,161]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:36,316]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:42,323]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:42,966]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:43,148]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:45,824]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:50,036]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:51,573]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:52,304]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:34:53,118]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:35:00,383]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:35:08,164]\u001b[0m Trial 613 finished with value: 51.43708676787506 and parameters: {'n_hidden': 3, 'learning_rate': 0.026111637465961256, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07672264563760965, 'dropout_rate_Layer_2': 0.23593821739246967, 'dropout_rate_Layer_3': 0.10336361426452667, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.931279626775168e-05, 'l1_Layer_2': 0.0016764872566509199, 'l1_Layer_3': 0.0002554548231257823, 'n_units_Layer_1': 120, 'n_units_Layer_2': 85, 'n_units_Layer_3': 140}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.44 | sMAPE for Validation Set is: 26.26% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 24.21 | sMAPE for Test Set is: 28.93% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:35:08,874]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:35:09,417]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:35:15,790]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:35:16,913]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:35:32,559]\u001b[0m Trial 611 finished with value: 44.48926471657814 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018686898285506597, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30516088768759897, 'dropout_rate_Layer_2': 0.20056046861692445, 'dropout_rate_Layer_3': 0.14502456453227094, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.028908400026875763, 'l1_Layer_2': 5.887633790668631e-05, 'l1_Layer_3': 0.008673508994067651, 'n_units_Layer_1': 140, 'n_units_Layer_2': 85, 'n_units_Layer_3': 220}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.49 | sMAPE for Validation Set is: 23.21% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 20.09 | sMAPE for Test Set is: 26.15% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:35:35,255]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:35:37,470]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:35:40,992]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:35:45,413]\u001b[0m Trial 616 finished with value: 43.119683863686 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018354134853584838, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34560940961850406, 'dropout_rate_Layer_2': 0.2287197932755509, 'dropout_rate_Layer_3': 0.14672532553634737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0032313397884240285, 'l1_Layer_2': 5.643392392307084e-05, 'l1_Layer_3': 0.016352418270768145, 'n_units_Layer_1': 150, 'n_units_Layer_2': 90, 'n_units_Layer_3': 205}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.12 | sMAPE for Validation Set is: 22.85% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 20.05 | sMAPE for Test Set is: 25.96% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:35:50,534]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:35:51,067]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:35:55,853]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:35:56,486]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:36:02,413]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:36:02,845]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:36:03,077]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:36:08,524]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:36:11,236]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:36:16,199]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:36:18,236]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:36:20,627]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:36:26,268]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:36:32,179]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:36:39,539]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:36:42,522]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:36:46,189]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:36:48,676]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:36:52,114]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:36:54,046]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:36:59,244]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:03,480]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:06,346]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:08,861]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:12,989]\u001b[0m Trial 634 finished with value: 42.48414393056925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011697729966442716, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3613024258410385, 'dropout_rate_Layer_2': 0.2184971341315078, 'dropout_rate_Layer_3': 0.11373388152541888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003203520711642732, 'l1_Layer_2': 5.7124616345762483e-05, 'l1_Layer_3': 0.008356493881808558, 'n_units_Layer_1': 140, 'n_units_Layer_2': 115, 'n_units_Layer_3': 210}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.48 | sMAPE for Validation Set is: 22.57% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.41 | sMAPE for Test Set is: 26.50% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:37:15,162]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:17,624]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:17,826]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:18,798]\u001b[0m Trial 620 finished with value: 43.07040466546679 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007876137651121133, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28028080021831964, 'dropout_rate_Layer_2': 5.157934179304347e-05, 'dropout_rate_Layer_3': 0.10189572610096777, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002135393016397499, 'l1_Layer_2': 0.002247613885040309, 'l1_Layer_3': 0.000879381630575957, 'n_units_Layer_1': 170, 'n_units_Layer_2': 205, 'n_units_Layer_3': 210}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.07 | sMAPE for Validation Set is: 23.00% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 21.83 | sMAPE for Test Set is: 30.17% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:37:19,482]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:26,379]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:29,330]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:31,127]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:32,570]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:33,260]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:37,248]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:40,236]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:40,390]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:41,161]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:48,541]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:48,808]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:48,992]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:58,246]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:37:58,416]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:38:04,809]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:38:06,085]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:38:10,745]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:38:14,949]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:38:22,211]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:38:26,898]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:38:36,008]\u001b[0m Trial 661 finished with value: 42.28946100821486 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012680564486906103, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33866300104672165, 'dropout_rate_Layer_2': 0.2102759818873747, 'dropout_rate_Layer_3': 0.1342887273661604, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0035564258522695685, 'l1_Layer_2': 2.3170487171782146e-05, 'l1_Layer_3': 0.008168242441227748, 'n_units_Layer_1': 120, 'n_units_Layer_2': 110, 'n_units_Layer_3': 200}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.29 | sMAPE for Validation Set is: 22.64% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.38 | sMAPE for Test Set is: 26.78% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:38:41,181]\u001b[0m Trial 664 finished with value: 41.989515398556506 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012008760134487794, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36876979507085567, 'dropout_rate_Layer_2': 0.21633411452037737, 'dropout_rate_Layer_3': 0.13151945504965146, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0037122198498544053, 'l1_Layer_2': 2.251498119480703e-05, 'l1_Layer_3': 0.008736156034579752, 'n_units_Layer_1': 120, 'n_units_Layer_2': 115, 'n_units_Layer_3': 160}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.99 | sMAPE for Validation Set is: 22.50% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.26 | sMAPE for Test Set is: 26.32% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:38:50,200]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:39:04,840]\u001b[0m Trial 670 finished with value: 42.24833618155585 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005495163614033527, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04300051525505172, 'dropout_rate_Layer_2': 0.00024775717573196493, 'dropout_rate_Layer_3': 0.09178388345634479, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2647257826358023e-05, 'l1_Layer_2': 0.003611757960059593, 'l1_Layer_3': 0.0009884172758647459, 'n_units_Layer_1': 165, 'n_units_Layer_2': 210, 'n_units_Layer_3': 200}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.25 | sMAPE for Validation Set is: 22.65% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 21.58 | sMAPE for Test Set is: 29.25% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:39:09,436]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:39:17,056]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:39:21,487]\u001b[0m Trial 676 finished with value: 45.14418587124277 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010461321630339047, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2431998176228454, 'dropout_rate_Layer_2': 0.24194851338192375, 'dropout_rate_Layer_3': 0.13044904083483344, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003144908825770181, 'l1_Layer_2': 0.0007191854882717706, 'l1_Layer_3': 0.001508149563813701, 'n_units_Layer_1': 165, 'n_units_Layer_2': 230, 'n_units_Layer_3': 225}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.14 | sMAPE for Validation Set is: 23.62% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.35 | sMAPE for Test Set is: 30.71% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:39:25,226]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:39:28,029]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:39:37,273]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:39:41,368]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:39:46,602]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:39:52,902]\u001b[0m Trial 675 finished with value: 43.096234530141125 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010416060368778981, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2420868764695258, 'dropout_rate_Layer_2': 8.299451919809069e-05, 'dropout_rate_Layer_3': 0.09946641562246115, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007853389654177512, 'l1_Layer_2': 0.00039442131411565026, 'l1_Layer_3': 0.0016189777914360453, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 190}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.10 | sMAPE for Validation Set is: 22.80% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 21.23 | sMAPE for Test Set is: 28.49% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:39:53,823]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:39:58,149]\u001b[0m Trial 682 finished with value: 43.06508176728389 and parameters: {'n_hidden': 3, 'learning_rate': 0.002407721813050891, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23884558410624068, 'dropout_rate_Layer_2': 0.12506653730536937, 'dropout_rate_Layer_3': 0.018211524892398707, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004300695164341253, 'l1_Layer_2': 0.00010340118508290123, 'l1_Layer_3': 0.00012606058337680354, 'n_units_Layer_1': 180, 'n_units_Layer_2': 205, 'n_units_Layer_3': 50}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.07 | sMAPE for Validation Set is: 23.17% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 21.34 | sMAPE for Test Set is: 29.21% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:39:59,092]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:40:00,087]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:40:07,264]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:40:07,451]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:40:18,560]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:40:20,902]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.57 | sMAPE for Validation Set is: 23.70% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 20.88 | sMAPE for Test Set is: 26.53% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:40:22,772]\u001b[0m Trial 692 finished with value: 44.56959467129556 and parameters: {'n_hidden': 3, 'learning_rate': 0.010182201166129128, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.062814296912647, 'dropout_rate_Layer_2': 0.25454919775719076, 'dropout_rate_Layer_3': 0.12813743330145771, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015770001220394766, 'l1_Layer_2': 0.015263020297075441, 'l1_Layer_3': 0.0001073915982547773, 'n_units_Layer_1': 130, 'n_units_Layer_2': 95, 'n_units_Layer_3': 150}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:40:27,060]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:40:30,245]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:40:31,613]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:40:32,640]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:40:35,387]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:40:45,801]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:40:46,698]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:40:52,452]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:40:59,254]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:41:01,360]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:41:06,056]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:41:09,456]\u001b[0m Trial 686 finished with value: 42.80237051316175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007682480705685647, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14737515171888305, 'dropout_rate_Layer_2': 0.012668735517797085, 'dropout_rate_Layer_3': 0.08524163940237649, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.122746127151239e-05, 'l1_Layer_2': 0.005687157864384573, 'l1_Layer_3': 0.0012661959127135785, 'n_units_Layer_1': 175, 'n_units_Layer_2': 210, 'n_units_Layer_3': 200}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.80 | sMAPE for Validation Set is: 22.91% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 21.34 | sMAPE for Test Set is: 28.57% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:41:13,491]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:41:13,749]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:41:20,462]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:41:23,974]\u001b[0m Trial 699 finished with value: 43.828112535223056 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007393919204983898, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20900854171331326, 'dropout_rate_Layer_2': 0.01747561246147355, 'dropout_rate_Layer_3': 0.1092169033164265, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009070880802051169, 'l1_Layer_2': 0.0005233861375686841, 'l1_Layer_3': 0.0013161117796270973, 'n_units_Layer_1': 170, 'n_units_Layer_2': 190, 'n_units_Layer_3': 190}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.83 | sMAPE for Validation Set is: 23.43% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 22.89 | sMAPE for Test Set is: 30.29% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:41:28,687]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:41:29,711]\u001b[0m Trial 710 finished with value: 46.70928699126679 and parameters: {'n_hidden': 3, 'learning_rate': 0.010992982556280407, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.086198410692286, 'dropout_rate_Layer_2': 0.2546416151418801, 'dropout_rate_Layer_3': 0.12575631296194792, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016107134562585597, 'l1_Layer_2': 0.0026084936435904977, 'l1_Layer_3': 9.596820621855593e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 95, 'n_units_Layer_3': 150}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.71 | sMAPE for Validation Set is: 24.39% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 25.37 | sMAPE for Test Set is: 29.24% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:41:36,060]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:41:42,841]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:41:46,263]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:41:46,987]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:41:52,768]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:41:53,237]\u001b[0m Trial 707 finished with value: 44.2838895542817 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007655707587642777, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3404655979788327, 'dropout_rate_Layer_2': 0.021295221780783132, 'dropout_rate_Layer_3': 0.08292466387501395, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007066343483345341, 'l1_Layer_2': 0.0008725659039035017, 'l1_Layer_3': 0.0007806178920427775, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 170}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.28 | sMAPE for Validation Set is: 23.54% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 23.07 | sMAPE for Test Set is: 30.29% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:41:53,373]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:41:53,886]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:41:59,096]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:42:03,113]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:42:03,281]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:42:03,900]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:42:06,842]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:42:11,797]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:42:17,303]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:42:20,918]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:42:27,407]\u001b[0m Trial 724 finished with value: 44.461548809667754 and parameters: {'n_hidden': 3, 'learning_rate': 0.011050870375154665, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09103328646807719, 'dropout_rate_Layer_2': 0.24644579256946034, 'dropout_rate_Layer_3': 0.13812829417206812, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014046211116879753, 'l1_Layer_2': 0.00262586901701713, 'l1_Layer_3': 0.00013523117970864383, 'n_units_Layer_1': 135, 'n_units_Layer_2': 100, 'n_units_Layer_3': 155}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.46 | sMAPE for Validation Set is: 23.52% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.92 | sMAPE for Test Set is: 29.03% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:42:30,834]\u001b[0m Trial 725 finished with value: 44.81821639535147 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026309979009139246, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3406670817869264, 'dropout_rate_Layer_2': 0.19751044344476332, 'dropout_rate_Layer_3': 0.17231417701536286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011948525050101714, 'l1_Layer_2': 2.011779650352723e-05, 'l1_Layer_3': 0.01749223614536655, 'n_units_Layer_1': 130, 'n_units_Layer_2': 90, 'n_units_Layer_3': 225}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.82 | sMAPE for Validation Set is: 23.30% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 20.14 | sMAPE for Test Set is: 25.87% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:42:35,542]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:42:37,586]\u001b[0m Trial 730 finished with value: 44.863431286074814 and parameters: {'n_hidden': 3, 'learning_rate': 0.011243348741615372, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09417871502142933, 'dropout_rate_Layer_2': 0.2445589973923972, 'dropout_rate_Layer_3': 0.13692043332490664, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001292655451934684, 'l1_Layer_2': 0.01366718035497256, 'l1_Layer_3': 0.000104247219739104, 'n_units_Layer_1': 130, 'n_units_Layer_2': 95, 'n_units_Layer_3': 185}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.86 | sMAPE for Validation Set is: 23.73% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 22.35 | sMAPE for Test Set is: 27.15% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:42:40,527]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:42:46,615]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:42:49,353]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:42:52,478]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:42:57,742]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:02,092]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:16,659]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:20,318]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:21,015]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:21,158]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:21,353]\u001b[0m Trial 734 finished with value: 44.12446335754359 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016622175487592393, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09482923976773987, 'dropout_rate_Layer_2': 0.02499142668435047, 'dropout_rate_Layer_3': 0.3623138680422546, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.985446449018652e-05, 'l1_Layer_2': 0.0077027358319730595, 'l1_Layer_3': 0.0013309922425338372, 'n_units_Layer_1': 175, 'n_units_Layer_2': 200, 'n_units_Layer_3': 190}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.12 | sMAPE for Validation Set is: 24.03% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.76 | sMAPE for Test Set is: 32.23% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:43:23,614]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:34,017]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:36,137]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:36,289]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:37,163]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:37,606]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:41,890]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:45,112]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:47,323]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:50,711]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:51,043]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:52,602]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:43:57,698]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:44:03,387]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:44:08,562]\u001b[0m Trial 754 finished with value: 47.2715945623174 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014007877970350906, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31286289198390116, 'dropout_rate_Layer_2': 0.2364014198347414, 'dropout_rate_Layer_3': 0.134068306955154, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.026967606244781197, 'l1_Layer_2': 2.4296963510936776e-05, 'l1_Layer_3': 0.0073181613273805915, 'n_units_Layer_1': 130, 'n_units_Layer_2': 80, 'n_units_Layer_3': 210}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.27 | sMAPE for Validation Set is: 24.18% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 21.26 | sMAPE for Test Set is: 27.18% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:44:12,633]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:44:16,812]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:44:20,818]\u001b[0m Trial 755 finished with value: 42.52888523741141 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013952449148201143, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3155475912966649, 'dropout_rate_Layer_2': 0.23951228499899305, 'dropout_rate_Layer_3': 0.13561191132713898, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022857500277202007, 'l1_Layer_2': 2.548746494346488e-05, 'l1_Layer_3': 0.001068112624345282, 'n_units_Layer_1': 160, 'n_units_Layer_2': 80, 'n_units_Layer_3': 190}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.53 | sMAPE for Validation Set is: 22.65% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 21.23 | sMAPE for Test Set is: 27.72% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:44:21,123]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:44:26,634]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:44:27,164]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:44:36,057]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:44:39,890]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:44:41,341]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:44:46,117]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:44:47,233]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:44:49,103]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:44:54,523]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:44:58,048]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:44:58,509]\u001b[0m Trial 759 finished with value: 45.28447687718232 and parameters: {'n_hidden': 3, 'learning_rate': 0.001082109962120352, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3114341723197094, 'dropout_rate_Layer_2': 0.23688269395983683, 'dropout_rate_Layer_3': 0.1342020571631021, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009210512577857443, 'l1_Layer_2': 2.422586725954562e-05, 'l1_Layer_3': 0.0074155882101370925, 'n_units_Layer_1': 130, 'n_units_Layer_2': 80, 'n_units_Layer_3': 190}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.28 | sMAPE for Validation Set is: 23.60% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 20.76 | sMAPE for Test Set is: 26.88% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:45:02,265]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:45:06,179]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:45:07,042]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:45:13,147]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:45:16,341]\u001b[0m Trial 774 finished with value: 46.53183119590943 and parameters: {'n_hidden': 3, 'learning_rate': 0.014741062018631538, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08787519310846459, 'dropout_rate_Layer_2': 0.20314827420072357, 'dropout_rate_Layer_3': 0.12424302989707908, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022252836213384482, 'l1_Layer_2': 0.00254644611405671, 'l1_Layer_3': 0.00018452938602156046, 'n_units_Layer_1': 130, 'n_units_Layer_2': 90, 'n_units_Layer_3': 150}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.53 | sMAPE for Validation Set is: 24.37% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 25.60 | sMAPE for Test Set is: 29.34% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:45:18,967]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:45:21,912]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:45:22,327]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:45:27,655]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:45:34,464]\u001b[0m Trial 777 finished with value: 50.56997824130777 and parameters: {'n_hidden': 3, 'learning_rate': 0.014782807349329564, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0941126893127455, 'dropout_rate_Layer_2': 0.2105145628121437, 'dropout_rate_Layer_3': 0.11839709610052598, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011758290296812804, 'l1_Layer_2': 0.002719802234216662, 'l1_Layer_3': 0.00021075626440660462, 'n_units_Layer_1': 125, 'n_units_Layer_2': 90, 'n_units_Layer_3': 160}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.57 | sMAPE for Validation Set is: 26.02% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 25.09 | sMAPE for Test Set is: 28.68% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:45:37,110]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:45:38,018]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:45:38,359]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:45:46,917]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:45:50,010]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:45:50,145]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:45:50,839]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:45:55,920]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:45:59,586]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.48 | sMAPE for Validation Set is: 27.76% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 24.72 | sMAPE for Test Set is: 30.25% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:46:01,448]\u001b[0m Trial 790 finished with value: 55.48117613764004 and parameters: {'n_hidden': 3, 'learning_rate': 0.020166096002896417, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05025706342123138, 'dropout_rate_Layer_2': 0.17599555092036737, 'dropout_rate_Layer_3': 0.1488435022852188, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.295215535839001e-05, 'l1_Layer_2': 0.0036086299713930536, 'l1_Layer_3': 5.970588828454194e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 60, 'n_units_Layer_3': 130}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:04,599]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:07,066]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:07,764]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:13,051]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:13,876]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:14,189]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:19,806]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:22,681]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:22,885]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:23,801]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:32,271]\u001b[0m Trial 792 finished with value: 43.87650842348734 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016592078347812756, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17015852947887591, 'dropout_rate_Layer_2': 0.18744690225598035, 'dropout_rate_Layer_3': 0.1458920119166782, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00267833055723203, 'l1_Layer_2': 3.159739884702852e-05, 'l1_Layer_3': 0.01719267620403002, 'n_units_Layer_1': 140, 'n_units_Layer_2': 95, 'n_units_Layer_3': 200}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.88 | sMAPE for Validation Set is: 23.36% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 21.13 | sMAPE for Test Set is: 27.26% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:46:35,872]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:37,346]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:40,412]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:40,715]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:42,476]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:45,825]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:48,778]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:50,903]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.08 | sMAPE for Validation Set is: 26.53% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 25.93 | sMAPE for Test Set is: 29.98% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:46:53,760]\u001b[0m Trial 808 finished with value: 53.0770804944651 and parameters: {'n_hidden': 3, 'learning_rate': 0.039310072242238564, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07090625781808002, 'dropout_rate_Layer_2': 0.15044582717421975, 'dropout_rate_Layer_3': 0.17243721053252614, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020878739575882504, 'l1_Layer_2': 0.008919041921276773, 'l1_Layer_3': 4.023808587879906e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 65, 'n_units_Layer_3': 140}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:54,360]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:54,495]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:46:55,088]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:47:02,041]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:47:02,385]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:47:03,413]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:47:03,465]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:47:10,372]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:47:11,086]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:47:17,577]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:47:17,736]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:47:24,838]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:47:30,783]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:47:31,439]\u001b[0m Trial 825 finished with value: 48.0956855323106 and parameters: {'n_hidden': 3, 'learning_rate': 0.01780413164747418, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10847511671420404, 'dropout_rate_Layer_2': 0.29399575517964227, 'dropout_rate_Layer_3': 0.14695222928052679, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00099779580617861, 'l1_Layer_2': 0.002303083818383464, 'l1_Layer_3': 6.844092738394988e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 80, 'n_units_Layer_3': 145}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.10 | sMAPE for Validation Set is: 24.94% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 22.08 | sMAPE for Test Set is: 27.75% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:47:38,496]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:47:42,319]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:47:42,593]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:47:49,045]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:47:54,455]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:47:55,205]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:48:00,145]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:48:02,599]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:48:05,177]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:48:06,938]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:48:09,513]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:48:12,046]\u001b[0m Trial 823 finished with value: 42.887372126838464 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008807543925532385, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25619154987396, 'dropout_rate_Layer_2': 0.14091518203767317, 'dropout_rate_Layer_3': 0.1167875953756723, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007666985525067332, 'l1_Layer_2': 1.974010969701298e-05, 'l1_Layer_3': 0.00033100278915877495, 'n_units_Layer_1': 220, 'n_units_Layer_2': 185, 'n_units_Layer_3': 120}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.89 | sMAPE for Validation Set is: 23.67% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 22.46 | sMAPE for Test Set is: 31.59% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:48:14,536]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:48:18,081]\u001b[0m Trial 821 finished with value: 41.894120941530616 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009006086444279421, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06552490148329553, 'dropout_rate_Layer_2': 0.13818427591913524, 'dropout_rate_Layer_3': 0.09867873570927758, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0069006627544040255, 'l1_Layer_2': 2.847108241789842e-05, 'l1_Layer_3': 4.710411251761232e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 185, 'n_units_Layer_3': 75}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.89 | sMAPE for Validation Set is: 22.57% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 21.11 | sMAPE for Test Set is: 29.32% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:48:18,480]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:48:23,328]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:48:25,071]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:48:30,384]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:48:33,736]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:48:36,006]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:48:36,230]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:48:54,276]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:49:04,419]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:49:13,946]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:49:23,916]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:49:26,708]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:49:27,798]\u001b[0m Trial 848 finished with value: 42.5590639967914 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008303057392002615, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0544817245988529, 'dropout_rate_Layer_2': 0.14963529565483433, 'dropout_rate_Layer_3': 0.12869812362938388, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006253911602460321, 'l1_Layer_2': 2.2958201797293268e-05, 'l1_Layer_3': 0.0005374942374554319, 'n_units_Layer_1': 110, 'n_units_Layer_2': 195, 'n_units_Layer_3': 90}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.56 | sMAPE for Validation Set is: 22.56% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 21.04 | sMAPE for Test Set is: 27.43% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:49:32,398]\u001b[0m Trial 850 finished with value: 42.00452953774114 and parameters: {'n_hidden': 3, 'learning_rate': 0.000769346241414072, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10050791752465467, 'dropout_rate_Layer_2': 0.1208243577314383, 'dropout_rate_Layer_3': 0.1293943253989128, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006512985760648958, 'l1_Layer_2': 2.3298974239303125e-05, 'l1_Layer_3': 0.0004102832012347571, 'n_units_Layer_1': 155, 'n_units_Layer_2': 195, 'n_units_Layer_3': 85}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.00 | sMAPE for Validation Set is: 22.49% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 21.34 | sMAPE for Test Set is: 28.02% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:49:32,917]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:49:37,881]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:49:38,991]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:49:40,831]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:49:48,423]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:49:48,497]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:49:58,005]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:50:02,454]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:50:06,950]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:50:11,437]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:50:16,053]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:50:22,653]\u001b[0m Trial 854 finished with value: 41.69307351473657 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009938327679700786, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21867495105682733, 'dropout_rate_Layer_2': 0.12670475265060913, 'dropout_rate_Layer_3': 0.12627290175440906, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007849029598252541, 'l1_Layer_2': 2.6709268921626115e-05, 'l1_Layer_3': 0.0004118433752643978, 'n_units_Layer_1': 165, 'n_units_Layer_2': 180, 'n_units_Layer_3': 60}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.69 | sMAPE for Validation Set is: 22.44% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.43 | sMAPE for Test Set is: 27.99% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:50:26,159]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:50:39,332]\u001b[0m Trial 860 finished with value: 41.59968806792876 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006134535346832448, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05041891576604646, 'dropout_rate_Layer_2': 0.14878755261600748, 'dropout_rate_Layer_3': 0.14433073120235823, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007602129031965563, 'l1_Layer_2': 1.987476624635487e-05, 'l1_Layer_3': 1.7727344700993323e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 195, 'n_units_Layer_3': 95}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.60 | sMAPE for Validation Set is: 22.23% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.62 | sMAPE for Test Set is: 27.19% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:50:46,999]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:50:47,350]\u001b[0m Trial 863 finished with value: 41.01370002796253 and parameters: {'n_hidden': 3, 'learning_rate': 0.000732091841603239, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08290603196126617, 'dropout_rate_Layer_2': 0.13543190508018463, 'dropout_rate_Layer_3': 0.142952712461357, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007441588876801687, 'l1_Layer_2': 1.974805318473306e-05, 'l1_Layer_3': 0.0005508931789118552, 'n_units_Layer_1': 115, 'n_units_Layer_2': 195, 'n_units_Layer_3': 95}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.01 | sMAPE for Validation Set is: 22.13% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 19.94 | sMAPE for Test Set is: 27.45% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:50:48,250]\u001b[0m Trial 868 finished with value: 43.76972298284704 and parameters: {'n_hidden': 3, 'learning_rate': 0.001686599835675172, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29232363956877666, 'dropout_rate_Layer_2': 0.17351624945558666, 'dropout_rate_Layer_3': 0.1501164601764703, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004759005818034152, 'l1_Layer_2': 1.0282087684490957e-05, 'l1_Layer_3': 0.016745684642218157, 'n_units_Layer_1': 155, 'n_units_Layer_2': 105, 'n_units_Layer_3': 220}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.77 | sMAPE for Validation Set is: 23.15% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 21.16 | sMAPE for Test Set is: 27.19% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:50:55,371]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:50:56,140]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:51:00,724]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:51:01,462]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:51:05,480]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:51:07,272]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:51:18,913]\u001b[0m Trial 880 finished with value: 48.97544989487312 and parameters: {'n_hidden': 3, 'learning_rate': 0.007326763326512527, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03869085488200122, 'dropout_rate_Layer_2': 0.26135590684661325, 'dropout_rate_Layer_3': 0.19380875199879938, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00033938181206547865, 'l1_Layer_2': 0.0005942966456279776, 'l1_Layer_3': 0.0006290571544368884, 'n_units_Layer_1': 160, 'n_units_Layer_2': 55, 'n_units_Layer_3': 200}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.98 | sMAPE for Validation Set is: 24.89% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 27.27 | sMAPE for Test Set is: 30.41% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:51:23,269]\u001b[0m Trial 870 finished with value: 41.69768851964778 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007335104695268112, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05022791119579441, 'dropout_rate_Layer_2': 0.14869899039287432, 'dropout_rate_Layer_3': 0.13782001786048295, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007457694492989403, 'l1_Layer_2': 2.7447161293382072e-05, 'l1_Layer_3': 0.000518253759009447, 'n_units_Layer_1': 115, 'n_units_Layer_2': 180, 'n_units_Layer_3': 95}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.70 | sMAPE for Validation Set is: 22.56% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 21.22 | sMAPE for Test Set is: 29.06% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:51:26,526]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:51:30,688]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:51:34,881]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:51:35,097]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:51:45,166]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:51:50,267]\u001b[0m Trial 873 finished with value: 41.05802593143292 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005707357423261504, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0952892390642097, 'dropout_rate_Layer_2': 0.13358381820432946, 'dropout_rate_Layer_3': 0.1455369199950573, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008405399651800735, 'l1_Layer_2': 2.906882283152139e-05, 'l1_Layer_3': 1.4181010048997762e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 190, 'n_units_Layer_3': 90}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.06 | sMAPE for Validation Set is: 22.32% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 20.22 | sMAPE for Test Set is: 27.89% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:51:53,673]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:52:00,491]\u001b[0m Trial 887 finished with value: 46.84209202555083 and parameters: {'n_hidden': 3, 'learning_rate': 0.011831822209515086, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016646675868167995, 'dropout_rate_Layer_2': 0.23624743971228984, 'dropout_rate_Layer_3': 0.03480176543973042, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0950134766436216e-05, 'l1_Layer_2': 0.01111375797559403, 'l1_Layer_3': 4.413432802536805e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 95, 'n_units_Layer_3': 175}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.84 | sMAPE for Validation Set is: 24.56% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.69 | sMAPE for Test Set is: 30.84% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:52:04,778]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:52:05,210]\u001b[0m Trial 879 finished with value: 41.73075087865707 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005354631465679654, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07793176562622701, 'dropout_rate_Layer_2': 0.13372763358264, 'dropout_rate_Layer_3': 0.1422616492354237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000769554087765686, 'l1_Layer_2': 2.6465532016932084e-05, 'l1_Layer_3': 1.6924930235167696e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 190, 'n_units_Layer_3': 100}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.73 | sMAPE for Validation Set is: 22.46% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.60 | sMAPE for Test Set is: 27.89% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:52:05,601]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:52:12,825]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:52:13,204]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:52:13,443]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:52:21,814]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:52:22,823]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:52:25,483]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:52:27,310]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:52:33,547]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:52:37,194]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:52:37,628]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:52:43,384]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:52:48,046]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:52:48,943]\u001b[0m Trial 888 finished with value: 41.41141900387667 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005423711814054656, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027546725365878863, 'dropout_rate_Layer_2': 0.13296758470728975, 'dropout_rate_Layer_3': 0.14412724841972904, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007755274646788125, 'l1_Layer_2': 2.9048303127126184e-05, 'l1_Layer_3': 1.894929997723349e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 195, 'n_units_Layer_3': 100}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.41 | sMAPE for Validation Set is: 22.41% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 21.78 | sMAPE for Test Set is: 28.87% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:52:54,936]\u001b[0m Trial 899 finished with value: 43.62162704754585 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016019985180505244, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18148563621193697, 'dropout_rate_Layer_2': 0.17629211438200715, 'dropout_rate_Layer_3': 0.14889260304925905, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004996196313436308, 'l1_Layer_2': 1.1570247657335919e-05, 'l1_Layer_3': 0.009036773745436696, 'n_units_Layer_1': 155, 'n_units_Layer_2': 105, 'n_units_Layer_3': 200}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.62 | sMAPE for Validation Set is: 23.01% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 20.09 | sMAPE for Test Set is: 25.92% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:53:00,704]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:53:08,679]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:53:16,203]\u001b[0m Trial 902 finished with value: 44.13748886596778 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011943518087096155, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28501487185954943, 'dropout_rate_Layer_2': 0.3956153734808066, 'dropout_rate_Layer_3': 0.13777835759728146, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0045007181909248765, 'l1_Layer_2': 1.1798203743849287e-05, 'l1_Layer_3': 0.010840505746135515, 'n_units_Layer_1': 155, 'n_units_Layer_2': 105, 'n_units_Layer_3': 220}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.14 | sMAPE for Validation Set is: 23.11% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 20.06 | sMAPE for Test Set is: 26.05% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:53:25,634]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:53:33,623]\u001b[0m Trial 905 finished with value: 41.46501252522682 and parameters: {'n_hidden': 3, 'learning_rate': 0.000713424345166031, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09833197770149574, 'dropout_rate_Layer_2': 0.13294813741523734, 'dropout_rate_Layer_3': 0.1368173618970907, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008663384255930002, 'l1_Layer_2': 2.1252866199770394e-05, 'l1_Layer_3': 1.5104553477264903e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 195, 'n_units_Layer_3': 90}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.47 | sMAPE for Validation Set is: 22.39% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 20.04 | sMAPE for Test Set is: 27.60% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:53:36,533]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:53:40,458]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:53:43,704]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:53:44,494]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:53:49,057]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:53:50,069]\u001b[0m Trial 906 finished with value: 41.47632965550798 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005956397065943375, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05168554009239711, 'dropout_rate_Layer_2': 0.13174366774209584, 'dropout_rate_Layer_3': 0.13127162562202732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008431223356769784, 'l1_Layer_2': 2.6886838429197014e-05, 'l1_Layer_3': 1.576193871709395e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 195, 'n_units_Layer_3': 90}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.48 | sMAPE for Validation Set is: 22.37% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 21.57 | sMAPE for Test Set is: 28.38% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:53:59,811]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:54:07,294]\u001b[0m Trial 909 finished with value: 41.57758284486039 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005852949046817622, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020621446288451414, 'dropout_rate_Layer_2': 0.12988656635593457, 'dropout_rate_Layer_3': 0.15470219845077166, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008561336250080178, 'l1_Layer_2': 2.783913081806036e-05, 'l1_Layer_3': 1.1997388894616299e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 195, 'n_units_Layer_3': 90}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.58 | sMAPE for Validation Set is: 22.33% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 21.48 | sMAPE for Test Set is: 27.80% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:54:15,699]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:54:16,449]\u001b[0m Trial 919 finished with value: 44.730336877895674 and parameters: {'n_hidden': 3, 'learning_rate': 0.010261404081408056, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017757948055075634, 'dropout_rate_Layer_2': 0.23936641397841885, 'dropout_rate_Layer_3': 0.027200357681790154, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.677975524818786e-05, 'l1_Layer_2': 0.009548076974372207, 'l1_Layer_3': 4.4339177022365994e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 95, 'n_units_Layer_3': 130}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.73 | sMAPE for Validation Set is: 23.66% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.42 | sMAPE for Test Set is: 28.03% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:54:20,269]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:54:25,208]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:54:28,618]\u001b[0m Trial 916 finished with value: 42.20338406517297 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007029703896883141, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09898322303576973, 'dropout_rate_Layer_2': 0.14834285426728352, 'dropout_rate_Layer_3': 0.14493216687540308, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007365173314960857, 'l1_Layer_2': 2.091942001744941e-05, 'l1_Layer_3': 1.1322659536281711e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 200, 'n_units_Layer_3': 100}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.20 | sMAPE for Validation Set is: 22.59% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.01 | sMAPE for Test Set is: 27.34% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:54:31,738]\u001b[0m Trial 922 finished with value: 46.362554449244804 and parameters: {'n_hidden': 3, 'learning_rate': 0.02203715986641157, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024912728400194376, 'dropout_rate_Layer_2': 0.23884527370797162, 'dropout_rate_Layer_3': 0.03096229331898675, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4198056166034927e-05, 'l1_Layer_2': 0.010914190572950644, 'l1_Layer_3': 4.143644086138176e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 100, 'n_units_Layer_3': 170}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.36 | sMAPE for Validation Set is: 24.38% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 24.08 | sMAPE for Test Set is: 29.07% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:54:50,085]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:55:02,422]\u001b[0m Trial 920 finished with value: 41.65006340421611 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007195826497969052, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01197463852127921, 'dropout_rate_Layer_2': 0.13937367983382803, 'dropout_rate_Layer_3': 0.14481450816023927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010229097348613797, 'l1_Layer_2': 2.6879387289848244e-05, 'l1_Layer_3': 1.0000443109435799e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 185, 'n_units_Layer_3': 100}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.65 | sMAPE for Validation Set is: 22.45% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 21.27 | sMAPE for Test Set is: 28.37% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:55:12,519]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:55:18,276]\u001b[0m Trial 924 finished with value: 41.11672733784998 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006977537202398239, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.049833902101461935, 'dropout_rate_Layer_2': 0.13642890812614325, 'dropout_rate_Layer_3': 0.14592666363375006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010212619209517357, 'l1_Layer_2': 2.57044227449061e-05, 'l1_Layer_3': 2.703152701342413e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 185, 'n_units_Layer_3': 90}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.12 | sMAPE for Validation Set is: 22.22% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 20.81 | sMAPE for Test Set is: 27.63% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:55:23,845]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:55:24,482]\u001b[0m Trial 926 finished with value: 40.84863529305773 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006901383908100386, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012903469593415939, 'dropout_rate_Layer_2': 0.13698311108912126, 'dropout_rate_Layer_3': 0.14526153770892566, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010055647541274864, 'l1_Layer_2': 2.619320615582814e-05, 'l1_Layer_3': 1.2799842383791225e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 190, 'n_units_Layer_3': 100}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.85 | sMAPE for Validation Set is: 21.98% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 20.58 | sMAPE for Test Set is: 27.25% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:55:30,170]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:55:35,291]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:55:40,726]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:55:45,243]\u001b[0m Trial 933 finished with value: 45.915894303348466 and parameters: {'n_hidden': 3, 'learning_rate': 0.022450591307017497, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012542639985941094, 'dropout_rate_Layer_2': 0.21826414992986476, 'dropout_rate_Layer_3': 0.21783762629913078, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.539354218555689e-05, 'l1_Layer_2': 0.04483995502577176, 'l1_Layer_3': 8.11055740981439e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 105, 'n_units_Layer_3': 155}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.92 | sMAPE for Validation Set is: 24.18% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.28 | sMAPE for Test Set is: 28.40% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:55:50,614]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:55:53,330]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:55:57,021]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:56:00,107]\u001b[0m Trial 929 finished with value: 41.5689130415075 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007426063732765296, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014885987696401723, 'dropout_rate_Layer_2': 0.13815281624275666, 'dropout_rate_Layer_3': 0.14503766904113571, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010407965668939093, 'l1_Layer_2': 2.66786310472852e-05, 'l1_Layer_3': 1.7062530152757405e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 190, 'n_units_Layer_3': 100}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.57 | sMAPE for Validation Set is: 22.45% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.04 | sMAPE for Test Set is: 27.28% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:56:00,579]\u001b[0m Trial 928 finished with value: 41.36461965128876 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007264245041104292, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015225757070242554, 'dropout_rate_Layer_2': 0.13833399421413936, 'dropout_rate_Layer_3': 0.14532032121986047, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010517026293677262, 'l1_Layer_2': 2.6809067827257252e-05, 'l1_Layer_3': 1.248935465345459e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 190, 'n_units_Layer_3': 100}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.36 | sMAPE for Validation Set is: 22.42% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 21.59 | sMAPE for Test Set is: 28.85% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:56:01,666]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:56:01,831]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:56:09,521]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:56:12,679]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:56:13,784]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:56:17,570]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:56:18,871]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:56:23,791]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:56:24,317]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:56:29,592]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:56:29,780]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:56:30,365]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:56:30,699]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:56:38,285]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:56:40,396]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:56:40,882]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:56:51,839]\u001b[0m Trial 957 finished with value: 50.21474026827394 and parameters: {'n_hidden': 3, 'learning_rate': 0.035751278830744936, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011618226609293451, 'dropout_rate_Layer_2': 0.2175624523621075, 'dropout_rate_Layer_3': 0.2421842139407124, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4690170962917793e-05, 'l1_Layer_2': 0.04904829509715494, 'l1_Layer_3': 3.454436839444788e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 105, 'n_units_Layer_3': 165}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.21 | sMAPE for Validation Set is: 25.44% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.67 | sMAPE for Test Set is: 27.42% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:56:56,957]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:57:00,519]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:57:04,867]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:57:06,720]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:57:09,656]\u001b[0m Trial 956 finished with value: 43.13512052194144 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016900888538371108, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13715795805152572, 'dropout_rate_Layer_2': 0.3103949673882476, 'dropout_rate_Layer_3': 0.007840379049928348, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013620403355763925, 'l1_Layer_2': 2.3614731125169603e-05, 'l1_Layer_3': 0.013045599544440869, 'n_units_Layer_1': 150, 'n_units_Layer_2': 110, 'n_units_Layer_3': 210}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.14 | sMAPE for Validation Set is: 23.20% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 21.35 | sMAPE for Test Set is: 27.59% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:57:17,158]\u001b[0m Trial 952 finished with value: 42.06201710464901 and parameters: {'n_hidden': 3, 'learning_rate': 0.000700728350532826, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023754331710827685, 'dropout_rate_Layer_2': 0.14514199175458828, 'dropout_rate_Layer_3': 0.1431740610158939, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000900560347568105, 'l1_Layer_2': 3.198381253563004e-05, 'l1_Layer_3': 1.0462217386339518e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 195, 'n_units_Layer_3': 105}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.06 | sMAPE for Validation Set is: 22.67% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.64 | sMAPE for Test Set is: 28.41% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:57:25,549]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:57:28,816]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:57:31,664]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:57:32,335]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:57:35,697]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:57:39,030]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:57:39,434]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:57:45,111]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:57:51,326]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:57:53,975]\u001b[0m Trial 961 finished with value: 42.016358221539015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007515802836701148, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018243951445012133, 'dropout_rate_Layer_2': 0.1325982292940059, 'dropout_rate_Layer_3': 0.13163304450071017, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012115763758469966, 'l1_Layer_2': 2.6337784227706942e-05, 'l1_Layer_3': 2.244026307547769e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 195, 'n_units_Layer_3': 95}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.02 | sMAPE for Validation Set is: 22.63% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.79 | sMAPE for Test Set is: 28.56% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:57:57,496]\u001b[0m Trial 971 finished with value: 44.35860332417976 and parameters: {'n_hidden': 3, 'learning_rate': 0.02758771416805314, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03048860840529762, 'dropout_rate_Layer_2': 0.24232532723360795, 'dropout_rate_Layer_3': 0.21716846215364494, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.911125081740857e-05, 'l1_Layer_2': 0.02671928397851098, 'l1_Layer_3': 7.360323721719906e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 125}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.36 | sMAPE for Validation Set is: 23.75% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 22.67 | sMAPE for Test Set is: 27.74% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:58:02,183]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:58:02,294]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:58:08,156]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:58:12,437]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:58:13,065]\u001b[0m Trial 973 finished with value: 45.548578359259345 and parameters: {'n_hidden': 3, 'learning_rate': 0.022129586149269895, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02940544381454666, 'dropout_rate_Layer_2': 0.1826483561818962, 'dropout_rate_Layer_3': 0.03592336160505436, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1944288601096285e-05, 'l1_Layer_2': 0.02153369042644194, 'l1_Layer_3': 7.647480737957231e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 195}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.55 | sMAPE for Validation Set is: 24.13% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.58 | sMAPE for Test Set is: 27.64% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:58:14,256]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:58:19,980]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:58:22,572]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:58:26,380]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:58:29,449]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:58:37,128]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:58:47,153]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.00 | sMAPE for Validation Set is: 22.12% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 21.17 | sMAPE for Test Set is: 28.30% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:58:53,946]\u001b[0m Trial 974 finished with value: 41.002253668347656 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006998400159445465, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0024576900707100544, 'dropout_rate_Layer_2': 0.13249103284334146, 'dropout_rate_Layer_3': 0.14280563318070427, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009606291038235878, 'l1_Layer_2': 2.5238644088377093e-05, 'l1_Layer_3': 1.0587834408482893e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 195, 'n_units_Layer_3': 95}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:58:57,319]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:58:58,070]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:59:05,024]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:59:09,373]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:59:12,113]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:59:18,706]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:59:18,949]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:59:20,073]\u001b[0m Trial 980 finished with value: 41.58763070656156 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006990314089182101, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0019329921679486304, 'dropout_rate_Layer_2': 0.1320649520616143, 'dropout_rate_Layer_3': 0.14468133621625032, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009517504167580224, 'l1_Layer_2': 2.5655010305256625e-05, 'l1_Layer_3': 2.031343281949406e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 195, 'n_units_Layer_3': 95}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:59:20,079]\u001b[0m Trial 985 finished with value: 41.69462917130642 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006954585790204913, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01598537924915002, 'dropout_rate_Layer_2': 0.1327086944276116, 'dropout_rate_Layer_3': 0.1420136481547244, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009711506165950897, 'l1_Layer_2': 2.4959013991652434e-05, 'l1_Layer_3': 1.8879544777694408e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 195, 'n_units_Layer_3': 95}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.59 | sMAPE for Validation Set is: 22.43% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 21.51 | sMAPE for Test Set is: 28.52% | rMAE for Test Set is: 0.67\n",
      "MAE for Validation Set is: 41.69 | sMAPE for Validation Set is: 22.40% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.06 | sMAPE for Test Set is: 27.18% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 10:59:26,060]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:59:31,663]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:59:32,206]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:59:35,751]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:59:39,714]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:59:40,778]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:59:42,505]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:59:49,272]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:59:52,496]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 10:59:55,232]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:00:00,278]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:00:03,753]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:00:03,988]\u001b[0m Trial 1002 finished with value: 46.73315870661529 and parameters: {'n_hidden': 3, 'learning_rate': 0.030492851720782987, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030435854283250414, 'dropout_rate_Layer_2': 0.1544405386679505, 'dropout_rate_Layer_3': 0.22025307145958922, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.390106886824508e-05, 'l1_Layer_2': 0.025543702350823424, 'l1_Layer_3': 7.760887800448271e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 65, 'n_units_Layer_3': 110}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.73 | sMAPE for Validation Set is: 24.50% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 21.02 | sMAPE for Test Set is: 26.77% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:00:08,969]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:00:12,323]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:00:13,390]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:00:20,549]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.17 | sMAPE for Validation Set is: 22.98% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 20.78 | sMAPE for Test Set is: 26.26% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:00:22,971]\u001b[0m Trial 995 finished with value: 43.1707998552269 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008021368089841708, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27467880295263436, 'dropout_rate_Layer_2': 0.020699924198723678, 'dropout_rate_Layer_3': 0.09542399433633765, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005131556513185225, 'l1_Layer_2': 0.0007996437554540522, 'l1_Layer_3': 0.0008603635220605924, 'n_units_Layer_1': 160, 'n_units_Layer_2': 225, 'n_units_Layer_3': 145}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:00:24,182]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:00:26,274]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:00:30,014]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:00:33,318]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:00:37,429]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:00:40,913]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:00:45,793]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:00:48,662]\u001b[0m Trial 1010 finished with value: 41.63659870221405 and parameters: {'n_hidden': 3, 'learning_rate': 0.00167987145893401, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23754346806612897, 'dropout_rate_Layer_2': 0.3718393067214146, 'dropout_rate_Layer_3': 0.2232097344186579, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005395070907111029, 'l1_Layer_2': 1.722771508654632e-05, 'l1_Layer_3': 0.0020805331337977206, 'n_units_Layer_1': 150, 'n_units_Layer_2': 95, 'n_units_Layer_3': 230}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.64 | sMAPE for Validation Set is: 22.41% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.65 | sMAPE for Test Set is: 26.69% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:00:51,466]\u001b[0m Trial 1016 finished with value: 43.31123950351772 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015477502563544447, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3519831162948086, 'dropout_rate_Layer_2': 0.17398258022420982, 'dropout_rate_Layer_3': 0.15454051150645318, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011005543605202936, 'l1_Layer_2': 1.721977476510549e-05, 'l1_Layer_3': 0.002154391383595495, 'n_units_Layer_1': 150, 'n_units_Layer_2': 80, 'n_units_Layer_3': 235}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.31 | sMAPE for Validation Set is: 22.80% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 21.18 | sMAPE for Test Set is: 27.15% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:00:54,934]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:00:57,508]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:01:01,626]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:01:02,033]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:01:06,494]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:01:09,332]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:01:10,670]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:01:13,450]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:01:16,060]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:01:19,199]\u001b[0m Trial 1022 finished with value: 43.48815800913663 and parameters: {'n_hidden': 3, 'learning_rate': 0.01649409777139333, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009809977610139324, 'dropout_rate_Layer_2': 0.2650631863929133, 'dropout_rate_Layer_3': 0.022454675215759633, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.027433443229913e-05, 'l1_Layer_2': 0.07484334502716058, 'l1_Layer_3': 6.214337146560086e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 195}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.49 | sMAPE for Validation Set is: 23.05% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 21.43 | sMAPE for Test Set is: 26.46% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:01:19,553]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:01:24,764]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:01:25,328]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:01:29,140]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:01:30,767]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:01:35,926]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:01:38,441]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:01:41,001]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:01:47,234]\u001b[0m Trial 1033 finished with value: 42.353091975812355 and parameters: {'n_hidden': 3, 'learning_rate': 0.001484073602803292, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22487971638683232, 'dropout_rate_Layer_2': 0.17974817955233813, 'dropout_rate_Layer_3': 0.3381093363342479, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013099389034628892, 'l1_Layer_2': 2.21144300471232e-05, 'l1_Layer_3': 0.00219222017934396, 'n_units_Layer_1': 150, 'n_units_Layer_2': 75, 'n_units_Layer_3': 235}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.35 | sMAPE for Validation Set is: 22.76% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.25 | sMAPE for Test Set is: 26.10% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:01:50,968]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:01:59,705]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:02:06,388]\u001b[0m Trial 1041 finished with value: 42.618689360361074 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021567458617010437, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2547336215241961, 'dropout_rate_Layer_2': 0.29782168588547414, 'dropout_rate_Layer_3': 0.3471589865482546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001205897390056113, 'l1_Layer_2': 1.6964390257782564e-05, 'l1_Layer_3': 0.002858199962356017, 'n_units_Layer_1': 145, 'n_units_Layer_2': 65, 'n_units_Layer_3': 230}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.62 | sMAPE for Validation Set is: 22.82% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.60 | sMAPE for Test Set is: 26.54% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:02:10,423]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:02:11,038]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:02:17,062]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:02:21,724]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:02:22,526]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:02:22,607]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:02:29,603]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:02:30,941]\u001b[0m Trial 1039 finished with value: 42.159282609648315 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009601126815540661, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3527302623246591, 'dropout_rate_Layer_2': 0.05742879808590584, 'dropout_rate_Layer_3': 0.2613308157357348, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.594317963883718e-05, 'l1_Layer_2': 0.004021813933212015, 'l1_Layer_3': 0.0006965107242144366, 'n_units_Layer_1': 135, 'n_units_Layer_2': 215, 'n_units_Layer_3': 160}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.16 | sMAPE for Validation Set is: 22.77% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 19.97 | sMAPE for Test Set is: 26.12% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:02:35,607]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:02:36,213]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:02:41,658]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:02:42,220]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:02:42,405]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:02:50,879]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:02:51,290]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:02:52,186]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:02:57,652]\u001b[0m Trial 1057 finished with value: 47.31309712113392 and parameters: {'n_hidden': 3, 'learning_rate': 0.023615919382919476, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014474084013210584, 'dropout_rate_Layer_2': 0.28871327567384514, 'dropout_rate_Layer_3': 0.04211270413535797, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0675011454105251e-05, 'l1_Layer_2': 0.04746641194521445, 'l1_Layer_3': 5.2370485922358186e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 190}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.31 | sMAPE for Validation Set is: 25.02% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 23.15 | sMAPE for Test Set is: 28.78% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:03:01,050]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:03,986]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:04,646]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:06,063]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:07,693]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:11,359]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:14,645]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:16,677]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:17,181]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:20,840]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:25,329]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:29,202]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:29,706]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:30,227]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:30,923]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:36,381]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:40,562]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:40,801]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:43,968]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:48,422]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:03:50,000]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:04:00,081]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:04:05,178]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:04:12,238]\u001b[0m Trial 1083 finished with value: 41.99963740365687 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016228263214796712, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22444674250383623, 'dropout_rate_Layer_2': 0.22897654759011724, 'dropout_rate_Layer_3': 0.36633094351459167, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001707331911669842, 'l1_Layer_2': 1.0039780574022656e-05, 'l1_Layer_3': 0.0013311608774901514, 'n_units_Layer_1': 135, 'n_units_Layer_2': 70, 'n_units_Layer_3': 240}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.00 | sMAPE for Validation Set is: 22.48% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.18 | sMAPE for Test Set is: 26.26% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:04:16,467]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:04:21,784]\u001b[0m Trial 1086 finished with value: 46.83097781608446 and parameters: {'n_hidden': 3, 'learning_rate': 0.028165681348991427, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03559882931803878, 'dropout_rate_Layer_2': 0.24226806565890077, 'dropout_rate_Layer_3': 0.19687516438455122, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6963917083668063e-05, 'l1_Layer_2': 0.039828253301473, 'l1_Layer_3': 2.915541361189694e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 80, 'n_units_Layer_3': 130}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.83 | sMAPE for Validation Set is: 24.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 21.82 | sMAPE for Test Set is: 26.84% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:04:22,733]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:04:28,772]\u001b[0m Trial 1080 finished with value: 42.71335254597986 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008485861879114153, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017624616682591746, 'dropout_rate_Layer_2': 0.13349867352343253, 'dropout_rate_Layer_3': 0.17053472737967948, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005740736520999514, 'l1_Layer_2': 3.743404598786606e-05, 'l1_Layer_3': 1.6598615089641648e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 185, 'n_units_Layer_3': 80}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.71 | sMAPE for Validation Set is: 22.91% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 22.13 | sMAPE for Test Set is: 29.13% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:04:30,139]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:04:30,909]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:04:36,478]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:04:36,703]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:04:40,246]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:04:46,751]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:04:51,971]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:04:55,745]\u001b[0m Trial 1096 finished with value: 44.19349157684119 and parameters: {'n_hidden': 3, 'learning_rate': 0.017061868850756497, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05033122097548013, 'dropout_rate_Layer_2': 0.27656498180445066, 'dropout_rate_Layer_3': 0.2091569915587523, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.9273022538642538e-05, 'l1_Layer_2': 0.019055890124200146, 'l1_Layer_3': 6.997419106021377e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 105, 'n_units_Layer_3': 235}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.19 | sMAPE for Validation Set is: 23.67% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.59 | sMAPE for Test Set is: 29.15% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:05:00,422]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:05:02,638]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:05:03,391]\u001b[0m Trial 1094 finished with value: 43.05969548616994 and parameters: {'n_hidden': 3, 'learning_rate': 0.002293005655942897, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22210277101666048, 'dropout_rate_Layer_2': 0.360767877734383, 'dropout_rate_Layer_3': 0.36807390861848305, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021912175016391444, 'l1_Layer_2': 1.4959314542258649e-05, 'l1_Layer_3': 0.004411398374794201, 'n_units_Layer_1': 135, 'n_units_Layer_2': 75, 'n_units_Layer_3': 245}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.06 | sMAPE for Validation Set is: 22.92% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.62 | sMAPE for Test Set is: 26.58% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:05:10,802]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:05:14,655]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:05:16,354]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:05:21,817]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:05:23,833]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:05:30,712]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:05:33,226]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:05:35,784]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:05:38,467]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:05:41,683]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:05:45,631]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:05:46,143]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:05:52,950]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:05:59,471]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:06:06,779]\u001b[0m Trial 1100 finished with value: 41.59661584954355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007469208518742045, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009942724552202685, 'dropout_rate_Layer_2': 0.1270770526886698, 'dropout_rate_Layer_3': 0.12499791186057348, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00098234896749154, 'l1_Layer_2': 4.769774888008685e-05, 'l1_Layer_3': 2.099269707364288e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 175, 'n_units_Layer_3': 90}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.60 | sMAPE for Validation Set is: 22.44% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 21.24 | sMAPE for Test Set is: 28.22% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:06:07,532]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:06:08,608]\u001b[0m Trial 1113 finished with value: 44.79386309875013 and parameters: {'n_hidden': 3, 'learning_rate': 0.009495670583020433, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05784394199208025, 'dropout_rate_Layer_2': 0.2805751975214699, 'dropout_rate_Layer_3': 0.20357192749670344, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.775472097027131e-05, 'l1_Layer_2': 0.026592187802159238, 'l1_Layer_3': 6.480798160524558e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 90, 'n_units_Layer_3': 215}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.79 | sMAPE for Validation Set is: 23.70% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 22.42 | sMAPE for Test Set is: 27.23% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:06:15,464]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:06:16,478]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:06:21,981]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:06:22,130]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:06:28,881]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:06:31,317]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:06:35,398]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:06:35,879]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:06:44,232]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:06:46,726]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:06:51,897]\u001b[0m Trial 1125 finished with value: 44.90327473304791 and parameters: {'n_hidden': 3, 'learning_rate': 0.009683154937042587, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.052576024024451766, 'dropout_rate_Layer_2': 0.31300790335511947, 'dropout_rate_Layer_3': 0.20613953145309116, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.983077827634263e-05, 'l1_Layer_2': 0.027441645893049225, 'l1_Layer_3': 5.820542224452983e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 140, 'n_units_Layer_3': 235}. Best is trial 153 with value: 40.61046692035912.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.90 | sMAPE for Validation Set is: 23.97% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.34 | sMAPE for Test Set is: 30.02% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:06:55,400]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:06:59,746]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:06:59,783]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:07:06,351]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:07:06,551]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:07:06,714]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:07:15,291]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:07:17,470]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:07:17,599]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:07:23,146]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:07:26,186]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:07:26,533]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:07:27,825]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:07:28,813]\u001b[0m Trial 1078 finished with value: 40.00264552475131 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011948831940370795, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3240129097516887, 'dropout_rate_Layer_2': 0.03386023006375243, 'dropout_rate_Layer_3': 0.2546571717672658, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.003971806593956e-05, 'l1_Layer_2': 0.004495715659346272, 'l1_Layer_3': 0.0006556345377161868, 'n_units_Layer_1': 195, 'n_units_Layer_2': 165, 'n_units_Layer_3': 170}. Best is trial 1078 with value: 40.00264552475131.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.00 | sMAPE for Validation Set is: 21.95% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 19.85 | sMAPE for Test Set is: 26.14% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:07:36,032]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:07:41,387]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:07:46,243]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:07:48,394]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:07:52,015]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:07:52,475]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:07:55,317]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:00,179]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:01,674]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:02,124]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:02,483]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:04,617]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:08,537]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:13,033]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:13,176]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:15,097]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:18,109]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:22,950]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:28,538]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:30,484]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:31,649]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:35,280]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:38,610]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:40,081]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:42,745]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:44,476]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:48,845]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:08:54,544]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:09:01,202]\u001b[0m Trial 1163 finished with value: 42.93839001815412 and parameters: {'n_hidden': 3, 'learning_rate': 0.001837950860739659, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06440363037524438, 'dropout_rate_Layer_2': 0.3740035043104423, 'dropout_rate_Layer_3': 0.35215160884779845, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009448880954116305, 'l1_Layer_2': 2.4532085794099318e-05, 'l1_Layer_3': 0.003258861992002647, 'n_units_Layer_1': 145, 'n_units_Layer_2': 65, 'n_units_Layer_3': 240}. Best is trial 1078 with value: 40.00264552475131.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.94 | sMAPE for Validation Set is: 22.79% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.38 | sMAPE for Test Set is: 26.28% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:09:04,395]\u001b[0m Trial 1168 finished with value: 43.81204516090272 and parameters: {'n_hidden': 3, 'learning_rate': 0.006238840329682996, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07390881044212366, 'dropout_rate_Layer_2': 0.2912770419852698, 'dropout_rate_Layer_3': 0.16177606643055323, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.9262980289175415e-05, 'l1_Layer_2': 0.06934003071217515, 'l1_Layer_3': 4.7324347662148e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 95, 'n_units_Layer_3': 215}. Best is trial 1078 with value: 40.00264552475131.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.81 | sMAPE for Validation Set is: 23.23% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 20.23 | sMAPE for Test Set is: 25.86% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:09:08,547]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:09:13,707]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:09:18,770]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:09:23,775]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:09:23,979]\u001b[0m Trial 1174 finished with value: 45.565629881968924 and parameters: {'n_hidden': 3, 'learning_rate': 0.007859624777179232, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07522014322703963, 'dropout_rate_Layer_2': 0.2983085796348704, 'dropout_rate_Layer_3': 0.16542308947796758, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.375110535315085e-05, 'l1_Layer_2': 0.06450912033385173, 'l1_Layer_3': 3.496402247013904e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 120, 'n_units_Layer_3': 215}. Best is trial 1078 with value: 40.00264552475131.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.57 | sMAPE for Validation Set is: 23.79% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 20.69 | sMAPE for Test Set is: 26.35% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:09:27,608]\u001b[0m Trial 1170 finished with value: 41.80584688286985 and parameters: {'n_hidden': 3, 'learning_rate': 0.001253035218511854, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26021673161588144, 'dropout_rate_Layer_2': 0.007381218552770175, 'dropout_rate_Layer_3': 0.10740707517665282, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006011214689285022, 'l1_Layer_2': 0.00024886742781642015, 'l1_Layer_3': 0.0011084925026843334, 'n_units_Layer_1': 160, 'n_units_Layer_2': 205, 'n_units_Layer_3': 215}. Best is trial 1078 with value: 40.00264552475131.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.81 | sMAPE for Validation Set is: 22.71% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.35 | sMAPE for Test Set is: 26.75% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:09:30,298]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:09:33,195]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:09:34,524]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:09:41,298]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:09:45,408]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:09:46,303]\u001b[0m Trial 1172 finished with value: 40.388259664301096 and parameters: {'n_hidden': 3, 'learning_rate': 0.000831226312496737, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.056355433436085574, 'dropout_rate_Layer_2': 0.14201728942572683, 'dropout_rate_Layer_3': 0.15361210698427355, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011970507857446775, 'l1_Layer_2': 2.004024450219702e-05, 'l1_Layer_3': 1.3988087031144378e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 185, 'n_units_Layer_3': 100}. Best is trial 1078 with value: 40.00264552475131.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.39 | sMAPE for Validation Set is: 21.89% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.70 | sMAPE for Test Set is: 25.59% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:09:52,970]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:09:53,738]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:09:54,515]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:10:03,368]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:10:09,208]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:10:13,986]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:10:21,552]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:10:26,959]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:10:29,563]\u001b[0m Trial 1190 finished with value: 45.05456219711339 and parameters: {'n_hidden': 3, 'learning_rate': 0.006212657734293769, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06594358718431179, 'dropout_rate_Layer_2': 0.2816112835876248, 'dropout_rate_Layer_3': 0.1878428890095611, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.370597579869054e-05, 'l1_Layer_2': 0.06275226527960337, 'l1_Layer_3': 2.2581743939049743e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 285, 'n_units_Layer_3': 255}. Best is trial 1078 with value: 40.00264552475131.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.05 | sMAPE for Validation Set is: 23.67% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 20.42 | sMAPE for Test Set is: 26.45% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:10:32,678]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:10:34,895]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:10:38,808]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:10:39,544]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:10:47,270]\u001b[0m Trial 1179 finished with value: 40.61083013608468 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005584564627299954, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005315106200691609, 'dropout_rate_Layer_2': 0.024484730785822584, 'dropout_rate_Layer_3': 0.13836980772341967, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000495558065249309, 'l1_Layer_2': 1.596133308750072e-05, 'l1_Layer_3': 1.0145552740933553e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 185, 'n_units_Layer_3': 90}. Best is trial 1078 with value: 40.00264552475131.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.61 | sMAPE for Validation Set is: 21.84% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.16 | sMAPE for Test Set is: 26.40% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:10:56,306]\u001b[0m Trial 1198 finished with value: 46.21258222001001 and parameters: {'n_hidden': 3, 'learning_rate': 0.010076310994617812, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11462473176829001, 'dropout_rate_Layer_2': 0.25772743149974636, 'dropout_rate_Layer_3': 0.16499369710745995, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0536014877942876e-05, 'l1_Layer_2': 0.09875039736110551, 'l1_Layer_3': 4.900904786622644e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 95, 'n_units_Layer_3': 225}. Best is trial 1078 with value: 40.00264552475131.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.21 | sMAPE for Validation Set is: 24.19% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 21.33 | sMAPE for Test Set is: 27.00% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:11:01,915]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:11:05,086]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:11:13,154]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:11:18,135]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:11:26,596]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.92 | sMAPE for Validation Set is: 23.63% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 19.99 | sMAPE for Test Set is: 25.79% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:11:29,307]\u001b[0m Trial 1202 finished with value: 44.91832283773013 and parameters: {'n_hidden': 3, 'learning_rate': 0.002778336493561553, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09973455746811694, 'dropout_rate_Layer_2': 0.27193001334543854, 'dropout_rate_Layer_3': 0.14139130725541735, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.6839281016607254e-05, 'l1_Layer_2': 0.02950514977589885, 'l1_Layer_3': 0.00011664792507332919, 'n_units_Layer_1': 155, 'n_units_Layer_2': 100, 'n_units_Layer_3': 210}. Best is trial 1078 with value: 40.00264552475131.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:11:32,923]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:11:38,333]\u001b[0m Trial 1199 finished with value: 39.99340061590214 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008181297817982111, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.059819014143816664, 'dropout_rate_Layer_2': 0.1361929348244446, 'dropout_rate_Layer_3': 0.13415683713397225, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0193528364846098e-05, 'l1_Layer_2': 2.0082070739911235e-05, 'l1_Layer_3': 2.14082968568376e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 185, 'n_units_Layer_3': 100}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 39.99 | sMAPE for Validation Set is: 21.76% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.89 | sMAPE for Test Set is: 25.02% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:11:38,754]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:11:44,703]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:11:47,857]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:11:52,570]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:11:56,946]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:12:01,465]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:12:07,693]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:12:15,150]\u001b[0m Trial 1211 finished with value: 43.39028248393557 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018722129008257615, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19831387761862346, 'dropout_rate_Layer_2': 0.35289121564970183, 'dropout_rate_Layer_3': 0.315222725472896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001393683154086578, 'l1_Layer_2': 2.9653313050934956e-05, 'l1_Layer_3': 0.0061781068493014174, 'n_units_Layer_1': 145, 'n_units_Layer_2': 75, 'n_units_Layer_3': 245}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.39 | sMAPE for Validation Set is: 22.98% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 20.77 | sMAPE for Test Set is: 27.16% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:12:17,344]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:12:20,774]\u001b[0m Trial 1200 finished with value: 40.59746365022503 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005091909558025416, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 9.459564535484188e-05, 'dropout_rate_Layer_2': 0.15528280638959485, 'dropout_rate_Layer_3': 0.1378199442327417, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004842677365426618, 'l1_Layer_2': 1.63426212722628e-05, 'l1_Layer_3': 1.227883182378144e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 185, 'n_units_Layer_3': 85}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.60 | sMAPE for Validation Set is: 22.04% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.65 | sMAPE for Test Set is: 25.65% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:12:23,586]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:12:25,378]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:12:30,094]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:12:42,259]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:12:42,629]\u001b[0m Trial 1217 finished with value: 42.294733554877375 and parameters: {'n_hidden': 3, 'learning_rate': 0.004745931708875846, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07855520758620227, 'dropout_rate_Layer_2': 0.29136421261072915, 'dropout_rate_Layer_3': 0.23235490992375835, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012103178296498603, 'l1_Layer_2': 0.03902493701802471, 'l1_Layer_3': 6.630566001990716e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 90, 'n_units_Layer_3': 235}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.29 | sMAPE for Validation Set is: 22.89% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.32 | sMAPE for Test Set is: 26.66% | rMAE for Test Set is: 0.63\n",
      "MAE for Validation Set is: 45.52 | sMAPE for Validation Set is: 23.71% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 21.36 | sMAPE for Test Set is: 26.61% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:12:47,100]\u001b[0m Trial 1222 finished with value: 45.51867785983911 and parameters: {'n_hidden': 3, 'learning_rate': 0.00497563217080528, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06021415918583743, 'dropout_rate_Layer_2': 0.2936921463884212, 'dropout_rate_Layer_3': 0.2087854776803614, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.208831430749081e-05, 'l1_Layer_2': 0.03874727447758455, 'l1_Layer_3': 6.694840050538347e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 80, 'n_units_Layer_3': 215}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:12:49,277]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:12:55,778]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:12:56,758]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:12:59,367]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:13:02,812]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:13:03,426]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:13:07,591]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:13:07,621]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:13:16,664]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:13:20,324]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:13:22,162]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:13:26,811]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:13:28,225]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:13:34,328]\u001b[0m Trial 1231 finished with value: 45.26081280225259 and parameters: {'n_hidden': 3, 'learning_rate': 0.006583656723581669, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03874839765742667, 'dropout_rate_Layer_2': 0.28364559397869976, 'dropout_rate_Layer_3': 0.22754916192336527, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.860350557848228e-05, 'l1_Layer_2': 0.07652245009588912, 'l1_Layer_3': 0.00016194561111380697, 'n_units_Layer_1': 105, 'n_units_Layer_2': 90, 'n_units_Layer_3': 240}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.26 | sMAPE for Validation Set is: 23.64% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 20.25 | sMAPE for Test Set is: 26.33% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:13:38,046]\u001b[0m Trial 1230 finished with value: 43.9169627048805 and parameters: {'n_hidden': 3, 'learning_rate': 0.004585712495011251, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.047309507077842476, 'dropout_rate_Layer_2': 0.3149182651160923, 'dropout_rate_Layer_3': 0.2298982990100618, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8368318925387108e-05, 'l1_Layer_2': 0.08766256057564561, 'l1_Layer_3': 0.00015677545478683103, 'n_units_Layer_1': 105, 'n_units_Layer_2': 90, 'n_units_Layer_3': 245}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.92 | sMAPE for Validation Set is: 23.19% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 19.95 | sMAPE for Test Set is: 25.80% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:13:38,629]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:13:40,333]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:13:45,017]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:13:49,247]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:13:49,405]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:13:51,937]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:13:58,101]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:13:58,943]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:14:02,852]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:14:05,040]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:14:06,185]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:14:13,611]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:14:13,889]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:14:20,058]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:14:25,802]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:14:28,637]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:14:30,872]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:14:35,774]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:14:36,007]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:14:37,318]\u001b[0m Trial 1242 finished with value: 42.76802694866555 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007070370296454149, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15576975007537974, 'dropout_rate_Layer_2': 0.029135693532055626, 'dropout_rate_Layer_3': 0.07295920927519113, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1705499922430292e-05, 'l1_Layer_2': 0.0037965473675211745, 'l1_Layer_3': 0.0004927911843045869, 'n_units_Layer_1': 200, 'n_units_Layer_2': 220, 'n_units_Layer_3': 145}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.77 | sMAPE for Validation Set is: 22.57% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.84 | sMAPE for Test Set is: 27.73% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:14:43,922]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:14:47,695]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:14:51,492]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:14:51,546]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:14:51,999]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:14:52,643]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:02,323]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:04,932]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:05,328]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:07,304]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:08,467]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:14,569]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:19,500]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:24,590]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:29,088]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:29,629]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:30,241]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:30,580]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:40,632]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:43,320]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:45,852]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:46,603]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:48,305]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:48,772]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:15:52,431]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:16:00,215]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:16:01,729]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:16:04,352]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:16:09,176]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:16:12,476]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:16:13,896]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:16:17,405]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:16:23,688]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:16:29,369]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:16:34,207]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:16:39,206]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:16:41,849]\u001b[0m Trial 1285 finished with value: 42.47767817134075 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015855810274967308, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03936904110596956, 'dropout_rate_Layer_2': 0.23275491111803112, 'dropout_rate_Layer_3': 0.3489848305569771, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016965112594904538, 'l1_Layer_2': 3.1715377610338225e-05, 'l1_Layer_3': 0.008997700277982006, 'n_units_Layer_1': 155, 'n_units_Layer_2': 75, 'n_units_Layer_3': 235}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.48 | sMAPE for Validation Set is: 22.57% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.17 | sMAPE for Test Set is: 26.05% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:16:42,799]\u001b[0m Trial 1292 finished with value: 43.30636993075216 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034609796429265847, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0231993150868315, 'dropout_rate_Layer_2': 0.31556478458177645, 'dropout_rate_Layer_3': 0.25286557042613167, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.244722320049424e-05, 'l1_Layer_2': 0.018218812795003682, 'l1_Layer_3': 9.571321478785516e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 105, 'n_units_Layer_3': 250}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.31 | sMAPE for Validation Set is: 23.06% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 20.09 | sMAPE for Test Set is: 25.98% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:16:45,651]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:16:48,841]\u001b[0m Trial 1286 finished with value: 45.42704235330467 and parameters: {'n_hidden': 3, 'learning_rate': 0.001263381279935539, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3030160386200456, 'dropout_rate_Layer_2': 0.013784393524033392, 'dropout_rate_Layer_3': 0.2423459522472064, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023785212070395653, 'l1_Layer_2': 0.0013568600657926008, 'l1_Layer_3': 0.0010799298380487568, 'n_units_Layer_1': 155, 'n_units_Layer_2': 225, 'n_units_Layer_3': 200}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.43 | sMAPE for Validation Set is: 23.91% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.68 | sMAPE for Test Set is: 30.73% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:16:54,789]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:16:55,050]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:17:03,374]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:17:10,038]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:17:14,443]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:17:18,181]\u001b[0m Trial 1298 finished with value: 42.827285367319256 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021411802227047456, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023970224581439444, 'dropout_rate_Layer_2': 0.23601073807805723, 'dropout_rate_Layer_3': 0.34751540791334207, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017272363323554616, 'l1_Layer_2': 4.769735421111613e-05, 'l1_Layer_3': 0.006748431062640979, 'n_units_Layer_1': 145, 'n_units_Layer_2': 70, 'n_units_Layer_3': 230}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.83 | sMAPE for Validation Set is: 22.81% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.04 | sMAPE for Test Set is: 26.02% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:17:22,415]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:17:30,304]\u001b[0m Trial 1297 finished with value: 44.58981036767947 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015210092896921002, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2823005615980774, 'dropout_rate_Layer_2': 0.019605534746770372, 'dropout_rate_Layer_3': 0.11303325636836943, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004064869433419719, 'l1_Layer_2': 0.0014520614746217006, 'l1_Layer_3': 6.0818365476615415e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 280, 'n_units_Layer_3': 140}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.59 | sMAPE for Validation Set is: 23.28% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 21.64 | sMAPE for Test Set is: 29.10% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:17:42,841]\u001b[0m Trial 1305 finished with value: 42.362069788742765 and parameters: {'n_hidden': 3, 'learning_rate': 0.001559426344205597, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3325877310524934, 'dropout_rate_Layer_2': 0.2369152493914136, 'dropout_rate_Layer_3': 0.34881681719677204, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016535965796210259, 'l1_Layer_2': 5.0646407372783926e-05, 'l1_Layer_3': 0.0021837001944220156, 'n_units_Layer_1': 170, 'n_units_Layer_2': 70, 'n_units_Layer_3': 230}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.36 | sMAPE for Validation Set is: 22.61% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.01 | sMAPE for Test Set is: 26.16% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:17:43,488]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:17:49,501]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:17:50,294]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:18:00,931]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:18:01,619]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:18:07,382]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:18:12,383]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:18:12,599]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:18:13,432]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:18:22,809]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:18:25,798]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:18:28,168]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:18:32,872]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:18:34,624]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:18:39,699]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:18:42,818]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:18:45,214]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:18:48,487]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:19:27,928]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.00 | sMAPE for Validation Set is: 22.89% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.58 | sMAPE for Test Set is: 26.58% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:19:31,564]\u001b[0m Trial 1327 finished with value: 42.99755663017542 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011995341149618906, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026238950676037084, 'dropout_rate_Layer_2': 0.2260184316392531, 'dropout_rate_Layer_3': 0.38394384677673854, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017877510520956203, 'l1_Layer_2': 7.424509227768891e-05, 'l1_Layer_3': 0.008446893513277829, 'n_units_Layer_1': 160, 'n_units_Layer_2': 65, 'n_units_Layer_3': 230}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:19:35,955]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:19:38,668]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:19:44,119]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:19:49,352]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:19:52,514]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:19:54,856]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:19:58,772]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:20:01,578]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:20:04,132]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:20:07,808]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:20:08,379]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:20:08,624]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:20:19,063]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:20:24,414]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:20:31,512]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:20:35,825]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:20:38,861]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.30 | sMAPE for Validation Set is: 23.84% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 21.98 | sMAPE for Test Set is: 28.37% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:20:41,499]\u001b[0m Trial 1341 finished with value: 45.30023982344614 and parameters: {'n_hidden': 3, 'learning_rate': 0.004253204943755063, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022369707127528976, 'dropout_rate_Layer_2': 0.3174041152825238, 'dropout_rate_Layer_3': 0.2551112083260606, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9504905513920165e-05, 'l1_Layer_2': 0.06245799693471749, 'l1_Layer_3': 4.690325484576253e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 115, 'n_units_Layer_3': 250}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:20:45,253]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:20:48,196]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:20:52,748]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:20:55,545]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:20:56,052]\u001b[0m Trial 1338 finished with value: 42.13204441107907 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008928410769943692, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27123815129811263, 'dropout_rate_Layer_2': 0.013509117502226789, 'dropout_rate_Layer_3': 0.14605988849842771, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00045237229113275607, 'l1_Layer_2': 0.0006564925312875684, 'l1_Layer_3': 0.00045974127577791895, 'n_units_Layer_1': 165, 'n_units_Layer_2': 230, 'n_units_Layer_3': 200}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.13 | sMAPE for Validation Set is: 22.37% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.79 | sMAPE for Test Set is: 27.84% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:21:02,202]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:21:07,771]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:21:07,878]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:21:12,400]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:21:15,618]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:21:18,287]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:21:23,034]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:21:29,550]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:21:33,990]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:21:40,255]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:21:42,727]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:21:57,129]\u001b[0m Trial 1347 finished with value: 41.08759271164624 and parameters: {'n_hidden': 3, 'learning_rate': 0.001020493530039798, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23981170587826175, 'dropout_rate_Layer_2': 0.029419404695651814, 'dropout_rate_Layer_3': 0.09168048517023844, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3804518348387002e-05, 'l1_Layer_2': 0.00022405020225399873, 'l1_Layer_3': 0.0009645164042464335, 'n_units_Layer_1': 180, 'n_units_Layer_2': 235, 'n_units_Layer_3': 285}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.09 | sMAPE for Validation Set is: 22.55% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 20.47 | sMAPE for Test Set is: 27.51% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:22:01,494]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:22:06,690]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:22:06,866]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:22:14,922]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:22:15,079]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:22:22,162]\u001b[0m Trial 1359 finished with value: 41.56762103352717 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007612946927504857, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005131778391421163, 'dropout_rate_Layer_2': 0.15374074454030065, 'dropout_rate_Layer_3': 0.1480783480055621, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015009458439582644, 'l1_Layer_2': 2.008718804342685e-05, 'l1_Layer_3': 2.0272639405038636e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 170, 'n_units_Layer_3': 105}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.57 | sMAPE for Validation Set is: 22.38% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 21.41 | sMAPE for Test Set is: 28.31% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:22:26,610]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:22:28,329]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:22:32,440]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:22:38,148]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:22:42,565]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:22:47,539]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:22:59,692]\u001b[0m Trial 1362 finished with value: 40.652065093612755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007333684204463043, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3142252553471615, 'dropout_rate_Layer_2': 0.021490065863303598, 'dropout_rate_Layer_3': 0.12890635123977462, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006382464679028748, 'l1_Layer_2': 0.0006506381773816344, 'l1_Layer_3': 0.00028296627383938997, 'n_units_Layer_1': 160, 'n_units_Layer_2': 225, 'n_units_Layer_3': 195}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.65 | sMAPE for Validation Set is: 22.25% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 20.14 | sMAPE for Test Set is: 26.92% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:23:09,069]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:23:18,587]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:23:19,153]\u001b[0m Trial 1371 finished with value: 40.6454909301914 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009417325655407003, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00034159756933046376, 'dropout_rate_Layer_2': 0.16779895534449946, 'dropout_rate_Layer_3': 0.13252256041652657, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019919322603942735, 'l1_Layer_2': 1.6107758218020873e-05, 'l1_Layer_3': 2.3439249089757518e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 165, 'n_units_Layer_3': 85}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.65 | sMAPE for Validation Set is: 22.09% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 18.70 | sMAPE for Test Set is: 24.88% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:23:24,942]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:23:28,642]\u001b[0m Trial 1372 finished with value: 40.49784514262911 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012098713726139427, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2367978248206418, 'dropout_rate_Layer_2': 0.04813202050839359, 'dropout_rate_Layer_3': 0.17151868214933322, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1649912256156862e-05, 'l1_Layer_2': 0.00023191502901579253, 'l1_Layer_3': 0.0005478608313188748, 'n_units_Layer_1': 180, 'n_units_Layer_2': 240, 'n_units_Layer_3': 285}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.50 | sMAPE for Validation Set is: 22.01% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 20.22 | sMAPE for Test Set is: 26.51% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:23:33,458]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:23:40,878]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:23:41,069]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:23:46,328]\u001b[0m Trial 1381 finished with value: 43.91089193241556 and parameters: {'n_hidden': 3, 'learning_rate': 0.005456378309318147, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022308638331294574, 'dropout_rate_Layer_2': 0.3041749339347264, 'dropout_rate_Layer_3': 0.15808487589406514, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.988689700385154e-05, 'l1_Layer_2': 0.01791282094615344, 'l1_Layer_3': 3.0307367412579984e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 100, 'n_units_Layer_3': 125}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.91 | sMAPE for Validation Set is: 23.24% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 20.31 | sMAPE for Test Set is: 26.00% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:23:49,149]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:23:49,561]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:23:53,542]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:24:15,590]\u001b[0m Trial 1376 finished with value: 40.07048702405596 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009159911639934565, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2175204915073125, 'dropout_rate_Layer_2': 0.03663013536551401, 'dropout_rate_Layer_3': 0.12558542839793463, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.539263706499717e-05, 'l1_Layer_2': 0.0003219258145975696, 'l1_Layer_3': 0.000667863192129705, 'n_units_Layer_1': 180, 'n_units_Layer_2': 230, 'n_units_Layer_3': 280}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.07 | sMAPE for Validation Set is: 21.86% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 20.81 | sMAPE for Test Set is: 27.27% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:24:19,772]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:24:39,299]\u001b[0m Trial 1387 finished with value: 40.042657128843565 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012421052159310162, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2173289200081271, 'dropout_rate_Layer_2': 0.05027149294081447, 'dropout_rate_Layer_3': 0.15819066815203442, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2705943522586497e-05, 'l1_Layer_2': 0.00019919941895433905, 'l1_Layer_3': 0.0002728342451749331, 'n_units_Layer_1': 160, 'n_units_Layer_2': 245, 'n_units_Layer_3': 285}. Best is trial 1199 with value: 39.99340061590214.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.04 | sMAPE for Validation Set is: 22.00% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.79 | sMAPE for Test Set is: 26.52% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:24:45,536]\u001b[0m Trial 1388 finished with value: 39.60633079123452 and parameters: {'n_hidden': 3, 'learning_rate': 0.001225319742685445, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24024764762875073, 'dropout_rate_Layer_2': 0.05699888324826005, 'dropout_rate_Layer_3': 0.15139415819557692, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1333747552877415e-05, 'l1_Layer_2': 0.00017488397737224168, 'l1_Layer_3': 0.0004030153409682037, 'n_units_Layer_1': 160, 'n_units_Layer_2': 250, 'n_units_Layer_3': 295}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 39.61 | sMAPE for Validation Set is: 21.65% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 20.18 | sMAPE for Test Set is: 26.08% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:24:49,270]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:24:54,532]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:25:13,932]\u001b[0m Trial 1391 finished with value: 39.81074477692111 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013364282758315895, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23443391945758724, 'dropout_rate_Layer_2': 0.04827448132667827, 'dropout_rate_Layer_3': 0.1383935696318274, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.61324860942714e-05, 'l1_Layer_2': 0.00022493564493217375, 'l1_Layer_3': 0.00031014430711461265, 'n_units_Layer_1': 155, 'n_units_Layer_2': 250, 'n_units_Layer_3': 285}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 39.81 | sMAPE for Validation Set is: 21.87% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 19.96 | sMAPE for Test Set is: 26.17% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:25:18,471]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:25:26,292]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:25:31,190]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:25:34,742]\u001b[0m Trial 1394 finished with value: 42.427070484429976 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034391798788624907, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03185492590850569, 'dropout_rate_Layer_2': 0.30301288663437403, 'dropout_rate_Layer_3': 0.1560076614394021, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.851297330406406e-05, 'l1_Layer_2': 0.04101572223338366, 'l1_Layer_3': 3.1938999092549175e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 110, 'n_units_Layer_3': 115}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.43 | sMAPE for Validation Set is: 23.07% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.51 | sMAPE for Test Set is: 27.74% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:25:36,741]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:25:42,150]\u001b[0m Trial 1393 finished with value: 40.459277260370094 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013136581246988785, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21079512454226562, 'dropout_rate_Layer_2': 0.06391042475968667, 'dropout_rate_Layer_3': 0.16378380064811135, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2421020103432103e-05, 'l1_Layer_2': 0.00014987840937932367, 'l1_Layer_3': 0.0002775765390479032, 'n_units_Layer_1': 100, 'n_units_Layer_2': 250, 'n_units_Layer_3': 285}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.46 | sMAPE for Validation Set is: 21.92% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 20.53 | sMAPE for Test Set is: 26.68% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:25:56,478]\u001b[0m Trial 1400 finished with value: 43.29000250824337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010061065707579384, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004945845691786389, 'dropout_rate_Layer_2': 0.2121304626755481, 'dropout_rate_Layer_3': 0.3306594438785003, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015957707528721483, 'l1_Layer_2': 7.760106411097821e-05, 'l1_Layer_3': 0.0036938781856754805, 'n_units_Layer_1': 165, 'n_units_Layer_2': 90, 'n_units_Layer_3': 215}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.29 | sMAPE for Validation Set is: 22.86% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 20.79 | sMAPE for Test Set is: 26.44% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:26:02,036]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:26:10,104]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:26:11,214]\u001b[0m Trial 1395 finished with value: 40.216092945567055 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012925666008409547, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21732685877585614, 'dropout_rate_Layer_2': 0.06496418965321771, 'dropout_rate_Layer_3': 0.1476486877597724, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1344277904400632e-05, 'l1_Layer_2': 0.00018280698388535002, 'l1_Layer_3': 0.00025000186615007795, 'n_units_Layer_1': 180, 'n_units_Layer_2': 255, 'n_units_Layer_3': 285}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.22 | sMAPE for Validation Set is: 22.04% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 21.45 | sMAPE for Test Set is: 27.02% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:26:20,701]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:26:26,540]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:26:29,253]\u001b[0m Trial 1402 finished with value: 40.33683155625891 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013196899064405899, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21102668454586102, 'dropout_rate_Layer_2': 0.07208164849473153, 'dropout_rate_Layer_3': 0.15985450725706535, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3642053885687945e-05, 'l1_Layer_2': 0.00014647157840098028, 'l1_Layer_3': 0.00023032356050126866, 'n_units_Layer_1': 165, 'n_units_Layer_2': 260, 'n_units_Layer_3': 285}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.34 | sMAPE for Validation Set is: 21.98% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 20.64 | sMAPE for Test Set is: 26.83% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:26:33,011]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:26:34,092]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:26:39,722]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:26:42,525]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:26:45,861]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:26:47,943]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:27:09,776]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:27:17,464]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:27:21,616]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:27:25,947]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:27:31,371]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:27:34,026]\u001b[0m Trial 1409 finished with value: 40.54275574684142 and parameters: {'n_hidden': 3, 'learning_rate': 0.000891167931476401, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0327663725559183, 'dropout_rate_Layer_2': 0.15288317525704054, 'dropout_rate_Layer_3': 0.145652707967131, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012354131981322626, 'l1_Layer_2': 3.601128823987043e-05, 'l1_Layer_3': 1.528158157869832e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 175, 'n_units_Layer_3': 95}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.54 | sMAPE for Validation Set is: 22.03% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.10 | sMAPE for Test Set is: 25.59% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:27:37,531]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:27:40,350]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:27:42,037]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:27:46,639]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:27:48,767]\u001b[0m Trial 1415 finished with value: 42.174496199106535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006066651309109189, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006506621784410156, 'dropout_rate_Layer_2': 0.12641342084652543, 'dropout_rate_Layer_3': 0.13388976145396345, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8746564429851272e-05, 'l1_Layer_2': 3.06998332537244e-05, 'l1_Layer_3': 1.9159918762640434e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 195, 'n_units_Layer_3': 85}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.17 | sMAPE for Validation Set is: 22.81% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 21.61 | sMAPE for Test Set is: 29.52% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:27:55,379]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:27:59,868]\u001b[0m Trial 1410 finished with value: 40.36776164031006 and parameters: {'n_hidden': 3, 'learning_rate': 0.00087562235688481, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02830761451605239, 'dropout_rate_Layer_2': 0.2267338199307834, 'dropout_rate_Layer_3': 0.14540484147153823, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001509254091871657, 'l1_Layer_2': 3.664331000401039e-05, 'l1_Layer_3': 1.6152199005619266e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 195, 'n_units_Layer_3': 95}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.37 | sMAPE for Validation Set is: 21.95% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.01 | sMAPE for Test Set is: 25.21% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:28:00,710]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:28:05,428]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:28:06,618]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:28:10,769]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:28:11,954]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:28:18,705]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:28:19,798]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:28:27,254]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:28:29,914]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:28:32,401]\u001b[0m Trial 1426 finished with value: 42.65471320627787 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029151321958808705, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04450665362400036, 'dropout_rate_Layer_2': 0.31028423387133686, 'dropout_rate_Layer_3': 0.18994366832748533, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.005476974223576e-05, 'l1_Layer_2': 0.0425946299391413, 'l1_Layer_3': 3.0848525186644424e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 135, 'n_units_Layer_3': 285}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.65 | sMAPE for Validation Set is: 22.95% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.14 | sMAPE for Test Set is: 26.43% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:28:36,906]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:28:37,038]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 39.80 | sMAPE for Validation Set is: 21.80% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 19.77 | sMAPE for Test Set is: 25.98% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:28:39,952]\u001b[0m Trial 1424 finished with value: 39.798587880933745 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013397152294826649, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2130135571832955, 'dropout_rate_Layer_2': 0.053068076246582954, 'dropout_rate_Layer_3': 0.15321920847944379, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.743436783079906e-05, 'l1_Layer_2': 0.00019446266604958287, 'l1_Layer_3': 0.00028901621622096687, 'n_units_Layer_1': 110, 'n_units_Layer_2': 255, 'n_units_Layer_3': 290}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:28:44,774]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:28:44,893]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:28:58,511]\u001b[0m Trial 1437 finished with value: 42.657334000642514 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012265048023493697, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04200654309612309, 'dropout_rate_Layer_2': 0.19897021129364995, 'dropout_rate_Layer_3': 0.36855683003119155, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00134917757098314, 'l1_Layer_2': 2.3834723327657013e-05, 'l1_Layer_3': 0.0027286117427733174, 'n_units_Layer_1': 155, 'n_units_Layer_2': 75, 'n_units_Layer_3': 230}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.66 | sMAPE for Validation Set is: 22.76% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.43 | sMAPE for Test Set is: 26.45% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:29:00,055]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:29:23,512]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:29:28,598]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:29:36,476]\u001b[0m Trial 1443 finished with value: 41.45588512144164 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006198571890673649, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.043176653922596446, 'dropout_rate_Layer_2': 0.16350768144263567, 'dropout_rate_Layer_3': 0.16486374026801975, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001068809692483539, 'l1_Layer_2': 1.9116748778212836e-05, 'l1_Layer_3': 1.6445593921416726e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 190, 'n_units_Layer_3': 85}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.46 | sMAPE for Validation Set is: 22.40% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 19.60 | sMAPE for Test Set is: 25.80% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:29:39,869]\u001b[0m Trial 1442 finished with value: 41.11683662692317 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006244820220104988, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.048282829179271236, 'dropout_rate_Layer_2': 0.16089352573983243, 'dropout_rate_Layer_3': 0.16415375859681303, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001038476526400813, 'l1_Layer_2': 0.0005012623476789741, 'l1_Layer_3': 2.124267334488493e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 190, 'n_units_Layer_3': 85}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.12 | sMAPE for Validation Set is: 22.50% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 19.48 | sMAPE for Test Set is: 26.36% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:29:42,641]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:29:48,903]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:29:51,568]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:29:54,785]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:29:57,290]\u001b[0m Trial 1444 finished with value: 40.56342277724871 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014404446633739536, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2127336770163143, 'dropout_rate_Layer_2': 0.06190576261804229, 'dropout_rate_Layer_3': 0.1542538035930161, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1947587881262007e-05, 'l1_Layer_2': 0.00023368228988993202, 'l1_Layer_3': 0.00017953567449695504, 'n_units_Layer_1': 115, 'n_units_Layer_2': 265, 'n_units_Layer_3': 285}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.56 | sMAPE for Validation Set is: 22.13% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 20.86 | sMAPE for Test Set is: 26.69% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:30:00,528]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:30:02,171]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:30:07,422]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:30:07,573]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:30:15,886]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:30:20,177]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:30:26,183]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:30:31,820]\u001b[0m Trial 1452 finished with value: 42.128332027043704 and parameters: {'n_hidden': 3, 'learning_rate': 0.001192807419778727, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03909827951774281, 'dropout_rate_Layer_2': 0.20225472629621008, 'dropout_rate_Layer_3': 0.36920497969140115, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016770797012015995, 'l1_Layer_2': 2.444107473798348e-05, 'l1_Layer_3': 0.0044917830919667424, 'n_units_Layer_1': 155, 'n_units_Layer_2': 85, 'n_units_Layer_3': 205}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.13 | sMAPE for Validation Set is: 22.50% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.38 | sMAPE for Test Set is: 26.05% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:30:34,585]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:30:38,114]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:30:41,525]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:30:44,853]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:30:54,736]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:30:59,183]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:31:01,051]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:31:05,611]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:31:07,326]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:31:07,957]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:31:11,525]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:31:17,119]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:31:18,573]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:31:20,503]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:31:22,028]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:31:26,351]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:31:28,798]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:31:29,276]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:31:43,663]\u001b[0m Trial 1471 finished with value: 42.84666095011283 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031728928401542804, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00045842041665514546, 'dropout_rate_Layer_2': 0.3383670205025485, 'dropout_rate_Layer_3': 0.26537512149117654, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.584025988205344e-05, 'l1_Layer_2': 0.0413176602075297, 'l1_Layer_3': 1.861123947385563e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 130, 'n_units_Layer_3': 285}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.85 | sMAPE for Validation Set is: 23.11% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.21 | sMAPE for Test Set is: 26.87% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:31:51,669]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:31:59,369]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:32:03,263]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:32:08,818]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:32:12,078]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:32:15,542]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:32:16,391]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:32:23,157]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:32:28,713]\u001b[0m Trial 1478 finished with value: 41.18881769339992 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007299738738201649, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007379523925430661, 'dropout_rate_Layer_2': 0.1536718035236694, 'dropout_rate_Layer_3': 0.13747815779365122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001461197187121867, 'l1_Layer_2': 2.3712916748945632e-05, 'l1_Layer_3': 2.1553503759214853e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 195, 'n_units_Layer_3': 90}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.19 | sMAPE for Validation Set is: 22.33% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 19.43 | sMAPE for Test Set is: 26.29% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:32:34,562]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:32:36,986]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:32:40,509]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:32:42,463]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:32:42,855]\u001b[0m Trial 1487 finished with value: 44.35528889785709 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033160890628778777, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023327728440476442, 'dropout_rate_Layer_2': 0.37650147341349094, 'dropout_rate_Layer_3': 0.23905051842215463, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.981036102782871e-05, 'l1_Layer_2': 0.030958949129225335, 'l1_Layer_3': 1.068009672294032e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 135, 'n_units_Layer_3': 290}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.36 | sMAPE for Validation Set is: 23.32% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 20.01 | sMAPE for Test Set is: 25.87% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:32:47,550]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:32:52,187]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:32:54,900]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:32:58,976]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:33:04,080]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:33:12,955]\u001b[0m Trial 1489 finished with value: 42.19339344663104 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013765956835597342, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03611950002419565, 'dropout_rate_Layer_2': 0.24437784078123365, 'dropout_rate_Layer_3': 0.3563435747121533, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013002321003581566, 'l1_Layer_2': 3.208149984548012e-05, 'l1_Layer_3': 0.004742062237131444, 'n_units_Layer_1': 140, 'n_units_Layer_2': 65, 'n_units_Layer_3': 185}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.19 | sMAPE for Validation Set is: 22.46% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.01 | sMAPE for Test Set is: 25.73% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-04 11:33:14,136]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-04 11:33:21,974]\u001b[0m Trial 1496 finished with value: 43.28071818799057 and parameters: {'n_hidden': 3, 'learning_rate': 0.001969963574077634, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009852476043863466, 'dropout_rate_Layer_2': 0.3744016905195513, 'dropout_rate_Layer_3': 0.24429654735967146, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.550021904153727e-05, 'l1_Layer_2': 0.08404489393479606, 'l1_Layer_3': 1.1078238790515755e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 135, 'n_units_Layer_3': 285}. Best is trial 1388 with value: 39.60633079123452.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.28 | sMAPE for Validation Set is: 23.11% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 19.95 | sMAPE for Test Set is: 26.23% | rMAE for Test Set is: 0.62\n",
      "for 2023-01-01, MAE is:29.92 & sMAPE is:133.30% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :29.92 & 133.30% & 0.29\n",
      "for 2023-01-02, MAE is:85.85 & sMAPE is:93.65% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :57.89 & 113.47% & 0.95\n",
      "for 2023-01-03, MAE is:14.24 & sMAPE is:10.57% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :43.34 & 79.17% & 0.75\n",
      "for 2023-01-04, MAE is:26.35 & sMAPE is:39.21% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :39.09 & 69.18% & 0.79\n",
      "for 2023-01-05, MAE is:54.82 & sMAPE is:70.29% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :42.24 & 69.40% & 0.84\n",
      "for 2023-01-06, MAE is:15.74 & sMAPE is:12.23% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :37.82 & 59.88% & 0.72\n",
      "for 2023-01-07, MAE is:21.78 & sMAPE is:23.53% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :35.53 & 54.68% & 0.67\n",
      "for 2023-01-08, MAE is:34.49 & sMAPE is:73.09% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :35.40 & 56.98% & 0.67\n",
      "for 2023-01-09, MAE is:46.82 & sMAPE is:40.74% & rMAE is:4.81 ||| daily mean of MAE & sMAPE & rMAE till now are :36.67 & 55.18% & 1.13\n",
      "for 2023-01-10, MAE is:22.49 & sMAPE is:17.94% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :35.25 & 51.46% & 1.11\n",
      "for 2023-01-11, MAE is:28.96 & sMAPE is:57.87% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :34.68 & 52.04% & 1.18\n",
      "for 2023-01-12, MAE is:27.37 & sMAPE is:50.89% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :34.07 & 51.94% & 1.14\n",
      "for 2023-01-13, MAE is:28.20 & sMAPE is:48.27% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :33.62 & 51.66% & 1.10\n",
      "for 2023-01-14, MAE is:18.75 & sMAPE is:21.27% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :32.56 & 49.49% & 1.07\n",
      "for 2023-01-15, MAE is:54.48 & sMAPE is:81.95% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :34.02 & 51.65% & 1.11\n",
      "for 2023-01-16, MAE is:25.44 & sMAPE is:22.01% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :33.48 & 49.80% & 1.16\n",
      "for 2023-01-17, MAE is:24.83 & sMAPE is:18.50% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :32.97 & 47.96% & 1.16\n",
      "for 2023-01-18, MAE is:21.43 & sMAPE is:16.47% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :32.33 & 46.21% & 1.12\n",
      "for 2023-01-19, MAE is:27.70 & sMAPE is:20.14% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :32.09 & 44.84% & 1.09\n",
      "for 2023-01-20, MAE is:42.43 & sMAPE is:27.05% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :32.60 & 43.95% & 1.05\n",
      "for 2023-01-21, MAE is:18.70 & sMAPE is:13.79% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :31.94 & 42.51% & 1.02\n",
      "for 2023-01-22, MAE is:35.35 & sMAPE is:26.69% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :32.10 & 41.79% & 0.99\n",
      "for 2023-01-23, MAE is:55.56 & sMAPE is:30.43% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :33.12 & 41.30% & 0.99\n",
      "for 2023-01-24, MAE is:22.30 & sMAPE is:11.42% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :32.67 & 40.05% & 0.96\n",
      "for 2023-01-25, MAE is:23.90 & sMAPE is:13.67% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :32.32 & 39.00% & 0.94\n",
      "for 2023-01-26, MAE is:26.01 & sMAPE is:16.45% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :32.07 & 38.13% & 0.95\n",
      "for 2023-01-27, MAE is:29.64 & sMAPE is:19.14% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :31.98 & 37.43% & 0.98\n",
      "for 2023-01-28, MAE is:10.84 & sMAPE is:7.59% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :31.23 & 36.36% & 0.98\n",
      "for 2023-01-29, MAE is:20.38 & sMAPE is:15.60% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :30.85 & 35.65% & 0.97\n",
      "for 2023-01-30, MAE is:40.95 & sMAPE is:53.32% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :31.19 & 36.24% & 0.96\n",
      "for 2023-01-31, MAE is:17.61 & sMAPE is:13.01% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :30.75 & 35.49% & 0.93\n",
      "for 2023-02-01, MAE is:20.38 & sMAPE is:17.80% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :30.43 & 34.93% & 0.91\n",
      "for 2023-02-02, MAE is:34.67 & sMAPE is:26.31% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :30.56 & 34.67% & 0.92\n",
      "for 2023-02-03, MAE is:18.37 & sMAPE is:12.97% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :30.20 & 34.03% & 0.91\n",
      "for 2023-02-04, MAE is:20.47 & sMAPE is:14.68% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :29.92 & 33.48% & 0.93\n",
      "for 2023-02-05, MAE is:15.34 & sMAPE is:11.88% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :29.52 & 32.88% & 0.92\n",
      "for 2023-02-06, MAE is:16.89 & sMAPE is:10.57% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :29.17 & 32.28% & 0.91\n",
      "for 2023-02-07, MAE is:23.04 & sMAPE is:13.55% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :29.01 & 31.79% & 0.90\n",
      "for 2023-02-08, MAE is:25.93 & sMAPE is:16.91% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :28.93 & 31.40% & 0.89\n",
      "for 2023-02-09, MAE is:21.45 & sMAPE is:13.99% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :28.75 & 30.97% & 0.89\n",
      "for 2023-02-10, MAE is:22.69 & sMAPE is:17.00% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :28.60 & 30.63% & 0.89\n",
      "for 2023-02-11, MAE is:34.15 & sMAPE is:28.14% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :28.73 & 30.57% & 0.92\n",
      "for 2023-02-12, MAE is:19.99 & sMAPE is:15.48% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :28.53 & 30.22% & 0.92\n",
      "for 2023-02-13, MAE is:22.54 & sMAPE is:14.81% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :28.39 & 29.87% & 0.95\n",
      "for 2023-02-14, MAE is:16.86 & sMAPE is:11.00% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :28.14 & 29.45% & 0.95\n",
      "for 2023-02-15, MAE is:20.89 & sMAPE is:14.38% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :27.98 & 29.12% & 0.95\n",
      "for 2023-02-16, MAE is:16.75 & sMAPE is:13.10% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :27.74 & 28.78% & 0.95\n",
      "for 2023-02-17, MAE is:20.90 & sMAPE is:18.01% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :27.60 & 28.56% & 0.95\n",
      "for 2023-02-18, MAE is:13.17 & sMAPE is:13.68% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :27.30 & 28.25% & 0.93\n",
      "for 2023-02-19, MAE is:23.68 & sMAPE is:22.40% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :27.23 & 28.13% & 0.93\n",
      "for 2023-02-20, MAE is:28.16 & sMAPE is:31.33% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :27.25 & 28.20% & 0.92\n",
      "for 2023-02-21, MAE is:22.54 & sMAPE is:17.59% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :27.16 & 27.99% & 0.93\n",
      "for 2023-02-22, MAE is:17.71 & sMAPE is:12.81% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :26.98 & 27.71% & 0.94\n",
      "for 2023-02-23, MAE is:15.86 & sMAPE is:11.60% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :26.77 & 27.41% & 0.94\n",
      "for 2023-02-24, MAE is:14.37 & sMAPE is:11.22% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :26.55 & 27.11% & 0.93\n",
      "for 2023-02-25, MAE is:25.18 & sMAPE is:25.22% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :26.52 & 27.08% & 0.93\n",
      "for 2023-02-26, MAE is:14.29 & sMAPE is:13.71% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :26.31 & 26.85% & 0.93\n",
      "for 2023-02-27, MAE is:23.82 & sMAPE is:17.41% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :26.27 & 26.68% & 0.93\n",
      "for 2023-02-28, MAE is:15.93 & sMAPE is:10.87% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :26.09 & 26.42% & 0.93\n",
      "for 2023-03-01, MAE is:16.85 & sMAPE is:11.98% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :25.94 & 26.17% & 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-03-02, MAE is:18.06 & sMAPE is:13.36% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :25.81 & 25.96% & 0.94\n",
      "for 2023-03-03, MAE is:22.68 & sMAPE is:17.40% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :25.76 & 25.83% & 0.95\n",
      "for 2023-03-04, MAE is:16.99 & sMAPE is:15.37% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :25.62 & 25.66% & 0.94\n",
      "for 2023-03-05, MAE is:16.16 & sMAPE is:14.08% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :25.47 & 25.48% & 0.95\n",
      "for 2023-03-06, MAE is:24.85 & sMAPE is:17.97% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :25.46 & 25.36% & 0.95\n",
      "for 2023-03-07, MAE is:9.23 & sMAPE is:7.21% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :25.22 & 25.09% & 0.94\n",
      "for 2023-03-08, MAE is:26.85 & sMAPE is:21.41% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :25.24 & 25.03% & 0.95\n",
      "for 2023-03-09, MAE is:9.66 & sMAPE is:7.64% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :25.01 & 24.78% & 0.95\n",
      "for 2023-03-10, MAE is:17.17 & sMAPE is:15.71% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :24.90 & 24.65% & 0.95\n",
      "for 2023-03-11, MAE is:24.21 & sMAPE is:23.40% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :24.89 & 24.63% & 0.95\n",
      "for 2023-03-12, MAE is:10.15 & sMAPE is:10.24% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :24.68 & 24.43% & 0.94\n",
      "for 2023-03-13, MAE is:48.26 & sMAPE is:93.33% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :25.01 & 25.38% & 0.93\n",
      "for 2023-03-14, MAE is:49.03 & sMAPE is:82.53% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :25.34 & 26.17% & 0.93\n",
      "for 2023-03-15, MAE is:30.29 & sMAPE is:24.63% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :25.40 & 26.15% & 0.94\n",
      "for 2023-03-16, MAE is:19.70 & sMAPE is:17.29% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :25.33 & 26.03% & 0.94\n",
      "for 2023-03-17, MAE is:23.04 & sMAPE is:22.19% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :25.30 & 25.98% & 0.94\n",
      "for 2023-03-18, MAE is:18.80 & sMAPE is:18.83% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :25.21 & 25.88% & 0.95\n",
      "for 2023-03-19, MAE is:12.44 & sMAPE is:11.57% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :25.05 & 25.70% & 0.94\n",
      "for 2023-03-20, MAE is:23.31 & sMAPE is:20.58% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :25.03 & 25.64% & 0.94\n",
      "for 2023-03-21, MAE is:16.19 & sMAPE is:13.52% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :24.92 & 25.48% & 0.93\n",
      "for 2023-03-22, MAE is:10.87 & sMAPE is:11.69% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :24.74 & 25.31% & 0.92\n",
      "for 2023-03-23, MAE is:19.94 & sMAPE is:27.79% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :24.68 & 25.34% & 0.91\n",
      "for 2023-03-24, MAE is:41.55 & sMAPE is:77.18% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :24.89 & 25.97% & 0.91\n",
      "for 2023-03-25, MAE is:40.72 & sMAPE is:145.37% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :25.08 & 27.39% & 0.91\n",
      "for 2023-03-26, MAE is:17.10 & sMAPE is:22.57% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :24.98 & 27.33% & 0.90\n",
      "for 2023-03-27, MAE is:37.89 & sMAPE is:64.86% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :25.13 & 27.77% & 0.90\n",
      "for 2023-03-28, MAE is:19.00 & sMAPE is:18.39% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :25.06 & 27.66% & 0.91\n",
      "for 2023-03-29, MAE is:19.84 & sMAPE is:18.84% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :25.00 & 27.56% & 0.91\n",
      "for 2023-03-30, MAE is:17.20 & sMAPE is:29.06% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :24.91 & 27.58% & 0.90\n",
      "for 2023-03-31, MAE is:18.70 & sMAPE is:22.19% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :24.85 & 27.52% & 0.90\n",
      "for 2023-04-01, MAE is:12.82 & sMAPE is:17.62% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :24.71 & 27.41% & 0.89\n",
      "for 2023-04-02, MAE is:22.56 & sMAPE is:55.82% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :24.69 & 27.72% & 0.89\n",
      "for 2023-04-03, MAE is:27.15 & sMAPE is:24.91% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :24.72 & 27.69% & 0.89\n",
      "for 2023-04-04, MAE is:23.56 & sMAPE is:18.86% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :24.70 & 27.59% & 0.89\n",
      "for 2023-04-05, MAE is:21.98 & sMAPE is:16.28% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :24.68 & 27.48% & 0.89\n",
      "for 2023-04-06, MAE is:8.19 & sMAPE is:6.16% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :24.50 & 27.25% & 0.88\n",
      "for 2023-04-07, MAE is:13.17 & sMAPE is:11.25% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :24.39 & 27.09% & 0.88\n",
      "for 2023-04-08, MAE is:8.92 & sMAPE is:8.73% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :24.23 & 26.90% & 0.87\n",
      "for 2023-04-09, MAE is:7.85 & sMAPE is:7.02% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :24.06 & 26.70% & 0.87\n",
      "for 2023-04-10, MAE is:56.50 & sMAPE is:89.97% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :24.39 & 27.33% & 0.87\n",
      "for 2023-04-11, MAE is:49.54 & sMAPE is:104.17% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :24.64 & 28.09% & 0.86\n",
      "for 2023-04-12, MAE is:16.16 & sMAPE is:19.09% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :24.55 & 28.01% & 0.86\n",
      "for 2023-04-13, MAE is:35.30 & sMAPE is:55.30% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :24.66 & 28.27% & 0.86\n",
      "for 2023-04-14, MAE is:26.05 & sMAPE is:24.23% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :24.67 & 28.23% & 0.87\n",
      "for 2023-04-15, MAE is:16.64 & sMAPE is:25.86% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :24.60 & 28.21% & 0.87\n",
      "for 2023-04-16, MAE is:23.82 & sMAPE is:30.23% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :24.59 & 28.23% & 0.88\n",
      "for 2023-04-17, MAE is:25.28 & sMAPE is:21.93% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :24.59 & 28.17% & 0.87\n",
      "for 2023-04-18, MAE is:12.27 & sMAPE is:10.75% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :24.48 & 28.01% & 0.87\n",
      "for 2023-04-19, MAE is:65.54 & sMAPE is:63.21% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :24.86 & 28.33% & 0.87\n",
      "for 2023-04-20, MAE is:40.94 & sMAPE is:60.32% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :25.00 & 28.62% & 0.87\n",
      "for 2023-04-21, MAE is:18.14 & sMAPE is:18.85% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :24.94 & 28.53% & 0.87\n",
      "for 2023-04-22, MAE is:22.50 & sMAPE is:36.42% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :24.92 & 28.60% & 0.87\n",
      "for 2023-04-23, MAE is:26.42 & sMAPE is:64.05% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :24.93 & 28.92% & 0.87\n",
      "for 2023-04-24, MAE is:20.62 & sMAPE is:20.81% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :24.90 & 28.85% & 0.87\n",
      "for 2023-04-25, MAE is:16.74 & sMAPE is:27.17% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :24.82 & 28.83% & 0.87\n",
      "for 2023-04-26, MAE is:16.73 & sMAPE is:16.68% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :24.75 & 28.73% & 0.87\n",
      "for 2023-04-27, MAE is:18.33 & sMAPE is:20.11% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :24.70 & 28.65% & 0.87\n",
      "for 2023-04-28, MAE is:17.81 & sMAPE is:19.02% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :24.64 & 28.57% & 0.87\n",
      "for 2023-04-29, MAE is:29.10 & sMAPE is:49.53% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :24.68 & 28.75% & 0.88\n",
      "for 2023-04-30, MAE is:25.49 & sMAPE is:55.59% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :24.69 & 28.97% & 0.88\n",
      "for 2023-05-01, MAE is:10.45 & sMAPE is:14.51% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :24.57 & 28.85% & 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-05-02, MAE is:16.60 & sMAPE is:17.89% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :24.50 & 28.76% & 0.88\n",
      "for 2023-05-03, MAE is:12.83 & sMAPE is:16.16% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :24.41 & 28.66% & 0.87\n",
      "for 2023-05-04, MAE is:13.38 & sMAPE is:14.79% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :24.32 & 28.55% & 0.88\n",
      "for 2023-05-05, MAE is:12.80 & sMAPE is:14.10% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :24.23 & 28.43% & 0.89\n",
      "for 2023-05-06, MAE is:26.01 & sMAPE is:47.17% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :24.24 & 28.58% & 0.90\n",
      "for 2023-05-07, MAE is:19.55 & sMAPE is:37.13% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :24.20 & 28.65% & 0.89\n",
      "for 2023-05-08, MAE is:14.18 & sMAPE is:13.50% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :24.13 & 28.53% & 0.90\n",
      "for 2023-05-09, MAE is:19.61 & sMAPE is:17.10% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :24.09 & 28.44% & 0.91\n",
      "for 2023-05-10, MAE is:22.20 & sMAPE is:23.67% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :24.08 & 28.41% & 0.91\n",
      "for 2023-05-11, MAE is:20.89 & sMAPE is:21.97% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :24.05 & 28.36% & 0.91\n",
      "for 2023-05-12, MAE is:9.27 & sMAPE is:9.06% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :23.94 & 28.21% & 0.91\n",
      "for 2023-05-13, MAE is:23.88 & sMAPE is:51.53% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :23.94 & 28.39% & 0.91\n",
      "for 2023-05-14, MAE is:21.08 & sMAPE is:65.04% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :23.92 & 28.66% & 0.91\n",
      "for 2023-05-15, MAE is:12.50 & sMAPE is:12.26% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :23.83 & 28.54% & 0.91\n",
      "for 2023-05-16, MAE is:17.55 & sMAPE is:28.59% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :23.79 & 28.54% & 0.91\n",
      "for 2023-05-17, MAE is:22.72 & sMAPE is:47.11% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :23.78 & 28.67% & 0.91\n",
      "for 2023-05-18, MAE is:12.81 & sMAPE is:16.96% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :23.70 & 28.59% & 0.91\n",
      "for 2023-05-19, MAE is:14.52 & sMAPE is:17.78% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :23.63 & 28.51% & 0.91\n",
      "for 2023-05-20, MAE is:16.60 & sMAPE is:66.34% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :23.58 & 28.78% & 0.91\n",
      "for 2023-05-21, MAE is:28.08 & sMAPE is:86.12% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :23.62 & 29.19% & 0.90\n",
      "for 2023-05-22, MAE is:23.71 & sMAPE is:30.70% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :23.62 & 29.20% & 0.91\n",
      "for 2023-05-23, MAE is:21.61 & sMAPE is:50.58% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :23.60 & 29.35% & 0.91\n",
      "for 2023-05-24, MAE is:22.08 & sMAPE is:27.11% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :23.59 & 29.33% & 0.91\n",
      "for 2023-05-25, MAE is:31.89 & sMAPE is:53.07% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :23.65 & 29.50% & 0.92\n",
      "for 2023-05-26, MAE is:28.26 & sMAPE is:61.59% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :23.68 & 29.72% & 0.92\n",
      "for 2023-05-27, MAE is:22.84 & sMAPE is:57.93% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :23.67 & 29.91% & 0.92\n",
      "for 2023-05-28, MAE is:53.42 & sMAPE is:85.01% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :23.88 & 30.28% & 0.92\n",
      "for 2023-05-29, MAE is:52.31 & sMAPE is:92.56% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :24.07 & 30.70% & 0.92\n",
      "for 2023-05-30, MAE is:32.62 & sMAPE is:52.39% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :24.12 & 30.84% & 0.92\n",
      "for 2023-05-31, MAE is:21.97 & sMAPE is:49.52% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :24.11 & 30.97% & 0.92\n",
      "for 2023-06-01, MAE is:22.76 & sMAPE is:48.87% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :24.10 & 31.08% & 0.93\n",
      "for 2023-06-02, MAE is:15.63 & sMAPE is:22.39% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :24.04 & 31.03% & 0.92\n",
      "for 2023-06-03, MAE is:16.96 & sMAPE is:56.42% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :24.00 & 31.19% & 0.92\n",
      "for 2023-06-04, MAE is:14.77 & sMAPE is:46.85% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :23.94 & 31.29% & 0.92\n",
      "for 2023-06-05, MAE is:20.26 & sMAPE is:29.80% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :23.92 & 31.28% & 0.92\n",
      "for 2023-06-06, MAE is:11.41 & sMAPE is:14.45% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :23.84 & 31.18% & 0.92\n",
      "for 2023-06-07, MAE is:22.91 & sMAPE is:30.42% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :23.83 & 31.17% & 0.92\n",
      "for 2023-06-08, MAE is:9.83 & sMAPE is:12.73% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :23.74 & 31.06% & 0.92\n",
      "for 2023-06-09, MAE is:12.86 & sMAPE is:16.18% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :23.67 & 30.96% & 0.92\n",
      "for 2023-06-10, MAE is:22.58 & sMAPE is:65.84% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :23.67 & 31.18% & 0.93\n",
      "for 2023-06-11, MAE is:14.84 & sMAPE is:55.16% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :23.61 & 31.33% & 0.93\n",
      "for 2023-06-12, MAE is:15.82 & sMAPE is:18.08% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :23.56 & 31.25% & 0.93\n",
      "for 2023-06-13, MAE is:15.79 & sMAPE is:21.68% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :23.52 & 31.19% & 0.93\n",
      "for 2023-06-14, MAE is:33.85 & sMAPE is:39.29% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :23.58 & 31.24% & 0.94\n",
      "for 2023-06-15, MAE is:18.23 & sMAPE is:15.74% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :23.55 & 31.14% & 0.94\n",
      "for 2023-06-16, MAE is:19.23 & sMAPE is:15.60% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :23.52 & 31.05% & 0.93\n",
      "for 2023-06-17, MAE is:10.73 & sMAPE is:13.85% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :23.45 & 30.95% & 0.93\n",
      "for 2023-06-18, MAE is:16.03 & sMAPE is:25.00% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :23.40 & 30.91% & 0.93\n",
      "for 2023-06-19, MAE is:19.07 & sMAPE is:15.95% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :23.38 & 30.82% & 0.93\n",
      "for 2023-06-20, MAE is:9.82 & sMAPE is:8.09% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :23.30 & 30.69% & 0.92\n",
      "for 2023-06-21, MAE is:19.04 & sMAPE is:15.43% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :23.27 & 30.60% & 0.92\n",
      "for 2023-06-22, MAE is:13.07 & sMAPE is:10.71% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :23.21 & 30.49% & 0.92\n",
      "for 2023-06-23, MAE is:5.08 & sMAPE is:4.81% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :23.11 & 30.34% & 0.92\n",
      "for 2023-06-24, MAE is:20.57 & sMAPE is:43.47% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :23.09 & 30.42% & 0.92\n",
      "for 2023-06-25, MAE is:29.07 & sMAPE is:67.23% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :23.13 & 30.62% & 0.92\n",
      "for 2023-06-26, MAE is:17.71 & sMAPE is:23.41% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :23.10 & 30.58% & 0.92\n",
      "for 2023-06-27, MAE is:15.54 & sMAPE is:15.89% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :23.06 & 30.50% & 0.92\n",
      "for 2023-06-28, MAE is:15.97 & sMAPE is:14.47% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :23.02 & 30.41% & 0.92\n",
      "for 2023-06-29, MAE is:14.21 & sMAPE is:12.63% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :22.97 & 30.31% & 0.92\n",
      "for 2023-06-30, MAE is:10.96 & sMAPE is:10.89% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :22.90 & 30.21% & 0.92\n",
      "CPU times: total: 1d 18h 23s\n",
      "Wall time: 19h 56min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for zone in zones:\n",
    "    large_scale_predictor(zone, first_year=2018, last_year=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
