{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_scale_prediction import large_scale_predictor, large_scale_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = ['DK_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:22:12,523]\u001b[0m A new study created in RDB with name: DK_2_2018\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:22:57,032]\u001b[0m Trial 2 finished with value: 5.663468264854155 and parameters: {'n_hidden': 3, 'learning_rate': 0.019279774812093732, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29219591021403396, 'dropout_rate_Layer_2': 0.296992121642135, 'dropout_rate_Layer_3': 0.18299003244447426, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009366963028721245, 'l1_Layer_2': 0.00047167567920128984, 'l1_Layer_3': 0.08288460092920139, 'n_units_Layer_1': 90, 'n_units_Layer_2': 245, 'n_units_Layer_3': 145}. Best is trial 2 with value: 5.663468264854155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 19.25% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 14.55 | sMAPE for Test Set is: 35.06% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:22:57,571]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 22.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:23:04,032]\u001b[0m Trial 0 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:23:35,131]\u001b[0m Trial 6 finished with value: 12.904477826542248 and parameters: {'n_hidden': 3, 'learning_rate': 0.05173938133695132, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16773505946095255, 'dropout_rate_Layer_2': 0.3117263726058324, 'dropout_rate_Layer_3': 0.31500990112437677, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002032045522094945, 'l1_Layer_2': 0.0009023371828016287, 'l1_Layer_3': 6.50286345490488e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 125, 'n_units_Layer_3': 225}. Best is trial 2 with value: 5.663468264854155.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.90 | sMAPE for Validation Set is: 45.72% | rMAE for Validation Set is: 1.61\n",
      "MAE for Test Set is: 19.60 | sMAPE for Test Set is: 55.32% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:23:49,164]\u001b[0m Trial 7 finished with value: 5.300080911440557 and parameters: {'n_hidden': 3, 'learning_rate': 0.008489524353100977, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10751603763043134, 'dropout_rate_Layer_2': 0.3361780976120715, 'dropout_rate_Layer_3': 0.036345436542430234, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00562803966779062, 'l1_Layer_2': 0.007618988857655749, 'l1_Layer_3': 6.995125534144713e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300}. Best is trial 7 with value: 5.300080911440557.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 18.61% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.17 | sMAPE for Test Set is: 26.95% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:24:01,641]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:24:02,485]\u001b[0m Trial 1 finished with value: 5.657136854268541 and parameters: {'n_hidden': 4, 'learning_rate': 0.011659087934072054, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.179023531121991, 'dropout_rate_Layer_2': 0.09464899818244668, 'dropout_rate_Layer_3': 0.09610333036450808, 'dropout_rate_Layer_4': 0.1824107640044138, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006173711163342603, 'l1_Layer_2': 0.03490224449725664, 'l1_Layer_3': 2.2569304809490613e-05, 'l1_Layer_4': 0.0015405965694998969, 'n_units_Layer_1': 150, 'n_units_Layer_2': 295, 'n_units_Layer_3': 280, 'n_units_Layer_4': 295}. Best is trial 7 with value: 5.300080911440557.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 19.16% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 14.62 | sMAPE for Test Set is: 35.39% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:24:07,011]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:24:11,346]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 18.42% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.29 | sMAPE for Test Set is: 29.68% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:24:12,366]\u001b[0m Trial 4 finished with value: 5.227551030227898 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007781011995769492, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1326133332429619, 'dropout_rate_Layer_2': 0.0817770155006886, 'dropout_rate_Layer_3': 0.3542827989221155, 'dropout_rate_Layer_4': 0.21170349073455622, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004376288021454244, 'l1_Layer_2': 4.08832630965756e-05, 'l1_Layer_3': 3.128725185055958e-05, 'l1_Layer_4': 0.004610592195130367, 'n_units_Layer_1': 120, 'n_units_Layer_2': 155, 'n_units_Layer_3': 115, 'n_units_Layer_4': 65}. Best is trial 4 with value: 5.227551030227898.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:24:20,329]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:24:25,358]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:24:25,674]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:24:41,147]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:24:45,381]\u001b[0m Trial 16 finished with value: 5.6880487725455025 and parameters: {'n_hidden': 4, 'learning_rate': 0.013127528277060404, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3306881136640565, 'dropout_rate_Layer_2': 0.3807893192542575, 'dropout_rate_Layer_3': 0.09689706323770189, 'dropout_rate_Layer_4': 0.37524179117095885, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0035185955805139475, 'l1_Layer_2': 9.36913696453722e-05, 'l1_Layer_3': 0.00034538148689079517, 'l1_Layer_4': 0.005293882227125138, 'n_units_Layer_1': 225, 'n_units_Layer_2': 100, 'n_units_Layer_3': 230, 'n_units_Layer_4': 165}. Best is trial 4 with value: 5.227551030227898.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 19.37% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 13.33 | sMAPE for Test Set is: 32.01% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:24:51,940]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.49 | sMAPE for Validation Set is: 47.18% | rMAE for Validation Set is: 1.55\n",
      "MAE for Test Set is: 22.85 | sMAPE for Test Set is: 61.07% | rMAE for Test Set is: 2.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:24:53,454]\u001b[0m Trial 17 finished with value: 12.489567296291861 and parameters: {'n_hidden': 3, 'learning_rate': 0.06689686002148994, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37106068230465844, 'dropout_rate_Layer_2': 0.19692558959311876, 'dropout_rate_Layer_3': 0.3925029967372722, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.004551211543103509, 'l1_Layer_2': 0.002514473105948767, 'l1_Layer_3': 1.0585843297001034e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 160, 'n_units_Layer_3': 60}. Best is trial 4 with value: 5.227551030227898.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 19.61% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.03 | sMAPE for Test Set is: 26.93% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:24:56,890]\u001b[0m Trial 5 finished with value: 5.631772178440344 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032736768176410084, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35548718024294546, 'dropout_rate_Layer_2': 0.15288699131515504, 'dropout_rate_Layer_3': 0.23003275890140898, 'dropout_rate_Layer_4': 0.2211513435911895, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.015675695451662402, 'l1_Layer_2': 0.04125022138337205, 'l1_Layer_3': 0.0004612478743885487, 'l1_Layer_4': 0.0020494752160618427, 'n_units_Layer_1': 275, 'n_units_Layer_2': 300, 'n_units_Layer_3': 110, 'n_units_Layer_4': 180}. Best is trial 4 with value: 5.227551030227898.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:25:04,263]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:25:07,137]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:25:13,871]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:25:15,995]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:25:16,169]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:25:17,113]\u001b[0m Trial 10 finished with value: 5.87841666899136 and parameters: {'n_hidden': 3, 'learning_rate': 0.022427507693457402, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.253312441555247, 'dropout_rate_Layer_2': 0.14969018767074674, 'dropout_rate_Layer_3': 0.06648810974455191, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 9.698002368079392e-05, 'l1_Layer_2': 0.004944699054400854, 'l1_Layer_3': 0.00041029583682973504, 'n_units_Layer_1': 240, 'n_units_Layer_2': 190, 'n_units_Layer_3': 180}. Best is trial 4 with value: 5.227551030227898.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 20.24% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 10.66 | sMAPE for Test Set is: 25.50% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:25:20,240]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:25:27,669]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:25:28,434]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:25:28,475]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:25:35,850]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:25:44,133]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:25:44,839]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:25:50,389]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:25:54,429]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:25:59,963]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:26:00,331]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:26:07,939]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:26:08,027]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:26:15,228]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:26:15,338]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:26:27,230]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:26:28,578]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:26:35,786]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:26:40,370]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:26:42,413]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:26:44,388]\u001b[0m Trial 25 finished with value: 5.186294014813514 and parameters: {'n_hidden': 4, 'learning_rate': 0.005866898704368643, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1808400460990589, 'dropout_rate_Layer_2': 0.3419916109574883, 'dropout_rate_Layer_3': 0.23398244066654877, 'dropout_rate_Layer_4': 0.20989889884275206, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00013057099959836607, 'l1_Layer_2': 7.172405459962054e-05, 'l1_Layer_3': 4.05433215736646e-05, 'l1_Layer_4': 4.308418444366372e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 80, 'n_units_Layer_3': 240, 'n_units_Layer_4': 300}. Best is trial 25 with value: 5.186294014813514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 18.27% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.48 | sMAPE for Test Set is: 27.56% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:26:47,614]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:26:52,850]\u001b[0m Trial 31 finished with value: 7.483509474373396 and parameters: {'n_hidden': 4, 'learning_rate': 0.07828847253107114, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06390751941888176, 'dropout_rate_Layer_2': 0.17223505255300037, 'dropout_rate_Layer_3': 0.1502472293307974, 'dropout_rate_Layer_4': 0.20776564053177388, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.008897255175814009, 'l1_Layer_2': 0.019106234087750317, 'l1_Layer_3': 3.8359974027128427e-05, 'l1_Layer_4': 0.03584985491645501, 'n_units_Layer_1': 95, 'n_units_Layer_2': 120, 'n_units_Layer_3': 110, 'n_units_Layer_4': 220}. Best is trial 25 with value: 5.186294014813514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.48 | sMAPE for Validation Set is: 25.53% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 17.74 | sMAPE for Test Set is: 44.77% | rMAE for Test Set is: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:26:54,408]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:26:57,141]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:27:02,351]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:27:05,961]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:27:13,159]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:27:15,418]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:27:22,433]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:27:27,348]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:27:34,195]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:27:39,657]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:27:44,910]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:27:53,913]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:27:58,883]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:28:03,748]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:28:05,727]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 19.28% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.85 | sMAPE for Test Set is: 28.40% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:28:07,518]\u001b[0m Trial 52 finished with value: 5.554892654230254 and parameters: {'n_hidden': 3, 'learning_rate': 0.0075038999851195914, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15992463871054793, 'dropout_rate_Layer_2': 0.18137312152892426, 'dropout_rate_Layer_3': 0.22507932994028826, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00048250560654379543, 'l1_Layer_2': 0.03607652926001283, 'l1_Layer_3': 0.00019976228956741456, 'n_units_Layer_1': 275, 'n_units_Layer_2': 170, 'n_units_Layer_3': 275}. Best is trial 25 with value: 5.186294014813514.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:28:24,130]\u001b[0m Trial 65 finished with value: 6.291879470619189 and parameters: {'n_hidden': 3, 'learning_rate': 0.030245488500383902, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3541119402720875, 'dropout_rate_Layer_2': 0.10160869385907395, 'dropout_rate_Layer_3': 0.33351760557695725, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.019052156514467e-05, 'l1_Layer_2': 0.029108399428295205, 'l1_Layer_3': 6.426139371692758e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 160, 'n_units_Layer_3': 300}. Best is trial 25 with value: 5.186294014813514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 21.19% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 13.15 | sMAPE for Test Set is: 31.85% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:28:26,397]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:28:31,882]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:28:31,984]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:28:37,973]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:28:43,620]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:28:48,188]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:28:51,866]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:28:54,257]\u001b[0m Trial 66 finished with value: 5.3741966980706835 and parameters: {'n_hidden': 3, 'learning_rate': 0.005954587072474154, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1646404780467138, 'dropout_rate_Layer_2': 0.2366446223931278, 'dropout_rate_Layer_3': 0.21979080815914045, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00028691003180662984, 'l1_Layer_2': 0.0003125317919005217, 'l1_Layer_3': 3.7036829002864805e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 180, 'n_units_Layer_3': 245}. Best is trial 25 with value: 5.186294014813514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 18.56% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.63 | sMAPE for Test Set is: 27.78% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:28:57,694]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:29:00,164]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:29:00,666]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:29:04,926]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:29:08,873]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:29:13,198]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:29:34,562]\u001b[0m Trial 78 finished with value: 5.408748040028347 and parameters: {'n_hidden': 4, 'learning_rate': 0.002855312385314795, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2743066076990423, 'dropout_rate_Layer_2': 0.13415509339655723, 'dropout_rate_Layer_3': 0.20542675935401872, 'dropout_rate_Layer_4': 0.22807657383265065, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.020561099182734653, 'l1_Layer_2': 1.0512436303647659e-05, 'l1_Layer_3': 0.00010177550914293683, 'l1_Layer_4': 1.4052593605501415e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 300, 'n_units_Layer_3': 230, 'n_units_Layer_4': 195}. Best is trial 25 with value: 5.186294014813514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 18.92% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.55 | sMAPE for Test Set is: 27.86% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:29:39,587]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:29:49,421]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:29:49,927]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:29:55,055]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:29:58,274]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:30:04,312]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:30:15,375]\u001b[0m Trial 59 finished with value: 5.212237128006291 and parameters: {'n_hidden': 4, 'learning_rate': 0.003336175078653522, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2243112263243378, 'dropout_rate_Layer_2': 0.387663604400821, 'dropout_rate_Layer_3': 0.14349914301394562, 'dropout_rate_Layer_4': 0.39946177312572273, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0006445161776270434, 'l1_Layer_2': 0.0002343474223020303, 'l1_Layer_3': 2.51723341068516e-05, 'l1_Layer_4': 0.0009812763504538564, 'n_units_Layer_1': 260, 'n_units_Layer_2': 225, 'n_units_Layer_3': 295, 'n_units_Layer_4': 245}. Best is trial 25 with value: 5.186294014813514.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 18.63% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.83 | sMAPE for Test Set is: 23.58% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:30:26,785]\u001b[0m Trial 80 finished with value: 5.09200988929809 and parameters: {'n_hidden': 3, 'learning_rate': 0.004771190764209163, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23032091934804527, 'dropout_rate_Layer_2': 0.19321550632179293, 'dropout_rate_Layer_3': 0.19849713949906295, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00265114873481495, 'l1_Layer_2': 0.00013733175183009333, 'l1_Layer_3': 0.0002909224205004538, 'n_units_Layer_1': 230, 'n_units_Layer_2': 160, 'n_units_Layer_3': 285}. Best is trial 80 with value: 5.09200988929809.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 17.82% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.84 | sMAPE for Test Set is: 25.91% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:30:27,699]\u001b[0m Trial 84 finished with value: 5.077908156823846 and parameters: {'n_hidden': 3, 'learning_rate': 0.002852135450353016, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15872657266989573, 'dropout_rate_Layer_2': 0.27417064244063716, 'dropout_rate_Layer_3': 0.291024975745708, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002676196984740166, 'l1_Layer_2': 0.0004653704853673188, 'l1_Layer_3': 0.00011271953782276041, 'n_units_Layer_1': 285, 'n_units_Layer_2': 100, 'n_units_Layer_3': 290}. Best is trial 84 with value: 5.077908156823846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 17.86% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.46 | sMAPE for Test Set is: 25.00% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:30:34,410]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:30:36,702]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:30:42,914]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:30:49,458]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:31:02,659]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:31:11,046]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:31:15,040]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:31:19,771]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:31:22,810]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:31:25,070]\u001b[0m Trial 92 finished with value: 5.2803841683496096 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026952860210458225, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1533643210599808, 'dropout_rate_Layer_2': 0.3680732789916519, 'dropout_rate_Layer_3': 0.3340354322188147, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002742781790691773, 'l1_Layer_2': 0.0009825434310617963, 'l1_Layer_3': 0.00013975564411888391, 'n_units_Layer_1': 280, 'n_units_Layer_2': 160, 'n_units_Layer_3': 285}. Best is trial 84 with value: 5.077908156823846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 18.42% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.79 | sMAPE for Test Set is: 25.74% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:31:27,054]\u001b[0m Trial 94 finished with value: 5.391398014755889 and parameters: {'n_hidden': 3, 'learning_rate': 0.008353048108882079, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24967951542253028, 'dropout_rate_Layer_2': 0.07748936953039637, 'dropout_rate_Layer_3': 0.336769859365837, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.567553233543304e-05, 'l1_Layer_2': 0.014534578673694886, 'l1_Layer_3': 0.00027444099403301886, 'n_units_Layer_1': 100, 'n_units_Layer_2': 120, 'n_units_Layer_3': 105}. Best is trial 84 with value: 5.077908156823846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 18.78% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 12.82 | sMAPE for Test Set is: 30.96% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:31:33,444]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:31:34,928]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:31:39,771]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:31:42,904]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:31:48,631]\u001b[0m Trial 93 finished with value: 5.189749217924682 and parameters: {'n_hidden': 3, 'learning_rate': 0.003001793961627325, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10052939936392197, 'dropout_rate_Layer_2': 0.34656559111869, 'dropout_rate_Layer_3': 0.2950188435211622, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002740177461830495, 'l1_Layer_2': 0.0005610382278905572, 'l1_Layer_3': 1.0170661496321831e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 165, 'n_units_Layer_3': 285}. Best is trial 84 with value: 5.077908156823846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 18.28% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.88 | sMAPE for Test Set is: 26.17% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:31:50,865]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:31:51,237]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:31:56,534]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:32:00,792]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:32:02,970]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:32:13,029]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:32:13,185]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:32:29,686]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:32:34,298]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:32:36,831]\u001b[0m Trial 111 finished with value: 5.096354618193495 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007935295813749293, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12965733151377415, 'dropout_rate_Layer_2': 0.275468205827071, 'dropout_rate_Layer_3': 0.2584593009901456, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00044500568795905864, 'l1_Layer_2': 9.820837110617395e-05, 'l1_Layer_3': 0.002794529402803868, 'n_units_Layer_1': 135, 'n_units_Layer_2': 290, 'n_units_Layer_3': 300}. Best is trial 84 with value: 5.077908156823846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 17.75% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.95 | sMAPE for Test Set is: 31.17% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:32:44,475]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:32:49,495]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:32:51,073]\u001b[0m Trial 109 finished with value: 5.09745765438182 and parameters: {'n_hidden': 3, 'learning_rate': 0.001083074664771516, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04950300559298684, 'dropout_rate_Layer_2': 0.3888688331035962, 'dropout_rate_Layer_3': 0.3302588147199687, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0007765274068749386, 'l1_Layer_2': 0.0005654392582822269, 'l1_Layer_3': 5.4126767464049034e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 130, 'n_units_Layer_3': 250}. Best is trial 84 with value: 5.077908156823846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 17.80% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.63 | sMAPE for Test Set is: 25.36% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:32:51,323]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:32:55,083]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:32:58,013]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:32:59,224]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:33:03,759]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:33:08,798]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:33:09,062]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:33:11,091]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:33:18,874]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:33:21,087]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:33:25,228]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:33:27,382]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:33:30,556]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:33:30,719]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:33:31,212]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:33:41,358]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:33:43,503]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:33:47,064]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:33:49,226]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:33:49,569]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:33:53,667]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:34:05,719]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:34:10,355]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:34:10,548]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:34:17,323]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:34:21,636]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:34:22,145]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:34:29,718]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:34:31,493]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:34:36,379]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:34:38,070]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:34:42,031]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:34:44,233]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:34:50,226]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:34:59,958]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:35:09,217]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:35:14,583]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:35:20,510]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:35:28,239]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:35:32,162]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:35:35,706]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:35:40,711]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:35:46,536]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:35:50,020]\u001b[0m Trial 152 finished with value: 5.209907899776984 and parameters: {'n_hidden': 4, 'learning_rate': 0.005810901714785778, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09816298443610688, 'dropout_rate_Layer_2': 0.18520947787380104, 'dropout_rate_Layer_3': 0.16446825240392862, 'dropout_rate_Layer_4': 0.18589942396413922, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0019149877388092119, 'l1_Layer_2': 0.0026609424310095157, 'l1_Layer_3': 2.7766856600501063e-05, 'l1_Layer_4': 0.00038885431410362137, 'n_units_Layer_1': 275, 'n_units_Layer_2': 140, 'n_units_Layer_3': 195, 'n_units_Layer_4': 65}. Best is trial 84 with value: 5.077908156823846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 18.62% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.11 | sMAPE for Test Set is: 24.36% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:35:53,118]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:35:56,662]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:35:59,979]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:36:04,379]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:36:14,691]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:36:16,643]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:36:17,232]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:36:19,088]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:36:24,087]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:36:24,536]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:36:29,088]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:36:34,451]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:36:39,639]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:36:41,959]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:36:52,254]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:36:57,248]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:37:01,319]\u001b[0m Trial 175 finished with value: 5.442847501174921 and parameters: {'n_hidden': 3, 'learning_rate': 0.002020672927985541, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09177030189362279, 'dropout_rate_Layer_2': 0.1828255041610395, 'dropout_rate_Layer_3': 0.33424487044293655, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00916840423764931, 'l1_Layer_2': 0.0017922149130379704, 'l1_Layer_3': 7.790690986828841e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 170, 'n_units_Layer_3': 70}. Best is trial 84 with value: 5.077908156823846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 18.95% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.99 | sMAPE for Test Set is: 23.91% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:37:05,370]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:37:08,784]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:37:08,830]\u001b[0m Trial 177 finished with value: 5.395463675284964 and parameters: {'n_hidden': 3, 'learning_rate': 0.003614971760282355, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2884674384874142, 'dropout_rate_Layer_2': 0.2164260254900664, 'dropout_rate_Layer_3': 0.24211207133012508, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007536156199375485, 'l1_Layer_2': 0.001627282627075181, 'l1_Layer_3': 6.197811823026195e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 80, 'n_units_Layer_3': 105}. Best is trial 84 with value: 5.077908156823846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 18.60% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.66 | sMAPE for Test Set is: 23.06% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:37:09,447]\u001b[0m Trial 178 finished with value: 5.095489144653803 and parameters: {'n_hidden': 3, 'learning_rate': 0.004529675133512904, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2987026267627602, 'dropout_rate_Layer_2': 0.22769348756175173, 'dropout_rate_Layer_3': 0.34236536573722653, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003630874781338389, 'l1_Layer_2': 0.0006636989076071115, 'l1_Layer_3': 2.4579394139592498e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 165, 'n_units_Layer_3': 185}. Best is trial 84 with value: 5.077908156823846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 17.75% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.09 | sMAPE for Test Set is: 23.92% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:37:19,208]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:37:19,434]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:37:24,533]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:37:28,181]\u001b[0m Trial 180 finished with value: 5.118411658707056 and parameters: {'n_hidden': 3, 'learning_rate': 0.002146106942983762, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0692180245331887, 'dropout_rate_Layer_2': 0.39840984036952837, 'dropout_rate_Layer_3': 0.35639548481023986, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0014878704068796123, 'l1_Layer_2': 0.00040150543340993134, 'l1_Layer_3': 0.00015060113376094052, 'n_units_Layer_1': 260, 'n_units_Layer_2': 190, 'n_units_Layer_3': 285}. Best is trial 84 with value: 5.077908156823846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 17.96% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.97 | sMAPE for Test Set is: 23.86% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:37:35,464]\u001b[0m Trial 185 finished with value: 5.1580966629884335 and parameters: {'n_hidden': 3, 'learning_rate': 0.00431968629696314, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08209493688767569, 'dropout_rate_Layer_2': 0.20215911641341192, 'dropout_rate_Layer_3': 0.35111694120264675, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003793460467600962, 'l1_Layer_2': 0.0007553122533668126, 'l1_Layer_3': 2.226858957974038e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 70, 'n_units_Layer_3': 70}. Best is trial 84 with value: 5.077908156823846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 18.03% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.52 | sMAPE for Test Set is: 22.76% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:37:36,016]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:37:50,659]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:37:51,107]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:37:56,584]\u001b[0m Trial 188 finished with value: 5.058239804222154 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021878495857399777, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07290387627928871, 'dropout_rate_Layer_2': 0.22648922450024203, 'dropout_rate_Layer_3': 0.3550702850470989, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003908855868154116, 'l1_Layer_2': 0.0007191586058835306, 'l1_Layer_3': 2.6383126595123793e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 75, 'n_units_Layer_3': 65}. Best is trial 188 with value: 5.058239804222154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 17.71% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.70 | sMAPE for Test Set is: 20.95% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:37:59,547]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:38:03,398]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:38:07,128]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:38:12,284]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:38:12,765]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:38:12,994]\u001b[0m Trial 191 finished with value: 5.121037995707612 and parameters: {'n_hidden': 3, 'learning_rate': 0.004225890288835198, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06387070241651599, 'dropout_rate_Layer_2': 0.2178122137814778, 'dropout_rate_Layer_3': 0.3844837467031914, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003594299771711179, 'l1_Layer_2': 0.0006078575254929806, 'l1_Layer_3': 2.225991875714816e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 70, 'n_units_Layer_3': 185}. Best is trial 188 with value: 5.058239804222154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 17.98% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.54 | sMAPE for Test Set is: 22.76% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:38:23,779]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:38:29,318]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:38:58,566]\u001b[0m Trial 202 finished with value: 4.933620325035002 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027253366417030367, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06419647417008364, 'dropout_rate_Layer_2': 0.18988088366374323, 'dropout_rate_Layer_3': 0.38410862040530147, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001407047532552992, 'l1_Layer_2': 0.00019271173216452639, 'l1_Layer_3': 1.4982957972153565e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 95, 'n_units_Layer_3': 190}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 17.27% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 8.57 | sMAPE for Test Set is: 20.51% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:39:03,661]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:39:09,230]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:39:33,784]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:39:57,905]\u001b[0m Trial 206 finished with value: 5.05066087832109 and parameters: {'n_hidden': 3, 'learning_rate': 0.002315224001603056, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07763975861661213, 'dropout_rate_Layer_2': 0.19530311904906172, 'dropout_rate_Layer_3': 0.3837769453395179, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017803343418317018, 'l1_Layer_2': 0.00019931843544836956, 'l1_Layer_3': 1.5673329855604454e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 65, 'n_units_Layer_3': 185}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 17.78% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.97 | sMAPE for Test Set is: 19.43% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:39:58,864]\u001b[0m Trial 200 finished with value: 5.032112049470402 and parameters: {'n_hidden': 4, 'learning_rate': 0.00726501692260471, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14083752410128947, 'dropout_rate_Layer_2': 0.038988927992986006, 'dropout_rate_Layer_3': 0.0009917718136709386, 'dropout_rate_Layer_4': 0.3451195963155858, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.013384232646524e-05, 'l1_Layer_2': 0.002435078882529472, 'l1_Layer_3': 5.786100046225675e-05, 'l1_Layer_4': 5.497287744963613e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 50, 'n_units_Layer_3': 245, 'n_units_Layer_4': 155}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 17.64% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.16 | sMAPE for Test Set is: 22.18% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:40:00,792]\u001b[0m Trial 194 finished with value: 5.074203377459303 and parameters: {'n_hidden': 3, 'learning_rate': 0.006685270922986144, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09043763441898203, 'dropout_rate_Layer_2': 0.3624908048575063, 'dropout_rate_Layer_3': 0.3536887138504113, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0007641612761240197, 'l1_Layer_2': 0.0009558663987926507, 'l1_Layer_3': 8.342620092274843e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 265, 'n_units_Layer_3': 255}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 17.80% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.02 | sMAPE for Test Set is: 26.47% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:40:08,048]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:40:08,242]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:40:17,091]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:40:18,873]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:40:25,068]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:40:27,134]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:40:33,177]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:40:35,295]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:40:40,128]\u001b[0m Trial 199 finished with value: 5.207948080117032 and parameters: {'n_hidden': 4, 'learning_rate': 0.00819409463215052, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13715034308320373, 'dropout_rate_Layer_2': 0.0710372673613699, 'dropout_rate_Layer_3': 0.130798828605875, 'dropout_rate_Layer_4': 0.34625971898841557, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011631746836478372, 'l1_Layer_2': 0.00270945580058982, 'l1_Layer_3': 4.4292934175274444e-05, 'l1_Layer_4': 4.286721420615547e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 265, 'n_units_Layer_3': 300, 'n_units_Layer_4': 160}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 18.32% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.72 | sMAPE for Test Set is: 21.23% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:40:42,173]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:40:42,735]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:40:42,929]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:40:47,675]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:40:48,577]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:40:50,329]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:40:53,479]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:40:53,938]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:40:58,076]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:41:00,076]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:41:04,338]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:41:06,820]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:41:10,870]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:41:14,541]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:41:30,075]\u001b[0m Trial 230 finished with value: 5.1543929923067715 and parameters: {'n_hidden': 3, 'learning_rate': 0.00661841653166713, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10179147217869264, 'dropout_rate_Layer_2': 0.33904836978283603, 'dropout_rate_Layer_3': 0.23374443601898248, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.004251938193645086, 'l1_Layer_2': 0.0036914966422921854, 'l1_Layer_3': 0.00013513890651446644, 'n_units_Layer_1': 235, 'n_units_Layer_2': 300, 'n_units_Layer_3': 270}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 18.19% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.21 | sMAPE for Test Set is: 26.97% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:41:33,262]\u001b[0m Trial 224 finished with value: 5.180187601349986 and parameters: {'n_hidden': 3, 'learning_rate': 0.003109144608003203, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06438860719238451, 'dropout_rate_Layer_2': 0.3717720173638266, 'dropout_rate_Layer_3': 0.33431051532804124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0021852900833511297, 'l1_Layer_2': 0.00033794451794792686, 'l1_Layer_3': 0.0004441444092951608, 'n_units_Layer_1': 280, 'n_units_Layer_2': 190, 'n_units_Layer_3': 295}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 18.22% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.18 | sMAPE for Test Set is: 24.40% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:41:41,713]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:41:46,264]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:41:50,148]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:41:55,826]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:42:04,654]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:42:05,046]\u001b[0m Trial 232 finished with value: 5.131095729888984 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025850837444252764, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16004872406132098, 'dropout_rate_Layer_2': 0.35410250455358255, 'dropout_rate_Layer_3': 0.35733700498498827, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016991700759390928, 'l1_Layer_2': 0.008208783006252145, 'l1_Layer_3': 8.463947797010035e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 260, 'n_units_Layer_3': 265}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 17.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 16.72% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:42:15,336]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:42:15,741]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:42:23,490]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:42:28,598]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:42:32,610]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:42:33,022]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:42:38,813]\u001b[0m Trial 240 finished with value: 4.93431213742861 and parameters: {'n_hidden': 3, 'learning_rate': 0.003414799567572513, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07284434363019163, 'dropout_rate_Layer_2': 0.20131545704748863, 'dropout_rate_Layer_3': 0.35134038165968173, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00042813577700380576, 'l1_Layer_2': 6.64957281016434e-05, 'l1_Layer_3': 3.0080390106411848e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 70, 'n_units_Layer_3': 195}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 17.37% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.49 | sMAPE for Test Set is: 22.74% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:42:39,034]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:42:45,591]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:42:47,445]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:42:51,598]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:42:54,131]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:42:57,228]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:43:07,294]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:43:10,965]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:43:15,069]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:43:31,517]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:43:34,335]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:43:39,734]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:43:42,783]\u001b[0m Trial 233 finished with value: 5.035365400261053 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009404159550949345, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15817405238958107, 'dropout_rate_Layer_2': 0.35288024000079354, 'dropout_rate_Layer_3': 0.17572081979025195, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0028043649893529556, 'l1_Layer_2': 0.006815222397136154, 'l1_Layer_3': 0.0004320832936127286, 'n_units_Layer_1': 95, 'n_units_Layer_2': 160, 'n_units_Layer_3': 265}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 17.63% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.75 | sMAPE for Test Set is: 16.95% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:43:46,182]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:43:47,033]\u001b[0m Trial 256 finished with value: 4.947350475568346 and parameters: {'n_hidden': 3, 'learning_rate': 0.000770837263358074, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10732088694651655, 'dropout_rate_Layer_2': 0.2243564520957314, 'dropout_rate_Layer_3': 0.054040433756409934, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001287114428372008, 'l1_Layer_2': 1.4115231263330432e-05, 'l1_Layer_3': 1.0019050758733112e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 60, 'n_units_Layer_3': 200}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 17.46% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.81 | sMAPE for Test Set is: 19.15% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:43:48,515]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:43:52,242]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:43:54,822]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:43:59,388]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:44:04,230]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:44:07,484]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:44:11,431]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:44:11,834]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:44:17,337]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:44:17,773]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:44:25,129]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:44:25,177]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:44:38,463]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:45:38,286]\u001b[0m Trial 253 finished with value: 5.08893706053329 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005031586782534799, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14342386197373783, 'dropout_rate_Layer_2': 0.34850787367530717, 'dropout_rate_Layer_3': 0.3349753455296392, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00506082793500014, 'l1_Layer_2': 0.00606220816472025, 'l1_Layer_3': 0.0005550173739776336, 'n_units_Layer_1': 255, 'n_units_Layer_2': 160, 'n_units_Layer_3': 245}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 17.81% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 17.24% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:45:41,751]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:45:53,444]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:45:58,185]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:46:01,373]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:46:07,699]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:46:14,097]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:46:21,795]\u001b[0m Trial 275 finished with value: 5.120916329547903 and parameters: {'n_hidden': 4, 'learning_rate': 0.007435447686978586, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11303799533519984, 'dropout_rate_Layer_2': 0.09794010606583536, 'dropout_rate_Layer_3': 0.1896659142979172, 'dropout_rate_Layer_4': 0.27335105465846415, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.493454981736145e-05, 'l1_Layer_2': 0.004937517069213371, 'l1_Layer_3': 5.309409472798114e-05, 'l1_Layer_4': 8.208200687705973e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 85, 'n_units_Layer_3': 220, 'n_units_Layer_4': 110}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 17.91% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.09 | sMAPE for Test Set is: 24.36% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:47:11,687]\u001b[0m Trial 283 finished with value: 5.301932100605922 and parameters: {'n_hidden': 3, 'learning_rate': 0.005633270121794075, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14965756793231524, 'dropout_rate_Layer_2': 0.08461328138240362, 'dropout_rate_Layer_3': 0.3670343832911084, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015600028246313322, 'l1_Layer_2': 0.0006973612734717435, 'l1_Layer_3': 0.0008304798316780764, 'n_units_Layer_1': 245, 'n_units_Layer_2': 165, 'n_units_Layer_3': 260}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 18.46% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 12.22 | sMAPE for Test Set is: 29.27% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:47:17,536]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:47:35,154]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:47:38,189]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:47:44,004]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:47:49,640]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:48:00,271]\u001b[0m Trial 285 finished with value: 5.203132886428393 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014969694211076916, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08281586510896652, 'dropout_rate_Layer_2': 0.24997290749091702, 'dropout_rate_Layer_3': 0.22597752736242188, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.003174663013835776, 'l1_Layer_2': 0.0009332425176589379, 'l1_Layer_3': 0.00022058645226309846, 'n_units_Layer_1': 270, 'n_units_Layer_2': 170, 'n_units_Layer_3': 255}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 18.15% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.04 | sMAPE for Test Set is: 28.96% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:48:03,335]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:48:07,028]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:48:07,372]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:48:12,553]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:48:13,060]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:48:17,844]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:48:22,792]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:48:26,204]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:48:36,737]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:48:38,758]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:48:45,125]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:48:50,894]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:49:03,106]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:49:07,767]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:49:08,109]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:49:13,651]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:49:18,909]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:49:22,955]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:49:24,839]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:49:25,165]\u001b[0m Trial 302 finished with value: 5.356911428667314 and parameters: {'n_hidden': 3, 'learning_rate': 0.001567236366430428, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05489602880445764, 'dropout_rate_Layer_2': 0.2635836056996979, 'dropout_rate_Layer_3': 0.13578705564079108, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.03438308539541927, 'l1_Layer_2': 0.0018081031032392962, 'l1_Layer_3': 0.0002617969749378364, 'n_units_Layer_1': 285, 'n_units_Layer_2': 175, 'n_units_Layer_3': 255}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 18.56% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.81 | sMAPE for Test Set is: 28.07% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:49:31,899]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:49:36,451]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:49:36,553]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:49:41,646]\u001b[0m Trial 267 finished with value: 5.092311872363758 and parameters: {'n_hidden': 4, 'learning_rate': 0.007784000827525744, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11115342949283004, 'dropout_rate_Layer_2': 0.017661198306493542, 'dropout_rate_Layer_3': 0.19668119811406085, 'dropout_rate_Layer_4': 0.2644173372748815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.7674765883107156e-05, 'l1_Layer_2': 0.0010229748536469013, 'l1_Layer_3': 5.714271465572487e-05, 'l1_Layer_4': 0.00010341943334088564, 'n_units_Layer_1': 235, 'n_units_Layer_2': 90, 'n_units_Layer_3': 190, 'n_units_Layer_4': 55}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 17.84% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.91 | sMAPE for Test Set is: 24.24% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:49:47,346]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:49:50,321]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:49:53,621]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:49:53,853]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:49:54,048]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:50:00,453]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:50:01,021]\u001b[0m Trial 313 finished with value: 4.9748738114505295 and parameters: {'n_hidden': 3, 'learning_rate': 0.004666217451655484, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10580137992999145, 'dropout_rate_Layer_2': 0.1757432802013755, 'dropout_rate_Layer_3': 0.32049708342974437, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003168432078133316, 'l1_Layer_2': 0.0002564964296578245, 'l1_Layer_3': 2.581311594246112e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 115, 'n_units_Layer_3': 170}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 17.40% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.86 | sMAPE for Test Set is: 21.22% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:50:01,610]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:50:08,359]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:50:08,967]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:50:13,166]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:50:16,595]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:50:17,126]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:50:17,673]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:50:23,174]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:50:26,056]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:50:29,789]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:50:30,229]\u001b[0m Trial 318 finished with value: 5.050107659614286 and parameters: {'n_hidden': 3, 'learning_rate': 0.00514011460987855, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10504056689988436, 'dropout_rate_Layer_2': 0.20007854304687475, 'dropout_rate_Layer_3': 0.38572883993083557, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.214733509010613e-05, 'l1_Layer_2': 0.0009479221916715239, 'l1_Layer_3': 4.5347381491364836e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 120, 'n_units_Layer_3': 140}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 17.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.73 | sMAPE for Test Set is: 20.93% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:50:32,761]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:50:36,183]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:50:39,600]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:50:47,617]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:50:50,623]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:50:54,856]\u001b[0m Trial 331 finished with value: 5.012406596220074 and parameters: {'n_hidden': 3, 'learning_rate': 0.002871013635659404, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1525243394809514, 'dropout_rate_Layer_2': 0.180860843721821, 'dropout_rate_Layer_3': 0.3562322853953114, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.058901848724333e-05, 'l1_Layer_2': 5.110714300731293e-05, 'l1_Layer_3': 4.2891144462874626e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 115, 'n_units_Layer_3': 140}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 17.60% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.10 | sMAPE for Test Set is: 19.56% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:50:55,454]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:51:00,543]\u001b[0m Trial 334 finished with value: 5.422992761756678 and parameters: {'n_hidden': 3, 'learning_rate': 0.004924830323870031, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08842849230870563, 'dropout_rate_Layer_2': 0.3427144680361794, 'dropout_rate_Layer_3': 0.2570785859322652, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.004465196054822217, 'l1_Layer_2': 0.00017316666567316672, 'l1_Layer_3': 0.00012104256271212802, 'n_units_Layer_1': 220, 'n_units_Layer_2': 280, 'n_units_Layer_3': 200}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 19.00% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 12.49 | sMAPE for Test Set is: 30.07% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:51:01,057]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:51:04,360]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:51:04,593]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:51:11,607]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:51:15,248]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:51:21,018]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:51:27,112]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:51:53,106]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:51:59,119]\u001b[0m Trial 344 finished with value: 5.118395562386436 and parameters: {'n_hidden': 3, 'learning_rate': 0.001157820704512676, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12418865163813606, 'dropout_rate_Layer_2': 0.2947748755795461, 'dropout_rate_Layer_3': 0.3686648403243266, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.000711301740831748, 'l1_Layer_2': 3.467041919749032e-05, 'l1_Layer_3': 6.962294977906486e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 135, 'n_units_Layer_3': 290}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 17.99% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.86 | sMAPE for Test Set is: 28.54% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:52:02,414]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:52:05,039]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:52:05,757]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:52:16,406]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:52:21,085]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:52:24,049]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:52:29,535]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:52:32,643]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:52:47,355]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:52:48,481]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:52:52,796]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:52:58,169]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:53:04,464]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:53:06,618]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:53:09,585]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:53:13,763]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:53:19,671]\u001b[0m Trial 356 finished with value: 5.114877473525288 and parameters: {'n_hidden': 3, 'learning_rate': 0.001154817166639847, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03334619909651844, 'dropout_rate_Layer_2': 0.2845107933766531, 'dropout_rate_Layer_3': 0.36667286826230894, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0008004398795397453, 'l1_Layer_2': 3.957454829476261e-05, 'l1_Layer_3': 6.032581898616161e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 105, 'n_units_Layer_3': 285}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 17.88% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.25 | sMAPE for Test Set is: 26.97% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:53:27,731]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:53:30,531]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:53:38,081]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:53:45,493]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:53:49,581]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:53:55,485]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:54:00,594]\u001b[0m Trial 367 finished with value: 5.0591964612071525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0052895939690482735, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07968685937712044, 'dropout_rate_Layer_2': 0.192815282911184, 'dropout_rate_Layer_3': 0.37071296616881294, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007212016371763238, 'l1_Layer_2': 0.0004810323339520927, 'l1_Layer_3': 1.9649530649674922e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 165, 'n_units_Layer_3': 180}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 17.76% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.87 | sMAPE for Test Set is: 21.40% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:54:00,977]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:54:07,911]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:54:08,735]\u001b[0m Trial 363 finished with value: 5.195371316760169 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012386963103292255, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03526353560675505, 'dropout_rate_Layer_2': 0.29414072127959534, 'dropout_rate_Layer_3': 0.36037169059164353, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0007207229567848001, 'l1_Layer_2': 0.0007033690087181135, 'l1_Layer_3': 5.560969458640192e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 125, 'n_units_Layer_3': 285}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 18.09% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.11 | sMAPE for Test Set is: 26.75% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:54:10,917]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:54:16,186]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:54:16,423]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:54:19,682]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:54:23,345]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:54:27,231]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:54:31,401]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:54:34,780]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:54:38,490]\u001b[0m Trial 357 finished with value: 5.081398208963805 and parameters: {'n_hidden': 4, 'learning_rate': 0.010978802806688948, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1180495565680642, 'dropout_rate_Layer_2': 0.08280659304891892, 'dropout_rate_Layer_3': 0.2505723652147797, 'dropout_rate_Layer_4': 0.3145762564907855, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.362749497770004e-05, 'l1_Layer_2': 0.0030626318780742103, 'l1_Layer_3': 0.00027598019861189906, 'l1_Layer_4': 4.793228399946892e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 80, 'n_units_Layer_3': 155, 'n_units_Layer_4': 100}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 17.97% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.20 | sMAPE for Test Set is: 22.55% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:54:40,411]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:54:40,825]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:54:45,565]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:54:49,438]\u001b[0m Trial 379 finished with value: 5.313175230423611 and parameters: {'n_hidden': 3, 'learning_rate': 0.002870361472354037, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12255094698521213, 'dropout_rate_Layer_2': 0.31239218939915775, 'dropout_rate_Layer_3': 0.3640469585907559, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00017024822338116132, 'l1_Layer_2': 3.2919448133861434e-05, 'l1_Layer_3': 1.967285643292629e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 70, 'n_units_Layer_3': 300}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 18.46% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.99 | sMAPE for Test Set is: 28.86% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:54:53,470]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:54:56,274]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:54:59,894]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:00,211]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:06,267]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:08,429]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:12,730]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:12,932]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:16,609]\u001b[0m Trial 387 finished with value: 5.1533456845689765 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008489394185058507, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.003059022488167043, 'dropout_rate_Layer_2': 0.3060567378383727, 'dropout_rate_Layer_3': 0.3678024907915873, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0001888897259311794, 'l1_Layer_2': 0.00013030961089493712, 'l1_Layer_3': 2.240319542955284e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 85, 'n_units_Layer_3': 300}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 18.07% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.97 | sMAPE for Test Set is: 28.78% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:55:17,979]\u001b[0m Trial 386 finished with value: 5.139648153472769 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008436225851878933, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12166445502122895, 'dropout_rate_Layer_2': 0.304993307829017, 'dropout_rate_Layer_3': 0.3626850311609475, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00015780585491270558, 'l1_Layer_2': 4.00884939668902e-05, 'l1_Layer_3': 9.185718337183007e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 80, 'n_units_Layer_3': 290}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 17.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.23 | sMAPE for Test Set is: 26.98% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:55:20,139]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:20,966]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:24,559]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:27,489]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:30,172]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:31,895]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:33,345]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:37,303]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:39,580]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:44,302]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:49,534]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:53,570]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:55,720]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:55:57,513]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:56:01,001]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:56:03,947]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:56:09,812]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:56:17,286]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:56:20,330]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:56:24,907]\u001b[0m Trial 406 finished with value: 5.283115645982257 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007101884152041804, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22139531276742874, 'dropout_rate_Layer_2': 0.18649159856572234, 'dropout_rate_Layer_3': 0.3084307697186134, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.782089620583107e-05, 'l1_Layer_2': 4.7420988421336115e-05, 'l1_Layer_3': 5.33712297550012e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 120, 'n_units_Layer_3': 285}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 18.40% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.14 | sMAPE for Test Set is: 24.42% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:56:30,636]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:56:40,890]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:56:45,845]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:56:48,147]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:56:51,308]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:56:54,028]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:57:00,051]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:57:03,932]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:57:08,170]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 18.63% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 13.10 | sMAPE for Test Set is: 31.89% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:57:09,177]\u001b[0m Trial 419 finished with value: 5.353581779035333 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020078183946579836, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16811015347346947, 'dropout_rate_Layer_2': 0.28095428918583826, 'dropout_rate_Layer_3': 0.3496273392278814, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0005228240621327798, 'l1_Layer_2': 2.2356306383893957e-05, 'l1_Layer_3': 8.763695930606327e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 135, 'n_units_Layer_3': 230}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:57:12,865]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:57:16,630]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:57:17,000]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:57:18,884]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:57:28,850]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:57:36,534]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:57:37,259]\u001b[0m Trial 420 finished with value: 5.3119191359707765 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011279371129013268, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17604590680674276, 'dropout_rate_Layer_2': 0.27627762988704013, 'dropout_rate_Layer_3': 0.35506624921102986, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 6.266799976037186e-05, 'l1_Layer_2': 2.5846015823224322e-05, 'l1_Layer_3': 8.704012523385963e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 130, 'n_units_Layer_3': 230}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 18.56% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.81 | sMAPE for Test Set is: 28.50% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:57:41,653]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:57:42,517]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:57:49,713]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:57:50,453]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:58:00,402]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:58:02,245]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:58:05,982]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:58:07,741]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:58:08,722]\u001b[0m Trial 434 finished with value: 5.128903002898787 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027920102821384477, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25877170601346644, 'dropout_rate_Layer_2': 0.37815749806042614, 'dropout_rate_Layer_3': 0.33327725951900405, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0006268906936644684, 'l1_Layer_2': 0.0009545375988369999, 'l1_Layer_3': 0.0001243471937660592, 'n_units_Layer_1': 295, 'n_units_Layer_2': 170, 'n_units_Layer_3': 250}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 17.83% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.46 | sMAPE for Test Set is: 27.25% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:58:09,936]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:58:10,146]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:58:15,916]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:58:17,971]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:58:20,026]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:58:20,221]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:58:21,574]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:58:29,252]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:58:42,045]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:58:48,648]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:58:52,757]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:58:57,427]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:59:03,102]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:59:08,099]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:59:08,219]\u001b[0m Trial 452 finished with value: 5.1615324574631245 and parameters: {'n_hidden': 3, 'learning_rate': 0.002558217480174038, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21973148276742555, 'dropout_rate_Layer_2': 0.365749469975018, 'dropout_rate_Layer_3': 0.37679484762256343, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00039586098539159313, 'l1_Layer_2': 4.9191861936803626e-05, 'l1_Layer_3': 4.427366885296073e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 105, 'n_units_Layer_3': 265}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 18.19% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.79 | sMAPE for Test Set is: 25.96% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:59:09,580]\u001b[0m Trial 444 finished with value: 5.216420893196289 and parameters: {'n_hidden': 3, 'learning_rate': 0.002412579597062669, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03368644198292846, 'dropout_rate_Layer_2': 0.3709630178819495, 'dropout_rate_Layer_3': 0.37580145075523036, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00034841214137061924, 'l1_Layer_2': 4.8600724227205024e-05, 'l1_Layer_3': 0.00053416750323481, 'n_units_Layer_1': 255, 'n_units_Layer_2': 110, 'n_units_Layer_3': 265}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.22 | sMAPE for Validation Set is: 18.22% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.71 | sMAPE for Test Set is: 28.38% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:59:15,116]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:59:18,747]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:59:20,013]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:59:23,392]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:59:25,857]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:59:32,640]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:59:35,780]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:59:36,276]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:59:40,965]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:59:41,866]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:59:46,041]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:59:46,191]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:59:50,476]\u001b[0m Trial 450 finished with value: 5.134420614582756 and parameters: {'n_hidden': 4, 'learning_rate': 0.018934764868350093, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.106207192895434, 'dropout_rate_Layer_2': 0.07730534757055696, 'dropout_rate_Layer_3': 0.30165885768414896, 'dropout_rate_Layer_4': 0.3166086247216377, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.500843514968961e-05, 'l1_Layer_2': 0.003731361973377356, 'l1_Layer_3': 0.00012064361061499518, 'l1_Layer_4': 6.492750372299016e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 105, 'n_units_Layer_3': 255, 'n_units_Layer_4': 155}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 18.03% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.56 | sMAPE for Test Set is: 22.93% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:59:53,547]\u001b[0m Trial 464 finished with value: 5.181207154339365 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008252057347555859, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02094227394690716, 'dropout_rate_Layer_2': 0.30442777383296465, 'dropout_rate_Layer_3': 0.3140760629989523, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0001943018950436839, 'l1_Layer_2': 0.0001188250310016331, 'l1_Layer_3': 2.2392176797888384e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 85, 'n_units_Layer_3': 290}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 18.11% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.80 | sMAPE for Test Set is: 28.37% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 17:59:56,308]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 17:59:56,385]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:00:10,927]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:00:16,465]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:00:20,510]\u001b[0m Trial 472 finished with value: 5.155871357766277 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008637081290752771, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019055223939387227, 'dropout_rate_Layer_2': 0.3093897993969405, 'dropout_rate_Layer_3': 0.31543130116470025, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00015079030139758683, 'l1_Layer_2': 0.00013320564424604663, 'l1_Layer_3': 1.688003590742837e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 85, 'n_units_Layer_3': 290}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 18.04% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.63 | sMAPE for Test Set is: 28.07% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:00:23,673]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:00:27,632]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:00:30,771]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:00:31,491]\u001b[0m Trial 475 finished with value: 5.081313861607327 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009275497314030813, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012311251426272039, 'dropout_rate_Layer_2': 0.3458504290186772, 'dropout_rate_Layer_3': 0.3797673203496063, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0008554871044516353, 'l1_Layer_2': 0.00010117498897820828, 'l1_Layer_3': 1.9329196049741448e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 80, 'n_units_Layer_3': 290}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 17.85% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.75 | sMAPE for Test Set is: 28.25% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:00:36,296]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:00:41,396]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:00:47,767]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:00:53,784]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:00:57,125]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:00:57,561]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:00:59,687]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:04,126]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:07,254]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:09,810]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:10,361]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:14,700]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:15,479]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:16,437]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:18,634]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:22,289]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:24,511]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:25,457]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:32,482]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:33,036]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:34,313]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:37,504]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:40,596]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:41,383]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:45,867]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:48,908]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:49,461]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:50,049]\u001b[0m Trial 491 finished with value: 4.9713487453866945 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011794298962488402, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3953169676141367, 'dropout_rate_Layer_2': 0.35399379564155475, 'dropout_rate_Layer_3': 0.3841799977761031, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.001238073041465287, 'l1_Layer_2': 1.52623253091821e-05, 'l1_Layer_3': 0.0018152707144811452, 'n_units_Layer_1': 300, 'n_units_Layer_2': 75, 'n_units_Layer_3': 245}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:50,151]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 17.43% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.66 | sMAPE for Test Set is: 25.56% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:01:55,351]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:01:57,515]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:02:00,026]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:02:03,428]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:02:04,657]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:02:09,623]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:02:11,472]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:02:16,516]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:02:21,609]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:02:24,883]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:02:29,721]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:02:32,736]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:02:43,436]\u001b[0m Trial 522 finished with value: 5.283513905677938 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023448729860827073, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02686286597400743, 'dropout_rate_Layer_2': 0.082259244813396, 'dropout_rate_Layer_3': 0.35094065200596025, 'dropout_rate_Layer_4': 0.3973330047142416, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003097013525111034, 'l1_Layer_2': 0.015783345872100178, 'l1_Layer_3': 3.600894058329326e-05, 'l1_Layer_4': 0.0002706995012407535, 'n_units_Layer_1': 265, 'n_units_Layer_2': 55, 'n_units_Layer_3': 165, 'n_units_Layer_4': 205}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 18.43% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.27 | sMAPE for Test Set is: 27.07% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:02:50,768]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:02:53,264]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:02:55,256]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:02:55,389]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:02:59,749]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:03:02,795]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:03:07,713]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:03:08,075]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:03:08,158]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:03:08,502]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:03:16,330]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:03:16,549]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:03:16,926]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:03:22,062]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:03:26,112]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:03:26,690]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:03:33,777]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:03:37,759]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:03:40,800]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:03:48,667]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:03:54,017]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:03:56,088]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:04:01,792]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:04:04,772]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:04:37,678]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:04:40,107]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:04:52,341]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:04:57,556]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:04:59,605]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:05:04,596]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:05:04,699]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:05:12,606]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:05:18,535]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:05:22,588]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:05:31,138]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:05:35,013]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:05:40,651]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:05:51,575]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:05:57,905]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:06:03,212]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:06:03,761]\u001b[0m Trial 547 finished with value: 5.134081658224265 and parameters: {'n_hidden': 4, 'learning_rate': 0.009115661394431691, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13913771411976025, 'dropout_rate_Layer_2': 0.07256509751130208, 'dropout_rate_Layer_3': 0.194475493149585, 'dropout_rate_Layer_4': 0.32888245121793286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.421770776826916e-05, 'l1_Layer_2': 0.0027822342825072274, 'l1_Layer_3': 6.58893481504887e-05, 'l1_Layer_4': 3.6935890254017794e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 70, 'n_units_Layer_3': 295, 'n_units_Layer_4': 160}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 17.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.47 | sMAPE for Test Set is: 22.92% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:06:08,730]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:06:09,530]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:06:10,837]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:06:12,650]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:06:15,132]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:06:17,961]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:06:28,564]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:06:30,732]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:06:35,195]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:06:39,428]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:06:47,012]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:06:51,495]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:06:57,459]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:02,260]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:04,404]\u001b[0m Trial 556 finished with value: 5.281090435129305 and parameters: {'n_hidden': 4, 'learning_rate': 0.007045357714084099, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1872810077244629, 'dropout_rate_Layer_2': 0.04882228929246535, 'dropout_rate_Layer_3': 0.16438072582053156, 'dropout_rate_Layer_4': 0.28500639750095824, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0012484149798645833, 'l1_Layer_2': 0.0036038061556529924, 'l1_Layer_3': 3.902665340169244e-05, 'l1_Layer_4': 6.650208787573218e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 220, 'n_units_Layer_3': 285, 'n_units_Layer_4': 145}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 18.41% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.59 | sMAPE for Test Set is: 22.36% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:07:08,412]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:10,553]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:12,870]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:19,366]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:22,388]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:22,819]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:23,176]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:29,582]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:31,083]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:34,339]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:38,642]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:42,031]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:42,636]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:47,418]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:51,953]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:52,381]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:56,985]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:58,863]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:07:58,929]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:08:00,086]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:08:04,155]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:08:08,745]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:08:09,535]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:08:15,947]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:08:16,363]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:08:16,568]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:08:23,934]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:08:26,772]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:08:33,315]\u001b[0m Trial 593 finished with value: 5.136176974775627 and parameters: {'n_hidden': 3, 'learning_rate': 0.010516262055562931, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2731902482064646, 'dropout_rate_Layer_2': 0.20912895989990382, 'dropout_rate_Layer_3': 0.1137961032558367, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000260207601184644, 'l1_Layer_2': 0.0018458648553064593, 'l1_Layer_3': 9.207883196507736e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 65, 'n_units_Layer_3': 140}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 17.78% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.65 | sMAPE for Test Set is: 25.68% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:08:37,794]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:08:39,410]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:08:43,217]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:08:50,688]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:08:51,445]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:08:55,373]\u001b[0m Trial 609 finished with value: 5.255743411744995 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012719056369560609, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13149269500013155, 'dropout_rate_Layer_2': 0.32768585798989047, 'dropout_rate_Layer_3': 0.3983929624369985, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 7.333024073901324e-05, 'l1_Layer_2': 3.6390436333829035e-05, 'l1_Layer_3': 6.501838027935104e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 110, 'n_units_Layer_3': 300}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 18.42% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.47 | sMAPE for Test Set is: 30.30% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:08:57,142]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:09:00,392]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:09:00,536]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:09:01,102]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:09:07,045]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:09:09,153]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:09:13,489]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:09:15,927]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:09:21,556]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:09:30,016]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:09:33,933]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:09:45,375]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:09:58,544]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:01,604]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:04,968]\u001b[0m Trial 624 finished with value: 5.019326684057602 and parameters: {'n_hidden': 3, 'learning_rate': 0.010353188202097739, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31769275929055985, 'dropout_rate_Layer_2': 0.21281284747818727, 'dropout_rate_Layer_3': 0.07323583575175936, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005269595499765794, 'l1_Layer_2': 0.00011979836177550823, 'l1_Layer_3': 2.628987070160926e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 55, 'n_units_Layer_3': 110}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 17.67% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.02 | sMAPE for Test Set is: 24.44% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:10:06,857]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:08,787]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:10,980]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:14,461]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:15,822]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:17,119]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:18,244]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:18,553]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:24,842]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:25,899]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:29,220]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:33,367]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:36,577]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:39,802]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:43,446]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:46,833]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:51,036]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:53,701]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:10:55,966]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:11:02,471]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:11:05,956]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:11:11,880]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:11:12,171]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:11:23,567]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:11:31,641]\u001b[0m Trial 650 finished with value: 5.1999762509899226 and parameters: {'n_hidden': 3, 'learning_rate': 0.0053892503165772964, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09877541255476163, 'dropout_rate_Layer_2': 0.33734847372787247, 'dropout_rate_Layer_3': 0.19613404910141696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00010339336602224736, 'l1_Layer_2': 0.0011820726575879452, 'l1_Layer_3': 5.1109894479568235e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 95, 'n_units_Layer_3': 290}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 18.36% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 12.32 | sMAPE for Test Set is: 29.89% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:11:35,997]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:11:38,276]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:11:42,454]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:11:45,934]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:11:51,794]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:11:57,526]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:12:03,484]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:12:08,428]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:12:17,809]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:12:22,851]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:12:28,603]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:12:29,188]\u001b[0m Trial 655 finished with value: 5.032956099212726 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006697043362673868, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08766615850586046, 'dropout_rate_Layer_2': 0.28411968721070086, 'dropout_rate_Layer_3': 0.3756866851187826, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.001161488422312231, 'l1_Layer_2': 3.4546228012323924e-05, 'l1_Layer_3': 0.0022737123947567718, 'n_units_Layer_1': 300, 'n_units_Layer_2': 55, 'n_units_Layer_3': 290}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 17.57% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.08 | sMAPE for Test Set is: 26.50% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:12:32,712]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:12:41,746]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:12:42,195]\u001b[0m Trial 643 finished with value: 5.182240329277138 and parameters: {'n_hidden': 3, 'learning_rate': 0.004960430951362731, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09772599436197617, 'dropout_rate_Layer_2': 0.37128276588558506, 'dropout_rate_Layer_3': 0.15048423981131281, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00010960486083116854, 'l1_Layer_2': 0.002863096285468211, 'l1_Layer_3': 2.3195960362875474e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 95, 'n_units_Layer_3': 290}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 18.22% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.00 | sMAPE for Test Set is: 26.47% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:12:44,846]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:12:50,788]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:12:51,643]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:12:56,511]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:13:00,221]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:13:00,411]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:13:09,288]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:13:10,842]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:13:17,116]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:13:25,766]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:13:28,350]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:13:36,026]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:13:39,700]\u001b[0m Trial 683 finished with value: 5.687367983073052 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013910285552498104, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05318606653264205, 'dropout_rate_Layer_2': 0.3541660292134161, 'dropout_rate_Layer_3': 0.32429064967472965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001098008769636989, 'l1_Layer_2': 2.9033506535048052e-05, 'l1_Layer_3': 0.0038284202721466814, 'n_units_Layer_1': 280, 'n_units_Layer_2': 50, 'n_units_Layer_3': 275}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 20.02% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 7.69 | sMAPE for Test Set is: 19.08% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:13:43,555]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:13:48,833]\u001b[0m Trial 675 finished with value: 5.055650093753023 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006606292704391181, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08509547181222873, 'dropout_rate_Layer_2': 0.2860483670689911, 'dropout_rate_Layer_3': 0.37955134532993495, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0010802040745638399, 'l1_Layer_2': 2.6439172311414322e-05, 'l1_Layer_3': 0.002020821539890223, 'n_units_Layer_1': 285, 'n_units_Layer_2': 60, 'n_units_Layer_3': 275}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 17.83% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.28 | sMAPE for Test Set is: 27.22% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:13:53,986]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:13:55,991]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:14:02,608]\u001b[0m Trial 679 finished with value: 5.019391084075307 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006715628280750503, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08924869511813224, 'dropout_rate_Layer_2': 0.27973764791336564, 'dropout_rate_Layer_3': 0.3807157427295572, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.001023936427130005, 'l1_Layer_2': 1.8733682053664447e-05, 'l1_Layer_3': 0.0008525694568008992, 'n_units_Layer_1': 290, 'n_units_Layer_2': 55, 'n_units_Layer_3': 275}. Best is trial 202 with value: 4.933620325035002.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:14:02,764]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 17.58% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.44 | sMAPE for Test Set is: 27.45% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:14:07,991]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:14:08,629]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:14:12,678]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:14:18,985]\u001b[0m Trial 686 finished with value: 4.9285596877691695 and parameters: {'n_hidden': 3, 'learning_rate': 0.001688250195873208, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1088124951402904, 'dropout_rate_Layer_2': 0.08634120851863097, 'dropout_rate_Layer_3': 0.342225354926181, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00036656573597517724, 'l1_Layer_2': 0.0007434974570303204, 'l1_Layer_3': 6.89833261287935e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130}. Best is trial 686 with value: 4.9285596877691695.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 17.32% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.42 | sMAPE for Test Set is: 22.45% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:14:19,698]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:14:24,125]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:14:28,709]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:14:30,348]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:14:34,353]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:14:36,348]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:14:39,350]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:14:43,140]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:14:43,717]\u001b[0m Trial 696 finished with value: 5.070254712357868 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029156806308322978, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.246792060232034, 'dropout_rate_Layer_2': 0.08836782107353511, 'dropout_rate_Layer_3': 0.3913702658019713, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004587041941998781, 'l1_Layer_2': 0.0004756941461693193, 'l1_Layer_3': 1.3830357179633143e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130}. Best is trial 686 with value: 4.9285596877691695.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 17.61% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.05 | sMAPE for Test Set is: 19.48% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:14:48,725]\u001b[0m Trial 689 finished with value: 5.210944551368222 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031395856645126076, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15706979218742276, 'dropout_rate_Layer_2': 0.3693436426570542, 'dropout_rate_Layer_3': 0.3166334195399769, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0028560756500085158, 'l1_Layer_2': 0.00037534472138694335, 'l1_Layer_3': 0.0006924382865930562, 'n_units_Layer_1': 285, 'n_units_Layer_2': 165, 'n_units_Layer_3': 300}. Best is trial 686 with value: 4.9285596877691695.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 18.37% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.53 | sMAPE for Test Set is: 25.33% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:14:49,099]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:14:58,870]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:15:01,237]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:15:07,084]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:15:07,844]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:15:13,719]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:15:16,841]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:15:23,794]\u001b[0m Trial 704 finished with value: 4.845786633745696 and parameters: {'n_hidden': 3, 'learning_rate': 0.002796956122975357, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24319104797517024, 'dropout_rate_Layer_2': 0.08467917088666278, 'dropout_rate_Layer_3': 0.01026045618330218, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00045471652587616616, 'l1_Layer_2': 0.0005987298895774973, 'l1_Layer_3': 1.5596835984961263e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 150}. Best is trial 704 with value: 4.845786633745696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 16.94% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.00 | sMAPE for Test Set is: 19.35% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:15:26,649]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:15:28,330]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:15:33,690]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:15:41,723]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:15:51,251]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:15:55,931]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:15:56,580]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:16:03,139]\u001b[0m Trial 702 finished with value: 4.98661717440274 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009534353043536919, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14493392416039924, 'dropout_rate_Layer_2': 0.27350915824936806, 'dropout_rate_Layer_3': 0.0856751267000282, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0031125785037807462, 'l1_Layer_2': 0.0013484958819438729, 'l1_Layer_3': 6.93131304133876e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 100, 'n_units_Layer_3': 270}. Best is trial 704 with value: 4.845786633745696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 17.50% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 16.33% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:16:07,042]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:16:07,729]\u001b[0m Trial 719 finished with value: 5.959050806598735 and parameters: {'n_hidden': 3, 'learning_rate': 0.026416602474681337, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07758207316054011, 'dropout_rate_Layer_2': 0.2010517844784488, 'dropout_rate_Layer_3': 0.3408800221022483, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0017681557245780254, 'l1_Layer_2': 1.3281814089647498e-05, 'l1_Layer_3': 0.0008037288196753969, 'n_units_Layer_1': 285, 'n_units_Layer_2': 60, 'n_units_Layer_3': 270}. Best is trial 704 with value: 4.845786633745696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 20.45% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 13.69 | sMAPE for Test Set is: 33.10% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:16:09,827]\u001b[0m Trial 712 finished with value: 4.998427658328576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007047249209264357, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.061264360288232504, 'dropout_rate_Layer_2': 0.24940427418968558, 'dropout_rate_Layer_3': 0.3371308232328568, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0016288345663432356, 'l1_Layer_2': 2.1626483548070457e-05, 'l1_Layer_3': 0.0008562698348774156, 'n_units_Layer_1': 290, 'n_units_Layer_2': 60, 'n_units_Layer_3': 270}. Best is trial 704 with value: 4.845786633745696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 17.45% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.64 | sMAPE for Test Set is: 27.98% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:16:15,104]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:16:17,160]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:16:17,654]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:16:21,832]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:16:22,262]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:16:26,710]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:16:27,097]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:16:27,649]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:16:32,418]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:16:35,296]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:16:39,034]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:16:44,038]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:16:44,138]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:16:57,417]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:16:59,625]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:17:02,582]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:17:11,333]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:17:11,683]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:17:17,821]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:17:18,232]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:17:27,495]\u001b[0m Trial 732 finished with value: 4.8328887404658225 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005313813358911358, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21451540218723697, 'dropout_rate_Layer_2': 0.09346626130412135, 'dropout_rate_Layer_3': 0.009684463432932264, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00035831502464873927, 'l1_Layer_2': 0.0006572377194954671, 'l1_Layer_3': 1.602865102154672e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 65, 'n_units_Layer_3': 150}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 17.08% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.06 | sMAPE for Test Set is: 17.56% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:17:32,008]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:17:32,635]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:17:39,803]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:17:52,267]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:17:52,816]\u001b[0m Trial 743 finished with value: 5.15230046118549 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005696307608232856, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06846360321218649, 'dropout_rate_Layer_2': 0.2691455849814928, 'dropout_rate_Layer_3': 0.34953850613321097, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.001993316359252841, 'l1_Layer_2': 1.7062154383865013e-05, 'l1_Layer_3': 0.0005002129946679859, 'n_units_Layer_1': 275, 'n_units_Layer_2': 95, 'n_units_Layer_3': 275}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 18.14% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.75 | sMAPE for Test Set is: 28.27% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:17:59,525]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:18:04,781]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:18:08,601]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:18:11,491]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:18:12,122]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:18:37,765]\u001b[0m Trial 746 finished with value: 4.8495419450254085 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005549163683759286, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06352936899701572, 'dropout_rate_Layer_2': 0.08071332299167092, 'dropout_rate_Layer_3': 0.0031177200061308485, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026725562115342117, 'l1_Layer_2': 0.0004923843686519444, 'l1_Layer_3': 1.3310086776935252e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 55, 'n_units_Layer_3': 160}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 17.17% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.56 | sMAPE for Test Set is: 18.61% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:18:53,874]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:19:01,862]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:19:08,283]\u001b[0m Trial 753 finished with value: 5.1705527001397344 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010816556394473132, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19180970424282265, 'dropout_rate_Layer_2': 0.09230278487648061, 'dropout_rate_Layer_3': 0.11578037498773602, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001317764465556668, 'l1_Layer_2': 0.0022735103362817935, 'l1_Layer_3': 0.000696172319020766, 'n_units_Layer_1': 105, 'n_units_Layer_2': 160, 'n_units_Layer_3': 285}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.17 | sMAPE for Validation Set is: 18.05% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.86 | sMAPE for Test Set is: 26.07% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:19:17,652]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:19:46,320]\u001b[0m Trial 757 finished with value: 5.139946487579336 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009996961294456432, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1766294053257943, 'dropout_rate_Layer_2': 0.10244881503907663, 'dropout_rate_Layer_3': 0.2870770409757893, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020001674015151553, 'l1_Layer_2': 0.00031984574687959905, 'l1_Layer_3': 0.000697534976291348, 'n_units_Layer_1': 100, 'n_units_Layer_2': 165, 'n_units_Layer_3': 245}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 18.03% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.30 | sMAPE for Test Set is: 29.60% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:19:56,695]\u001b[0m Trial 754 finished with value: 4.880629114421498 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009882484553160491, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19481594352791828, 'dropout_rate_Layer_2': 0.08191483026508835, 'dropout_rate_Layer_3': 0.2855522315393153, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00131461646447881, 'l1_Layer_2': 0.0021784466838249647, 'l1_Layer_3': 1.3523512852116535e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 165, 'n_units_Layer_3': 245}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 17.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.96 | sMAPE for Test Set is: 23.73% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:20:02,465]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:20:10,003]\u001b[0m Trial 758 finished with value: 4.866464682898487 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005564528016381125, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2195716448091458, 'dropout_rate_Layer_2': 0.06876607404140378, 'dropout_rate_Layer_3': 0.022325289320483374, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000271863793877365, 'l1_Layer_2': 0.0004903395221710367, 'l1_Layer_3': 1.2908841896416425e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 55, 'n_units_Layer_3': 160}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 17.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.01 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:20:21,712]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:20:33,358]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:20:38,562]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:20:44,235]\u001b[0m Trial 761 finished with value: 4.851761110668631 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006723830268979182, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21756976456828359, 'dropout_rate_Layer_2': 0.10257177798225847, 'dropout_rate_Layer_3': 0.0021063322860304743, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029005336427712157, 'l1_Layer_2': 0.0005012135702418029, 'l1_Layer_3': 1.3454241959469557e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 55, 'n_units_Layer_3': 160}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.32 | sMAPE for Test Set is: 18.01% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:20:46,786]\u001b[0m Trial 763 finished with value: 5.003634413537644 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011391901656393495, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20721491701686917, 'dropout_rate_Layer_2': 0.09926883002261817, 'dropout_rate_Layer_3': 0.1217216026239704, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014364397150731816, 'l1_Layer_2': 0.0002451126751437185, 'l1_Layer_3': 0.0007949219948152246, 'n_units_Layer_1': 110, 'n_units_Layer_2': 155, 'n_units_Layer_3': 235}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 17.68% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.60 | sMAPE for Test Set is: 27.89% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:20:58,533]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:21:14,079]\u001b[0m Trial 767 finished with value: 5.156458610992089 and parameters: {'n_hidden': 3, 'learning_rate': 0.001004188395016512, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18821614179363896, 'dropout_rate_Layer_2': 0.11392589478810113, 'dropout_rate_Layer_3': 0.2863027675833492, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010077866486017686, 'l1_Layer_2': 0.00029465402120701595, 'l1_Layer_3': 1.9576419230404203e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 165, 'n_units_Layer_3': 235}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 18.01% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.98 | sMAPE for Test Set is: 28.75% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:21:26,445]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:21:36,872]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:21:37,609]\u001b[0m Trial 769 finished with value: 5.167006661067519 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011769920386215953, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21254748829126338, 'dropout_rate_Layer_2': 0.10370264675072566, 'dropout_rate_Layer_3': 0.1238427473204761, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001428804994735401, 'l1_Layer_2': 0.000221142635447739, 'l1_Layer_3': 0.0010262788214332513, 'n_units_Layer_1': 105, 'n_units_Layer_2': 155, 'n_units_Layer_3': 245}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.17 | sMAPE for Validation Set is: 18.15% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.49 | sMAPE for Test Set is: 30.06% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:22:08,182]\u001b[0m Trial 768 finished with value: 4.843632400375783 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005252972940138152, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20538092066339644, 'dropout_rate_Layer_2': 0.08688419492827906, 'dropout_rate_Layer_3': 0.0013702760007148554, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029130187077929784, 'l1_Layer_2': 0.0005001793570097797, 'l1_Layer_3': 1.271689761641644e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 55, 'n_units_Layer_3': 165}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 17.01% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.01 | sMAPE for Test Set is: 17.37% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:22:34,213]\u001b[0m Trial 773 finished with value: 5.057078839940621 and parameters: {'n_hidden': 3, 'learning_rate': 0.001235525126851824, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21401576012909923, 'dropout_rate_Layer_2': 0.1108159073183265, 'dropout_rate_Layer_3': 0.28536206631379923, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001095555411113947, 'l1_Layer_2': 0.0002156199708288356, 'l1_Layer_3': 0.0010653415877255243, 'n_units_Layer_1': 95, 'n_units_Layer_2': 165, 'n_units_Layer_3': 225}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 17.58% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.94 | sMAPE for Test Set is: 28.39% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:22:36,725]\u001b[0m Trial 774 finished with value: 5.159885058291256 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012294700721434766, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20031359594639594, 'dropout_rate_Layer_2': 0.10924948448143174, 'dropout_rate_Layer_3': 0.12415976112768004, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010060818629222741, 'l1_Layer_2': 0.00022984702354077665, 'l1_Layer_3': 0.0012837680909838088, 'n_units_Layer_1': 90, 'n_units_Layer_2': 165, 'n_units_Layer_3': 225}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 18.00% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.50 | sMAPE for Test Set is: 29.94% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:22:54,170]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:22:59,777]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:23:06,357]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:23:14,408]\u001b[0m Trial 772 finished with value: 5.001442393876988 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031168140202325507, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10190350158420795, 'dropout_rate_Layer_2': 0.10883959247117264, 'dropout_rate_Layer_3': 0.15952048530310087, 'dropout_rate_Layer_4': 0.1333732004906424, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013226318701637426, 'l1_Layer_2': 0.004158987724089195, 'l1_Layer_3': 7.124584018755679e-05, 'l1_Layer_4': 1.9522683878948145e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 85, 'n_units_Layer_3': 255, 'n_units_Layer_4': 270}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 17.63% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.79 | sMAPE for Test Set is: 26.04% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:23:26,232]\u001b[0m Trial 777 finished with value: 4.853725915686913 and parameters: {'n_hidden': 3, 'learning_rate': 0.000666378901393118, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21149377335897931, 'dropout_rate_Layer_2': 0.10233396522150404, 'dropout_rate_Layer_3': 0.009652142289260262, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019676462863037675, 'l1_Layer_2': 0.0004438447193788182, 'l1_Layer_3': 1.2877488742313937e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 50, 'n_units_Layer_3': 155}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.85 | sMAPE for Validation Set is: 17.13% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.32 | sMAPE for Test Set is: 18.03% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:23:34,891]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:23:40,739]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:23:49,807]\u001b[0m Trial 780 finished with value: 5.058372822371303 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012514682099882884, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2069714322771974, 'dropout_rate_Layer_2': 0.10544860508471736, 'dropout_rate_Layer_3': 0.13523371130973355, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011548213994867077, 'l1_Layer_2': 0.00018620461878740384, 'l1_Layer_3': 0.0013583671652031104, 'n_units_Layer_1': 95, 'n_units_Layer_2': 165, 'n_units_Layer_3': 225}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 17.77% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.29 | sMAPE for Test Set is: 29.62% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:23:50,002]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:24:08,398]\u001b[0m Trial 781 finished with value: 4.873256324984245 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006737842138948087, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21243533441085957, 'dropout_rate_Layer_2': 0.06499315950399598, 'dropout_rate_Layer_3': 0.008134767582896999, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021845636503072744, 'l1_Layer_2': 0.00046254736637232544, 'l1_Layer_3': 1.3317304727476393e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 50, 'n_units_Layer_3': 155}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 17.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.45 | sMAPE for Test Set is: 18.29% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:24:14,614]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:24:19,048]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:24:19,359]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:24:31,288]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:24:46,278]\u001b[0m Trial 784 finished with value: 5.153194378328335 and parameters: {'n_hidden': 3, 'learning_rate': 0.001213311746802493, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20713684324347398, 'dropout_rate_Layer_2': 0.10472249954966746, 'dropout_rate_Layer_3': 0.27521001806035633, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.102780732613552e-05, 'l1_Layer_2': 0.00020954780670172116, 'l1_Layer_3': 0.001412754059262026, 'n_units_Layer_1': 95, 'n_units_Layer_2': 155, 'n_units_Layer_3': 235}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 17.93% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.18 | sMAPE for Test Set is: 29.13% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:24:56,395]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:25:00,631]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:25:05,918]\u001b[0m Trial 789 finished with value: 5.057962427545527 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011419371191079995, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22275737529192594, 'dropout_rate_Layer_2': 0.11649924691666139, 'dropout_rate_Layer_3': 0.1368428273382957, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.479430716124629e-05, 'l1_Layer_2': 0.00022624530720530313, 'l1_Layer_3': 0.0012114998884296337, 'n_units_Layer_1': 90, 'n_units_Layer_2': 155, 'n_units_Layer_3': 210}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 17.74% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.14 | sMAPE for Test Set is: 29.09% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:25:12,764]\u001b[0m Trial 788 finished with value: 4.862308312784084 and parameters: {'n_hidden': 3, 'learning_rate': 0.000510527329977706, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21090627954258423, 'dropout_rate_Layer_2': 0.03822195630119632, 'dropout_rate_Layer_3': 0.0070869299860877605, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015729874237317064, 'l1_Layer_2': 0.00039446340013390724, 'l1_Layer_3': 1.0066475817835955e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 55, 'n_units_Layer_3': 155}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 17.12% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.22 | sMAPE for Test Set is: 17.85% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:25:13,080]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:25:21,176]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:25:24,675]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:25:34,603]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:25:44,444]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:25:58,850]\u001b[0m Trial 794 finished with value: 5.12630584543956 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013229504051985959, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21917046217117694, 'dropout_rate_Layer_2': 0.10167051489674467, 'dropout_rate_Layer_3': 0.12948640790342933, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.5100110271411826e-05, 'l1_Layer_2': 0.00020003123694867198, 'l1_Layer_3': 0.0024774857845711287, 'n_units_Layer_1': 95, 'n_units_Layer_2': 150, 'n_units_Layer_3': 235}. Best is trial 732 with value: 4.8328887404658225.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 17.89% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.22 | sMAPE for Test Set is: 29.35% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:26:03,414]\u001b[0m Trial 800 finished with value: 4.820645083241179 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006966617770322904, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21547769504393127, 'dropout_rate_Layer_2': 0.06521549180596752, 'dropout_rate_Layer_3': 0.006071196421642109, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017284090462764762, 'l1_Layer_2': 0.0003663078947340348, 'l1_Layer_3': 1.1720076074549198e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 55, 'n_units_Layer_3': 165}. Best is trial 800 with value: 4.820645083241179.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 16.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.54 | sMAPE for Test Set is: 16.46% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:26:06,443]\u001b[0m Trial 795 finished with value: 5.14702021472836 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014028312694407156, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21471965940116905, 'dropout_rate_Layer_2': 0.10367493312013626, 'dropout_rate_Layer_3': 0.13422896138204873, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.212214771402129e-05, 'l1_Layer_2': 0.00018105460092402584, 'l1_Layer_3': 0.0017140106390754685, 'n_units_Layer_1': 95, 'n_units_Layer_2': 155, 'n_units_Layer_3': 225}. Best is trial 800 with value: 4.820645083241179.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 17.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.64 | sMAPE for Test Set is: 30.26% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:26:11,019]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:26:16,348]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:26:18,341]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:26:23,350]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:26:23,708]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:26:32,956]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:26:46,761]\u001b[0m Trial 803 finished with value: 4.805088354933356 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007430909291962174, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20339258178469127, 'dropout_rate_Layer_2': 0.06538364636062988, 'dropout_rate_Layer_3': 0.0024429934700693438, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016343661620718455, 'l1_Layer_2': 0.0002820961160015625, 'l1_Layer_3': 1.1760863604305946e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 55, 'n_units_Layer_3': 165}. Best is trial 803 with value: 4.805088354933356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.81 | sMAPE for Validation Set is: 16.82% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 16.81% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:26:57,677]\u001b[0m Trial 805 finished with value: 5.082176413129273 and parameters: {'n_hidden': 3, 'learning_rate': 0.00146964557615157, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19756659199159424, 'dropout_rate_Layer_2': 0.09220545779722332, 'dropout_rate_Layer_3': 0.13605791743321977, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9795300237258163e-05, 'l1_Layer_2': 0.0002235927940220253, 'l1_Layer_3': 0.001324439529321731, 'n_units_Layer_1': 95, 'n_units_Layer_2': 150, 'n_units_Layer_3': 235}. Best is trial 803 with value: 4.805088354933356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 17.80% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.00 | sMAPE for Test Set is: 28.78% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:27:04,159]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:27:09,623]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:27:11,183]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:27:21,487]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:27:31,739]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:27:32,012]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:27:32,035]\u001b[0m Trial 810 finished with value: 4.780159944991826 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007821999968787905, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20363834991619142, 'dropout_rate_Layer_2': 0.06547886954838007, 'dropout_rate_Layer_3': 0.025354527737024235, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001818391626445409, 'l1_Layer_2': 0.00025173796861558453, 'l1_Layer_3': 1.010402898867266e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 55, 'n_units_Layer_3': 150}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.78 | sMAPE for Validation Set is: 16.89% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.58 | sMAPE for Test Set is: 18.48% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:27:42,383]\u001b[0m Trial 815 finished with value: 4.821859867231474 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007871013550664883, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20238604914784453, 'dropout_rate_Layer_2': 0.06490453300996119, 'dropout_rate_Layer_3': 0.02603165802947301, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001754556054820607, 'l1_Layer_2': 0.000271836162891674, 'l1_Layer_3': 1.1675417417734627e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 55, 'n_units_Layer_3': 160}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 16.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.98 | sMAPE for Test Set is: 17.19% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:27:44,059]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:27:56,283]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:27:56,834]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:28:02,428]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:28:08,775]\u001b[0m Trial 820 finished with value: 4.899522856067679 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008210483341805854, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20226625935293424, 'dropout_rate_Layer_2': 0.06610225860468996, 'dropout_rate_Layer_3': 0.028269116410319546, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017402893449863465, 'l1_Layer_2': 0.00027175159403594655, 'l1_Layer_3': 1.0555972225590954e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 55, 'n_units_Layer_3': 160}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 17.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 16.55% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:28:14,494]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:28:19,034]\u001b[0m Trial 825 finished with value: 7.747375052965329 and parameters: {'n_hidden': 3, 'learning_rate': 0.05960887239311406, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11136264722420271, 'dropout_rate_Layer_2': 0.29657806166644984, 'dropout_rate_Layer_3': 0.21275643448198295, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0005987686737786036, 'l1_Layer_2': 2.9680359275395147e-05, 'l1_Layer_3': 0.0017688805801144465, 'n_units_Layer_1': 290, 'n_units_Layer_2': 55, 'n_units_Layer_3': 260}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.75 | sMAPE for Validation Set is: 26.68% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 20.36 | sMAPE for Test Set is: 53.29% | rMAE for Test Set is: 1.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:28:22,854]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:28:29,794]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:28:40,027]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:28:43,801]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:28:47,375]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:29:00,879]\u001b[0m Trial 824 finished with value: 5.152502593010581 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009907640846831657, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21436743318548035, 'dropout_rate_Layer_2': 0.10251986421183587, 'dropout_rate_Layer_3': 0.14571055544460798, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.136782610384581e-05, 'l1_Layer_2': 0.00018460754896764255, 'l1_Layer_3': 0.000965245838977546, 'n_units_Layer_1': 95, 'n_units_Layer_2': 155, 'n_units_Layer_3': 210}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 18.01% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.63 | sMAPE for Test Set is: 30.28% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:29:12,133]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:29:25,996]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:29:31,967]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:29:40,956]\u001b[0m Trial 831 finished with value: 4.9684953569078365 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009456439079655598, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031747978913160356, 'dropout_rate_Layer_2': 0.2861076152858158, 'dropout_rate_Layer_3': 0.3997589709756732, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0009764888085008277, 'l1_Layer_2': 1.2152655072927253e-05, 'l1_Layer_3': 0.0010167749830992518, 'n_units_Layer_1': 265, 'n_units_Layer_2': 65, 'n_units_Layer_3': 285}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 17.43% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.31 | sMAPE for Test Set is: 27.04% | rMAE for Test Set is: 1.07\n",
      "MAE for Validation Set is: 5.17 | sMAPE for Validation Set is: 18.02% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 13.04 | sMAPE for Test Set is: 31.54% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:29:42,509]\u001b[0m Trial 833 finished with value: 5.171154517050785 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009972811625764187, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19721160540540997, 'dropout_rate_Layer_2': 0.12350411098346037, 'dropout_rate_Layer_3': 0.1260772849660785, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.664741893338099e-05, 'l1_Layer_2': 0.00014578217539134062, 'l1_Layer_3': 0.0017168851012420241, 'n_units_Layer_1': 80, 'n_units_Layer_2': 145, 'n_units_Layer_3': 235}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:29:52,069]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:29:55,860]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:29:56,328]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:30:03,695]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:30:08,708]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:30:27,905]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:30:30,480]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:30:39,864]\u001b[0m Trial 838 finished with value: 5.011531125180548 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009126236072472507, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.037890580191861936, 'dropout_rate_Layer_2': 0.33359307792293097, 'dropout_rate_Layer_3': 0.386672325979493, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.001287385148508271, 'l1_Layer_2': 1.1954482834411688e-05, 'l1_Layer_3': 0.0007620210022518546, 'n_units_Layer_1': 280, 'n_units_Layer_2': 80, 'n_units_Layer_3': 295}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 17.54% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.93 | sMAPE for Test Set is: 28.62% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:30:47,826]\u001b[0m Trial 843 finished with value: 5.031103169379178 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007693225299739649, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03623195880679484, 'dropout_rate_Layer_2': 0.27786761683920835, 'dropout_rate_Layer_3': 0.3867194666041852, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0013935620915225644, 'l1_Layer_2': 1.2252501067738893e-05, 'l1_Layer_3': 0.00039091389049842245, 'n_units_Layer_1': 280, 'n_units_Layer_2': 80, 'n_units_Layer_3': 295}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 17.71% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.56 | sMAPE for Test Set is: 27.88% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:30:54,963]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:30:58,284]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:31:06,692]\u001b[0m Trial 846 finished with value: 4.915819375764724 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008923262644034776, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20494765960812783, 'dropout_rate_Layer_2': 0.10613140237515596, 'dropout_rate_Layer_3': 0.014650108703930957, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022465733422912985, 'l1_Layer_2': 0.0003069477994274602, 'l1_Layer_3': 1.4125072618448175e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 165}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.81 | sMAPE for Test Set is: 16.83% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:31:09,052]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:31:21,208]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:31:24,454]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:31:28,362]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 16.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 16.99% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:31:30,336]\u001b[0m Trial 847 finished with value: 4.823467903838423 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008831158257564416, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2047029644383348, 'dropout_rate_Layer_2': 0.05258396559443618, 'dropout_rate_Layer_3': 0.015111924739878806, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002172150196480927, 'l1_Layer_2': 0.00029974106762430244, 'l1_Layer_3': 1.4207080708065371e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 50, 'n_units_Layer_3': 165}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:31:36,712]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:31:41,772]\u001b[0m Trial 849 finished with value: 4.816745188804258 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007277822483254735, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2062127438660085, 'dropout_rate_Layer_2': 0.053206513378012486, 'dropout_rate_Layer_3': 0.01523449985979969, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015913524098947555, 'l1_Layer_2': 0.00030687845149275216, 'l1_Layer_3': 1.4462202192719766e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 50, 'n_units_Layer_3': 165}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.82 | sMAPE for Validation Set is: 16.88% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.08 | sMAPE for Test Set is: 17.18% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:31:54,520]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:32:00,134]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:32:03,759]\u001b[0m Trial 850 finished with value: 5.101888973344416 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006318533207784309, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030984084302619952, 'dropout_rate_Layer_2': 0.32658461215590373, 'dropout_rate_Layer_3': 0.391237775514201, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.001414002758125305, 'l1_Layer_2': 1.0908900270461648e-05, 'l1_Layer_3': 0.0003916014506016669, 'n_units_Layer_1': 280, 'n_units_Layer_2': 65, 'n_units_Layer_3': 280}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 17.76% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.57 | sMAPE for Test Set is: 27.81% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:32:07,329]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:32:12,585]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:32:25,117]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:32:29,716]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:32:37,666]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:32:50,183]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:32:53,162]\u001b[0m Trial 865 finished with value: 8.11955176946615 and parameters: {'n_hidden': 3, 'learning_rate': 0.012826016058375902, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.055769256683914456, 'dropout_rate_Layer_2': 0.2881820023448592, 'dropout_rate_Layer_3': 0.38785262352849154, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.09732703547604994, 'l1_Layer_2': 1.31831964100777e-05, 'l1_Layer_3': 0.0008245725653945752, 'n_units_Layer_1': 265, 'n_units_Layer_2': 80, 'n_units_Layer_3': 295}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.12 | sMAPE for Validation Set is: 27.78% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 21.29 | sMAPE for Test Set is: 56.01% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:32:56,751]\u001b[0m Trial 854 finished with value: 5.120706620778008 and parameters: {'n_hidden': 3, 'learning_rate': 0.001039512012861485, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23053263120128734, 'dropout_rate_Layer_2': 0.1049558686218793, 'dropout_rate_Layer_3': 0.28438054093648296, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.406339275637593e-05, 'l1_Layer_2': 0.00022630525792416203, 'l1_Layer_3': 0.0026840799762081016, 'n_units_Layer_1': 100, 'n_units_Layer_2': 170, 'n_units_Layer_3': 240}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 17.83% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.13 | sMAPE for Test Set is: 29.01% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:33:03,137]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:33:12,243]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:33:19,700]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:33:22,471]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:33:26,468]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:33:30,586]\u001b[0m Trial 868 finished with value: 4.880802198674398 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008957872601549729, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20531511404633004, 'dropout_rate_Layer_2': 0.03746146713446108, 'dropout_rate_Layer_3': 0.009880998573104635, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022441486786024426, 'l1_Layer_2': 0.0004025411984667892, 'l1_Layer_3': 1.0124422062664901e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 50, 'n_units_Layer_3': 170}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 17.10% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.99 | sMAPE for Test Set is: 16.99% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:33:37,685]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:33:37,994]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:33:49,202]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:34:00,023]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:34:00,215]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:34:06,862]\u001b[0m Trial 871 finished with value: 4.862674746598002 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005018559523954064, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18791690733950858, 'dropout_rate_Layer_2': 0.036665009090126745, 'dropout_rate_Layer_3': 0.02209217113327324, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001734978323864574, 'l1_Layer_2': 0.00042142017731033383, 'l1_Layer_3': 1.0617508145427908e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 60, 'n_units_Layer_3': 170}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 17.04% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 16.65% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:34:11,139]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:34:16,894]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:34:22,141]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:34:26,273]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:34:32,043]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 17.30% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 16.86% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:34:33,717]\u001b[0m Trial 876 finished with value: 4.861342279475072 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005386183478838518, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17855605288390855, 'dropout_rate_Layer_2': 0.06603644452007301, 'dropout_rate_Layer_3': 0.022805129771537345, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001572127006932786, 'l1_Layer_2': 0.0004128906692314903, 'l1_Layer_3': 1.3823452579722584e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 55, 'n_units_Layer_3': 160}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:34:34,325]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:34:43,091]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:34:43,838]\u001b[0m Trial 882 finished with value: 4.883310132498404 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005160016748802602, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1837123091552925, 'dropout_rate_Layer_2': 0.0671163186731095, 'dropout_rate_Layer_3': 0.0222343612004325, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017385275301305767, 'l1_Layer_2': 0.000413814481323042, 'l1_Layer_3': 1.3574186220340608e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 55, 'n_units_Layer_3': 170}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 17.15% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.82 | sMAPE for Test Set is: 16.97% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:34:48,990]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:34:49,521]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:34:50,889]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:34:57,388]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:35:08,416]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:35:13,292]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:35:17,477]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:35:19,703]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:35:29,042]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:35:34,778]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:35:39,558]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:35:47,661]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:35:55,603]\u001b[0m Trial 885 finished with value: 5.046659684379896 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007681860990477488, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0437490912943011, 'dropout_rate_Layer_2': 0.258473732046635, 'dropout_rate_Layer_3': 0.3997410331812901, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.004051318242497952, 'l1_Layer_2': 1.985317781803056e-05, 'l1_Layer_3': 0.0007123715140652945, 'n_units_Layer_1': 300, 'n_units_Layer_2': 55, 'n_units_Layer_3': 270}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 17.68% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.58 | sMAPE for Test Set is: 27.89% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:35:57,906]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:36:10,319]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:36:17,382]\u001b[0m Trial 893 finished with value: 4.992055290389106 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007453679158729825, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.041775634536287215, 'dropout_rate_Layer_2': 0.2621076869693893, 'dropout_rate_Layer_3': 0.3978910160821878, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.001136430364161998, 'l1_Layer_2': 2.0095072958788604e-05, 'l1_Layer_3': 0.0003820088336555396, 'n_units_Layer_1': 295, 'n_units_Layer_2': 55, 'n_units_Layer_3': 270}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 17.45% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.92 | sMAPE for Test Set is: 28.60% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:36:22,452]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:36:59,833]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:37:13,318]\u001b[0m Trial 906 finished with value: 5.123535192123089 and parameters: {'n_hidden': 3, 'learning_rate': 0.001197562722633599, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1974573219913202, 'dropout_rate_Layer_2': 0.10912248005246182, 'dropout_rate_Layer_3': 0.12776550717268817, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.4561842711674635e-05, 'l1_Layer_2': 0.0002806747172238684, 'l1_Layer_3': 0.0016171099705999442, 'n_units_Layer_1': 110, 'n_units_Layer_2': 170, 'n_units_Layer_3': 230}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 17.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.89 | sMAPE for Test Set is: 30.79% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:37:14,439]\u001b[0m Trial 905 finished with value: 5.126005804524645 and parameters: {'n_hidden': 3, 'learning_rate': 0.000980289578868214, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22829679742685527, 'dropout_rate_Layer_2': 0.10910808776460718, 'dropout_rate_Layer_3': 0.13115218947542548, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.47429673175581e-05, 'l1_Layer_2': 0.0003261533844420293, 'l1_Layer_3': 0.0008060711740817693, 'n_units_Layer_1': 100, 'n_units_Layer_2': 150, 'n_units_Layer_3': 245}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 17.89% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.07 | sMAPE for Test Set is: 28.73% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:37:18,956]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:37:21,145]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:37:22,239]\u001b[0m Trial 902 finished with value: 4.855779110935258 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005428262618145819, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.194523251420563, 'dropout_rate_Layer_2': 0.05065590913282081, 'dropout_rate_Layer_3': 0.02388562279633837, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002862305460739686, 'l1_Layer_2': 0.000618598433103775, 'l1_Layer_3': 1.4263395151600426e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 55, 'n_units_Layer_3': 165}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 16.77% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 16.61% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:37:27,409]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:37:30,862]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:38:11,738]\u001b[0m Trial 911 finished with value: 4.860206696399223 and parameters: {'n_hidden': 3, 'learning_rate': 0.000552302781878663, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1963766994328451, 'dropout_rate_Layer_2': 0.049571645699500407, 'dropout_rate_Layer_3': 0.02614647655801366, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027173393369250056, 'l1_Layer_2': 0.0003658128329320997, 'l1_Layer_3': 1.515885235639019e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 60, 'n_units_Layer_3': 160}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 17.22% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.70 | sMAPE for Test Set is: 16.86% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:38:17,932]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:38:27,987]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:38:33,654]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:38:35,824]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:38:41,623]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:38:46,454]\u001b[0m Trial 910 finished with value: 4.985373782274805 and parameters: {'n_hidden': 3, 'learning_rate': 0.000917356306069047, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23974186439217668, 'dropout_rate_Layer_2': 0.12770600860891376, 'dropout_rate_Layer_3': 0.14049070823535573, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.2452759234478644e-05, 'l1_Layer_2': 0.0003171237213122251, 'l1_Layer_3': 0.0007620265507031784, 'n_units_Layer_1': 110, 'n_units_Layer_2': 175, 'n_units_Layer_3': 235}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 17.50% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.21 | sMAPE for Test Set is: 29.37% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:38:46,857]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:39:02,591]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:39:11,548]\u001b[0m Trial 919 finished with value: 4.866905440261633 and parameters: {'n_hidden': 3, 'learning_rate': 0.000500394423765475, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20127660302553363, 'dropout_rate_Layer_2': 0.04886573307111859, 'dropout_rate_Layer_3': 0.02769215433170542, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002245414660593519, 'l1_Layer_2': 0.00042003065389159506, 'l1_Layer_3': 1.784267352273867e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 65, 'n_units_Layer_3': 160}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 17.15% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 16.72% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:39:39,462]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:39:46,517]\u001b[0m Trial 923 finished with value: 5.071173177605679 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008498190699054652, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2198357198833371, 'dropout_rate_Layer_2': 0.13212363407391492, 'dropout_rate_Layer_3': 0.14760520725308732, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.701326473637167e-05, 'l1_Layer_2': 0.00013660029422535782, 'l1_Layer_3': 0.0007561290705197702, 'n_units_Layer_1': 110, 'n_units_Layer_2': 175, 'n_units_Layer_3': 230}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 17.67% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.21 | sMAPE for Test Set is: 29.27% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:39:59,128]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:40:03,637]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:40:10,580]\u001b[0m Trial 924 finished with value: 5.13576363672133 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013881330301920042, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24656313849366557, 'dropout_rate_Layer_2': 0.1288676092114278, 'dropout_rate_Layer_3': 0.1454563600988429, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.6675394452407575e-05, 'l1_Layer_2': 0.0001268212881711354, 'l1_Layer_3': 0.0009478561174201223, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 230}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 17.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.82 | sMAPE for Test Set is: 30.78% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:40:15,615]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:40:23,750]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:40:29,544]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:40:32,542]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:40:36,207]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:40:40,005]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:41:13,169]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:41:20,874]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:41:28,179]\u001b[0m Trial 935 finished with value: 4.957194117358583 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005037447943718161, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21594538757078224, 'dropout_rate_Layer_2': 0.04569311904424903, 'dropout_rate_Layer_3': 0.031036885549723822, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018152782413878124, 'l1_Layer_2': 0.00043951552054190496, 'l1_Layer_3': 1.725674968730781e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 65, 'n_units_Layer_3': 150}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 17.40% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 16.82% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:41:32,374]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:41:38,730]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:41:45,222]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:41:48,857]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:41:58,068]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:42:08,381]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:42:13,659]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:42:19,700]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:42:25,986]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:42:33,817]\u001b[0m Trial 942 finished with value: 4.983464534801034 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008869471328858962, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22296497639347335, 'dropout_rate_Layer_2': 0.12387626339249369, 'dropout_rate_Layer_3': 0.14010129653973555, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0475990822019855e-05, 'l1_Layer_2': 0.0003496546776841716, 'l1_Layer_3': 0.000626476118582595, 'n_units_Layer_1': 105, 'n_units_Layer_2': 165, 'n_units_Layer_3': 250}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 17.38% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.13 | sMAPE for Test Set is: 28.96% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:42:40,906]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:42:44,796]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:42:47,846]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:42:51,626]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:42:54,221]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:43:05,118]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:43:12,897]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:43:27,886]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:43:31,824]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:43:36,589]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:43:51,241]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:43:58,352]\u001b[0m Trial 952 finished with value: 5.020060370061443 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007415901101385093, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24022849191911488, 'dropout_rate_Layer_2': 0.12435586860194707, 'dropout_rate_Layer_3': 0.10675903271577522, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7598872865747238e-05, 'l1_Layer_2': 0.0004071952495438441, 'l1_Layer_3': 0.0005312941884960259, 'n_units_Layer_1': 115, 'n_units_Layer_2': 180, 'n_units_Layer_3': 255}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 17.55% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.77 | sMAPE for Test Set is: 28.07% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:44:01,552]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:44:06,576]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:44:06,930]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:44:13,619]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:44:15,808]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:44:21,262]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:44:24,733]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:44:29,151]\u001b[0m Trial 954 finished with value: 5.098779391641391 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010943799365736523, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09482378749528382, 'dropout_rate_Layer_2': 0.23161630892419444, 'dropout_rate_Layer_3': 0.38723251797556324, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0035666063343442415, 'l1_Layer_2': 1.6785011611998156e-05, 'l1_Layer_3': 0.0002126291946296868, 'n_units_Layer_1': 280, 'n_units_Layer_2': 75, 'n_units_Layer_3': 295}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 17.83% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.48 | sMAPE for Test Set is: 30.01% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:44:31,536]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:44:35,596]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:44:43,404]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:45:16,064]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:45:28,566]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:45:35,449]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:45:45,230]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:45:50,283]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:45:54,558]\u001b[0m Trial 971 finished with value: 5.019108876978747 and parameters: {'n_hidden': 3, 'learning_rate': 0.00115829231083138, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22222342314419355, 'dropout_rate_Layer_2': 0.1304814908400688, 'dropout_rate_Layer_3': 0.14000393499390065, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.290558067294269e-05, 'l1_Layer_2': 0.009440267231847413, 'l1_Layer_3': 8.530160645455169e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 150, 'n_units_Layer_3': 245}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 17.57% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.43 | sMAPE for Test Set is: 24.65% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:46:04,368]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:46:07,488]\u001b[0m Trial 964 finished with value: 4.94012243067655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009174409772726635, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25550841714838773, 'dropout_rate_Layer_2': 0.13055002692722417, 'dropout_rate_Layer_3': 0.10663649545235415, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.619887067013685e-05, 'l1_Layer_2': 0.0002635784043486124, 'l1_Layer_3': 0.0005489630872609463, 'n_units_Layer_1': 130, 'n_units_Layer_2': 170, 'n_units_Layer_3': 235}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 17.25% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.04 | sMAPE for Test Set is: 28.90% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:46:11,657]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:46:18,729]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:46:22,778]\u001b[0m Trial 975 finished with value: 4.799185135525199 and parameters: {'n_hidden': 3, 'learning_rate': 0.000530439845616789, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2106815445485325, 'dropout_rate_Layer_2': 0.057257614464054286, 'dropout_rate_Layer_3': 0.007622046404836668, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001581042101776666, 'l1_Layer_2': 0.0003402728820469481, 'l1_Layer_3': 1.53328900836628e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 55, 'n_units_Layer_3': 175}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 16.91% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 16.62% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:46:31,919]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:46:36,606]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:46:55,963]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:46:59,877]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:47:05,703]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:47:11,150]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:47:18,508]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:47:19,384]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:47:32,817]\u001b[0m Trial 977 finished with value: 4.9471425809873555 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009150549558243088, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3160794129460549, 'dropout_rate_Layer_2': 0.2932829489403964, 'dropout_rate_Layer_3': 0.368612611269781, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0070714353010724795, 'l1_Layer_2': 1.024704412173158e-05, 'l1_Layer_3': 0.0004460008474049286, 'n_units_Layer_1': 280, 'n_units_Layer_2': 100, 'n_units_Layer_3': 300}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 17.36% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.94 | sMAPE for Test Set is: 21.61% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:47:37,443]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:48:04,211]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:48:05,961]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:48:10,811]\u001b[0m Trial 981 finished with value: 5.009481112427552 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007168317257998301, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22041568262278569, 'dropout_rate_Layer_2': 0.12594409848349714, 'dropout_rate_Layer_3': 0.10726781213161435, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4911199527876043e-05, 'l1_Layer_2': 0.00033547856575488007, 'l1_Layer_3': 0.0005509509350251333, 'n_units_Layer_1': 110, 'n_units_Layer_2': 145, 'n_units_Layer_3': 245}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 17.48% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.94 | sMAPE for Test Set is: 28.51% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:48:12,474]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:48:25,558]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:48:29,412]\u001b[0m Trial 992 finished with value: 5.023125454175566 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008024783170313813, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2121788203816375, 'dropout_rate_Layer_2': 0.12560752222068458, 'dropout_rate_Layer_3': 0.08968274365556311, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9638887886062644e-05, 'l1_Layer_2': 0.00021334150553300552, 'l1_Layer_3': 0.0006978096920190995, 'n_units_Layer_1': 130, 'n_units_Layer_2': 150, 'n_units_Layer_3': 255}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 17.54% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.59 | sMAPE for Test Set is: 30.26% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:48:34,312]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:48:39,012]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:48:46,940]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:48:50,342]\u001b[0m Trial 993 finished with value: 4.91173860539854 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006038539244530514, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20105795153146944, 'dropout_rate_Layer_2': 0.04190437744409385, 'dropout_rate_Layer_3': 0.025518465080182764, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020124765292340698, 'l1_Layer_2': 0.0004964714229497071, 'l1_Layer_3': 1.001276363012088e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 55, 'n_units_Layer_3': 170}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 17.38% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 17.27% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:48:55,030]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:49:00,675]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:49:03,459]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:49:13,942]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:49:16,626]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:49:20,655]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:49:39,348]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:49:44,213]\u001b[0m Trial 1008 finished with value: 4.879491346410825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005083871046840134, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22059075564857863, 'dropout_rate_Layer_2': 0.06691288156900674, 'dropout_rate_Layer_3': 0.006750496044007155, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013721504866703483, 'l1_Layer_2': 0.0002516282856427987, 'l1_Layer_3': 1.548604715900913e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 60, 'n_units_Layer_3': 145}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 17.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.64 | sMAPE for Test Set is: 16.60% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:49:56,482]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:50:00,963]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:50:06,889]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:50:10,797]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:50:16,318]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:50:27,562]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:50:34,488]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:50:37,302]\u001b[0m Trial 1001 finished with value: 4.928493366498272 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006634870565802757, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20562821444511925, 'dropout_rate_Layer_2': 0.12783617455565555, 'dropout_rate_Layer_3': 0.09711498331725484, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.254290731378927e-05, 'l1_Layer_2': 0.011966388106396506, 'l1_Layer_3': 0.0006437772139173778, 'n_units_Layer_1': 120, 'n_units_Layer_2': 150, 'n_units_Layer_3': 245}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 17.37% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.62 | sMAPE for Test Set is: 23.08% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:50:42,069]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:50:55,142]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:50:58,015]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:51:08,726]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:51:13,548]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:51:16,488]\u001b[0m Trial 1004 finished with value: 4.938230662417479 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006901942088731746, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.203944483693804, 'dropout_rate_Layer_2': 0.14885824741191706, 'dropout_rate_Layer_3': 0.10004425778616294, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1339347560917647e-05, 'l1_Layer_2': 0.0004517909526138555, 'l1_Layer_3': 0.0007209817372539352, 'n_units_Layer_1': 135, 'n_units_Layer_2': 150, 'n_units_Layer_3': 245}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 17.32% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.58 | sMAPE for Test Set is: 27.58% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:51:19,768]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:51:22,837]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:51:28,914]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:51:31,524]\u001b[0m Trial 1020 finished with value: 4.889891551999962 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005776027687221813, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23213441227635384, 'dropout_rate_Layer_2': 0.0562311287685591, 'dropout_rate_Layer_3': 0.006270421002003587, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024435135519731093, 'l1_Layer_2': 0.0002995957069036675, 'l1_Layer_3': 1.24939051222637e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 60, 'n_units_Layer_3': 175}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 17.18% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.78 | sMAPE for Test Set is: 16.74% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:51:35,639]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:51:43,734]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:51:53,590]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:51:55,794]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:51:55,976]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:52:01,598]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:52:09,510]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:52:17,238]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:52:17,381]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:52:24,411]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:52:35,690]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:52:35,878]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:52:39,221]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:53:01,415]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:53:02,330]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:53:05,791]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:53:11,889]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 17.31% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.77 | sMAPE for Test Set is: 17.04% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:53:14,203]\u001b[0m Trial 1039 finished with value: 4.883212339473713 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007243129078501553, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21266947849730772, 'dropout_rate_Layer_2': 0.071892613614981, 'dropout_rate_Layer_3': 0.01659005647083528, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019667860097316497, 'l1_Layer_2': 0.0004561089191949662, 'l1_Layer_3': 1.8576228183418225e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 50, 'n_units_Layer_3': 155}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:53:15,368]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:53:19,095]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:53:24,018]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:53:25,382]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:53:25,453]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:53:32,624]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:53:37,123]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:53:54,075]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:54:40,187]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:54:44,108]\u001b[0m Trial 1048 finished with value: 4.875573811258018 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005825269610052887, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2118742502622199, 'dropout_rate_Layer_2': 0.15843591526337844, 'dropout_rate_Layer_3': 0.09675100834524071, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.957822219216893e-05, 'l1_Layer_2': 0.009084955309957517, 'l1_Layer_3': 0.0004098873414530768, 'n_units_Layer_1': 115, 'n_units_Layer_2': 160, 'n_units_Layer_3': 255}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 17.05% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.28 | sMAPE for Test Set is: 22.11% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:54:49,278]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:54:53,078]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:54:57,580]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:55:02,939]\u001b[0m Trial 1054 finished with value: 5.024327701078503 and parameters: {'n_hidden': 3, 'learning_rate': 0.000724562852941026, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22029198822698517, 'dropout_rate_Layer_2': 0.14750140271656145, 'dropout_rate_Layer_3': 0.08269157182947902, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.106942712994392e-05, 'l1_Layer_2': 0.00020652424839220294, 'l1_Layer_3': 0.0007066841545893071, 'n_units_Layer_1': 115, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 17.58% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.10 | sMAPE for Test Set is: 28.96% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:55:10,497]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:55:14,857]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:55:19,914]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:56:00,968]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:56:05,782]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:56:29,406]\u001b[0m Trial 1063 finished with value: 4.937839984894354 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005882684815772572, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21498410119948386, 'dropout_rate_Layer_2': 0.1529767324109166, 'dropout_rate_Layer_3': 0.0651882818479042, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0728295231763659e-05, 'l1_Layer_2': 0.009855706806740895, 'l1_Layer_3': 0.0004934738210742529, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 250}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 17.35% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.32 | sMAPE for Test Set is: 22.25% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:56:30,649]\u001b[0m Trial 1061 finished with value: 4.916238699069791 and parameters: {'n_hidden': 3, 'learning_rate': 0.000592463484674895, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21845357180253552, 'dropout_rate_Layer_2': 0.16145399986110137, 'dropout_rate_Layer_3': 0.06131259265156086, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0584233513549748e-05, 'l1_Layer_2': 0.0106647899328042, 'l1_Layer_3': 0.0005064225552328425, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 255}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 17.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.95 | sMAPE for Test Set is: 23.76% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:56:49,763]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:56:52,701]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:57:29,713]\u001b[0m Trial 1068 finished with value: 5.303136141058232 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023680085559191506, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03542316881777361, 'dropout_rate_Layer_2': 0.07121102833333712, 'dropout_rate_Layer_3': 0.32467605962016133, 'dropout_rate_Layer_4': 0.39859074832773567, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011400618653861065, 'l1_Layer_2': 0.05778020639018366, 'l1_Layer_3': 6.031572987726854e-05, 'l1_Layer_4': 0.00023696951343156632, 'n_units_Layer_1': 265, 'n_units_Layer_2': 50, 'n_units_Layer_3': 170, 'n_units_Layer_4': 235}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 18.47% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.04 | sMAPE for Test Set is: 26.59% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:57:30,446]\u001b[0m Trial 1069 finished with value: 4.900747488541998 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005001951640297463, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1996639326583462, 'dropout_rate_Layer_2': 0.08286521588607662, 'dropout_rate_Layer_3': 0.010657619483289912, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011201011702519614, 'l1_Layer_2': 0.00040222289546455096, 'l1_Layer_3': 1.56417239196811e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 55, 'n_units_Layer_3': 165}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 17.29% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.91 | sMAPE for Test Set is: 16.92% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:57:37,858]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:57:45,552]\u001b[0m Trial 1060 finished with value: 4.9856714854530955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005455493763869493, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20403717345081387, 'dropout_rate_Layer_2': 0.15245204222665115, 'dropout_rate_Layer_3': 0.07707322534090365, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1676306573980649e-05, 'l1_Layer_2': 0.006396827826751994, 'l1_Layer_3': 0.0005156879989426074, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 250}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 17.47% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.73 | sMAPE for Test Set is: 23.13% | rMAE for Test Set is: 0.92\n",
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 17.52% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.52 | sMAPE for Test Set is: 22.71% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:57:47,456]\u001b[0m Trial 1065 finished with value: 4.976849500041186 and parameters: {'n_hidden': 3, 'learning_rate': 0.000526859762950704, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21881013383442452, 'dropout_rate_Layer_2': 0.1586615557828426, 'dropout_rate_Layer_3': 0.06772360659437678, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.684214598039535e-05, 'l1_Layer_2': 0.011753988869204429, 'l1_Layer_3': 0.0004925169633006042, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 250}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:57:57,453]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:58:03,345]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:58:14,145]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:58:25,841]\u001b[0m Trial 1072 finished with value: 4.984184973195501 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009232992246035608, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07701563969398444, 'dropout_rate_Layer_2': 0.27320496390545684, 'dropout_rate_Layer_3': 0.3704363958668462, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0005926635702258551, 'l1_Layer_2': 2.410091673881312e-05, 'l1_Layer_3': 0.000988142908462075, 'n_units_Layer_1': 265, 'n_units_Layer_2': 80, 'n_units_Layer_3': 270}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 17.36% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.11 | sMAPE for Test Set is: 26.54% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:58:36,605]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:58:49,282]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:58:53,801]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:58:58,431]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:58:59,524]\u001b[0m Trial 1071 finished with value: 4.948302271633064 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005287542873474959, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20517489798268682, 'dropout_rate_Layer_2': 0.16277198647867064, 'dropout_rate_Layer_3': 0.07384582926757874, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0481124634642544e-05, 'l1_Layer_2': 0.00963152648084328, 'l1_Layer_3': 0.000492899673460613, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 250}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 17.34% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.38 | sMAPE for Test Set is: 22.31% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 18:59:12,510]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:59:17,845]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:59:23,717]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 18:59:33,639]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:00:20,499]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:00:26,574]\u001b[0m Trial 1083 finished with value: 4.983224958190053 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005740965516390427, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20911836441216977, 'dropout_rate_Layer_2': 0.16593405850766138, 'dropout_rate_Layer_3': 0.0698813899944356, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1818325600558825e-05, 'l1_Layer_2': 0.010802734385893308, 'l1_Layer_3': 0.0004149405434257944, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 250}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 17.56% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.37 | sMAPE for Test Set is: 22.59% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:00:34,869]\u001b[0m Trial 1087 finished with value: 4.896974268430217 and parameters: {'n_hidden': 3, 'learning_rate': 0.000654418954729275, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2022992835975283, 'dropout_rate_Layer_2': 0.16362289200124455, 'dropout_rate_Layer_3': 0.04718845571811966, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3542734794540653e-05, 'l1_Layer_2': 0.010385833405166738, 'l1_Layer_3': 0.0004003840256349692, 'n_units_Layer_1': 120, 'n_units_Layer_2': 150, 'n_units_Layer_3': 260}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.73 | sMAPE for Test Set is: 23.15% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:00:41,126]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:00:41,470]\u001b[0m Trial 1082 finished with value: 4.973156246177061 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005780775349910085, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21006808660856618, 'dropout_rate_Layer_2': 0.16444247952759036, 'dropout_rate_Layer_3': 0.04695008283074041, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1528619112246531e-05, 'l1_Layer_2': 0.01065899099403895, 'l1_Layer_3': 0.0004048236062407548, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 250}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 17.44% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.18 | sMAPE for Test Set is: 21.82% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:01:05,330]\u001b[0m Trial 1090 finished with value: 5.002566524490965 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011265942435354256, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07486487224041358, 'dropout_rate_Layer_2': 0.27553430149695246, 'dropout_rate_Layer_3': 0.37741579081189314, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0005592902468842734, 'l1_Layer_2': 2.5653447009795305e-05, 'l1_Layer_3': 0.000905226277023618, 'n_units_Layer_1': 280, 'n_units_Layer_2': 80, 'n_units_Layer_3': 280}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 17.50% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.47 | sMAPE for Test Set is: 27.56% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:01:49,828]\u001b[0m Trial 1088 finished with value: 5.013722404003685 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006267389258771139, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20229198419102845, 'dropout_rate_Layer_2': 0.14550506603745084, 'dropout_rate_Layer_3': 0.07295818437945065, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3480427150222316e-05, 'l1_Layer_2': 0.01046902472765748, 'l1_Layer_3': 0.000430390920860656, 'n_units_Layer_1': 110, 'n_units_Layer_2': 220, 'n_units_Layer_3': 260}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 17.60% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.62 | sMAPE for Test Set is: 23.03% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:01:54,439]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:02:04,764]\u001b[0m Trial 1092 finished with value: 4.916703909202522 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005939458196382446, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2019482134385085, 'dropout_rate_Layer_2': 0.17976795013712568, 'dropout_rate_Layer_3': 0.04633629916446679, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.318523591244244e-05, 'l1_Layer_2': 0.011313246300375411, 'l1_Layer_3': 0.0003731367891902655, 'n_units_Layer_1': 120, 'n_units_Layer_2': 150, 'n_units_Layer_3': 260}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 17.33% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 8.80 | sMAPE for Test Set is: 21.21% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:02:07,719]\u001b[0m Trial 1093 finished with value: 4.865560362319041 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011698682748475255, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20681322392791893, 'dropout_rate_Layer_2': 0.11618841599176137, 'dropout_rate_Layer_3': 0.3884561962772835, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004596829783811154, 'l1_Layer_2': 1.398957144107731e-05, 'l1_Layer_3': 0.0012760539462303637, 'n_units_Layer_1': 260, 'n_units_Layer_2': 85, 'n_units_Layer_3': 300}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 17.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.50 | sMAPE for Test Set is: 25.23% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:02:08,670]\u001b[0m Trial 1091 finished with value: 4.985260479377801 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006053097528412148, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20105739446615306, 'dropout_rate_Layer_2': 0.17215421496342112, 'dropout_rate_Layer_3': 0.05151930687744176, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4461612572576959e-05, 'l1_Layer_2': 0.011144184210512963, 'l1_Layer_3': 0.0003895787554426921, 'n_units_Layer_1': 115, 'n_units_Layer_2': 150, 'n_units_Layer_3': 260}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 17.55% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.83 | sMAPE for Test Set is: 21.12% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:02:32,885]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:02:36,508]\u001b[0m Trial 1097 finished with value: 4.883065988902607 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006882365589806238, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21020782237796803, 'dropout_rate_Layer_2': 0.06447809600377669, 'dropout_rate_Layer_3': 0.03114293275563365, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020648818793808472, 'l1_Layer_2': 0.00018352321612000817, 'l1_Layer_3': 1.7247075533321855e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 60, 'n_units_Layer_3': 165}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 17.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.03 | sMAPE for Test Set is: 17.26% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:02:44,450]\u001b[0m Trial 1096 finished with value: 4.9687392575791876 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014979401344783474, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22790054643459848, 'dropout_rate_Layer_2': 0.26770151730861746, 'dropout_rate_Layer_3': 0.38674491934201843, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004380602897196592, 'l1_Layer_2': 1.2922854697591421e-05, 'l1_Layer_3': 0.001249722545801871, 'n_units_Layer_1': 265, 'n_units_Layer_2': 80, 'n_units_Layer_3': 300}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 17.58% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.10 | sMAPE for Test Set is: 24.32% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:02:48,527]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:02:51,956]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:03:00,346]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:03:00,633]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:03:01,569]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:03:09,704]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:03:18,436]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:03:24,007]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:03:34,128]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:03:38,214]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:03:43,257]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:03:48,081]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:03:54,905]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:03:59,009]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:04:03,706]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:04:10,691]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:04:17,539]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:04:27,487]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:04:32,535]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:04:32,696]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:04:49,268]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:05:09,576]\u001b[0m Trial 1110 finished with value: 4.930528421551684 and parameters: {'n_hidden': 3, 'learning_rate': 0.000565626049104411, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18634413341889594, 'dropout_rate_Layer_2': 0.17224394697123352, 'dropout_rate_Layer_3': 0.055712629893352385, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1561912102182383e-05, 'l1_Layer_2': 0.007797367674490675, 'l1_Layer_3': 0.00043742664004005756, 'n_units_Layer_1': 125, 'n_units_Layer_2': 215, 'n_units_Layer_3': 265}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 17.33% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.45 | sMAPE for Test Set is: 22.51% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:05:11,384]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:05:14,772]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:05:15,209]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:05:21,355]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:05:29,231]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:05:35,534]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:05:39,517]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:05:49,551]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:05:53,832]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:06:03,763]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:06:12,987]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:06:18,611]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:06:34,558]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:06:36,540]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:06:38,680]\u001b[0m Trial 1124 finished with value: 4.799600583902756 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011916552244245159, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22346066754407254, 'dropout_rate_Layer_2': 0.11838340860521387, 'dropout_rate_Layer_3': 0.3333193294598565, 'dropout_rate_Layer_4': 0.0035119763200015253, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00042518405856046946, 'l1_Layer_2': 2.438190014756721e-05, 'l1_Layer_3': 0.0011433599211992265, 'l1_Layer_4': 0.00024680578046800186, 'n_units_Layer_1': 265, 'n_units_Layer_2': 90, 'n_units_Layer_3': 285, 'n_units_Layer_4': 180}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 17.00% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 10.03 | sMAPE for Test Set is: 24.11% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:06:49,760]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:06:52,398]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:06:52,917]\u001b[0m Trial 1137 finished with value: 5.1602847924356805 and parameters: {'n_hidden': 3, 'learning_rate': 0.004434443167642244, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023648386643272554, 'dropout_rate_Layer_2': 0.3376904910202799, 'dropout_rate_Layer_3': 0.2945167181193076, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005815309326387934, 'l1_Layer_2': 0.00933855534472712, 'l1_Layer_3': 7.326943497013477e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 175, 'n_units_Layer_3': 295}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 18.01% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.22 | sMAPE for Test Set is: 24.63% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:07:04,532]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:07:16,849]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:07:17,890]\u001b[0m Trial 1141 finished with value: 4.9132666222457 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008411174075517449, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19133811846561335, 'dropout_rate_Layer_2': 0.05254699864573297, 'dropout_rate_Layer_3': 0.013628047695822872, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026122184724617736, 'l1_Layer_2': 0.0004547689475044046, 'l1_Layer_3': 1.7497088447969826e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 70, 'n_units_Layer_3': 155}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 16.95% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:07:20,363]\u001b[0m Trial 1140 finished with value: 5.075138992946908 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027948534567054668, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011319928296351256, 'dropout_rate_Layer_2': 0.34101518279529397, 'dropout_rate_Layer_3': 0.19296829269476945, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005518150723606522, 'l1_Layer_2': 0.01000391828707072, 'l1_Layer_3': 8.335423694170461e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 175, 'n_units_Layer_3': 295}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 17.83% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.97 | sMAPE for Test Set is: 21.71% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:07:38,045]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:07:42,039]\u001b[0m Trial 1128 finished with value: 4.98333810642112 and parameters: {'n_hidden': 3, 'learning_rate': 0.000602222042836469, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19545613899627653, 'dropout_rate_Layer_2': 0.15902268458675498, 'dropout_rate_Layer_3': 0.06340406940995852, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4608854837554604e-05, 'l1_Layer_2': 0.014951086369803484, 'l1_Layer_3': 0.0003934614649765008, 'n_units_Layer_1': 130, 'n_units_Layer_2': 225, 'n_units_Layer_3': 265}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 17.58% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.79 | sMAPE for Test Set is: 21.16% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:07:42,651]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:07:48,259]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:07:50,566]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:08:08,310]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:08:13,853]\u001b[0m Trial 1150 finished with value: 5.051352212313612 and parameters: {'n_hidden': 3, 'learning_rate': 0.004181849310124772, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01663215703333283, 'dropout_rate_Layer_2': 0.32120695106951, 'dropout_rate_Layer_3': 0.2947965424201501, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005914828443917924, 'l1_Layer_2': 0.009282545007950232, 'l1_Layer_3': 9.033483699977451e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 185, 'n_units_Layer_3': 295}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 17.62% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.16 | sMAPE for Test Set is: 22.08% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:08:14,269]\u001b[0m Trial 1149 finished with value: 5.1151234071481175 and parameters: {'n_hidden': 3, 'learning_rate': 0.003011183855573416, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019023383561149694, 'dropout_rate_Layer_2': 0.32262417462343645, 'dropout_rate_Layer_3': 0.2952438985561058, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005808390272690963, 'l1_Layer_2': 0.009137156433095359, 'l1_Layer_3': 8.865915848306479e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 165, 'n_units_Layer_3': 295}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 17.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.72 | sMAPE for Test Set is: 21.09% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:08:22,487]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:08:23,075]\u001b[0m Trial 1143 finished with value: 4.896888265666835 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008413451136101574, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2182620350927459, 'dropout_rate_Layer_2': 0.04469508234302011, 'dropout_rate_Layer_3': 0.0006742762911310825, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020462359878180097, 'l1_Layer_2': 0.00023014956791283077, 'l1_Layer_3': 1.0177484020943625e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 60, 'n_units_Layer_3': 165}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 17.17% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.19 | sMAPE for Test Set is: 17.47% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:08:29,997]\u001b[0m Trial 1151 finished with value: 5.279155289709458 and parameters: {'n_hidden': 3, 'learning_rate': 0.002977668773657713, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.049369257690293225, 'dropout_rate_Layer_2': 0.33521875066610635, 'dropout_rate_Layer_3': 0.3002563154254042, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0007607634038666892, 'l1_Layer_2': 0.008832871848234426, 'l1_Layer_3': 0.00012384407999634718, 'n_units_Layer_1': 280, 'n_units_Layer_2': 180, 'n_units_Layer_3': 295}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 18.55% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.28 | sMAPE for Test Set is: 22.30% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:08:39,542]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:08:40,171]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:08:51,789]\u001b[0m Trial 1154 finished with value: 5.034860051975238 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009286848627202434, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2058974005332231, 'dropout_rate_Layer_2': 0.13366998142840214, 'dropout_rate_Layer_3': 0.3195142818179723, 'dropout_rate_Layer_4': 0.09108063859896738, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00021181491833956648, 'l1_Layer_2': 1.6882946338229712e-05, 'l1_Layer_3': 0.0005545396475638963, 'l1_Layer_4': 8.019164340269681e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 95, 'n_units_Layer_3': 290, 'n_units_Layer_4': 255}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 17.74% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.26 | sMAPE for Test Set is: 26.90% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:09:06,740]\u001b[0m Trial 1158 finished with value: 4.969787697936348 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009446328688883237, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2412053508644748, 'dropout_rate_Layer_2': 0.12312990929362953, 'dropout_rate_Layer_3': 0.32490909466060874, 'dropout_rate_Layer_4': 0.07727671887816007, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00026099494931877286, 'l1_Layer_2': 1.5848799211489145e-05, 'l1_Layer_3': 0.000630690045441248, 'l1_Layer_4': 6.578390106728936e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 95, 'n_units_Layer_3': 290, 'n_units_Layer_4': 245}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 17.66% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.32 | sMAPE for Test Set is: 24.88% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:09:12,832]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:09:18,036]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:09:26,879]\u001b[0m Trial 1152 finished with value: 4.905614236174238 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006083867333555723, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1959499261860123, 'dropout_rate_Layer_2': 0.16122250229003143, 'dropout_rate_Layer_3': 0.039703941205055236, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.570473368310261e-05, 'l1_Layer_2': 0.014112048293565547, 'l1_Layer_3': 0.00028313627894540136, 'n_units_Layer_1': 110, 'n_units_Layer_2': 230, 'n_units_Layer_3': 260}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 17.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 8.77 | sMAPE for Test Set is: 21.07% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:09:31,600]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:09:37,014]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:09:42,356]\u001b[0m Trial 1157 finished with value: 4.901577233861389 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009287708734985209, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20112073692162022, 'dropout_rate_Layer_2': 0.11496040297836439, 'dropout_rate_Layer_3': 0.01937350762573467, 'dropout_rate_Layer_4': 0.08914845539013361, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002177444360925325, 'l1_Layer_2': 1.527953582985459e-05, 'l1_Layer_3': 0.0009628556286187551, 'l1_Layer_4': 6.790734005741852e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 95, 'n_units_Layer_3': 290, 'n_units_Layer_4': 250}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 17.32% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.23 | sMAPE for Test Set is: 24.38% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:09:50,240]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:09:54,463]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:09:58,897]\u001b[0m Trial 1162 finished with value: 4.842245786303526 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005669274359062626, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22393402862538106, 'dropout_rate_Layer_2': 0.01429424398523749, 'dropout_rate_Layer_3': 0.026803489968044752, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016171009407303874, 'l1_Layer_2': 0.00036565665398271055, 'l1_Layer_3': 1.5988616569107883e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 65, 'n_units_Layer_3': 160}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 17.05% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.76 | sMAPE for Test Set is: 16.77% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:10:03,786]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:10:06,733]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:10:10,107]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:10:10,561]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:10:17,457]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:10:32,715]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:10:42,568]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:10:52,289]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:11:15,509]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:11:24,013]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:11:55,593]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:11:56,128]\u001b[0m Trial 1168 finished with value: 4.884295052751982 and parameters: {'n_hidden': 3, 'learning_rate': 0.000552124716940692, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20359618147605188, 'dropout_rate_Layer_2': 0.1616997454534487, 'dropout_rate_Layer_3': 0.02961973989905766, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3166180918449424e-05, 'l1_Layer_2': 0.009194670557152422, 'l1_Layer_3': 0.0003523511625593781, 'n_units_Layer_1': 120, 'n_units_Layer_2': 215, 'n_units_Layer_3': 255}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 17.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.70 | sMAPE for Test Set is: 23.05% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:12:07,049]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:12:09,296]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:12:20,849]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:12:25,532]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:12:28,833]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:12:33,024]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:12:33,534]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:12:34,762]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:12:50,600]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:12:51,966]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:12:55,857]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:13:00,963]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:13:03,463]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:13:08,165]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:13:11,693]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:13:20,869]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:13:24,799]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:13:29,534]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:13:35,522]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:13:38,703]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:13:44,007]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:13:50,481]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:13:54,927]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:13:58,105]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:14:03,104]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:14:07,553]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:14:12,297]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:14:12,976]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:14:14,413]\u001b[0m Trial 1193 finished with value: 4.947602899013231 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015175445472603132, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23431866579314123, 'dropout_rate_Layer_2': 0.10590290260782047, 'dropout_rate_Layer_3': 0.16525805050962666, 'dropout_rate_Layer_4': 0.0630850773644176, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.796417192500574e-05, 'l1_Layer_2': 1.4809234667243233e-05, 'l1_Layer_3': 0.0013064539083109295, 'l1_Layer_4': 1.0080709956944797e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 105, 'n_units_Layer_3': 300, 'n_units_Layer_4': 195}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 17.25% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.84 | sMAPE for Test Set is: 28.09% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:14:24,763]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:14:28,880]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:14:39,492]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:14:54,287]\u001b[0m Trial 1205 finished with value: 4.914902863056301 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018563933514808152, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22625051301948595, 'dropout_rate_Layer_2': 0.14001716737488717, 'dropout_rate_Layer_3': 0.026654482791716394, 'dropout_rate_Layer_4': 0.12258566111866606, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00011633626413686603, 'l1_Layer_2': 2.126696786542781e-05, 'l1_Layer_3': 0.0013365357189205752, 'l1_Layer_4': 9.667337474905331e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 100, 'n_units_Layer_3': 270, 'n_units_Layer_4': 250}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 17.32% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.60 | sMAPE for Test Set is: 25.37% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:15:00,299]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:15:06,233]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:15:12,097]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:15:12,383]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:15:19,297]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:15:19,806]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:15:25,747]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:15:28,096]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:15:32,490]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:15:37,191]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:15:37,393]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:15:41,523]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:15:49,553]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:15:54,440]\u001b[0m Trial 1214 finished with value: 4.965997829193065 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017459165841165493, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25944232620761015, 'dropout_rate_Layer_2': 0.10430675937727889, 'dropout_rate_Layer_3': 0.008445763711093927, 'dropout_rate_Layer_4': 0.12676448621621667, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00011245022832911878, 'l1_Layer_2': 3.1643803826970164e-05, 'l1_Layer_3': 0.0020543984650381315, 'l1_Layer_4': 8.117230331306996e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 105, 'n_units_Layer_3': 125, 'n_units_Layer_4': 250}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 17.45% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.97 | sMAPE for Test Set is: 19.25% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:16:07,085]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:16:11,395]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:16:17,558]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:16:21,301]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:16:33,295]\u001b[0m Trial 1230 finished with value: 5.020945361615116 and parameters: {'n_hidden': 3, 'learning_rate': 0.003406884773935622, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005478312516930254, 'dropout_rate_Layer_2': 0.3446602192779818, 'dropout_rate_Layer_3': 0.27471392349797974, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000577694228273667, 'l1_Layer_2': 0.008926461429810293, 'l1_Layer_3': 0.0001517241432920762, 'n_units_Layer_1': 275, 'n_units_Layer_2': 170, 'n_units_Layer_3': 295}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 17.62% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.52 | sMAPE for Test Set is: 20.62% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:16:53,648]\u001b[0m Trial 1232 finished with value: 5.037067929137797 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018673306542586032, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22574079138453865, 'dropout_rate_Layer_2': 0.09944598252715812, 'dropout_rate_Layer_3': 0.01286082732531155, 'dropout_rate_Layer_4': 0.12454234259196931, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00013211569267828103, 'l1_Layer_2': 1.7553176871691785e-05, 'l1_Layer_3': 0.0015769244174104378, 'l1_Layer_4': 3.741826321036011e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 110, 'n_units_Layer_3': 135, 'n_units_Layer_4': 255}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 17.67% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.84 | sMAPE for Test Set is: 21.17% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:16:58,603]\u001b[0m Trial 1233 finished with value: 4.993588594784285 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018190889203250227, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2582568095303594, 'dropout_rate_Layer_2': 0.09767597606936472, 'dropout_rate_Layer_3': 0.020208580270332982, 'dropout_rate_Layer_4': 0.12814975500107073, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.695097216462403e-05, 'l1_Layer_2': 1.789053227026427e-05, 'l1_Layer_3': 0.001984188348648231, 'l1_Layer_4': 4.142690527795901e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 125, 'n_units_Layer_3': 115, 'n_units_Layer_4': 265}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 17.46% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.13 | sMAPE for Test Set is: 19.59% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:17:01,583]\u001b[0m Trial 1227 finished with value: 4.901040317983934 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006386165795464885, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19068208401247624, 'dropout_rate_Layer_2': 0.18090073739939178, 'dropout_rate_Layer_3': 0.029845001997850326, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7047580663958205e-05, 'l1_Layer_2': 0.006983746595704625, 'l1_Layer_3': 0.0005032501842941158, 'n_units_Layer_1': 120, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:17:01,657]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 17.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.21 | sMAPE for Test Set is: 24.16% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:17:03,605]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:17:19,719]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:17:25,132]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:17:30,394]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:17:34,929]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:17:35,778]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:17:53,146]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:17:58,816]\u001b[0m Trial 1237 finished with value: 4.986449226891307 and parameters: {'n_hidden': 4, 'learning_rate': 0.001514100977601213, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20251290714731984, 'dropout_rate_Layer_2': 0.1237571356977358, 'dropout_rate_Layer_3': 0.005825353757895533, 'dropout_rate_Layer_4': 0.054235229967547496, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.285776330456894e-05, 'l1_Layer_2': 1.4467212363238786e-05, 'l1_Layer_3': 0.0035015490842710893, 'l1_Layer_4': 0.0004653513724336098, 'n_units_Layer_1': 230, 'n_units_Layer_2': 115, 'n_units_Layer_3': 65, 'n_units_Layer_4': 225}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 17.46% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.09 | sMAPE for Test Set is: 19.68% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:18:03,790]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:18:09,413]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:18:36,511]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:18:59,594]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:19:13,209]\u001b[0m Trial 1249 finished with value: 5.3082789052354125 and parameters: {'n_hidden': 3, 'learning_rate': 0.003369998224730477, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023503722569540975, 'dropout_rate_Layer_2': 0.3063214492258244, 'dropout_rate_Layer_3': 0.2620496272769144, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000616144477860552, 'l1_Layer_2': 0.017408038123320774, 'l1_Layer_3': 0.00020491314728103522, 'n_units_Layer_1': 285, 'n_units_Layer_2': 175, 'n_units_Layer_3': 280}. Best is trial 810 with value: 4.780159944991826.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 18.62% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.85 | sMAPE for Test Set is: 23.48% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:19:13,410]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:19:20,308]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:19:20,506]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.76 | sMAPE for Validation Set is: 16.80% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 11.21 | sMAPE for Test Set is: 26.90% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:19:25,641]\u001b[0m Trial 1248 finished with value: 4.759253509752869 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006343397225527659, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21989642538506327, 'dropout_rate_Layer_2': 0.05490226400456178, 'dropout_rate_Layer_3': 0.0351833760712165, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021754055967287012, 'l1_Layer_2': 0.00014116611634767192, 'l1_Layer_3': 1.4057154685087106e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 60, 'n_units_Layer_3': 170}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:19:33,740]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:19:34,411]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:19:36,737]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:19:42,233]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:19:44,941]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:19:46,234]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:19:49,145]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:19:55,222]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:20:00,117]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:20:05,110]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:20:10,209]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:20:15,116]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:20:21,642]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:20:26,602]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:20:30,608]\u001b[0m Trial 1243 finished with value: 5.031491813257031 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006052084980424131, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.205633570516195, 'dropout_rate_Layer_2': 0.192875905311036, 'dropout_rate_Layer_3': 0.04482402046326614, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.18603679195508e-05, 'l1_Layer_2': 0.00884742002375947, 'l1_Layer_3': 0.0003966283061489238, 'n_units_Layer_1': 120, 'n_units_Layer_2': 135, 'n_units_Layer_3': 245}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 17.79% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.57 | sMAPE for Test Set is: 22.93% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:20:35,127]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:20:43,525]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:20:46,597]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:20:49,952]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:20:53,210]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:20:56,567]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:20:58,995]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:21:04,889]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:21:09,713]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:21:20,669]\u001b[0m Trial 1260 finished with value: 4.933242390525408 and parameters: {'n_hidden': 3, 'learning_rate': 0.000600014495632119, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19508712403602047, 'dropout_rate_Layer_2': 0.166297120597834, 'dropout_rate_Layer_3': 0.06500017422794613, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9371983115913278e-05, 'l1_Layer_2': 0.010965181579962565, 'l1_Layer_3': 0.0003069976582317658, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 240}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 17.32% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 8.83 | sMAPE for Test Set is: 21.27% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:21:22,165]\u001b[0m Trial 1277 finished with value: 5.262551908692835 and parameters: {'n_hidden': 3, 'learning_rate': 0.002428518924803266, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016776150882523214, 'dropout_rate_Layer_2': 0.3405826178586239, 'dropout_rate_Layer_3': 0.2886798098216255, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0007423481869868981, 'l1_Layer_2': 0.007913912158110775, 'l1_Layer_3': 0.0001367484121837416, 'n_units_Layer_1': 300, 'n_units_Layer_2': 195, 'n_units_Layer_3': 290}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 18.42% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.85 | sMAPE for Test Set is: 23.52% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:21:28,027]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:21:32,886]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:21:33,257]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:21:39,868]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:21:46,389]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:21:51,090]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:21:55,500]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:21:59,190]\u001b[0m Trial 1284 finished with value: 5.3096320501497125 and parameters: {'n_hidden': 3, 'learning_rate': 0.002979279790166833, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020223945379947445, 'dropout_rate_Layer_2': 0.33310363682574884, 'dropout_rate_Layer_3': 0.29469183943728483, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003478102301785773, 'l1_Layer_2': 0.014251719530338462, 'l1_Layer_3': 0.0003312146893162383, 'n_units_Layer_1': 270, 'n_units_Layer_2': 180, 'n_units_Layer_3': 290}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 18.60% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.81 | sMAPE for Test Set is: 23.44% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:22:05,107]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:22:07,625]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:22:10,820]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:22:11,744]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:22:14,685]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:22:20,200]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:22:22,085]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:22:26,912]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:22:33,653]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:22:38,465]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:22:44,155]\u001b[0m Trial 1294 finished with value: 5.126509765220089 and parameters: {'n_hidden': 3, 'learning_rate': 0.005065147163752006, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00017036300959192424, 'dropout_rate_Layer_2': 0.2889835715499208, 'dropout_rate_Layer_3': 0.3067270733176044, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.1828858858657174e-05, 'l1_Layer_2': 0.009257902381139193, 'l1_Layer_3': 9.662214872026206e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 80, 'n_units_Layer_3': 280}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 17.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.14 | sMAPE for Test Set is: 24.43% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:22:46,365]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:22:51,351]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:22:56,050]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:23:01,326]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:23:01,912]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:23:02,353]\u001b[0m Trial 1299 finished with value: 5.106914507510276 and parameters: {'n_hidden': 3, 'learning_rate': 0.005262699992882905, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0001814014022165876, 'dropout_rate_Layer_2': 0.31985824114301936, 'dropout_rate_Layer_3': 0.30450085416917977, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.7759529331123646e-05, 'l1_Layer_2': 0.010427937092119862, 'l1_Layer_3': 9.845605990129583e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 80, 'n_units_Layer_3': 280}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 17.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.80 | sMAPE for Test Set is: 23.44% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:23:08,280]\u001b[0m Trial 1268 finished with value: 4.982660667486143 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006009614433436361, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19988606881794957, 'dropout_rate_Layer_2': 0.1511449453687509, 'dropout_rate_Layer_3': 0.036673821465406306, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.20915129941769e-05, 'l1_Layer_2': 0.0068662767093018865, 'l1_Layer_3': 0.00042389652541737036, 'n_units_Layer_1': 115, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 17.51% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.78 | sMAPE for Test Set is: 23.29% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:23:10,671]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:23:16,665]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:23:20,696]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:23:21,322]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:23:22,095]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:23:26,975]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:23:28,731]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:23:31,214]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:23:38,027]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:23:39,836]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:23:45,775]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:23:48,248]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 17.94% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.62 | sMAPE for Test Set is: 25.40% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:23:52,031]\u001b[0m Trial 1310 finished with value: 5.155422121339671 and parameters: {'n_hidden': 3, 'learning_rate': 0.004998113282370545, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004358893927597833, 'dropout_rate_Layer_2': 0.2901078184219278, 'dropout_rate_Layer_3': 0.3049989736792373, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.355770719461854e-05, 'l1_Layer_2': 0.009547872166923762, 'l1_Layer_3': 9.774066161772455e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 80, 'n_units_Layer_3': 280}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:24:13,289]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:24:49,468]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:25:05,081]\u001b[0m Trial 1314 finished with value: 4.9302073330683305 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006157918887126894, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18803464371668221, 'dropout_rate_Layer_2': 0.16122048751015106, 'dropout_rate_Layer_3': 0.04141353550350569, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4087822637837713e-05, 'l1_Layer_2': 0.0071672978727877435, 'l1_Layer_3': 0.000470572856567465, 'n_units_Layer_1': 130, 'n_units_Layer_2': 140, 'n_units_Layer_3': 270}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 17.34% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.74 | sMAPE for Test Set is: 23.26% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:25:09,534]\u001b[0m Trial 1321 finished with value: 5.099510537815494 and parameters: {'n_hidden': 3, 'learning_rate': 0.004138552932626009, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00020477978043940504, 'dropout_rate_Layer_2': 0.30240230044935446, 'dropout_rate_Layer_3': 0.30554089432545395, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.2646882790263015e-05, 'l1_Layer_2': 0.010620930027339116, 'l1_Layer_3': 0.00010289203839603816, 'n_units_Layer_1': 295, 'n_units_Layer_2': 80, 'n_units_Layer_3': 280}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 17.86% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.75 | sMAPE for Test Set is: 23.36% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:25:20,904]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:25:26,005]\u001b[0m Trial 1319 finished with value: 4.899347319158846 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007027591292529306, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19075545551648843, 'dropout_rate_Layer_2': 0.14830664809752656, 'dropout_rate_Layer_3': 0.0682078221597056, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1817136369022573e-05, 'l1_Layer_2': 0.009530437988133906, 'l1_Layer_3': 0.0004983530080930716, 'n_units_Layer_1': 120, 'n_units_Layer_2': 160, 'n_units_Layer_3': 275}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 17.28% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.44 | sMAPE for Test Set is: 22.45% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:25:26,756]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:25:30,773]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:25:31,960]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:25:38,377]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:25:42,198]\u001b[0m Trial 1320 finished with value: 4.922515636128366 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005945168122470365, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21294713719244257, 'dropout_rate_Layer_2': 0.17576000099563427, 'dropout_rate_Layer_3': 0.05956582036396044, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3222840997381952e-05, 'l1_Layer_2': 0.010723411845931764, 'l1_Layer_3': 0.0003266861988061094, 'n_units_Layer_1': 115, 'n_units_Layer_2': 165, 'n_units_Layer_3': 275}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 17.35% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.05 | sMAPE for Test Set is: 21.73% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:25:53,398]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:25:58,750]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:26:01,066]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:26:03,529]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:26:06,398]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:26:09,992]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:26:10,760]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:26:18,447]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:26:28,579]\u001b[0m Trial 1331 finished with value: 5.11348246229705 and parameters: {'n_hidden': 3, 'learning_rate': 0.00382293755739664, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0032390941383082378, 'dropout_rate_Layer_2': 0.2792913409744625, 'dropout_rate_Layer_3': 0.30300883812941254, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.320074115410294e-05, 'l1_Layer_2': 0.009193683041740428, 'l1_Layer_3': 0.00010262686052751564, 'n_units_Layer_1': 295, 'n_units_Layer_2': 185, 'n_units_Layer_3': 275}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 17.87% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.10 | sMAPE for Test Set is: 26.52% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:26:34,303]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:26:39,559]\u001b[0m Trial 1338 finished with value: 5.116121049568862 and parameters: {'n_hidden': 3, 'learning_rate': 0.004645365354260077, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02504948752312411, 'dropout_rate_Layer_2': 0.2751332159744788, 'dropout_rate_Layer_3': 0.29951764295168437, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.951182482220374e-05, 'l1_Layer_2': 0.008157655870039464, 'l1_Layer_3': 0.00015217012423478988, 'n_units_Layer_1': 285, 'n_units_Layer_2': 85, 'n_units_Layer_3': 280}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 17.78% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.96 | sMAPE for Test Set is: 26.24% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:26:39,873]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:26:55,343]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:26:57,956]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:27:04,262]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:27:07,534]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:27:11,777]\u001b[0m Trial 1339 finished with value: 4.878155873562843 and parameters: {'n_hidden': 3, 'learning_rate': 0.00060450941590067, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21705156661082295, 'dropout_rate_Layer_2': 0.0734736640845167, 'dropout_rate_Layer_3': 0.016021843473202457, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014633114223572966, 'l1_Layer_2': 0.0004280569277850246, 'l1_Layer_3': 2.348239989931937e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 55, 'n_units_Layer_3': 145}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.88 | sMAPE for Validation Set is: 17.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 16.40% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:27:12,453]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:27:13,863]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:27:20,964]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:27:23,271]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:27:31,019]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:27:35,824]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:27:37,070]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:27:45,307]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:27:51,110]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:27:55,264]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:28:00,742]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:28:20,482]\u001b[0m Trial 1356 finished with value: 4.898100374001642 and parameters: {'n_hidden': 3, 'learning_rate': 0.000553282457750294, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2164708921550075, 'dropout_rate_Layer_2': 0.06424388117157023, 'dropout_rate_Layer_3': 0.03291878744688582, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011558540257698115, 'l1_Layer_2': 0.0006414252626340714, 'l1_Layer_3': 1.8863068170956295e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 65, 'n_units_Layer_3': 150}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 17.17% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.88 | sMAPE for Test Set is: 16.95% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:28:28,792]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:28:32,936]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:28:36,732]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:28:36,904]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:28:37,050]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:28:49,376]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 17.42% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.02 | sMAPE for Test Set is: 21.64% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:28:51,134]\u001b[0m Trial 1351 finished with value: 4.941527442729008 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005992634012419647, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19973511781032816, 'dropout_rate_Layer_2': 0.1603053197196571, 'dropout_rate_Layer_3': 0.04594340861956375, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5973591109611987e-05, 'l1_Layer_2': 0.013101563676343679, 'l1_Layer_3': 0.00042806663056735035, 'n_units_Layer_1': 120, 'n_units_Layer_2': 160, 'n_units_Layer_3': 270}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:28:55,828]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:28:57,075]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:29:10,267]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:29:24,656]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:29:29,685]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:29:37,088]\u001b[0m Trial 1369 finished with value: 5.09018819355099 and parameters: {'n_hidden': 3, 'learning_rate': 0.002060221833197139, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016014396261336435, 'dropout_rate_Layer_2': 0.2609180265945214, 'dropout_rate_Layer_3': 0.31852211418757886, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.036541867455851e-05, 'l1_Layer_2': 0.00796351315077492, 'l1_Layer_3': 0.00017804996363472708, 'n_units_Layer_1': 290, 'n_units_Layer_2': 85, 'n_units_Layer_3': 280}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 17.85% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.03 | sMAPE for Test Set is: 24.08% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:29:54,690]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 17.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.58 | sMAPE for Test Set is: 25.70% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:29:56,594]\u001b[0m Trial 1372 finished with value: 5.128033169180544 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030757981317137044, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01143978076425303, 'dropout_rate_Layer_2': 0.2817712594306029, 'dropout_rate_Layer_3': 0.31994843553056856, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.2677643257243125e-05, 'l1_Layer_2': 0.007970859745513995, 'l1_Layer_3': 0.0001756527701097156, 'n_units_Layer_1': 290, 'n_units_Layer_2': 85, 'n_units_Layer_3': 280}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:30:04,585]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:30:25,786]\u001b[0m Trial 1374 finished with value: 5.120719100242442 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021574119239635, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011822887003332234, 'dropout_rate_Layer_2': 0.28609820337512165, 'dropout_rate_Layer_3': 0.31734447392157833, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.3456708620266926e-05, 'l1_Layer_2': 0.007078861139517909, 'l1_Layer_3': 0.00019210502924090316, 'n_units_Layer_1': 290, 'n_units_Layer_2': 85, 'n_units_Layer_3': 265}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 17.89% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.23 | sMAPE for Test Set is: 22.34% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:30:30,874]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:30:35,897]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:30:41,691]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:30:47,664]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:30:52,760]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:30:56,595]\u001b[0m Trial 1367 finished with value: 4.936494516495276 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005443148046064703, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18988564493205626, 'dropout_rate_Layer_2': 0.043327453023744106, 'dropout_rate_Layer_3': 0.02344842722097048, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.14843807516026e-05, 'l1_Layer_2': 0.015220730082149516, 'l1_Layer_3': 0.0003632549789536013, 'n_units_Layer_1': 130, 'n_units_Layer_2': 165, 'n_units_Layer_3': 270}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 17.36% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.40 | sMAPE for Test Set is: 22.63% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:31:06,362]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:31:10,551]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 17.84% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.06 | sMAPE for Test Set is: 24.24% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:31:12,982]\u001b[0m Trial 1381 finished with value: 5.101410018847198 and parameters: {'n_hidden': 3, 'learning_rate': 0.002689933740229803, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014125803735955098, 'dropout_rate_Layer_2': 0.2637538968085482, 'dropout_rate_Layer_3': 0.32937569608962214, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.4502631450065763e-05, 'l1_Layer_2': 0.007687808289614361, 'l1_Layer_3': 0.00022164624424127189, 'n_units_Layer_1': 290, 'n_units_Layer_2': 85, 'n_units_Layer_3': 265}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:31:20,637]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:31:23,651]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:31:26,278]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:31:32,773]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:31:33,270]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:31:39,414]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:31:43,906]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:31:44,021]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:32:04,104]\u001b[0m Trial 1390 finished with value: 5.32187923978161 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011708064510999362, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2423228820461231, 'dropout_rate_Layer_2': 0.08727220281986198, 'dropout_rate_Layer_3': 0.021347684111567698, 'dropout_rate_Layer_4': 0.11380606362189796, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.152316793957411e-05, 'l1_Layer_2': 1.2212562715231236e-05, 'l1_Layer_3': 0.0027974759955328122, 'l1_Layer_4': 0.00015234057350938733, 'n_units_Layer_1': 235, 'n_units_Layer_2': 85, 'n_units_Layer_3': 195, 'n_units_Layer_4': 245}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 18.49% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.16 | sMAPE for Test Set is: 26.63% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:32:10,257]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:32:20,896]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:32:25,991]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:33:11,718]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:33:16,974]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:33:21,498]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:33:26,172]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:33:29,003]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:33:32,649]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:33:37,418]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:33:44,090]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:34:14,116]\u001b[0m Trial 1405 finished with value: 5.119789659173352 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020364860116702183, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26529294822993577, 'dropout_rate_Layer_2': 0.0682773122383003, 'dropout_rate_Layer_3': 0.008255280610421524, 'dropout_rate_Layer_4': 0.06436779837496728, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.555948963057268e-05, 'l1_Layer_2': 3.0263954907000807e-05, 'l1_Layer_3': 0.001934653966428223, 'l1_Layer_4': 2.2817597146689788e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 100, 'n_units_Layer_3': 125, 'n_units_Layer_4': 185}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 18.02% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 11.81 | sMAPE for Test Set is: 28.43% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:34:20,590]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:34:38,443]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:34:46,998]\u001b[0m Trial 1391 finished with value: 4.943720583235308 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005047441555848527, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19361485518522042, 'dropout_rate_Layer_2': 0.02346450464033499, 'dropout_rate_Layer_3': 0.011899211267186679, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1897286967371034e-05, 'l1_Layer_2': 0.01929842101284881, 'l1_Layer_3': 0.00024748614005730375, 'n_units_Layer_1': 130, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 17.12% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.20 | sMAPE for Test Set is: 22.00% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:34:55,843]\u001b[0m Trial 1397 finished with value: 5.009720597650364 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005491872857822763, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19144237323098098, 'dropout_rate_Layer_2': 0.021408752404090084, 'dropout_rate_Layer_3': 0.02665486440956672, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.483850137646745e-05, 'l1_Layer_2': 0.009608243416103876, 'l1_Layer_3': 0.0004408857106437622, 'n_units_Layer_1': 130, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 17.47% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.26 | sMAPE for Test Set is: 24.42% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:35:00,456]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:35:04,260]\u001b[0m Trial 1408 finished with value: 5.072026066699064 and parameters: {'n_hidden': 3, 'learning_rate': 0.002116807991911245, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04283656856600976, 'dropout_rate_Layer_2': 0.2830974738641571, 'dropout_rate_Layer_3': 0.3324288089772973, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.514518420519642e-05, 'l1_Layer_2': 0.006379296938266304, 'l1_Layer_3': 0.0002322560205445249, 'n_units_Layer_1': 290, 'n_units_Layer_2': 85, 'n_units_Layer_3': 265}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 17.83% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.80 | sMAPE for Test Set is: 23.51% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:35:11,940]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:35:16,748]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:35:23,003]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:35:27,001]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:35:27,246]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:35:27,361]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:35:28,702]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:35:38,578]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:35:43,037]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:35:46,441]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:35:58,045]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:36:03,771]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 17.75% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.52 | sMAPE for Test Set is: 22.89% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:36:05,837]\u001b[0m Trial 1416 finished with value: 5.077444566692499 and parameters: {'n_hidden': 3, 'learning_rate': 0.002016668745819556, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016900580114784142, 'dropout_rate_Layer_2': 0.261142247239446, 'dropout_rate_Layer_3': 0.33813082908539943, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.918871134704694e-05, 'l1_Layer_2': 0.0059091643635263225, 'l1_Layer_3': 0.0002646404217595633, 'n_units_Layer_1': 300, 'n_units_Layer_2': 90, 'n_units_Layer_3': 265}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:36:07,282]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:36:13,948]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:36:14,117]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:36:23,040]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:36:23,185]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:36:24,266]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:36:31,848]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:36:33,580]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:36:35,545]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:36:42,524]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:36:46,845]\u001b[0m Trial 1426 finished with value: 5.105633511970052 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019962102549493446, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03963562015588823, 'dropout_rate_Layer_2': 0.2599824600318508, 'dropout_rate_Layer_3': 0.3291372926203926, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.934459785753783e-05, 'l1_Layer_2': 0.006257110916109098, 'l1_Layer_3': 0.00023070111266741637, 'n_units_Layer_1': 300, 'n_units_Layer_2': 90, 'n_units_Layer_3': 260}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 17.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 8.20 | sMAPE for Test Set is: 19.12% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:36:49,312]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:36:49,825]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:36:56,477]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:37:00,508]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:37:04,869]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:37:05,433]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:37:08,951]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:37:17,471]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:37:22,979]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:37:27,361]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:37:27,924]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:37:34,455]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:37:35,883]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:37:42,817]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:37:46,670]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:37:50,228]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:37:53,270]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:38:02,815]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:38:21,230]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:38:25,983]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:38:31,146]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:38:48,368]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:38:57,555]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:39:00,069]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:39:05,547]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:39:07,875]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:39:14,317]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:39:14,454]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:39:20,376]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:39:20,590]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:39:21,316]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:39:30,331]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:39:31,068]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:39:36,764]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:39:41,656]\u001b[0m Trial 1453 finished with value: 4.994638449867678 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006990291356845506, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19855462293729922, 'dropout_rate_Layer_2': 0.15731508097388364, 'dropout_rate_Layer_3': 0.05795307109422852, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.690408271865405e-05, 'l1_Layer_2': 0.012904115681172, 'l1_Layer_3': 0.0005866252033945352, 'n_units_Layer_1': 130, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 17.51% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.29 | sMAPE for Test Set is: 24.59% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:39:49,424]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:39:57,236]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:39:59,624]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:40:02,653]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:40:05,130]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:40:08,275]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:40:12,753]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:40:16,401]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:40:19,726]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:40:32,931]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:40:33,942]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:40:39,290]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:40:51,586]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:40:55,282]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:40:57,757]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:40:58,598]\u001b[0m Trial 1482 finished with value: 5.113485866440963 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010235424563036946, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20596294709939286, 'dropout_rate_Layer_2': 0.1066745357258578, 'dropout_rate_Layer_3': 0.0005670518379672779, 'dropout_rate_Layer_4': 0.10279990833364884, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00017235949596691085, 'l1_Layer_2': 3.550189374686269e-05, 'l1_Layer_3': 0.0006122188443849015, 'l1_Layer_4': 1.7325269680026473e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 105, 'n_units_Layer_3': 295, 'n_units_Layer_4': 260}. Best is trial 1248 with value: 4.759253509752869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 17.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.61 | sMAPE for Test Set is: 30.18% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:41:06,452]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:41:08,996]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:41:15,261]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:41:17,915]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:41:30,467]\u001b[0m Trial 1475 finished with value: 4.672115596790818 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005590127048653304, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21124461126607735, 'dropout_rate_Layer_2': 0.02192063048645742, 'dropout_rate_Layer_3': 0.011818307981561946, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002044219990590379, 'l1_Layer_2': 0.0005588730012428382, 'l1_Layer_3': 1.6779636517665835e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 160}. Best is trial 1475 with value: 4.672115596790818.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 16.47% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 16.58% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:41:33,983]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:41:38,530]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:41:42,823]\u001b[0m Trial 1491 finished with value: 5.074765697291444 and parameters: {'n_hidden': 3, 'learning_rate': 0.001918393854081888, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013925191396004177, 'dropout_rate_Layer_2': 0.2560413969457505, 'dropout_rate_Layer_3': 0.3171673310864476, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.2615947744061657e-05, 'l1_Layer_2': 0.005635579528831756, 'l1_Layer_3': 0.0003031682928879412, 'n_units_Layer_1': 290, 'n_units_Layer_2': 185, 'n_units_Layer_3': 255}. Best is trial 1475 with value: 4.672115596790818.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 17.79% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.69 | sMAPE for Test Set is: 23.12% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:41:49,675]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:41:59,618]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:42:05,201]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:42:05,455]\u001b[0m Trial 1490 finished with value: 4.834321223745328 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006559435962801664, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21495571348881867, 'dropout_rate_Layer_2': 0.0549536774748365, 'dropout_rate_Layer_3': 0.023717119931016717, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.582347574114801e-05, 'l1_Layer_2': 0.0009495329130554593, 'l1_Layer_3': 1.4287689609951666e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 65, 'n_units_Layer_3': 170}. Best is trial 1475 with value: 4.672115596790818.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.83 | sMAPE for Validation Set is: 17.01% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 11.26 | sMAPE for Test Set is: 26.88% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 19:42:21,268]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:42:34,193]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:42:38,187]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 19:42:46,038]\u001b[0m Trial 1498 finished with value: 4.865601918840265 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008589633618144393, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20120212789867342, 'dropout_rate_Layer_2': 0.007368618147706307, 'dropout_rate_Layer_3': 0.033456595719467075, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.1405554861779664e-05, 'l1_Layer_2': 0.0010458662645370055, 'l1_Layer_3': 1.3340525012390551e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 205, 'n_units_Layer_3': 180}. Best is trial 1475 with value: 4.672115596790818.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.87 | sMAPE for Validation Set is: 17.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.19 | sMAPE for Test Set is: 29.35% | rMAE for Test Set is: 1.15\n",
      "for 2018-01-01, MAE is:4.53 & sMAPE is:20.54% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 20.54% & 0.35\n",
      "for 2018-01-02, MAE is:6.57 & sMAPE is:21.69% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 21.12% & 0.32\n",
      "for 2018-01-03, MAE is:10.27 & sMAPE is:55.60% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 32.61% & 0.68\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000223F4207430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-04, MAE is:3.54 & sMAPE is:10.36% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 27.05% & 0.74\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000224046C6280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-05, MAE is:5.05 & sMAPE is:12.60% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 24.16% & 0.69\n",
      "for 2018-01-06, MAE is:3.73 & sMAPE is:11.59% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 22.06% & 0.64\n",
      "for 2018-01-07, MAE is:2.79 & sMAPE is:10.08% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 20.35% & 0.75\n",
      "for 2018-01-08, MAE is:3.70 & sMAPE is:10.11% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 19.07% & 0.70\n",
      "for 2018-01-09, MAE is:3.62 & sMAPE is:18.92% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 19.05% & 0.68\n",
      "for 2018-01-10, MAE is:4.44 & sMAPE is:12.15% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 18.36% & 0.64\n",
      "for 2018-01-11, MAE is:5.87 & sMAPE is:13.64% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 17.93% & 0.64\n",
      "for 2018-01-12, MAE is:4.24 & sMAPE is:11.01% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 17.36% & 0.64\n",
      "for 2018-01-13, MAE is:2.44 & sMAPE is:8.38% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 16.67% & 0.63\n",
      "for 2018-01-14, MAE is:1.36 & sMAPE is:4.63% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 15.81% & 0.65\n",
      "for 2018-01-15, MAE is:6.74 & sMAPE is:27.89% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.59 & 16.61% & 0.66\n",
      "for 2018-01-16, MAE is:12.69 & sMAPE is:73.65% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 20.18% & 0.74\n",
      "for 2018-01-17, MAE is:3.74 & sMAPE is:12.49% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 19.73% & 0.73\n",
      "for 2018-01-18, MAE is:5.28 & sMAPE is:16.08% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 19.52% & 0.72\n",
      "for 2018-01-19, MAE is:3.75 & sMAPE is:9.62% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 19.00% & 0.73\n",
      "for 2018-01-20, MAE is:4.65 & sMAPE is:12.54% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 18.68% & 0.74\n",
      "for 2018-01-21, MAE is:2.26 & sMAPE is:6.29% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 18.09% & 0.72\n",
      "for 2018-01-22, MAE is:2.76 & sMAPE is:7.01% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 17.58% & 0.70\n",
      "for 2018-01-23, MAE is:10.85 & sMAPE is:27.61% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 18.02% & 0.70\n",
      "for 2018-01-24, MAE is:6.17 & sMAPE is:28.98% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 18.48% & 0.70\n",
      "for 2018-01-25, MAE is:9.49 & sMAPE is:47.80% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 19.65% & 0.71\n",
      "for 2018-01-26, MAE is:9.45 & sMAPE is:25.39% & rMAE is:3.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 19.87% & 0.81\n",
      "for 2018-01-27, MAE is:4.69 & sMAPE is:21.00% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 19.91% & 0.80\n",
      "for 2018-01-28, MAE is:11.65 & sMAPE is:94.46% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 22.57% & 0.79\n",
      "for 2018-01-29, MAE is:6.72 & sMAPE is:48.57% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 23.47% & 0.77\n",
      "for 2018-01-30, MAE is:3.79 & sMAPE is:14.38% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 23.17% & 0.76\n",
      "for 2018-01-31, MAE is:4.84 & sMAPE is:15.75% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 22.93% & 0.76\n",
      "for 2018-02-01, MAE is:2.61 & sMAPE is:9.14% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 22.50% & 0.75\n",
      "for 2018-02-02, MAE is:5.06 & sMAPE is:14.33% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 22.25% & 0.77\n",
      "for 2018-02-03, MAE is:3.97 & sMAPE is:11.89% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 21.95% & 0.77\n",
      "for 2018-02-04, MAE is:3.71 & sMAPE is:11.73% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 21.65% & 0.75\n",
      "for 2018-02-05, MAE is:8.81 & sMAPE is:15.96% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 21.50% & 0.74\n",
      "for 2018-02-06, MAE is:4.20 & sMAPE is:8.36% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 21.14% & 0.72\n",
      "for 2018-02-07, MAE is:4.13 & sMAPE is:8.79% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 20.82% & 0.71\n",
      "for 2018-02-08, MAE is:3.66 & sMAPE is:7.94% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 20.49% & 0.70\n",
      "for 2018-02-09, MAE is:2.90 & sMAPE is:7.15% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 20.15% & 0.73\n",
      "for 2018-02-10, MAE is:2.82 & sMAPE is:8.96% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 19.88% & 0.75\n",
      "for 2018-02-11, MAE is:8.75 & sMAPE is:44.13% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 20.46% & 0.75\n",
      "for 2018-02-12, MAE is:9.17 & sMAPE is:35.86% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 20.82% & 0.74\n",
      "for 2018-02-13, MAE is:5.71 & sMAPE is:16.20% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 20.71% & 0.74\n",
      "for 2018-02-14, MAE is:4.35 & sMAPE is:11.59% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 20.51% & 0.74\n",
      "for 2018-02-15, MAE is:2.93 & sMAPE is:10.72% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 20.29% & 0.72\n",
      "for 2018-02-16, MAE is:3.90 & sMAPE is:11.12% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 20.10% & 0.74\n",
      "for 2018-02-17, MAE is:6.39 & sMAPE is:17.99% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 20.06% & 0.76\n",
      "for 2018-02-18, MAE is:4.41 & sMAPE is:12.75% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 19.91% & 0.75\n",
      "for 2018-02-19, MAE is:8.12 & sMAPE is:17.51% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 19.86% & 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-02-20, MAE is:4.20 & sMAPE is:9.01% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 19.65% & 0.74\n",
      "for 2018-02-21, MAE is:3.98 & sMAPE is:8.97% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 19.44% & 0.73\n",
      "for 2018-02-22, MAE is:5.76 & sMAPE is:12.39% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 19.31% & 0.73\n",
      "for 2018-02-23, MAE is:6.70 & sMAPE is:14.07% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 19.21% & 0.73\n",
      "for 2018-02-24, MAE is:1.96 & sMAPE is:5.27% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 18.96% & 0.73\n",
      "for 2018-02-25, MAE is:4.16 & sMAPE is:10.72% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 18.81% & 0.75\n",
      "for 2018-02-26, MAE is:6.16 & sMAPE is:13.05% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 18.71% & 0.76\n",
      "for 2018-02-27, MAE is:6.39 & sMAPE is:12.73% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 18.61% & 0.76\n",
      "for 2018-02-28, MAE is:6.27 & sMAPE is:12.34% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 18.50% & 0.77\n",
      "for 2018-03-01, MAE is:50.01 & sMAPE is:53.10% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 19.08% & 0.78\n",
      "for 2018-03-02, MAE is:11.10 & sMAPE is:17.02% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 19.04% & 0.78\n",
      "for 2018-03-03, MAE is:8.26 & sMAPE is:20.93% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 19.07% & 0.79\n",
      "for 2018-03-04, MAE is:8.83 & sMAPE is:19.71% & rMAE is:3.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.08% & 0.83\n",
      "for 2018-03-05, MAE is:8.17 & sMAPE is:16.34% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.04% & 0.84\n",
      "for 2018-03-06, MAE is:3.59 & sMAPE is:6.89% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 18.85% & 0.84\n",
      "for 2018-03-07, MAE is:5.62 & sMAPE is:12.52% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 18.76% & 0.84\n",
      "for 2018-03-08, MAE is:3.33 & sMAPE is:7.50% & rMAE is:0.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 18.59% & 0.83\n",
      "for 2018-03-09, MAE is:4.80 & sMAPE is:12.87% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 18.51% & 0.82\n",
      "for 2018-03-10, MAE is:2.79 & sMAPE is:7.28% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 18.34% & 0.82\n",
      "for 2018-03-11, MAE is:4.18 & sMAPE is:12.10% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 18.25% & 0.81\n",
      "for 2018-03-12, MAE is:6.23 & sMAPE is:16.77% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 18.23% & 0.81\n",
      "for 2018-03-13, MAE is:2.63 & sMAPE is:6.46% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 18.07% & 0.80\n",
      "for 2018-03-14, MAE is:7.30 & sMAPE is:15.63% & rMAE is:4.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 18.04% & 0.85\n",
      "for 2018-03-15, MAE is:8.94 & sMAPE is:24.75% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 18.13% & 0.85\n",
      "for 2018-03-16, MAE is:6.75 & sMAPE is:25.23% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 18.22% & 0.85\n",
      "for 2018-03-17, MAE is:26.94 & sMAPE is:122.43% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 19.59% & 0.86\n",
      "for 2018-03-18, MAE is:18.67 & sMAPE is:101.80% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 20.66% & 0.87\n",
      "for 2018-03-19, MAE is:6.34 & sMAPE is:17.92% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 20.62% & 0.89\n",
      "for 2018-03-20, MAE is:8.55 & sMAPE is:21.69% & rMAE is:3.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 20.64% & 0.92\n",
      "for 2018-03-21, MAE is:6.10 & sMAPE is:13.69% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 20.55% & 0.92\n",
      "for 2018-03-22, MAE is:9.26 & sMAPE is:20.17% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 20.55% & 0.92\n",
      "for 2018-03-23, MAE is:7.18 & sMAPE is:15.27% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 20.48% & 0.91\n",
      "for 2018-03-24, MAE is:7.38 & sMAPE is:20.13% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 20.48% & 0.91\n",
      "for 2018-03-25, MAE is:4.55 & sMAPE is:12.17% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 20.38% & 0.90\n",
      "for 2018-03-26, MAE is:6.48 & sMAPE is:14.32% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 20.31% & 0.90\n",
      "for 2018-03-27, MAE is:4.64 & sMAPE is:10.09% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 20.19% & 0.90\n",
      "for 2018-03-28, MAE is:7.21 & sMAPE is:16.92% & rMAE is:2.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 20.15% & 0.92\n",
      "for 2018-03-29, MAE is:6.27 & sMAPE is:19.62% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 20.15% & 0.91\n",
      "for 2018-03-30, MAE is:4.33 & sMAPE is:11.66% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 20.05% & 0.91\n",
      "for 2018-03-31, MAE is:4.20 & sMAPE is:12.73% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 19.97% & 0.91\n",
      "for 2018-04-01, MAE is:4.12 & sMAPE is:11.26% & rMAE is:2.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 19.87% & 0.93\n",
      "for 2018-04-02, MAE is:2.44 & sMAPE is:6.60% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 19.73% & 0.92\n",
      "for 2018-04-03, MAE is:3.79 & sMAPE is:9.35% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 19.62% & 0.92\n",
      "for 2018-04-04, MAE is:5.56 & sMAPE is:16.38% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 19.58% & 0.92\n",
      "for 2018-04-05, MAE is:5.28 & sMAPE is:15.15% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 19.54% & 0.92\n",
      "for 2018-04-06, MAE is:4.80 & sMAPE is:13.07% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 19.47% & 0.92\n",
      "for 2018-04-07, MAE is:14.64 & sMAPE is:75.95% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 20.05% & 0.92\n",
      "for 2018-04-08, MAE is:10.42 & sMAPE is:31.87% & rMAE is:6.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 20.17% & 0.97\n",
      "for 2018-04-09, MAE is:5.40 & sMAPE is:12.63% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 20.10% & 0.97\n",
      "for 2018-04-10, MAE is:2.98 & sMAPE is:8.31% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 19.98% & 0.97\n",
      "for 2018-04-11, MAE is:4.97 & sMAPE is:16.37% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 19.94% & 0.97\n",
      "for 2018-04-12, MAE is:6.91 & sMAPE is:22.17% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 19.96% & 0.96\n",
      "for 2018-04-13, MAE is:9.56 & sMAPE is:28.55% & rMAE is:3.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 20.05% & 0.99\n",
      "for 2018-04-14, MAE is:3.63 & sMAPE is:9.98% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 19.95% & 0.98\n",
      "for 2018-04-15, MAE is:4.25 & sMAPE is:11.58% & rMAE is:4.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 19.87% & 1.01\n",
      "for 2018-04-16, MAE is:9.67 & sMAPE is:22.31% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 19.89% & 1.02\n",
      "for 2018-04-17, MAE is:3.93 & sMAPE is:9.62% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 19.80% & 1.02\n",
      "for 2018-04-18, MAE is:3.34 & sMAPE is:7.91% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 19.69% & 1.01\n",
      "for 2018-04-19, MAE is:2.69 & sMAPE is:6.66% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 19.57% & 1.00\n",
      "for 2018-04-20, MAE is:3.05 & sMAPE is:8.46% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 19.47% & 1.00\n",
      "for 2018-04-21, MAE is:2.63 & sMAPE is:8.24% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 19.37% & 1.00\n",
      "for 2018-04-22, MAE is:2.27 & sMAPE is:6.96% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 19.26% & 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-04-23, MAE is:5.64 & sMAPE is:20.61% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.27% & 0.99\n",
      "for 2018-04-24, MAE is:5.65 & sMAPE is:16.25% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.24% & 0.98\n",
      "for 2018-04-25, MAE is:2.98 & sMAPE is:9.16% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.15% & 0.98\n",
      "for 2018-04-26, MAE is:5.32 & sMAPE is:16.64% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 19.13% & 0.98\n",
      "for 2018-04-27, MAE is:8.23 & sMAPE is:23.21% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 19.17% & 0.99\n",
      "for 2018-04-28, MAE is:2.60 & sMAPE is:7.96% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 19.07% & 0.99\n",
      "for 2018-04-29, MAE is:2.64 & sMAPE is:8.23% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 18.98% & 0.99\n",
      "for 2018-04-30, MAE is:17.78 & sMAPE is:82.03% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 19.51% & 0.99\n",
      "for 2018-05-01, MAE is:8.33 & sMAPE is:45.78% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 19.72% & 0.99\n",
      "for 2018-05-02, MAE is:10.36 & sMAPE is:32.81% & rMAE is:2.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 19.83% & 1.00\n",
      "for 2018-05-03, MAE is:5.09 & sMAPE is:13.41% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 19.78% & 1.00\n",
      "for 2018-05-04, MAE is:13.44 & sMAPE is:26.67% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 19.83% & 1.00\n",
      "for 2018-05-05, MAE is:3.76 & sMAPE is:11.87% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 19.77% & 1.00\n",
      "for 2018-05-06, MAE is:7.43 & sMAPE is:29.66% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 19.85% & 1.00\n",
      "for 2018-05-07, MAE is:6.59 & sMAPE is:19.56% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 19.85% & 0.99\n",
      "for 2018-05-08, MAE is:4.97 & sMAPE is:16.91% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 19.82% & 0.99\n",
      "for 2018-05-09, MAE is:10.34 & sMAPE is:36.70% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 19.95% & 0.99\n",
      "for 2018-05-10, MAE is:5.77 & sMAPE is:48.98% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 20.18% & 0.99\n",
      "for 2018-05-11, MAE is:21.12 & sMAPE is:79.96% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 20.63% & 0.99\n",
      "for 2018-05-12, MAE is:6.19 & sMAPE is:18.38% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 20.62% & 1.00\n",
      "for 2018-05-13, MAE is:3.73 & sMAPE is:20.83% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 20.62% & 1.00\n",
      "for 2018-05-14, MAE is:14.62 & sMAPE is:50.18% & rMAE is:2.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 20.84% & 1.01\n",
      "for 2018-05-15, MAE is:13.09 & sMAPE is:24.12% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 20.86% & 1.00\n",
      "for 2018-05-16, MAE is:36.11 & sMAPE is:47.31% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 21.06% & 1.00\n",
      "for 2018-05-17, MAE is:13.72 & sMAPE is:44.92% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 21.23% & 1.00\n",
      "for 2018-05-18, MAE is:8.48 & sMAPE is:33.24% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 21.32% & 1.01\n",
      "for 2018-05-19, MAE is:5.64 & sMAPE is:17.83% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 21.29% & 1.01\n",
      "for 2018-05-20, MAE is:4.18 & sMAPE is:16.23% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 21.26% & 1.00\n",
      "for 2018-05-21, MAE is:12.50 & sMAPE is:63.64% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 21.56% & 1.01\n",
      "for 2018-05-22, MAE is:18.30 & sMAPE is:39.22% & rMAE is:2.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 21.68% & 1.02\n",
      "for 2018-05-23, MAE is:13.17 & sMAPE is:21.24% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 21.68% & 1.01\n",
      "for 2018-05-24, MAE is:11.83 & sMAPE is:25.95% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 21.71% & 1.01\n",
      "for 2018-05-25, MAE is:3.45 & sMAPE is:9.33% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 21.62% & 1.01\n",
      "for 2018-05-26, MAE is:2.09 & sMAPE is:5.51% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 21.51% & 1.01\n",
      "for 2018-05-27, MAE is:3.12 & sMAPE is:8.61% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 21.43% & 1.00\n",
      "for 2018-05-28, MAE is:4.63 & sMAPE is:11.38% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 21.36% & 1.00\n",
      "for 2018-05-29, MAE is:4.40 & sMAPE is:9.52% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 21.28% & 0.99\n",
      "for 2018-05-30, MAE is:4.81 & sMAPE is:10.72% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 21.21% & 0.99\n",
      "for 2018-05-31, MAE is:4.29 & sMAPE is:10.43% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 21.14% & 0.98\n",
      "for 2018-06-01, MAE is:13.31 & sMAPE is:25.20% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 21.16% & 0.98\n",
      "for 2018-06-02, MAE is:1.63 & sMAPE is:3.58% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 21.05% & 0.98\n",
      "for 2018-06-03, MAE is:1.77 & sMAPE is:4.34% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 20.94% & 0.97\n",
      "for 2018-06-04, MAE is:4.28 & sMAPE is:9.26% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 20.86% & 0.98\n",
      "for 2018-06-05, MAE is:4.54 & sMAPE is:9.51% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 20.79% & 0.97\n",
      "for 2018-06-06, MAE is:4.59 & sMAPE is:9.32% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 20.72% & 0.98\n",
      "for 2018-06-07, MAE is:6.23 & sMAPE is:12.99% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 20.67% & 0.98\n",
      "for 2018-06-08, MAE is:3.94 & sMAPE is:8.48% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 20.59% & 0.97\n",
      "for 2018-06-09, MAE is:2.60 & sMAPE is:5.76% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 20.50% & 0.97\n",
      "for 2018-06-10, MAE is:5.70 & sMAPE is:13.30% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 20.46% & 0.97\n",
      "for 2018-06-11, MAE is:13.10 & sMAPE is:17.49% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 20.44% & 0.97\n",
      "for 2018-06-12, MAE is:50.33 & sMAPE is:52.10% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 20.63% & 0.97\n",
      "for 2018-06-13, MAE is:9.53 & sMAPE is:15.89% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 20.60% & 0.98\n",
      "for 2018-06-14, MAE is:6.00 & sMAPE is:12.20% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 20.55% & 0.98\n",
      "for 2018-06-15, MAE is:5.56 & sMAPE is:11.43% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 20.50% & 0.99\n",
      "for 2018-06-16, MAE is:3.15 & sMAPE is:7.61% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 20.42% & 0.99\n",
      "for 2018-06-17, MAE is:1.98 & sMAPE is:4.76% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 20.33% & 0.99\n",
      "for 2018-06-18, MAE is:5.24 & sMAPE is:12.42% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 20.28% & 0.98\n",
      "for 2018-06-19, MAE is:4.79 & sMAPE is:10.95% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 20.22% & 0.98\n",
      "for 2018-06-20, MAE is:10.01 & sMAPE is:19.79% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 20.22% & 0.98\n",
      "for 2018-06-21, MAE is:5.06 & sMAPE is:12.10% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 20.17% & 0.98\n",
      "for 2018-06-22, MAE is:6.96 & sMAPE is:31.53% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 20.24% & 0.97\n",
      "for 2018-06-23, MAE is:8.77 & sMAPE is:29.08% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 20.29% & 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-06-24, MAE is:4.84 & sMAPE is:13.15% & rMAE is:3.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 20.25% & 0.99\n",
      "for 2018-06-25, MAE is:12.48 & sMAPE is:25.07% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 20.28% & 0.99\n",
      "for 2018-06-26, MAE is:21.70 & sMAPE is:35.76% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 20.37% & 0.99\n",
      "for 2018-06-27, MAE is:14.12 & sMAPE is:26.35% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 20.40% & 0.99\n",
      "for 2018-06-28, MAE is:3.97 & sMAPE is:8.36% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 20.33% & 0.99\n",
      "for 2018-06-29, MAE is:5.30 & sMAPE is:10.25% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 20.28% & 0.98\n",
      "for 2018-06-30, MAE is:5.66 & sMAPE is:13.52% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 20.24% & 0.98\n",
      "for 2018-07-01, MAE is:5.13 & sMAPE is:12.11% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 20.19% & 0.98\n",
      "for 2018-07-02, MAE is:4.45 & sMAPE is:9.25% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 20.13% & 0.98\n",
      "for 2018-07-03, MAE is:8.21 & sMAPE is:16.97% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 20.12% & 0.98\n",
      "for 2018-07-04, MAE is:4.09 & sMAPE is:7.95% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 20.05% & 0.98\n",
      "for 2018-07-05, MAE is:3.88 & sMAPE is:7.48% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 19.98% & 0.97\n",
      "for 2018-07-06, MAE is:3.91 & sMAPE is:7.80% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 19.92% & 0.97\n",
      "for 2018-07-07, MAE is:2.24 & sMAPE is:4.95% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 19.84% & 0.97\n",
      "for 2018-07-08, MAE is:3.98 & sMAPE is:8.76% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 19.78% & 0.97\n",
      "for 2018-07-09, MAE is:2.75 & sMAPE is:5.67% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 19.71% & 0.97\n",
      "for 2018-07-10, MAE is:4.25 & sMAPE is:8.45% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 19.65% & 0.98\n",
      "for 2018-07-11, MAE is:4.86 & sMAPE is:9.75% & rMAE is:3.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 19.59% & 0.99\n",
      "for 2018-07-12, MAE is:4.68 & sMAPE is:9.22% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 19.54% & 0.99\n",
      "for 2018-07-13, MAE is:3.45 & sMAPE is:6.82% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 19.48% & 0.99\n",
      "for 2018-07-14, MAE is:3.62 & sMAPE is:7.42% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 19.41% & 0.99\n",
      "for 2018-07-15, MAE is:3.84 & sMAPE is:7.78% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 19.35% & 0.99\n",
      "for 2018-07-16, MAE is:3.05 & sMAPE is:5.74% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 19.29% & 0.99\n",
      "for 2018-07-17, MAE is:2.72 & sMAPE is:5.06% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 19.21% & 0.99\n",
      "for 2018-07-18, MAE is:2.36 & sMAPE is:4.70% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 19.14% & 1.00\n",
      "for 2018-07-19, MAE is:3.75 & sMAPE is:7.33% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 19.08% & 1.00\n",
      "for 2018-07-20, MAE is:3.35 & sMAPE is:6.48% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 19.02% & 1.00\n",
      "for 2018-07-21, MAE is:3.54 & sMAPE is:7.05% & rMAE is:2.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 18.96% & 1.01\n",
      "for 2018-07-22, MAE is:6.15 & sMAPE is:12.44% & rMAE is:3.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 18.93% & 1.02\n",
      "for 2018-07-23, MAE is:8.46 & sMAPE is:13.43% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 18.90% & 1.02\n",
      "for 2018-07-24, MAE is:4.39 & sMAPE is:7.81% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 18.85% & 1.03\n",
      "for 2018-07-25, MAE is:6.64 & sMAPE is:11.63% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 18.81% & 1.02\n",
      "for 2018-07-26, MAE is:2.16 & sMAPE is:3.73% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 18.74% & 1.02\n",
      "for 2018-07-27, MAE is:5.00 & sMAPE is:8.15% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 18.69% & 1.02\n",
      "for 2018-07-28, MAE is:3.05 & sMAPE is:6.37% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 18.63% & 1.02\n",
      "for 2018-07-29, MAE is:2.10 & sMAPE is:4.12% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 18.56% & 1.02\n",
      "for 2018-07-30, MAE is:4.34 & sMAPE is:7.22% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 18.51% & 1.02\n",
      "for 2018-07-31, MAE is:6.12 & sMAPE is:11.05% & rMAE is:3.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 18.47% & 1.03\n",
      "for 2018-08-01, MAE is:3.25 & sMAPE is:5.73% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 18.41% & 1.03\n",
      "for 2018-08-02, MAE is:4.66 & sMAPE is:7.89% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 18.36% & 1.03\n",
      "for 2018-08-03, MAE is:12.76 & sMAPE is:18.05% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 18.36% & 1.03\n",
      "for 2018-08-04, MAE is:2.50 & sMAPE is:4.92% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 18.30% & 1.03\n",
      "for 2018-08-05, MAE is:3.64 & sMAPE is:7.85% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 18.25% & 1.03\n",
      "for 2018-08-06, MAE is:6.24 & sMAPE is:9.71% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 18.21% & 1.03\n",
      "for 2018-08-07, MAE is:4.22 & sMAPE is:6.38% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 18.16% & 1.03\n",
      "for 2018-08-08, MAE is:5.82 & sMAPE is:9.80% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 18.12% & 1.03\n",
      "for 2018-08-09, MAE is:3.87 & sMAPE is:6.83% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 18.07% & 1.03\n",
      "for 2018-08-10, MAE is:6.71 & sMAPE is:18.68% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 18.07% & 1.03\n",
      "for 2018-08-11, MAE is:3.25 & sMAPE is:7.10% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 18.02% & 1.03\n",
      "for 2018-08-12, MAE is:4.61 & sMAPE is:9.42% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 17.98% & 1.03\n",
      "for 2018-08-13, MAE is:7.08 & sMAPE is:12.75% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 17.96% & 1.03\n",
      "for 2018-08-14, MAE is:4.96 & sMAPE is:8.89% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 17.92% & 1.02\n",
      "for 2018-08-15, MAE is:3.68 & sMAPE is:6.56% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 17.87% & 1.02\n",
      "for 2018-08-16, MAE is:5.83 & sMAPE is:10.01% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 17.83% & 1.02\n",
      "for 2018-08-17, MAE is:3.03 & sMAPE is:5.03% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 17.78% & 1.02\n",
      "for 2018-08-18, MAE is:3.13 & sMAPE is:6.50% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 17.73% & 1.02\n",
      "for 2018-08-19, MAE is:5.49 & sMAPE is:10.99% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 17.70% & 1.03\n",
      "for 2018-08-20, MAE is:6.46 & sMAPE is:11.09% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 17.67% & 1.03\n",
      "for 2018-08-21, MAE is:14.39 & sMAPE is:24.16% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 17.70% & 1.03\n",
      "for 2018-08-22, MAE is:3.95 & sMAPE is:6.43% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 17.65% & 1.03\n",
      "for 2018-08-23, MAE is:8.15 & sMAPE is:13.64% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 17.63% & 1.03\n",
      "for 2018-08-24, MAE is:7.39 & sMAPE is:12.75% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 17.61% & 1.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-08-25, MAE is:5.57 & sMAPE is:11.37% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 17.59% & 1.03\n",
      "for 2018-08-26, MAE is:6.70 & sMAPE is:13.20% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 17.57% & 1.03\n",
      "for 2018-08-27, MAE is:6.04 & sMAPE is:13.98% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 17.55% & 1.03\n",
      "for 2018-08-28, MAE is:12.17 & sMAPE is:20.47% & rMAE is:4.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 17.57% & 1.05\n",
      "for 2018-08-29, MAE is:6.04 & sMAPE is:9.57% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 17.53% & 1.05\n",
      "for 2018-08-30, MAE is:6.79 & sMAPE is:11.50% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 17.51% & 1.05\n",
      "for 2018-08-31, MAE is:7.58 & sMAPE is:12.94% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 17.49% & 1.05\n",
      "for 2018-09-01, MAE is:5.59 & sMAPE is:9.54% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 17.46% & 1.05\n",
      "for 2018-09-02, MAE is:5.12 & sMAPE is:9.42% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 17.42% & 1.05\n",
      "for 2018-09-03, MAE is:7.93 & sMAPE is:13.36% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 17.41% & 1.04\n",
      "for 2018-09-04, MAE is:6.22 & sMAPE is:9.93% & rMAE is:2.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 17.38% & 1.05\n",
      "for 2018-09-05, MAE is:6.18 & sMAPE is:9.41% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 17.35% & 1.06\n",
      "for 2018-09-06, MAE is:4.30 & sMAPE is:6.63% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 17.30% & 1.06\n",
      "for 2018-09-07, MAE is:4.88 & sMAPE is:8.28% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 17.27% & 1.06\n",
      "for 2018-09-08, MAE is:4.91 & sMAPE is:9.67% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 17.24% & 1.06\n",
      "for 2018-09-09, MAE is:3.97 & sMAPE is:7.23% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 17.20% & 1.06\n",
      "for 2018-09-10, MAE is:7.26 & sMAPE is:11.76% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 17.17% & 1.06\n",
      "for 2018-09-11, MAE is:5.71 & sMAPE is:9.28% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 17.14% & 1.06\n",
      "for 2018-09-12, MAE is:5.62 & sMAPE is:9.80% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 17.11% & 1.05\n",
      "for 2018-09-13, MAE is:14.02 & sMAPE is:21.66% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 17.13% & 1.06\n",
      "for 2018-09-14, MAE is:5.28 & sMAPE is:8.48% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 17.10% & 1.06\n",
      "for 2018-09-15, MAE is:5.89 & sMAPE is:11.44% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 17.08% & 1.06\n",
      "for 2018-09-16, MAE is:4.42 & sMAPE is:8.08% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 17.04% & 1.06\n",
      "for 2018-09-17, MAE is:8.54 & sMAPE is:13.44% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 17.03% & 1.06\n",
      "for 2018-09-18, MAE is:3.62 & sMAPE is:6.37% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 16.99% & 1.06\n",
      "for 2018-09-19, MAE is:5.27 & sMAPE is:9.71% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 16.96% & 1.06\n",
      "for 2018-09-20, MAE is:7.99 & sMAPE is:15.02% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 16.95% & 1.06\n",
      "for 2018-09-21, MAE is:15.74 & sMAPE is:38.51% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 17.03% & 1.06\n",
      "for 2018-09-22, MAE is:6.52 & sMAPE is:45.55% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 17.14% & 1.05\n",
      "for 2018-09-23, MAE is:10.51 & sMAPE is:33.34% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 17.20% & 1.05\n",
      "for 2018-09-24, MAE is:6.11 & sMAPE is:23.90% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 17.23% & 1.05\n",
      "for 2018-09-25, MAE is:13.31 & sMAPE is:26.40% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 17.26% & 1.05\n",
      "for 2018-09-26, MAE is:11.47 & sMAPE is:39.82% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 17.35% & 1.05\n",
      "for 2018-09-27, MAE is:6.01 & sMAPE is:19.22% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 17.35% & 1.05\n",
      "for 2018-09-28, MAE is:3.00 & sMAPE is:7.85% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 17.32% & 1.05\n",
      "for 2018-09-29, MAE is:7.73 & sMAPE is:20.35% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 17.33% & 1.05\n",
      "for 2018-09-30, MAE is:14.09 & sMAPE is:34.65% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 17.39% & 1.05\n",
      "for 2018-10-01, MAE is:6.00 & sMAPE is:10.43% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 17.37% & 1.04\n",
      "for 2018-10-02, MAE is:14.32 & sMAPE is:35.66% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 17.43% & 1.04\n",
      "for 2018-10-03, MAE is:21.08 & sMAPE is:88.66% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 17.69% & 1.05\n",
      "for 2018-10-04, MAE is:13.23 & sMAPE is:22.51% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 17.71% & 1.04\n",
      "for 2018-10-05, MAE is:10.76 & sMAPE is:18.00% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 17.71% & 1.04\n",
      "for 2018-10-06, MAE is:12.53 & sMAPE is:23.82% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 17.73% & 1.04\n",
      "for 2018-10-07, MAE is:6.52 & sMAPE is:11.81% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 17.71% & 1.04\n",
      "for 2018-10-08, MAE is:9.06 & sMAPE is:14.58% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 17.70% & 1.04\n",
      "for 2018-10-09, MAE is:15.60 & sMAPE is:23.09% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 17.72% & 1.04\n",
      "for 2018-10-10, MAE is:8.20 & sMAPE is:13.07% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 17.70% & 1.03\n",
      "for 2018-10-11, MAE is:9.83 & sMAPE is:18.63% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 17.71% & 1.03\n",
      "for 2018-10-12, MAE is:7.35 & sMAPE is:12.88% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 17.69% & 1.03\n",
      "for 2018-10-13, MAE is:8.35 & sMAPE is:23.59% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 17.71% & 1.03\n",
      "for 2018-10-14, MAE is:7.94 & sMAPE is:51.42% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 17.83% & 1.03\n",
      "for 2018-10-15, MAE is:31.53 & sMAPE is:80.72% & rMAE is:2.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 18.05% & 1.04\n",
      "for 2018-10-16, MAE is:20.10 & sMAPE is:32.11% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 18.09% & 1.04\n",
      "for 2018-10-17, MAE is:19.62 & sMAPE is:30.53% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 18.14% & 1.04\n",
      "for 2018-10-18, MAE is:8.33 & sMAPE is:13.72% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 18.12% & 1.04\n",
      "for 2018-10-19, MAE is:7.31 & sMAPE is:10.60% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 18.10% & 1.04\n",
      "for 2018-10-20, MAE is:5.01 & sMAPE is:9.33% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 18.07% & 1.04\n",
      "for 2018-10-21, MAE is:6.00 & sMAPE is:12.52% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 18.05% & 1.03\n",
      "for 2018-10-22, MAE is:8.95 & sMAPE is:22.20% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 18.06% & 1.03\n",
      "for 2018-10-23, MAE is:12.32 & sMAPE is:37.61% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 18.13% & 1.03\n",
      "for 2018-10-24, MAE is:17.76 & sMAPE is:64.77% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 18.28% & 1.03\n",
      "for 2018-10-25, MAE is:4.89 & sMAPE is:11.40% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 18.26% & 1.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-10-26, MAE is:9.81 & sMAPE is:17.38% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 18.26% & 1.02\n",
      "for 2018-10-27, MAE is:8.93 & sMAPE is:21.38% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 18.27% & 1.02\n",
      "for 2018-10-28, MAE is:5.33 & sMAPE is:11.36% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 18.25% & 1.02\n",
      "for 2018-10-29, MAE is:8.73 & sMAPE is:21.13% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 18.26% & 1.03\n",
      "for 2018-10-30, MAE is:6.49 & sMAPE is:20.24% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 18.26% & 1.03\n",
      "for 2018-10-31, MAE is:12.82 & sMAPE is:28.73% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 18.30% & 1.03\n",
      "for 2018-11-01, MAE is:4.38 & sMAPE is:8.67% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 18.26% & 1.03\n",
      "for 2018-11-02, MAE is:5.44 & sMAPE is:12.73% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 18.25% & 1.02\n",
      "for 2018-11-03, MAE is:11.96 & sMAPE is:25.40% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 18.27% & 1.02\n",
      "for 2018-11-04, MAE is:5.81 & sMAPE is:12.98% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 18.25% & 1.03\n",
      "for 2018-11-05, MAE is:6.43 & sMAPE is:11.46% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 18.23% & 1.02\n",
      "for 2018-11-06, MAE is:9.38 & sMAPE is:17.40% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 18.23% & 1.02\n",
      "for 2018-11-07, MAE is:6.88 & sMAPE is:13.06% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 18.21% & 1.02\n",
      "for 2018-11-08, MAE is:13.05 & sMAPE is:22.43% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 18.22% & 1.02\n",
      "for 2018-11-09, MAE is:5.53 & sMAPE is:10.10% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 18.20% & 1.02\n",
      "for 2018-11-10, MAE is:4.25 & sMAPE is:9.17% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 18.17% & 1.02\n",
      "for 2018-11-11, MAE is:4.64 & sMAPE is:12.36% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 18.15% & 1.02\n",
      "for 2018-11-12, MAE is:6.74 & sMAPE is:13.24% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 18.14% & 1.02\n",
      "for 2018-11-13, MAE is:4.05 & sMAPE is:8.43% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 18.11% & 1.01\n",
      "for 2018-11-14, MAE is:11.17 & sMAPE is:20.09% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 18.11% & 1.02\n",
      "for 2018-11-15, MAE is:7.76 & sMAPE is:13.53% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 18.10% & 1.02\n",
      "for 2018-11-16, MAE is:6.32 & sMAPE is:11.66% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 18.08% & 1.03\n",
      "for 2018-11-17, MAE is:4.56 & sMAPE is:9.58% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 18.05% & 1.03\n",
      "for 2018-11-18, MAE is:3.18 & sMAPE is:7.02% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 18.02% & 1.02\n",
      "for 2018-11-19, MAE is:5.33 & sMAPE is:10.85% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 17.99% & 1.02\n",
      "for 2018-11-20, MAE is:5.43 & sMAPE is:12.15% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 17.98% & 1.02\n",
      "for 2018-11-21, MAE is:4.66 & sMAPE is:8.49% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 17.95% & 1.02\n",
      "for 2018-11-22, MAE is:22.26 & sMAPE is:31.08% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 17.99% & 1.02\n",
      "for 2018-11-23, MAE is:14.39 & sMAPE is:18.19% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 17.99% & 1.02\n",
      "for 2018-11-24, MAE is:6.70 & sMAPE is:11.47% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 17.97% & 1.02\n",
      "for 2018-11-25, MAE is:3.84 & sMAPE is:7.17% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 17.94% & 1.02\n",
      "for 2018-11-26, MAE is:17.75 & sMAPE is:25.30% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 17.96% & 1.02\n",
      "for 2018-11-27, MAE is:8.07 & sMAPE is:10.47% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 17.93% & 1.02\n",
      "for 2018-11-28, MAE is:8.65 & sMAPE is:15.36% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 17.93% & 1.02\n",
      "for 2018-11-29, MAE is:3.84 & sMAPE is:8.33% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 17.90% & 1.02\n",
      "for 2018-11-30, MAE is:3.69 & sMAPE is:8.00% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 17.87% & 1.01\n",
      "for 2018-12-01, MAE is:2.74 & sMAPE is:6.37% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 17.83% & 1.01\n",
      "for 2018-12-02, MAE is:6.28 & sMAPE is:17.69% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 17.83% & 1.01\n",
      "for 2018-12-03, MAE is:4.23 & sMAPE is:9.89% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 17.81% & 1.01\n",
      "for 2018-12-04, MAE is:5.29 & sMAPE is:11.76% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 17.79% & 1.00\n",
      "for 2018-12-05, MAE is:15.57 & sMAPE is:29.87% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 17.83% & 1.01\n",
      "for 2018-12-06, MAE is:6.62 & sMAPE is:12.47% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 17.81% & 1.01\n",
      "for 2018-12-07, MAE is:5.92 & sMAPE is:14.92% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 17.80% & 1.01\n",
      "for 2018-12-08, MAE is:17.27 & sMAPE is:94.07% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 18.03% & 1.00\n",
      "for 2018-12-09, MAE is:19.57 & sMAPE is:103.68% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 18.28% & 1.01\n",
      "for 2018-12-10, MAE is:11.08 & sMAPE is:54.63% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 18.38% & 1.01\n",
      "for 2018-12-11, MAE is:20.93 & sMAPE is:45.57% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 18.46% & 1.01\n",
      "for 2018-12-12, MAE is:16.04 & sMAPE is:25.00% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 18.48% & 1.01\n",
      "for 2018-12-13, MAE is:11.93 & sMAPE is:19.99% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 18.48% & 1.01\n",
      "for 2018-12-14, MAE is:10.98 & sMAPE is:15.35% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 18.48% & 1.01\n",
      "for 2018-12-15, MAE is:7.00 & sMAPE is:13.81% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 18.46% & 1.01\n",
      "for 2018-12-16, MAE is:3.68 & sMAPE is:7.77% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 18.43% & 1.00\n",
      "for 2018-12-17, MAE is:13.22 & sMAPE is:20.47% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 18.44% & 1.00\n",
      "for 2018-12-18, MAE is:5.77 & sMAPE is:9.87% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 18.41% & 1.00\n",
      "for 2018-12-19, MAE is:3.72 & sMAPE is:7.51% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 18.38% & 1.00\n",
      "for 2018-12-20, MAE is:4.49 & sMAPE is:7.98% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 18.35% & 1.00\n",
      "for 2018-12-21, MAE is:5.85 & sMAPE is:10.10% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 18.33% & 1.00\n",
      "for 2018-12-22, MAE is:2.61 & sMAPE is:4.92% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 18.29% & 0.99\n",
      "for 2018-12-23, MAE is:5.05 & sMAPE is:10.33% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 18.27% & 0.99\n",
      "for 2018-12-24, MAE is:4.56 & sMAPE is:9.02% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 18.24% & 0.99\n",
      "for 2018-12-25, MAE is:21.45 & sMAPE is:86.88% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 18.43% & 0.99\n",
      "for 2018-12-26, MAE is:10.50 & sMAPE is:25.70% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 18.45% & 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-12-27, MAE is:6.17 & sMAPE is:11.20% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 18.43% & 0.99\n",
      "for 2018-12-28, MAE is:12.11 & sMAPE is:25.97% & rMAE is:4.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 18.46% & 1.00\n",
      "for 2018-12-29, MAE is:6.52 & sMAPE is:16.02% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 18.45% & 1.00\n",
      "for 2018-12-30, MAE is:17.77 & sMAPE is:71.51% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 18.59% & 1.00\n",
      "for 2018-12-31, MAE is:10.23 & sMAPE is:22.02% & rMAE is:3.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 18.60% & 1.01\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:29:08,014]\u001b[0m A new study created in RDB with name: DK_2_2019\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:29:31,761]\u001b[0m Trial 1 finished with value: 17.70321866125146 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005830317236332878, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2692542320998711, 'dropout_rate_Layer_2': 0.3594946974051636, 'dropout_rate_Layer_3': 0.007734622981173667, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.018916809647468474, 'l1_Layer_2': 0.07972285552101199, 'l1_Layer_3': 0.019799524833383552, 'n_units_Layer_1': 65, 'n_units_Layer_2': 255, 'n_units_Layer_3': 150}. Best is trial 1 with value: 17.70321866125146.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.70 | sMAPE for Validation Set is: 43.95% | rMAE for Validation Set is: 1.68\n",
      "MAE for Test Set is: 11.53 | sMAPE for Test Set is: 33.01% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:29:37,632]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:29:39,775]\u001b[0m Trial 3 finished with value: 8.9676612441411 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023385926420708314, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11954931906314675, 'dropout_rate_Layer_2': 0.06766051565959845, 'dropout_rate_Layer_3': 0.31495165641068257, 'dropout_rate_Layer_4': 0.1556434931665004, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00019409994217606434, 'l1_Layer_2': 0.011232859359092, 'l1_Layer_3': 0.05568613727148557, 'l1_Layer_4': 0.002149386134002587, 'n_units_Layer_1': 75, 'n_units_Layer_2': 75, 'n_units_Layer_3': 160, 'n_units_Layer_4': 150}. Best is trial 3 with value: 8.9676612441411.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.97 | sMAPE for Validation Set is: 21.52% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 7.54 | sMAPE for Test Set is: 21.30% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:29:43,369]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:29:47,545]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:29:52,424]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:29:55,057]\u001b[0m Trial 5 finished with value: 12.104483376064337 and parameters: {'n_hidden': 3, 'learning_rate': 0.018066489005067965, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32827046235618706, 'dropout_rate_Layer_2': 0.22400238658823401, 'dropout_rate_Layer_3': 0.36145466761643763, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.021490811198626465, 'l1_Layer_2': 0.00010960871298150439, 'l1_Layer_3': 0.0022682585572708115, 'n_units_Layer_1': 235, 'n_units_Layer_2': 230, 'n_units_Layer_3': 225}. Best is trial 3 with value: 8.9676612441411.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.10 | sMAPE for Validation Set is: 28.86% | rMAE for Validation Set is: 1.15\n",
      "MAE for Test Set is: 7.37 | sMAPE for Test Set is: 21.27% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:29:56,155]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:29:59,759]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:30:02,930]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:30:06,232]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:30:06,625]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:30:12,487]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:30:13,701]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:30:17,001]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:30:17,382]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.88 | sMAPE for Validation Set is: 26.19% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 7.11 | sMAPE for Test Set is: 20.70% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:30:18,377]\u001b[0m Trial 2 finished with value: 10.883571475502277 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008125566193880673, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15292484931403855, 'dropout_rate_Layer_2': 0.05638121982032845, 'dropout_rate_Layer_3': 0.05677127706166374, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.04143336954049141, 'l1_Layer_2': 2.6350620109669428e-05, 'l1_Layer_3': 0.0004579716833250831, 'n_units_Layer_1': 250, 'n_units_Layer_2': 160, 'n_units_Layer_3': 115}. Best is trial 3 with value: 8.9676612441411.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:30:24,478]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:30:25,719]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:30:31,434]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:30:35,195]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:30:39,741]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:30:43,611]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:30:53,481]\u001b[0m Trial 20 finished with value: 6.969647840689902 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021755724897883633, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23566175564142502, 'dropout_rate_Layer_2': 0.2002029707299843, 'dropout_rate_Layer_3': 0.3108296666635888, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005108372208967066, 'l1_Layer_2': 0.00980174346868146, 'l1_Layer_3': 0.0055642809843974945, 'n_units_Layer_1': 65, 'n_units_Layer_2': 60, 'n_units_Layer_3': 300}. Best is trial 20 with value: 6.969647840689902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.97 | sMAPE for Validation Set is: 17.34% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.92 | sMAPE for Test Set is: 17.76% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:30:58,075]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:31:01,484]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:31:10,539]\u001b[0m Trial 0 finished with value: 9.25553694942588 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009882194046801547, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16647292110349074, 'dropout_rate_Layer_2': 0.18679372602715105, 'dropout_rate_Layer_3': 0.33029543381436044, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.006268031041189396, 'l1_Layer_2': 0.007750007160307826, 'l1_Layer_3': 0.0001649135394404598, 'n_units_Layer_1': 185, 'n_units_Layer_2': 200, 'n_units_Layer_3': 225}. Best is trial 20 with value: 6.969647840689902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.26 | sMAPE for Validation Set is: 22.42% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 6.33 | sMAPE for Test Set is: 18.69% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:31:14,329]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:31:20,683]\u001b[0m Trial 29 finished with value: 7.485049641927081 and parameters: {'n_hidden': 3, 'learning_rate': 0.005503605100557268, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3471493070769647, 'dropout_rate_Layer_2': 0.06117109730230266, 'dropout_rate_Layer_3': 0.3012898630471754, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04043968856803109, 'l1_Layer_2': 9.858416867002004e-05, 'l1_Layer_3': 2.8221062762557964e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 125, 'n_units_Layer_3': 120}. Best is trial 20 with value: 6.969647840689902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.49 | sMAPE for Validation Set is: 18.32% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.32 | sMAPE for Test Set is: 18.54% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:31:28,511]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:31:34,255]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:31:34,776]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:31:40,034]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:31:41,187]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:31:45,146]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:31:47,859]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:31:50,717]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:31:53,802]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:31:57,099]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:32:11,386]\u001b[0m Trial 40 finished with value: 8.564869810296726 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031629299824491256, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15853316928927685, 'dropout_rate_Layer_2': 0.1425996598920317, 'dropout_rate_Layer_3': 0.0667944672838662, 'dropout_rate_Layer_4': 0.03614005567165921, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.540351662529957e-05, 'l1_Layer_2': 2.2068797675170755e-05, 'l1_Layer_3': 0.0022177492224394737, 'l1_Layer_4': 0.03596792694944262, 'n_units_Layer_1': 270, 'n_units_Layer_2': 105, 'n_units_Layer_3': 285, 'n_units_Layer_4': 300}. Best is trial 20 with value: 6.969647840689902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.56 | sMAPE for Validation Set is: 21.64% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 6.99 | sMAPE for Test Set is: 21.30% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:32:24,014]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:32:27,544]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:32:30,371]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:32:33,946]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:32:36,282]\u001b[0m Trial 21 finished with value: 7.377709331388135 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024446475412669313, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28484042020007994, 'dropout_rate_Layer_2': 0.29667362714366524, 'dropout_rate_Layer_3': 0.01003696522750035, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0025909155429415455, 'l1_Layer_2': 0.004008249048301957, 'l1_Layer_3': 0.03163516578496759, 'n_units_Layer_1': 75, 'n_units_Layer_2': 220, 'n_units_Layer_3': 85}. Best is trial 20 with value: 6.969647840689902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.38 | sMAPE for Validation Set is: 18.04% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.22 | sMAPE for Test Set is: 18.29% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:32:38,278]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:32:42,338]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:32:45,864]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:32:48,619]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:32:52,470]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:32:56,198]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:33:01,038]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:33:05,046]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.28 | sMAPE for Validation Set is: 21.99% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 7.35 | sMAPE for Test Set is: 20.52% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:33:08,025]\u001b[0m Trial 51 finished with value: 9.278384850642313 and parameters: {'n_hidden': 3, 'learning_rate': 0.02865866852444908, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0315639751513273, 'dropout_rate_Layer_2': 0.3562293915354736, 'dropout_rate_Layer_3': 0.08277040396998721, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.04751248696418e-05, 'l1_Layer_2': 5.504148080566379e-05, 'l1_Layer_3': 0.08739208809151776, 'n_units_Layer_1': 150, 'n_units_Layer_2': 140, 'n_units_Layer_3': 260}. Best is trial 20 with value: 6.969647840689902.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:33:08,742]\u001b[0m Trial 42 finished with value: 10.825466590855596 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021740590376626164, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03170296813144802, 'dropout_rate_Layer_2': 0.1450182186534057, 'dropout_rate_Layer_3': 0.04593074302743645, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 8.842096020997288e-05, 'l1_Layer_2': 0.0007327328347014327, 'l1_Layer_3': 1.2016306287819951e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 140, 'n_units_Layer_3': 95}. Best is trial 20 with value: 6.969647840689902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.83 | sMAPE for Validation Set is: 25.98% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 7.19 | sMAPE for Test Set is: 20.62% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:33:12,440]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:33:20,522]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:33:30,583]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:33:37,147]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:33:40,827]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:33:41,407]\u001b[0m Trial 26 finished with value: 10.150606434265327 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006350796841245124, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21780997293670368, 'dropout_rate_Layer_2': 0.02772605021033341, 'dropout_rate_Layer_3': 0.06429301589773173, 'dropout_rate_Layer_4': 0.3015020361634213, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00010978977173509068, 'l1_Layer_2': 0.011117917344172366, 'l1_Layer_3': 0.0001301492945903445, 'l1_Layer_4': 8.712664650539684e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 145, 'n_units_Layer_3': 130, 'n_units_Layer_4': 135}. Best is trial 20 with value: 6.969647840689902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.15 | sMAPE for Validation Set is: 24.47% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 19.96% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:33:46,939]\u001b[0m Trial 59 finished with value: 7.216408017565196 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012020715809458237, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32229816588199156, 'dropout_rate_Layer_2': 0.07987117548238572, 'dropout_rate_Layer_3': 0.1387011961669838, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00865356213289144, 'l1_Layer_2': 0.017777674175216317, 'l1_Layer_3': 0.04065654279776869, 'n_units_Layer_1': 110, 'n_units_Layer_2': 245, 'n_units_Layer_3': 125}. Best is trial 20 with value: 6.969647840689902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 17.87% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.99 | sMAPE for Test Set is: 17.88% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:33:51,646]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:33:55,710]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:34:03,114]\u001b[0m Trial 63 finished with value: 14.171085800156689 and parameters: {'n_hidden': 3, 'learning_rate': 0.09010022260140836, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011683070068929125, 'dropout_rate_Layer_2': 0.270049683106214, 'dropout_rate_Layer_3': 0.3884305658004222, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0062763784771335054, 'l1_Layer_2': 3.6105163334111035e-05, 'l1_Layer_3': 0.002288892719510656, 'n_units_Layer_1': 265, 'n_units_Layer_2': 135, 'n_units_Layer_3': 185}. Best is trial 20 with value: 6.969647840689902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.17 | sMAPE for Validation Set is: 35.36% | rMAE for Validation Set is: 1.34\n",
      "MAE for Test Set is: 10.01 | sMAPE for Test Set is: 29.95% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:34:06,364]\u001b[0m Trial 64 finished with value: 8.99529542206386 and parameters: {'n_hidden': 3, 'learning_rate': 0.00529274124535235, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3491456300780662, 'dropout_rate_Layer_2': 0.04571734714363421, 'dropout_rate_Layer_3': 0.12267277764969663, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026763424841826815, 'l1_Layer_2': 0.005083348033528448, 'l1_Layer_3': 0.0001324470140518913, 'n_units_Layer_1': 200, 'n_units_Layer_2': 70, 'n_units_Layer_3': 120}. Best is trial 20 with value: 6.969647840689902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.00 | sMAPE for Validation Set is: 21.54% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 18.94% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:34:12,781]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:34:16,408]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:34:18,403]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:34:18,854]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:34:23,755]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:34:29,563]\u001b[0m Trial 67 finished with value: 8.960168538866096 and parameters: {'n_hidden': 3, 'learning_rate': 0.009365241476924378, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1877831695729542, 'dropout_rate_Layer_2': 0.029549010677176968, 'dropout_rate_Layer_3': 0.10116287622637904, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00908801636477577, 'l1_Layer_2': 2.9191244310508685e-05, 'l1_Layer_3': 0.0001308898020223625, 'n_units_Layer_1': 175, 'n_units_Layer_2': 75, 'n_units_Layer_3': 240}. Best is trial 20 with value: 6.969647840689902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.96 | sMAPE for Validation Set is: 21.46% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 19.57% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:34:31,863]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:34:35,267]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:34:44,555]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:34:46,593]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:34:49,694]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:34:52,029]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:35:01,168]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:35:07,336]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:35:10,428]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:35:14,166]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:35:17,505]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:35:20,968]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:35:24,233]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:35:26,625]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:35:29,475]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:35:32,685]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:35:36,699]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:35:39,640]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:35:43,954]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:35:48,850]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:35:59,857]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:36:03,691]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:36:11,773]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:36:16,343]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:36:19,477]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:36:23,178]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:36:30,111]\u001b[0m Trial 94 finished with value: 17.42544405169105 and parameters: {'n_hidden': 4, 'learning_rate': 0.001098021250991806, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3473053900784855, 'dropout_rate_Layer_2': 0.343842888402888, 'dropout_rate_Layer_3': 0.35611931072013875, 'dropout_rate_Layer_4': 0.2840252863645556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.03699159978279514, 'l1_Layer_2': 0.037711865746583195, 'l1_Layer_3': 0.0556355815173079, 'l1_Layer_4': 0.0004476007153410781, 'n_units_Layer_1': 265, 'n_units_Layer_2': 165, 'n_units_Layer_3': 260, 'n_units_Layer_4': 105}. Best is trial 20 with value: 6.969647840689902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.43 | sMAPE for Validation Set is: 43.14% | rMAE for Validation Set is: 1.65\n",
      "MAE for Test Set is: 11.27 | sMAPE for Test Set is: 32.21% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:36:30,715]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:36:36,184]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:36:36,899]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:36:39,250]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:36:42,987]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:36:44,422]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:36:49,708]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:36:52,254]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:36:55,341]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:36:57,580]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:36:59,851]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:03,281]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:05,014]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:09,581]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:09,955]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:14,087]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:14,696]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:16,011]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:21,277]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:22,638]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:24,141]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:27,971]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:32,283]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:37,267]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:40,456]\u001b[0m Trial 122 finished with value: 7.625399479830509 and parameters: {'n_hidden': 3, 'learning_rate': 0.03388211339564151, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24805062279342294, 'dropout_rate_Layer_2': 0.006738968118488814, 'dropout_rate_Layer_3': 0.10590989634284663, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.120301634540569e-05, 'l1_Layer_2': 1.07710511143546e-05, 'l1_Layer_3': 0.0001893425888194977, 'n_units_Layer_1': 60, 'n_units_Layer_2': 50, 'n_units_Layer_3': 225}. Best is trial 20 with value: 6.969647840689902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.63 | sMAPE for Validation Set is: 18.82% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.42 | sMAPE for Test Set is: 19.07% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:37:40,606]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:41,466]\u001b[0m Trial 124 finished with value: 7.841928953032254 and parameters: {'n_hidden': 3, 'learning_rate': 0.03949064180269955, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1289598744766794, 'dropout_rate_Layer_2': 0.009571782259202816, 'dropout_rate_Layer_3': 0.08952984671768383, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000698496960781537, 'l1_Layer_2': 4.473086836545217e-05, 'l1_Layer_3': 0.00017625208866805836, 'n_units_Layer_1': 250, 'n_units_Layer_2': 50, 'n_units_Layer_3': 230}. Best is trial 20 with value: 6.969647840689902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.84 | sMAPE for Validation Set is: 19.19% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.47 | sMAPE for Test Set is: 19.01% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:37:46,958]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:50,569]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:55,105]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:37:57,722]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:01,995]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:04,920]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:09,920]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:13,698]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:14,191]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:14,729]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:21,931]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:22,491]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:28,283]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:30,956]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:31,482]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:38,512]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:39,032]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:41,935]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:45,113]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:46,059]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:48,542]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:52,376]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:53,639]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:54,600]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:38:59,754]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:39:01,503]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:39:04,720]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:39:09,913]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:39:12,859]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:39:16,049]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:39:19,540]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:39:20,358]\u001b[0m Trial 145 finished with value: 7.789046057828977 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008147143373541598, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24315613898027114, 'dropout_rate_Layer_2': 0.28313152261062874, 'dropout_rate_Layer_3': 0.3730143434081198, 'dropout_rate_Layer_4': 0.25227609520737887, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00019877579318943952, 'l1_Layer_2': 1.7121794323045945e-05, 'l1_Layer_3': 6.096647205588637e-05, 'l1_Layer_4': 0.0003039348163397876, 'n_units_Layer_1': 200, 'n_units_Layer_2': 110, 'n_units_Layer_3': 115, 'n_units_Layer_4': 105}. Best is trial 20 with value: 6.969647840689902.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.79 | sMAPE for Validation Set is: 19.02% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.05 | sMAPE for Test Set is: 17.90% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:39:24,671]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:39:38,522]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:39:43,666]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:39:46,338]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:39:49,166]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:39:49,375]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:39:55,357]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:01,184]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:05,072]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:05,555]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:07,596]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:09,975]\u001b[0m Trial 161 finished with value: 6.910539820340759 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006810575143735752, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30459602314446094, 'dropout_rate_Layer_2': 0.025068401570377787, 'dropout_rate_Layer_3': 0.06898980429414689, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.760212795298468e-05, 'l1_Layer_2': 0.07980714100032635, 'l1_Layer_3': 0.0030380516880305114, 'n_units_Layer_1': 95, 'n_units_Layer_2': 280, 'n_units_Layer_3': 170}. Best is trial 161 with value: 6.910539820340759.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.91 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 17.31% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:40:12,548]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:12,747]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:13,763]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:17,583]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:23,566]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:26,043]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:29,665]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:33,269]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:35,270]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:39,865]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:42,968]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:46,271]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:48,355]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:52,459]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:54,486]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:40:57,798]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:41:01,479]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:41:01,783]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:41:07,072]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:41:10,693]\u001b[0m Trial 174 finished with value: 11.881015601229178 and parameters: {'n_hidden': 4, 'learning_rate': 0.04908126809138587, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07180028385277915, 'dropout_rate_Layer_2': 0.24974285533486504, 'dropout_rate_Layer_3': 0.22773785081643283, 'dropout_rate_Layer_4': 0.21412318369747374, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.7007087904074934e-05, 'l1_Layer_2': 0.017022600132967754, 'l1_Layer_3': 4.949734401573521e-05, 'l1_Layer_4': 0.0007861446128746455, 'n_units_Layer_1': 145, 'n_units_Layer_2': 210, 'n_units_Layer_3': 210, 'n_units_Layer_4': 75}. Best is trial 161 with value: 6.910539820340759.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.88 | sMAPE for Validation Set is: 28.49% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 7.77 | sMAPE for Test Set is: 22.43% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:41:16,599]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:41:20,746]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:41:24,961]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:41:29,212]\u001b[0m Trial 192 finished with value: 10.42350584723652 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011081212061993598, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3515391321401576, 'dropout_rate_Layer_2': 0.24715858036326505, 'dropout_rate_Layer_3': 0.26181429325463323, 'dropout_rate_Layer_4': 0.2490067557057906, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00019960535350176277, 'l1_Layer_2': 1.2765736704341927e-05, 'l1_Layer_3': 0.00021789382713306688, 'l1_Layer_4': 0.0054298921616975195, 'n_units_Layer_1': 145, 'n_units_Layer_2': 155, 'n_units_Layer_3': 95, 'n_units_Layer_4': 105}. Best is trial 161 with value: 6.910539820340759.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.42 | sMAPE for Validation Set is: 24.75% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 6.90 | sMAPE for Test Set is: 19.93% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:41:31,516]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:41:39,567]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:41:39,940]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:41:45,915]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:41:49,126]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:41:49,463]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:41:55,769]\u001b[0m Trial 175 finished with value: 6.583345990962378 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010323152215076217, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3150029660877969, 'dropout_rate_Layer_2': 0.018510691703656726, 'dropout_rate_Layer_3': 0.036483619033494286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021025886892916834, 'l1_Layer_2': 0.035869749640961325, 'l1_Layer_3': 0.005632970974242692, 'n_units_Layer_1': 105, 'n_units_Layer_2': 290, 'n_units_Layer_3': 200}. Best is trial 175 with value: 6.583345990962378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 16.47% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 16.89% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:41:56,130]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:42:01,348]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:42:08,705]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:42:14,115]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:42:17,533]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:42:22,050]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:42:25,851]\u001b[0m Trial 196 finished with value: 6.594652565098342 and parameters: {'n_hidden': 3, 'learning_rate': 0.001091802686051471, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2847829507194599, 'dropout_rate_Layer_2': 0.16751830948299187, 'dropout_rate_Layer_3': 0.01311963110297551, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.113873006782929e-05, 'l1_Layer_2': 0.02017881053274872, 'l1_Layer_3': 9.567713124942462e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 295, 'n_units_Layer_3': 150}. Best is trial 175 with value: 6.583345990962378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 16.56% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.54 | sMAPE for Test Set is: 16.87% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:42:28,333]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:42:34,430]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:42:40,393]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:42:46,420]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:42:49,433]\u001b[0m Trial 202 finished with value: 6.9824449206108925 and parameters: {'n_hidden': 3, 'learning_rate': 0.01871283036657503, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27462129883658387, 'dropout_rate_Layer_2': 0.2455126451568794, 'dropout_rate_Layer_3': 0.34261908457567647, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.363644982538976e-05, 'l1_Layer_2': 0.04438518730150211, 'l1_Layer_3': 0.0365191085436301, 'n_units_Layer_1': 105, 'n_units_Layer_2': 235, 'n_units_Layer_3': 120}. Best is trial 175 with value: 6.583345990962378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.98 | sMAPE for Validation Set is: 17.33% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 17.88% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:42:58,024]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:43:01,776]\u001b[0m Trial 212 finished with value: 6.439055430624127 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034080099579558674, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28266858173014386, 'dropout_rate_Layer_2': 0.13263575379616446, 'dropout_rate_Layer_3': 0.008748974966340339, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.598447948026915e-05, 'l1_Layer_2': 0.013073094343398999, 'l1_Layer_3': 3.143842083070747e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 295, 'n_units_Layer_3': 165}. Best is trial 212 with value: 6.439055430624127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 16.26% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.47 | sMAPE for Test Set is: 16.84% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:43:09,073]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:43:13,113]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:43:16,693]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:43:30,712]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:43:31,355]\u001b[0m Trial 216 finished with value: 6.608528968071361 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033258566956075562, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31169168665100416, 'dropout_rate_Layer_2': 0.011084954145170208, 'dropout_rate_Layer_3': 0.0005514276488541529, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014042792207256366, 'l1_Layer_2': 0.025859797193058157, 'l1_Layer_3': 0.00011673940401774216, 'n_units_Layer_1': 90, 'n_units_Layer_2': 295, 'n_units_Layer_3': 140}. Best is trial 212 with value: 6.439055430624127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 16.39% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 17.25% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:43:38,336]\u001b[0m Trial 218 finished with value: 6.464238719203173 and parameters: {'n_hidden': 3, 'learning_rate': 0.003208112144533469, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31072755478775127, 'dropout_rate_Layer_2': 0.3507024357352721, 'dropout_rate_Layer_3': 0.011910203425866005, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012951492728909193, 'l1_Layer_2': 0.015100465473940112, 'l1_Layer_3': 2.059194441171121e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 295, 'n_units_Layer_3': 165}. Best is trial 212 with value: 6.439055430624127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 16.18% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.71 | sMAPE for Test Set is: 17.27% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:43:47,355]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:43:48,948]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:43:49,217]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:43:53,081]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:43:54,161]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:43:54,463]\u001b[0m Trial 215 finished with value: 9.416893067599675 and parameters: {'n_hidden': 4, 'learning_rate': 0.018067194251168445, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09986155812517886, 'dropout_rate_Layer_2': 0.30424821416638614, 'dropout_rate_Layer_3': 0.10813055512011967, 'dropout_rate_Layer_4': 0.009565944817070404, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00044224122406770434, 'l1_Layer_2': 0.006087998231016737, 'l1_Layer_3': 0.015108098742948446, 'l1_Layer_4': 0.0002400619297750556, 'n_units_Layer_1': 175, 'n_units_Layer_2': 225, 'n_units_Layer_3': 275, 'n_units_Layer_4': 185}. Best is trial 212 with value: 6.439055430624127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.42 | sMAPE for Validation Set is: 22.85% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 19.55% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:44:01,308]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:44:06,363]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:44:10,281]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:44:10,569]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:44:10,770]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:44:16,628]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:44:20,277]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:44:20,298]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:44:22,071]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:44:31,790]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:44:36,892]\u001b[0m Trial 229 finished with value: 6.472875301966675 and parameters: {'n_hidden': 3, 'learning_rate': 0.00424684220126566, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3175567969015132, 'dropout_rate_Layer_2': 0.38217149248726356, 'dropout_rate_Layer_3': 0.02291409744437688, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005683390189365453, 'l1_Layer_2': 0.007071227811057458, 'l1_Layer_3': 0.0001391671723337731, 'n_units_Layer_1': 80, 'n_units_Layer_2': 290, 'n_units_Layer_3': 125}. Best is trial 212 with value: 6.439055430624127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 16.16% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 17.49% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:44:37,417]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:44:41,721]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:44:45,183]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:44:48,482]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:44:52,990]\u001b[0m Trial 238 finished with value: 6.6440324878559425 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028129287436080737, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27304701174472135, 'dropout_rate_Layer_2': 0.32137397282290786, 'dropout_rate_Layer_3': 0.021090056715887352, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013721228820946058, 'l1_Layer_2': 0.009710092675994266, 'l1_Layer_3': 6.586394888939886e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 280, 'n_units_Layer_3': 155}. Best is trial 212 with value: 6.439055430624127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.64 | sMAPE for Validation Set is: 16.45% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.72 | sMAPE for Test Set is: 17.17% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:44:54,579]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:44:57,793]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:44:58,468]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:45:01,506]\u001b[0m Trial 237 finished with value: 6.632212436978377 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028136708255133754, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.270471931241686, 'dropout_rate_Layer_2': 0.019590907159938786, 'dropout_rate_Layer_3': 0.022664507253015408, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011994212640531804, 'l1_Layer_2': 0.012812801878300235, 'l1_Layer_3': 6.665985051704784e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 280, 'n_units_Layer_3': 155}. Best is trial 212 with value: 6.439055430624127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.63 | sMAPE for Validation Set is: 16.64% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.51 | sMAPE for Test Set is: 16.93% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:45:02,095]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:45:08,054]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:45:12,594]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:45:14,631]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:45:18,495]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:45:23,768]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:45:35,736]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:45:40,236]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:45:44,291]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:45:48,536]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:45:48,566]\u001b[0m Trial 251 finished with value: 6.560353437786439 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034963489540195177, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3006030268030821, 'dropout_rate_Layer_2': 0.37218292797861874, 'dropout_rate_Layer_3': 0.036912894793600756, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026903293640927114, 'l1_Layer_2': 0.008716434117645533, 'l1_Layer_3': 3.3516578219691564e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 285, 'n_units_Layer_3': 160}. Best is trial 212 with value: 6.439055430624127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.56 | sMAPE for Validation Set is: 16.19% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.56 | sMAPE for Test Set is: 16.73% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:45:52,779]\u001b[0m Trial 252 finished with value: 6.352078756383676 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035562336358798408, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2818475851068267, 'dropout_rate_Layer_2': 0.013238099139624194, 'dropout_rate_Layer_3': 0.03779279014375517, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.262628094198794e-05, 'l1_Layer_2': 0.012888275204161982, 'l1_Layer_3': 4.972208100267071e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 285, 'n_units_Layer_3': 165}. Best is trial 252 with value: 6.352078756383676.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.35 | sMAPE for Validation Set is: 15.77% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.52 | sMAPE for Test Set is: 16.86% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:45:54,599]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:45:57,183]\u001b[0m Trial 254 finished with value: 6.354773279057755 and parameters: {'n_hidden': 3, 'learning_rate': 0.002754319354111256, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2570716163560921, 'dropout_rate_Layer_2': 0.37239387500948845, 'dropout_rate_Layer_3': 0.02494505724627053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014721546705592735, 'l1_Layer_2': 0.012339269398044809, 'l1_Layer_3': 0.00010341899926610571, 'n_units_Layer_1': 105, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 252 with value: 6.352078756383676.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.35 | sMAPE for Validation Set is: 15.77% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.55 | sMAPE for Test Set is: 16.76% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:46:01,568]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:46:05,039]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:46:07,791]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:46:07,976]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:46:16,824]\u001b[0m Trial 264 finished with value: 6.539275391045784 and parameters: {'n_hidden': 4, 'learning_rate': 0.006295483552358985, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04318229414456139, 'dropout_rate_Layer_2': 0.004643353123499518, 'dropout_rate_Layer_3': 0.20240866310692165, 'dropout_rate_Layer_4': 0.22447614279640254, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00014877219350047883, 'l1_Layer_2': 9.02397692160473e-05, 'l1_Layer_3': 0.00020899132008186198, 'l1_Layer_4': 3.3463940865477204e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 110, 'n_units_Layer_3': 165, 'n_units_Layer_4': 140}. Best is trial 252 with value: 6.352078756383676.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 16.17% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 17.11% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:46:20,282]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:46:23,371]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:46:25,269]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:46:27,954]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:46:31,027]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:46:36,497]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:46:42,320]\u001b[0m Trial 261 finished with value: 6.24806672043363 and parameters: {'n_hidden': 3, 'learning_rate': 0.003022507663427497, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2868749010846037, 'dropout_rate_Layer_2': 0.0009336182869675025, 'dropout_rate_Layer_3': 0.045936219178859164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.716425020848493e-05, 'l1_Layer_2': 0.01815146849880451, 'l1_Layer_3': 5.43910091447716e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 285, 'n_units_Layer_3': 155}. Best is trial 261 with value: 6.24806672043363.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 15.51% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 16.65% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:46:45,249]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:46:48,012]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:46:53,016]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:46:55,332]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:46:58,328]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:47:02,863]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:47:06,052]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:47:09,265]\u001b[0m Trial 279 finished with value: 6.586215458631905 and parameters: {'n_hidden': 3, 'learning_rate': 0.006335081590010396, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0019651622942990846, 'dropout_rate_Layer_2': 0.003001442895905093, 'dropout_rate_Layer_3': 0.2121433716699777, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004917330233122816, 'l1_Layer_2': 0.00010301432178892739, 'l1_Layer_3': 5.31634687433247e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 115, 'n_units_Layer_3': 170}. Best is trial 261 with value: 6.24806672043363.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 16.19% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 17.13% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:47:17,079]\u001b[0m Trial 274 finished with value: 6.78321359392429 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008947031087971815, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3018765296184346, 'dropout_rate_Layer_2': 0.08413838691423545, 'dropout_rate_Layer_3': 0.31214877335573366, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007482128213197853, 'l1_Layer_2': 0.00017429905943325383, 'l1_Layer_3': 0.008830770981063784, 'n_units_Layer_1': 240, 'n_units_Layer_2': 105, 'n_units_Layer_3': 130}. Best is trial 261 with value: 6.24806672043363.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.78 | sMAPE for Validation Set is: 16.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 17.61% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:47:22,285]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:47:25,053]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:47:32,427]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:47:44,399]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:47:44,616]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:47:48,212]\u001b[0m Trial 286 finished with value: 6.407872776460437 and parameters: {'n_hidden': 3, 'learning_rate': 0.002528726825949645, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12618898463725697, 'dropout_rate_Layer_2': 0.21109027607337788, 'dropout_rate_Layer_3': 0.0606717934989224, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007311373958179848, 'l1_Layer_2': 0.0016895959897233236, 'l1_Layer_3': 1.3824205886308751e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 135, 'n_units_Layer_3': 145}. Best is trial 261 with value: 6.24806672043363.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 15.95% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.53 | sMAPE for Test Set is: 16.82% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:47:52,171]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:47:58,946]\u001b[0m Trial 287 finished with value: 6.255769866110836 and parameters: {'n_hidden': 3, 'learning_rate': 0.003174273365878603, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3236846731119277, 'dropout_rate_Layer_2': 0.022080577883862647, 'dropout_rate_Layer_3': 0.04406103440024638, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015755868926388246, 'l1_Layer_2': 0.0002758080944468534, 'l1_Layer_3': 5.1497705871200824e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 295, 'n_units_Layer_3': 145}. Best is trial 261 with value: 6.24806672043363.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 15.56% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 16.45% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:48:03,965]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:48:06,863]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:48:07,332]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:48:14,476]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:48:16,824]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:48:20,526]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:48:34,204]\u001b[0m Trial 290 finished with value: 6.184423751446732 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032293427054945947, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3447493699967849, 'dropout_rate_Layer_2': 0.022661382827960843, 'dropout_rate_Layer_3': 0.046306587924334966, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016083609133162206, 'l1_Layer_2': 0.0001737467263691752, 'l1_Layer_3': 6.757536534706181e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 295, 'n_units_Layer_3': 145}. Best is trial 290 with value: 6.184423751446732.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 15.37% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.36 | sMAPE for Test Set is: 16.41% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:48:40,718]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:48:43,059]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:48:46,687]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:48:52,016]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:48:56,528]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:49:00,479]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:49:03,830]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:49:07,451]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:49:10,055]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:49:15,304]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:49:19,615]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:49:26,239]\u001b[0m Trial 304 finished with value: 6.2383093896444395 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021155458481089333, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33014820171267895, 'dropout_rate_Layer_2': 0.03860474546591751, 'dropout_rate_Layer_3': 0.04150098645023916, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.999573134590016e-05, 'l1_Layer_2': 0.00012004918296404024, 'l1_Layer_3': 3.3649133091669564e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 295, 'n_units_Layer_3': 120}. Best is trial 290 with value: 6.184423751446732.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 15.62% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 16.51% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:49:31,623]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:49:53,265]\u001b[0m Trial 311 finished with value: 6.212216833666855 and parameters: {'n_hidden': 3, 'learning_rate': 0.002141066655281099, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3393392991241468, 'dropout_rate_Layer_2': 0.031009416946820908, 'dropout_rate_Layer_3': 0.027003559703188008, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011277145163234671, 'l1_Layer_2': 0.0001083211681058043, 'l1_Layer_3': 6.191619935333704e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 300, 'n_units_Layer_3': 145}. Best is trial 290 with value: 6.184423751446732.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 15.51% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.26 | sMAPE for Test Set is: 16.18% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:49:56,327]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:50:02,679]\u001b[0m Trial 299 finished with value: 6.706542625045422 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008725596217221391, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14845867697027829, 'dropout_rate_Layer_2': 0.18650808847430825, 'dropout_rate_Layer_3': 0.12147086620620132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017272153943088077, 'l1_Layer_2': 0.01644319511348525, 'l1_Layer_3': 0.003141564146664825, 'n_units_Layer_1': 125, 'n_units_Layer_2': 150, 'n_units_Layer_3': 130}. Best is trial 290 with value: 6.184423751446732.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.71 | sMAPE for Validation Set is: 16.83% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 17.65% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:50:08,055]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:50:12,453]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:50:19,062]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:50:29,611]\u001b[0m Trial 315 finished with value: 6.995434524617824 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022197497337475306, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22602851041393848, 'dropout_rate_Layer_2': 0.0033443606657193926, 'dropout_rate_Layer_3': 0.3113135425189225, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05303816985302162, 'l1_Layer_2': 7.502853654009955e-05, 'l1_Layer_3': 0.022629155263482668, 'n_units_Layer_1': 295, 'n_units_Layer_2': 175, 'n_units_Layer_3': 240}. Best is trial 290 with value: 6.184423751446732.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.00 | sMAPE for Validation Set is: 17.35% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 17.74% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:50:32,802]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:50:38,426]\u001b[0m Trial 313 finished with value: 19.3917949227381 and parameters: {'n_hidden': 3, 'learning_rate': 0.07733878374341807, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23757236361257422, 'dropout_rate_Layer_2': 0.1066499935849953, 'dropout_rate_Layer_3': 0.3992645745138853, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0016332523292998753, 'l1_Layer_2': 0.010242493634105954, 'l1_Layer_3': 0.001223874919013371, 'n_units_Layer_1': 225, 'n_units_Layer_2': 275, 'n_units_Layer_3': 65}. Best is trial 290 with value: 6.184423751446732.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.39 | sMAPE for Validation Set is: 49.92% | rMAE for Validation Set is: 1.84\n",
      "MAE for Test Set is: 13.22 | sMAPE for Test Set is: 39.23% | rMAE for Test Set is: 1.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:50:42,880]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:50:48,696]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:50:58,808]\u001b[0m Trial 319 finished with value: 6.203033424053113 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024430900684813454, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35966726177455244, 'dropout_rate_Layer_2': 0.04046944144987221, 'dropout_rate_Layer_3': 0.03500602050391278, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.647442705969064e-05, 'l1_Layer_2': 0.00012455955120235885, 'l1_Layer_3': 5.5486197340967505e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 300, 'n_units_Layer_3': 105}. Best is trial 290 with value: 6.184423751446732.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 15.45% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.47 | sMAPE for Test Set is: 16.68% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:51:01,961]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:51:06,616]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:51:11,177]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:51:13,154]\u001b[0m Trial 323 finished with value: 6.3618707722841705 and parameters: {'n_hidden': 3, 'learning_rate': 0.00183994133740665, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3567738410768623, 'dropout_rate_Layer_2': 0.02274001756951994, 'dropout_rate_Layer_3': 0.022970208416060192, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010448627837885919, 'l1_Layer_2': 0.0001296657858725782, 'l1_Layer_3': 3.946210680839252e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 285, 'n_units_Layer_3': 170}. Best is trial 290 with value: 6.184423751446732.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 15.86% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 16.59% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:51:17,848]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:51:36,411]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:51:42,176]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:51:47,496]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:51:53,165]\u001b[0m Trial 324 finished with value: 6.148641795327877 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018116163421656823, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3581555567019457, 'dropout_rate_Layer_2': 0.030745734559541223, 'dropout_rate_Layer_3': 0.02286955380217054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010950850137304476, 'l1_Layer_2': 0.00012213251369796289, 'l1_Layer_3': 6.680026163450591e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 285, 'n_units_Layer_3': 170}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 15.32% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.17 | sMAPE for Test Set is: 15.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:51:56,604]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:51:57,416]\u001b[0m Trial 330 finished with value: 6.277885843503465 and parameters: {'n_hidden': 3, 'learning_rate': 0.002000207686725365, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3596525325238455, 'dropout_rate_Layer_2': 0.008596593067113868, 'dropout_rate_Layer_3': 0.022254522981649268, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.912244736052841e-05, 'l1_Layer_2': 0.00011483045995285107, 'l1_Layer_3': 3.871514516261197e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 15.63% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.36 | sMAPE for Test Set is: 16.41% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:52:03,760]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:52:17,615]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:52:17,866]\u001b[0m Trial 333 finished with value: 8.319358795128721 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006295425917933714, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38710375313518136, 'dropout_rate_Layer_2': 0.28362585389773015, 'dropout_rate_Layer_3': 0.08964695580573007, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.138629684558541e-05, 'l1_Layer_2': 0.05949376257748687, 'l1_Layer_3': 0.0004735468878794004, 'n_units_Layer_1': 110, 'n_units_Layer_2': 55, 'n_units_Layer_3': 120}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.32 | sMAPE for Validation Set is: 20.26% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 6.26 | sMAPE for Test Set is: 18.65% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:52:25,214]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:52:25,876]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:52:29,679]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:52:31,410]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:52:33,898]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:52:36,537]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:52:40,098]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:52:43,971]\u001b[0m Trial 295 finished with value: 6.9135416313523015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016621083131621256, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20785998380042098, 'dropout_rate_Layer_2': 0.20394766260503788, 'dropout_rate_Layer_3': 0.3421284215019767, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.785413333456286e-05, 'l1_Layer_2': 0.08134263164344209, 'l1_Layer_3': 0.004609902443246314, 'n_units_Layer_1': 105, 'n_units_Layer_2': 95, 'n_units_Layer_3': 165}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.91 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.22 | sMAPE for Test Set is: 18.25% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:52:53,060]\u001b[0m Trial 342 finished with value: 6.363852857168162 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018174925658394707, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3503382363136042, 'dropout_rate_Layer_2': 0.00815247903797769, 'dropout_rate_Layer_3': 0.008140365047185804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010369673574463604, 'l1_Layer_2': 0.00015890432079934878, 'l1_Layer_3': 5.3080296431872314e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 290, 'n_units_Layer_3': 160}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 15.94% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.41 | sMAPE for Test Set is: 16.58% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:53:02,531]\u001b[0m Trial 344 finished with value: 6.370478904392134 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017942020596310132, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3559611970161565, 'dropout_rate_Layer_2': 0.038718771828946855, 'dropout_rate_Layer_3': 0.03004900913401802, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013645608866290687, 'l1_Layer_2': 0.0001559916953233722, 'l1_Layer_3': 1.8032110674428236e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 295, 'n_units_Layer_3': 165}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 15.88% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.66 | sMAPE for Test Set is: 17.20% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:53:04,866]\u001b[0m Trial 346 finished with value: 6.42558156273829 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017598340930766742, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3566983729509662, 'dropout_rate_Layer_2': 0.03915204367144538, 'dropout_rate_Layer_3': 0.021891802964609314, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.833288515263017e-05, 'l1_Layer_2': 0.00014087635886791543, 'l1_Layer_3': 3.1162511822967225e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 16.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.59 | sMAPE for Test Set is: 17.12% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:53:10,161]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:53:12,922]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:53:14,937]\u001b[0m Trial 349 finished with value: 16.656721896903253 and parameters: {'n_hidden': 3, 'learning_rate': 0.004422662728037489, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09720223593256078, 'dropout_rate_Layer_2': 0.14121217657397073, 'dropout_rate_Layer_3': 0.30013802186406885, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.07344993123296696, 'l1_Layer_2': 0.00019619153222134996, 'l1_Layer_3': 0.004344695707351603, 'n_units_Layer_1': 290, 'n_units_Layer_2': 215, 'n_units_Layer_3': 250}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.66 | sMAPE for Validation Set is: 40.83% | rMAE for Validation Set is: 1.58\n",
      "MAE for Test Set is: 10.56 | sMAPE for Test Set is: 29.98% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:53:15,456]\u001b[0m Trial 348 finished with value: 6.353267342938835 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018884902886171354, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37777757779525895, 'dropout_rate_Layer_2': 0.0009899182188296326, 'dropout_rate_Layer_3': 0.00019893720236597093, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.396708668089553e-05, 'l1_Layer_2': 0.00012657258737895706, 'l1_Layer_3': 1.8295893672564668e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.35 | sMAPE for Validation Set is: 15.96% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.44 | sMAPE for Test Set is: 16.67% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:53:15,803]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:53:22,105]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:53:28,901]\u001b[0m Trial 347 finished with value: 6.228768279801366 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017369443645688183, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.375095302441596, 'dropout_rate_Layer_2': 0.028044928834326202, 'dropout_rate_Layer_3': 0.022431816142600113, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.363863165085029e-05, 'l1_Layer_2': 0.0001549725455099168, 'l1_Layer_3': 2.0181338439014453e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 15.58% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 16.72% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:53:38,094]\u001b[0m Trial 356 finished with value: 7.72769990548963 and parameters: {'n_hidden': 3, 'learning_rate': 0.014982188829468102, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.035996183716329545, 'dropout_rate_Layer_2': 0.07277218558598332, 'dropout_rate_Layer_3': 0.22444074745843218, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09290915546120292, 'l1_Layer_2': 0.00010774765992824929, 'l1_Layer_3': 9.157874606719851e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 95, 'n_units_Layer_3': 180}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.73 | sMAPE for Validation Set is: 19.03% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 6.32 | sMAPE for Test Set is: 18.67% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:53:39,219]\u001b[0m Trial 353 finished with value: 7.006279299796405 and parameters: {'n_hidden': 3, 'learning_rate': 0.004131426213715527, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10809213494220989, 'dropout_rate_Layer_2': 0.023504785093102637, 'dropout_rate_Layer_3': 0.14845950858651163, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0039425165857108055, 'l1_Layer_2': 0.000879872218061492, 'l1_Layer_3': 0.0395554989076561, 'n_units_Layer_1': 50, 'n_units_Layer_2': 215, 'n_units_Layer_3': 215}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.01 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 17.72% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:53:43,744]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:53:46,568]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:53:46,600]\u001b[0m Trial 355 finished with value: 6.409134982504104 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017373535905650915, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3858052096584411, 'dropout_rate_Layer_2': 0.02950571632443945, 'dropout_rate_Layer_3': 0.028867137440682148, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.731449063845393e-05, 'l1_Layer_2': 0.000249232295181417, 'l1_Layer_3': 1.5571471081868207e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 16.01% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.55 | sMAPE for Test Set is: 17.00% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:53:50,356]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:53:54,068]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:53:54,327]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:53:58,416]\u001b[0m Trial 357 finished with value: 6.324641146884619 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018166830655440905, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3904633569111837, 'dropout_rate_Layer_2': 0.028402784237297404, 'dropout_rate_Layer_3': 0.031074885141955527, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.4672041236605386e-05, 'l1_Layer_2': 0.00012712124794261095, 'l1_Layer_3': 2.2097397427059573e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 285, 'n_units_Layer_3': 175}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 15.84% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.41 | sMAPE for Test Set is: 16.65% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:54:05,704]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:54:14,578]\u001b[0m Trial 361 finished with value: 6.3350527395066605 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017101108093747173, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37238666137532134, 'dropout_rate_Layer_2': 0.04271251788042783, 'dropout_rate_Layer_3': 0.026675842826161558, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.742650985851307e-05, 'l1_Layer_2': 0.00018103185903859233, 'l1_Layer_3': 1.4602424591034164e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 300, 'n_units_Layer_3': 165}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.34 | sMAPE for Validation Set is: 15.86% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 16.55% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:54:19,346]\u001b[0m Trial 366 finished with value: 6.320338981079434 and parameters: {'n_hidden': 3, 'learning_rate': 0.001920560657464799, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38396110917803145, 'dropout_rate_Layer_2': 0.046708665672086945, 'dropout_rate_Layer_3': 0.005636273814011987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.8031920962720515e-05, 'l1_Layer_2': 0.0001377862519610319, 'l1_Layer_3': 1.7547118910760504e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 15.80% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.54 | sMAPE for Test Set is: 16.79% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:54:24,837]\u001b[0m Trial 367 finished with value: 8.46105274414439 and parameters: {'n_hidden': 3, 'learning_rate': 0.015149508180356567, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0414582110007439, 'dropout_rate_Layer_2': 0.0795742790087988, 'dropout_rate_Layer_3': 0.23464707544517777, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03856173620576408, 'l1_Layer_2': 0.0001531196947004836, 'l1_Layer_3': 8.731590408091883e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 95, 'n_units_Layer_3': 180}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.46 | sMAPE for Validation Set is: 20.96% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 19.38% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:54:30,836]\u001b[0m Trial 364 finished with value: 6.211603453037238 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019525905074912317, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36167383473331566, 'dropout_rate_Layer_2': 0.042841930419657795, 'dropout_rate_Layer_3': 0.006446151763507879, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.342188165672976e-05, 'l1_Layer_2': 0.00015235579743590769, 'l1_Layer_3': 1.8258966781982954e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 290, 'n_units_Layer_3': 175}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 15.48% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 16.57% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:54:34,241]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:54:37,222]\u001b[0m Trial 368 finished with value: 6.288065082352031 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017788760357464247, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3883034911195364, 'dropout_rate_Layer_2': 0.061265152033891046, 'dropout_rate_Layer_3': 0.04862278088365987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.812979052389446e-05, 'l1_Layer_2': 0.00013114297972606772, 'l1_Layer_3': 1.9207219922878988e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 295, 'n_units_Layer_3': 170}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 15.73% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.54 | sMAPE for Test Set is: 16.83% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:54:37,439]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:54:42,098]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:54:42,609]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:54:46,478]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:55:04,735]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:55:05,702]\u001b[0m Trial 369 finished with value: 6.225496714737829 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017690304022275366, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.398870917743373, 'dropout_rate_Layer_2': 0.05905825172668642, 'dropout_rate_Layer_3': 0.01644938031842981, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9337658231289946e-05, 'l1_Layer_2': 0.00012686100596738347, 'l1_Layer_3': 1.629326026267453e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 295, 'n_units_Layer_3': 170}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 15.46% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.42 | sMAPE for Test Set is: 16.48% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:55:09,793]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:55:11,446]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:55:14,338]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:55:16,991]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:55:19,292]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:55:23,023]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:55:23,176]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:55:28,757]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:55:39,739]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:55:40,759]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:55:45,308]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:55:46,497]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:55:52,106]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:55:54,723]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:55:58,091]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:56:01,325]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:56:10,921]\u001b[0m Trial 391 finished with value: 6.995254395876072 and parameters: {'n_hidden': 3, 'learning_rate': 0.011970722884425626, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.060598776607198354, 'dropout_rate_Layer_2': 0.10842536221444396, 'dropout_rate_Layer_3': 0.221281206592293, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024028362682664838, 'l1_Layer_2': 7.86512876074469e-05, 'l1_Layer_3': 0.00046034939833466254, 'n_units_Layer_1': 255, 'n_units_Layer_2': 145, 'n_units_Layer_3': 145}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.00 | sMAPE for Validation Set is: 17.40% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.12 | sMAPE for Test Set is: 18.39% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:56:22,402]\u001b[0m Trial 395 finished with value: 7.071241854693414 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032735144085247153, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11567832281785949, 'dropout_rate_Layer_2': 0.022802930499334927, 'dropout_rate_Layer_3': 0.15899782739678636, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009789399587033334, 'l1_Layer_2': 0.0001937360021185777, 'l1_Layer_3': 0.009534109713412169, 'n_units_Layer_1': 60, 'n_units_Layer_2': 210, 'n_units_Layer_3': 215}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.07 | sMAPE for Validation Set is: 17.50% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 18.37% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:56:28,789]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:56:31,630]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:56:38,501]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:56:58,477]\u001b[0m Trial 398 finished with value: 6.401267851295863 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018438747724234387, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36772931270928527, 'dropout_rate_Layer_2': 0.01935029846280718, 'dropout_rate_Layer_3': 0.01395724688114585, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.9275257549690116e-05, 'l1_Layer_2': 5.558967677888293e-05, 'l1_Layer_3': 3.989267533728194e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 295, 'n_units_Layer_3': 165}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 15.93% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.59 | sMAPE for Test Set is: 17.10% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:57:06,499]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:57:10,173]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:57:13,317]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:57:18,586]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:57:21,755]\u001b[0m Trial 401 finished with value: 6.43381641729584 and parameters: {'n_hidden': 3, 'learning_rate': 0.002269758753496263, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38201886030524074, 'dropout_rate_Layer_2': 0.019206463459509302, 'dropout_rate_Layer_3': 0.034202702069807925, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.138760570827343e-05, 'l1_Layer_2': 5.576265628266623e-05, 'l1_Layer_3': 5.062219861741098e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 16.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.51 | sMAPE for Test Set is: 16.98% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:57:40,049]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:57:45,161]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:57:48,628]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:57:51,656]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:57:57,740]\u001b[0m Trial 405 finished with value: 6.276940455713642 and parameters: {'n_hidden': 3, 'learning_rate': 0.002273900261331587, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3589335755510683, 'dropout_rate_Layer_2': 0.017547671413200096, 'dropout_rate_Layer_3': 0.03449087414467598, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.550487098290712e-05, 'l1_Layer_2': 0.00012667782543967745, 'l1_Layer_3': 3.945564735832647e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 280, 'n_units_Layer_3': 165}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 15.70% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.44 | sMAPE for Test Set is: 16.67% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:58:04,978]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:58:11,013]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:58:15,227]\u001b[0m Trial 409 finished with value: 6.355597904017074 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018082087997346706, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3593462936997096, 'dropout_rate_Layer_2': 0.032494615923577705, 'dropout_rate_Layer_3': 0.008385707573966044, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.726436743933216e-05, 'l1_Layer_2': 0.0003551656292407554, 'l1_Layer_3': 3.0429544533689664e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 285, 'n_units_Layer_3': 165}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 15.93% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.52 | sMAPE for Test Set is: 16.86% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:58:18,824]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:58:19,616]\u001b[0m Trial 406 finished with value: 6.173961067304599 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017585136847585404, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3626077656051446, 'dropout_rate_Layer_2': 0.032625584638607416, 'dropout_rate_Layer_3': 0.01115546094153273, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.485894912560202e-05, 'l1_Layer_2': 0.0003386782671869958, 'l1_Layer_3': 1.5824969883520383e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 285, 'n_units_Layer_3': 165}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 15.37% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.33 | sMAPE for Test Set is: 16.39% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:58:20,854]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:58:24,798]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:58:27,699]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:58:28,324]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:58:31,922]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:58:36,107]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:58:39,037]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:58:42,358]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:58:45,634]\u001b[0m Trial 415 finished with value: 10.01952245718496 and parameters: {'n_hidden': 3, 'learning_rate': 0.00916819050463212, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007554153266000077, 'dropout_rate_Layer_2': 0.08857657407232242, 'dropout_rate_Layer_3': 0.1526532546229638, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008322057424760117, 'l1_Layer_2': 0.0009931377926573318, 'l1_Layer_3': 0.09218473081720407, 'n_units_Layer_1': 245, 'n_units_Layer_2': 245, 'n_units_Layer_3': 300}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.02 | sMAPE for Validation Set is: 23.76% | rMAE for Validation Set is: 0.95\n",
      "MAE for Test Set is: 6.75 | sMAPE for Test Set is: 19.43% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:58:46,108]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.63 | sMAPE for Validation Set is: 18.47% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 19.12% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:58:50,335]\u001b[0m Trial 421 finished with value: 7.625472712721016 and parameters: {'n_hidden': 3, 'learning_rate': 0.006576446391758405, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0975737995697616, 'dropout_rate_Layer_2': 0.26090172364999303, 'dropout_rate_Layer_3': 0.310387988370437, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.454807873150838e-05, 'l1_Layer_2': 6.813653846467461e-05, 'l1_Layer_3': 0.002689988337025008, 'n_units_Layer_1': 270, 'n_units_Layer_2': 165, 'n_units_Layer_3': 110}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:58:50,478]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:58:57,250]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:01,080]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:01,225]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:02,209]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:04,606]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:07,587]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:10,156]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:10,379]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:11,223]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:16,003]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:16,549]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:16,829]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:24,549]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:28,090]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:31,071]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:40,586]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:40,814]\u001b[0m Trial 430 finished with value: 6.47868539626705 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023229071351927324, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20997883490944183, 'dropout_rate_Layer_2': 0.04174428132563904, 'dropout_rate_Layer_3': 0.13029431931281826, 'dropout_rate_Layer_4': 0.2715717175234196, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00015283959609057568, 'l1_Layer_2': 0.009199879749038907, 'l1_Layer_3': 0.0003105499367336081, 'l1_Layer_4': 0.00010495984166100475, 'n_units_Layer_1': 230, 'n_units_Layer_2': 195, 'n_units_Layer_3': 170, 'n_units_Layer_4': 115}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.48 | sMAPE for Validation Set is: 16.16% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.69 | sMAPE for Test Set is: 17.19% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:59:45,221]\u001b[0m Trial 440 finished with value: 7.034552717421974 and parameters: {'n_hidden': 4, 'learning_rate': 0.009574280704083725, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20740607733287347, 'dropout_rate_Layer_2': 0.0397580212804575, 'dropout_rate_Layer_3': 0.22401750737530923, 'dropout_rate_Layer_4': 0.2743789495642253, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.000139195702126074, 'l1_Layer_2': 0.013735247753876788, 'l1_Layer_3': 0.00026719122225229443, 'l1_Layer_4': 7.021400249962101e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 110, 'n_units_Layer_3': 140, 'n_units_Layer_4': 115}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.03 | sMAPE for Validation Set is: 17.25% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 17.96% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 21:59:45,449]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:45,745]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:52,205]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:52,867]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:52,893]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 21:59:55,570]\u001b[0m Trial 439 finished with value: 7.121513269511458 and parameters: {'n_hidden': 3, 'learning_rate': 0.001988579355484706, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1475958830315751, 'dropout_rate_Layer_2': 0.00367533320051692, 'dropout_rate_Layer_3': 0.286878224631106, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.028818948467487972, 'l1_Layer_2': 4.940205833396152e-05, 'l1_Layer_3': 0.011544666640242326, 'n_units_Layer_1': 290, 'n_units_Layer_2': 110, 'n_units_Layer_3': 200}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.12 | sMAPE for Validation Set is: 17.63% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 17.83% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:00:00,759]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:01,092]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:01,131]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:10,398]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:11,882]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:13,702]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:17,847]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:18,664]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:21,255]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:23,925]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:25,160]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:29,729]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:33,304]\u001b[0m Trial 454 finished with value: 6.340556685360672 and parameters: {'n_hidden': 3, 'learning_rate': 0.0076232361224787045, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.041837858159670366, 'dropout_rate_Layer_2': 0.1595248747743675, 'dropout_rate_Layer_3': 0.16743596723003235, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008079613530268901, 'l1_Layer_2': 0.0008443031717646373, 'l1_Layer_3': 0.004166561819113277, 'n_units_Layer_1': 195, 'n_units_Layer_2': 195, 'n_units_Layer_3': 235}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.34 | sMAPE for Validation Set is: 15.82% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 16.49% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:00:36,086]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:37,714]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:39,499]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:40,458]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:41,647]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:43,402]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:47,106]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:47,399]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:00:48,958]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:01:01,739]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:01:03,980]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:01:05,858]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:01:07,712]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:01:12,945]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:01:15,706]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:01:18,539]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:01:20,178]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:01:24,039]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:01:33,085]\u001b[0m Trial 473 finished with value: 6.657682427822766 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012503045742595935, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15019969404932834, 'dropout_rate_Layer_2': 0.2151711391000174, 'dropout_rate_Layer_3': 0.15750099317815072, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006640463463295453, 'l1_Layer_2': 0.014970838033766875, 'l1_Layer_3': 0.0006342100936769469, 'n_units_Layer_1': 135, 'n_units_Layer_2': 150, 'n_units_Layer_3': 185}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.66 | sMAPE for Validation Set is: 16.64% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 17.19% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:01:35,394]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:01:38,307]\u001b[0m Trial 481 finished with value: 6.680690735545237 and parameters: {'n_hidden': 3, 'learning_rate': 0.010598273365116805, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010561692859679082, 'dropout_rate_Layer_2': 0.18200865788737167, 'dropout_rate_Layer_3': 0.3327904159799364, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005919576567396938, 'l1_Layer_2': 5.793926751462716e-05, 'l1_Layer_3': 0.0028339056459538896, 'n_units_Layer_1': 210, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.68 | sMAPE for Validation Set is: 16.65% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 17.40% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:01:38,616]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:01:43,285]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:01:45,941]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:01:49,745]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:01:54,254]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:01:58,702]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:02:00,963]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:02:03,382]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:02:03,722]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:02:06,384]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:02:11,724]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:02:14,283]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:02:17,332]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:02:19,831]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:02:25,454]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:02:30,946]\u001b[0m Trial 482 finished with value: 7.2328381208378945 and parameters: {'n_hidden': 3, 'learning_rate': 0.000861713154833637, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24083107063387887, 'dropout_rate_Layer_2': 0.18066547960425708, 'dropout_rate_Layer_3': 0.39359121098264344, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0029817070589717e-05, 'l1_Layer_2': 0.009792117386500434, 'l1_Layer_3': 0.01177822454360624, 'n_units_Layer_1': 125, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.23 | sMAPE for Validation Set is: 18.02% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 18.10% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:02:33,915]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:02:38,781]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.08 | sMAPE for Validation Set is: 17.44% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.46 | sMAPE for Test Set is: 19.02% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:02:39,750]\u001b[0m Trial 495 finished with value: 7.08239434509526 and parameters: {'n_hidden': 3, 'learning_rate': 0.029511030369949974, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23763249298942962, 'dropout_rate_Layer_2': 0.25881671306176274, 'dropout_rate_Layer_3': 0.35128701775798843, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006198539166654785, 'l1_Layer_2': 0.01229346282408694, 'l1_Layer_3': 0.0023604435330460156, 'n_units_Layer_1': 130, 'n_units_Layer_2': 155, 'n_units_Layer_3': 80}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:02:43,189]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:02:43,825]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:02:48,010]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:02:48,271]\u001b[0m Trial 498 finished with value: 6.285054664067107 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019539115466566497, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.371030531956517, 'dropout_rate_Layer_2': 0.024707585620721992, 'dropout_rate_Layer_3': 0.018401896705324234, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.022032395425071e-05, 'l1_Layer_2': 0.0011710274119267159, 'l1_Layer_3': 1.6786733033433827e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 290, 'n_units_Layer_3': 155}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 15.69% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 16.70% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:02:48,645]\u001b[0m Trial 501 finished with value: 6.874469937407993 and parameters: {'n_hidden': 4, 'learning_rate': 0.006651899073960525, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18370927602811826, 'dropout_rate_Layer_2': 0.04284782822987736, 'dropout_rate_Layer_3': 0.2588889250083538, 'dropout_rate_Layer_4': 0.3316690046964129, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004919195857904384, 'l1_Layer_2': 0.008836358866039052, 'l1_Layer_3': 0.0015307224645613516, 'l1_Layer_4': 0.00026050873163179113, 'n_units_Layer_1': 230, 'n_units_Layer_2': 135, 'n_units_Layer_3': 140, 'n_units_Layer_4': 100}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.87 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 18.23% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:02:57,834]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:00,041]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:02,772]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:03,257]\u001b[0m Trial 507 finished with value: 7.053087461585217 and parameters: {'n_hidden': 3, 'learning_rate': 0.00984612502189956, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19086392012836767, 'dropout_rate_Layer_2': 0.195013769157939, 'dropout_rate_Layer_3': 0.3087744251204565, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.012380471206481303, 'l1_Layer_2': 0.060918958552135014, 'l1_Layer_3': 0.0019083857877195461, 'n_units_Layer_1': 60, 'n_units_Layer_2': 135, 'n_units_Layer_3': 105}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.05 | sMAPE for Validation Set is: 17.51% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.08 | sMAPE for Test Set is: 18.08% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:03:07,438]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:07,700]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:14,606]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:14,710]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:15,807]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:21,001]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:23,699]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:23,837]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:27,912]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:36,090]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:36,985]\u001b[0m Trial 513 finished with value: 7.035338554950621 and parameters: {'n_hidden': 4, 'learning_rate': 0.004321866822138603, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021690960744058067, 'dropout_rate_Layer_2': 0.02463715283192741, 'dropout_rate_Layer_3': 0.253722764931688, 'dropout_rate_Layer_4': 0.31688845042172775, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004887981119112196, 'l1_Layer_2': 0.028426946102180953, 'l1_Layer_3': 0.0017900301415357594, 'l1_Layer_4': 0.00021678538760427362, 'n_units_Layer_1': 290, 'n_units_Layer_2': 230, 'n_units_Layer_3': 190, 'n_units_Layer_4': 85}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 17.54% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.89 | sMAPE for Test Set is: 17.73% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:03:37,524]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:42,417]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:43,939]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:44,952]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:47,222]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:47,344]\u001b[0m Trial 521 finished with value: 6.341668912655287 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020610205459781544, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33598535297961873, 'dropout_rate_Layer_2': 0.029151849964569827, 'dropout_rate_Layer_3': 0.036814632752384696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0465651672435796e-05, 'l1_Layer_2': 8.813325669572509e-05, 'l1_Layer_3': 2.7478588890558452e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 280, 'n_units_Layer_3': 95}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.34 | sMAPE for Validation Set is: 15.87% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.51 | sMAPE for Test Set is: 16.91% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:03:49,469]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:52,826]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:55,847]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:03:57,505]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:02,015]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:02,159]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:03,295]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:09,560]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:09,853]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:14,699]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:17,745]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:18,048]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:23,162]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:23,411]\u001b[0m Trial 535 finished with value: 10.095995676664002 and parameters: {'n_hidden': 3, 'learning_rate': 0.028990247651472945, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0013861508663253596, 'dropout_rate_Layer_2': 0.1743848103017267, 'dropout_rate_Layer_3': 0.1842203890102791, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0006641799091153498, 'l1_Layer_2': 0.0019440733768213811, 'l1_Layer_3': 0.001837770917324596, 'n_units_Layer_1': 200, 'n_units_Layer_2': 110, 'n_units_Layer_3': 300}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.10 | sMAPE for Validation Set is: 24.14% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 19.73% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:04:23,779]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:28,935]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:31,701]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:34,670]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:34,727]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:35,110]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:39,985]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:40,355]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:40,544]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:45,474]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:46,144]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:46,429]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:50,816]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:52,726]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:04:56,459]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:05:00,120]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:05:02,293]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:05:05,918]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:05:09,912]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:05:10,507]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:05:13,733]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:05:14,226]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:05:18,224]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:05:21,296]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:05:32,256]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:05:35,883]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:05:38,505]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:05:42,607]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:05:46,080]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:05:51,074]\u001b[0m Trial 561 finished with value: 8.764660795947025 and parameters: {'n_hidden': 3, 'learning_rate': 0.008701705995822274, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05311839709719171, 'dropout_rate_Layer_2': 0.19435428899041665, 'dropout_rate_Layer_3': 0.10704092531021547, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000526378474698077, 'l1_Layer_2': 6.256134888539278e-05, 'l1_Layer_3': 0.0031823840873627346, 'n_units_Layer_1': 215, 'n_units_Layer_2': 300, 'n_units_Layer_3': 270}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.76 | sMAPE for Validation Set is: 20.98% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 19.10% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:05:55,631]\u001b[0m Trial 567 finished with value: 6.823574673463511 and parameters: {'n_hidden': 3, 'learning_rate': 0.02367495076997841, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23104017908450655, 'dropout_rate_Layer_2': 0.24722185540162855, 'dropout_rate_Layer_3': 0.3286514009484148, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007893297751999661, 'l1_Layer_2': 0.0013967148638587227, 'l1_Layer_3': 0.0011572618585889791, 'n_units_Layer_1': 130, 'n_units_Layer_2': 150, 'n_units_Layer_3': 80}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 16.99% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 17.85% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:05:56,083]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:05:58,907]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:06:00,104]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:06:04,035]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:06:07,532]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:06:11,630]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:06:20,625]\u001b[0m Trial 578 finished with value: 7.398728807767231 and parameters: {'n_hidden': 3, 'learning_rate': 0.012610636556435779, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19925054119976257, 'dropout_rate_Layer_2': 0.19892350443231988, 'dropout_rate_Layer_3': 0.061920329345453995, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006150974561966277, 'l1_Layer_2': 0.026667707854854696, 'l1_Layer_3': 0.02398278533733122, 'n_units_Layer_1': 190, 'n_units_Layer_2': 95, 'n_units_Layer_3': 215}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.40 | sMAPE for Validation Set is: 18.23% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 18.42% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:06:24,072]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:06:26,787]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:06:30,848]\u001b[0m Trial 580 finished with value: 6.963845674862853 and parameters: {'n_hidden': 4, 'learning_rate': 0.011917879992262553, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2106157230469014, 'dropout_rate_Layer_2': 0.04002799625490844, 'dropout_rate_Layer_3': 0.22383527736552772, 'dropout_rate_Layer_4': 0.2791494915531785, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00018521485514732833, 'l1_Layer_2': 0.013760894184460188, 'l1_Layer_3': 0.0002606382251754442, 'l1_Layer_4': 0.00013494883597885732, 'n_units_Layer_1': 230, 'n_units_Layer_2': 300, 'n_units_Layer_3': 140, 'n_units_Layer_4': 140}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.96 | sMAPE for Validation Set is: 17.18% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 18.14% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:06:34,519]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:06:37,009]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:06:42,093]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:06:45,112]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:06:48,685]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:06:51,475]\u001b[0m Trial 585 finished with value: 6.890771903769708 and parameters: {'n_hidden': 4, 'learning_rate': 0.00907108577537006, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21033882157336276, 'dropout_rate_Layer_2': 0.041106512151156654, 'dropout_rate_Layer_3': 0.23343737083612923, 'dropout_rate_Layer_4': 0.27584025110839383, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012339807793316815, 'l1_Layer_2': 0.017336082213574123, 'l1_Layer_3': 0.00023690729135902804, 'l1_Layer_4': 0.00013269333182451304, 'n_units_Layer_1': 230, 'n_units_Layer_2': 110, 'n_units_Layer_3': 135, 'n_units_Layer_4': 145}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.89 | sMAPE for Validation Set is: 17.04% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.87 | sMAPE for Test Set is: 17.50% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:06:55,977]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:06:59,034]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:01,939]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:04,187]\u001b[0m Trial 582 finished with value: 6.531429143442566 and parameters: {'n_hidden': 3, 'learning_rate': 0.01878012310834931, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2909098317661515, 'dropout_rate_Layer_2': 0.23447502309502316, 'dropout_rate_Layer_3': 0.32104949509319947, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.6477126145670646e-05, 'l1_Layer_2': 0.001327640343820454, 'l1_Layer_3': 0.0009010572815824512, 'n_units_Layer_1': 105, 'n_units_Layer_2': 130, 'n_units_Layer_3': 125}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.53 | sMAPE for Validation Set is: 16.32% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.59 | sMAPE for Test Set is: 17.02% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:07:08,217]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:08,884]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:14,298]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:14,715]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:15,419]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:18,552]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:21,399]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:22,244]\u001b[0m Trial 587 finished with value: 7.3900562816403195 and parameters: {'n_hidden': 3, 'learning_rate': 0.022253911388355467, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29469270412288334, 'dropout_rate_Layer_2': 0.2247036199639081, 'dropout_rate_Layer_3': 0.3173101577186617, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.025546698130479113, 'l1_Layer_2': 0.0010276411177208402, 'l1_Layer_3': 0.0007017220019359094, 'n_units_Layer_1': 155, 'n_units_Layer_2': 125, 'n_units_Layer_3': 125}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.39 | sMAPE for Validation Set is: 18.25% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 18.33% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:07:22,663]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:28,576]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:30,250]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:33,357]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:35,940]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:36,311]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:43,064]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:43,584]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:46,724]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:47,318]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:48,982]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:07:55,437]\u001b[0m Trial 600 finished with value: 6.292109873059243 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016568487576947462, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.354331215439533, 'dropout_rate_Layer_2': 0.03631755268891265, 'dropout_rate_Layer_3': 0.04134659515365944, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.290963927334691e-05, 'l1_Layer_2': 0.00019401749912031541, 'l1_Layer_3': 1.9806865144538044e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 290, 'n_units_Layer_3': 145}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 15.81% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.42 | sMAPE for Test Set is: 16.80% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:07:55,739]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:00,426]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:00,760]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:08,090]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:10,856]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:13,965]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:15,654]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:18,277]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:18,403]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:19,374]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:26,153]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:26,598]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:31,244]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:31,691]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:31,996]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:38,344]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:46,406]\u001b[0m Trial 630 finished with value: 15.057718452856747 and parameters: {'n_hidden': 3, 'learning_rate': 0.04700232771905563, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23469275905552653, 'dropout_rate_Layer_2': 0.18081958271551535, 'dropout_rate_Layer_3': 0.32509801409028954, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0010107592337204533, 'l1_Layer_2': 0.00047799358575435834, 'l1_Layer_3': 0.001509164439730117, 'n_units_Layer_1': 300, 'n_units_Layer_2': 145, 'n_units_Layer_3': 190}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.06 | sMAPE for Validation Set is: 36.23% | rMAE for Validation Set is: 1.43\n",
      "MAE for Test Set is: 9.23 | sMAPE for Test Set is: 25.97% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:08:51,038]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:55,976]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:08:56,352]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:00,093]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:04,976]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:05,279]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:10,671]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:12,984]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:15,566]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:18,641]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:22,045]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:25,605]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:29,581]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:33,843]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:36,131]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:36,518]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:41,510]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:44,725]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:47,716]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:51,926]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:09:52,715]\u001b[0m Trial 641 finished with value: 6.464814754326583 and parameters: {'n_hidden': 3, 'learning_rate': 0.035323593647368805, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17082542791388144, 'dropout_rate_Layer_2': 0.34188670131311355, 'dropout_rate_Layer_3': 0.007643384988096885, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.223522831260234e-05, 'l1_Layer_2': 9.753517805412668e-05, 'l1_Layer_3': 0.001104046922903876, 'n_units_Layer_1': 165, 'n_units_Layer_2': 110, 'n_units_Layer_3': 75}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 16.12% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.59 | sMAPE for Test Set is: 16.94% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:09:53,096]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:10:05,265]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:10:08,164]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:10:08,610]\u001b[0m Trial 653 finished with value: 7.181037391013494 and parameters: {'n_hidden': 4, 'learning_rate': 0.007892267148652071, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2890588822999449, 'dropout_rate_Layer_2': 0.048822414022438296, 'dropout_rate_Layer_3': 0.2917977349651861, 'dropout_rate_Layer_4': 0.2445749710777659, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006755202958279704, 'l1_Layer_2': 0.021423902805662372, 'l1_Layer_3': 0.00012793856610372574, 'l1_Layer_4': 1.040570115119419e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 280, 'n_units_Layer_3': 120, 'n_units_Layer_4': 140}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.18 | sMAPE for Validation Set is: 17.80% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 17.68% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:10:13,085]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:10:13,505]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:10:18,320]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:10:19,026]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:10:23,205]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:10:24,939]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:10:25,210]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:10:26,477]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:10:34,789]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:10:40,845]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:10:41,660]\u001b[0m Trial 664 finished with value: 6.791991744485425 and parameters: {'n_hidden': 3, 'learning_rate': 0.005316608685863261, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.171847543021159, 'dropout_rate_Layer_2': 0.06166966813524019, 'dropout_rate_Layer_3': 0.2573926880165981, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00025539400874662115, 'l1_Layer_2': 2.7462528664880304e-05, 'l1_Layer_3': 1.1224430933239528e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 230}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.79 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 17.23% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:10:47,314]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:10:47,791]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:10:48,104]\u001b[0m Trial 631 finished with value: 6.221440549088257 and parameters: {'n_hidden': 3, 'learning_rate': 0.001685189852012981, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07940071286074485, 'dropout_rate_Layer_2': 0.29807809301530236, 'dropout_rate_Layer_3': 0.06153988333525895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011532699886338455, 'l1_Layer_2': 5.571296577569405e-05, 'l1_Layer_3': 0.004601555816277894, 'n_units_Layer_1': 185, 'n_units_Layer_2': 175, 'n_units_Layer_3': 120}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 15.52% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.42 | sMAPE for Test Set is: 16.57% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:10:54,450]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:10:55,352]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:11:00,422]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:11:07,977]\u001b[0m Trial 668 finished with value: 6.969156878722669 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020966815182015446, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19106377480855008, 'dropout_rate_Layer_2': 0.3203574219724512, 'dropout_rate_Layer_3': 0.09668317723321382, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007814216815398395, 'l1_Layer_2': 0.0168369321302023, 'l1_Layer_3': 0.0005542468924957258, 'n_units_Layer_1': 230, 'n_units_Layer_2': 130, 'n_units_Layer_3': 115}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.97 | sMAPE for Validation Set is: 17.31% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.06 | sMAPE for Test Set is: 18.11% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:11:11,463]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:11:14,196]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:11:15,865]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:11:16,192]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:11:17,288]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:11:23,654]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:11:32,522]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:11:36,683]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:11:37,248]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:11:39,537]\u001b[0m Trial 681 finished with value: 7.754801491341333 and parameters: {'n_hidden': 3, 'learning_rate': 0.06977311180834335, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17612110716018908, 'dropout_rate_Layer_2': 0.3874323174459645, 'dropout_rate_Layer_3': 0.07669994066676059, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.472699077947368e-05, 'l1_Layer_2': 2.5376073370694674e-05, 'l1_Layer_3': 0.00034579154344284977, 'n_units_Layer_1': 165, 'n_units_Layer_2': 80, 'n_units_Layer_3': 80}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.75 | sMAPE for Validation Set is: 18.91% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 20.13% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:11:42,710]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:11:46,083]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:11:49,321]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:11:51,459]\u001b[0m Trial 673 finished with value: 7.1213363133462435 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020923472012197666, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09615390917640897, 'dropout_rate_Layer_2': 0.30708978202972337, 'dropout_rate_Layer_3': 0.17296594739986454, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011941214743084183, 'l1_Layer_2': 0.03304524212903883, 'l1_Layer_3': 0.005605016316845017, 'n_units_Layer_1': 175, 'n_units_Layer_2': 140, 'n_units_Layer_3': 115}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.12 | sMAPE for Validation Set is: 17.53% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.18 | sMAPE for Test Set is: 18.26% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:11:53,126]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:11:55,902]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:12:00,981]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:12:03,827]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:12:04,323]\u001b[0m Trial 686 finished with value: 6.413902290230634 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022572840044177236, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37174070566023304, 'dropout_rate_Layer_2': 0.019872330537451167, 'dropout_rate_Layer_3': 0.05228931994951466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.621923872083928e-05, 'l1_Layer_2': 0.00016519599712293715, 'l1_Layer_3': 2.4870798753506592e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 300, 'n_units_Layer_3': 145}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 16.08% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.56 | sMAPE for Test Set is: 17.09% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:12:04,877]\u001b[0m Trial 684 finished with value: 6.393855868597936 and parameters: {'n_hidden': 3, 'learning_rate': 0.002237957327436534, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3470281504468635, 'dropout_rate_Layer_2': 0.021616218984176722, 'dropout_rate_Layer_3': 0.05546333760223888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.0250646458347858e-05, 'l1_Layer_2': 0.00016491225676897899, 'l1_Layer_3': 1.2151432503053727e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 300, 'n_units_Layer_3': 145}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 16.00% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 17.37% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:12:10,295]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:12:11,336]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:12:16,863]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:12:20,207]\u001b[0m Trial 692 finished with value: 6.701941226208009 and parameters: {'n_hidden': 3, 'learning_rate': 0.017632853183274625, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0798006651130942, 'dropout_rate_Layer_2': 0.06884750472811542, 'dropout_rate_Layer_3': 0.25725960381455065, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00027115051766851694, 'l1_Layer_2': 3.697293476737273e-05, 'l1_Layer_3': 0.005492305808053826, 'n_units_Layer_1': 180, 'n_units_Layer_2': 190, 'n_units_Layer_3': 215}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.70 | sMAPE for Validation Set is: 16.74% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.65 | sMAPE for Test Set is: 17.16% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:12:20,805]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:12:25,204]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:12:25,526]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:12:25,670]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:12:36,213]\u001b[0m Trial 696 finished with value: 6.330656556956595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019560021957064208, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3855453842587416, 'dropout_rate_Layer_2': 0.06344770154041512, 'dropout_rate_Layer_3': 0.041043188566127126, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.7519187600209e-05, 'l1_Layer_2': 1.2920838290971041e-05, 'l1_Layer_3': 3.18098980336015e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 280, 'n_units_Layer_3': 105}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 15.78% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.46 | sMAPE for Test Set is: 16.72% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:12:36,415]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:12:41,430]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:12:44,596]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:12:46,219]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:12:48,546]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:12:50,263]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:12:54,935]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:12:55,499]\u001b[0m Trial 706 finished with value: 7.939539388198426 and parameters: {'n_hidden': 3, 'learning_rate': 0.04614996861585527, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07647682655677553, 'dropout_rate_Layer_2': 0.15244038913480557, 'dropout_rate_Layer_3': 0.25781423335481735, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.5182920330417386e-05, 'l1_Layer_2': 0.00029874514211551743, 'l1_Layer_3': 0.00796288325037873, 'n_units_Layer_1': 175, 'n_units_Layer_2': 235, 'n_units_Layer_3': 205}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.94 | sMAPE for Validation Set is: 19.19% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.63 | sMAPE for Test Set is: 18.91% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:12:55,629]\u001b[0m Trial 702 finished with value: 6.9577806570987235 and parameters: {'n_hidden': 4, 'learning_rate': 0.011185762717589198, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24997925999296228, 'dropout_rate_Layer_2': 0.09408032451204476, 'dropout_rate_Layer_3': 0.2409597026807775, 'dropout_rate_Layer_4': 0.16062119083349896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00018528039206830029, 'l1_Layer_2': 0.0032778943015441702, 'l1_Layer_3': 0.00034508089051923176, 'l1_Layer_4': 0.00030562625613588776, 'n_units_Layer_1': 245, 'n_units_Layer_2': 135, 'n_units_Layer_3': 145, 'n_units_Layer_4': 170}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.96 | sMAPE for Validation Set is: 17.19% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 18.35% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:13:01,402]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:03,198]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:05,585]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:05,618]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:06,668]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:06,976]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:13,571]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:14,120]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:14,290]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:14,414]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:19,583]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:24,009]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:24,871]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:25,397]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:25,761]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:29,130]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:34,446]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:35,101]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:36,657]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:40,938]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:43,975]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:46,320]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:48,453]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:51,366]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:52,080]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:55,893]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:13:57,016]\u001b[0m Trial 729 finished with value: 6.7436812995132795 and parameters: {'n_hidden': 3, 'learning_rate': 0.013068145528902248, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03249273134640708, 'dropout_rate_Layer_2': 0.19934367706915357, 'dropout_rate_Layer_3': 0.1971586238251295, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002883325233662606, 'l1_Layer_2': 3.305005835852309e-05, 'l1_Layer_3': 0.005626491195637492, 'n_units_Layer_1': 145, 'n_units_Layer_2': 195, 'n_units_Layer_3': 190}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.74 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 17.38% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:14:01,257]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:04,033]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.89 | sMAPE for Validation Set is: 17.16% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 17.47% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:14:06,007]\u001b[0m Trial 735 finished with value: 6.886850570500229 and parameters: {'n_hidden': 3, 'learning_rate': 0.015033010907362287, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022628243075286967, 'dropout_rate_Layer_2': 0.22926090953307854, 'dropout_rate_Layer_3': 0.19011401856209934, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00035050025112660395, 'l1_Layer_2': 3.08164765771435e-05, 'l1_Layer_3': 0.0006533317411900561, 'n_units_Layer_1': 150, 'n_units_Layer_2': 195, 'n_units_Layer_3': 185}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:08,665]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:12,137]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:14,563]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:15,952]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:18,191]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:19,329]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:21,259]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:21,778]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:27,553]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:29,383]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:32,156]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:34,319]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:37,857]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:38,439]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:42,344]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:44,190]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:52,882]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:14:56,920]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:15:00,343]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:15:04,107]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:15:16,288]\u001b[0m Trial 764 finished with value: 9.0170810407944 and parameters: {'n_hidden': 3, 'learning_rate': 0.02597951525981748, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06720582386040524, 'dropout_rate_Layer_2': 0.06335503454341568, 'dropout_rate_Layer_3': 0.23883231747312655, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011159604215675828, 'l1_Layer_2': 0.00012051819507789329, 'l1_Layer_3': 0.0016662388435800819, 'n_units_Layer_1': 200, 'n_units_Layer_2': 130, 'n_units_Layer_3': 150}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.02 | sMAPE for Validation Set is: 21.50% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 7.25 | sMAPE for Test Set is: 20.50% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:15:19,342]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:15:23,086]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 16.17% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.50 | sMAPE for Test Set is: 16.94% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:15:24,668]\u001b[0m Trial 750 finished with value: 6.456575726703004 and parameters: {'n_hidden': 3, 'learning_rate': 0.014940640926135852, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22060346731251643, 'dropout_rate_Layer_2': 0.27275288226937466, 'dropout_rate_Layer_3': 0.00395224341000701, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.9449308109802166e-05, 'l1_Layer_2': 9.883869821354654e-05, 'l1_Layer_3': 0.0029496504186226702, 'n_units_Layer_1': 135, 'n_units_Layer_2': 85, 'n_units_Layer_3': 130}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:15:27,836]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:15:30,326]\u001b[0m Trial 752 finished with value: 6.500439592300736 and parameters: {'n_hidden': 3, 'learning_rate': 0.018819966715523734, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21106934753532533, 'dropout_rate_Layer_2': 0.28126016673263277, 'dropout_rate_Layer_3': 0.002120368665723589, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.971725980713527e-05, 'l1_Layer_2': 0.00011752358667903885, 'l1_Layer_3': 0.0013526412705556726, 'n_units_Layer_1': 140, 'n_units_Layer_2': 85, 'n_units_Layer_3': 130}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.50 | sMAPE for Validation Set is: 16.32% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.63 | sMAPE for Test Set is: 17.21% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:15:33,556]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:15:34,158]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:15:34,245]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:15:41,118]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:15:47,169]\u001b[0m Trial 760 finished with value: 6.597303991676266 and parameters: {'n_hidden': 3, 'learning_rate': 0.015117275459448428, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21724673557209054, 'dropout_rate_Layer_2': 0.2820050837635757, 'dropout_rate_Layer_3': 0.05431293218830268, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.290223348433548e-05, 'l1_Layer_2': 9.017161721488397e-05, 'l1_Layer_3': 0.003371141929172244, 'n_units_Layer_1': 140, 'n_units_Layer_2': 85, 'n_units_Layer_3': 135}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 16.63% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 17.59% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:15:49,449]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:15:50,192]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 16.86% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.87 | sMAPE for Test Set is: 17.83% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:15:51,588]\u001b[0m Trial 771 finished with value: 6.818586407325455 and parameters: {'n_hidden': 3, 'learning_rate': 0.01068648020648237, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20139316856795494, 'dropout_rate_Layer_2': 0.1685776888541142, 'dropout_rate_Layer_3': 0.09669571720629364, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00047995460053282946, 'l1_Layer_2': 1.8361615639320938e-05, 'l1_Layer_3': 0.0021540711170345427, 'n_units_Layer_1': 125, 'n_units_Layer_2': 170, 'n_units_Layer_3': 135}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.37 | sMAPE for Validation Set is: 19.93% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.04 | sMAPE for Test Set is: 19.93% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:15:52,019]\u001b[0m Trial 774 finished with value: 8.366807227427733 and parameters: {'n_hidden': 3, 'learning_rate': 0.006331564161246442, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1441525410878748, 'dropout_rate_Layer_2': 0.11851519019780055, 'dropout_rate_Layer_3': 0.2950255886449968, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0018961517720501395, 'l1_Layer_2': 0.00042011613368672033, 'l1_Layer_3': 0.015755760653675947, 'n_units_Layer_1': 235, 'n_units_Layer_2': 240, 'n_units_Layer_3': 280}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:15:53,386]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:15:57,505]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:15:59,009]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:15:59,334]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:01,590]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:04,585]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:07,499]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:09,695]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:11,267]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:13,353]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:15,781]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:16,921]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:20,004]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:22,994]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:25,797]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:29,599]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:32,223]\u001b[0m Trial 783 finished with value: 7.206237108818422 and parameters: {'n_hidden': 3, 'learning_rate': 0.0382790115847357, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0827249607958292, 'dropout_rate_Layer_2': 0.17025884570179456, 'dropout_rate_Layer_3': 0.024360056792724516, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003431782010563011, 'l1_Layer_2': 0.0022100066679283307, 'l1_Layer_3': 0.005427424104899821, 'n_units_Layer_1': 120, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.21 | sMAPE for Validation Set is: 17.93% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.10 | sMAPE for Test Set is: 18.41% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:16:34,175]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:36,215]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:37,063]\u001b[0m Trial 784 finished with value: 6.301340664477682 and parameters: {'n_hidden': 3, 'learning_rate': 0.002627783138178176, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18496631935838606, 'dropout_rate_Layer_2': 0.19584525460781932, 'dropout_rate_Layer_3': 0.08405459663505255, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000848140781744571, 'l1_Layer_2': 1.5068393355856326e-05, 'l1_Layer_3': 0.0015450175781771016, 'n_units_Layer_1': 125, 'n_units_Layer_2': 165, 'n_units_Layer_3': 135}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 15.76% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 17.12% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:16:41,694]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:44,931]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:48,293]\u001b[0m Trial 797 finished with value: 7.667040680231772 and parameters: {'n_hidden': 3, 'learning_rate': 0.010565149074289855, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13470245946654835, 'dropout_rate_Layer_2': 0.22073103024044166, 'dropout_rate_Layer_3': 0.2735546104805505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010212018232463442, 'l1_Layer_2': 0.00011654646835729783, 'l1_Layer_3': 0.00033512182922286124, 'n_units_Layer_1': 180, 'n_units_Layer_2': 85, 'n_units_Layer_3': 255}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.67 | sMAPE for Validation Set is: 18.77% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 19.26% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:16:50,547]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:53,534]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:16:56,280]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.33 | sMAPE for Validation Set is: 17.70% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.39 | sMAPE for Test Set is: 18.60% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:16:58,386]\u001b[0m Trial 798 finished with value: 7.327009772526263 and parameters: {'n_hidden': 4, 'learning_rate': 0.013868135293683682, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23826886221986332, 'dropout_rate_Layer_2': 0.0351801878660132, 'dropout_rate_Layer_3': 0.12232501096962911, 'dropout_rate_Layer_4': 0.2036422813080653, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008083141423585608, 'l1_Layer_2': 3.787257923520287e-05, 'l1_Layer_3': 4.420694653538773e-05, 'l1_Layer_4': 0.00017520907833219447, 'n_units_Layer_1': 130, 'n_units_Layer_2': 180, 'n_units_Layer_3': 200, 'n_units_Layer_4': 170}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:17:02,050]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:17:02,177]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:17:03,580]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:17:09,338]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:17:11,281]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:17:16,130]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:17:21,770]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:17:24,785]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:17:28,318]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:17:33,540]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:17:34,408]\u001b[0m Trial 808 finished with value: 7.063640121206002 and parameters: {'n_hidden': 3, 'learning_rate': 0.011245745687783738, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029743921656968847, 'dropout_rate_Layer_2': 0.09433116045868523, 'dropout_rate_Layer_3': 0.21725996405544565, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020588215156260354, 'l1_Layer_2': 6.750054909616918e-05, 'l1_Layer_3': 0.0005664404138608928, 'n_units_Layer_1': 250, 'n_units_Layer_2': 160, 'n_units_Layer_3': 145}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.06 | sMAPE for Validation Set is: 17.56% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.05 | sMAPE for Test Set is: 18.01% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:17:37,995]\u001b[0m Trial 800 finished with value: 6.466414591069551 and parameters: {'n_hidden': 3, 'learning_rate': 0.0182480326153582, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17479159128630284, 'dropout_rate_Layer_2': 0.29071153773632946, 'dropout_rate_Layer_3': 0.04964748536931782, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.188850459187394e-05, 'l1_Layer_2': 3.2759243858156496e-05, 'l1_Layer_3': 0.0004983999057229247, 'n_units_Layer_1': 145, 'n_units_Layer_2': 80, 'n_units_Layer_3': 105}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 16.13% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.49 | sMAPE for Test Set is: 16.80% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:17:38,181]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:17:50,889]\u001b[0m Trial 817 finished with value: 6.570172182115097 and parameters: {'n_hidden': 3, 'learning_rate': 0.012851407969123037, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03837910067371685, 'dropout_rate_Layer_2': 0.19104805120914858, 'dropout_rate_Layer_3': 0.20480323526023747, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00042094753698620547, 'l1_Layer_2': 2.4853528975970286e-05, 'l1_Layer_3': 0.005645598598037078, 'n_units_Layer_1': 130, 'n_units_Layer_2': 200, 'n_units_Layer_3': 185}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 16.44% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:17:53,758]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:17:57,438]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:18:01,590]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:18:02,291]\u001b[0m Trial 818 finished with value: 6.436734595027938 and parameters: {'n_hidden': 3, 'learning_rate': 0.002263292906514146, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3368069952154829, 'dropout_rate_Layer_2': 0.03454272071988305, 'dropout_rate_Layer_3': 0.00022167721151929512, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9144929766122604e-05, 'l1_Layer_2': 1.9402637671605455e-05, 'l1_Layer_3': 7.101630479000558e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 290, 'n_units_Layer_3': 120}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 16.18% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.63 | sMAPE for Test Set is: 17.14% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:18:06,088]\u001b[0m Trial 819 finished with value: 6.6548637207449035 and parameters: {'n_hidden': 3, 'learning_rate': 0.012458081511103301, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0341886416798888, 'dropout_rate_Layer_2': 0.1955099587150109, 'dropout_rate_Layer_3': 0.13169092654162276, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011411788058097334, 'l1_Layer_2': 3.683271871554819e-05, 'l1_Layer_3': 0.002224875426835068, 'n_units_Layer_1': 190, 'n_units_Layer_2': 205, 'n_units_Layer_3': 190}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.65 | sMAPE for Validation Set is: 16.57% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 17.56% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:18:08,358]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:18:11,924]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:18:14,877]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:18:18,745]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:18:24,981]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:18:25,623]\u001b[0m Trial 825 finished with value: 6.4062131321563385 and parameters: {'n_hidden': 3, 'learning_rate': 0.006485046422757334, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029464821325534584, 'dropout_rate_Layer_2': 0.16740221230561586, 'dropout_rate_Layer_3': 0.12101187170432356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.510670754331318e-05, 'l1_Layer_2': 2.139560999553552e-05, 'l1_Layer_3': 0.002356438303743129, 'n_units_Layer_1': 125, 'n_units_Layer_2': 205, 'n_units_Layer_3': 155}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 16.03% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.47 | sMAPE for Test Set is: 16.53% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:18:29,777]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:18:29,955]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:18:35,215]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:18:40,515]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:18:46,279]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:18:48,844]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:18:49,297]\u001b[0m Trial 812 finished with value: 6.410549518513725 and parameters: {'n_hidden': 3, 'learning_rate': 0.017864639584804057, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08141054280230767, 'dropout_rate_Layer_2': 0.29273065440986973, 'dropout_rate_Layer_3': 0.050831717529497666, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.81819489233131e-05, 'l1_Layer_2': 3.900832433394315e-05, 'l1_Layer_3': 0.0006290173840713962, 'n_units_Layer_1': 145, 'n_units_Layer_2': 80, 'n_units_Layer_3': 195}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 16.04% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 16.52% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:18:54,324]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:18:55,120]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:18:59,500]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:18:59,802]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:19:04,206]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:19:04,822]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:19:11,060]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:19:13,715]\u001b[0m Trial 833 finished with value: 6.3218330846405 and parameters: {'n_hidden': 3, 'learning_rate': 0.003048932593354207, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17199425332132318, 'dropout_rate_Layer_2': 0.16375656236716207, 'dropout_rate_Layer_3': 0.19247351980246147, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003571215372842601, 'l1_Layer_2': 0.0004668770317431095, 'l1_Layer_3': 0.0022275911372250344, 'n_units_Layer_1': 160, 'n_units_Layer_2': 165, 'n_units_Layer_3': 135}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 15.65% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 17.10% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:19:16,805]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:19:23,540]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:19:26,167]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:19:26,578]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:19:31,346]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:19:33,855]\u001b[0m Trial 835 finished with value: 6.557326806271988 and parameters: {'n_hidden': 3, 'learning_rate': 0.018940204499034795, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13446488244024152, 'dropout_rate_Layer_2': 0.3376896950932328, 'dropout_rate_Layer_3': 0.054091112778923096, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8064320140824957e-05, 'l1_Layer_2': 5.0712225479062875e-05, 'l1_Layer_3': 1.4393033805521424e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 85, 'n_units_Layer_3': 120}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.56 | sMAPE for Validation Set is: 16.57% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 16.99% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:19:34,747]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:19:38,585]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:19:39,730]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:19:43,725]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:19:45,671]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:19:50,715]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:19:54,239]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:19:54,544]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:19:55,102]\u001b[0m Trial 847 finished with value: 6.368219286585486 and parameters: {'n_hidden': 3, 'learning_rate': 0.002875583868156553, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10127771156354953, 'dropout_rate_Layer_2': 0.14945772628298182, 'dropout_rate_Layer_3': 0.08322687806481495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005825547379704922, 'l1_Layer_2': 0.0002624639081012035, 'l1_Layer_3': 0.0036877242298698418, 'n_units_Layer_1': 160, 'n_units_Layer_2': 160, 'n_units_Layer_3': 140}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 15.94% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.55 | sMAPE for Test Set is: 17.07% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:19:55,453]\u001b[0m Trial 849 finished with value: 6.394939336336496 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033977649133876634, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09999155923583314, 'dropout_rate_Layer_2': 0.14405819628318617, 'dropout_rate_Layer_3': 0.08698865262921902, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006355373282362045, 'l1_Layer_2': 3.2834490493684105e-05, 'l1_Layer_3': 0.002584207085786144, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 140}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 15.93% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 17.15% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:20:03,002]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:20:03,688]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:20:07,772]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:20:12,768]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:20:22,156]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:20:25,113]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 15.69% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.63 | sMAPE for Test Set is: 16.89% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:20:32,010]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:20:32,027]\u001b[0m Trial 861 finished with value: 6.311437748948623 and parameters: {'n_hidden': 3, 'learning_rate': 0.002410175046234185, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10497596240407134, 'dropout_rate_Layer_2': 0.1465373697764928, 'dropout_rate_Layer_3': 0.10289103337693, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006559818152568854, 'l1_Layer_2': 0.000559084308240307, 'l1_Layer_3': 0.002594801245020111, 'n_units_Layer_1': 160, 'n_units_Layer_2': 180, 'n_units_Layer_3': 145}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:20:33,150]\u001b[0m Trial 860 finished with value: 6.239680944483041 and parameters: {'n_hidden': 3, 'learning_rate': 0.002939454260213792, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10011240729719788, 'dropout_rate_Layer_2': 0.14613903459147928, 'dropout_rate_Layer_3': 0.19373869818568168, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006027562716830185, 'l1_Layer_2': 3.388740052608268e-05, 'l1_Layer_3': 0.0025492890298928, 'n_units_Layer_1': 160, 'n_units_Layer_2': 180, 'n_units_Layer_3': 145}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 15.45% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.49 | sMAPE for Test Set is: 16.80% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:20:39,522]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:20:43,009]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:20:43,458]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:20:53,228]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:20:53,828]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:20:58,873]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:20:59,563]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:04,578]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:05,789]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:09,075]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:09,108]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:09,149]\u001b[0m Trial 875 finished with value: 10.47626956306925 and parameters: {'n_hidden': 4, 'learning_rate': 0.006586284273032058, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0363783564238444, 'dropout_rate_Layer_2': 0.15076011103806394, 'dropout_rate_Layer_3': 0.1276235434345129, 'dropout_rate_Layer_4': 0.0024743729671724, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.175636295857316e-05, 'l1_Layer_2': 1.9423542154085305e-05, 'l1_Layer_3': 0.0011599573914038363, 'l1_Layer_4': 0.0814867046169913, 'n_units_Layer_1': 125, 'n_units_Layer_2': 230, 'n_units_Layer_3': 155, 'n_units_Layer_4': 295}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.48 | sMAPE for Validation Set is: 31.07% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 7.81 | sMAPE for Test Set is: 23.22% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:21:09,575]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:16,981]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:18,020]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:18,072]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:19,810]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:22,703]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:26,896]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:30,007]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:32,890]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:36,354]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:36,749]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:41,928]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:45,386]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:45,864]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:52,383]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:55,287]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:58,132]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:21:58,693]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:22:06,280]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:22:08,219]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:22:08,820]\u001b[0m Trial 896 finished with value: 6.412650029994478 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030740887419003654, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10988672629546195, 'dropout_rate_Layer_2': 0.1564199617660594, 'dropout_rate_Layer_3': 0.17858876049095238, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004456518923666418, 'l1_Layer_2': 0.0011573699422409837, 'l1_Layer_3': 0.0027122648658898557, 'n_units_Layer_1': 165, 'n_units_Layer_2': 195, 'n_units_Layer_3': 145}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 16.05% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 16.94% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:22:09,602]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:22:15,823]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:22:16,527]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:22:20,177]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:22:22,015]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:22:22,222]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:22:25,099]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:22:31,455]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:22:35,164]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:22:45,181]\u001b[0m Trial 889 finished with value: 6.268864071490989 and parameters: {'n_hidden': 3, 'learning_rate': 0.012236249240060507, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04935713769205191, 'dropout_rate_Layer_2': 0.29477625719218414, 'dropout_rate_Layer_3': 0.00016846713715934492, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.634006976899756e-05, 'l1_Layer_2': 5.364626982001533e-05, 'l1_Layer_3': 8.342685202870384e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 15.66% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.41 | sMAPE for Test Set is: 16.61% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:22:52,353]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:22:54,640]\u001b[0m Trial 913 finished with value: 10.924638828734002 and parameters: {'n_hidden': 3, 'learning_rate': 0.002689517704925228, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29437471409292826, 'dropout_rate_Layer_2': 0.22520654000472412, 'dropout_rate_Layer_3': 0.07103171389594685, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 3.16506584963369e-05, 'l1_Layer_2': 1.0909848380851509e-05, 'l1_Layer_3': 0.0020970490478660862, 'n_units_Layer_1': 100, 'n_units_Layer_2': 205, 'n_units_Layer_3': 170}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.92 | sMAPE for Validation Set is: 26.28% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 7.10 | sMAPE for Test Set is: 20.66% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:22:56,323]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:23:01,316]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:23:01,464]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:23:05,241]\u001b[0m Trial 914 finished with value: 10.955285054780475 and parameters: {'n_hidden': 3, 'learning_rate': 0.004065727639371008, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02690367881811346, 'dropout_rate_Layer_2': 0.32086773247283407, 'dropout_rate_Layer_3': 0.054183742299096394, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.9047836261082005e-05, 'l1_Layer_2': 1.0876052415044343e-05, 'l1_Layer_3': 0.0018589286240425671, 'n_units_Layer_1': 80, 'n_units_Layer_2': 255, 'n_units_Layer_3': 140}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.96 | sMAPE for Validation Set is: 26.40% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 7.13 | sMAPE for Test Set is: 20.67% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:23:07,225]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:23:08,149]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:23:09,030]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:23:11,564]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:23:18,237]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:23:21,084]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:23:22,005]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:23:25,268]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:23:34,136]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:23:34,799]\u001b[0m Trial 912 finished with value: 6.8814873303714394 and parameters: {'n_hidden': 3, 'learning_rate': 0.011785051778968682, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 9.536277512658953e-05, 'dropout_rate_Layer_2': 0.37311161662788056, 'dropout_rate_Layer_3': 0.004926737899701197, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.173013738640992e-05, 'l1_Layer_2': 4.819517152303028e-05, 'l1_Layer_3': 8.783907785120997e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 50, 'n_units_Layer_3': 160}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.88 | sMAPE for Validation Set is: 17.11% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.66 | sMAPE for Test Set is: 17.25% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:23:39,211]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:23:42,543]\u001b[0m Trial 927 finished with value: 7.170506912880548 and parameters: {'n_hidden': 4, 'learning_rate': 0.009423368006603552, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16551830077059104, 'dropout_rate_Layer_2': 0.03964302651988845, 'dropout_rate_Layer_3': 0.22011185540161082, 'dropout_rate_Layer_4': 0.26791951525007246, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00017232477084817437, 'l1_Layer_2': 0.01550199990348239, 'l1_Layer_3': 0.00015170803310226967, 'l1_Layer_4': 7.608789776051216e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 110, 'n_units_Layer_3': 140, 'n_units_Layer_4': 120}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:23:42,650]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.17 | sMAPE for Validation Set is: 17.73% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.17 | sMAPE for Test Set is: 18.32% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:23:42,785]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:23:48,967]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:23:49,196]\u001b[0m Trial 924 finished with value: 6.39063703543425 and parameters: {'n_hidden': 3, 'learning_rate': 0.002467482915174825, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12450748138992841, 'dropout_rate_Layer_2': 0.13852346611394312, 'dropout_rate_Layer_3': 0.20598769424182822, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00045484090807734555, 'l1_Layer_2': 0.0006338774595553532, 'l1_Layer_3': 0.004917136087715528, 'n_units_Layer_1': 155, 'n_units_Layer_2': 180, 'n_units_Layer_3': 155}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 16.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.64 | sMAPE for Test Set is: 17.29% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:23:49,775]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:23:49,789]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:24:00,345]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:24:03,963]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:24:04,177]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:24:05,158]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:24:11,537]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:24:12,463]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:24:22,661]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:24:31,314]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:24:31,657]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:24:36,887]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:24:39,418]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:24:40,693]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:24:45,790]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:24:48,819]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:24:52,908]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:24:53,058]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:25:09,646]\u001b[0m Trial 945 finished with value: 6.187689427317743 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011807229998115206, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37760095664818977, 'dropout_rate_Layer_2': 0.027919937019474716, 'dropout_rate_Layer_3': 0.09741809700875621, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.178644421685194e-05, 'l1_Layer_2': 0.00017891480276700588, 'l1_Layer_3': 2.7969862722410346e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 15.44% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.39 | sMAPE for Test Set is: 16.38% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:25:13,633]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:25:18,869]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:25:26,240]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:25:31,350]\u001b[0m Trial 940 finished with value: 6.360358719292965 and parameters: {'n_hidden': 3, 'learning_rate': 0.00885492990655511, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06402871143141477, 'dropout_rate_Layer_2': 0.3003497638720867, 'dropout_rate_Layer_3': 0.03587162860503399, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6206779934275045e-05, 'l1_Layer_2': 0.00012822077554757065, 'l1_Layer_3': 1.895835727924065e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 70, 'n_units_Layer_3': 220}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 15.94% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.54 | sMAPE for Test Set is: 16.72% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:25:31,806]\u001b[0m Trial 954 finished with value: 6.289599353758484 and parameters: {'n_hidden': 3, 'learning_rate': 0.002890722163017911, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1317359232143434, 'dropout_rate_Layer_2': 0.1491748022560134, 'dropout_rate_Layer_3': 0.18149151013467055, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007270989503946275, 'l1_Layer_2': 0.0010284404068952614, 'l1_Layer_3': 0.0024370319639942734, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 140}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 15.69% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.57 | sMAPE for Test Set is: 16.96% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:25:31,963]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:25:40,962]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:25:40,993]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:25:41,695]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:25:48,372]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:25:49,002]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:25:49,820]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:25:50,643]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:25:58,724]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:25:59,434]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:26:04,871]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:26:05,096]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:26:10,656]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:26:11,731]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:26:23,694]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:26:27,419]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:26:30,542]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:26:34,555]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:26:35,603]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:26:40,029]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:26:40,788]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:26:45,614]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:26:48,688]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:26:50,397]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:26:53,010]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:26:58,106]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:27:12,281]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:27:18,685]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:27:22,060]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:27:22,227]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:27:23,122]\u001b[0m Trial 967 finished with value: 6.430912761631625 and parameters: {'n_hidden': 3, 'learning_rate': 0.004495137633520343, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05259105880058638, 'dropout_rate_Layer_2': 0.32004814598361886, 'dropout_rate_Layer_3': 0.033744612774932486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.336775203873259e-05, 'l1_Layer_2': 6.840556680999918e-05, 'l1_Layer_3': 2.7296720476248483e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 16.06% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.40 | sMAPE for Test Set is: 16.54% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:27:32,498]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:27:46,984]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:27:56,319]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:28:00,629]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:28:05,586]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:28:09,407]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:28:10,173]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:28:14,707]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:28:17,387]\u001b[0m Trial 990 finished with value: 10.241006314323823 and parameters: {'n_hidden': 4, 'learning_rate': 0.020709798194884527, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05466083599725017, 'dropout_rate_Layer_2': 0.26469531806421953, 'dropout_rate_Layer_3': 0.11979385831061429, 'dropout_rate_Layer_4': 0.3848732764708608, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00011070317062459032, 'l1_Layer_2': 0.01340400252621977, 'l1_Layer_3': 8.335878709270118e-05, 'l1_Layer_4': 0.08402223453766701, 'n_units_Layer_1': 165, 'n_units_Layer_2': 165, 'n_units_Layer_3': 185, 'n_units_Layer_4': 210}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.24 | sMAPE for Validation Set is: 24.82% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 7.17 | sMAPE for Test Set is: 21.09% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:28:18,279]\u001b[0m Trial 991 finished with value: 6.226983677865573 and parameters: {'n_hidden': 3, 'learning_rate': 0.002303206782902426, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11295081160959372, 'dropout_rate_Layer_2': 0.15802850520213085, 'dropout_rate_Layer_3': 0.17566621627539625, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00032784429551966884, 'l1_Layer_2': 0.0007961855444869744, 'l1_Layer_3': 0.004044829289296414, 'n_units_Layer_1': 170, 'n_units_Layer_2': 160, 'n_units_Layer_3': 145}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 15.63% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 16.87% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:28:18,470]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:28:19,366]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:28:26,867]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:28:27,918]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:28:32,372]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:28:36,685]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:28:40,557]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:28:42,671]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:28:45,657]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:28:50,649]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:28:51,061]\u001b[0m Trial 1003 finished with value: 6.634228989954212 and parameters: {'n_hidden': 3, 'learning_rate': 0.006280393326249612, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2711154156315543, 'dropout_rate_Layer_2': 0.16286952162403445, 'dropout_rate_Layer_3': 0.17223357228761127, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.090356281425635e-05, 'l1_Layer_2': 2.0719223238909955e-05, 'l1_Layer_3': 0.00085611778087931, 'n_units_Layer_1': 130, 'n_units_Layer_2': 225, 'n_units_Layer_3': 105}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.63 | sMAPE for Validation Set is: 16.47% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 17.59% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:28:56,774]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:28:57,147]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:29:04,972]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:29:08,270]\u001b[0m Trial 1002 finished with value: 6.776572083308598 and parameters: {'n_hidden': 4, 'learning_rate': 0.0042017418512937015, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09661451043660105, 'dropout_rate_Layer_2': 0.009384561240520551, 'dropout_rate_Layer_3': 0.2893446893528352, 'dropout_rate_Layer_4': 0.2483687288408692, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001934879641990872, 'l1_Layer_2': 8.727390968348744e-05, 'l1_Layer_3': 0.0004695485865814106, 'l1_Layer_4': 2.6676434671653336e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 80, 'n_units_Layer_3': 180, 'n_units_Layer_4': 135}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.78 | sMAPE for Validation Set is: 16.59% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 17.37% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:29:08,769]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:29:11,256]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:29:13,799]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:29:17,377]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:29:21,985]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:29:24,409]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:29:28,190]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:29:31,343]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:29:35,601]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:29:39,090]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:29:39,506]\u001b[0m Trial 1017 finished with value: 11.545120117011683 and parameters: {'n_hidden': 4, 'learning_rate': 0.005639282645737721, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2823567915653339, 'dropout_rate_Layer_2': 0.38889813435165876, 'dropout_rate_Layer_3': 0.2147184753400144, 'dropout_rate_Layer_4': 0.11705166646582134, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.6485771541647023e-05, 'l1_Layer_2': 9.198713373627447e-05, 'l1_Layer_3': 0.000946125312557052, 'l1_Layer_4': 1.1484509306523176e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 225, 'n_units_Layer_3': 95, 'n_units_Layer_4': 240}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.55 | sMAPE for Validation Set is: 27.65% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 7.52 | sMAPE for Test Set is: 21.60% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:29:49,732]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:29:51,955]\u001b[0m Trial 1019 finished with value: 6.403881062355232 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020479438408494153, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05555091984063288, 'dropout_rate_Layer_2': 0.034593530087622074, 'dropout_rate_Layer_3': 0.304902806267546, 'dropout_rate_Layer_4': 0.2280691522039605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004164915188801329, 'l1_Layer_2': 5.711396612808131e-05, 'l1_Layer_3': 0.001924014102013169, 'l1_Layer_4': 2.6759560430864923e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 100, 'n_units_Layer_3': 160, 'n_units_Layer_4': 135}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 15.88% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.38 | sMAPE for Test Set is: 16.30% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:29:53,543]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:29:54,788]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:30:00,613]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:30:03,841]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:30:07,775]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:30:10,653]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:30:18,789]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:30:24,908]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:30:28,418]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:30:31,472]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:30:34,065]\u001b[0m Trial 1029 finished with value: 6.44955352265464 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025361000097155447, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06792202796995228, 'dropout_rate_Layer_2': 0.006187470979514869, 'dropout_rate_Layer_3': 0.3464376849190659, 'dropout_rate_Layer_4': 0.22348932091431672, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00043458000279267793, 'l1_Layer_2': 5.874044147298785e-05, 'l1_Layer_3': 0.0018919171064010693, 'l1_Layer_4': 3.182397138217339e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 100, 'n_units_Layer_3': 170, 'n_units_Layer_4': 135}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 15.61% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 16.96% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:30:36,176]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:30:39,707]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:30:47,288]\u001b[0m Trial 1034 finished with value: 6.515911170651848 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016342867441400436, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05465283884666825, 'dropout_rate_Layer_2': 0.008355618141525308, 'dropout_rate_Layer_3': 0.33643182230423835, 'dropout_rate_Layer_4': 0.19724160052499748, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0008982879552513267, 'l1_Layer_2': 5.347734310114563e-05, 'l1_Layer_3': 0.0016767946401497374, 'l1_Layer_4': 1.0915304106841434e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 75, 'n_units_Layer_3': 160, 'n_units_Layer_4': 140}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.52 | sMAPE for Validation Set is: 16.06% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.62 | sMAPE for Test Set is: 16.85% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:30:50,830]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:30:51,167]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:31:01,725]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:31:01,852]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:31:07,167]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:31:07,511]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:31:12,313]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:31:16,006]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:31:20,270]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:31:23,209]\u001b[0m Trial 1026 finished with value: 6.535729603983559 and parameters: {'n_hidden': 3, 'learning_rate': 0.002760669986664464, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0859641159730799, 'dropout_rate_Layer_2': 0.32408411012574806, 'dropout_rate_Layer_3': 0.10199969472128674, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.52810911006293e-05, 'l1_Layer_2': 1.6241121309463708e-05, 'l1_Layer_3': 4.8739403722875486e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 100, 'n_units_Layer_3': 260}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 16.43% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.43 | sMAPE for Test Set is: 16.57% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:31:26,392]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:31:30,408]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:31:36,630]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:31:40,279]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:31:43,492]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:31:47,206]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:31:50,380]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:31:52,811]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:31:54,891]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:31:58,240]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:32:01,216]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:32:03,623]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:32:07,963]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:32:08,354]\u001b[0m Trial 1049 finished with value: 6.3356978434401965 and parameters: {'n_hidden': 3, 'learning_rate': 0.002684222176805427, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08277947059627142, 'dropout_rate_Layer_2': 0.3980461844205879, 'dropout_rate_Layer_3': 0.03832668325507815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1638166607606605e-05, 'l1_Layer_2': 6.990506682223121e-05, 'l1_Layer_3': 2.378803068239282e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 90, 'n_units_Layer_3': 220}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.34 | sMAPE for Validation Set is: 15.89% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.49 | sMAPE for Test Set is: 16.69% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:32:14,132]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:32:18,184]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:32:20,998]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:32:22,933]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:32:26,520]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:32:29,549]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:32:33,359]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:32:36,958]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:32:47,943]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:32:51,172]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:32:56,750]\u001b[0m Trial 1074 finished with value: 8.823704886103476 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033111163005028537, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.269388617050106, 'dropout_rate_Layer_2': 0.11954580124812997, 'dropout_rate_Layer_3': 0.1630149682102113, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.323699048432519e-05, 'l1_Layer_2': 1.802295308863187e-05, 'l1_Layer_3': 0.0002899617609465829, 'n_units_Layer_1': 130, 'n_units_Layer_2': 265, 'n_units_Layer_3': 50}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.82 | sMAPE for Validation Set is: 21.49% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 20.11% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:32:57,307]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:02,904]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:03,604]\u001b[0m Trial 1075 finished with value: 6.867442098334291 and parameters: {'n_hidden': 4, 'learning_rate': 0.003335149762642108, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05475667073115275, 'dropout_rate_Layer_2': 0.02238555837840303, 'dropout_rate_Layer_3': 0.3729664701537053, 'dropout_rate_Layer_4': 0.21981886184944296, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0008953797692941309, 'l1_Layer_2': 5.625792241665465e-05, 'l1_Layer_3': 0.005986337266518524, 'l1_Layer_4': 2.4584252258288877e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 85, 'n_units_Layer_3': 195, 'n_units_Layer_4': 115}. Best is trial 324 with value: 6.148641795327877.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.87 | sMAPE for Validation Set is: 17.00% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 17.39% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:33:03,690]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:09,865]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:10,833]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:14,394]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 15.43% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.39 | sMAPE for Test Set is: 16.51% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:33:14,434]\u001b[0m Trial 1046 finished with value: 6.137732341645816 and parameters: {'n_hidden': 3, 'learning_rate': 0.010153128511899695, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09150826286316194, 'dropout_rate_Layer_2': 0.36989524689619885, 'dropout_rate_Layer_3': 0.041626869478356504, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2825671553150184e-05, 'l1_Layer_2': 0.00037129803757117213, 'l1_Layer_3': 6.713499944406543e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 90, 'n_units_Layer_3': 230}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:17,858]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:21,993]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:24,398]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:24,794]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:25,890]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:32,674]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:34,698]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:36,255]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:37,569]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:45,023]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:45,448]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:45,501]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:51,184]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:55,379]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:33:55,527]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:34:01,426]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:34:05,033]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:34:05,536]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:34:11,193]\u001b[0m Trial 1091 finished with value: 6.728550662665838 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025334248717215307, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0388670828307979, 'dropout_rate_Layer_2': 0.02280152064471208, 'dropout_rate_Layer_3': 0.37794360367541946, 'dropout_rate_Layer_4': 0.2138730289273872, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0009649004121427858, 'l1_Layer_2': 5.381303166189171e-05, 'l1_Layer_3': 0.010638741206613298, 'l1_Layer_4': 3.101284738221481e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 90, 'n_units_Layer_3': 185, 'n_units_Layer_4': 100}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.73 | sMAPE for Validation Set is: 16.78% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 17.22% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:34:11,497]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:34:16,406]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:34:19,777]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:34:20,271]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:34:27,869]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:34:53,098]\u001b[0m Trial 1110 finished with value: 6.663721174645467 and parameters: {'n_hidden': 3, 'learning_rate': 0.012433870820361468, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3165177998616759, 'dropout_rate_Layer_2': 0.1651974536521843, 'dropout_rate_Layer_3': 0.17680054768340964, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017254797017559278, 'l1_Layer_2': 1.781304071055759e-05, 'l1_Layer_3': 0.000991098939720703, 'n_units_Layer_1': 135, 'n_units_Layer_2': 205, 'n_units_Layer_3': 120}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.66 | sMAPE for Validation Set is: 16.46% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 17.55% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:34:58,525]\u001b[0m Trial 1108 finished with value: 6.740249370520785 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019482654895607104, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01623140126171389, 'dropout_rate_Layer_2': 0.008568473952890888, 'dropout_rate_Layer_3': 0.38320541491597276, 'dropout_rate_Layer_4': 0.25219708305581867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0023641524392017405, 'l1_Layer_2': 2.227478002530736e-05, 'l1_Layer_3': 0.005846349160799551, 'l1_Layer_4': 1.967772796991644e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 95, 'n_units_Layer_3': 190, 'n_units_Layer_4': 95}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.74 | sMAPE for Validation Set is: 16.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 17.23% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:34:59,556]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:35:03,024]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:35:06,330]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:35:11,158]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:35:21,144]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:35:23,252]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:35:25,885]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:35:27,804]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:35:30,742]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:35:33,510]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:35:34,899]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:35:38,311]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:35:39,367]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:35:44,144]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:35:46,486]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:35:57,023]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:36:00,787]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:36:04,943]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:36:07,850]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:36:12,918]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:36:16,864]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:36:33,242]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:36:38,247]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:36:41,770]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:36:45,068]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:36:49,044]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:37:15,157]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:37:24,189]\u001b[0m Trial 1126 finished with value: 6.81464907325624 and parameters: {'n_hidden': 3, 'learning_rate': 0.004807578393246969, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026978231344529643, 'dropout_rate_Layer_2': 0.3731828928735686, 'dropout_rate_Layer_3': 0.02010656469612898, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3694028713433366e-05, 'l1_Layer_2': 0.0003682804347646545, 'l1_Layer_3': 2.8233040371729535e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 75, 'n_units_Layer_3': 215}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 16.91% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 17.56% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:37:34,388]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:37:40,047]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:37:46,656]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:37:51,191]\u001b[0m Trial 1139 finished with value: 6.276216879163208 and parameters: {'n_hidden': 3, 'learning_rate': 0.002100673090475486, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13652060068246366, 'dropout_rate_Layer_2': 0.15461186167308186, 'dropout_rate_Layer_3': 0.08092393216472257, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006632267443749435, 'l1_Layer_2': 0.0010071432954370679, 'l1_Layer_3': 0.0017769124651230872, 'n_units_Layer_1': 145, 'n_units_Layer_2': 175, 'n_units_Layer_3': 135}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 15.74% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.54 | sMAPE for Test Set is: 17.05% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:37:55,969]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:37:56,807]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:37:57,716]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:38:02,588]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:38:05,082]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:38:08,603]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:38:11,890]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:38:14,614]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:38:16,927]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:38:18,132]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:38:20,355]\u001b[0m Trial 1140 finished with value: 6.251235603856363 and parameters: {'n_hidden': 3, 'learning_rate': 0.002108957075004621, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13589276069617448, 'dropout_rate_Layer_2': 0.1340318093788258, 'dropout_rate_Layer_3': 0.19528857164306884, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001825433580589959, 'l1_Layer_2': 0.0009012068620206146, 'l1_Layer_3': 0.0019163574252049275, 'n_units_Layer_1': 145, 'n_units_Layer_2': 175, 'n_units_Layer_3': 130}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 15.68% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.47 | sMAPE for Test Set is: 16.76% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:38:21,941]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:38:24,428]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:38:27,303]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:38:38,334]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:38:43,756]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 16.60% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.56 | sMAPE for Test Set is: 17.06% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:38:46,773]\u001b[0m Trial 1146 finished with value: 6.609718357117038 and parameters: {'n_hidden': 3, 'learning_rate': 0.007345863628868181, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.048569688492102955, 'dropout_rate_Layer_2': 0.39923597091252955, 'dropout_rate_Layer_3': 0.037823145271729794, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.186570561888876e-05, 'l1_Layer_2': 0.00015224286480701368, 'l1_Layer_3': 3.823153348786266e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 60, 'n_units_Layer_3': 250}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:38:50,662]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:38:53,193]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:38:56,144]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:38:58,943]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:39:01,736]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:39:05,223]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:39:09,507]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:39:13,261]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:39:16,826]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:39:20,103]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:39:23,802]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:39:27,833]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:39:31,047]\u001b[0m Trial 1165 finished with value: 6.649957486335571 and parameters: {'n_hidden': 3, 'learning_rate': 0.007234739395151911, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31411188255532435, 'dropout_rate_Layer_2': 0.20820634426881557, 'dropout_rate_Layer_3': 0.1385632088827314, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001458208942680306, 'l1_Layer_2': 2.2797232255168137e-05, 'l1_Layer_3': 0.02191270213517834, 'n_units_Layer_1': 160, 'n_units_Layer_2': 155, 'n_units_Layer_3': 135}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.65 | sMAPE for Validation Set is: 16.55% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 17.53% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:39:31,538]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:39:32,877]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:39:38,650]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:39:39,148]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:39:40,691]\u001b[0m Trial 1166 finished with value: 6.329467931555193 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019977603597907375, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13525078134962076, 'dropout_rate_Layer_2': 0.15623244870045538, 'dropout_rate_Layer_3': 0.06732023433363761, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2241061010583874e-05, 'l1_Layer_2': 3.3495987221545516e-05, 'l1_Layer_3': 0.0018814057833491137, 'n_units_Layer_1': 240, 'n_units_Layer_2': 170, 'n_units_Layer_3': 135}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 15.87% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 17.19% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:39:47,198]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:39:49,277]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:39:50,489]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:39:54,467]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:39:58,229]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:40:00,628]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:40:03,339]\u001b[0m Trial 1176 finished with value: 6.849658230114692 and parameters: {'n_hidden': 3, 'learning_rate': 0.007373711750196617, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3388409533189825, 'dropout_rate_Layer_2': 0.21618922347714056, 'dropout_rate_Layer_3': 0.21476192053256754, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004254078616512208, 'l1_Layer_2': 0.00013824485064267922, 'l1_Layer_3': 0.028112276802057086, 'n_units_Layer_1': 160, 'n_units_Layer_2': 165, 'n_units_Layer_3': 135}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.85 | sMAPE for Validation Set is: 17.00% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.89 | sMAPE for Test Set is: 17.55% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:40:05,995]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:40:09,228]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:40:12,351]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:40:15,948]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:40:20,442]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:40:23,744]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:40:27,832]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:40:38,127]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:40:48,204]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:40:53,790]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:40:54,268]\u001b[0m Trial 1183 finished with value: 7.094463763593294 and parameters: {'n_hidden': 3, 'learning_rate': 0.007167504792676422, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10583369861850517, 'dropout_rate_Layer_2': 0.3781409488485602, 'dropout_rate_Layer_3': 0.018650325854904656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0216198592363937e-05, 'l1_Layer_2': 0.000748007466910401, 'l1_Layer_3': 1.3842131397804752e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 65, 'n_units_Layer_3': 230}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.09 | sMAPE for Validation Set is: 17.60% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.85 | sMAPE for Test Set is: 17.54% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:41:00,486]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:01,559]\u001b[0m Trial 1184 finished with value: 6.783279010268341 and parameters: {'n_hidden': 3, 'learning_rate': 0.005922235645151262, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10963014097112106, 'dropout_rate_Layer_2': 0.2593065477724298, 'dropout_rate_Layer_3': 0.014302091049828818, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0400728828867936e-05, 'l1_Layer_2': 0.0006630473963361085, 'l1_Layer_3': 4.9805763712223793e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 65, 'n_units_Layer_3': 230}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.78 | sMAPE for Validation Set is: 17.12% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.54 | sMAPE for Test Set is: 17.03% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:41:06,665]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:06,953]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:11,886]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:12,476]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:16,214]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:21,027]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:22,281]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:25,390]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:26,159]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:32,067]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:33,629]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:35,143]\u001b[0m Trial 1193 finished with value: 6.947409429870393 and parameters: {'n_hidden': 3, 'learning_rate': 0.006517428795838382, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10398512570244701, 'dropout_rate_Layer_2': 0.3807090310326944, 'dropout_rate_Layer_3': 0.01742749678191233, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0598823631963912e-05, 'l1_Layer_2': 7.2209188801143e-05, 'l1_Layer_3': 5.1607317823786477e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 50, 'n_units_Layer_3': 195}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.95 | sMAPE for Validation Set is: 17.07% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.57 | sMAPE for Test Set is: 16.81% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:41:35,948]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:38,004]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:43,691]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:44,639]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:45,859]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:46,831]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:56,103]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:41:56,333]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:42:01,091]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:42:01,425]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:42:17,993]\u001b[0m Trial 1220 finished with value: 10.453226000316983 and parameters: {'n_hidden': 3, 'learning_rate': 0.005495373321332578, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3878699495743785, 'dropout_rate_Layer_2': 0.24331336662470598, 'dropout_rate_Layer_3': 0.1433846347471918, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017161693827080697, 'l1_Layer_2': 0.019294772784616526, 'l1_Layer_3': 0.03778629285812761, 'n_units_Layer_1': 110, 'n_units_Layer_2': 150, 'n_units_Layer_3': 105}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.45 | sMAPE for Validation Set is: 24.73% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 6.93 | sMAPE for Test Set is: 19.84% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:42:22,376]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:42:30,928]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:42:35,156]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:42:39,473]\u001b[0m Trial 1221 finished with value: 6.183226182099773 and parameters: {'n_hidden': 3, 'learning_rate': 0.002630710508462099, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14949712616023705, 'dropout_rate_Layer_2': 0.04769184206826126, 'dropout_rate_Layer_3': 0.057814699608846436, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015965697219909823, 'l1_Layer_2': 1.831288108256505e-05, 'l1_Layer_3': 0.0027705723062266653, 'n_units_Layer_1': 230, 'n_units_Layer_2': 235, 'n_units_Layer_3': 135}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 15.52% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.32 | sMAPE for Test Set is: 16.28% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:42:42,573]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:42:43,318]\u001b[0m Trial 1219 finished with value: 6.319818502790547 and parameters: {'n_hidden': 3, 'learning_rate': 0.009872208366788702, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06114388277633161, 'dropout_rate_Layer_2': 0.3361257411316346, 'dropout_rate_Layer_3': 0.031885674199372695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3158179981203282e-05, 'l1_Layer_2': 4.035967964390334e-05, 'l1_Layer_3': 0.00012519317196916225, 'n_units_Layer_1': 170, 'n_units_Layer_2': 115, 'n_units_Layer_3': 245}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 15.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.43 | sMAPE for Test Set is: 16.82% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:42:48,895]\u001b[0m Trial 1214 finished with value: 6.288365567177812 and parameters: {'n_hidden': 3, 'learning_rate': 0.002261438987806206, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1484278616124124, 'dropout_rate_Layer_2': 0.20082359172200437, 'dropout_rate_Layer_3': 0.05836420954576201, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016059020346016549, 'l1_Layer_2': 0.0007532397076055484, 'l1_Layer_3': 0.0026974787309714944, 'n_units_Layer_1': 250, 'n_units_Layer_2': 55, 'n_units_Layer_3': 135}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 15.75% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 16.65% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:42:49,272]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:42:50,181]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:42:56,760]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:42:57,473]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:42:57,474]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:43:04,871]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:43:08,070]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:43:12,813]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:43:13,259]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:43:18,822]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:43:22,359]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:43:22,868]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:43:28,617]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:43:32,739]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:43:33,354]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:43:40,651]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:43:43,969]\u001b[0m Trial 1241 finished with value: 6.848840084084806 and parameters: {'n_hidden': 3, 'learning_rate': 0.004684760995311372, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36388612067994375, 'dropout_rate_Layer_2': 0.12971629437417015, 'dropout_rate_Layer_3': 0.07799231472748656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.161279506367042e-05, 'l1_Layer_2': 2.2548372021114776e-05, 'l1_Layer_3': 0.016644055219905033, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 145}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.85 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 17.75% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:43:47,686]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:43:47,869]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:43:51,051]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:43:59,890]\u001b[0m Trial 1230 finished with value: 6.304727918810907 and parameters: {'n_hidden': 3, 'learning_rate': 0.010513118346145685, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0640067931495445, 'dropout_rate_Layer_2': 0.3492419526551247, 'dropout_rate_Layer_3': 0.044551802183815006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.35945083658275e-05, 'l1_Layer_2': 4.1324472561203553e-05, 'l1_Layer_3': 0.0001649089710536641, 'n_units_Layer_1': 175, 'n_units_Layer_2': 120, 'n_units_Layer_3': 245}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 15.84% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.43 | sMAPE for Test Set is: 16.72% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:44:02,566]\u001b[0m Trial 1248 finished with value: 11.021565375789805 and parameters: {'n_hidden': 3, 'learning_rate': 0.007197147933658426, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20179602317506545, 'dropout_rate_Layer_2': 0.15718611981846145, 'dropout_rate_Layer_3': 0.17174264072441858, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.450558601756741e-05, 'l1_Layer_2': 1.4253773079818156e-05, 'l1_Layer_3': 0.06570115221248414, 'n_units_Layer_1': 140, 'n_units_Layer_2': 225, 'n_units_Layer_3': 75}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.02 | sMAPE for Validation Set is: 25.93% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 19.79% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:44:05,850]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:44:07,022]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:44:11,015]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:44:12,298]\u001b[0m Trial 1247 finished with value: 10.070188112321068 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035235579754266315, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21358807258843182, 'dropout_rate_Layer_2': 0.15840195110334812, 'dropout_rate_Layer_3': 0.17725563977898687, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.468576011143842e-05, 'l1_Layer_2': 1.5109623160875768e-05, 'l1_Layer_3': 0.008827492919926355, 'n_units_Layer_1': 95, 'n_units_Layer_2': 220, 'n_units_Layer_3': 80}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.07 | sMAPE for Validation Set is: 23.95% | rMAE for Validation Set is: 0.95\n",
      "MAE for Test Set is: 7.02 | sMAPE for Test Set is: 20.03% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:44:15,707]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:44:17,293]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:44:18,486]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:44:24,291]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:44:32,445]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:44:33,445]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:44:37,732]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:44:38,779]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:44:42,709]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:44:43,779]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:44:49,180]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:44:51,223]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:44:55,234]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:44:58,661]\u001b[0m Trial 1254 finished with value: 6.50973143324034 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021675896481045806, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11792379611755989, 'dropout_rate_Layer_2': 0.01633299559334922, 'dropout_rate_Layer_3': 0.33964950053902127, 'dropout_rate_Layer_4': 0.14112483776345108, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002379748151315739, 'l1_Layer_2': 7.086009865404044e-05, 'l1_Layer_3': 0.0016312582122014235, 'l1_Layer_4': 1.6003358609131254e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 75, 'n_units_Layer_3': 160, 'n_units_Layer_4': 265}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 16.06% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 16.91% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:44:59,741]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:01,298]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:06,004]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:11,684]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:14,932]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:15,076]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:20,815]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:24,028]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:28,146]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:29,101]\u001b[0m Trial 1266 finished with value: 6.554144354502582 and parameters: {'n_hidden': 3, 'learning_rate': 0.009987868804148066, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05724170975600309, 'dropout_rate_Layer_2': 0.3462475517087095, 'dropout_rate_Layer_3': 0.0433245243480669, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2765549658148393e-05, 'l1_Layer_2': 4.109352725821099e-05, 'l1_Layer_3': 0.000159283394670105, 'n_units_Layer_1': 170, 'n_units_Layer_2': 115, 'n_units_Layer_3': 245}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.55 | sMAPE for Validation Set is: 16.40% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.47 | sMAPE for Test Set is: 16.80% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:45:33,420]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:35,922]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:36,283]\u001b[0m Trial 1271 finished with value: 6.406798121906694 and parameters: {'n_hidden': 3, 'learning_rate': 0.002661485727302281, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3524794318875435, 'dropout_rate_Layer_2': 0.05181547753282681, 'dropout_rate_Layer_3': 0.03632718464458656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.3734250368164526e-05, 'l1_Layer_2': 4.5572700640231396e-05, 'l1_Layer_3': 2.2203453830434913e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 16.00% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.47 | sMAPE for Test Set is: 16.83% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:45:38,151]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:44,407]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:44,501]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:44,989]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:45,178]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:52,708]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:54,101]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:54,899]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:45:55,112]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:00,809]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:02,599]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:03,658]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:05,634]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:09,727]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:13,436]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:15,324]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:16,716]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:23,629]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:27,191]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:28,551]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:32,202]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:37,145]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:40,325]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:44,772]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:46,972]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:52,198]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:52,651]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:57,597]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:46:58,906]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:04,231]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:08,605]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:10,760]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:13,118]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:19,066]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:22,412]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:24,552]\u001b[0m Trial 1311 finished with value: 6.799480933146325 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026143654074967217, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3070923771116338, 'dropout_rate_Layer_2': 0.006253781790999323, 'dropout_rate_Layer_3': 0.2707156714641561, 'dropout_rate_Layer_4': 0.14703673168766737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012355317952590747, 'l1_Layer_2': 4.182922910392874e-05, 'l1_Layer_3': 1.8434974831776774e-05, 'l1_Layer_4': 0.0009008766501758053, 'n_units_Layer_1': 285, 'n_units_Layer_2': 110, 'n_units_Layer_3': 150, 'n_units_Layer_4': 165}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.80 | sMAPE for Validation Set is: 16.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.22 | sMAPE for Test Set is: 18.53% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:47:26,710]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:27,757]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:29,301]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:34,391]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:35,279]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:35,878]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:40,114]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:44,499]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:45,945]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:47,198]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:52,334]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:53,511]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:47:56,045]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:00,853]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:02,868]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:06,369]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:08,994]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:13,393]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:13,856]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:19,307]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:20,199]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:27,371]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:30,758]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:33,786]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:34,304]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:37,815]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:40,391]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:43,892]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:44,954]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:50,518]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:51,045]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:53,718]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:56,010]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:48:59,043]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:03,567]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:04,493]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:09,261]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:09,917]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:14,819]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:15,331]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:16,573]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:24,092]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:24,367]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:24,723]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:32,131]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:33,497]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:34,740]\u001b[0m Trial 1350 finished with value: 10.906055559446026 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025698783643589855, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3228564687136472, 'dropout_rate_Layer_2': 0.1846774778094442, 'dropout_rate_Layer_3': 0.11022820008028444, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001519813313800162, 'l1_Layer_2': 4.2260065743522726e-05, 'l1_Layer_3': 0.0037784319452727694, 'n_units_Layer_1': 120, 'n_units_Layer_2': 245, 'n_units_Layer_3': 125}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.91 | sMAPE for Validation Set is: 25.99% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 7.06 | sMAPE for Test Set is: 20.27% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:49:35,602]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:42,213]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:44,934]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:45,332]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:45,505]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:52,772]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:56,624]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:49:58,897]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:00,885]\u001b[0m Trial 1366 finished with value: 6.727319326214283 and parameters: {'n_hidden': 3, 'learning_rate': 0.01294977787321843, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2627856640044677, 'dropout_rate_Layer_2': 0.20610128942288247, 'dropout_rate_Layer_3': 0.1407211005130555, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.888182286204563e-05, 'l1_Layer_2': 2.776124723301056e-05, 'l1_Layer_3': 0.021193430889024895, 'n_units_Layer_1': 195, 'n_units_Layer_2': 205, 'n_units_Layer_3': 165}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.73 | sMAPE for Validation Set is: 16.64% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.96 | sMAPE for Test Set is: 17.63% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:50:05,439]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:09,188]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:09,966]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:09,988]\u001b[0m Trial 1370 finished with value: 7.850609632763781 and parameters: {'n_hidden': 3, 'learning_rate': 0.011113478569126879, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2586301829484813, 'dropout_rate_Layer_2': 0.21293613024745364, 'dropout_rate_Layer_3': 0.13055598120088144, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007820526788137306, 'l1_Layer_2': 0.09799401316086621, 'l1_Layer_3': 0.021959366371147194, 'n_units_Layer_1': 190, 'n_units_Layer_2': 210, 'n_units_Layer_3': 165}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.85 | sMAPE for Validation Set is: 19.48% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.34 | sMAPE for Test Set is: 18.94% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:50:18,469]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:21,250]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:25,076]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:25,337]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:25,516]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:32,335]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:32,586]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:33,193]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:33,472]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:38,811]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:40,340]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:43,928]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:44,378]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:48,844]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:50,780]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:54,222]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:50:59,337]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:01,983]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:03,538]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:04,274]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:05,537]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:05,638]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:12,945]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:13,202]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:16,277]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:18,735]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:23,078]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:26,468]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:26,941]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:27,821]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:36,897]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:37,971]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:39,367]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:43,102]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:47,467]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:51,363]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:54,119]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:51:57,976]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:52:03,697]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:52:05,891]\u001b[0m Trial 1410 finished with value: 6.941395399912332 and parameters: {'n_hidden': 3, 'learning_rate': 0.002859292536512566, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17216337328966955, 'dropout_rate_Layer_2': 0.15245951600928218, 'dropout_rate_Layer_3': 0.0878227983726837, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016653586569265273, 'l1_Layer_2': 0.0005565084561464105, 'l1_Layer_3': 0.007681624726057322, 'n_units_Layer_1': 165, 'n_units_Layer_2': 190, 'n_units_Layer_3': 140}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.94 | sMAPE for Validation Set is: 17.39% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 18.61% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:52:07,774]\u001b[0m Trial 1414 finished with value: 7.741532375781451 and parameters: {'n_hidden': 3, 'learning_rate': 0.021870681394268638, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012571543413609013, 'dropout_rate_Layer_2': 0.23746058081448415, 'dropout_rate_Layer_3': 0.20548009462886885, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011777634454461347, 'l1_Layer_2': 4.7982274210194504e-05, 'l1_Layer_3': 0.002402740166308065, 'n_units_Layer_1': 175, 'n_units_Layer_2': 195, 'n_units_Layer_3': 130}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.74 | sMAPE for Validation Set is: 18.74% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 6.76 | sMAPE for Test Set is: 19.29% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:52:08,676]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:52:14,425]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:52:14,641]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:52:20,538]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:52:20,728]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:52:21,392]\u001b[0m Trial 1418 finished with value: 7.946000543315539 and parameters: {'n_hidden': 3, 'learning_rate': 0.009359819883054147, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10449456579893147, 'dropout_rate_Layer_2': 0.23839884480816073, 'dropout_rate_Layer_3': 0.08805571105208444, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014977723105429207, 'l1_Layer_2': 5.082726939559522e-05, 'l1_Layer_3': 0.0014087307185047127, 'n_units_Layer_1': 175, 'n_units_Layer_2': 200, 'n_units_Layer_3': 175}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.95 | sMAPE for Validation Set is: 19.17% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.70 | sMAPE for Test Set is: 19.13% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:52:30,146]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:52:31,462]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:52:35,981]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:52:40,069]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:52:43,447]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:52:43,623]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:52:50,000]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:52:50,953]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:52:51,356]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:52:54,961]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:53:00,576]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:53:03,335]\u001b[0m Trial 1409 finished with value: 6.147945828166978 and parameters: {'n_hidden': 3, 'learning_rate': 0.013061681907570405, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04041013273057914, 'dropout_rate_Layer_2': 0.3503605221567988, 'dropout_rate_Layer_3': 0.0332959286372815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8119179590589493e-05, 'l1_Layer_2': 5.629156658259514e-05, 'l1_Layer_3': 0.00012116425300004329, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 180}. Best is trial 1046 with value: 6.137732341645816.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 15.33% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.29 | sMAPE for Test Set is: 16.21% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:53:04,399]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:53:04,625]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:53:09,302]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:53:11,762]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:53:13,078]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:53:18,339]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:53:19,462]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:53:25,513]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:53:26,321]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:53:30,979]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:53:31,602]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:53:32,875]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:53:36,225]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:53:42,792]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:53:55,209]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:53:59,574]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:04,563]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:07,719]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:08,571]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:13,902]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:17,169]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:17,548]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:22,991]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:25,237]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:28,928]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:31,420]\u001b[0m Trial 1446 finished with value: 6.118333460803195 and parameters: {'n_hidden': 3, 'learning_rate': 0.002428569052366389, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24852067183627263, 'dropout_rate_Layer_2': 0.04633832990592826, 'dropout_rate_Layer_3': 0.02954298484420055, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.420998554450917e-05, 'l1_Layer_2': 0.0009453868651431949, 'l1_Layer_3': 7.760650670816505e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 295, 'n_units_Layer_3': 195}. Best is trial 1446 with value: 6.118333460803195.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 15.23% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.29 | sMAPE for Test Set is: 16.27% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:54:34,822]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:37,214]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:38,183]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:40,918]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:45,475]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:45,746]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:48,837]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:56,001]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:54:59,725]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:55:07,720]\u001b[0m Trial 1462 finished with value: 6.278973762916896 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033013730173994827, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12178962648665999, 'dropout_rate_Layer_2': 0.1627106649408725, 'dropout_rate_Layer_3': 0.19218458270865835, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004063604009858199, 'l1_Layer_2': 3.076356109630526e-05, 'l1_Layer_3': 0.004083124112691357, 'n_units_Layer_1': 145, 'n_units_Layer_2': 185, 'n_units_Layer_3': 130}. Best is trial 1446 with value: 6.118333460803195.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 15.67% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.69 | sMAPE for Test Set is: 17.20% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:55:11,422]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:55:14,457]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:55:17,196]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:55:18,712]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:55:20,310]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:55:26,100]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:55:26,428]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:55:30,870]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:55:32,264]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:55:35,347]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:55:38,534]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:55:42,854]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:56:00,443]\u001b[0m Trial 1472 finished with value: 6.355265224023238 and parameters: {'n_hidden': 3, 'learning_rate': 0.011425800822343294, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12694268897033117, 'dropout_rate_Layer_2': 0.369734836740277, 'dropout_rate_Layer_3': 0.1758231138730385, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1241375352196487e-05, 'l1_Layer_2': 5.1188339757328864e-05, 'l1_Layer_3': 0.00010617229510194955, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 240}. Best is trial 1446 with value: 6.118333460803195.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 15.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.49 | sMAPE for Test Set is: 16.72% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:56:04,406]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:56:04,558]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:56:05,762]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:56:06,711]\u001b[0m Trial 1480 finished with value: 6.462664502230879 and parameters: {'n_hidden': 3, 'learning_rate': 0.024005934995196654, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03564138966016453, 'dropout_rate_Layer_2': 0.3696215453477768, 'dropout_rate_Layer_3': 0.07899340446335681, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001210305579428397, 'l1_Layer_2': 0.00013058847461320296, 'l1_Layer_3': 0.00011779209071047268, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 240}. Best is trial 1446 with value: 6.118333460803195.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 16.08% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.51 | sMAPE for Test Set is: 16.64% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:56:14,369]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:56:14,790]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:56:15,125]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:56:15,508]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:56:24,148]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:56:25,050]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:56:27,682]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:56:33,637]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:56:34,224]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.66 | sMAPE for Validation Set is: 20.72% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 6.46 | sMAPE for Test Set is: 18.84% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-06 22:56:34,700]\u001b[0m Trial 1494 finished with value: 8.65692964201311 and parameters: {'n_hidden': 3, 'learning_rate': 0.009374980831655772, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0003478708157305596, 'dropout_rate_Layer_2': 0.19426248815779149, 'dropout_rate_Layer_3': 0.1588528574098526, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002251732399296809, 'l1_Layer_2': 0.0019274406950174736, 'l1_Layer_3': 0.0001553627860466365, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 95}. Best is trial 1446 with value: 6.118333460803195.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:56:34,751]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:56:39,112]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-06 22:56:39,376]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-01-01, MAE is:38.28 & sMAPE is:183.39% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :38.28 & 183.39% & 1.49\n",
      "for 2019-01-02, MAE is:35.50 & sMAPE is:129.93% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :36.89 & 156.66% & 1.72\n",
      "for 2019-01-03, MAE is:4.67 & sMAPE is:8.79% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :26.15 & 107.37% & 1.40\n",
      "for 2019-01-04, MAE is:4.31 & sMAPE is:9.30% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :20.69 & 82.85% & 1.34\n",
      "for 2019-01-05, MAE is:13.32 & sMAPE is:32.89% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :19.22 & 72.86% & 1.32\n",
      "for 2019-01-06, MAE is:5.21 & sMAPE is:11.55% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :16.88 & 62.64% & 1.15\n",
      "for 2019-01-07, MAE is:8.90 & sMAPE is:18.99% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :15.74 & 56.41% & 1.13\n",
      "for 2019-01-08, MAE is:5.53 & sMAPE is:18.67% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :14.47 & 51.69% & 1.00\n",
      "for 2019-01-09, MAE is:6.84 & sMAPE is:26.15% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :13.62 & 48.85% & 0.94\n",
      "for 2019-01-10, MAE is:14.38 & sMAPE is:22.55% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :13.69 & 46.22% & 0.98\n",
      "for 2019-01-11, MAE is:9.06 & sMAPE is:16.38% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :13.27 & 43.51% & 1.09\n",
      "for 2019-01-12, MAE is:4.24 & sMAPE is:9.41% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :12.52 & 40.67% & 1.04\n",
      "for 2019-01-13, MAE is:9.65 & sMAPE is:29.96% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :12.30 & 39.84% & 1.02\n",
      "for 2019-01-14, MAE is:10.49 & sMAPE is:66.16% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :12.17 & 41.72% & 0.98\n",
      "for 2019-01-15, MAE is:4.98 & sMAPE is:11.06% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :11.69 & 39.68% & 0.93\n",
      "for 2019-01-16, MAE is:6.86 & sMAPE is:14.46% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :11.39 & 38.10% & 0.91\n",
      "for 2019-01-17, MAE is:5.11 & sMAPE is:10.92% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :11.02 & 36.50% & 0.87\n",
      "for 2019-01-18, MAE is:6.59 & sMAPE is:10.88% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :10.77 & 35.08% & 0.86\n",
      "for 2019-01-19, MAE is:3.23 & sMAPE is:5.73% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :10.38 & 33.53% & 0.83\n",
      "for 2019-01-20, MAE is:4.25 & sMAPE is:7.91% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :10.07 & 32.25% & 0.81\n",
      "for 2019-01-21, MAE is:9.25 & sMAPE is:13.39% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :10.03 & 31.36% & 0.78\n",
      "for 2019-01-22, MAE is:4.28 & sMAPE is:6.78% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :9.77 & 30.24% & 0.76\n",
      "for 2019-01-23, MAE is:10.81 & sMAPE is:15.15% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :9.81 & 29.58% & 0.75\n",
      "for 2019-01-24, MAE is:16.31 & sMAPE is:20.30% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :10.09 & 29.20% & 0.75\n",
      "for 2019-01-25, MAE is:7.99 & sMAPE is:11.53% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.00 & 28.49% & 0.77\n",
      "for 2019-01-26, MAE is:1.93 & sMAPE is:3.56% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :9.69 & 27.53% & 0.78\n",
      "for 2019-01-27, MAE is:6.60 & sMAPE is:17.33% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :9.58 & 27.15% & 0.78\n",
      "for 2019-01-28, MAE is:7.93 & sMAPE is:13.60% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.52 & 26.67% & 0.77\n",
      "for 2019-01-29, MAE is:3.66 & sMAPE is:5.92% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :9.32 & 25.95% & 0.78\n",
      "for 2019-01-30, MAE is:5.35 & sMAPE is:9.01% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :9.18 & 25.39% & 0.77\n",
      "for 2019-01-31, MAE is:2.38 & sMAPE is:4.24% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :8.96 & 24.71% & 0.75\n",
      "for 2019-02-01, MAE is:4.58 & sMAPE is:7.70% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 24.17% & 0.74\n",
      "for 2019-02-02, MAE is:3.45 & sMAPE is:6.41% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 23.64% & 0.75\n",
      "for 2019-02-03, MAE is:5.01 & sMAPE is:9.52% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :8.56 & 23.22% & 0.75\n",
      "for 2019-02-04, MAE is:6.58 & sMAPE is:12.71% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 22.92% & 0.78\n",
      "for 2019-02-05, MAE is:3.70 & sMAPE is:7.96% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 22.51% & 0.77\n",
      "for 2019-02-06, MAE is:4.35 & sMAPE is:8.03% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 22.11% & 0.78\n",
      "for 2019-02-07, MAE is:5.79 & sMAPE is:11.44% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 21.83% & 0.77\n",
      "for 2019-02-08, MAE is:4.89 & sMAPE is:11.99% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 21.58% & 0.76\n",
      "for 2019-02-09, MAE is:25.53 & sMAPE is:133.07% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.54 & 24.37% & 0.76\n",
      "for 2019-02-10, MAE is:19.73 & sMAPE is:88.86% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 25.94% & 0.77\n",
      "for 2019-02-11, MAE is:10.59 & sMAPE is:41.01% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :8.86 & 26.30% & 0.77\n",
      "for 2019-02-12, MAE is:8.03 & sMAPE is:17.83% & rMAE is:2.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.84 & 26.10% & 0.81\n",
      "for 2019-02-13, MAE is:3.19 & sMAPE is:7.46% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.71 & 25.68% & 0.80\n",
      "for 2019-02-14, MAE is:3.96 & sMAPE is:7.96% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :8.61 & 25.29% & 0.80\n",
      "for 2019-02-15, MAE is:3.72 & sMAPE is:7.82% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 24.91% & 0.79\n",
      "for 2019-02-16, MAE is:2.93 & sMAPE is:7.70% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :8.38 & 24.54% & 0.78\n",
      "for 2019-02-17, MAE is:2.77 & sMAPE is:7.20% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 24.18% & 0.77\n",
      "for 2019-02-18, MAE is:4.63 & sMAPE is:10.30% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 23.90% & 0.76\n",
      "for 2019-02-19, MAE is:3.40 & sMAPE is:7.68% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 23.57% & 0.76\n",
      "for 2019-02-20, MAE is:2.98 & sMAPE is:6.65% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 23.24% & 0.76\n",
      "for 2019-02-21, MAE is:3.82 & sMAPE is:8.21% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 22.95% & 0.76\n",
      "for 2019-02-22, MAE is:2.51 & sMAPE is:5.42% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.81 & 22.62% & 0.77\n",
      "for 2019-02-23, MAE is:1.98 & sMAPE is:4.66% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 22.29% & 0.77\n",
      "for 2019-02-24, MAE is:2.65 & sMAPE is:6.64% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 22.00% & 0.77\n",
      "for 2019-02-25, MAE is:4.70 & sMAPE is:9.95% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 21.79% & 0.78\n",
      "for 2019-02-26, MAE is:4.12 & sMAPE is:8.98% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 21.56% & 0.79\n",
      "for 2019-02-27, MAE is:4.24 & sMAPE is:9.50% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 21.35% & 0.79\n",
      "for 2019-02-28, MAE is:3.76 & sMAPE is:9.23% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 21.15% & 0.80\n",
      "for 2019-03-01, MAE is:2.86 & sMAPE is:6.32% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 20.90% & 0.80\n",
      "for 2019-03-02, MAE is:4.57 & sMAPE is:11.30% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 20.74% & 0.80\n",
      "for 2019-03-03, MAE is:9.03 & sMAPE is:40.19% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 21.06% & 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-03-04, MAE is:16.11 & sMAPE is:72.14% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 21.87% & 0.82\n",
      "for 2019-03-05, MAE is:17.74 & sMAPE is:91.15% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 22.95% & 0.83\n",
      "for 2019-03-06, MAE is:5.80 & sMAPE is:14.61% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 22.82% & 0.84\n",
      "for 2019-03-07, MAE is:7.71 & sMAPE is:21.17% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 22.80% & 0.84\n",
      "for 2019-03-08, MAE is:5.92 & sMAPE is:18.35% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 22.73% & 0.84\n",
      "for 2019-03-09, MAE is:26.87 & sMAPE is:137.99% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 24.43% & 0.84\n",
      "for 2019-03-10, MAE is:16.62 & sMAPE is:98.57% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 25.50% & 0.86\n",
      "for 2019-03-11, MAE is:7.85 & sMAPE is:19.66% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 25.42% & 0.85\n",
      "for 2019-03-12, MAE is:5.93 & sMAPE is:19.18% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 25.33% & 0.84\n",
      "for 2019-03-13, MAE is:14.93 & sMAPE is:49.71% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 25.67% & 0.86\n",
      "for 2019-03-14, MAE is:4.01 & sMAPE is:10.88% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 25.47% & 0.87\n",
      "for 2019-03-15, MAE is:6.95 & sMAPE is:24.13% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 25.45% & 0.86\n",
      "for 2019-03-16, MAE is:17.18 & sMAPE is:89.82% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.07 & 26.31% & 0.86\n",
      "for 2019-03-17, MAE is:33.29 & sMAPE is:154.67% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.41 & 28.00% & 0.87\n",
      "for 2019-03-18, MAE is:10.86 & sMAPE is:36.58% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 28.11% & 0.87\n",
      "for 2019-03-19, MAE is:8.37 & sMAPE is:20.00% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 28.00% & 0.88\n",
      "for 2019-03-20, MAE is:4.98 & sMAPE is:12.52% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 27.81% & 0.88\n",
      "for 2019-03-21, MAE is:3.46 & sMAPE is:8.51% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 27.57% & 0.88\n",
      "for 2019-03-22, MAE is:3.07 & sMAPE is:7.23% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 27.31% & 0.88\n",
      "for 2019-03-23, MAE is:3.20 & sMAPE is:9.18% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :8.20 & 27.09% & 0.87\n",
      "for 2019-03-24, MAE is:2.37 & sMAPE is:7.28% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :8.13 & 26.85% & 0.86\n",
      "for 2019-03-25, MAE is:3.16 & sMAPE is:9.66% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :8.08 & 26.65% & 0.86\n",
      "for 2019-03-26, MAE is:4.86 & sMAPE is:12.10% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :8.04 & 26.48% & 0.86\n",
      "for 2019-03-27, MAE is:3.49 & sMAPE is:7.99% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 26.26% & 0.87\n",
      "for 2019-03-28, MAE is:3.93 & sMAPE is:9.55% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 26.07% & 0.87\n",
      "for 2019-03-29, MAE is:5.84 & sMAPE is:14.24% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 25.94% & 0.88\n",
      "for 2019-03-30, MAE is:4.25 & sMAPE is:12.67% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.87 & 25.79% & 0.89\n",
      "for 2019-03-31, MAE is:7.06 & sMAPE is:32.57% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 25.86% & 0.89\n",
      "for 2019-04-01, MAE is:4.98 & sMAPE is:13.33% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :7.83 & 25.73% & 0.89\n",
      "for 2019-04-02, MAE is:3.12 & sMAPE is:8.85% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 25.54% & 0.89\n",
      "for 2019-04-03, MAE is:4.63 & sMAPE is:12.06% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 25.40% & 0.89\n",
      "for 2019-04-04, MAE is:3.25 & sMAPE is:7.61% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 25.21% & 0.89\n",
      "for 2019-04-05, MAE is:2.44 & sMAPE is:5.62% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 25.00% & 0.89\n",
      "for 2019-04-06, MAE is:4.64 & sMAPE is:12.48% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 24.87% & 0.89\n",
      "for 2019-04-07, MAE is:3.27 & sMAPE is:8.41% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 24.70% & 0.88\n",
      "for 2019-04-08, MAE is:4.38 & sMAPE is:9.97% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 24.55% & 0.88\n",
      "for 2019-04-09, MAE is:3.09 & sMAPE is:7.58% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 24.38% & 0.88\n",
      "for 2019-04-10, MAE is:2.38 & sMAPE is:5.45% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 24.19% & 0.88\n",
      "for 2019-04-11, MAE is:3.46 & sMAPE is:7.41% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 24.02% & 0.87\n",
      "for 2019-04-12, MAE is:2.93 & sMAPE is:6.10% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 23.85% & 0.87\n",
      "for 2019-04-13, MAE is:2.84 & sMAPE is:6.83% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 23.68% & 0.87\n",
      "for 2019-04-14, MAE is:5.27 & sMAPE is:13.40% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 23.58% & 0.88\n",
      "for 2019-04-15, MAE is:5.64 & sMAPE is:13.67% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 23.49% & 0.88\n",
      "for 2019-04-16, MAE is:5.81 & sMAPE is:13.96% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 23.40% & 0.89\n",
      "for 2019-04-17, MAE is:3.05 & sMAPE is:7.24% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 23.25% & 0.89\n",
      "for 2019-04-18, MAE is:4.59 & sMAPE is:10.89% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 23.14% & 0.90\n",
      "for 2019-04-19, MAE is:1.40 & sMAPE is:3.44% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 22.95% & 0.89\n",
      "for 2019-04-20, MAE is:2.62 & sMAPE is:6.65% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 22.81% & 0.89\n",
      "for 2019-04-21, MAE is:2.33 & sMAPE is:6.12% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 22.66% & 0.89\n",
      "for 2019-04-22, MAE is:10.72 & sMAPE is:41.23% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 22.82% & 0.89\n",
      "for 2019-04-23, MAE is:17.40 & sMAPE is:133.98% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 23.81% & 0.89\n",
      "for 2019-04-24, MAE is:14.75 & sMAPE is:64.34% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 24.16% & 0.89\n",
      "for 2019-04-25, MAE is:8.25 & sMAPE is:21.29% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 24.14% & 0.89\n",
      "for 2019-04-26, MAE is:4.25 & sMAPE is:10.18% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 24.02% & 0.90\n",
      "for 2019-04-27, MAE is:1.73 & sMAPE is:5.35% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 23.86% & 0.89\n",
      "for 2019-04-28, MAE is:3.53 & sMAPE is:9.97% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 23.74% & 0.89\n",
      "for 2019-04-29, MAE is:3.34 & sMAPE is:7.79% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 23.60% & 0.88\n",
      "for 2019-04-30, MAE is:5.34 & sMAPE is:12.60% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 23.51% & 0.88\n",
      "for 2019-05-01, MAE is:17.98 & sMAPE is:62.44% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 23.83% & 0.88\n",
      "for 2019-05-02, MAE is:8.09 & sMAPE is:43.32% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 23.99% & 0.88\n",
      "for 2019-05-03, MAE is:2.66 & sMAPE is:6.65% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 23.85% & 0.88\n",
      "for 2019-05-04, MAE is:2.48 & sMAPE is:6.41% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 23.71% & 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-05-05, MAE is:7.51 & sMAPE is:23.86% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 23.71% & 0.88\n",
      "for 2019-05-06, MAE is:3.80 & sMAPE is:8.55% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 23.59% & 0.88\n",
      "for 2019-05-07, MAE is:4.68 & sMAPE is:9.22% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 23.48% & 0.88\n",
      "for 2019-05-08, MAE is:7.57 & sMAPE is:16.39% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 23.42% & 0.88\n",
      "for 2019-05-09, MAE is:4.42 & sMAPE is:10.10% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 23.32% & 0.87\n",
      "for 2019-05-10, MAE is:4.16 & sMAPE is:9.19% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 23.21% & 0.87\n",
      "for 2019-05-11, MAE is:4.62 & sMAPE is:11.46% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 23.12% & 0.88\n",
      "for 2019-05-12, MAE is:17.19 & sMAPE is:68.58% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 23.47% & 0.88\n",
      "for 2019-05-13, MAE is:8.04 & sMAPE is:22.74% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 23.46% & 0.89\n",
      "for 2019-05-14, MAE is:3.35 & sMAPE is:7.18% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 23.34% & 0.89\n",
      "for 2019-05-15, MAE is:3.28 & sMAPE is:7.05% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 23.22% & 0.89\n",
      "for 2019-05-16, MAE is:5.01 & sMAPE is:11.70% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 23.14% & 0.89\n",
      "for 2019-05-17, MAE is:5.07 & sMAPE is:12.19% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 23.06% & 0.89\n",
      "for 2019-05-18, MAE is:2.93 & sMAPE is:7.63% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 22.94% & 0.89\n",
      "for 2019-05-19, MAE is:2.21 & sMAPE is:5.79% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 22.82% & 0.89\n",
      "for 2019-05-20, MAE is:4.00 & sMAPE is:8.76% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 22.72% & 0.89\n",
      "for 2019-05-21, MAE is:2.18 & sMAPE is:5.04% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 22.59% & 0.88\n",
      "for 2019-05-22, MAE is:2.98 & sMAPE is:7.40% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 22.49% & 0.88\n",
      "for 2019-05-23, MAE is:4.92 & sMAPE is:11.42% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 22.41% & 0.88\n",
      "for 2019-05-24, MAE is:4.44 & sMAPE is:10.49% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 22.33% & 0.88\n",
      "for 2019-05-25, MAE is:2.26 & sMAPE is:6.55% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 22.22% & 0.88\n",
      "for 2019-05-26, MAE is:6.87 & sMAPE is:24.64% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 22.23% & 0.88\n",
      "for 2019-05-27, MAE is:5.49 & sMAPE is:19.22% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 22.21% & 0.88\n",
      "for 2019-05-28, MAE is:4.55 & sMAPE is:10.68% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 22.14% & 0.88\n",
      "for 2019-05-29, MAE is:5.78 & sMAPE is:13.97% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 22.08% & 0.89\n",
      "for 2019-05-30, MAE is:21.94 & sMAPE is:101.68% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 22.61% & 0.89\n",
      "for 2019-05-31, MAE is:3.15 & sMAPE is:9.20% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 22.52% & 0.89\n",
      "for 2019-06-01, MAE is:5.72 & sMAPE is:18.79% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 22.50% & 0.89\n",
      "for 2019-06-02, MAE is:3.22 & sMAPE is:12.31% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 22.43% & 0.89\n",
      "for 2019-06-03, MAE is:4.67 & sMAPE is:12.88% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 22.37% & 0.89\n",
      "for 2019-06-04, MAE is:3.99 & sMAPE is:9.96% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 22.29% & 0.89\n",
      "for 2019-06-05, MAE is:9.03 & sMAPE is:28.66% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 22.33% & 0.89\n",
      "for 2019-06-06, MAE is:6.56 & sMAPE is:17.56% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 22.30% & 0.89\n",
      "for 2019-06-07, MAE is:7.70 & sMAPE is:19.77% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 22.28% & 0.89\n",
      "for 2019-06-08, MAE is:13.50 & sMAPE is:89.03% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 22.70% & 0.89\n",
      "for 2019-06-09, MAE is:9.74 & sMAPE is:77.22% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 23.04% & 0.89\n",
      "for 2019-06-10, MAE is:8.90 & sMAPE is:24.41% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 23.05% & 0.89\n",
      "for 2019-06-11, MAE is:11.07 & sMAPE is:28.90% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 23.09% & 0.89\n",
      "for 2019-06-12, MAE is:6.75 & sMAPE is:16.38% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 23.05% & 0.89\n",
      "for 2019-06-13, MAE is:11.42 & sMAPE is:34.93% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 23.12% & 0.89\n",
      "for 2019-06-14, MAE is:6.74 & sMAPE is:16.03% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 23.08% & 0.89\n",
      "for 2019-06-15, MAE is:8.39 & sMAPE is:26.04% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 23.10% & 0.89\n",
      "for 2019-06-16, MAE is:4.77 & sMAPE is:15.09% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 23.05% & 0.89\n",
      "for 2019-06-17, MAE is:6.90 & sMAPE is:15.26% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 23.00% & 0.88\n",
      "for 2019-06-18, MAE is:6.61 & sMAPE is:16.02% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 22.96% & 0.88\n",
      "for 2019-06-19, MAE is:4.67 & sMAPE is:10.65% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 22.89% & 0.89\n",
      "for 2019-06-20, MAE is:4.07 & sMAPE is:10.79% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 22.82% & 0.88\n",
      "for 2019-06-21, MAE is:5.38 & sMAPE is:14.00% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 22.77% & 0.88\n",
      "for 2019-06-22, MAE is:3.93 & sMAPE is:13.56% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 22.71% & 0.88\n",
      "for 2019-06-23, MAE is:3.67 & sMAPE is:14.02% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 22.66% & 0.88\n",
      "for 2019-06-24, MAE is:4.14 & sMAPE is:11.84% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 22.60% & 0.88\n",
      "for 2019-06-25, MAE is:7.50 & sMAPE is:17.07% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 22.57% & 0.89\n",
      "for 2019-06-26, MAE is:9.78 & sMAPE is:28.16% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 22.60% & 0.89\n",
      "for 2019-06-27, MAE is:5.81 & sMAPE is:18.15% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 22.58% & 0.89\n",
      "for 2019-06-28, MAE is:10.81 & sMAPE is:27.61% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 22.60% & 0.89\n",
      "for 2019-06-29, MAE is:6.13 & sMAPE is:17.28% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 22.57% & 0.90\n",
      "for 2019-06-30, MAE is:11.16 & sMAPE is:50.44% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 22.73% & 0.90\n",
      "for 2019-07-01, MAE is:6.74 & sMAPE is:24.26% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 22.74% & 0.90\n",
      "for 2019-07-02, MAE is:3.52 & sMAPE is:11.17% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 22.67% & 0.90\n",
      "for 2019-07-03, MAE is:3.37 & sMAPE is:11.43% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 22.61% & 0.90\n",
      "for 2019-07-04, MAE is:4.03 & sMAPE is:13.54% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 22.56% & 0.89\n",
      "for 2019-07-05, MAE is:3.62 & sMAPE is:11.78% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 22.51% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-07-06, MAE is:3.11 & sMAPE is:11.83% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 22.45% & 0.89\n",
      "for 2019-07-07, MAE is:4.65 & sMAPE is:18.13% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 22.43% & 0.89\n",
      "for 2019-07-08, MAE is:3.46 & sMAPE is:11.24% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 22.37% & 0.89\n",
      "for 2019-07-09, MAE is:6.85 & sMAPE is:20.27% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 22.36% & 0.89\n",
      "for 2019-07-10, MAE is:6.57 & sMAPE is:16.61% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 22.33% & 0.88\n",
      "for 2019-07-11, MAE is:6.93 & sMAPE is:15.77% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 22.29% & 0.88\n",
      "for 2019-07-12, MAE is:3.76 & sMAPE is:8.37% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 22.22% & 0.88\n",
      "for 2019-07-13, MAE is:2.82 & sMAPE is:7.74% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 22.14% & 0.87\n",
      "for 2019-07-14, MAE is:1.28 & sMAPE is:3.71% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 22.05% & 0.87\n",
      "for 2019-07-15, MAE is:3.28 & sMAPE is:8.68% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 21.98% & 0.87\n",
      "for 2019-07-16, MAE is:5.45 & sMAPE is:13.34% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 21.94% & 0.87\n",
      "for 2019-07-17, MAE is:3.90 & sMAPE is:8.71% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 21.87% & 0.87\n",
      "for 2019-07-18, MAE is:3.23 & sMAPE is:7.14% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 21.80% & 0.87\n",
      "for 2019-07-19, MAE is:3.35 & sMAPE is:7.26% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 21.72% & 0.87\n",
      "for 2019-07-20, MAE is:4.65 & sMAPE is:11.63% & rMAE is:3.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 21.67% & 0.89\n",
      "for 2019-07-21, MAE is:1.78 & sMAPE is:5.23% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 21.59% & 0.89\n",
      "for 2019-07-22, MAE is:4.02 & sMAPE is:10.69% & rMAE is:2.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 21.54% & 0.90\n",
      "for 2019-07-23, MAE is:8.09 & sMAPE is:18.18% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 21.52% & 0.90\n",
      "for 2019-07-24, MAE is:5.95 & sMAPE is:11.22% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 21.47% & 0.90\n",
      "for 2019-07-25, MAE is:3.99 & sMAPE is:7.67% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 21.40% & 0.90\n",
      "for 2019-07-26, MAE is:3.51 & sMAPE is:8.43% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 21.34% & 0.91\n",
      "for 2019-07-27, MAE is:2.82 & sMAPE is:8.00% & rMAE is:2.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 21.28% & 0.91\n",
      "for 2019-07-28, MAE is:1.38 & sMAPE is:4.05% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 21.20% & 0.91\n",
      "for 2019-07-29, MAE is:5.71 & sMAPE is:12.90% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 21.16% & 0.91\n",
      "for 2019-07-30, MAE is:3.82 & sMAPE is:9.06% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 21.10% & 0.91\n",
      "for 2019-07-31, MAE is:10.80 & sMAPE is:24.09% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 21.11% & 0.92\n",
      "for 2019-08-01, MAE is:6.11 & sMAPE is:13.33% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 21.08% & 0.92\n",
      "for 2019-08-02, MAE is:4.30 & sMAPE is:9.56% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 21.02% & 0.92\n",
      "for 2019-08-03, MAE is:2.48 & sMAPE is:6.71% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 20.96% & 0.92\n",
      "for 2019-08-04, MAE is:4.39 & sMAPE is:11.88% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 20.91% & 0.92\n",
      "for 2019-08-05, MAE is:3.46 & sMAPE is:7.59% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 20.85% & 0.92\n",
      "for 2019-08-06, MAE is:4.40 & sMAPE is:10.23% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 20.80% & 0.92\n",
      "for 2019-08-07, MAE is:4.82 & sMAPE is:11.22% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 20.76% & 0.92\n",
      "for 2019-08-08, MAE is:4.36 & sMAPE is:10.47% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 20.71% & 0.92\n",
      "for 2019-08-09, MAE is:3.53 & sMAPE is:8.94% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 20.66% & 0.92\n",
      "for 2019-08-10, MAE is:2.10 & sMAPE is:6.31% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 20.60% & 0.92\n",
      "for 2019-08-11, MAE is:5.00 & sMAPE is:20.69% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 20.60% & 0.91\n",
      "for 2019-08-12, MAE is:7.68 & sMAPE is:16.91% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 20.58% & 0.91\n",
      "for 2019-08-13, MAE is:6.86 & sMAPE is:17.27% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 20.56% & 0.92\n",
      "for 2019-08-14, MAE is:5.66 & sMAPE is:12.82% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 20.53% & 0.92\n",
      "for 2019-08-15, MAE is:7.11 & sMAPE is:17.39% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 20.52% & 0.92\n",
      "for 2019-08-16, MAE is:4.25 & sMAPE is:10.81% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 20.47% & 0.92\n",
      "for 2019-08-17, MAE is:3.14 & sMAPE is:11.38% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 20.43% & 0.92\n",
      "for 2019-08-18, MAE is:2.82 & sMAPE is:9.35% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 20.39% & 0.91\n",
      "for 2019-08-19, MAE is:3.42 & sMAPE is:8.88% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 20.34% & 0.91\n",
      "for 2019-08-20, MAE is:4.04 & sMAPE is:10.10% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 20.29% & 0.91\n",
      "for 2019-08-21, MAE is:6.96 & sMAPE is:15.97% & rMAE is:2.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 20.27% & 0.92\n",
      "for 2019-08-22, MAE is:3.92 & sMAPE is:9.66% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 20.23% & 0.92\n",
      "for 2019-08-23, MAE is:5.53 & sMAPE is:13.87% & rMAE is:3.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 20.20% & 0.93\n",
      "for 2019-08-24, MAE is:3.03 & sMAPE is:9.36% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 20.16% & 0.93\n",
      "for 2019-08-25, MAE is:3.29 & sMAPE is:9.73% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 20.11% & 0.93\n",
      "for 2019-08-26, MAE is:7.93 & sMAPE is:17.61% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 20.10% & 0.93\n",
      "for 2019-08-27, MAE is:7.56 & sMAPE is:17.37% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 20.09% & 0.93\n",
      "for 2019-08-28, MAE is:8.82 & sMAPE is:17.48% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 20.08% & 0.94\n",
      "for 2019-08-29, MAE is:3.22 & sMAPE is:7.02% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 20.02% & 0.93\n",
      "for 2019-08-30, MAE is:5.22 & sMAPE is:12.95% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 20.00% & 0.93\n",
      "for 2019-08-31, MAE is:1.98 & sMAPE is:5.35% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 19.93% & 0.93\n",
      "for 2019-09-01, MAE is:1.51 & sMAPE is:4.53% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 19.87% & 0.93\n",
      "for 2019-09-02, MAE is:2.91 & sMAPE is:6.89% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 19.82% & 0.93\n",
      "for 2019-09-03, MAE is:5.37 & sMAPE is:14.88% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 19.80% & 0.93\n",
      "for 2019-09-04, MAE is:6.17 & sMAPE is:13.95% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 19.78% & 0.93\n",
      "for 2019-09-05, MAE is:3.66 & sMAPE is:9.85% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 19.74% & 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-09-06, MAE is:1.84 & sMAPE is:5.57% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.68% & 0.92\n",
      "for 2019-09-07, MAE is:6.22 & sMAPE is:18.51% & rMAE is:3.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.67% & 0.93\n",
      "for 2019-09-08, MAE is:5.45 & sMAPE is:15.46% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.66% & 0.94\n",
      "for 2019-09-09, MAE is:6.27 & sMAPE is:14.26% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.64% & 0.94\n",
      "for 2019-09-10, MAE is:4.16 & sMAPE is:11.07% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 19.60% & 0.94\n",
      "for 2019-09-11, MAE is:4.50 & sMAPE is:12.52% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 19.57% & 0.94\n",
      "for 2019-09-12, MAE is:4.61 & sMAPE is:12.43% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 19.55% & 0.94\n",
      "for 2019-09-13, MAE is:6.88 & sMAPE is:19.45% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 19.55% & 0.94\n",
      "for 2019-09-14, MAE is:3.80 & sMAPE is:10.79% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.51% & 0.94\n",
      "for 2019-09-15, MAE is:6.71 & sMAPE is:26.25% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.54% & 0.94\n",
      "for 2019-09-16, MAE is:6.24 & sMAPE is:24.19% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.56% & 0.94\n",
      "for 2019-09-17, MAE is:5.55 & sMAPE is:14.70% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.54% & 0.94\n",
      "for 2019-09-18, MAE is:6.84 & sMAPE is:18.51% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.53% & 0.94\n",
      "for 2019-09-19, MAE is:5.41 & sMAPE is:11.74% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.50% & 0.94\n",
      "for 2019-09-20, MAE is:5.50 & sMAPE is:13.17% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.48% & 0.94\n",
      "for 2019-09-21, MAE is:6.05 & sMAPE is:17.82% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.47% & 0.94\n",
      "for 2019-09-22, MAE is:3.05 & sMAPE is:10.12% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 19.44% & 0.94\n",
      "for 2019-09-23, MAE is:9.81 & sMAPE is:24.46% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.46% & 0.94\n",
      "for 2019-09-24, MAE is:9.39 & sMAPE is:21.20% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 19.46% & 0.94\n",
      "for 2019-09-25, MAE is:9.19 & sMAPE is:21.36% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 19.47% & 0.94\n",
      "for 2019-09-26, MAE is:4.35 & sMAPE is:10.92% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 19.44% & 0.94\n",
      "for 2019-09-27, MAE is:4.02 & sMAPE is:10.48% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 19.40% & 0.94\n",
      "for 2019-09-28, MAE is:2.94 & sMAPE is:9.56% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.37% & 0.94\n",
      "for 2019-09-29, MAE is:5.06 & sMAPE is:29.91% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 19.41% & 0.94\n",
      "for 2019-09-30, MAE is:4.14 & sMAPE is:11.56% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 19.38% & 0.94\n",
      "for 2019-10-01, MAE is:6.71 & sMAPE is:16.01% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 19.37% & 0.94\n",
      "for 2019-10-02, MAE is:3.64 & sMAPE is:8.94% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 19.33% & 0.94\n",
      "for 2019-10-03, MAE is:6.25 & sMAPE is:14.93% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 19.31% & 0.94\n",
      "for 2019-10-04, MAE is:5.28 & sMAPE is:11.17% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 19.28% & 0.93\n",
      "for 2019-10-05, MAE is:5.45 & sMAPE is:15.06% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 19.27% & 0.93\n",
      "for 2019-10-06, MAE is:2.97 & sMAPE is:7.97% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 19.23% & 0.93\n",
      "for 2019-10-07, MAE is:16.24 & sMAPE is:29.92% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.27% & 0.93\n",
      "for 2019-10-08, MAE is:7.63 & sMAPE is:15.65% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.25% & 0.93\n",
      "for 2019-10-09, MAE is:12.51 & sMAPE is:25.96% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 19.28% & 0.93\n",
      "for 2019-10-10, MAE is:6.97 & sMAPE is:15.88% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.26% & 0.93\n",
      "for 2019-10-11, MAE is:5.07 & sMAPE is:13.84% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 19.25% & 0.93\n",
      "for 2019-10-12, MAE is:9.10 & sMAPE is:52.33% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.36% & 0.93\n",
      "for 2019-10-13, MAE is:6.23 & sMAPE is:23.23% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.37% & 0.93\n",
      "for 2019-10-14, MAE is:15.46 & sMAPE is:47.98% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 19.47% & 0.93\n",
      "for 2019-10-15, MAE is:5.88 & sMAPE is:14.22% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 19.46% & 0.93\n",
      "for 2019-10-16, MAE is:7.84 & sMAPE is:17.21% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 19.45% & 0.93\n",
      "for 2019-10-17, MAE is:7.76 & sMAPE is:17.51% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 19.44% & 0.93\n",
      "for 2019-10-18, MAE is:5.98 & sMAPE is:14.45% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 19.42% & 0.93\n",
      "for 2019-10-19, MAE is:4.93 & sMAPE is:14.66% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 19.41% & 0.93\n",
      "for 2019-10-20, MAE is:4.23 & sMAPE is:11.41% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 19.38% & 0.93\n",
      "for 2019-10-21, MAE is:7.00 & sMAPE is:15.92% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 19.37% & 0.93\n",
      "for 2019-10-22, MAE is:5.19 & sMAPE is:10.82% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 19.34% & 0.94\n",
      "for 2019-10-23, MAE is:2.81 & sMAPE is:6.31% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 19.30% & 0.94\n",
      "for 2019-10-24, MAE is:4.37 & sMAPE is:11.11% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 19.27% & 0.93\n",
      "for 2019-10-25, MAE is:3.42 & sMAPE is:9.55% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.24% & 0.93\n",
      "for 2019-10-26, MAE is:4.90 & sMAPE is:19.62% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.24% & 0.93\n",
      "for 2019-10-27, MAE is:5.20 & sMAPE is:27.62% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 19.27% & 0.93\n",
      "for 2019-10-28, MAE is:10.35 & sMAPE is:28.40% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 19.30% & 0.93\n",
      "for 2019-10-29, MAE is:5.40 & sMAPE is:11.25% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.27% & 0.94\n",
      "for 2019-10-30, MAE is:6.00 & sMAPE is:12.83% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.25% & 0.94\n",
      "for 2019-10-31, MAE is:4.48 & sMAPE is:10.57% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.22% & 0.94\n",
      "for 2019-11-01, MAE is:6.30 & sMAPE is:15.32% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 19.21% & 0.94\n",
      "for 2019-11-02, MAE is:2.87 & sMAPE is:8.97% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 19.17% & 0.93\n",
      "for 2019-11-03, MAE is:5.39 & sMAPE is:16.40% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 19.16% & 0.93\n",
      "for 2019-11-04, MAE is:4.06 & sMAPE is:10.77% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 19.14% & 0.93\n",
      "for 2019-11-05, MAE is:4.42 & sMAPE is:10.45% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.11% & 0.93\n",
      "for 2019-11-06, MAE is:9.22 & sMAPE is:18.22% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 19.11% & 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-11-07, MAE is:4.85 & sMAPE is:10.17% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 19.08% & 0.94\n",
      "for 2019-11-08, MAE is:7.96 & sMAPE is:17.14% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 19.07% & 0.94\n",
      "for 2019-11-09, MAE is:3.11 & sMAPE is:7.76% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.03% & 0.93\n",
      "for 2019-11-10, MAE is:4.46 & sMAPE is:11.16% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.01% & 0.93\n",
      "for 2019-11-11, MAE is:4.43 & sMAPE is:9.40% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 18.98% & 0.93\n",
      "for 2019-11-12, MAE is:3.49 & sMAPE is:7.76% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 18.94% & 0.93\n",
      "for 2019-11-13, MAE is:4.33 & sMAPE is:8.76% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 18.91% & 0.93\n",
      "for 2019-11-14, MAE is:4.28 & sMAPE is:8.88% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 18.88% & 0.93\n",
      "for 2019-11-15, MAE is:3.90 & sMAPE is:10.04% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 18.85% & 0.93\n",
      "for 2019-11-16, MAE is:2.32 & sMAPE is:6.32% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 18.81% & 0.93\n",
      "for 2019-11-17, MAE is:2.76 & sMAPE is:7.58% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 18.78% & 0.93\n",
      "for 2019-11-18, MAE is:4.62 & sMAPE is:11.25% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 18.75% & 0.93\n",
      "for 2019-11-19, MAE is:4.65 & sMAPE is:9.92% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 18.73% & 0.93\n",
      "for 2019-11-20, MAE is:9.56 & sMAPE is:18.75% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 18.73% & 0.94\n",
      "for 2019-11-21, MAE is:4.15 & sMAPE is:8.18% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 18.69% & 0.94\n",
      "for 2019-11-22, MAE is:3.02 & sMAPE is:6.99% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 18.66% & 0.94\n",
      "for 2019-11-23, MAE is:1.68 & sMAPE is:4.68% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 18.62% & 0.94\n",
      "for 2019-11-24, MAE is:6.67 & sMAPE is:27.29% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 18.64% & 0.94\n",
      "for 2019-11-25, MAE is:8.61 & sMAPE is:18.46% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 18.64% & 0.94\n",
      "for 2019-11-26, MAE is:2.82 & sMAPE is:5.88% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 18.60% & 0.93\n",
      "for 2019-11-27, MAE is:4.57 & sMAPE is:10.17% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 18.58% & 0.93\n",
      "for 2019-11-28, MAE is:5.17 & sMAPE is:12.77% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 18.56% & 0.93\n",
      "for 2019-11-29, MAE is:4.60 & sMAPE is:14.29% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 18.55% & 0.93\n",
      "for 2019-11-30, MAE is:3.87 & sMAPE is:9.22% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 18.52% & 0.93\n",
      "for 2019-12-01, MAE is:1.79 & sMAPE is:4.04% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 18.48% & 0.93\n",
      "for 2019-12-02, MAE is:3.86 & sMAPE is:8.21% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 18.45% & 0.93\n",
      "for 2019-12-03, MAE is:7.28 & sMAPE is:14.31% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 18.43% & 0.93\n",
      "for 2019-12-04, MAE is:5.32 & sMAPE is:10.75% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 18.41% & 0.93\n",
      "for 2019-12-05, MAE is:7.74 & sMAPE is:18.54% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 18.41% & 0.93\n",
      "for 2019-12-06, MAE is:4.08 & sMAPE is:13.62% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 18.40% & 0.93\n",
      "for 2019-12-07, MAE is:9.17 & sMAPE is:55.32% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 18.51% & 0.93\n",
      "for 2019-12-08, MAE is:20.25 & sMAPE is:99.86% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 18.74% & 0.93\n",
      "for 2019-12-09, MAE is:8.79 & sMAPE is:48.96% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 18.83% & 0.93\n",
      "for 2019-12-10, MAE is:10.95 & sMAPE is:33.62% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 18.87% & 0.93\n",
      "for 2019-12-11, MAE is:12.06 & sMAPE is:46.06% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 18.95% & 0.93\n",
      "for 2019-12-12, MAE is:5.55 & sMAPE is:12.68% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 18.94% & 0.93\n",
      "for 2019-12-13, MAE is:5.02 & sMAPE is:16.09% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 18.93% & 0.93\n",
      "for 2019-12-14, MAE is:7.80 & sMAPE is:26.93% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 18.95% & 0.93\n",
      "for 2019-12-15, MAE is:11.52 & sMAPE is:66.40% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 19.09% & 0.93\n",
      "for 2019-12-16, MAE is:4.87 & sMAPE is:12.59% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 19.07% & 0.93\n",
      "for 2019-12-17, MAE is:5.29 & sMAPE is:11.86% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 19.05% & 0.93\n",
      "for 2019-12-18, MAE is:4.20 & sMAPE is:10.71% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 19.02% & 0.93\n",
      "for 2019-12-19, MAE is:7.84 & sMAPE is:18.16% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 19.02% & 0.93\n",
      "for 2019-12-20, MAE is:6.34 & sMAPE is:16.51% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 19.01% & 0.93\n",
      "for 2019-12-21, MAE is:5.27 & sMAPE is:16.10% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 19.01% & 0.93\n",
      "for 2019-12-22, MAE is:1.40 & sMAPE is:3.94% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 18.96% & 0.93\n",
      "for 2019-12-23, MAE is:3.00 & sMAPE is:8.25% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 18.93% & 0.93\n",
      "for 2019-12-24, MAE is:3.35 & sMAPE is:12.06% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 18.91% & 0.93\n",
      "for 2019-12-25, MAE is:2.35 & sMAPE is:7.23% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.14 & 18.88% & 0.92\n",
      "for 2019-12-26, MAE is:3.82 & sMAPE is:11.14% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 18.86% & 0.93\n",
      "for 2019-12-27, MAE is:2.83 & sMAPE is:7.32% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 18.83% & 0.93\n",
      "for 2019-12-28, MAE is:3.44 & sMAPE is:9.45% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 18.80% & 0.93\n",
      "for 2019-12-29, MAE is:4.72 & sMAPE is:15.80% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 18.79% & 0.93\n",
      "for 2019-12-30, MAE is:4.99 & sMAPE is:28.59% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 18.82% & 0.93\n",
      "for 2019-12-31, MAE is:2.90 & sMAPE is:14.96% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 18.81% & 0.93\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:09:00,576]\u001b[0m A new study created in RDB with name: DK_2_2020\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:09:19,534]\u001b[0m Trial 1 finished with value: 8.116949646148822 and parameters: {'n_hidden': 3, 'learning_rate': 0.05639266229594675, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3354620897567, 'dropout_rate_Layer_2': 0.22543811523638496, 'dropout_rate_Layer_3': 0.26453439488486336, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.01102564360078642, 'l1_Layer_2': 0.0009165274211673834, 'l1_Layer_3': 0.036136555620628105, 'n_units_Layer_1': 250, 'n_units_Layer_2': 245, 'n_units_Layer_3': 265}. Best is trial 1 with value: 8.116949646148822.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.12 | sMAPE for Validation Set is: 23.37% | rMAE for Validation Set is: 1.00\n",
      "MAE for Test Set is: 13.73 | sMAPE for Test Set is: 53.16% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:09:19,896]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 15.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:09:25,404]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:09:28,920]\u001b[0m Trial 2 finished with value: 5.422760143737331 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017021961612464945, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11498355333543585, 'dropout_rate_Layer_2': 0.08859893201046454, 'dropout_rate_Layer_3': 0.23594874238407187, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0034887066269254047, 'l1_Layer_2': 0.0004706196352418337, 'l1_Layer_3': 5.218565286806924e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 75, 'n_units_Layer_3': 120}. Best is trial 2 with value: 5.422760143737331.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 16.26% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.43 | sMAPE for Test Set is: 44.61% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:09:31,341]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:09:33,360]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:09:33,818]\u001b[0m Trial 0 finished with value: 5.812589164570501 and parameters: {'n_hidden': 3, 'learning_rate': 0.007935360447987273, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026909761612452156, 'dropout_rate_Layer_2': 0.24601180273206316, 'dropout_rate_Layer_3': 0.13156705743509733, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.041840897702313154, 'l1_Layer_2': 0.0005528106130032744, 'l1_Layer_3': 0.001268833081075131, 'n_units_Layer_1': 160, 'n_units_Layer_2': 255, 'n_units_Layer_3': 270}. Best is trial 2 with value: 5.422760143737331.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 17.21% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 12.06 | sMAPE for Test Set is: 49.08% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:09:37,466]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:09:41,515]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:09:43,777]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:09:46,741]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:09:50,351]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:09:54,111]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:09:56,519]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:10:00,559]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:10:00,897]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:10:06,825]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:10:06,978]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:10:13,212]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:10:16,826]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:10:19,697]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:10:27,525]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:10:30,673]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:10:35,209]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:10:38,620]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:10:41,483]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:10:45,813]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:10:50,210]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:10:51,974]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:10:57,090]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:02,062]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:05,523]\u001b[0m Trial 11 finished with value: 5.52730636390672 and parameters: {'n_hidden': 3, 'learning_rate': 0.004298049438397758, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08304080434498684, 'dropout_rate_Layer_2': 0.037833953822386995, 'dropout_rate_Layer_3': 0.030912603092809833, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0024273581117410644, 'l1_Layer_2': 0.00048426931438029714, 'l1_Layer_3': 0.0033410649574781588, 'n_units_Layer_1': 260, 'n_units_Layer_2': 240, 'n_units_Layer_3': 200}. Best is trial 2 with value: 5.422760143737331.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 16.56% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.73 | sMAPE for Test Set is: 48.54% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:11:10,233]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:13,611]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:17,218]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:17,310]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:22,670]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:24,964]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:28,712]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:31,092]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:31,938]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:37,006]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:37,443]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:41,732]\u001b[0m Trial 4 finished with value: 5.9958805271056335 and parameters: {'n_hidden': 4, 'learning_rate': 0.007142644294669131, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3992382318342515, 'dropout_rate_Layer_2': 0.06179730863187523, 'dropout_rate_Layer_3': 0.3470996853522932, 'dropout_rate_Layer_4': 0.16648449662069276, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.000835343849232686, 'l1_Layer_2': 5.472468348480439e-05, 'l1_Layer_3': 0.019825896512738063, 'l1_Layer_4': 0.0002668564085957766, 'n_units_Layer_1': 175, 'n_units_Layer_2': 210, 'n_units_Layer_3': 55, 'n_units_Layer_4': 80}. Best is trial 2 with value: 5.422760143737331.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 17.76% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 11.73 | sMAPE for Test Set is: 48.36% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:11:42,147]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:42,491]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:44,110]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:46,440]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:49,215]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:55,145]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:55,517]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:55,918]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:11:58,080]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:01,104]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:08,651]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:08,883]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:14,161]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:17,141]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:19,426]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:21,719]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:22,626]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:25,830]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:26,881]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:29,858]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:31,602]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:34,522]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:35,630]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:43,747]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:46,033]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:49,480]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:50,767]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:51,475]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:12:58,273]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:13:01,289]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:13:11,225]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:13:11,494]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:13:19,900]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:13:20,966]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:13:26,710]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:13:28,014]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:13:30,236]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:13:35,543]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:13:36,052]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:13:37,175]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:13:44,890]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:13:49,954]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:14:13,158]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:14:20,699]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:14:20,978]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:14:21,588]\u001b[0m Trial 72 finished with value: 5.817835480594102 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026025590009493946, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13574463752134763, 'dropout_rate_Layer_2': 0.18484125385536698, 'dropout_rate_Layer_3': 0.24261418982306582, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00042241016627988956, 'l1_Layer_2': 0.00022047405012644687, 'l1_Layer_3': 0.0012451664347515018, 'n_units_Layer_1': 80, 'n_units_Layer_2': 165, 'n_units_Layer_3': 135}. Best is trial 2 with value: 5.422760143737331.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 17.24% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 11.74 | sMAPE for Test Set is: 48.21% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:14:25,893]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:14:29,089]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:14:30,219]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:14:36,428]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:14:36,573]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:14:39,204]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:14:43,246]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:14:47,540]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:14:52,260]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:14:52,455]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:14:56,207]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:14:59,434]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:14:59,651]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:15:06,466]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:15:09,617]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:15:11,442]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:15:14,318]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:15:14,384]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:15:16,233]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:15:22,257]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:15:25,998]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:15:26,312]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:15:32,324]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:15:40,226]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:15:40,812]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:15:42,381]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:15:45,790]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:15:49,310]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:15:52,752]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:15:57,766]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:01,015]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:04,800]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:08,399]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:08,561]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:13,551]\u001b[0m Trial 105 finished with value: 8.704551287345602 and parameters: {'n_hidden': 4, 'learning_rate': 0.02621160386041397, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22232742741514958, 'dropout_rate_Layer_2': 0.0527525402082814, 'dropout_rate_Layer_3': 0.1552151798108471, 'dropout_rate_Layer_4': 0.31232628094354686, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 9.686001185912598e-05, 'l1_Layer_2': 0.0015652179413216175, 'l1_Layer_3': 9.549680588156388e-05, 'l1_Layer_4': 9.880350613813272e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 190, 'n_units_Layer_3': 200, 'n_units_Layer_4': 235}. Best is trial 2 with value: 5.422760143737331.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.70 | sMAPE for Validation Set is: 24.64% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 14.12 | sMAPE for Test Set is: 53.96% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:16:15,928]\u001b[0m Trial 119 finished with value: 5.484717144264633 and parameters: {'n_hidden': 3, 'learning_rate': 0.003935870543198738, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04636304944430658, 'dropout_rate_Layer_2': 0.12283917239807103, 'dropout_rate_Layer_3': 0.19889901683073183, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002856734823369849, 'l1_Layer_2': 0.0004854197388853773, 'l1_Layer_3': 4.7152942788490863e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 140, 'n_units_Layer_3': 205}. Best is trial 2 with value: 5.422760143737331.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 16.54% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.39 | sMAPE for Test Set is: 44.21% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:16:18,279]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:18,904]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:19,073]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:23,960]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:27,796]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:27,905]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:30,960]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:35,157]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:39,277]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:41,275]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:41,682]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:46,524]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:49,490]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:51,149]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:53,906]\u001b[0m Trial 129 finished with value: 5.78822521028572 and parameters: {'n_hidden': 4, 'learning_rate': 0.013105494939551003, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04181531895889609, 'dropout_rate_Layer_2': 0.12881110269489587, 'dropout_rate_Layer_3': 0.16952287635017882, 'dropout_rate_Layer_4': 0.04255526725177569, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006386892190976626, 'l1_Layer_2': 0.05800197120474498, 'l1_Layer_3': 1.0089093165866597e-05, 'l1_Layer_4': 0.08026723229940452, 'n_units_Layer_1': 175, 'n_units_Layer_2': 90, 'n_units_Layer_3': 55, 'n_units_Layer_4': 60}. Best is trial 2 with value: 5.422760143737331.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 17.30% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.29 | sMAPE for Test Set is: 47.16% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:16:54,097]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:16:54,755]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:01,228]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:04,510]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:06,105]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:10,154]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:11,907]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:15,124]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:16,381]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:22,667]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:24,946]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:27,765]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:30,076]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:32,618]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:35,637]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:35,703]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:40,011]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:43,040]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:43,085]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:48,816]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:49,013]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:57,390]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:17:59,245]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:08,018]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:12,166]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:14,345]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 16.11% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.88 | sMAPE for Test Set is: 46.04% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:18:16,256]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:16,271]\u001b[0m Trial 145 finished with value: 5.3344296247560665 and parameters: {'n_hidden': 3, 'learning_rate': 0.003855535742721991, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026890582644690103, 'dropout_rate_Layer_2': 0.11111349879693164, 'dropout_rate_Layer_3': 0.017660317671270104, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00391462636652435, 'l1_Layer_2': 0.00038397617728463, 'l1_Layer_3': 0.00408083311270911, 'n_units_Layer_1': 300, 'n_units_Layer_2': 270, 'n_units_Layer_3': 165}. Best is trial 145 with value: 5.3344296247560665.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:16,897]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:23,809]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:26,947]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:27,088]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:27,271]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:34,500]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:35,311]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:39,613]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:40,101]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:44,919]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:46,727]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:51,916]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:53,512]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:53,863]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:18:59,000]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:19:00,637]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:19:04,910]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:19:05,118]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:19:12,500]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:19:12,539]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:19:18,444]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:19:18,662]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:19:24,688]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:19:27,154]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:19:30,685]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:19:32,189]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:19:36,272]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:19:37,284]\u001b[0m Trial 170 finished with value: 5.369378782082315 and parameters: {'n_hidden': 3, 'learning_rate': 0.001471797983356234, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12894349153393625, 'dropout_rate_Layer_2': 0.013928073285317588, 'dropout_rate_Layer_3': 0.09929133799278833, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0033067699522787044, 'l1_Layer_2': 0.011874533413810968, 'l1_Layer_3': 0.008246205995520258, 'n_units_Layer_1': 210, 'n_units_Layer_2': 125, 'n_units_Layer_3': 295}. Best is trial 145 with value: 5.3344296247560665.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 16.19% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.37 | sMAPE for Test Set is: 47.25% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:19:43,027]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:19:50,339]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:19:54,550]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:19:55,225]\u001b[0m Trial 197 finished with value: 5.998420775944517 and parameters: {'n_hidden': 4, 'learning_rate': 0.007224943633009201, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3581028212015438, 'dropout_rate_Layer_2': 0.10714388090647722, 'dropout_rate_Layer_3': 0.16442891971764018, 'dropout_rate_Layer_4': 0.07424535104933419, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00022658396692116475, 'l1_Layer_2': 0.0030108680091067573, 'l1_Layer_3': 0.009284564047000222, 'l1_Layer_4': 0.0006882614251824789, 'n_units_Layer_1': 135, 'n_units_Layer_2': 150, 'n_units_Layer_3': 140, 'n_units_Layer_4': 260}. Best is trial 145 with value: 5.3344296247560665.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 17.61% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 12.20 | sMAPE for Test Set is: 49.53% | rMAE for Test Set is: 0.92\n",
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 15.99% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.66 | sMAPE for Test Set is: 41.40% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:20:00,897]\u001b[0m Trial 185 finished with value: 5.189271086392512 and parameters: {'n_hidden': 3, 'learning_rate': 0.001430557809641866, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13933131351652508, 'dropout_rate_Layer_2': 0.27186565940408175, 'dropout_rate_Layer_3': 0.22756712777733923, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009643535420086616, 'l1_Layer_2': 0.012600097630652923, 'l1_Layer_3': 0.0004516229458942939, 'n_units_Layer_1': 295, 'n_units_Layer_2': 130, 'n_units_Layer_3': 160}. Best is trial 185 with value: 5.189271086392512.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:02,396]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:05,947]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:09,775]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:10,365]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:10,587]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:17,036]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:17,077]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:17,585]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:23,735]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:27,602]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:27,815]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:28,103]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:34,679]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:35,025]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:35,665]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:39,892]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:40,965]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:44,584]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:45,330]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:48,279]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:52,607]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:54,932]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:55,643]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:20:56,074]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:02,634]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:04,075]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:08,041]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:08,353]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:10,646]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:19,838]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:20,558]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:25,652]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:25,807]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:26,915]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:28,647]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:33,117]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:33,206]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:36,972]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:42,461]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:42,611]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:43,360]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:49,566]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:49,607]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:49,950]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:56,217]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:21:56,715]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:02,282]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:02,445]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:03,140]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:10,690]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:13,001]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:14,483]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:15,380]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:20,317]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:22,201]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:24,018]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:24,877]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:25,715]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:32,169]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:37,048]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:37,563]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:44,607]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:44,838]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:53,655]\u001b[0m Trial 239 finished with value: 5.44322198991225 and parameters: {'n_hidden': 3, 'learning_rate': 0.001724403298947956, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1331444259900867, 'dropout_rate_Layer_2': 0.08788816031912322, 'dropout_rate_Layer_3': 0.04162828503908356, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003369189943910058, 'l1_Layer_2': 0.010095764487368826, 'l1_Layer_3': 0.009352715635416398, 'n_units_Layer_1': 210, 'n_units_Layer_2': 115, 'n_units_Layer_3': 165}. Best is trial 185 with value: 5.189271086392512.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 16.36% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.62 | sMAPE for Test Set is: 48.03% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:22:56,316]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:22:58,109]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:00,158]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:03,526]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:03,840]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:08,764]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:15,738]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:18,690]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:21,724]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:23,929]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:26,026]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:28,330]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:31,392]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:33,194]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:37,288]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:39,302]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:41,431]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:45,509]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:45,735]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:45,897]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:53,534]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:54,307]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:23:59,642]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:24:02,257]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:24:02,726]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:24:05,039]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:24:05,354]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:24:08,732]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:24:17,817]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:24:18,513]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:24:26,393]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:24:27,410]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:24:37,063]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:24:41,387]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:24:45,137]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:24:51,836]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:24:53,776]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:24:54,375]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 17.69% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 12.47 | sMAPE for Test Set is: 50.26% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:24:56,169]\u001b[0m Trial 303 finished with value: 6.002852537183567 and parameters: {'n_hidden': 4, 'learning_rate': 0.008982400814621197, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37702893113695385, 'dropout_rate_Layer_2': 0.1110335499220873, 'dropout_rate_Layer_3': 0.17718870514171559, 'dropout_rate_Layer_4': 0.06930030909011015, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0003678449398787582, 'l1_Layer_2': 0.0007112264063039236, 'l1_Layer_3': 0.006321206481927854, 'l1_Layer_4': 0.0007063340979986521, 'n_units_Layer_1': 115, 'n_units_Layer_2': 130, 'n_units_Layer_3': 140, 'n_units_Layer_4': 300}. Best is trial 185 with value: 5.189271086392512.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:25:05,175]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:25:08,231]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:25:10,393]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:25:15,697]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:25:31,198]\u001b[0m Trial 311 finished with value: 5.862556844325927 and parameters: {'n_hidden': 3, 'learning_rate': 0.005427925249533478, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0660987221861005, 'dropout_rate_Layer_2': 0.06689753920422029, 'dropout_rate_Layer_3': 0.022897783004125438, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.029845803479871653, 'l1_Layer_2': 0.000814926093300359, 'l1_Layer_3': 0.0051235865695141635, 'n_units_Layer_1': 235, 'n_units_Layer_2': 260, 'n_units_Layer_3': 220}. Best is trial 185 with value: 5.189271086392512.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 17.22% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 12.82 | sMAPE for Test Set is: 51.03% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:25:37,497]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:25:49,526]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:25:54,430]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:25:55,465]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:25:56,769]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:26:07,734]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:26:13,570]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:26:16,465]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:26:20,103]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:26:20,350]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:26:28,739]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:26:32,710]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:26:34,817]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:26:51,310]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:26:51,511]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:27:12,537]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:27:19,863]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:27:23,154]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:27:33,224]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:27:46,231]\u001b[0m Trial 316 finished with value: 5.653498720493952 and parameters: {'n_hidden': 3, 'learning_rate': 0.025556254739836543, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28109636456583403, 'dropout_rate_Layer_2': 0.3981980802850614, 'dropout_rate_Layer_3': 0.0002385248786357997, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.5924021696901174e-05, 'l1_Layer_2': 0.0016277016518087455, 'l1_Layer_3': 0.055193064625133924, 'n_units_Layer_1': 225, 'n_units_Layer_2': 75, 'n_units_Layer_3': 80}. Best is trial 185 with value: 5.189271086392512.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 10.95 | sMAPE for Test Set is: 46.27% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:27:56,785]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:29:06,758]\u001b[0m Trial 329 finished with value: 5.796774508149486 and parameters: {'n_hidden': 3, 'learning_rate': 0.019425471570273828, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2734429044062273, 'dropout_rate_Layer_2': 0.39979927798391307, 'dropout_rate_Layer_3': 0.039727196386416336, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.1051811520345831e-05, 'l1_Layer_2': 0.000916328971273874, 'l1_Layer_3': 0.036742099783983934, 'n_units_Layer_1': 225, 'n_units_Layer_2': 85, 'n_units_Layer_3': 50}. Best is trial 185 with value: 5.189271086392512.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 17.04% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 12.07 | sMAPE for Test Set is: 49.57% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:29:13,108]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:29:15,309]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:29:32,498]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:29:49,694]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:29:52,915]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:29:56,509]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:29:58,625]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:30:09,815]\u001b[0m Trial 333 finished with value: 5.491988061617651 and parameters: {'n_hidden': 3, 'learning_rate': 0.018544768953623107, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27689198577833246, 'dropout_rate_Layer_2': 0.3981782353111905, 'dropout_rate_Layer_3': 0.025761421718338604, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.1756434695399732e-05, 'l1_Layer_2': 0.0013207516060296093, 'l1_Layer_3': 0.03731589098630542, 'n_units_Layer_1': 220, 'n_units_Layer_2': 70, 'n_units_Layer_3': 55}. Best is trial 185 with value: 5.189271086392512.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 16.52% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.68 | sMAPE for Test Set is: 44.69% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:30:12,008]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:30:15,271]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:30:17,052]\u001b[0m Trial 339 finished with value: 5.9040703517320665 and parameters: {'n_hidden': 4, 'learning_rate': 0.004012234856387479, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38101426856680903, 'dropout_rate_Layer_2': 0.1579252347507481, 'dropout_rate_Layer_3': 0.19837137608949176, 'dropout_rate_Layer_4': 0.18310501936859436, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00043146345436191136, 'l1_Layer_2': 0.000751998719172062, 'l1_Layer_3': 0.0042297657367889735, 'l1_Layer_4': 0.0002916411406106196, 'n_units_Layer_1': 90, 'n_units_Layer_2': 130, 'n_units_Layer_3': 75, 'n_units_Layer_4': 300}. Best is trial 185 with value: 5.189271086392512.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 17.58% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 11.67 | sMAPE for Test Set is: 48.21% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:30:28,923]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:30:31,308]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:30:34,071]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:30:37,261]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:30:40,368]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:30:46,095]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:30:54,893]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:31:01,855]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:31:04,682]\u001b[0m Trial 345 finished with value: 5.098256594209587 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007552685273432264, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09242864776103313, 'dropout_rate_Layer_2': 0.025978042227927024, 'dropout_rate_Layer_3': 0.07411700425913727, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00048204336567322307, 'l1_Layer_2': 4.850953982582209e-05, 'l1_Layer_3': 0.0007804932982109493, 'n_units_Layer_1': 215, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 15.57% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.52 | sMAPE for Test Set is: 40.86% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:31:09,035]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:31:13,247]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:31:15,112]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:31:18,648]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:31:21,373]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:31:21,501]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:31:32,040]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:31:39,671]\u001b[0m Trial 346 finished with value: 5.722871432233345 and parameters: {'n_hidden': 3, 'learning_rate': 0.018139128806153582, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2554557294957015, 'dropout_rate_Layer_2': 0.39060430621965797, 'dropout_rate_Layer_3': 0.02496019014916645, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.9853400930636622e-05, 'l1_Layer_2': 0.0021204337940704996, 'l1_Layer_3': 0.029875637581095283, 'n_units_Layer_1': 220, 'n_units_Layer_2': 70, 'n_units_Layer_3': 55}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.28 | sMAPE for Test Set is: 47.14% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:31:41,759]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:31:41,813]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:31:48,448]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:31:50,769]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:31:50,809]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:31:58,440]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:32:02,138]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:32:13,521]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:32:16,170]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:32:19,909]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:32:20,411]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:32:30,019]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:32:33,679]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:32:36,256]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:32:38,454]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:32:44,730]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:32:50,010]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:32:53,254]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:32:53,356]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:32:59,524]\u001b[0m Trial 366 finished with value: 5.630666313659767 and parameters: {'n_hidden': 3, 'learning_rate': 0.019817020316736517, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2631879474235055, 'dropout_rate_Layer_2': 0.38067428995098185, 'dropout_rate_Layer_3': 6.0332649469136665e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.5515529082122724e-05, 'l1_Layer_2': 0.0011126059467124838, 'l1_Layer_3': 0.05868302438800685, 'n_units_Layer_1': 210, 'n_units_Layer_2': 80, 'n_units_Layer_3': 55}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 16.84% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.06 | sMAPE for Test Set is: 46.46% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:33:03,847]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:33:10,662]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:33:33,683]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:33:38,831]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:33:39,004]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:33:42,102]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:33:48,835]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:33:49,187]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:33:56,955]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:34:00,561]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:34:13,101]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:34:50,062]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:35:00,371]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:35:09,068]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:35:09,791]\u001b[0m Trial 393 finished with value: 5.805908170305817 and parameters: {'n_hidden': 4, 'learning_rate': 0.003471048140453094, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3376285448372161, 'dropout_rate_Layer_2': 0.11416710404698059, 'dropout_rate_Layer_3': 0.22856164527630568, 'dropout_rate_Layer_4': 0.025209498655189122, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0003984813731359421, 'l1_Layer_2': 0.0021777806803004447, 'l1_Layer_3': 0.0016465072589289184, 'l1_Layer_4': 0.0009562230370978129, 'n_units_Layer_1': 175, 'n_units_Layer_2': 195, 'n_units_Layer_3': 95, 'n_units_Layer_4': 270}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 17.22% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 12.53 | sMAPE for Test Set is: 50.42% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:35:15,372]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:35:22,580]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 17.14% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 12.23 | sMAPE for Test Set is: 49.64% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:35:24,050]\u001b[0m Trial 392 finished with value: 5.804506126648886 and parameters: {'n_hidden': 4, 'learning_rate': 0.003736064300397827, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3350758178457144, 'dropout_rate_Layer_2': 0.11972121982959802, 'dropout_rate_Layer_3': 0.36142489996714905, 'dropout_rate_Layer_4': 0.023484935582214678, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0004243946850544875, 'l1_Layer_2': 0.002249168500584366, 'l1_Layer_3': 0.001211741003928245, 'l1_Layer_4': 0.0008253908044940995, 'n_units_Layer_1': 115, 'n_units_Layer_2': 190, 'n_units_Layer_3': 65, 'n_units_Layer_4': 270}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:35:31,799]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:35:33,824]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:35:39,920]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:35:45,302]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:35:48,918]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:36:18,348]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:36:27,088]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:36:27,654]\u001b[0m Trial 396 finished with value: 5.743203344229658 and parameters: {'n_hidden': 3, 'learning_rate': 0.01511509936875922, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2720636025004346, 'dropout_rate_Layer_2': 0.3805118845532272, 'dropout_rate_Layer_3': 0.07350941138493156, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.5330610205243956e-05, 'l1_Layer_2': 0.0008712712764958485, 'l1_Layer_3': 0.03003814242674012, 'n_units_Layer_1': 210, 'n_units_Layer_2': 60, 'n_units_Layer_3': 55}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 17.02% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.93 | sMAPE for Test Set is: 49.02% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:36:36,777]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:36:45,235]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:36:49,739]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:36:53,444]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:37:02,312]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:37:10,818]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:37:13,006]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:37:20,295]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:37:30,778]\u001b[0m Trial 405 finished with value: 5.880846464860373 and parameters: {'n_hidden': 3, 'learning_rate': 0.0243968166259878, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2630304084239408, 'dropout_rate_Layer_2': 0.23515524820565453, 'dropout_rate_Layer_3': 0.046682293988712875, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 1.4849666598318546e-05, 'l1_Layer_2': 0.001281231680568975, 'l1_Layer_3': 0.07162567647931946, 'n_units_Layer_1': 200, 'n_units_Layer_2': 75, 'n_units_Layer_3': 75}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 17.41% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 12.11 | sMAPE for Test Set is: 49.36% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:37:34,906]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:37:40,362]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:37:50,247]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:37:58,819]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:38:01,277]\u001b[0m Trial 407 finished with value: 6.041611509944697 and parameters: {'n_hidden': 3, 'learning_rate': 0.020682239963734004, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2373181583665694, 'dropout_rate_Layer_2': 0.38968354415817846, 'dropout_rate_Layer_3': 0.006916294723451363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.4902085474991413e-05, 'l1_Layer_2': 0.0012845398155175733, 'l1_Layer_3': 0.07020260855142499, 'n_units_Layer_1': 225, 'n_units_Layer_2': 75, 'n_units_Layer_3': 50}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 17.90% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 12.68 | sMAPE for Test Set is: 50.83% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:38:07,956]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:38:14,260]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:38:20,049]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:38:25,332]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:38:27,458]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:38:30,071]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:38:33,247]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:38:35,630]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:38:38,007]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:38:43,839]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:38:48,900]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:38:52,644]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:38:58,357]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:39:01,857]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:39:05,396]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:39:09,728]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:39:11,801]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:39:16,239]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:39:19,780]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:39:23,631]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:39:23,754]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:39:28,586]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:39:28,769]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:39:36,820]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:39:40,963]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:39:43,720]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:39:43,877]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:39:53,696]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:39:58,819]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:40:03,180]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:40:05,591]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:40:10,963]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:40:34,394]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:40:46,272]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:40:46,892]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:40:56,667]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:41:01,613]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:41:03,930]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:41:05,316]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:41:11,053]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:41:15,976]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:41:17,952]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:41:22,620]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:41:39,441]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:41:40,182]\u001b[0m Trial 453 finished with value: 5.530844079671181 and parameters: {'n_hidden': 3, 'learning_rate': 0.01993784075932683, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3020331837749618, 'dropout_rate_Layer_2': 0.22343121504733024, 'dropout_rate_Layer_3': 0.04171891930077924, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.0005967638355225e-05, 'l1_Layer_2': 0.0011433519776367861, 'l1_Layer_3': 0.026141167616561062, 'n_units_Layer_1': 230, 'n_units_Layer_2': 70, 'n_units_Layer_3': 80}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 16.62% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.57 | sMAPE for Test Set is: 44.90% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:41:46,477]\u001b[0m Trial 461 finished with value: 5.839622120457655 and parameters: {'n_hidden': 3, 'learning_rate': 0.021959567436262237, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2553759812824996, 'dropout_rate_Layer_2': 0.39939807880842276, 'dropout_rate_Layer_3': 0.01879480895636943, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.5822543441365596e-05, 'l1_Layer_2': 0.002796378208257241, 'l1_Layer_3': 0.02019042296729499, 'n_units_Layer_1': 230, 'n_units_Layer_2': 80, 'n_units_Layer_3': 50}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 17.43% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 11.80 | sMAPE for Test Set is: 48.53% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:41:51,002]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:41:51,512]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:41:57,670]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:41:58,235]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:08,360]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:11,493]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:14,830]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 17.89% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 11.02 | sMAPE for Test Set is: 46.42% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:42:16,582]\u001b[0m Trial 465 finished with value: 6.0062795597658925 and parameters: {'n_hidden': 3, 'learning_rate': 0.02063228656532979, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23830218439354336, 'dropout_rate_Layer_2': 0.22385114244148566, 'dropout_rate_Layer_3': 0.047840964234235395, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.416262145040637e-05, 'l1_Layer_2': 0.001120976037246413, 'l1_Layer_3': 0.030483674437683184, 'n_units_Layer_1': 220, 'n_units_Layer_2': 65, 'n_units_Layer_3': 55}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:17,724]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:21,839]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:23,332]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:24,740]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:28,960]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:29,362]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:35,980]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:36,446]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:40,120]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:44,684]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:47,659]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:47,739]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:52,846]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:54,630]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:57,492]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:42:57,897]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:02,386]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:04,701]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:05,440]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:09,356]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:13,188]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:13,655]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:16,371]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:19,851]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:20,214]\u001b[0m Trial 489 finished with value: 5.813966632990419 and parameters: {'n_hidden': 4, 'learning_rate': 0.008885123357429671, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37148738181543534, 'dropout_rate_Layer_2': 0.14774209480894918, 'dropout_rate_Layer_3': 0.1439667225144953, 'dropout_rate_Layer_4': 0.16485892366007807, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0003593096775032515, 'l1_Layer_2': 0.0006334916701994157, 'l1_Layer_3': 0.0038716578136909364, 'l1_Layer_4': 0.0004106322765763765, 'n_units_Layer_1': 70, 'n_units_Layer_2': 220, 'n_units_Layer_3': 150, 'n_units_Layer_4': 280}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 17.28% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 12.18 | sMAPE for Test Set is: 49.43% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:43:20,648]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:26,954]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:27,416]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:27,652]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:35,216]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:37,268]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:37,527]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:40,390]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:45,222]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:45,369]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:45,866]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:47,803]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:55,906]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:43:56,064]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:44:06,916]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:44:07,024]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:44:12,360]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:44:12,940]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:44:15,765]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:44:21,929]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:44:24,204]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:44:28,533]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:44:31,817]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:44:35,125]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:45:13,128]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:45:15,437]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:45:19,315]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:45:19,824]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:45:25,870]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:45:29,494]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:45:33,513]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:45:38,463]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:45:48,955]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:45:51,551]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:45:53,838]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:46:00,284]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:46:06,792]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:46:10,889]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:46:13,715]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:46:15,603]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:46:17,784]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:46:21,634]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:46:25,028]\u001b[0m Trial 531 finished with value: 5.836250347398512 and parameters: {'n_hidden': 4, 'learning_rate': 0.018463143005705396, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3982094658388737, 'dropout_rate_Layer_2': 0.1809243283424675, 'dropout_rate_Layer_3': 0.06672301626622346, 'dropout_rate_Layer_4': 0.1441387686772, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 3.011038639355876e-05, 'l1_Layer_2': 0.0005161275872045624, 'l1_Layer_3': 0.009614617025052844, 'l1_Layer_4': 0.028000118836733548, 'n_units_Layer_1': 80, 'n_units_Layer_2': 215, 'n_units_Layer_3': 185, 'n_units_Layer_4': 275}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 17.18% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 13.18 | sMAPE for Test Set is: 52.15% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:46:33,455]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:46:33,821]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:46:39,910]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:46:43,551]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:46:46,065]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:46:50,967]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:46:51,887]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:46:59,304]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:47:06,402]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:47:11,342]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:47:19,946]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:47:20,090]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:47:29,084]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:47:37,525]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:47:46,245]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:48:02,576]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:48:04,816]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:48:09,099]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:48:09,493]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:48:11,823]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:48:17,564]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:48:20,885]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:48:23,971]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:48:26,466]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:48:32,897]\u001b[0m Trial 555 finished with value: 5.753451379282293 and parameters: {'n_hidden': 3, 'learning_rate': 0.0211767637418281, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24945369903102857, 'dropout_rate_Layer_2': 0.379041863956584, 'dropout_rate_Layer_3': 0.042320136663281126, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.2749697288496524e-05, 'l1_Layer_2': 0.0008584516069356511, 'l1_Layer_3': 0.04403387541102768, 'n_units_Layer_1': 230, 'n_units_Layer_2': 50, 'n_units_Layer_3': 55}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 17.14% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.38 | sMAPE for Test Set is: 47.37% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:48:33,111]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:48:42,299]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:48:45,883]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:48:50,218]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:48:56,229]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:49:00,085]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:49:00,608]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:49:06,508]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:49:07,112]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:49:15,642]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:49:17,352]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:49:22,757]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:49:28,222]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:49:32,545]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:49:41,393]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:49:46,982]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:49:49,115]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:49:55,321]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:50:01,714]\u001b[0m Trial 564 finished with value: 5.6133323248094245 and parameters: {'n_hidden': 4, 'learning_rate': 0.003685356861117264, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38898108544771204, 'dropout_rate_Layer_2': 0.12710184736120003, 'dropout_rate_Layer_3': 0.039393478047949654, 'dropout_rate_Layer_4': 0.1783872786153445, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.001624586558597224, 'l1_Layer_2': 1.634955809716307e-05, 'l1_Layer_3': 0.00384419030243578, 'l1_Layer_4': 0.002656687123944985, 'n_units_Layer_1': 80, 'n_units_Layer_2': 265, 'n_units_Layer_3': 210, 'n_units_Layer_4': 290}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 16.60% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 12.80 | sMAPE for Test Set is: 51.34% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:50:12,516]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:50:35,645]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:50:39,672]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:50:59,132]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:51:06,429]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:51:18,955]\u001b[0m Trial 586 finished with value: 5.643354869998812 and parameters: {'n_hidden': 3, 'learning_rate': 0.018554232072002342, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09553705792801097, 'dropout_rate_Layer_2': 0.35697829435172657, 'dropout_rate_Layer_3': 0.04674762873320915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.0082972580839877e-05, 'l1_Layer_2': 0.0014037731929308188, 'l1_Layer_3': 0.037767331145904845, 'n_units_Layer_1': 195, 'n_units_Layer_2': 75, 'n_units_Layer_3': 50}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 16.91% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.07 | sMAPE for Test Set is: 46.25% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:51:21,562]\u001b[0m Trial 581 finished with value: 5.4954208218984775 and parameters: {'n_hidden': 3, 'learning_rate': 0.01681736954278402, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0995146139759551, 'dropout_rate_Layer_2': 0.3618894092635101, 'dropout_rate_Layer_3': 0.031245587309957773, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.4687056089746873e-05, 'l1_Layer_2': 0.0011344445705294426, 'l1_Layer_3': 0.03969203388020652, 'n_units_Layer_1': 205, 'n_units_Layer_2': 60, 'n_units_Layer_3': 70}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 16.51% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.05 | sMAPE for Test Set is: 45.89% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:51:21,997]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:51:27,387]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:51:32,064]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:51:34,736]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:51:36,453]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:51:42,202]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:51:44,331]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:51:50,336]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:51:50,616]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:51:58,012]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:51:59,146]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:52:04,546]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:52:10,279]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:52:12,716]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:52:15,882]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:52:20,793]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:52:25,421]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:52:33,569]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:52:38,303]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:52:38,957]\u001b[0m Trial 589 finished with value: 5.461613765686362 and parameters: {'n_hidden': 3, 'learning_rate': 0.014474478682888137, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29075614697875357, 'dropout_rate_Layer_2': 0.3723958911955843, 'dropout_rate_Layer_3': 0.0453791940322622, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.7368660529412803e-05, 'l1_Layer_2': 0.0014203620535744, 'l1_Layer_3': 0.005096433539915989, 'n_units_Layer_1': 215, 'n_units_Layer_2': 75, 'n_units_Layer_3': 50}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 16.49% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.18 | sMAPE for Test Set is: 46.22% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:52:46,611]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:52:49,849]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:52:52,770]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:52:54,762]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:53:01,560]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:53:07,443]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:53:12,523]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:53:31,473]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:53:34,356]\u001b[0m Trial 615 finished with value: 5.735861544138449 and parameters: {'n_hidden': 3, 'learning_rate': 0.016337879485929827, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2906185614828225, 'dropout_rate_Layer_2': 0.35751411530600286, 'dropout_rate_Layer_3': 0.04918135785821427, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.1917174544775515e-05, 'l1_Layer_2': 0.001789671148226231, 'l1_Layer_3': 0.009427963076101735, 'n_units_Layer_1': 205, 'n_units_Layer_2': 75, 'n_units_Layer_3': 60}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 16.95% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 12.79 | sMAPE for Test Set is: 51.18% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:53:39,951]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:53:42,659]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:53:45,251]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:53:47,338]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:53:49,456]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:53:52,154]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:53:56,446]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:54:01,012]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:54:06,240]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:54:15,315]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:54:15,948]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:54:20,832]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:54:25,087]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:54:27,808]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:54:32,315]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:54:36,681]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:54:38,735]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:54:43,792]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:54:49,044]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:55:05,662]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:55:17,021]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:55:21,004]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:55:23,900]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:55:35,868]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:55:39,652]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:55:44,412]\u001b[0m Trial 647 finished with value: 5.905656912757475 and parameters: {'n_hidden': 4, 'learning_rate': 0.008115334981814904, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3998996478506462, 'dropout_rate_Layer_2': 0.07849994312876651, 'dropout_rate_Layer_3': 0.38769062243658936, 'dropout_rate_Layer_4': 0.39790552328790785, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0006656310893997529, 'l1_Layer_2': 0.002102666590958694, 'l1_Layer_3': 0.008073766580903433, 'l1_Layer_4': 0.017338588421157673, 'n_units_Layer_1': 75, 'n_units_Layer_2': 200, 'n_units_Layer_3': 280, 'n_units_Layer_4': 205}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 17.49% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 12.15 | sMAPE for Test Set is: 49.38% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:55:46,087]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:55:48,927]\u001b[0m Trial 619 finished with value: 5.648660843572138 and parameters: {'n_hidden': 4, 'learning_rate': 0.005209646367566699, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3091706181056103, 'dropout_rate_Layer_2': 0.17366739581533003, 'dropout_rate_Layer_3': 0.12129597793495747, 'dropout_rate_Layer_4': 0.13144089571414302, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0003105124136812791, 'l1_Layer_2': 0.00023090467588262893, 'l1_Layer_3': 0.009558056243088963, 'l1_Layer_4': 0.013364329809780987, 'n_units_Layer_1': 85, 'n_units_Layer_2': 185, 'n_units_Layer_3': 280, 'n_units_Layer_4': 260}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 16.70% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 13.02 | sMAPE for Test Set is: 51.78% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:55:54,504]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:56:01,086]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:56:04,182]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:56:10,104]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:56:12,197]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:56:15,816]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:56:18,680]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:56:22,706]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:56:26,367]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:56:27,129]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:56:35,234]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:56:40,588]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:56:48,140]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:56:50,817]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:56:52,421]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:56:55,467]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 16.69% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.91 | sMAPE for Test Set is: 45.98% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:56:56,588]\u001b[0m Trial 664 finished with value: 5.536673325639865 and parameters: {'n_hidden': 3, 'learning_rate': 0.004156063269327899, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.051899927704381336, 'dropout_rate_Layer_2': 0.12110775118434591, 'dropout_rate_Layer_3': 0.055714558720808674, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020129867689636446, 'l1_Layer_2': 0.0007267165022176499, 'l1_Layer_3': 4.370132772487601e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 155, 'n_units_Layer_3': 285}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:56:57,098]\u001b[0m Trial 645 finished with value: 5.624362189339082 and parameters: {'n_hidden': 3, 'learning_rate': 0.010286794365358131, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2439476712874408, 'dropout_rate_Layer_2': 0.36108232290380904, 'dropout_rate_Layer_3': 0.06246409655722163, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.80295666987772e-05, 'l1_Layer_2': 0.0014406920391491266, 'l1_Layer_3': 0.002698974186678642, 'n_units_Layer_1': 210, 'n_units_Layer_2': 80, 'n_units_Layer_3': 55}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 16.94% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.74 | sMAPE for Test Set is: 45.09% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:56:59,442]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:57:01,911]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:57:04,184]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:57:11,320]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:57:11,431]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:57:16,598]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:57:17,019]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:57:21,611]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:57:23,784]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:57:25,917]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:57:26,843]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:57:34,414]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:57:38,571]\u001b[0m Trial 680 finished with value: 5.76278890542256 and parameters: {'n_hidden': 3, 'learning_rate': 0.01137617283636816, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022748641277834554, 'dropout_rate_Layer_2': 0.0009621352094027272, 'dropout_rate_Layer_3': 0.16325388172184424, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011382569407065365, 'l1_Layer_2': 0.0012511172506898503, 'l1_Layer_3': 0.00011886054398368414, 'n_units_Layer_1': 240, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 17.28% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.33 | sMAPE for Test Set is: 44.25% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 00:57:39,085]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:57:39,780]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:57:48,303]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:57:51,915]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:57:52,297]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:57:59,445]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:58:03,302]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:58:06,786]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:58:10,585]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:58:12,967]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:58:19,680]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:58:19,949]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:58:20,247]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:58:29,312]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:58:33,189]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:58:34,693]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:58:39,371]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:58:45,857]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:58:49,334]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:58:52,112]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:58:56,921]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:58:57,316]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:58:57,910]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:59:03,914]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:59:08,693]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:59:08,827]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:59:17,398]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:59:23,409]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:59:27,736]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:59:28,301]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:59:43,047]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:59:51,865]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 00:59:57,597]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:00:25,655]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:00:31,454]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:00:38,126]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:00:42,049]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:00:51,137]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:00:55,260]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:01:00,939]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:01:04,396]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:01:06,625]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:01:07,788]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:01:12,302]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:01:15,365]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:01:21,249]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:01:21,679]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:01:30,193]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:01:33,167]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:01:42,434]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:01:44,121]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:01:46,458]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:01:48,191]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:01:51,553]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:01:53,900]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:01:59,592]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:02:12,090]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:02:18,121]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:02:21,680]\u001b[0m Trial 738 finished with value: 5.851840604963248 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011059169482963399, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2419395793140555, 'dropout_rate_Layer_2': 0.3712308858121051, 'dropout_rate_Layer_3': 0.3928137756864006, 'dropout_rate_Layer_4': 0.3216187414618086, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.04841191957540327, 'l1_Layer_2': 5.2501953048681184e-05, 'l1_Layer_3': 0.0022586015854474477, 'l1_Layer_4': 1.2095298622601546e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 280, 'n_units_Layer_3': 170, 'n_units_Layer_4': 240}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 17.39% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 12.11 | sMAPE for Test Set is: 49.36% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:02:21,948]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:02:28,073]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:02:31,292]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:02:31,417]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:02:34,777]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:02:38,674]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:02:40,710]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:02:40,803]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:02:44,528]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:02:48,670]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:02:54,324]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:02:54,599]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:02:58,516]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:03:02,925]\u001b[0m Trial 693 finished with value: 5.798929443883274 and parameters: {'n_hidden': 4, 'learning_rate': 0.004919477773063955, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38416458860072866, 'dropout_rate_Layer_2': 0.09149091076387016, 'dropout_rate_Layer_3': 0.3631717501989811, 'dropout_rate_Layer_4': 0.34701132437461135, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0006683177598155496, 'l1_Layer_2': 0.00014325310711630956, 'l1_Layer_3': 0.018648748879849485, 'l1_Layer_4': 0.05762371304232544, 'n_units_Layer_1': 85, 'n_units_Layer_2': 200, 'n_units_Layer_3': 285, 'n_units_Layer_4': 95}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 17.15% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 12.81 | sMAPE for Test Set is: 51.10% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:03:05,031]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:03:05,600]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:03:11,659]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:03:15,855]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:03:19,114]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:03:19,927]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:03:26,560]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:03:29,499]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:03:32,680]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:03:39,048]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:03:45,306]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:03:46,186]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:03:51,816]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:04:00,186]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:04:00,919]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:04:08,794]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:04:12,951]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:04:15,678]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:04:20,014]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:04:25,106]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:04:25,629]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:04:31,029]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:04:31,836]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:04:48,969]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:05:22,749]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:05:30,304]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:05:36,090]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:05:40,212]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:05:49,080]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:05:49,960]\u001b[0m Trial 775 finished with value: 5.378701304199254 and parameters: {'n_hidden': 3, 'learning_rate': 0.004399847217134552, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1271173767232915, 'dropout_rate_Layer_2': 0.0463750218343454, 'dropout_rate_Layer_3': 0.037361014813238974, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0054715440223187415, 'l1_Layer_2': 0.009750655800447997, 'l1_Layer_3': 0.007505968471195766, 'n_units_Layer_1': 280, 'n_units_Layer_2': 230, 'n_units_Layer_3': 200}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 16.18% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.92 | sMAPE for Test Set is: 45.68% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:05:56,471]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:05:58,585]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:05:58,796]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:06:01,568]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:06:06,920]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:06:08,451]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:06:09,711]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:06:11,899]\u001b[0m Trial 780 finished with value: 6.0713891524043175 and parameters: {'n_hidden': 3, 'learning_rate': 0.02857993390516484, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2143295109171997, 'dropout_rate_Layer_2': 0.3237274994456659, 'dropout_rate_Layer_3': 0.15303564550979631, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.3728507656618596e-05, 'l1_Layer_2': 0.0012303210814574627, 'l1_Layer_3': 0.025865024694535894, 'n_units_Layer_1': 220, 'n_units_Layer_2': 65, 'n_units_Layer_3': 60}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 18.14% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 11.37 | sMAPE for Test Set is: 47.28% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:06:22,758]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:06:23,366]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:06:28,092]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:06:29,671]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:06:30,395]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:06:45,642]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:06:45,980]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:06:46,518]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:06:54,968]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:00,757]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:01,297]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:05,309]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:05,383]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:06,512]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:06,887]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:16,413]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:16,930]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:23,450]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:26,558]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:28,879]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:35,647]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:36,308]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:41,336]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:43,879]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:44,945]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:48,822]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:49,819]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:53,815]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:07:58,939]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:08:02,137]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:08:06,111]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:08:13,210]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:08:19,027]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:08:25,198]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:08:33,537]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:08:35,851]\u001b[0m Trial 826 finished with value: 5.735917796520326 and parameters: {'n_hidden': 4, 'learning_rate': 0.001134454039761479, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.250993073240416, 'dropout_rate_Layer_2': 0.37693384385072265, 'dropout_rate_Layer_3': 0.03356873550556727, 'dropout_rate_Layer_4': 0.32531627293387044, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03084374021220545, 'l1_Layer_2': 2.31649755632884e-05, 'l1_Layer_3': 1.6995619895109032e-05, 'l1_Layer_4': 1.2097302284463915e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 280, 'n_units_Layer_3': 175, 'n_units_Layer_4': 255}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 17.20% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.18 | sMAPE for Test Set is: 46.82% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:08:41,030]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:08:41,244]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:08:56,436]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:09:00,479]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:09:04,272]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:09:07,093]\u001b[0m Trial 813 finished with value: 5.556457425442488 and parameters: {'n_hidden': 3, 'learning_rate': 0.014067889382652764, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22144401710576395, 'dropout_rate_Layer_2': 0.39155659932431713, 'dropout_rate_Layer_3': 0.04761470906725802, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.3333984519146191e-05, 'l1_Layer_2': 0.0013771316966572245, 'l1_Layer_3': 0.03687698106251061, 'n_units_Layer_1': 200, 'n_units_Layer_2': 70, 'n_units_Layer_3': 50}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 16.61% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 12.04 | sMAPE for Test Set is: 49.25% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:09:09,901]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:09:15,215]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:09:17,493]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:09:20,058]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:09:24,708]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:09:25,267]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:09:28,633]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:09:31,592]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:09:34,047]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:09:43,735]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:09:47,226]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:09:47,346]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:09:54,835]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:09:57,833]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:10:02,017]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:10:16,538]\u001b[0m Trial 847 finished with value: 5.698340004285176 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010365507079255153, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17668530963114207, 'dropout_rate_Layer_2': 0.3679027971344351, 'dropout_rate_Layer_3': 0.04324102618852345, 'dropout_rate_Layer_4': 0.3287441279407254, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03363934029024256, 'l1_Layer_2': 1.3936821741078883e-05, 'l1_Layer_3': 1.1349069443860126e-05, 'l1_Layer_4': 1.0037256850061291e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 285, 'n_units_Layer_3': 180, 'n_units_Layer_4': 245}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 17.10% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 10.91 | sMAPE for Test Set is: 46.11% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:10:18,366]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:10:43,047]\u001b[0m Trial 853 finished with value: 5.767852210936378 and parameters: {'n_hidden': 4, 'learning_rate': 0.000891669032773742, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24058301698174617, 'dropout_rate_Layer_2': 0.3673229851160997, 'dropout_rate_Layer_3': 0.04509944746543988, 'dropout_rate_Layer_4': 0.3428113174813662, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.023462647511817817, 'l1_Layer_2': 1.406439790782589e-05, 'l1_Layer_3': 1.587622645116296e-05, 'l1_Layer_4': 1.2557656846070272e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 170, 'n_units_Layer_3': 170, 'n_units_Layer_4': 265}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 17.24% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.76 | sMAPE for Test Set is: 45.62% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:10:45,192]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:10:52,171]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:11:02,040]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:11:10,578]\u001b[0m Trial 850 finished with value: 6.032343443456753 and parameters: {'n_hidden': 4, 'learning_rate': 0.008379238416311078, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3023892434485798, 'dropout_rate_Layer_2': 0.07485034721935689, 'dropout_rate_Layer_3': 0.11932177649919067, 'dropout_rate_Layer_4': 0.056932901199638945, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0020981460985391906, 'l1_Layer_2': 0.0011253130389600877, 'l1_Layer_3': 0.0047017064369376535, 'l1_Layer_4': 0.00043840922037283083, 'n_units_Layer_1': 85, 'n_units_Layer_2': 155, 'n_units_Layer_3': 170, 'n_units_Layer_4': 260}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.03 | sMAPE for Validation Set is: 17.62% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 12.64 | sMAPE for Test Set is: 50.62% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:11:15,458]\u001b[0m Trial 821 finished with value: 5.715081743634614 and parameters: {'n_hidden': 4, 'learning_rate': 0.0044175799154679484, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30411401998847376, 'dropout_rate_Layer_2': 0.08239449395603804, 'dropout_rate_Layer_3': 0.2983182925319104, 'dropout_rate_Layer_4': 0.24590964423927, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0005349704454141285, 'l1_Layer_2': 0.001107357948755116, 'l1_Layer_3': 0.006409398646669796, 'l1_Layer_4': 0.007496475538683593, 'n_units_Layer_1': 80, 'n_units_Layer_2': 220, 'n_units_Layer_3': 100, 'n_units_Layer_4': 85}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 17.10% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.65 | sMAPE for Test Set is: 48.15% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:11:15,640]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:11:22,310]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:11:25,102]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:11:25,619]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:11:27,903]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:11:36,670]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:11:38,985]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:11:40,020]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:11:44,761]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:11:49,641]\u001b[0m Trial 858 finished with value: 5.7260695404358195 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008817215723248673, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37893851177063415, 'dropout_rate_Layer_2': 0.3751998997009126, 'dropout_rate_Layer_3': 0.04277905625616014, 'dropout_rate_Layer_4': 0.33842716216464597, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01912842925442828, 'l1_Layer_2': 1.2560563653321503e-05, 'l1_Layer_3': 1.2231287305875773e-05, 'l1_Layer_4': 1.519757866970911e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 150, 'n_units_Layer_3': 170, 'n_units_Layer_4': 265}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 17.10% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.55 | sMAPE for Test Set is: 47.90% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:11:51,146]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:11:51,471]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:11:51,523]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:11:55,496]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:12:04,846]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:12:06,947]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:12:12,434]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:12:12,636]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:12:16,539]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:12:20,752]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:12:28,929]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:12:35,663]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:12:38,636]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:12:39,792]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:12:44,698]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:12:48,672]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:12:51,003]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:12:56,524]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:12:58,693]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:13:00,323]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:13:04,834]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:13:07,424]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:13:15,701]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:13:23,056]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:13:24,724]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:13:34,302]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:13:34,789]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:13:41,410]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:13:41,621]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:13:49,481]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:13:56,254]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:14:06,303]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:14:12,587]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:14:17,124]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:14:22,273]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:14:24,267]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:14:29,550]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:14:36,036]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:14:40,430]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:14:56,448]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:15:06,291]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:15:15,206]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:15:17,162]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:15:20,686]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:15:25,449]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:15:30,727]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:15:32,913]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:15:36,898]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:15:40,796]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:15:44,653]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:15:50,735]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:16:03,106]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:16:06,171]\u001b[0m Trial 916 finished with value: 5.701693403290193 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010399847603430965, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24064890411924095, 'dropout_rate_Layer_2': 0.252126923502774, 'dropout_rate_Layer_3': 0.04241489394964326, 'dropout_rate_Layer_4': 0.17259239262774628, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.031893020376153075, 'l1_Layer_2': 4.203539259185478e-05, 'l1_Layer_3': 2.7192624896485597e-05, 'l1_Layer_4': 1.1873049527415616e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 170, 'n_units_Layer_3': 165, 'n_units_Layer_4': 245}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.25 | sMAPE for Test Set is: 47.19% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:16:13,207]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:16:18,079]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:16:22,985]\u001b[0m Trial 909 finished with value: 5.593738599436243 and parameters: {'n_hidden': 3, 'learning_rate': 0.017232972565797575, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0034500896997720493, 'dropout_rate_Layer_2': 0.3703981849347808, 'dropout_rate_Layer_3': 0.0696048083679245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.265845275776254e-05, 'l1_Layer_2': 0.0011426953040057375, 'l1_Layer_3': 0.026487445534992795, 'n_units_Layer_1': 245, 'n_units_Layer_2': 85, 'n_units_Layer_3': 50}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 16.77% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.13 | sMAPE for Test Set is: 46.78% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:16:25,350]\u001b[0m Trial 919 finished with value: 5.685958922064725 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010516741655338061, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24160689760456447, 'dropout_rate_Layer_2': 0.2504784953669752, 'dropout_rate_Layer_3': 0.042203591981749194, 'dropout_rate_Layer_4': 0.3346225661124931, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03308946414627856, 'l1_Layer_2': 4.3107114773458484e-05, 'l1_Layer_3': 1.18343828417893e-05, 'l1_Layer_4': 1.239139272015104e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 170, 'n_units_Layer_3': 165, 'n_units_Layer_4': 245}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 16.99% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.18 | sMAPE for Test Set is: 46.95% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:16:28,400]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:16:28,777]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:16:30,236]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:16:36,950]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:16:37,099]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:16:38,040]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:16:45,991]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:16:49,475]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:16:54,998]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:16:55,719]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:17:00,032]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:17:01,088]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:17:06,024]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:17:12,042]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:17:18,315]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:17:27,167]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:17:27,825]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:17:34,407]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:17:35,135]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:17:44,302]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:17:49,264]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:17:49,609]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:17:57,352]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:18:03,377]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:18:11,920]\u001b[0m Trial 948 finished with value: 5.81676744854872 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011793141187323277, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2479837898159678, 'dropout_rate_Layer_2': 0.2457674062225939, 'dropout_rate_Layer_3': 0.20656942636374825, 'dropout_rate_Layer_4': 0.3171259534383808, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0378478410540683, 'l1_Layer_2': 2.9262242522276362e-05, 'l1_Layer_3': 1.486783900786278e-05, 'l1_Layer_4': 1.0279908577715333e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 200, 'n_units_Layer_3': 165, 'n_units_Layer_4': 245}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 17.35% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 11.17 | sMAPE for Test Set is: 46.91% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:18:16,372]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:18:17,140]\u001b[0m Trial 937 finished with value: 5.4453582448666324 and parameters: {'n_hidden': 4, 'learning_rate': 0.01002560615755499, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3613961010062073, 'dropout_rate_Layer_2': 0.10832953405970497, 'dropout_rate_Layer_3': 0.3541455474889409, 'dropout_rate_Layer_4': 0.15444310868660474, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0006014710156415167, 'l1_Layer_2': 0.0015059772132797668, 'l1_Layer_3': 0.011517339419645233, 'l1_Layer_4': 0.0003473510710306128, 'n_units_Layer_1': 75, 'n_units_Layer_2': 210, 'n_units_Layer_3': 55, 'n_units_Layer_4': 270}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 16.61% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.54 | sMAPE for Test Set is: 44.03% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:18:24,842]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:18:28,429]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:18:34,764]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:18:43,734]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:19:03,019]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:19:08,136]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:19:15,877]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:19:20,902]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:19:27,313]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:19:34,323]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:19:39,413]\u001b[0m Trial 952 finished with value: 5.630313711406134 and parameters: {'n_hidden': 3, 'learning_rate': 0.02204599614893409, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15422149503416488, 'dropout_rate_Layer_2': 0.3862988345661415, 'dropout_rate_Layer_3': 0.02299838761734367, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.9214135065508155e-05, 'l1_Layer_2': 0.00107946112960291, 'l1_Layer_3': 0.022445760796436974, 'n_units_Layer_1': 230, 'n_units_Layer_2': 65, 'n_units_Layer_3': 60}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 16.78% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.19 | sMAPE for Test Set is: 46.72% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:19:46,476]\u001b[0m Trial 945 finished with value: 5.888802046633743 and parameters: {'n_hidden': 4, 'learning_rate': 0.0035707593937554737, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3823329312665946, 'dropout_rate_Layer_2': 0.1064851650173941, 'dropout_rate_Layer_3': 0.18714815200973925, 'dropout_rate_Layer_4': 0.1522284407029453, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0006030154626078145, 'l1_Layer_2': 0.0006724214483715124, 'l1_Layer_3': 0.01214370593499328, 'l1_Layer_4': 0.0004781962132456472, 'n_units_Layer_1': 120, 'n_units_Layer_2': 260, 'n_units_Layer_3': 70, 'n_units_Layer_4': 290}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.89 | sMAPE for Validation Set is: 17.43% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 12.16 | sMAPE for Test Set is: 49.42% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:19:49,267]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:20:05,458]\u001b[0m Trial 961 finished with value: 5.805232716543493 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010656534343827656, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26283208341790704, 'dropout_rate_Layer_2': 0.2272712556150978, 'dropout_rate_Layer_3': 0.22407791013010658, 'dropout_rate_Layer_4': 0.1672378880509224, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05611241942234584, 'l1_Layer_2': 2.8067025134867163e-05, 'l1_Layer_3': 1.898114023604121e-05, 'l1_Layer_4': 1.2167666624457968e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 200, 'n_units_Layer_3': 165, 'n_units_Layer_4': 245}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 17.38% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.05 | sMAPE for Test Set is: 46.47% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:20:09,751]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:20:13,794]\u001b[0m Trial 964 finished with value: 5.747465214063336 and parameters: {'n_hidden': 4, 'learning_rate': 0.00110549932746812, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26398407816319475, 'dropout_rate_Layer_2': 0.23141708283120227, 'dropout_rate_Layer_3': 0.21297170375290123, 'dropout_rate_Layer_4': 0.12279687438120918, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05349999616247009, 'l1_Layer_2': 0.0037094980345025925, 'l1_Layer_3': 2.0405836642295132e-05, 'l1_Layer_4': 1.604018045506049e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 200, 'n_units_Layer_3': 145, 'n_units_Layer_4': 235}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 17.04% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.92 | sMAPE for Test Set is: 48.99% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:20:14,874]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:20:26,175]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:20:59,584]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:21:05,611]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:21:11,103]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:21:11,531]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:21:19,336]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:21:25,358]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:21:26,089]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:21:30,021]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:21:32,411]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:21:38,410]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:21:41,001]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:21:49,017]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:21:49,306]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:21:49,431]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:22:03,170]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:22:09,370]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:22:10,126]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:22:13,447]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:22:19,931]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:22:29,582]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:22:37,999]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:22:40,485]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:22:47,420]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:22:47,887]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:22:50,830]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:22:56,918]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:23:00,824]\u001b[0m Trial 990 finished with value: 5.741679008055887 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009139990302487293, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2657318469243523, 'dropout_rate_Layer_2': 0.2320882953629087, 'dropout_rate_Layer_3': 0.2252765232450009, 'dropout_rate_Layer_4': 0.16631881714919364, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04671615311854811, 'l1_Layer_2': 0.013366701471064729, 'l1_Layer_3': 2.7615656397760882e-05, 'l1_Layer_4': 1.187746994899749e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 215, 'n_units_Layer_3': 145, 'n_units_Layer_4': 240}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 17.15% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.96 | sMAPE for Test Set is: 49.14% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:23:01,050]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:23:05,285]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:23:10,106]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:23:13,069]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:23:18,568]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:23:33,411]\u001b[0m Trial 1004 finished with value: 5.626290738294023 and parameters: {'n_hidden': 3, 'learning_rate': 0.007779516895302658, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04608566298161336, 'dropout_rate_Layer_2': 0.11690554367892175, 'dropout_rate_Layer_3': 0.08322401028091328, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018106076224209781, 'l1_Layer_2': 0.0007735927565250987, 'l1_Layer_3': 1.8922153267480666e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 155, 'n_units_Layer_3': 300}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 17.05% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.02 | sMAPE for Test Set is: 46.38% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:23:37,832]\u001b[0m Trial 1003 finished with value: 5.5139185373338035 and parameters: {'n_hidden': 3, 'learning_rate': 0.0045712647314530355, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.051438985397213234, 'dropout_rate_Layer_2': 0.12120260844552423, 'dropout_rate_Layer_3': 0.08519572825134582, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015312571648561066, 'l1_Layer_2': 0.0006791833075848248, 'l1_Layer_3': 3.256022074404646e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 150, 'n_units_Layer_3': 285}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 16.74% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.53 | sMAPE for Test Set is: 44.52% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:23:38,107]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:23:38,360]\u001b[0m Trial 1002 finished with value: 5.429725768532833 and parameters: {'n_hidden': 3, 'learning_rate': 0.004309061480897536, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05151509426464933, 'dropout_rate_Layer_2': 0.12733045817627156, 'dropout_rate_Layer_3': 0.08760989135569003, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004446640797232268, 'l1_Layer_2': 0.0006783823658577997, 'l1_Layer_3': 3.644499376031797e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 155, 'n_units_Layer_3': 290}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 16.55% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.59 | sMAPE for Test Set is: 44.92% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:23:48,100]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:23:48,248]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:23:49,739]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:24:03,908]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:24:04,459]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:24:07,446]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:24:07,606]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:24:14,821]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:24:17,928]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:24:18,422]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:24:19,116]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:24:19,950]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:24:30,859]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:24:31,029]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:24:37,563]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:24:42,891]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:24:43,019]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:24:43,535]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:24:56,245]\u001b[0m Trial 1020 finished with value: 5.790939150331627 and parameters: {'n_hidden': 4, 'learning_rate': 0.001111342008752137, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2725378647206676, 'dropout_rate_Layer_2': 0.23612347129010822, 'dropout_rate_Layer_3': 0.20883338422592135, 'dropout_rate_Layer_4': 0.14452474883173347, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03488448394830057, 'l1_Layer_2': 0.025127561143522704, 'l1_Layer_3': 3.539455107931356e-05, 'l1_Layer_4': 1.1853921729380072e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 185, 'n_units_Layer_3': 165, 'n_units_Layer_4': 240}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 17.29% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.12 | sMAPE for Test Set is: 46.81% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:25:07,427]\u001b[0m Trial 1024 finished with value: 5.404459676984664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0044782614795954865, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09277682128327375, 'dropout_rate_Layer_2': 0.13112731626378563, 'dropout_rate_Layer_3': 0.1119842264981607, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.55298777452743e-05, 'l1_Layer_2': 0.001594779189170841, 'l1_Layer_3': 3.363394747020929e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 16.50% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.77 | sMAPE for Test Set is: 45.81% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:25:10,393]\u001b[0m Trial 1026 finished with value: 5.927133967419132 and parameters: {'n_hidden': 4, 'learning_rate': 0.002637857506667307, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.377914447150528, 'dropout_rate_Layer_2': 0.12378306694444571, 'dropout_rate_Layer_3': 0.22599751094676332, 'dropout_rate_Layer_4': 0.14267403729851347, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00048167186364765207, 'l1_Layer_2': 1.8208740934730737e-05, 'l1_Layer_3': 0.0021342841003935426, 'l1_Layer_4': 0.017488925101752952, 'n_units_Layer_1': 95, 'n_units_Layer_2': 215, 'n_units_Layer_3': 50, 'n_units_Layer_4': 265}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 17.68% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 11.49 | sMAPE for Test Set is: 47.66% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:25:16,755]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:25:21,626]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:25:24,256]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:25:28,850]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:25:33,926]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:25:36,115]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:25:41,415]\u001b[0m Trial 1028 finished with value: 5.3850024954033975 and parameters: {'n_hidden': 3, 'learning_rate': 0.002732719087007244, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1299444515932597, 'dropout_rate_Layer_2': 0.15872658169527695, 'dropout_rate_Layer_3': 0.11523742411418363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.747220409333769e-05, 'l1_Layer_2': 0.0014673373289677298, 'l1_Layer_3': 4.481581406255665e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 270}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 16.33% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.10 | sMAPE for Test Set is: 43.41% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:25:48,809]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:25:54,963]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:25:58,711]\u001b[0m Trial 1025 finished with value: 5.6926057230915665 and parameters: {'n_hidden': 3, 'learning_rate': 0.01705810035592524, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2996020160778739, 'dropout_rate_Layer_2': 0.36427485710657026, 'dropout_rate_Layer_3': 0.022765927593165362, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.2043121443316098e-05, 'l1_Layer_2': 0.0014173932684861678, 'l1_Layer_3': 0.008302797197329967, 'n_units_Layer_1': 215, 'n_units_Layer_2': 65, 'n_units_Layer_3': 60}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 16.92% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.51 | sMAPE for Test Set is: 47.70% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:25:59,548]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 16.17% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.25 | sMAPE for Test Set is: 43.96% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:26:05,258]\u001b[0m Trial 1035 finished with value: 5.335364323106337 and parameters: {'n_hidden': 3, 'learning_rate': 0.002883240788261122, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0960549773381498, 'dropout_rate_Layer_2': 0.15692542625255496, 'dropout_rate_Layer_3': 0.12054240016187774, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007512012030014922, 'l1_Layer_2': 0.001646822732592189, 'l1_Layer_3': 4.8241564781198935e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 170, 'n_units_Layer_3': 290}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:26:08,858]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:26:13,173]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:26:13,734]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:26:20,709]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:26:23,324]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:26:28,761]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:26:33,719]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:26:36,166]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:26:41,453]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:26:46,733]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:26:50,356]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:26:53,218]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:26:58,737]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:26:59,422]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:27:04,504]\u001b[0m Trial 1036 finished with value: 5.552842640534904 and parameters: {'n_hidden': 3, 'learning_rate': 0.013931034428523389, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22838981641631276, 'dropout_rate_Layer_2': 0.37229838115983754, 'dropout_rate_Layer_3': 0.06408267483353428, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.0014198828616189e-05, 'l1_Layer_2': 0.0017354207349515134, 'l1_Layer_3': 0.00028166679217360446, 'n_units_Layer_1': 220, 'n_units_Layer_2': 75, 'n_units_Layer_3': 55}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 16.77% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.98 | sMAPE for Test Set is: 45.84% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:27:10,919]\u001b[0m Trial 1050 finished with value: 5.461292892239392 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026619697826766376, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0951071225208397, 'dropout_rate_Layer_2': 0.15328302792016474, 'dropout_rate_Layer_3': 0.12353182954902661, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.169974215243679e-05, 'l1_Layer_2': 0.001490046484212779, 'l1_Layer_3': 2.3395452489148017e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 180, 'n_units_Layer_3': 290}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 16.63% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.51 | sMAPE for Test Set is: 44.68% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:27:11,250]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:27:17,383]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:27:19,730]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:27:20,636]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:27:28,321]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:27:30,975]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:27:37,724]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:27:43,253]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:27:44,354]\u001b[0m Trial 1062 finished with value: 5.684635141663935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032749763029752826, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.149608143273016, 'dropout_rate_Layer_2': 0.16744186908919811, 'dropout_rate_Layer_3': 0.13447082824188258, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4076053972475673e-05, 'l1_Layer_2': 0.0010168715305032322, 'l1_Layer_3': 1.3111866761082787e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 165, 'n_units_Layer_3': 270}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 16.87% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.58 | sMAPE for Test Set is: 47.98% | rMAE for Test Set is: 0.88\n",
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 17.05% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 12.10 | sMAPE for Test Set is: 49.52% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:27:48,764]\u001b[0m Trial 1055 finished with value: 5.741603064750161 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010460601075884955, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27443241713104993, 'dropout_rate_Layer_2': 0.20380859074293808, 'dropout_rate_Layer_3': 0.23633870895160997, 'dropout_rate_Layer_4': 0.16023097070377412, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05435319864563615, 'l1_Layer_2': 0.03336567492600841, 'l1_Layer_3': 1.8972223085175682e-05, 'l1_Layer_4': 1.3191382903576767e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 185, 'n_units_Layer_3': 165, 'n_units_Layer_4': 245}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:27:55,022]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:27:57,051]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:01,358]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:05,405]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:08,126]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:11,073]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:14,683]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:15,253]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:15,569]\u001b[0m Trial 1067 finished with value: 5.51733056864925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021543943383365606, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13394057688133756, 'dropout_rate_Layer_2': 0.1342028728392233, 'dropout_rate_Layer_3': 0.109115195050236, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9702300064505736e-05, 'l1_Layer_2': 0.0020493750341685013, 'l1_Layer_3': 4.775661136789823e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 285}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 16.64% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.44 | sMAPE for Test Set is: 44.58% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:28:19,245]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:28,651]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:29,743]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:35,660]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:36,137]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:36,182]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:36,721]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:47,111]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:50,051]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:50,621]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:52,063]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:28:56,826]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:29:03,605]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:29:03,764]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:29:04,789]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:29:13,911]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 16.36% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.37 | sMAPE for Test Set is: 44.47% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:29:16,250]\u001b[0m Trial 1087 finished with value: 5.451591343764264 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037713063489716197, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12643524391314254, 'dropout_rate_Layer_2': 0.1042993554191717, 'dropout_rate_Layer_3': 0.10042368260786697, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007522218893613975, 'l1_Layer_2': 0.005281120396432435, 'l1_Layer_3': 2.9616535157341692e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 160, 'n_units_Layer_3': 275}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:29:25,637]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:29:27,792]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:29:28,643]\u001b[0m Trial 1091 finished with value: 5.418449776789774 and parameters: {'n_hidden': 3, 'learning_rate': 0.003869672633819791, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12730957542079852, 'dropout_rate_Layer_2': 0.16855672538609429, 'dropout_rate_Layer_3': 0.0982191075265105, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007939558059848133, 'l1_Layer_2': 0.00585511656474119, 'l1_Layer_3': 0.00011133453897688758, 'n_units_Layer_1': 290, 'n_units_Layer_2': 170, 'n_units_Layer_3': 275}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 16.26% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.60 | sMAPE for Test Set is: 45.20% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:29:36,908]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:29:43,230]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:29:49,037]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:29:54,081]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:29:57,277]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:30:01,790]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:30:04,291]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:30:09,530]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:30:09,845]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:30:10,078]\u001b[0m Trial 1097 finished with value: 5.74061294407374 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008424053296999479, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1895081580037221, 'dropout_rate_Layer_2': 0.22740740862377476, 'dropout_rate_Layer_3': 0.22483730975970842, 'dropout_rate_Layer_4': 0.1770862124731735, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.8138413784259732e-05, 'l1_Layer_2': 0.016107783141464153, 'l1_Layer_3': 2.7295502701801883e-05, 'l1_Layer_4': 1.3580732713333055e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 165, 'n_units_Layer_4': 230}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:30:10,128]\u001b[0m Trial 1098 finished with value: 6.010364609661494 and parameters: {'n_hidden': 4, 'learning_rate': 0.0045223769933640115, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3576606448189012, 'dropout_rate_Layer_2': 0.18551894899158838, 'dropout_rate_Layer_3': 0.05748148086140219, 'dropout_rate_Layer_4': 0.15288500729324608, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00029798841577132314, 'l1_Layer_2': 3.070347312646783e-05, 'l1_Layer_3': 0.00114328983475828, 'l1_Layer_4': 0.026157644984916947, 'n_units_Layer_1': 85, 'n_units_Layer_2': 205, 'n_units_Layer_3': 70, 'n_units_Layer_4': 260}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 17.18% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.73 | sMAPE for Test Set is: 45.49% | rMAE for Test Set is: 0.81\n",
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 17.95% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 11.58 | sMAPE for Test Set is: 47.78% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:30:19,768]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:30:22,374]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:30:24,597]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:30:25,904]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:30:28,861]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:30:34,070]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:30:36,948]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:30:43,688]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:30:52,069]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:30:55,171]\u001b[0m Trial 1107 finished with value: 5.74772523928399 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011188437190702138, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01109300458749399, 'dropout_rate_Layer_2': 0.23064376883777776, 'dropout_rate_Layer_3': 0.2439988855974774, 'dropout_rate_Layer_4': 0.1868154739732073, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0030855566050658405, 'l1_Layer_2': 0.00427964982607061, 'l1_Layer_3': 1.849092524179791e-05, 'l1_Layer_4': 2.3879626531704054e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 175, 'n_units_Layer_3': 160, 'n_units_Layer_4': 235}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 17.31% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.51 | sMAPE for Test Set is: 44.86% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:30:59,227]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:31:03,018]\u001b[0m Trial 1113 finished with value: 5.729357746486559 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006749193660281397, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011397752132762751, 'dropout_rate_Layer_2': 0.22502997064122388, 'dropout_rate_Layer_3': 0.24092224409584873, 'dropout_rate_Layer_4': 0.1764809490868467, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02190440389402519, 'l1_Layer_2': 0.005019173624725584, 'l1_Layer_3': 1.4019764242429802e-05, 'l1_Layer_4': 2.15734224514851e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 180, 'n_units_Layer_3': 145, 'n_units_Layer_4': 235}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 17.19% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.88 | sMAPE for Test Set is: 46.13% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:31:07,117]\u001b[0m Trial 1111 finished with value: 5.648592744148865 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010114427404462304, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21221795670065366, 'dropout_rate_Layer_2': 0.23301691758225948, 'dropout_rate_Layer_3': 0.24335818017434077, 'dropout_rate_Layer_4': 0.1919782268566023, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03639575819364145, 'l1_Layer_2': 0.005780617543403217, 'l1_Layer_3': 1.8007871088803624e-05, 'l1_Layer_4': 2.209670680471357e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 195, 'n_units_Layer_3': 150, 'n_units_Layer_4': 230}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 16.80% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.80 | sMAPE for Test Set is: 48.68% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:31:10,295]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:31:10,503]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 16.54% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.95 | sMAPE for Test Set is: 46.24% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:31:14,220]\u001b[0m Trial 1117 finished with value: 5.5390346036010625 and parameters: {'n_hidden': 3, 'learning_rate': 0.006574831473398315, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11474167604579437, 'dropout_rate_Layer_2': 0.1779818217621325, 'dropout_rate_Layer_3': 0.11905891034813737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004565832665855202, 'l1_Layer_2': 0.0075420544591293616, 'l1_Layer_3': 6.327530703334263e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 195, 'n_units_Layer_3': 275}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:31:18,454]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:31:25,448]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:31:25,749]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:31:25,881]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:31:34,802]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:31:37,442]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:31:41,880]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:31:46,698]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:31:47,878]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:32:03,385]\u001b[0m Trial 1124 finished with value: 5.73795686640553 and parameters: {'n_hidden': 4, 'learning_rate': 0.000717979107564681, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01827029470128312, 'dropout_rate_Layer_2': 0.2324887611801574, 'dropout_rate_Layer_3': 0.24065773951187527, 'dropout_rate_Layer_4': 0.1755054524962862, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.021408203962377685, 'l1_Layer_2': 0.004710676091484699, 'l1_Layer_3': 1.3618181423894751e-05, 'l1_Layer_4': 2.9273583928153432e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 175, 'n_units_Layer_3': 155, 'n_units_Layer_4': 225}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 17.23% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.73 | sMAPE for Test Set is: 45.48% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:32:08,556]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:32:09,398]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:32:15,651]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:32:16,218]\u001b[0m Trial 1125 finished with value: 5.7160016475620665 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027522959846643376, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3995486390277025, 'dropout_rate_Layer_2': 0.17157958529670633, 'dropout_rate_Layer_3': 0.21535962616448737, 'dropout_rate_Layer_4': 0.17740304648277566, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0018374978487705198, 'l1_Layer_2': 1.3041470862071004e-05, 'l1_Layer_3': 0.01082146161669505, 'l1_Layer_4': 0.00023752854655678516, 'n_units_Layer_1': 50, 'n_units_Layer_2': 225, 'n_units_Layer_3': 50, 'n_units_Layer_4': 225}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 17.02% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.53 | sMAPE for Test Set is: 47.87% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:32:16,503]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:32:24,701]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:32:28,126]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:32:30,276]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:32:31,118]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:32:32,468]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:32:41,482]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:32:52,401]\u001b[0m Trial 1141 finished with value: 5.603403101810976 and parameters: {'n_hidden': 3, 'learning_rate': 0.004365152346710121, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06111433788686692, 'dropout_rate_Layer_2': 0.17845642056259517, 'dropout_rate_Layer_3': 0.15024075004615545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.953007901040956e-05, 'l1_Layer_2': 0.0014872257369634887, 'l1_Layer_3': 0.00010985702929137186, 'n_units_Layer_1': 60, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 16.91% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.37 | sMAPE for Test Set is: 44.37% | rMAE for Test Set is: 0.79\n",
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 17.28% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.22 | sMAPE for Test Set is: 47.06% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:32:52,487]\u001b[0m Trial 1140 finished with value: 5.769642213460898 and parameters: {'n_hidden': 4, 'learning_rate': 0.000720608225772228, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01852276957233102, 'dropout_rate_Layer_2': 0.24570249577309647, 'dropout_rate_Layer_3': 0.24140195746961654, 'dropout_rate_Layer_4': 0.18803494107263344, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.021371900076510464, 'l1_Layer_2': 0.005114106033203625, 'l1_Layer_3': 1.3832733965099509e-05, 'l1_Layer_4': 3.080767646451818e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 180, 'n_units_Layer_3': 160, 'n_units_Layer_4': 220}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:32:58,193]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:33:02,790]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:33:02,885]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:33:07,248]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:33:14,469]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:33:17,697]\u001b[0m Trial 1144 finished with value: 5.757246454228237 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008307486058855413, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009798341997324952, 'dropout_rate_Layer_2': 0.23488446763553392, 'dropout_rate_Layer_3': 0.2437354006025578, 'dropout_rate_Layer_4': 0.1974500148575833, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.021457389465490195, 'l1_Layer_2': 0.0036820084575034293, 'l1_Layer_3': 1.346289162856267e-05, 'l1_Layer_4': 2.4595651722154333e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 175, 'n_units_Layer_3': 140, 'n_units_Layer_4': 225}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 17.21% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.11 | sMAPE for Test Set is: 46.73% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:33:19,716]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:33:33,817]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:33:37,768]\u001b[0m Trial 1152 finished with value: 5.551630522933974 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032235025329183527, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13669643874325085, 'dropout_rate_Layer_2': 0.12820316014815025, 'dropout_rate_Layer_3': 0.09411343785435464, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012110421681720033, 'l1_Layer_2': 0.013506586585741052, 'l1_Layer_3': 3.654356144598699e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 125, 'n_units_Layer_3': 295}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 16.66% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.72 | sMAPE for Test Set is: 45.56% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:33:40,395]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:33:46,580]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:33:53,155]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:33:56,488]\u001b[0m Trial 1150 finished with value: 5.556802738081366 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006147231042711365, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005693233937480929, 'dropout_rate_Layer_2': 0.24583230391848665, 'dropout_rate_Layer_3': 0.242693832888711, 'dropout_rate_Layer_4': 0.19580242141781393, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005307821319002977, 'l1_Layer_2': 0.004845738923319014, 'l1_Layer_3': 1.4520826390297037e-05, 'l1_Layer_4': 4.2461800280489025e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 180, 'n_units_Layer_3': 150, 'n_units_Layer_4': 220}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 16.63% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.56 | sMAPE for Test Set is: 45.13% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:33:57,909]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:33:59,043]\u001b[0m Trial 1151 finished with value: 5.725430435721435 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005868754726865961, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022229961695594547, 'dropout_rate_Layer_2': 0.2470000512255658, 'dropout_rate_Layer_3': 0.24149506383140923, 'dropout_rate_Layer_4': 0.19488347845388043, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0031660140660274344, 'l1_Layer_2': 0.005983954466668252, 'l1_Layer_3': 1.3716752148123048e-05, 'l1_Layer_4': 3.2540439200353424e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 150, 'n_units_Layer_4': 225}. Best is trial 345 with value: 5.098256594209587.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 17.13% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.10 | sMAPE for Test Set is: 46.64% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:34:08,399]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:34:13,399]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:34:13,686]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:34:16,948]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:34:20,848]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:34:23,974]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:34:27,578]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:34:30,015]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:34:31,173]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:34:37,199]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:34:37,240]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:34:37,350]\u001b[0m Trial 1155 finished with value: 5.006350356870552 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018937443361444195, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12628070760475885, 'dropout_rate_Layer_2': 0.1605022391571223, 'dropout_rate_Layer_3': 0.1042877169440353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007729158580315368, 'l1_Layer_2': 0.011117866775281074, 'l1_Layer_3': 5.5872359676720803e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 150, 'n_units_Layer_3': 290}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 15.46% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.09 | sMAPE for Test Set is: 43.34% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:34:37,688]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:34:47,585]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:34:51,639]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:34:52,203]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:35:03,601]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:35:07,160]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:35:10,299]\u001b[0m Trial 1175 finished with value: 5.587465669957841 and parameters: {'n_hidden': 3, 'learning_rate': 0.003775149463167262, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29289617354029307, 'dropout_rate_Layer_2': 0.14837240674766797, 'dropout_rate_Layer_3': 0.12939443448592025, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0006363924019673365, 'l1_Layer_2': 0.0020877959254195413, 'l1_Layer_3': 2.5280970295874872e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 155, 'n_units_Layer_3': 280}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 16.75% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.78 | sMAPE for Test Set is: 45.60% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:35:13,727]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:35:18,073]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:35:23,183]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:35:29,232]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:35:33,441]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:35:36,080]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:35:41,530]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:35:44,780]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:35:50,681]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:35:53,761]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:35:55,319]\u001b[0m Trial 1182 finished with value: 5.700121204750943 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022316063290690365, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36616990292579765, 'dropout_rate_Layer_2': 0.19416645834038213, 'dropout_rate_Layer_3': 0.22539522124456607, 'dropout_rate_Layer_4': 0.1440953822678754, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.003553848192423144, 'l1_Layer_2': 0.0008621720260506138, 'l1_Layer_3': 0.006119294522168971, 'l1_Layer_4': 0.03504727954051378, 'n_units_Layer_1': 80, 'n_units_Layer_2': 225, 'n_units_Layer_3': 85, 'n_units_Layer_4': 295}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 16.95% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.64 | sMAPE for Test Set is: 48.13% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:35:58,925]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:36:04,149]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:36:07,708]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:36:12,142]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:36:16,554]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:36:23,640]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:36:30,509]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:36:30,827]\u001b[0m Trial 1187 finished with value: 5.63588532496653 and parameters: {'n_hidden': 4, 'learning_rate': 0.003887734062723684, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39404974602795684, 'dropout_rate_Layer_2': 0.19441607183591916, 'dropout_rate_Layer_3': 0.22472979397289383, 'dropout_rate_Layer_4': 0.14583998710864013, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0029941857773463625, 'l1_Layer_2': 5.932668187308582e-05, 'l1_Layer_3': 0.010012283591949537, 'l1_Layer_4': 0.00010740809368772767, 'n_units_Layer_1': 95, 'n_units_Layer_2': 210, 'n_units_Layer_3': 50, 'n_units_Layer_4': 285}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 16.95% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.02 | sMAPE for Test Set is: 46.30% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:36:39,340]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:36:39,809]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:36:55,492]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:37:00,083]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:37:00,846]\u001b[0m Trial 1200 finished with value: 5.409658321126382 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024031753850616883, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07919954909616228, 'dropout_rate_Layer_2': 0.17173802942640026, 'dropout_rate_Layer_3': 0.1059173489630229, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00045376241870111645, 'l1_Layer_2': 1.2147444589094468e-05, 'l1_Layer_3': 8.234022574216559e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 135, 'n_units_Layer_3': 295}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 16.71% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.74 | sMAPE for Test Set is: 42.01% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:37:10,060]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:37:12,645]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:37:17,597]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:37:19,269]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:37:22,439]\u001b[0m Trial 1197 finished with value: 5.450154555070334 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007141703887108533, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0010722689297745763, 'dropout_rate_Layer_2': 0.25642045778360284, 'dropout_rate_Layer_3': 0.22072276973598176, 'dropout_rate_Layer_4': 0.2149605302449254, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006519889985229351, 'l1_Layer_2': 0.004590429318207465, 'l1_Layer_3': 1.3476540091775777e-05, 'l1_Layer_4': 3.4269101250253793e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 195, 'n_units_Layer_3': 160, 'n_units_Layer_4': 225}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 16.40% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.30 | sMAPE for Test Set is: 44.21% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:37:23,307]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:37:28,051]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:37:31,554]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:37:36,403]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:37:43,457]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:37:44,225]\u001b[0m Trial 1192 finished with value: 5.671846534899494 and parameters: {'n_hidden': 3, 'learning_rate': 0.01103904558145888, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3088814436808478, 'dropout_rate_Layer_2': 0.2172748422117645, 'dropout_rate_Layer_3': 0.06929319013264841, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.034462332972499e-05, 'l1_Layer_2': 0.002239344653525539, 'l1_Layer_3': 0.01834891497257917, 'n_units_Layer_1': 120, 'n_units_Layer_2': 65, 'n_units_Layer_3': 60}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 16.92% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.17 | sMAPE for Test Set is: 46.53% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:37:52,374]\u001b[0m Trial 1212 finished with value: 5.55880710193981 and parameters: {'n_hidden': 3, 'learning_rate': 0.002513572728714647, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1044322625071185, 'dropout_rate_Layer_2': 0.17589982480145644, 'dropout_rate_Layer_3': 0.1054903486691176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002338852911397194, 'l1_Layer_2': 1.5962156428487216e-05, 'l1_Layer_3': 7.175207371760777e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 135, 'n_units_Layer_3': 255}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 17.19% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.87 | sMAPE for Test Set is: 42.82% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:37:52,908]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:37:53,222]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:38:00,192]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:38:07,076]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:38:13,244]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:38:15,429]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:38:20,753]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:38:24,155]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:38:31,293]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:38:37,368]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:38:44,661]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 16.63% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.20 | sMAPE for Test Set is: 43.92% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:38:46,375]\u001b[0m Trial 1218 finished with value: 5.542366792063473 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005306572510233058, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005489591368278533, 'dropout_rate_Layer_2': 0.2579141497227613, 'dropout_rate_Layer_3': 0.17822256210941942, 'dropout_rate_Layer_4': 0.2087584205698394, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.403787556992319e-05, 'l1_Layer_2': 0.003234839557772667, 'l1_Layer_3': 1.6661810839831318e-05, 'l1_Layer_4': 5.546549532751844e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 240, 'n_units_Layer_3': 160, 'n_units_Layer_4': 230}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:39:01,027]\u001b[0m Trial 1211 finished with value: 5.261313205271391 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005566607986522854, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01205502256634263, 'dropout_rate_Layer_2': 0.2569153002408849, 'dropout_rate_Layer_3': 0.24348185476440248, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008111806978226847, 'l1_Layer_2': 0.0043723976582195605, 'l1_Layer_3': 1.3972321122034013e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 195, 'n_units_Layer_3': 125}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 16.35% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.61 | sMAPE for Test Set is: 41.79% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:39:01,247]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:39:12,017]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:39:13,301]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:39:19,597]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:39:22,069]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:39:25,908]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:39:35,613]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:39:41,303]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:39:47,303]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:39:50,112]\u001b[0m Trial 1234 finished with value: 5.436470874883027 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027974589540862463, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.085752908205367, 'dropout_rate_Layer_2': 0.2098676404205481, 'dropout_rate_Layer_3': 0.14955374845547095, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00034724572173578077, 'l1_Layer_2': 3.371396179722395e-05, 'l1_Layer_3': 0.0006364589205520418, 'n_units_Layer_1': 80, 'n_units_Layer_2': 145, 'n_units_Layer_3': 300}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 16.82% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.87 | sMAPE for Test Set is: 44.05% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:39:57,515]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:40:03,724]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:40:09,108]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:40:09,625]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:40:16,900]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:40:17,841]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:40:20,562]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:40:26,473]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:40:30,279]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:40:30,336]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:40:36,658]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:40:37,600]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:40:46,277]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:40:48,648]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:40:56,050]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:41:02,386]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:41:05,131]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:41:09,786]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:41:10,948]\u001b[0m Trial 1236 finished with value: 5.153172704848206 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005653802157754456, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04638221400919603, 'dropout_rate_Layer_2': 0.2580573639646181, 'dropout_rate_Layer_3': 0.23768649391261917, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010492523568805736, 'l1_Layer_2': 0.003130147978899281, 'l1_Layer_3': 1.1925494712668909e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 250, 'n_units_Layer_3': 115}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 15.86% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.82 | sMAPE for Test Set is: 42.33% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:41:16,508]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:41:18,138]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:41:23,457]\u001b[0m Trial 1248 finished with value: 5.3871887778514385 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005650636860142788, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0013743830851941554, 'dropout_rate_Layer_2': 0.2563490004378781, 'dropout_rate_Layer_3': 0.23869625617254572, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.017509636679877e-05, 'l1_Layer_2': 0.0033811749127227427, 'l1_Layer_3': 1.1819155071989636e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 250, 'n_units_Layer_3': 120}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 16.46% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.34 | sMAPE for Test Set is: 40.75% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:41:23,702]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:41:27,429]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:41:33,023]\u001b[0m Trial 1256 finished with value: 5.538957287724126 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013556188583242323, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13716352364427553, 'dropout_rate_Layer_2': 0.1700911512465914, 'dropout_rate_Layer_3': 0.13426786613025918, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004942588709440125, 'l1_Layer_2': 5.730614363309804e-05, 'l1_Layer_3': 0.00013717046072890155, 'n_units_Layer_1': 125, 'n_units_Layer_2': 160, 'n_units_Layer_3': 245}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 17.01% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.48 | sMAPE for Test Set is: 41.70% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:41:35,626]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:41:45,059]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:41:47,372]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:42:01,770]\u001b[0m Trial 1261 finished with value: 5.770609740997827 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026736833640854016, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38011657016297107, 'dropout_rate_Layer_2': 0.18341994009619447, 'dropout_rate_Layer_3': 0.23382324744739336, 'dropout_rate_Layer_4': 0.13832836291989764, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.004758791405756539, 'l1_Layer_2': 1.899953741239019e-05, 'l1_Layer_3': 0.004434005929670559, 'l1_Layer_4': 0.021958342046885834, 'n_units_Layer_1': 95, 'n_units_Layer_2': 225, 'n_units_Layer_3': 50, 'n_units_Layer_4': 270}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 17.13% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 12.06 | sMAPE for Test Set is: 49.17% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:42:20,247]\u001b[0m Trial 1264 finished with value: 5.401191269513395 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005022422516953571, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04260832377103499, 'dropout_rate_Layer_2': 0.2567397794125613, 'dropout_rate_Layer_3': 0.24640795441820718, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.1550888366640336e-05, 'l1_Layer_2': 0.002093507309528373, 'l1_Layer_3': 1.1954892030409102e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 255, 'n_units_Layer_3': 130}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 16.52% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.46 | sMAPE for Test Set is: 41.20% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:42:20,965]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 17.05% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.88 | sMAPE for Test Set is: 48.58% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:42:25,998]\u001b[0m Trial 1266 finished with value: 5.733518543678511 and parameters: {'n_hidden': 4, 'learning_rate': 0.0026050023779153404, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37802339715064637, 'dropout_rate_Layer_2': 0.13543140858634042, 'dropout_rate_Layer_3': 0.17412213486663985, 'dropout_rate_Layer_4': 0.14134004577372053, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.002529480694986587, 'l1_Layer_2': 1.923453273550307e-05, 'l1_Layer_3': 0.009361825081503143, 'l1_Layer_4': 0.020655454619806835, 'n_units_Layer_1': 95, 'n_units_Layer_2': 215, 'n_units_Layer_3': 50, 'n_units_Layer_4': 270}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:42:29,238]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:42:35,957]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:42:39,000]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:42:43,131]\u001b[0m Trial 1268 finished with value: 5.557482515425878 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006338072833059201, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0007525933626387829, 'dropout_rate_Layer_2': 0.2623639725813835, 'dropout_rate_Layer_3': 0.247858004882746, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5047828174839245e-05, 'l1_Layer_2': 0.002831157245382761, 'l1_Layer_3': 1.185810315296911e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 175, 'n_units_Layer_3': 120}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 16.88% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.76 | sMAPE for Test Set is: 42.23% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:42:52,578]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:42:58,382]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:43:18,051]\u001b[0m Trial 1273 finished with value: 5.5127919423491365 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005026424739169805, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.041706954985161464, 'dropout_rate_Layer_2': 0.2612739900126069, 'dropout_rate_Layer_3': 0.2483541938883384, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9789301754048722e-05, 'l1_Layer_2': 0.001959652402825848, 'l1_Layer_3': 1.1624618360590892e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 245, 'n_units_Layer_3': 120}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 16.80% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.48 | sMAPE for Test Set is: 41.17% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:43:30,999]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:43:31,475]\u001b[0m Trial 1270 finished with value: 5.665760525955613 and parameters: {'n_hidden': 3, 'learning_rate': 0.01959749511780062, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2060344793109165, 'dropout_rate_Layer_2': 0.2319991389293863, 'dropout_rate_Layer_3': 0.0746867358466157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.6326341073444745e-05, 'l1_Layer_2': 0.0009467391003809786, 'l1_Layer_3': 0.098670006607674, 'n_units_Layer_1': 225, 'n_units_Layer_2': 90, 'n_units_Layer_3': 65}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 17.02% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 10.86 | sMAPE for Test Set is: 45.91% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:43:40,431]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:43:41,237]\u001b[0m Trial 1279 finished with value: 7.2975668134458465 and parameters: {'n_hidden': 3, 'learning_rate': 0.04879703946858196, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09951024988659612, 'dropout_rate_Layer_2': 0.18578657101728407, 'dropout_rate_Layer_3': 0.11330956327352737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006870269616233287, 'l1_Layer_2': 1.0114565795592539e-05, 'l1_Layer_3': 5.839829723383913e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 190, 'n_units_Layer_3': 280}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.30 | sMAPE for Validation Set is: 20.26% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 14.49 | sMAPE for Test Set is: 54.60% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:43:46,570]\u001b[0m Trial 1277 finished with value: 5.540591767047371 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005006659649928234, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0532925559370544, 'dropout_rate_Layer_2': 0.26605961092460695, 'dropout_rate_Layer_3': 0.25230345602121496, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.540442082776828e-05, 'l1_Layer_2': 0.0023677103149275453, 'l1_Layer_3': 1.1787321753089186e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 245, 'n_units_Layer_3': 120}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 16.92% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.79 | sMAPE for Test Set is: 42.53% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:43:52,665]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:44:28,740]\u001b[0m Trial 1274 finished with value: 5.538307067988306 and parameters: {'n_hidden': 3, 'learning_rate': 0.011688564231902471, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0913804084825688, 'dropout_rate_Layer_2': 0.31004247902853876, 'dropout_rate_Layer_3': 0.021479065392661114, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.654867567481428e-05, 'l1_Layer_2': 1.370331719100484e-05, 'l1_Layer_3': 0.047772811388632694, 'n_units_Layer_1': 215, 'n_units_Layer_2': 60, 'n_units_Layer_3': 50}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 16.58% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.03 | sMAPE for Test Set is: 46.48% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:44:35,409]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:44:36,146]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:44:43,688]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:44:46,399]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:44:46,918]\u001b[0m Trial 1282 finished with value: 5.467265732418227 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005295277212173718, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.047125281492223545, 'dropout_rate_Layer_2': 0.2675851855410568, 'dropout_rate_Layer_3': 0.2489357600708396, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.927589760368206e-05, 'l1_Layer_2': 0.0029943592939611513, 'l1_Layer_3': 1.1409162539539217e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 245, 'n_units_Layer_3': 120}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 16.60% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.90 | sMAPE for Test Set is: 42.79% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:44:52,402]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:44:55,612]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:44:56,150]\u001b[0m Trial 1281 finished with value: 5.8147140409515785 and parameters: {'n_hidden': 3, 'learning_rate': 0.01746121272406909, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1873080261286027, 'dropout_rate_Layer_2': 0.23782888634233296, 'dropout_rate_Layer_3': 0.34441847265171066, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.051369845190306e-05, 'l1_Layer_2': 0.0008094067360766666, 'l1_Layer_3': 0.0778745894222408, 'n_units_Layer_1': 235, 'n_units_Layer_2': 95, 'n_units_Layer_3': 70}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 17.33% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 11.27 | sMAPE for Test Set is: 47.13% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:45:00,952]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:45:06,210]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:45:06,528]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:45:17,151]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:45:17,800]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:45:18,228]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:45:28,582]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:45:30,959]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:45:37,007]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:45:37,789]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:45:42,395]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:45:45,350]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:45:51,367]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:45:51,919]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:45:59,307]\u001b[0m Trial 1294 finished with value: 5.595976124240477 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005063891870480405, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.041564885259031986, 'dropout_rate_Layer_2': 0.2668573294385703, 'dropout_rate_Layer_3': 0.2495412796994451, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.187042871369636e-05, 'l1_Layer_2': 0.0022128392163726545, 'l1_Layer_3': 1.0617336080600551e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 245, 'n_units_Layer_3': 120}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 16.84% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.65 | sMAPE for Test Set is: 41.84% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:46:03,081]\u001b[0m Trial 1303 finished with value: 5.66963108701191 and parameters: {'n_hidden': 3, 'learning_rate': 0.0058704504661206, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12325918976464305, 'dropout_rate_Layer_2': 0.23110838470167666, 'dropout_rate_Layer_3': 0.09737289913510541, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005834269355597778, 'l1_Layer_2': 2.773100539992498e-05, 'l1_Layer_3': 0.00028051850503403396, 'n_units_Layer_1': 300, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 16.87% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.89 | sMAPE for Test Set is: 48.76% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:46:06,353]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:46:10,526]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:46:15,723]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:46:18,033]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:46:26,011]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:46:39,444]\u001b[0m Trial 1306 finished with value: 5.547227043737024 and parameters: {'n_hidden': 3, 'learning_rate': 0.000524349240018104, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.055233131890513536, 'dropout_rate_Layer_2': 0.26763752496230614, 'dropout_rate_Layer_3': 0.2689539544403837, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.43329923303948e-05, 'l1_Layer_2': 0.0019666000341675175, 'l1_Layer_3': 1.040479240371312e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 255, 'n_units_Layer_3': 120}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 16.82% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.69 | sMAPE for Test Set is: 41.98% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:46:43,346]\u001b[0m Trial 1307 finished with value: 5.545064110713741 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005364726672083094, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05610324992862589, 'dropout_rate_Layer_2': 0.2641643654323794, 'dropout_rate_Layer_3': 0.25083257515546975, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5010387853951455e-05, 'l1_Layer_2': 0.0018570055215900462, 'l1_Layer_3': 1.0082560430193248e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 245, 'n_units_Layer_3': 120}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 16.65% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.85 | sMAPE for Test Set is: 42.82% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:46:47,133]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:46:55,917]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:47:07,362]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:47:36,658]\u001b[0m Trial 1318 finished with value: 5.582484699096983 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005051495385391862, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05927783550726256, 'dropout_rate_Layer_2': 0.2874491654488033, 'dropout_rate_Layer_3': 0.2723791773611062, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.56239080776358e-05, 'l1_Layer_2': 0.001952013174993057, 'l1_Layer_3': 1.0023717343294256e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 245, 'n_units_Layer_3': 120}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 16.73% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.26 | sMAPE for Test Set is: 44.03% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:47:42,204]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:47:43,002]\u001b[0m Trial 1316 finished with value: 6.0022721522880005 and parameters: {'n_hidden': 3, 'learning_rate': 0.017089350907622217, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17855210945111877, 'dropout_rate_Layer_2': 0.3072052887673339, 'dropout_rate_Layer_3': 0.32751841544122695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.3578217318667145e-05, 'l1_Layer_2': 0.000517810261549368, 'l1_Layer_3': 0.06778970791387474, 'n_units_Layer_1': 60, 'n_units_Layer_2': 80, 'n_units_Layer_3': 50}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 17.61% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 11.97 | sMAPE for Test Set is: 49.06% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:47:47,523]\u001b[0m Trial 1319 finished with value: 5.499065745411862 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005050103115729273, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.049030438295425464, 'dropout_rate_Layer_2': 0.269956670774566, 'dropout_rate_Layer_3': 0.2733041782649234, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5180593363882225e-05, 'l1_Layer_2': 0.0016374758740203368, 'l1_Layer_3': 1.0004646361792144e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 255, 'n_units_Layer_3': 120}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 16.81% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.74 | sMAPE for Test Set is: 42.27% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:47:50,174]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:47:57,384]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:48:03,654]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:48:12,171]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:48:25,254]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:48:25,987]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:48:30,180]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:48:36,561]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:48:40,605]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:48:44,628]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:48:48,596]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:48:49,853]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:48:51,539]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:48:59,403]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:49:03,190]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:49:06,358]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:49:08,939]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:49:11,495]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:49:17,034]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:49:19,164]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:49:44,914]\u001b[0m Trial 1313 finished with value: 5.8242877782878475 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024477008696005462, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.341792397473094, 'dropout_rate_Layer_2': 0.148692746716761, 'dropout_rate_Layer_3': 0.20391504645253472, 'dropout_rate_Layer_4': 0.15025509308408297, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.002142715616502149, 'l1_Layer_2': 1.47880704640319e-05, 'l1_Layer_3': 0.0032900767996289567, 'l1_Layer_4': 0.029396960345685223, 'n_units_Layer_1': 90, 'n_units_Layer_2': 205, 'n_units_Layer_3': 70, 'n_units_Layer_4': 250}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 17.16% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 12.93 | sMAPE for Test Set is: 51.52% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:49:53,018]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:49:57,555]\u001b[0m Trial 1341 finished with value: 5.490128158628386 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005756498399178334, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07588579049047292, 'dropout_rate_Layer_2': 0.2639614483338646, 'dropout_rate_Layer_3': 0.2648795604451037, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8158064794608347e-05, 'l1_Layer_2': 0.002862783445152481, 'l1_Layer_3': 1.1962973095581502e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 235, 'n_units_Layer_3': 125}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 16.53% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.64 | sMAPE for Test Set is: 41.87% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:50:02,096]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:50:03,387]\u001b[0m Trial 1342 finished with value: 5.6011481081418255 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005786106425754265, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07303495073337371, 'dropout_rate_Layer_2': 0.2647511626697614, 'dropout_rate_Layer_3': 0.26428554757651, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.568903833441025e-05, 'l1_Layer_2': 0.0028736134017844804, 'l1_Layer_3': 1.2252704839481713e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 240, 'n_units_Layer_3': 125}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 16.80% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.97 | sMAPE for Test Set is: 42.93% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:50:06,656]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:50:09,114]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:50:10,426]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:50:14,888]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:50:19,811]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:50:21,282]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:50:23,390]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:50:27,776]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:50:33,416]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:50:39,395]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:50:49,144]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:50:55,340]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:51:02,456]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:51:07,017]\u001b[0m Trial 1357 finished with value: 5.492510388430271 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006199173641507656, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03790750631020203, 'dropout_rate_Layer_2': 0.2578815770107319, 'dropout_rate_Layer_3': 0.2526110899536738, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5560312957710948e-05, 'l1_Layer_2': 0.0029056404662131797, 'l1_Layer_3': 1.1621909078499321e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 240, 'n_units_Layer_3': 115}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 16.68% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.92 | sMAPE for Test Set is: 42.85% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:51:09,980]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:51:16,332]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:51:19,221]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:51:23,233]\u001b[0m Trial 1356 finished with value: 5.553035390616588 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005004201349842192, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03573665610055241, 'dropout_rate_Layer_2': 0.2574390229653046, 'dropout_rate_Layer_3': 0.2660683865889055, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.1610109469105185e-05, 'l1_Layer_2': 0.0011978760188447047, 'l1_Layer_3': 1.1520505004406402e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 240, 'n_units_Layer_3': 130}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 16.93% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.92 | sMAPE for Test Set is: 42.47% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:51:29,449]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:51:33,510]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:51:40,308]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:51:50,734]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 15.89% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.16 | sMAPE for Test Set is: 39.32% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:51:52,929]\u001b[0m Trial 1364 finished with value: 5.190062723104293 and parameters: {'n_hidden': 3, 'learning_rate': 0.005007104882700806, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06666662784445518, 'dropout_rate_Layer_2': 0.13395843550385156, 'dropout_rate_Layer_3': 0.10858293627021665, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00048214921543819346, 'l1_Layer_2': 0.02318516824297941, 'l1_Layer_3': 2.9537948811713532e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 145, 'n_units_Layer_3': 300}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:51:58,060]\u001b[0m Trial 1367 finished with value: 5.289780225502935 and parameters: {'n_hidden': 3, 'learning_rate': 0.003957523380236031, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0901626961813815, 'dropout_rate_Layer_2': 0.13335412533731383, 'dropout_rate_Layer_3': 0.08992676340389881, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007119714984244984, 'l1_Layer_2': 0.025321018551340797, 'l1_Layer_3': 3.048734501434794e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 145, 'n_units_Layer_3': 300}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 16.10% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.51 | sMAPE for Test Set is: 41.37% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:52:01,431]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:52:10,186]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:52:12,847]\u001b[0m Trial 1363 finished with value: 5.5551186485796675 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005013846105196099, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03871566036686496, 'dropout_rate_Layer_2': 0.2587502519271606, 'dropout_rate_Layer_3': 0.26302835833323995, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3662202773508407e-05, 'l1_Layer_2': 0.002966235912160646, 'l1_Layer_3': 1.0138979404360723e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 230, 'n_units_Layer_3': 115}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 16.77% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.99 | sMAPE for Test Set is: 42.92% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:52:18,284]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:52:28,503]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:52:32,705]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:52:33,634]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:52:42,456]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:52:47,693]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:52:48,075]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:52:49,489]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:53:00,743]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:53:07,375]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:53:09,327]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:53:20,674]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:53:27,600]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:53:30,831]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:53:43,324]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:53:47,638]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:53:50,126]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:53:50,474]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:53:57,943]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:54:11,575]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:54:25,330]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:54:30,038]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:54:34,758]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:54:46,290]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:54:49,566]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:55:01,095]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:55:08,063]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:55:11,271]\u001b[0m Trial 1393 finished with value: 5.463335628646045 and parameters: {'n_hidden': 3, 'learning_rate': 0.000623402119147821, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05276545670100525, 'dropout_rate_Layer_2': 0.2615832527696514, 'dropout_rate_Layer_3': 0.282250854179912, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0599268798581493e-05, 'l1_Layer_2': 0.0022153332506936016, 'l1_Layer_3': 1.4937425745454005e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 250, 'n_units_Layer_3': 105}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 16.62% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.62 | sMAPE for Test Set is: 41.53% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:55:18,120]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:55:18,507]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:55:26,108]\u001b[0m Trial 1398 finished with value: 5.568024786606403 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005504683105025267, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.032964712168018453, 'dropout_rate_Layer_2': 0.2855241440002693, 'dropout_rate_Layer_3': 0.2552565786173834, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.272734070841897e-05, 'l1_Layer_2': 0.002828128269778153, 'l1_Layer_3': 1.0093262544728747e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 90}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 16.60% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.39 | sMAPE for Test Set is: 44.40% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:55:28,635]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:55:36,087]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:55:42,783]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:55:43,757]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:55:44,239]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:55:53,288]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:55:56,616]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:55:57,162]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:56:07,037]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:56:14,022]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:56:16,824]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:56:22,824]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:56:23,734]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:56:30,361]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:56:33,755]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:56:40,089]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:56:45,924]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:56:49,324]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:56:51,288]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:56:56,496]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:57:01,793]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:57:05,809]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:57:08,454]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:57:12,655]\u001b[0m Trial 1416 finished with value: 5.549549072492501 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006207665890891037, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07707093852997496, 'dropout_rate_Layer_2': 0.2825302759937199, 'dropout_rate_Layer_3': 0.26163988269605987, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0062702530253763e-05, 'l1_Layer_2': 0.0027137087214774342, 'l1_Layer_3': 1.4050967213042177e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 260, 'n_units_Layer_3': 115}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 16.68% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.69 | sMAPE for Test Set is: 41.90% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:57:15,664]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:57:15,919]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:57:20,619]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:57:28,792]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:57:31,198]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:57:37,178]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:57:38,116]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:57:43,638]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:57:46,905]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:57:51,347]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:57:51,641]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:57:58,040]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:57:58,680]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:58:01,699]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:58:04,669]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:58:05,253]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:58:13,455]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:58:19,676]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:58:22,778]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:58:23,504]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:58:29,937]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:58:36,245]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:58:37,262]\u001b[0m Trial 1443 finished with value: 5.773799195618158 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017052587952633988, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38129896972411087, 'dropout_rate_Layer_2': 0.09928674264200471, 'dropout_rate_Layer_3': 0.20673959448515225, 'dropout_rate_Layer_4': 0.018297454018411423, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 4.6093446908777875e-05, 'l1_Layer_2': 0.0017497382318321787, 'l1_Layer_3': 0.01186819031951098, 'l1_Layer_4': 3.667412117664749e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 200, 'n_units_Layer_3': 280, 'n_units_Layer_4': 225}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 17.24% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.82 | sMAPE for Test Set is: 48.44% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:58:43,938]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:58:44,245]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:58:54,546]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:58:59,933]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:59:13,125]\u001b[0m Trial 1452 finished with value: 5.809868729989177 and parameters: {'n_hidden': 4, 'learning_rate': 0.0029164605897116515, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36307111354448873, 'dropout_rate_Layer_2': 0.11426449245530614, 'dropout_rate_Layer_3': 0.20727030791691664, 'dropout_rate_Layer_4': 0.040161172561933925, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 5.0901275598436704e-05, 'l1_Layer_2': 0.0015729499643604267, 'l1_Layer_3': 0.011233120535382547, 'l1_Layer_4': 0.00031016880203690135, 'n_units_Layer_1': 70, 'n_units_Layer_2': 195, 'n_units_Layer_3': 245, 'n_units_Layer_4': 280}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 17.37% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 11.62 | sMAPE for Test Set is: 47.97% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:59:15,670]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:59:20,221]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:59:21,294]\u001b[0m Trial 1457 finished with value: 5.798957405116972 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018260841341323799, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36403794030370124, 'dropout_rate_Layer_2': 0.1025470960698554, 'dropout_rate_Layer_3': 0.20733020555748408, 'dropout_rate_Layer_4': 0.02223314633962538, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.8840179805095524e-05, 'l1_Layer_2': 0.00106086700450646, 'l1_Layer_3': 0.019999354686448992, 'l1_Layer_4': 2.6056845646023746e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 200, 'n_units_Layer_3': 50, 'n_units_Layer_4': 280}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 17.23% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.69 | sMAPE for Test Set is: 48.16% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 01:59:25,092]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:59:30,853]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:59:33,962]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:59:39,062]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:59:42,007]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:59:49,122]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 01:59:49,765]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:00:00,179]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:00:07,946]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:00:09,077]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:00:12,833]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:00:17,364]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:00:18,077]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:00:26,333]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:00:32,382]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:00:38,542]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:01:24,620]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:01:25,184]\u001b[0m Trial 1477 finished with value: 5.159172106921895 and parameters: {'n_hidden': 3, 'learning_rate': 0.004652999780582502, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06408994895875056, 'dropout_rate_Layer_2': 0.35570032159428744, 'dropout_rate_Layer_3': 0.16271254100695223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009632189739305468, 'l1_Layer_2': 0.01682031356225755, 'l1_Layer_3': 1.7442972026126266e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 165, 'n_units_Layer_3': 150}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 15.85% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.95 | sMAPE for Test Set is: 42.18% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 02:01:35,583]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 15.84% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.49 | sMAPE for Test Set is: 43.91% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 02:01:39,085]\u001b[0m Trial 1474 finished with value: 5.19920708757317 and parameters: {'n_hidden': 3, 'learning_rate': 0.0052763521359059755, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11890641194509043, 'dropout_rate_Layer_2': 0.3594794220099148, 'dropout_rate_Layer_3': 0.11375914318369115, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7421977919818763e-05, 'l1_Layer_2': 0.01841499415125041, 'l1_Layer_3': 7.413724591087453e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 165, 'n_units_Layer_3': 150}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:01:42,535]\u001b[0m Trial 1460 finished with value: 5.382972502488664 and parameters: {'n_hidden': 3, 'learning_rate': 0.014978464110126476, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26182584324931324, 'dropout_rate_Layer_2': 0.17230480644742335, 'dropout_rate_Layer_3': 0.05633531801003701, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.3951350125651847e-05, 'l1_Layer_2': 0.001086897442409557, 'l1_Layer_3': 0.005511672259362726, 'n_units_Layer_1': 200, 'n_units_Layer_2': 65, 'n_units_Layer_3': 75}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 16.40% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.54 | sMAPE for Test Set is: 44.37% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 02:01:46,970]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:01:50,919]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:01:54,990]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:02:00,557]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:02:00,607]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:02:09,373]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:02:10,160]\u001b[0m Trial 1479 finished with value: 5.824244122922532 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017633404804372741, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3617952735252567, 'dropout_rate_Layer_2': 0.09166705955843182, 'dropout_rate_Layer_3': 0.2340663865639409, 'dropout_rate_Layer_4': 0.045774376640599065, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.5490984465083975e-05, 'l1_Layer_2': 0.0017086644814508977, 'l1_Layer_3': 0.019027189613532076, 'l1_Layer_4': 3.3791069030732454e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 195, 'n_units_Layer_3': 260, 'n_units_Layer_4': 265}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 17.32% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 11.91 | sMAPE for Test Set is: 48.74% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 02:02:11,401]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:02:15,002]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:02:20,832]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:02:22,917]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:02:26,707]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:02:34,260]\u001b[0m Trial 1488 finished with value: 5.778005034182104 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023037331698136498, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3575269376644148, 'dropout_rate_Layer_2': 0.0880815189561665, 'dropout_rate_Layer_3': 0.22754493255371241, 'dropout_rate_Layer_4': 0.044552909055695214, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.031061041682639e-05, 'l1_Layer_2': 0.0016352506617503127, 'l1_Layer_3': 0.01895635020928421, 'l1_Layer_4': 3.9198654869338166e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 185, 'n_units_Layer_3': 265, 'n_units_Layer_4': 240}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 17.26% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.46 | sMAPE for Test Set is: 47.62% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 02:02:39,704]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:02:55,156]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:03:02,320]\u001b[0m Trial 1492 finished with value: 5.655422070568057 and parameters: {'n_hidden': 3, 'learning_rate': 0.016656127497680896, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2983580897025075, 'dropout_rate_Layer_2': 0.39998590472412204, 'dropout_rate_Layer_3': 0.06432945062139792, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.3697718971064993e-05, 'l1_Layer_2': 0.0010148268210299401, 'l1_Layer_3': 0.006965724035027549, 'n_units_Layer_1': 200, 'n_units_Layer_2': 70, 'n_units_Layer_3': 60}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:03:02,442]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 16.75% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.51 | sMAPE for Test Set is: 47.59% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 02:03:11,282]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:03:12,353]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:03:16,050]\u001b[0m Trial 1493 finished with value: 5.482599363720159 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006080670928136925, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03961779542130355, 'dropout_rate_Layer_2': 0.28557026404679947, 'dropout_rate_Layer_3': 0.26683373012015776, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.567167112045181e-05, 'l1_Layer_2': 0.003274424128877968, 'l1_Layer_3': 1.173515293159636e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 250, 'n_units_Layer_3': 120}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 02:03:16,056]\u001b[0m Trial 1494 finished with value: 5.575321233724305 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005980849044859327, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.039012388265242434, 'dropout_rate_Layer_2': 0.2858374794856463, 'dropout_rate_Layer_3': 0.2655141505172372, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3301062972627136e-05, 'l1_Layer_2': 0.0033388195421096387, 'l1_Layer_3': 1.1771215114444674e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 250, 'n_units_Layer_3': 120}. Best is trial 1155 with value: 5.006350356870552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 16.77% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.81 | sMAPE for Test Set is: 42.45% | rMAE for Test Set is: 0.74\n",
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 16.96% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.77 | sMAPE for Test Set is: 42.17% | rMAE for Test Set is: 0.74\n",
      "for 2020-01-01, MAE is:4.88 & sMAPE is:17.56% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 17.56% & 1.21\n",
      "for 2020-01-02, MAE is:3.11 & sMAPE is:8.40% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 12.98% & 0.89\n",
      "for 2020-01-03, MAE is:8.73 & sMAPE is:44.36% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.57 & 23.44% & 0.82\n",
      "for 2020-01-04, MAE is:8.63 & sMAPE is:50.68% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 30.25% & 0.76\n",
      "for 2020-01-05, MAE is:4.46 & sMAPE is:14.39% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 27.08% & 0.79\n",
      "for 2020-01-06, MAE is:5.73 & sMAPE is:16.35% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 25.29% & 0.82\n",
      "for 2020-01-07, MAE is:5.12 & sMAPE is:15.07% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.81 & 23.83% & 0.78\n",
      "for 2020-01-08, MAE is:6.82 & sMAPE is:40.90% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 25.96% & 0.78\n",
      "for 2020-01-09, MAE is:4.54 & sMAPE is:13.36% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 24.56% & 0.78\n",
      "for 2020-01-10, MAE is:4.36 & sMAPE is:12.61% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 23.37% & 0.75\n",
      "for 2020-01-11, MAE is:3.98 & sMAPE is:14.74% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 22.58% & 0.71\n",
      "for 2020-01-12, MAE is:3.25 & sMAPE is:13.66% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 21.84% & 0.68\n",
      "for 2020-01-13, MAE is:7.41 & sMAPE is:20.75% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 21.76% & 0.70\n",
      "for 2020-01-14, MAE is:10.03 & sMAPE is:36.17% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 22.79% & 0.71\n",
      "for 2020-01-15, MAE is:4.12 & sMAPE is:30.78% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 23.32% & 0.73\n",
      "for 2020-01-16, MAE is:6.71 & sMAPE is:22.19% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 23.25% & 0.73\n",
      "for 2020-01-17, MAE is:5.45 & sMAPE is:18.49% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 22.97% & 0.74\n",
      "for 2020-01-18, MAE is:2.47 & sMAPE is:10.04% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 22.25% & 0.75\n",
      "for 2020-01-19, MAE is:6.53 & sMAPE is:22.44% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 22.26% & 0.75\n",
      "for 2020-01-20, MAE is:7.48 & sMAPE is:22.07% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.69 & 22.25% & 0.79\n",
      "for 2020-01-21, MAE is:8.37 & sMAPE is:30.24% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 22.63% & 0.84\n",
      "for 2020-01-22, MAE is:20.73 & sMAPE is:65.63% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 24.59% & 0.85\n",
      "for 2020-01-23, MAE is:12.32 & sMAPE is:36.22% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 25.09% & 0.85\n",
      "for 2020-01-24, MAE is:5.73 & sMAPE is:23.72% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 25.03% & 0.85\n",
      "for 2020-01-25, MAE is:7.06 & sMAPE is:33.64% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 25.38% & 0.87\n",
      "for 2020-01-26, MAE is:4.50 & sMAPE is:20.06% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 25.17% & 0.86\n",
      "for 2020-01-27, MAE is:7.41 & sMAPE is:28.82% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 25.31% & 0.84\n",
      "for 2020-01-28, MAE is:3.93 & sMAPE is:14.15% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 24.91% & 0.84\n",
      "for 2020-01-29, MAE is:6.54 & sMAPE is:25.78% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 24.94% & 0.82\n",
      "for 2020-01-30, MAE is:4.09 & sMAPE is:17.00% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 24.68% & 0.80\n",
      "for 2020-01-31, MAE is:3.81 & sMAPE is:17.69% & rMAE is:3.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 24.45% & 0.88\n",
      "for 2020-02-01, MAE is:13.97 & sMAPE is:111.36% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 27.17% & 0.88\n",
      "for 2020-02-02, MAE is:5.32 & sMAPE is:41.77% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 27.61% & 0.86\n",
      "for 2020-02-03, MAE is:4.69 & sMAPE is:18.83% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 27.35% & 0.86\n",
      "for 2020-02-04, MAE is:4.33 & sMAPE is:15.03% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 27.00% & 0.86\n",
      "for 2020-02-05, MAE is:8.95 & sMAPE is:38.66% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 27.32% & 0.88\n",
      "for 2020-02-06, MAE is:7.03 & sMAPE is:27.70% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 27.33% & 0.88\n",
      "for 2020-02-07, MAE is:6.56 & sMAPE is:21.79% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 27.19% & 0.87\n",
      "for 2020-02-08, MAE is:9.00 & sMAPE is:48.37% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 27.73% & 0.88\n",
      "for 2020-02-09, MAE is:10.93 & sMAPE is:81.14% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 29.06% & 0.88\n",
      "for 2020-02-10, MAE is:10.52 & sMAPE is:96.08% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 30.70% & 0.87\n",
      "for 2020-02-11, MAE is:7.39 & sMAPE is:69.33% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 31.62% & 0.86\n",
      "for 2020-02-12, MAE is:6.78 & sMAPE is:43.19% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 31.89% & 0.86\n",
      "for 2020-02-13, MAE is:13.10 & sMAPE is:42.61% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 32.13% & 0.87\n",
      "for 2020-02-14, MAE is:7.76 & sMAPE is:26.87% & rMAE is:2.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 32.01% & 0.91\n",
      "for 2020-02-15, MAE is:9.75 & sMAPE is:61.04% & rMAE is:3.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 32.65% & 0.96\n",
      "for 2020-02-16, MAE is:8.79 & sMAPE is:71.29% & rMAE is:3.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 33.47% & 1.02\n",
      "for 2020-02-17, MAE is:10.83 & sMAPE is:73.84% & rMAE is:3.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 34.31% & 1.07\n",
      "for 2020-02-18, MAE is:7.41 & sMAPE is:41.37% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 34.45% & 1.08\n",
      "for 2020-02-19, MAE is:7.08 & sMAPE is:24.75% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 34.26% & 1.07\n",
      "for 2020-02-20, MAE is:13.53 & sMAPE is:66.84% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 34.90% & 1.06\n",
      "for 2020-02-21, MAE is:5.88 & sMAPE is:54.09% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 35.27% & 1.05\n",
      "for 2020-02-22, MAE is:10.45 & sMAPE is:81.07% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 36.13% & 1.07\n",
      "for 2020-02-23, MAE is:10.93 & sMAPE is:74.08% & rMAE is:12.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 36.83% & 1.28\n",
      "for 2020-02-24, MAE is:15.69 & sMAPE is:78.32% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 37.59% & 1.27\n",
      "for 2020-02-25, MAE is:5.57 & sMAPE is:29.60% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 37.45% & 1.27\n",
      "for 2020-02-26, MAE is:9.29 & sMAPE is:48.85% & rMAE is:3.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 37.65% & 1.31\n",
      "for 2020-02-27, MAE is:14.53 & sMAPE is:35.65% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 37.61% & 1.30\n",
      "for 2020-02-28, MAE is:4.67 & sMAPE is:14.45% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 37.22% & 1.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-02-29, MAE is:13.92 & sMAPE is:73.56% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 37.82% & 1.30\n",
      "for 2020-03-01, MAE is:8.97 & sMAPE is:56.39% & rMAE is:3.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 38.13% & 1.34\n",
      "for 2020-03-02, MAE is:7.49 & sMAPE is:27.92% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 37.96% & 1.33\n",
      "for 2020-03-03, MAE is:5.11 & sMAPE is:13.54% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 37.58% & 1.32\n",
      "for 2020-03-04, MAE is:9.26 & sMAPE is:24.24% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 37.37% & 1.31\n",
      "for 2020-03-05, MAE is:4.33 & sMAPE is:11.70% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 36.97% & 1.30\n",
      "for 2020-03-06, MAE is:6.12 & sMAPE is:23.52% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 36.77% & 1.29\n",
      "for 2020-03-07, MAE is:5.65 & sMAPE is:21.45% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 36.54% & 1.28\n",
      "for 2020-03-08, MAE is:10.22 & sMAPE is:66.22% & rMAE is:3.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 36.98% & 1.31\n",
      "for 2020-03-09, MAE is:11.92 & sMAPE is:37.18% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 36.98% & 1.32\n",
      "for 2020-03-10, MAE is:19.49 & sMAPE is:89.86% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.88 & 37.74% & 1.31\n",
      "for 2020-03-11, MAE is:9.80 & sMAPE is:76.23% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 38.28% & 1.30\n",
      "for 2020-03-12, MAE is:11.17 & sMAPE is:108.89% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 39.26% & 1.29\n",
      "for 2020-03-13, MAE is:13.67 & sMAPE is:88.08% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 39.93% & 1.28\n",
      "for 2020-03-14, MAE is:9.19 & sMAPE is:42.04% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.04 & 39.96% & 1.29\n",
      "for 2020-03-15, MAE is:11.79 & sMAPE is:92.60% & rMAE is:2.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 40.66% & 1.31\n",
      "for 2020-03-16, MAE is:8.71 & sMAPE is:38.81% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.10 & 40.63% & 1.30\n",
      "for 2020-03-17, MAE is:14.42 & sMAPE is:69.90% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 41.01% & 1.31\n",
      "for 2020-03-18, MAE is:9.47 & sMAPE is:64.07% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :8.20 & 41.31% & 1.31\n",
      "for 2020-03-19, MAE is:9.37 & sMAPE is:53.93% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 41.47% & 1.31\n",
      "for 2020-03-20, MAE is:7.24 & sMAPE is:38.66% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :8.20 & 41.43% & 1.30\n",
      "for 2020-03-21, MAE is:7.51 & sMAPE is:52.10% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.20 & 41.57% & 1.29\n",
      "for 2020-03-22, MAE is:5.50 & sMAPE is:49.91% & rMAE is:2.28 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 41.67% & 1.30\n",
      "for 2020-03-23, MAE is:5.09 & sMAPE is:32.10% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :8.13 & 41.55% & 1.29\n",
      "for 2020-03-24, MAE is:4.65 & sMAPE is:22.74% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.08 & 41.33% & 1.28\n",
      "for 2020-03-25, MAE is:4.24 & sMAPE is:18.83% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.04 & 41.06% & 1.27\n",
      "for 2020-03-26, MAE is:3.89 & sMAPE is:16.95% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 40.78% & 1.26\n",
      "for 2020-03-27, MAE is:4.06 & sMAPE is:17.84% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 40.52% & 1.25\n",
      "for 2020-03-28, MAE is:8.14 & sMAPE is:61.54% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 40.76% & 1.26\n",
      "for 2020-03-29, MAE is:11.48 & sMAPE is:111.06% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 41.55% & 1.26\n",
      "for 2020-03-30, MAE is:5.38 & sMAPE is:23.62% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 41.35% & 1.26\n",
      "for 2020-03-31, MAE is:6.67 & sMAPE is:28.37% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 41.21% & 1.25\n",
      "for 2020-04-01, MAE is:5.52 & sMAPE is:42.11% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 41.22% & 1.25\n",
      "for 2020-04-02, MAE is:7.87 & sMAPE is:59.61% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 41.41% & 1.24\n",
      "for 2020-04-03, MAE is:6.31 & sMAPE is:57.35% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 41.58% & 1.23\n",
      "for 2020-04-04, MAE is:5.31 & sMAPE is:26.67% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.87 & 41.43% & 1.23\n",
      "for 2020-04-05, MAE is:14.67 & sMAPE is:104.84% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 42.09% & 1.24\n",
      "for 2020-04-06, MAE is:6.32 & sMAPE is:62.35% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 42.30% & 1.24\n",
      "for 2020-04-07, MAE is:6.10 & sMAPE is:26.72% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 42.14% & 1.25\n",
      "for 2020-04-08, MAE is:6.37 & sMAPE is:23.47% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.89 & 41.95% & 1.24\n",
      "for 2020-04-09, MAE is:3.93 & sMAPE is:18.31% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 41.71% & 1.23\n",
      "for 2020-04-10, MAE is:6.46 & sMAPE is:31.19% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 41.61% & 1.22\n",
      "for 2020-04-11, MAE is:6.67 & sMAPE is:35.93% & rMAE is:2.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.83 & 41.55% & 1.24\n",
      "for 2020-04-12, MAE is:8.97 & sMAPE is:74.36% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 41.87% & 1.24\n",
      "for 2020-04-13, MAE is:23.50 & sMAPE is:165.10% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 43.06% & 1.24\n",
      "for 2020-04-14, MAE is:7.07 & sMAPE is:60.13% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 43.22% & 1.24\n",
      "for 2020-04-15, MAE is:9.90 & sMAPE is:80.48% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 43.57% & 1.23\n",
      "for 2020-04-16, MAE is:7.13 & sMAPE is:34.42% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 43.48% & 1.23\n",
      "for 2020-04-17, MAE is:6.67 & sMAPE is:23.28% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 43.30% & 1.23\n",
      "for 2020-04-18, MAE is:4.06 & sMAPE is:21.25% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 43.10% & 1.23\n",
      "for 2020-04-19, MAE is:7.13 & sMAPE is:50.92% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 43.17% & 1.23\n",
      "for 2020-04-20, MAE is:12.37 & sMAPE is:87.94% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 43.57% & 1.23\n",
      "for 2020-04-21, MAE is:11.26 & sMAPE is:78.85% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 43.88% & 1.22\n",
      "for 2020-04-22, MAE is:6.91 & sMAPE is:53.75% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 43.97% & 1.22\n",
      "for 2020-04-23, MAE is:8.94 & sMAPE is:33.98% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 43.88% & 1.22\n",
      "for 2020-04-24, MAE is:7.10 & sMAPE is:34.64% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 43.80% & 1.22\n",
      "for 2020-04-25, MAE is:4.74 & sMAPE is:33.98% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 43.72% & 1.22\n",
      "for 2020-04-26, MAE is:5.52 & sMAPE is:32.06% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 43.62% & 1.21\n",
      "for 2020-04-27, MAE is:5.28 & sMAPE is:19.40% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 43.41% & 1.21\n",
      "for 2020-04-28, MAE is:3.63 & sMAPE is:13.61% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.89 & 43.16% & 1.20\n",
      "for 2020-04-29, MAE is:3.16 & sMAPE is:15.11% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 42.93% & 1.19\n",
      "for 2020-04-30, MAE is:4.79 & sMAPE is:29.56% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 42.82% & 1.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-05-01, MAE is:10.84 & sMAPE is:84.50% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 43.16% & 1.18\n",
      "for 2020-05-02, MAE is:5.79 & sMAPE is:42.93% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.83 & 43.16% & 1.18\n",
      "for 2020-05-03, MAE is:7.46 & sMAPE is:57.75% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.83 & 43.28% & 1.18\n",
      "for 2020-05-04, MAE is:6.40 & sMAPE is:32.75% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 43.19% & 1.18\n",
      "for 2020-05-05, MAE is:3.03 & sMAPE is:14.34% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 42.96% & 1.17\n",
      "for 2020-05-06, MAE is:2.26 & sMAPE is:10.75% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 42.71% & 1.17\n",
      "for 2020-05-07, MAE is:5.89 & sMAPE is:23.81% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 42.56% & 1.17\n",
      "for 2020-05-08, MAE is:8.15 & sMAPE is:38.76% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 42.53% & 1.16\n",
      "for 2020-05-09, MAE is:3.95 & sMAPE is:18.20% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 42.35% & 1.16\n",
      "for 2020-05-10, MAE is:9.30 & sMAPE is:55.39% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 42.45% & 1.16\n",
      "for 2020-05-11, MAE is:7.64 & sMAPE is:66.44% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 42.63% & 1.16\n",
      "for 2020-05-12, MAE is:4.10 & sMAPE is:21.37% & rMAE is:2.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 42.47% & 1.17\n",
      "for 2020-05-13, MAE is:8.30 & sMAPE is:29.31% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 42.37% & 1.17\n",
      "for 2020-05-14, MAE is:4.35 & sMAPE is:16.70% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 42.18% & 1.17\n",
      "for 2020-05-15, MAE is:2.02 & sMAPE is:9.61% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 41.94% & 1.16\n",
      "for 2020-05-16, MAE is:6.64 & sMAPE is:45.75% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 41.97% & 1.16\n",
      "for 2020-05-17, MAE is:9.38 & sMAPE is:77.61% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 42.23% & 1.16\n",
      "for 2020-05-18, MAE is:7.03 & sMAPE is:40.41% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 42.21% & 1.16\n",
      "for 2020-05-19, MAE is:5.69 & sMAPE is:25.17% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 42.09% & 1.16\n",
      "for 2020-05-20, MAE is:13.35 & sMAPE is:38.51% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 42.07% & 1.17\n",
      "for 2020-05-21, MAE is:6.85 & sMAPE is:31.68% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 41.99% & 1.17\n",
      "for 2020-05-22, MAE is:3.57 & sMAPE is:21.11% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 41.85% & 1.17\n",
      "for 2020-05-23, MAE is:8.78 & sMAPE is:65.52% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 42.01% & 1.17\n",
      "for 2020-05-24, MAE is:18.61 & sMAPE is:167.91% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 42.88% & 1.17\n",
      "for 2020-05-25, MAE is:5.00 & sMAPE is:56.80% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 42.97% & 1.17\n",
      "for 2020-05-26, MAE is:16.12 & sMAPE is:54.65% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 43.05% & 1.17\n",
      "for 2020-05-27, MAE is:7.12 & sMAPE is:24.16% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 42.93% & 1.17\n",
      "for 2020-05-28, MAE is:8.28 & sMAPE is:35.49% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 42.88% & 1.17\n",
      "for 2020-05-29, MAE is:3.83 & sMAPE is:16.80% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 42.70% & 1.17\n",
      "for 2020-05-30, MAE is:7.21 & sMAPE is:51.47% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 42.76% & 1.17\n",
      "for 2020-05-31, MAE is:9.57 & sMAPE is:101.74% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 43.15% & 1.17\n",
      "for 2020-06-01, MAE is:5.69 & sMAPE is:53.19% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 43.21% & 1.17\n",
      "for 2020-06-02, MAE is:14.12 & sMAPE is:45.49% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 43.23% & 1.17\n",
      "for 2020-06-03, MAE is:5.51 & sMAPE is:15.08% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 43.05% & 1.17\n",
      "for 2020-06-04, MAE is:5.50 & sMAPE is:19.68% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 42.90% & 1.17\n",
      "for 2020-06-05, MAE is:5.24 & sMAPE is:24.90% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 42.78% & 1.17\n",
      "for 2020-06-06, MAE is:11.04 & sMAPE is:117.63% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 43.26% & 1.17\n",
      "for 2020-06-07, MAE is:4.15 & sMAPE is:22.91% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 43.13% & 1.17\n",
      "for 2020-06-08, MAE is:12.70 & sMAPE is:51.26% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 43.18% & 1.16\n",
      "for 2020-06-09, MAE is:12.85 & sMAPE is:36.52% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.76 & 43.14% & 1.16\n",
      "for 2020-06-10, MAE is:3.01 & sMAPE is:9.49% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 42.93% & 1.16\n",
      "for 2020-06-11, MAE is:5.04 & sMAPE is:18.81% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 42.78% & 1.16\n",
      "for 2020-06-12, MAE is:4.70 & sMAPE is:25.19% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 42.67% & 1.16\n",
      "for 2020-06-13, MAE is:2.26 & sMAPE is:12.29% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 42.49% & 1.15\n",
      "for 2020-06-14, MAE is:4.53 & sMAPE is:30.75% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 42.42% & 1.15\n",
      "for 2020-06-15, MAE is:6.05 & sMAPE is:20.24% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 42.29% & 1.16\n",
      "for 2020-06-16, MAE is:2.81 & sMAPE is:8.16% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 42.08% & 1.15\n",
      "for 2020-06-17, MAE is:13.52 & sMAPE is:36.87% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 42.05% & 1.16\n",
      "for 2020-06-18, MAE is:9.72 & sMAPE is:23.52% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 41.94% & 1.15\n",
      "for 2020-06-19, MAE is:2.70 & sMAPE is:8.83% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 41.75% & 1.15\n",
      "for 2020-06-20, MAE is:3.64 & sMAPE is:15.30% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 41.60% & 1.15\n",
      "for 2020-06-21, MAE is:8.07 & sMAPE is:40.21% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 41.59% & 1.15\n",
      "for 2020-06-22, MAE is:10.16 & sMAPE is:25.73% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 41.50% & 1.15\n",
      "for 2020-06-23, MAE is:20.24 & sMAPE is:46.48% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 41.53% & 1.15\n",
      "for 2020-06-24, MAE is:8.53 & sMAPE is:19.61% & rMAE is:2.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 41.40% & 1.16\n",
      "for 2020-06-25, MAE is:23.96 & sMAPE is:35.51% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 41.37% & 1.16\n",
      "for 2020-06-26, MAE is:12.95 & sMAPE is:25.27% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 41.28% & 1.15\n",
      "for 2020-06-27, MAE is:4.28 & sMAPE is:11.13% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 41.11% & 1.15\n",
      "for 2020-06-28, MAE is:6.21 & sMAPE is:25.94% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 41.03% & 1.15\n",
      "for 2020-06-29, MAE is:4.90 & sMAPE is:17.32% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 40.89% & 1.14\n",
      "for 2020-06-30, MAE is:14.88 & sMAPE is:86.28% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.81 & 41.14% & 1.14\n",
      "for 2020-07-01, MAE is:12.63 & sMAPE is:83.38% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 41.37% & 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-07-02, MAE is:7.47 & sMAPE is:20.71% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 41.26% & 1.13\n",
      "for 2020-07-03, MAE is:5.21 & sMAPE is:15.26% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 41.12% & 1.13\n",
      "for 2020-07-04, MAE is:13.40 & sMAPE is:118.38% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 41.54% & 1.13\n",
      "for 2020-07-05, MAE is:18.15 & sMAPE is:173.01% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 42.24% & 1.12\n",
      "for 2020-07-06, MAE is:14.29 & sMAPE is:170.20% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 42.92% & 1.12\n",
      "for 2020-07-07, MAE is:7.21 & sMAPE is:75.64% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 43.09% & 1.12\n",
      "for 2020-07-08, MAE is:13.63 & sMAPE is:39.90% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 43.08% & 1.12\n",
      "for 2020-07-09, MAE is:3.90 & sMAPE is:9.69% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 42.90% & 1.12\n",
      "for 2020-07-10, MAE is:6.66 & sMAPE is:23.82% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 42.80% & 1.12\n",
      "for 2020-07-11, MAE is:7.57 & sMAPE is:52.59% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 42.85% & 1.12\n",
      "for 2020-07-12, MAE is:6.01 & sMAPE is:42.05% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 42.85% & 1.11\n",
      "for 2020-07-13, MAE is:11.49 & sMAPE is:44.49% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 42.86% & 1.11\n",
      "for 2020-07-14, MAE is:10.00 & sMAPE is:31.55% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 42.80% & 1.11\n",
      "for 2020-07-15, MAE is:8.45 & sMAPE is:22.15% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 42.70% & 1.11\n",
      "for 2020-07-16, MAE is:5.20 & sMAPE is:11.72% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 42.54% & 1.11\n",
      "for 2020-07-17, MAE is:2.63 & sMAPE is:7.23% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 42.36% & 1.11\n",
      "for 2020-07-18, MAE is:3.81 & sMAPE is:12.99% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 42.21% & 1.10\n",
      "for 2020-07-19, MAE is:3.52 & sMAPE is:12.58% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.88 & 42.07% & 1.10\n",
      "for 2020-07-20, MAE is:4.41 & sMAPE is:14.17% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 41.93% & 1.10\n",
      "for 2020-07-21, MAE is:10.10 & sMAPE is:50.53% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :7.87 & 41.97% & 1.09\n",
      "for 2020-07-22, MAE is:6.01 & sMAPE is:21.31% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 41.87% & 1.09\n",
      "for 2020-07-23, MAE is:5.12 & sMAPE is:14.86% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 41.74% & 1.09\n",
      "for 2020-07-24, MAE is:9.93 & sMAPE is:41.93% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 41.74% & 1.09\n",
      "for 2020-07-25, MAE is:4.55 & sMAPE is:18.64% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 41.63% & 1.09\n",
      "for 2020-07-26, MAE is:9.86 & sMAPE is:70.73% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 41.77% & 1.09\n",
      "for 2020-07-27, MAE is:8.22 & sMAPE is:30.00% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 41.71% & 1.09\n",
      "for 2020-07-28, MAE is:12.10 & sMAPE is:87.98% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.87 & 41.93% & 1.09\n",
      "for 2020-07-29, MAE is:17.40 & sMAPE is:168.01% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 42.53% & 1.09\n",
      "for 2020-07-30, MAE is:16.19 & sMAPE is:139.19% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 42.98% & 1.09\n",
      "for 2020-07-31, MAE is:14.14 & sMAPE is:45.53% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 43.00% & 1.09\n",
      "for 2020-08-01, MAE is:4.73 & sMAPE is:16.56% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 42.87% & 1.09\n",
      "for 2020-08-02, MAE is:8.23 & sMAPE is:35.63% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 42.84% & 1.09\n",
      "for 2020-08-03, MAE is:7.36 & sMAPE is:22.44% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 42.75% & 1.09\n",
      "for 2020-08-04, MAE is:6.29 & sMAPE is:17.89% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 42.63% & 1.09\n",
      "for 2020-08-05, MAE is:6.04 & sMAPE is:19.83% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 42.53% & 1.08\n",
      "for 2020-08-06, MAE is:5.48 & sMAPE is:16.11% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 42.41% & 1.08\n",
      "for 2020-08-07, MAE is:6.57 & sMAPE is:19.51% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 42.30% & 1.08\n",
      "for 2020-08-08, MAE is:7.11 & sMAPE is:24.23% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 42.22% & 1.08\n",
      "for 2020-08-09, MAE is:3.71 & sMAPE is:12.67% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 42.09% & 1.09\n",
      "for 2020-08-10, MAE is:9.90 & sMAPE is:26.83% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 42.02% & 1.09\n",
      "for 2020-08-11, MAE is:8.90 & sMAPE is:23.38% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 41.93% & 1.09\n",
      "for 2020-08-12, MAE is:15.68 & sMAPE is:37.25% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 41.91% & 1.09\n",
      "for 2020-08-13, MAE is:8.41 & sMAPE is:17.62% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 41.81% & 1.09\n",
      "for 2020-08-14, MAE is:3.44 & sMAPE is:7.72% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 41.66% & 1.09\n",
      "for 2020-08-15, MAE is:3.11 & sMAPE is:9.33% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 41.51% & 1.09\n",
      "for 2020-08-16, MAE is:5.43 & sMAPE is:19.77% & rMAE is:2.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 41.42% & 1.10\n",
      "for 2020-08-17, MAE is:19.82 & sMAPE is:42.80% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.96 & 41.43% & 1.10\n",
      "for 2020-08-18, MAE is:31.12 & sMAPE is:39.19% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :8.06 & 41.42% & 1.10\n",
      "for 2020-08-19, MAE is:17.46 & sMAPE is:28.39% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :8.10 & 41.36% & 1.10\n",
      "for 2020-08-20, MAE is:14.57 & sMAPE is:28.29% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.13 & 41.30% & 1.10\n",
      "for 2020-08-21, MAE is:12.51 & sMAPE is:26.50% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.15 & 41.24% & 1.11\n",
      "for 2020-08-22, MAE is:7.15 & sMAPE is:27.88% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.15 & 41.18% & 1.10\n",
      "for 2020-08-23, MAE is:5.73 & sMAPE is:27.00% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 41.12% & 1.10\n",
      "for 2020-08-24, MAE is:15.43 & sMAPE is:35.05% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :8.17 & 41.10% & 1.11\n",
      "for 2020-08-25, MAE is:13.44 & sMAPE is:25.43% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 41.03% & 1.11\n",
      "for 2020-08-26, MAE is:9.04 & sMAPE is:26.98% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 40.97% & 1.10\n",
      "for 2020-08-27, MAE is:13.89 & sMAPE is:30.64% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 40.93% & 1.10\n",
      "for 2020-08-28, MAE is:4.89 & sMAPE is:11.17% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :8.20 & 40.81% & 1.10\n",
      "for 2020-08-29, MAE is:4.00 & sMAPE is:11.30% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 40.68% & 1.10\n",
      "for 2020-08-30, MAE is:4.12 & sMAPE is:12.92% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :8.17 & 40.57% & 1.09\n",
      "for 2020-08-31, MAE is:18.91 & sMAPE is:37.57% & rMAE is:3.15 ||| daily mean of MAE & sMAPE & rMAE till now are :8.21 & 40.56% & 1.10\n",
      "for 2020-09-01, MAE is:5.44 & sMAPE is:10.13% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.20 & 40.43% & 1.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-09-02, MAE is:4.02 & sMAPE is:7.53% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.18 & 40.30% & 1.10\n",
      "for 2020-09-03, MAE is:5.63 & sMAPE is:12.95% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :8.17 & 40.19% & 1.10\n",
      "for 2020-09-04, MAE is:6.39 & sMAPE is:18.37% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.17 & 40.10% & 1.10\n",
      "for 2020-09-05, MAE is:4.79 & sMAPE is:14.59% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.15 & 40.00% & 1.10\n",
      "for 2020-09-06, MAE is:3.71 & sMAPE is:10.47% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 39.88% & 1.09\n",
      "for 2020-09-07, MAE is:7.78 & sMAPE is:18.85% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.13 & 39.80% & 1.09\n",
      "for 2020-09-08, MAE is:8.66 & sMAPE is:30.47% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 39.76% & 1.09\n",
      "for 2020-09-09, MAE is:8.89 & sMAPE is:28.80% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 39.72% & 1.09\n",
      "for 2020-09-10, MAE is:17.06 & sMAPE is:46.85% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.17 & 39.74% & 1.09\n",
      "for 2020-09-11, MAE is:9.98 & sMAPE is:22.14% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :8.18 & 39.68% & 1.09\n",
      "for 2020-09-12, MAE is:3.26 & sMAPE is:11.21% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 39.56% & 1.09\n",
      "for 2020-09-13, MAE is:7.67 & sMAPE is:41.44% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 39.57% & 1.08\n",
      "for 2020-09-14, MAE is:22.77 & sMAPE is:56.11% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 39.64% & 1.09\n",
      "for 2020-09-15, MAE is:30.39 & sMAPE is:44.05% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.30 & 39.65% & 1.09\n",
      "for 2020-09-16, MAE is:11.67 & sMAPE is:22.08% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :8.32 & 39.59% & 1.08\n",
      "for 2020-09-17, MAE is:9.68 & sMAPE is:30.04% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :8.32 & 39.55% & 1.09\n",
      "for 2020-09-18, MAE is:6.78 & sMAPE is:17.08% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :8.31 & 39.46% & 1.09\n",
      "for 2020-09-19, MAE is:7.82 & sMAPE is:23.14% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :8.31 & 39.40% & 1.09\n",
      "for 2020-09-20, MAE is:8.70 & sMAPE is:25.99% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.31 & 39.35% & 1.08\n",
      "for 2020-09-21, MAE is:22.82 & sMAPE is:36.58% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 39.34% & 1.09\n",
      "for 2020-09-22, MAE is:9.77 & sMAPE is:19.81% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 39.27% & 1.09\n",
      "for 2020-09-23, MAE is:10.21 & sMAPE is:28.85% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.38 & 39.23% & 1.08\n",
      "for 2020-09-24, MAE is:11.76 & sMAPE is:53.60% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 39.28% & 1.08\n",
      "for 2020-09-25, MAE is:12.36 & sMAPE is:61.05% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :8.41 & 39.36% & 1.08\n",
      "for 2020-09-26, MAE is:8.14 & sMAPE is:80.15% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :8.41 & 39.51% & 1.08\n",
      "for 2020-09-27, MAE is:7.26 & sMAPE is:92.97% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 39.71% & 1.08\n",
      "for 2020-09-28, MAE is:23.32 & sMAPE is:70.89% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 39.83% & 1.08\n",
      "for 2020-09-29, MAE is:20.13 & sMAPE is:37.85% & rMAE is:2.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 39.82% & 1.08\n",
      "for 2020-09-30, MAE is:8.61 & sMAPE is:19.19% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 39.74% & 1.08\n",
      "for 2020-10-01, MAE is:7.42 & sMAPE is:24.25% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 39.69% & 1.08\n",
      "for 2020-10-02, MAE is:6.90 & sMAPE is:42.47% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 39.70% & 1.07\n",
      "for 2020-10-03, MAE is:5.19 & sMAPE is:80.65% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 39.84% & 1.08\n",
      "for 2020-10-04, MAE is:8.02 & sMAPE is:100.84% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 40.06% & 1.08\n",
      "for 2020-10-05, MAE is:10.36 & sMAPE is:41.59% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 40.07% & 1.08\n",
      "for 2020-10-06, MAE is:6.26 & sMAPE is:22.28% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 40.01% & 1.08\n",
      "for 2020-10-07, MAE is:11.61 & sMAPE is:43.94% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 40.02% & 1.07\n",
      "for 2020-10-08, MAE is:7.10 & sMAPE is:32.39% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 39.99% & 1.07\n",
      "for 2020-10-09, MAE is:17.64 & sMAPE is:78.42% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :8.52 & 40.13% & 1.08\n",
      "for 2020-10-10, MAE is:9.07 & sMAPE is:51.41% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :8.52 & 40.17% & 1.07\n",
      "for 2020-10-11, MAE is:12.31 & sMAPE is:51.43% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.53 & 40.21% & 1.07\n",
      "for 2020-10-12, MAE is:10.94 & sMAPE is:23.84% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :8.54 & 40.15% & 1.07\n",
      "for 2020-10-13, MAE is:14.92 & sMAPE is:31.23% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :8.56 & 40.12% & 1.07\n",
      "for 2020-10-14, MAE is:8.58 & sMAPE is:34.81% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :8.56 & 40.10% & 1.07\n",
      "for 2020-10-15, MAE is:15.53 & sMAPE is:60.91% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 40.17% & 1.07\n",
      "for 2020-10-16, MAE is:16.12 & sMAPE is:42.71% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.61 & 40.18% & 1.07\n",
      "for 2020-10-17, MAE is:11.06 & sMAPE is:36.67% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :8.62 & 40.17% & 1.07\n",
      "for 2020-10-18, MAE is:6.47 & sMAPE is:54.46% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :8.61 & 40.22% & 1.07\n",
      "for 2020-10-19, MAE is:16.69 & sMAPE is:60.59% & rMAE is:2.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 40.29% & 1.07\n",
      "for 2020-10-20, MAE is:7.76 & sMAPE is:24.10% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 40.23% & 1.07\n",
      "for 2020-10-21, MAE is:10.63 & sMAPE is:39.56% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 40.23% & 1.07\n",
      "for 2020-10-22, MAE is:4.44 & sMAPE is:37.29% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.63 & 40.22% & 1.07\n",
      "for 2020-10-23, MAE is:22.28 & sMAPE is:97.23% & rMAE is:2.80 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 40.41% & 1.07\n",
      "for 2020-10-24, MAE is:3.58 & sMAPE is:17.07% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 40.33% & 1.07\n",
      "for 2020-10-25, MAE is:8.89 & sMAPE is:70.72% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 40.44% & 1.07\n",
      "for 2020-10-26, MAE is:8.90 & sMAPE is:35.63% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 40.42% & 1.07\n",
      "for 2020-10-27, MAE is:8.36 & sMAPE is:41.70% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 40.42% & 1.07\n",
      "for 2020-10-28, MAE is:8.29 & sMAPE is:61.04% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 40.49% & 1.07\n",
      "for 2020-10-29, MAE is:15.68 & sMAPE is:59.62% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 40.56% & 1.06\n",
      "for 2020-10-30, MAE is:9.76 & sMAPE is:46.58% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 40.58% & 1.06\n",
      "for 2020-10-31, MAE is:14.87 & sMAPE is:83.95% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :8.70 & 40.72% & 1.06\n",
      "for 2020-11-01, MAE is:8.32 & sMAPE is:99.21% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.70 & 40.91% & 1.06\n",
      "for 2020-11-02, MAE is:12.69 & sMAPE is:134.88% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :8.72 & 41.21% & 1.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-11-03, MAE is:12.23 & sMAPE is:81.28% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.73 & 41.34% & 1.06\n",
      "for 2020-11-04, MAE is:10.78 & sMAPE is:106.41% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.73 & 41.56% & 1.06\n",
      "for 2020-11-05, MAE is:11.11 & sMAPE is:143.79% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :8.74 & 41.89% & 1.06\n",
      "for 2020-11-06, MAE is:19.03 & sMAPE is:88.39% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.78 & 42.03% & 1.06\n",
      "for 2020-11-07, MAE is:11.18 & sMAPE is:35.60% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.78 & 42.01% & 1.06\n",
      "for 2020-11-08, MAE is:20.53 & sMAPE is:46.57% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 42.03% & 1.06\n",
      "for 2020-11-09, MAE is:23.50 & sMAPE is:49.13% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 42.05% & 1.06\n",
      "for 2020-11-10, MAE is:19.90 & sMAPE is:29.72% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.90 & 42.01% & 1.05\n",
      "for 2020-11-11, MAE is:8.49 & sMAPE is:15.79% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :8.90 & 41.93% & 1.05\n",
      "for 2020-11-12, MAE is:23.11 & sMAPE is:65.89% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :8.95 & 42.00% & 1.05\n",
      "for 2020-11-13, MAE is:20.02 & sMAPE is:43.31% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :8.98 & 42.01% & 1.05\n",
      "for 2020-11-14, MAE is:11.03 & sMAPE is:26.44% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :8.99 & 41.96% & 1.05\n",
      "for 2020-11-15, MAE is:16.43 & sMAPE is:92.10% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :9.01 & 42.12% & 1.05\n",
      "for 2020-11-16, MAE is:10.88 & sMAPE is:73.05% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :9.02 & 42.21% & 1.05\n",
      "for 2020-11-17, MAE is:15.13 & sMAPE is:70.08% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :9.04 & 42.30% & 1.04\n",
      "for 2020-11-18, MAE is:13.93 & sMAPE is:95.06% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :9.05 & 42.46% & 1.04\n",
      "for 2020-11-19, MAE is:14.37 & sMAPE is:113.46% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :9.07 & 42.68% & 1.04\n",
      "for 2020-11-20, MAE is:34.16 & sMAPE is:99.51% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :9.14 & 42.86% & 1.04\n",
      "for 2020-11-21, MAE is:33.65 & sMAPE is:103.06% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :9.22 & 43.04% & 1.04\n",
      "for 2020-11-22, MAE is:14.23 & sMAPE is:154.18% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :9.23 & 43.38% & 1.04\n",
      "for 2020-11-23, MAE is:18.66 & sMAPE is:103.25% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :9.26 & 43.56% & 1.04\n",
      "for 2020-11-24, MAE is:13.82 & sMAPE is:71.70% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :9.28 & 43.65% & 1.05\n",
      "for 2020-11-25, MAE is:15.96 & sMAPE is:54.34% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :9.30 & 43.68% & 1.05\n",
      "for 2020-11-26, MAE is:30.18 & sMAPE is:81.07% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 43.79% & 1.05\n",
      "for 2020-11-27, MAE is:16.69 & sMAPE is:26.51% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 43.74% & 1.05\n",
      "for 2020-11-28, MAE is:3.17 & sMAPE is:6.96% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 43.63% & 1.04\n",
      "for 2020-11-29, MAE is:6.61 & sMAPE is:14.40% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 43.54% & 1.04\n",
      "for 2020-11-30, MAE is:40.37 & sMAPE is:43.35% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 43.54% & 1.04\n",
      "for 2020-12-01, MAE is:21.42 & sMAPE is:29.55% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :9.48 & 43.50% & 1.04\n",
      "for 2020-12-02, MAE is:11.41 & sMAPE is:18.62% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :9.49 & 43.43% & 1.04\n",
      "for 2020-12-03, MAE is:14.14 & sMAPE is:50.87% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :9.50 & 43.45% & 1.04\n",
      "for 2020-12-04, MAE is:8.51 & sMAPE is:48.90% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :9.50 & 43.47% & 1.03\n",
      "for 2020-12-05, MAE is:8.74 & sMAPE is:27.69% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :9.50 & 43.42% & 1.03\n",
      "for 2020-12-06, MAE is:20.17 & sMAPE is:49.23% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :9.53 & 43.44% & 1.03\n",
      "for 2020-12-07, MAE is:41.87 & sMAPE is:106.51% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :9.62 & 43.62% & 1.03\n",
      "for 2020-12-08, MAE is:29.88 & sMAPE is:66.63% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :9.68 & 43.69% & 1.03\n",
      "for 2020-12-09, MAE is:18.87 & sMAPE is:35.22% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :9.71 & 43.66% & 1.03\n",
      "for 2020-12-10, MAE is:25.72 & sMAPE is:42.65% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :9.76 & 43.66% & 1.03\n",
      "for 2020-12-11, MAE is:14.47 & sMAPE is:31.75% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :9.77 & 43.63% & 1.03\n",
      "for 2020-12-12, MAE is:12.89 & sMAPE is:43.62% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :9.78 & 43.63% & 1.04\n",
      "for 2020-12-13, MAE is:6.78 & sMAPE is:12.78% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :9.77 & 43.54% & 1.03\n",
      "for 2020-12-14, MAE is:43.19 & sMAPE is:61.28% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :9.87 & 43.59% & 1.03\n",
      "for 2020-12-15, MAE is:7.98 & sMAPE is:23.41% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.86 & 43.53% & 1.03\n",
      "for 2020-12-16, MAE is:12.04 & sMAPE is:31.38% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :9.87 & 43.50% & 1.03\n",
      "for 2020-12-17, MAE is:8.12 & sMAPE is:26.02% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :9.86 & 43.45% & 1.03\n",
      "for 2020-12-18, MAE is:10.51 & sMAPE is:33.00% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.86 & 43.42% & 1.03\n",
      "for 2020-12-19, MAE is:7.86 & sMAPE is:42.57% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.86 & 43.42% & 1.03\n",
      "for 2020-12-20, MAE is:7.21 & sMAPE is:37.25% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :9.85 & 43.40% & 1.02\n",
      "for 2020-12-21, MAE is:9.93 & sMAPE is:33.06% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :9.85 & 43.37% & 1.02\n",
      "for 2020-12-22, MAE is:6.66 & sMAPE is:52.87% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :9.84 & 43.40% & 1.02\n",
      "for 2020-12-23, MAE is:9.27 & sMAPE is:24.47% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :9.84 & 43.34% & 1.02\n",
      "for 2020-12-24, MAE is:14.57 & sMAPE is:62.75% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :9.85 & 43.40% & 1.02\n",
      "for 2020-12-25, MAE is:16.95 & sMAPE is:62.46% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :9.87 & 43.45% & 1.02\n",
      "for 2020-12-26, MAE is:15.95 & sMAPE is:63.93% & rMAE is:3.51 ||| daily mean of MAE & sMAPE & rMAE till now are :9.89 & 43.51% & 1.03\n",
      "for 2020-12-27, MAE is:7.55 & sMAPE is:101.03% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :9.88 & 43.67% & 1.02\n",
      "for 2020-12-28, MAE is:20.45 & sMAPE is:79.59% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.91 & 43.76% & 1.03\n",
      "for 2020-12-29, MAE is:8.33 & sMAPE is:20.17% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :9.91 & 43.70% & 1.02\n",
      "for 2020-12-30, MAE is:5.98 & sMAPE is:16.28% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :9.90 & 43.62% & 1.02\n",
      "for 2020-12-31, MAE is:16.85 & sMAPE is:47.73% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :9.92 & 43.64% & 1.02\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:21:05,252]\u001b[0m A new study created in RDB with name: DK_2_2021\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:21:20,009]\u001b[0m Trial 0 finished with value: 18.219301081173047 and parameters: {'n_hidden': 4, 'learning_rate': 0.022282976408511818, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01938158340872689, 'dropout_rate_Layer_2': 0.29190676904737395, 'dropout_rate_Layer_3': 0.21843337952057468, 'dropout_rate_Layer_4': 0.16517687687410879, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.3504237455997476e-05, 'l1_Layer_2': 0.008103279187713187, 'l1_Layer_3': 8.378193198400037e-05, 'l1_Layer_4': 1.3074643064184263e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265, 'n_units_Layer_4': 215}. Best is trial 0 with value: 18.219301081173047.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.22 | sMAPE for Validation Set is: 62.43% | rMAE for Validation Set is: 1.38\n",
      "MAE for Test Set is: 52.90 | sMAPE for Test Set is: 66.89% | rMAE for Test Set is: 1.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:21:20,328]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 25.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:21:27,634]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:21:31,860]\u001b[0m Trial 3 finished with value: 13.310482517993329 and parameters: {'n_hidden': 4, 'learning_rate': 0.008590445800615795, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14383088047716944, 'dropout_rate_Layer_2': 0.09725625123214213, 'dropout_rate_Layer_3': 0.3971817793723169, 'dropout_rate_Layer_4': 0.23843494808352925, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006993256733978606, 'l1_Layer_2': 0.0015846386469733677, 'l1_Layer_3': 0.015934809759231613, 'l1_Layer_4': 0.00035769309307338745, 'n_units_Layer_1': 220, 'n_units_Layer_2': 295, 'n_units_Layer_3': 50, 'n_units_Layer_4': 115}. Best is trial 3 with value: 13.310482517993329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.31 | sMAPE for Validation Set is: 52.14% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 44.32 | sMAPE for Test Set is: 51.30% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:21:35,202]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:21:38,345]\u001b[0m Trial 1 finished with value: 14.263243594483967 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011011920914673551, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2555354510910163, 'dropout_rate_Layer_2': 0.30561746150639424, 'dropout_rate_Layer_3': 0.2676637387681338, 'dropout_rate_Layer_4': 0.15561752656561847, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.011053505865821463, 'l1_Layer_2': 0.04140683066931491, 'l1_Layer_3': 0.004952500325137015, 'l1_Layer_4': 0.022543158744731433, 'n_units_Layer_1': 185, 'n_units_Layer_2': 250, 'n_units_Layer_3': 140, 'n_units_Layer_4': 175}. Best is trial 3 with value: 13.310482517993329.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.26 | sMAPE for Validation Set is: 54.42% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 46.07 | sMAPE for Test Set is: 54.08% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:21:38,747]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:21:43,527]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:21:51,619]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:21:55,345]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:22:09,801]\u001b[0m Trial 4 finished with value: 11.898013438540914 and parameters: {'n_hidden': 3, 'learning_rate': 0.014695072075723598, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0872167061584963, 'dropout_rate_Layer_2': 0.3078682938617703, 'dropout_rate_Layer_3': 0.216130233977753, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.04576594697716642, 'l1_Layer_2': 0.00045288053013020933, 'l1_Layer_3': 0.0050506288148087376, 'n_units_Layer_1': 220, 'n_units_Layer_2': 130, 'n_units_Layer_3': 210}. Best is trial 4 with value: 11.898013438540914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.90 | sMAPE for Validation Set is: 48.42% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 42.91 | sMAPE for Test Set is: 49.11% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:22:12,970]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:22:19,261]\u001b[0m Trial 13 finished with value: 12.04831248994436 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015820705265875566, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17379961068153307, 'dropout_rate_Layer_2': 0.027551589841458002, 'dropout_rate_Layer_3': 0.07823904937626272, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019390230815912654, 'l1_Layer_2': 0.0006145174960534476, 'l1_Layer_3': 0.0005000696559269187, 'n_units_Layer_1': 145, 'n_units_Layer_2': 70, 'n_units_Layer_3': 175}. Best is trial 4 with value: 11.898013438540914.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:22:19,428]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.05 | sMAPE for Validation Set is: 49.10% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 41.00 | sMAPE for Test Set is: 46.41% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:22:24,523]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:22:27,877]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:22:28,190]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:22:29,654]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:22:34,350]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:22:38,688]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:22:39,021]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:22:45,523]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:22:46,872]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:22:52,541]\u001b[0m Trial 21 finished with value: 12.172381717660633 and parameters: {'n_hidden': 3, 'learning_rate': 0.03403066918238904, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05362156686726878, 'dropout_rate_Layer_2': 0.10127580922943352, 'dropout_rate_Layer_3': 0.20407108387027237, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02206882070359149, 'l1_Layer_2': 0.000958052908678056, 'l1_Layer_3': 2.0930238887352704e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 240, 'n_units_Layer_3': 70}. Best is trial 4 with value: 11.898013438540914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.17 | sMAPE for Validation Set is: 49.34% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 42.71 | sMAPE for Test Set is: 49.33% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:22:55,200]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:22:55,820]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:00,843]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:02,278]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:06,292]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:10,184]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:13,014]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:14,753]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:18,542]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:23,117]\u001b[0m Trial 26 finished with value: 11.088018734370436 and parameters: {'n_hidden': 3, 'learning_rate': 0.07469681039456252, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01835315055599021, 'dropout_rate_Layer_2': 0.39536804156940913, 'dropout_rate_Layer_3': 0.01768401378857637, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09216279946671216, 'l1_Layer_2': 0.0004958497874390157, 'l1_Layer_3': 0.006976187205010572, 'n_units_Layer_1': 295, 'n_units_Layer_2': 290, 'n_units_Layer_3': 55}. Best is trial 26 with value: 11.088018734370436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.09 | sMAPE for Validation Set is: 46.19% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 26.83 | sMAPE for Test Set is: 32.82% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:23:27,296]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:27,734]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:28,062]\u001b[0m Trial 34 finished with value: 12.306225446198093 and parameters: {'n_hidden': 4, 'learning_rate': 0.0737400934029667, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3927742406195465, 'dropout_rate_Layer_2': 0.19122040094656492, 'dropout_rate_Layer_3': 0.09054660408492016, 'dropout_rate_Layer_4': 0.007618561336914676, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.008435864429670507, 'l1_Layer_2': 1.6626014424797206e-05, 'l1_Layer_3': 2.802260604825134e-05, 'l1_Layer_4': 4.482461066871207e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 100, 'n_units_Layer_3': 270, 'n_units_Layer_4': 280}. Best is trial 26 with value: 11.088018734370436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.31 | sMAPE for Validation Set is: 49.66% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 47.71 | sMAPE for Test Set is: 57.86% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:23:35,958]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:38,473]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:39,006]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:43,755]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:44,301]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:49,150]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:49,438]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:50,019]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:57,307]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:23:58,706]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:01,156]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:01,838]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:03,916]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:08,346]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:11,027]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:12,621]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:17,630]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:18,049]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:21,084]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:25,978]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:27,775]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:30,064]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:35,336]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:39,162]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:42,860]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:43,209]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:48,156]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:52,297]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:53,015]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:24:59,839]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:03,606]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:06,330]\u001b[0m Trial 66 finished with value: 11.183026241454796 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008785160854768594, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004501084273254248, 'dropout_rate_Layer_2': 0.022026400605183016, 'dropout_rate_Layer_3': 0.19733634671532455, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05577501603420305, 'l1_Layer_2': 0.0001101607018020759, 'l1_Layer_3': 0.002669459396326338, 'n_units_Layer_1': 285, 'n_units_Layer_2': 130, 'n_units_Layer_3': 55}. Best is trial 26 with value: 11.088018734370436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.18 | sMAPE for Validation Set is: 46.62% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 24.71 | sMAPE for Test Set is: 30.08% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:25:10,744]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:15,588]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:18,054]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:18,640]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:18,855]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:25,401]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:29,593]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:31,169]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:34,513]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:34,865]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:39,777]\u001b[0m Trial 77 finished with value: 10.465199091928142 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005390679982176174, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0161623750924429, 'dropout_rate_Layer_2': 0.005745269026422306, 'dropout_rate_Layer_3': 0.1979757980685484, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05401649315944718, 'l1_Layer_2': 0.00011643473869326731, 'l1_Layer_3': 0.001983517024156109, 'n_units_Layer_1': 295, 'n_units_Layer_2': 130, 'n_units_Layer_3': 50}. Best is trial 77 with value: 10.465199091928142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.47 | sMAPE for Validation Set is: 44.32% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 24.92 | sMAPE for Test Set is: 30.10% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:25:43,255]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:45,431]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:48,421]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:48,665]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:52,077]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:55,899]\u001b[0m Trial 6 finished with value: 11.828830550042369 and parameters: {'n_hidden': 3, 'learning_rate': 0.001775231200870372, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1268616873560613, 'dropout_rate_Layer_2': 0.14973444799505997, 'dropout_rate_Layer_3': 0.39134794230455855, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0019639240520390754, 'l1_Layer_2': 0.07567792112970685, 'l1_Layer_3': 4.666112487043966e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 170, 'n_units_Layer_3': 140}. Best is trial 77 with value: 10.465199091928142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.83 | sMAPE for Validation Set is: 48.26% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 42.33 | sMAPE for Test Set is: 48.18% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:25:58,799]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:59,105]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:59,635]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:25:59,957]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:05,567]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:08,745]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:10,842]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:11,607]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:15,032]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:18,841]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:23,308]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:23,873]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:24,056]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:26,649]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:32,901]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:40,638]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:46,195]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:47,416]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:50,432]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:51,106]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:55,312]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:26:58,708]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:00,356]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:01,726]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:04,004]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:05,311]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:08,072]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:11,201]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:16,217]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:16,740]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:21,637]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:21,991]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:28,483]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:29,989]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:33,045]\u001b[0m Trial 119 finished with value: 11.70215064780183 and parameters: {'n_hidden': 3, 'learning_rate': 0.017798631491617672, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05726156645891192, 'dropout_rate_Layer_2': 0.07965260453020287, 'dropout_rate_Layer_3': 0.21800408542541685, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0435074941094715, 'l1_Layer_2': 0.0005174155786015316, 'l1_Layer_3': 0.00044108247408161086, 'n_units_Layer_1': 270, 'n_units_Layer_2': 155, 'n_units_Layer_3': 75}. Best is trial 77 with value: 10.465199091928142.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.70 | sMAPE for Validation Set is: 47.90% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 47.81 | sMAPE for Test Set is: 57.94% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:27:36,620]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:38,785]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:40,518]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:42,792]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:44,880]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:51,179]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:52,518]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:56,212]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:59,230]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:59,324]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:27:59,586]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:06,321]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:06,570]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:07,290]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:07,456]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:11,491]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:13,390]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:16,651]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:20,102]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:20,333]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:20,448]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:32,944]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:37,296]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:39,856]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:42,833]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:44,809]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:48,408]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:48,828]\u001b[0m Trial 142 finished with value: 9.48112297499357 and parameters: {'n_hidden': 3, 'learning_rate': 0.001006310055571043, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024330713171704946, 'dropout_rate_Layer_2': 0.14620551354502628, 'dropout_rate_Layer_3': 0.10561820926870057, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005937289964904284, 'l1_Layer_2': 8.94179858385514e-05, 'l1_Layer_3': 0.0014104049710068813, 'n_units_Layer_1': 125, 'n_units_Layer_2': 85, 'n_units_Layer_3': 120}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.48 | sMAPE for Validation Set is: 41.07% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 28.68 | sMAPE for Test Set is: 32.67% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:28:54,362]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:28:54,549]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:03,046]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:06,469]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:10,579]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:13,883]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:18,194]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:22,610]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:24,231]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:27,378]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:29,456]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:33,251]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:36,260]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:39,081]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:41,089]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:41,767]\u001b[0m Trial 160 finished with value: 10.218489143328194 and parameters: {'n_hidden': 3, 'learning_rate': 0.005345059725136825, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1420988927579399, 'dropout_rate_Layer_2': 0.026660336508076588, 'dropout_rate_Layer_3': 0.23807191391646818, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04795172036777669, 'l1_Layer_2': 7.212182224706154e-05, 'l1_Layer_3': 0.0006946911168367985, 'n_units_Layer_1': 265, 'n_units_Layer_2': 190, 'n_units_Layer_3': 125}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.22 | sMAPE for Validation Set is: 43.61% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 36.35 | sMAPE for Test Set is: 40.86% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:29:46,805]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:51,281]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:52,395]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:56,785]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.15 | sMAPE for Validation Set is: 43.70% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 37.29 | sMAPE for Test Set is: 42.20% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:29:58,933]\u001b[0m Trial 169 finished with value: 10.150333925555344 and parameters: {'n_hidden': 3, 'learning_rate': 0.0062600715682419065, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13888836914554625, 'dropout_rate_Layer_2': 0.08663728511996685, 'dropout_rate_Layer_3': 0.19084102205792525, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014531750901021285, 'l1_Layer_2': 0.0003410226484050129, 'l1_Layer_3': 0.0010613932792541184, 'n_units_Layer_1': 285, 'n_units_Layer_2': 145, 'n_units_Layer_3': 60}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:29:59,414]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:30:03,601]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:30:04,100]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:30:05,310]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:30:11,149]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:30:14,105]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:30:14,467]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:30:18,463]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:30:22,070]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:30:25,141]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.00 | sMAPE for Validation Set is: 42.78% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 25.78 | sMAPE for Test Set is: 31.51% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:30:27,759]\u001b[0m Trial 150 finished with value: 10.001356614541434 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006181679580516697, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015704261839689163, 'dropout_rate_Layer_2': 0.026875924070062146, 'dropout_rate_Layer_3': 0.18984338184439822, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007214725090020235, 'l1_Layer_2': 0.017497498490525426, 'l1_Layer_3': 0.0003618315935335564, 'n_units_Layer_1': 80, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:30:32,424]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:30:36,452]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:30:39,827]\u001b[0m Trial 180 finished with value: 11.546176554370833 and parameters: {'n_hidden': 3, 'learning_rate': 0.0112438010754356, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22909267468427943, 'dropout_rate_Layer_2': 0.024732630890749542, 'dropout_rate_Layer_3': 0.2967555846886665, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013382712435716463, 'l1_Layer_2': 0.00028651959766670774, 'l1_Layer_3': 0.0006831403962069411, 'n_units_Layer_1': 290, 'n_units_Layer_2': 110, 'n_units_Layer_3': 95}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.55 | sMAPE for Validation Set is: 47.71% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 39.99 | sMAPE for Test Set is: 44.83% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:30:43,260]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:30:43,512]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:30:50,227]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:30:58,673]\u001b[0m Trial 183 finished with value: 10.100715266168395 and parameters: {'n_hidden': 3, 'learning_rate': 0.001095073433725921, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00030374783462570887, 'dropout_rate_Layer_2': 0.1773831382919991, 'dropout_rate_Layer_3': 0.15748158314690208, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001404928939565093, 'l1_Layer_2': 0.025502098062897105, 'l1_Layer_3': 0.0005494686648832721, 'n_units_Layer_1': 90, 'n_units_Layer_2': 50, 'n_units_Layer_3': 155}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.10 | sMAPE for Validation Set is: 43.19% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 25.58 | sMAPE for Test Set is: 31.21% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:31:03,220]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:31:14,159]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:31:19,284]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:31:21,382]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:31:24,080]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:31:27,459]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:31:28,641]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:31:33,807]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:31:34,734]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:31:39,021]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:31:52,351]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:32:04,407]\u001b[0m Trial 189 finished with value: 10.003309085765368 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011341048246682147, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03335320270624816, 'dropout_rate_Layer_2': 0.08097233215892657, 'dropout_rate_Layer_3': 0.15007316251754202, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001295768732341758, 'l1_Layer_2': 0.022777501754752003, 'l1_Layer_3': 0.00011876902069562839, 'n_units_Layer_1': 165, 'n_units_Layer_2': 50, 'n_units_Layer_3': 155}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.00 | sMAPE for Validation Set is: 43.04% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 25.47 | sMAPE for Test Set is: 30.57% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:32:08,998]\u001b[0m Trial 190 finished with value: 9.906408665634023 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011297751863777476, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.036053150553454226, 'dropout_rate_Layer_2': 0.08523889478561955, 'dropout_rate_Layer_3': 0.15651383218121417, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015671282606042917, 'l1_Layer_2': 0.018532346634841854, 'l1_Layer_3': 0.0005346984370394981, 'n_units_Layer_1': 50, 'n_units_Layer_2': 50, 'n_units_Layer_3': 120}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.91 | sMAPE for Validation Set is: 42.74% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 24.85 | sMAPE for Test Set is: 30.12% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:32:09,190]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:32:22,972]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:32:23,072]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:32:30,267]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:32:30,745]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:32:44,751]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:33:08,548]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:33:12,363]\u001b[0m Trial 208 finished with value: 10.069091646611525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013211978719763796, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027002928968885703, 'dropout_rate_Layer_2': 0.07822945057782046, 'dropout_rate_Layer_3': 0.17359995113104643, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001029438731724672, 'l1_Layer_2': 0.03475085912117822, 'l1_Layer_3': 0.00019613820762345242, 'n_units_Layer_1': 65, 'n_units_Layer_2': 60, 'n_units_Layer_3': 150}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.07 | sMAPE for Validation Set is: 43.15% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 24.83 | sMAPE for Test Set is: 30.11% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:33:20,121]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:33:26,543]\u001b[0m Trial 207 finished with value: 9.814806027938316 and parameters: {'n_hidden': 3, 'learning_rate': 0.001300408029663296, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029757480532888937, 'dropout_rate_Layer_2': 0.08067643521131278, 'dropout_rate_Layer_3': 0.17517076796713277, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010047614373646157, 'l1_Layer_2': 0.011182740054045818, 'l1_Layer_3': 0.00018556831448372579, 'n_units_Layer_1': 65, 'n_units_Layer_2': 70, 'n_units_Layer_3': 180}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.81 | sMAPE for Validation Set is: 44.01% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 28.35 | sMAPE for Test Set is: 32.98% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:33:27,089]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:33:32,483]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:33:32,751]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:33:38,254]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:33:41,182]\u001b[0m Trial 205 finished with value: 10.08750323085289 and parameters: {'n_hidden': 3, 'learning_rate': 0.001273383604323118, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027861455911859342, 'dropout_rate_Layer_2': 0.08698313336896486, 'dropout_rate_Layer_3': 0.17249105992133068, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001175790173870107, 'l1_Layer_2': 0.01188927197772859, 'l1_Layer_3': 0.000670665846468825, 'n_units_Layer_1': 65, 'n_units_Layer_2': 60, 'n_units_Layer_3': 150}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.09 | sMAPE for Validation Set is: 43.15% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 25.53 | sMAPE for Test Set is: 31.20% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:33:41,837]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:33:47,360]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:33:51,778]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:33:52,104]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:33:57,699]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:34:02,462]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:34:09,765]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:34:21,031]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:34:24,318]\u001b[0m Trial 215 finished with value: 9.71013210532836 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013424246641951466, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028764713020182398, 'dropout_rate_Layer_2': 0.09237822690379598, 'dropout_rate_Layer_3': 0.21132313679589435, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005062232191649213, 'l1_Layer_2': 0.013062847038427625, 'l1_Layer_3': 0.00013985665055468965, 'n_units_Layer_1': 65, 'n_units_Layer_2': 60, 'n_units_Layer_3': 170}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.71 | sMAPE for Validation Set is: 42.10% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 26.61 | sMAPE for Test Set is: 31.28% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:34:28,605]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:34:31,788]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:34:34,588]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:34:37,036]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:34:44,971]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:34:45,787]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:34:51,714]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:34:54,497]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:34:54,628]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:35:02,833]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:35:03,545]\u001b[0m Trial 234 finished with value: 10.115126813796792 and parameters: {'n_hidden': 3, 'learning_rate': 0.0084740756319181, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2220791329506802, 'dropout_rate_Layer_2': 0.026503942379328415, 'dropout_rate_Layer_3': 0.3094343118633302, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013706156633739924, 'l1_Layer_2': 0.00040533694098329363, 'l1_Layer_3': 0.0006390700014901329, 'n_units_Layer_1': 290, 'n_units_Layer_2': 115, 'n_units_Layer_3': 90}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.12 | sMAPE for Validation Set is: 43.84% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 33.32 | sMAPE for Test Set is: 36.89% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:35:15,296]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:35:15,808]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:35:18,139]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:35:24,359]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:35:27,936]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:35:30,562]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:35:36,149]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:35:41,720]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:35:46,801]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:35:52,090]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:35:55,340]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:36:11,646]\u001b[0m Trial 244 finished with value: 9.72616123777246 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016896683699645202, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009754723533792493, 'dropout_rate_Layer_2': 0.1340567423823013, 'dropout_rate_Layer_3': 0.22084508896637634, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00029263113736851805, 'l1_Layer_2': 0.014147195172136211, 'l1_Layer_3': 0.0004526643973152529, 'n_units_Layer_1': 75, 'n_units_Layer_2': 70, 'n_units_Layer_3': 135}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.73 | sMAPE for Validation Set is: 41.94% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 25.37 | sMAPE for Test Set is: 31.29% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:36:16,537]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:36:34,209]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:36:39,274]\u001b[0m Trial 245 finished with value: 9.840932554915312 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009083121213642035, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024260825138027735, 'dropout_rate_Layer_2': 0.07875942241926738, 'dropout_rate_Layer_3': 0.22744172054991887, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008528069719028378, 'l1_Layer_2': 0.014747425541232612, 'l1_Layer_3': 0.0001476161902062795, 'n_units_Layer_1': 75, 'n_units_Layer_2': 70, 'n_units_Layer_3': 180}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.84 | sMAPE for Validation Set is: 42.29% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 24.74 | sMAPE for Test Set is: 29.84% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:36:42,807]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:36:47,742]\u001b[0m Trial 250 finished with value: 9.859215295702747 and parameters: {'n_hidden': 3, 'learning_rate': 0.001702508107922779, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025078916943346408, 'dropout_rate_Layer_2': 0.0819112400296012, 'dropout_rate_Layer_3': 0.15418494739238017, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007553284916426838, 'l1_Layer_2': 0.014846296099660818, 'l1_Layer_3': 0.00014224059343776767, 'n_units_Layer_1': 70, 'n_units_Layer_2': 70, 'n_units_Layer_3': 180}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.86 | sMAPE for Validation Set is: 43.45% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 24.95 | sMAPE for Test Set is: 30.60% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:36:48,138]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:36:57,434]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:37:06,734]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:37:09,641]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:37:16,103]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:37:21,261]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:37:27,817]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:37:42,520]\u001b[0m Trial 252 finished with value: 10.894044467329204 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005121692620208418, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0062211150351895415, 'dropout_rate_Layer_2': 0.041448991695101134, 'dropout_rate_Layer_3': 0.366334479547558, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026860642605180673, 'l1_Layer_2': 0.016317316275573892, 'l1_Layer_3': 3.551853502950848e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 290, 'n_units_Layer_3': 220}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.89 | sMAPE for Validation Set is: 45.77% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 40.79 | sMAPE for Test Set is: 46.23% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:37:50,675]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:37:50,847]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.86 | sMAPE for Validation Set is: 43.14% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 28.12 | sMAPE for Test Set is: 32.74% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:37:54,738]\u001b[0m Trial 259 finished with value: 9.85998784970302 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022582548626551876, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0719691702497654, 'dropout_rate_Layer_2': 0.04771007836194213, 'dropout_rate_Layer_3': 0.2534454923318621, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007692473327876605, 'l1_Layer_2': 0.007369955396004734, 'l1_Layer_3': 8.139521243351013e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 90, 'n_units_Layer_3': 210}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:38:02,525]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:38:04,213]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:38:08,005]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:38:08,495]\u001b[0m Trial 262 finished with value: 9.827153365618672 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021366849751654135, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0691274052920762, 'dropout_rate_Layer_2': 0.11488347856288883, 'dropout_rate_Layer_3': 0.2510734267185325, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001401386985853003, 'l1_Layer_2': 0.008593240255467652, 'l1_Layer_3': 9.880982748203365e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 90, 'n_units_Layer_3': 210}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.83 | sMAPE for Validation Set is: 42.44% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 26.38 | sMAPE for Test Set is: 31.11% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:38:10,756]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:38:22,543]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:38:32,496]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:38:33,789]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:38:36,102]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:38:38,781]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:38:39,642]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:38:42,504]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:38:49,856]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:38:58,804]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:39:03,969]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:39:07,375]\u001b[0m Trial 279 finished with value: 11.018637520118014 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011234967828273746, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2883904813258052, 'dropout_rate_Layer_2': 0.11181687090188941, 'dropout_rate_Layer_3': 0.39982076534194305, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017406157228927453, 'l1_Layer_2': 0.00873058271395897, 'l1_Layer_3': 9.373080099728441e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 295, 'n_units_Layer_3': 165}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.02 | sMAPE for Validation Set is: 46.20% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 40.60 | sMAPE for Test Set is: 46.06% | rMAE for Test Set is: 1.13\n",
      "MAE for Validation Set is: 10.82 | sMAPE for Validation Set is: 45.47% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 41.60 | sMAPE for Test Set is: 47.59% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:39:07,577]\u001b[0m Trial 278 finished with value: 10.820429915084594 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006715673153629597, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2760535531610217, 'dropout_rate_Layer_2': 0.16614535738725736, 'dropout_rate_Layer_3': 0.35506554298378645, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015272824040378984, 'l1_Layer_2': 0.008747553867999027, 'l1_Layer_3': 9.865415607986454e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 295, 'n_units_Layer_3': 160}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:39:07,887]\u001b[0m Trial 274 finished with value: 11.277510164556618 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006679453625021199, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28409054298225767, 'dropout_rate_Layer_2': 0.07177905482195994, 'dropout_rate_Layer_3': 0.3531326155275032, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00431780078630862, 'l1_Layer_2': 0.012051947607989742, 'l1_Layer_3': 8.956618306041695e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 270, 'n_units_Layer_3': 165}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.28 | sMAPE for Validation Set is: 46.96% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 40.99 | sMAPE for Test Set is: 46.53% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:39:09,030]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:39:21,411]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:39:25,727]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:39:26,223]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:39:26,384]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:39:34,842]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:39:42,613]\u001b[0m Trial 283 finished with value: 10.9200013070474 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007621859295739082, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28951327006985306, 'dropout_rate_Layer_2': 0.11094613733091296, 'dropout_rate_Layer_3': 0.39780129632516753, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016871216721886884, 'l1_Layer_2': 0.009555300959416174, 'l1_Layer_3': 0.00012463877550640824, 'n_units_Layer_1': 275, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.92 | sMAPE for Validation Set is: 45.82% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 41.65 | sMAPE for Test Set is: 47.68% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:39:46,624]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:39:51,465]\u001b[0m Trial 288 finished with value: 10.735941836079073 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014100999829269915, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28897094985876803, 'dropout_rate_Layer_2': 0.1124274643960066, 'dropout_rate_Layer_3': 0.3608453022183952, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001599981816066649, 'l1_Layer_2': 0.009648142204515271, 'l1_Layer_3': 0.0001166688707664537, 'n_units_Layer_1': 280, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.74 | sMAPE for Validation Set is: 45.30% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 40.19 | sMAPE for Test Set is: 45.56% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:39:51,857]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:39:58,321]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:40:02,988]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:40:07,326]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:40:14,915]\u001b[0m Trial 294 finished with value: 10.747003162551392 and parameters: {'n_hidden': 3, 'learning_rate': 0.001464339538197008, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.285435726756889, 'dropout_rate_Layer_2': 0.11344732061557204, 'dropout_rate_Layer_3': 0.35968970352682517, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015350209938950923, 'l1_Layer_2': 0.008970017732644432, 'l1_Layer_3': 0.00012063143273361996, 'n_units_Layer_1': 280, 'n_units_Layer_2': 280, 'n_units_Layer_3': 150}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.75 | sMAPE for Validation Set is: 45.27% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 42.29 | sMAPE for Test Set is: 48.70% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:40:19,541]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:40:23,057]\u001b[0m Trial 297 finished with value: 10.421374954278534 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016564295643217615, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2859057513157713, 'dropout_rate_Layer_2': 0.10834593367223995, 'dropout_rate_Layer_3': 0.36162475016003787, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001488718553928013, 'l1_Layer_2': 0.006657919397422394, 'l1_Layer_3': 0.00012122845333871017, 'n_units_Layer_1': 280, 'n_units_Layer_2': 280, 'n_units_Layer_3': 165}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.42 | sMAPE for Validation Set is: 44.32% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 39.89 | sMAPE for Test Set is: 45.25% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:40:25,209]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:40:32,465]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:40:41,615]\u001b[0m Trial 300 finished with value: 10.454079008102418 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016374943812458263, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2646668850122619, 'dropout_rate_Layer_2': 0.11331192146183319, 'dropout_rate_Layer_3': 0.3447229883204838, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015737152047261098, 'l1_Layer_2': 0.0051966546637267205, 'l1_Layer_3': 0.00012632636557939587, 'n_units_Layer_1': 280, 'n_units_Layer_2': 280, 'n_units_Layer_3': 150}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.45 | sMAPE for Validation Set is: 44.43% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 41.38 | sMAPE for Test Set is: 47.43% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:40:48,118]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:40:50,942]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:40:51,150]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:41:00,972]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:41:12,384]\u001b[0m Trial 306 finished with value: 10.481105302223588 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016270824208039142, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26367382062735406, 'dropout_rate_Layer_2': 0.10987973882365863, 'dropout_rate_Layer_3': 0.34360739391307854, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008796470826928615, 'l1_Layer_2': 0.005527034219881066, 'l1_Layer_3': 0.00020132789249290877, 'n_units_Layer_1': 280, 'n_units_Layer_2': 280, 'n_units_Layer_3': 150}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.48 | sMAPE for Validation Set is: 44.43% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 42.14 | sMAPE for Test Set is: 48.65% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:41:12,886]\u001b[0m Trial 307 finished with value: 10.511896184830059 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017347318361859425, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26591635642642175, 'dropout_rate_Layer_2': 0.10831194077230669, 'dropout_rate_Layer_3': 0.3466128746484842, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009309403168988216, 'l1_Layer_2': 0.005253432709405551, 'l1_Layer_3': 0.0002045508882199042, 'n_units_Layer_1': 280, 'n_units_Layer_2': 280, 'n_units_Layer_3': 150}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.51 | sMAPE for Validation Set is: 44.59% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 40.30 | sMAPE for Test Set is: 45.88% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:41:21,104]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:41:24,126]\u001b[0m Trial 292 finished with value: 9.754926993625523 and parameters: {'n_hidden': 3, 'learning_rate': 0.000628194307448397, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06541703222855226, 'dropout_rate_Layer_2': 0.07162459820766345, 'dropout_rate_Layer_3': 0.22868474297240246, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004537928544120436, 'l1_Layer_2': 0.015408246646007819, 'l1_Layer_3': 3.21197127747262e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 75, 'n_units_Layer_3': 215}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.75 | sMAPE for Validation Set is: 41.97% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 25.31 | sMAPE for Test Set is: 30.61% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:41:29,589]\u001b[0m Trial 308 finished with value: 10.639123299929869 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014022350292911658, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2654344119951224, 'dropout_rate_Layer_2': 0.1245286910786576, 'dropout_rate_Layer_3': 0.34554455974129206, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000942825329815868, 'l1_Layer_2': 0.005737868868860751, 'l1_Layer_3': 0.0001798918406697703, 'n_units_Layer_1': 295, 'n_units_Layer_2': 280, 'n_units_Layer_3': 150}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.64 | sMAPE for Validation Set is: 44.97% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 40.12 | sMAPE for Test Set is: 45.32% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:41:30,885]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:41:33,192]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:41:40,472]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:41:41,177]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:41:47,226]\u001b[0m Trial 311 finished with value: 10.469324449293019 and parameters: {'n_hidden': 3, 'learning_rate': 0.001347885537928081, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27303572880220256, 'dropout_rate_Layer_2': 0.12401357385664225, 'dropout_rate_Layer_3': 0.33729228369528785, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014480221888040902, 'l1_Layer_2': 0.006399340384489608, 'l1_Layer_3': 0.00014013351335845592, 'n_units_Layer_1': 280, 'n_units_Layer_2': 275, 'n_units_Layer_3': 145}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.47 | sMAPE for Validation Set is: 44.52% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 39.90 | sMAPE for Test Set is: 45.12% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:41:48,329]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:41:50,491]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:41:57,893]\u001b[0m Trial 313 finished with value: 10.406798058769278 and parameters: {'n_hidden': 3, 'learning_rate': 0.002041161272102716, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2766496008727951, 'dropout_rate_Layer_2': 0.12627731034722736, 'dropout_rate_Layer_3': 0.32746895986229213, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00135126209670874, 'l1_Layer_2': 0.005429364306611271, 'l1_Layer_3': 9.964097352385402e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.41 | sMAPE for Validation Set is: 44.24% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 41.26 | sMAPE for Test Set is: 47.32% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:42:01,896]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:42:03,419]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:42:10,319]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:42:12,949]\u001b[0m Trial 318 finished with value: 10.726383513208885 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016587024473268212, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2570118435061048, 'dropout_rate_Layer_2': 0.12277943097391991, 'dropout_rate_Layer_3': 0.35395316120712383, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000752461608712226, 'l1_Layer_2': 0.008303345446237754, 'l1_Layer_3': 0.00022986298884859383, 'n_units_Layer_1': 275, 'n_units_Layer_2': 270, 'n_units_Layer_3': 125}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.73 | sMAPE for Validation Set is: 45.21% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 41.72 | sMAPE for Test Set is: 47.86% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:42:19,355]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:42:19,982]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:42:22,320]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:42:22,661]\u001b[0m Trial 321 finished with value: 10.437974916252697 and parameters: {'n_hidden': 3, 'learning_rate': 0.001254820821585049, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2594028458791359, 'dropout_rate_Layer_2': 0.10156424959206913, 'dropout_rate_Layer_3': 0.33266565663063913, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007158934346871076, 'l1_Layer_2': 0.004495935915854298, 'l1_Layer_3': 0.00023898921516704913, 'n_units_Layer_1': 300, 'n_units_Layer_2': 270, 'n_units_Layer_3': 130}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.44 | sMAPE for Validation Set is: 44.31% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 38.59 | sMAPE for Test Set is: 43.22% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:42:33,323]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:42:36,689]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:42:37,169]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:42:43,506]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:43:00,692]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:43:07,618]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:43:14,418]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:43:15,025]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:43:22,161]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:43:23,974]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:43:30,815]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:43:35,710]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:43:49,100]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:43:55,313]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:44:01,095]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:44:01,329]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:44:10,564]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:44:13,699]\u001b[0m Trial 332 finished with value: 9.580752398911294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010104046797922378, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0052722007080034244, 'dropout_rate_Layer_2': 0.06046913261758877, 'dropout_rate_Layer_3': 0.0997623468452278, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001618018192799531, 'l1_Layer_2': 0.021028199873698646, 'l1_Layer_3': 7.601604099580016e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 120}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.58 | sMAPE for Validation Set is: 41.34% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 24.51 | sMAPE for Test Set is: 30.00% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:44:16,794]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:44:19,956]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:44:25,938]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:44:26,324]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:44:26,526]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:44:38,460]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:44:45,166]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:44:49,439]\u001b[0m Trial 330 finished with value: 9.92349051847459 and parameters: {'n_hidden': 3, 'learning_rate': 0.001052557367678942, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0068191509478649805, 'dropout_rate_Layer_2': 0.06039552644012069, 'dropout_rate_Layer_3': 0.17916518287532981, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008789918851674117, 'l1_Layer_2': 0.02057759888072725, 'l1_Layer_3': 7.609627058348057e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 115}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.92 | sMAPE for Validation Set is: 42.80% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 24.16 | sMAPE for Test Set is: 29.46% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:44:49,866]\u001b[0m Trial 350 finished with value: 10.466450153579288 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012317825894055205, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2650280764703471, 'dropout_rate_Layer_2': 0.17206208888850294, 'dropout_rate_Layer_3': 0.3359155437237284, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00146575652039001, 'l1_Layer_2': 0.008408761768518826, 'l1_Layer_3': 0.0002795865570272929, 'n_units_Layer_1': 290, 'n_units_Layer_2': 95, 'n_units_Layer_3': 155}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.47 | sMAPE for Validation Set is: 44.47% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 40.59 | sMAPE for Test Set is: 46.12% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:45:03,426]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:45:07,908]\u001b[0m Trial 353 finished with value: 10.57225711487794 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008963906923073029, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27936431753747537, 'dropout_rate_Layer_2': 0.13691530679342634, 'dropout_rate_Layer_3': 0.335395305945459, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007333687134694129, 'l1_Layer_2': 0.006273760153448794, 'l1_Layer_3': 0.00014218885294690689, 'n_units_Layer_1': 300, 'n_units_Layer_2': 280, 'n_units_Layer_3': 115}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.57 | sMAPE for Validation Set is: 44.84% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 40.09 | sMAPE for Test Set is: 45.33% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:45:11,217]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:45:16,548]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:45:27,376]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:45:31,414]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:45:35,882]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:45:39,395]\u001b[0m Trial 359 finished with value: 10.343816423478124 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010536425994598902, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29408940890035606, 'dropout_rate_Layer_2': 0.12968376368986584, 'dropout_rate_Layer_3': 0.34082352190056636, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005234924116045323, 'l1_Layer_2': 0.005995757426722907, 'l1_Layer_3': 0.00027886561392585996, 'n_units_Layer_1': 300, 'n_units_Layer_2': 100, 'n_units_Layer_3': 130}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.34 | sMAPE for Validation Set is: 44.03% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 38.57 | sMAPE for Test Set is: 43.10% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:45:57,749]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:46:03,125]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:46:09,251]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:46:13,385]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:46:18,022]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:46:24,345]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:46:28,064]\u001b[0m Trial 363 finished with value: 10.388682119768864 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005005592392481272, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013650204889638536, 'dropout_rate_Layer_2': 0.002987459474717062, 'dropout_rate_Layer_3': 0.24326015750585153, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03173021087284192, 'l1_Layer_2': 0.0006810617355761799, 'l1_Layer_3': 0.00031690433588691205, 'n_units_Layer_1': 260, 'n_units_Layer_2': 95, 'n_units_Layer_3': 155}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.39 | sMAPE for Validation Set is: 44.21% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 23.90 | sMAPE for Test Set is: 28.95% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:46:31,894]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:46:32,292]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:46:38,809]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:46:42,956]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:46:43,904]\u001b[0m Trial 356 finished with value: 9.748623148976597 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008713191696314456, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014313765919624966, 'dropout_rate_Layer_2': 0.06169130143130756, 'dropout_rate_Layer_3': 0.17967780147840395, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009531709174913109, 'l1_Layer_2': 0.016185292705858344, 'l1_Layer_3': 6.827434176150884e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 55, 'n_units_Layer_3': 100}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.75 | sMAPE for Validation Set is: 42.12% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 25.61 | sMAPE for Test Set is: 30.66% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:46:52,433]\u001b[0m Trial 355 finished with value: 9.856689483603617 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008510061060564379, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01653423935598434, 'dropout_rate_Layer_2': 0.05939610156672316, 'dropout_rate_Layer_3': 0.09623455756158705, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008200841467356406, 'l1_Layer_2': 0.01698340957262639, 'l1_Layer_3': 5.21815810947036e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 55, 'n_units_Layer_3': 95}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.86 | sMAPE for Validation Set is: 42.47% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 25.02 | sMAPE for Test Set is: 30.02% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:46:52,949]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:46:58,628]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:47:01,093]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:47:05,727]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:47:06,130]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:47:10,106]\u001b[0m Trial 375 finished with value: 10.640927123726799 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020596398220386115, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29856841678921897, 'dropout_rate_Layer_2': 0.11573804803008848, 'dropout_rate_Layer_3': 0.3363077606012449, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005599414705741332, 'l1_Layer_2': 0.005700426045116176, 'l1_Layer_3': 0.0003292661389217184, 'n_units_Layer_1': 295, 'n_units_Layer_2': 285, 'n_units_Layer_3': 130}. Best is trial 142 with value: 9.48112297499357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.64 | sMAPE for Validation Set is: 45.01% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 39.84 | sMAPE for Test Set is: 44.95% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:47:18,426]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:47:25,749]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:47:30,136]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:47:38,828]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:47:43,673]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:47:48,097]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:47:52,889]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:47:57,528]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:47:57,704]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:48:06,840]\u001b[0m Trial 384 finished with value: 9.394065004866105 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008218827783441208, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01648748887773688, 'dropout_rate_Layer_2': 0.0013743341491760097, 'dropout_rate_Layer_3': 0.2290335984826132, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015050176445727719, 'l1_Layer_2': 0.00026827863363199317, 'l1_Layer_3': 0.0013482878157138117, 'n_units_Layer_1': 230, 'n_units_Layer_2': 100, 'n_units_Layer_3': 175}. Best is trial 384 with value: 9.394065004866105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.39 | sMAPE for Validation Set is: 40.42% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 23.35 | sMAPE for Test Set is: 28.06% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:48:14,325]\u001b[0m Trial 377 finished with value: 9.817849125450369 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005051726976440047, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01911011097049175, 'dropout_rate_Layer_2': 0.04357534234597803, 'dropout_rate_Layer_3': 0.2582609418094127, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.016349268883610595, 'l1_Layer_2': 0.0006974357500586627, 'l1_Layer_3': 0.0012917362572694587, 'n_units_Layer_1': 275, 'n_units_Layer_2': 70, 'n_units_Layer_3': 155}. Best is trial 384 with value: 9.394065004866105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.82 | sMAPE for Validation Set is: 42.35% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 23.98 | sMAPE for Test Set is: 28.94% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:48:16,803]\u001b[0m Trial 391 finished with value: 10.594842908504171 and parameters: {'n_hidden': 3, 'learning_rate': 0.001752959856871812, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23619610519962048, 'dropout_rate_Layer_2': 0.13016983330738366, 'dropout_rate_Layer_3': 0.3669072311963264, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00146681214101738, 'l1_Layer_2': 0.006904020807617333, 'l1_Layer_3': 0.00011746670056127138, 'n_units_Layer_1': 290, 'n_units_Layer_2': 125, 'n_units_Layer_3': 150}. Best is trial 384 with value: 9.394065004866105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.59 | sMAPE for Validation Set is: 44.98% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 38.99 | sMAPE for Test Set is: 43.85% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:48:21,071]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:48:38,494]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:48:39,437]\u001b[0m Trial 392 finished with value: 9.697379670030228 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006431920014829876, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02189629186957695, 'dropout_rate_Layer_2': 0.0023785555170762612, 'dropout_rate_Layer_3': 0.17131749652668693, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012131828653333367, 'l1_Layer_2': 0.0025766731952967213, 'l1_Layer_3': 0.0007746056252328704, 'n_units_Layer_1': 265, 'n_units_Layer_2': 115, 'n_units_Layer_3': 95}. Best is trial 384 with value: 9.394065004866105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.70 | sMAPE for Validation Set is: 41.47% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 24.95 | sMAPE for Test Set is: 30.30% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:48:46,457]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:48:53,855]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:48:57,820]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:49:03,670]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:49:07,658]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:49:08,297]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:49:14,333]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:49:15,866]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:49:20,410]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:49:26,890]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:49:27,618]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:49:34,613]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:49:39,071]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:49:40,525]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:49:44,457]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:49:48,292]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:49:52,666]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:49:53,208]\u001b[0m Trial 393 finished with value: 9.984788056004348 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008293950809418276, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0024159221643059135, 'dropout_rate_Layer_2': 0.078588413380779, 'dropout_rate_Layer_3': 0.16696974022849875, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.110155588842935e-05, 'l1_Layer_2': 0.025781032353665655, 'l1_Layer_3': 4.378765657379959e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 65, 'n_units_Layer_3': 105}. Best is trial 384 with value: 9.394065004866105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.98 | sMAPE for Validation Set is: 42.87% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 27.47 | sMAPE for Test Set is: 31.91% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:50:05,649]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:50:09,111]\u001b[0m Trial 399 finished with value: 8.955792014623198 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006258465088286411, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.061826568732083635, 'dropout_rate_Layer_2': 0.0005351433067290502, 'dropout_rate_Layer_3': 0.2510857508685266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006251406298622275, 'l1_Layer_2': 0.004901240248734594, 'l1_Layer_3': 0.00047063853655772463, 'n_units_Layer_1': 230, 'n_units_Layer_2': 75, 'n_units_Layer_3': 190}. Best is trial 399 with value: 8.955792014623198.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.96 | sMAPE for Validation Set is: 38.93% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 24.07 | sMAPE for Test Set is: 29.04% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:50:13,542]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:50:19,767]\u001b[0m Trial 415 finished with value: 9.415602854681769 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014349614938881181, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2532950462822038, 'dropout_rate_Layer_2': 0.09861476593849218, 'dropout_rate_Layer_3': 0.3293739578264722, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012834804642272801, 'l1_Layer_2': 0.005862811841243948, 'l1_Layer_3': 6.605442663911046e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 295, 'n_units_Layer_3': 165}. Best is trial 399 with value: 8.955792014623198.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.42 | sMAPE for Validation Set is: 40.76% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 25.27 | sMAPE for Test Set is: 31.75% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:50:25,146]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:50:35,221]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:50:40,777]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:50:45,617]\u001b[0m Trial 417 finished with value: 9.56532450258704 and parameters: {'n_hidden': 3, 'learning_rate': 0.00151044374737371, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29103190454756817, 'dropout_rate_Layer_2': 0.09539671395227514, 'dropout_rate_Layer_3': 0.32737957028311276, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001047625818289246, 'l1_Layer_2': 0.005852280040879035, 'l1_Layer_3': 6.576295900623286e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 285, 'n_units_Layer_3': 165}. Best is trial 399 with value: 8.955792014623198.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.57 | sMAPE for Validation Set is: 44.48% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 23.18 | sMAPE for Test Set is: 28.19% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:50:50,093]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:50:54,611]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:50:59,734]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:51:06,521]\u001b[0m Trial 418 finished with value: 9.68624902606038 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015102797524585206, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0477828120097359, 'dropout_rate_Layer_2': 0.10125695881935962, 'dropout_rate_Layer_3': 0.05637334622676924, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010853567440644242, 'l1_Layer_2': 0.015324089862249698, 'l1_Layer_3': 8.993674625379452e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 75, 'n_units_Layer_3': 205}. Best is trial 399 with value: 8.955792014623198.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.69 | sMAPE for Validation Set is: 41.87% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 23.74 | sMAPE for Test Set is: 28.85% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:51:10,715]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:51:13,189]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:51:23,834]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:51:31,550]\u001b[0m Trial 421 finished with value: 8.976497764257557 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007443819195687066, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03329445938259748, 'dropout_rate_Layer_2': 0.004051916971446414, 'dropout_rate_Layer_3': 0.27114759655874393, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02095469900620336, 'l1_Layer_2': 0.00348193660383024, 'l1_Layer_3': 0.00025655295263775883, 'n_units_Layer_1': 245, 'n_units_Layer_2': 65, 'n_units_Layer_3': 160}. Best is trial 399 with value: 8.955792014623198.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.98 | sMAPE for Validation Set is: 38.78% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 24.03 | sMAPE for Test Set is: 28.64% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:51:32,633]\u001b[0m Trial 430 finished with value: 9.105139851634604 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018923135145978967, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.060843939193340066, 'dropout_rate_Layer_2': 0.110574923258651, 'dropout_rate_Layer_3': 0.043544485101802845, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007525606973042565, 'l1_Layer_2': 0.017916176658705586, 'l1_Layer_3': 6.806404275510765e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 85, 'n_units_Layer_3': 215}. Best is trial 399 with value: 8.955792014623198.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.11 | sMAPE for Validation Set is: 41.31% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 24.32 | sMAPE for Test Set is: 29.43% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:51:39,427]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:51:45,513]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:51:50,380]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:52:10,158]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:52:28,810]\u001b[0m Trial 429 finished with value: 9.092686499746149 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007177338599594202, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021911194552015893, 'dropout_rate_Layer_2': 0.0022960347451384078, 'dropout_rate_Layer_3': 0.25376690274046, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.019812138154035125, 'l1_Layer_2': 0.0037623464115043776, 'l1_Layer_3': 0.0009330570395322821, 'n_units_Layer_1': 240, 'n_units_Layer_2': 65, 'n_units_Layer_3': 170}. Best is trial 399 with value: 8.955792014623198.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.09 | sMAPE for Validation Set is: 39.40% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.38 | sMAPE for Test Set is: 27.75% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:52:33,642]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:52:37,751]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:52:41,317]\u001b[0m Trial 432 finished with value: 9.18618357826021 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018852297253899766, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06024057561783255, 'dropout_rate_Layer_2': 0.11297617543107652, 'dropout_rate_Layer_3': 0.03921590489320437, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007827923833268487, 'l1_Layer_2': 0.019030078103690326, 'l1_Layer_3': 6.74947115179409e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 70, 'n_units_Layer_3': 215}. Best is trial 399 with value: 8.955792014623198.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.19 | sMAPE for Validation Set is: 41.05% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 22.45 | sMAPE for Test Set is: 27.36% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:52:45,572]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:52:56,743]\u001b[0m Trial 436 finished with value: 8.96093630314648 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006215040628566117, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02445650131887237, 'dropout_rate_Layer_2': 0.03551728146605179, 'dropout_rate_Layer_3': 0.25694049131354313, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.019766091884889203, 'l1_Layer_2': 0.004093486185455182, 'l1_Layer_3': 0.0009042035801236518, 'n_units_Layer_1': 235, 'n_units_Layer_2': 65, 'n_units_Layer_3': 170}. Best is trial 399 with value: 8.955792014623198.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.96 | sMAPE for Validation Set is: 38.72% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.55 | sMAPE for Test Set is: 28.31% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:53:12,759]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:53:24,049]\u001b[0m Trial 443 finished with value: 9.422124558070825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014578526152649056, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11057572092762571, 'dropout_rate_Layer_2': 0.14620766339618013, 'dropout_rate_Layer_3': 0.36783214998670877, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013581917706290275, 'l1_Layer_2': 0.0039635063950061705, 'l1_Layer_3': 5.175305254607849e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 300, 'n_units_Layer_3': 155}. Best is trial 399 with value: 8.955792014623198.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.42 | sMAPE for Validation Set is: 42.05% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 26.14 | sMAPE for Test Set is: 31.84% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:53:28,644]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:53:37,458]\u001b[0m Trial 440 finished with value: 9.263260381110255 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019375584161540668, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04704069735361321, 'dropout_rate_Layer_2': 0.09802332266053232, 'dropout_rate_Layer_3': 0.058134969255291345, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004801634009253705, 'l1_Layer_2': 0.010118915276309317, 'l1_Layer_3': 0.00017648391171767703, 'n_units_Layer_1': 85, 'n_units_Layer_2': 100, 'n_units_Layer_3': 220}. Best is trial 399 with value: 8.955792014623198.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.26 | sMAPE for Validation Set is: 43.22% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 22.10 | sMAPE for Test Set is: 27.82% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:53:40,370]\u001b[0m Trial 442 finished with value: 9.26889226289734 and parameters: {'n_hidden': 3, 'learning_rate': 0.001971903148874866, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07602308310513835, 'dropout_rate_Layer_2': 0.11711046527388205, 'dropout_rate_Layer_3': 0.08326455907438195, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004908340143224027, 'l1_Layer_2': 0.010428145695461969, 'l1_Layer_3': 5.2672433216995764e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 80, 'n_units_Layer_3': 220}. Best is trial 399 with value: 8.955792014623198.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.27 | sMAPE for Validation Set is: 42.58% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 22.44 | sMAPE for Test Set is: 27.72% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:53:43,794]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:53:47,140]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:54:01,586]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:54:13,558]\u001b[0m Trial 450 finished with value: 9.365093011534535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015091946804906857, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15331513659139645, 'dropout_rate_Layer_2': 0.14382577173081448, 'dropout_rate_Layer_3': 0.33555684631137106, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012152118537991237, 'l1_Layer_2': 0.004848445676039408, 'l1_Layer_3': 5.5638503557309354e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150}. Best is trial 399 with value: 8.955792014623198.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.37 | sMAPE for Validation Set is: 40.79% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 24.82 | sMAPE for Test Set is: 30.53% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:54:31,891]\u001b[0m Trial 444 finished with value: 8.942690972300833 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007426217705386125, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03616666380427294, 'dropout_rate_Layer_2': 0.0003905417770275379, 'dropout_rate_Layer_3': 0.27040658034504833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.019422700138019857, 'l1_Layer_2': 0.0033500278754346672, 'l1_Layer_3': 0.0008371216259373519, 'n_units_Layer_1': 235, 'n_units_Layer_2': 65, 'n_units_Layer_3': 215}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.94 | sMAPE for Validation Set is: 38.56% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.43 | sMAPE for Test Set is: 27.83% | rMAE for Test Set is: 0.65\n",
      "MAE for Validation Set is: 9.44 | sMAPE for Validation Set is: 40.70% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 25.24 | sMAPE for Test Set is: 31.06% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:54:32,118]\u001b[0m Trial 451 finished with value: 9.44401227171928 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017653676382479375, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24631249879346886, 'dropout_rate_Layer_2': 0.14077690601381548, 'dropout_rate_Layer_3': 0.33377826502961694, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001132420418240099, 'l1_Layer_2': 0.004642605425632924, 'l1_Layer_3': 0.00031751783861308443, 'n_units_Layer_1': 290, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:54:41,310]\u001b[0m Trial 449 finished with value: 9.121051963738191 and parameters: {'n_hidden': 3, 'learning_rate': 0.001767232370561792, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04433146659640185, 'dropout_rate_Layer_2': 0.12773727960652392, 'dropout_rate_Layer_3': 0.05607323391918805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005047215623479834, 'l1_Layer_2': 0.01080102266513039, 'l1_Layer_3': 0.00012260247940873605, 'n_units_Layer_1': 100, 'n_units_Layer_2': 85, 'n_units_Layer_3': 235}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.12 | sMAPE for Validation Set is: 42.13% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 22.09 | sMAPE for Test Set is: 27.75% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:54:56,471]\u001b[0m Trial 452 finished with value: 9.410767225516318 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027954097319152237, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0826940040120966, 'dropout_rate_Layer_2': 0.10226595018958638, 'dropout_rate_Layer_3': 0.057458897598306025, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000473238393694997, 'l1_Layer_2': 0.011019765457704342, 'l1_Layer_3': 0.00013694938809365507, 'n_units_Layer_1': 80, 'n_units_Layer_2': 85, 'n_units_Layer_3': 230}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.41 | sMAPE for Validation Set is: 44.48% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 22.85 | sMAPE for Test Set is: 28.40% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:55:02,880]\u001b[0m Trial 453 finished with value: 9.428704839102794 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017469139184702668, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12686422200187825, 'dropout_rate_Layer_2': 0.14470192493257308, 'dropout_rate_Layer_3': 0.3306338604690999, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011011534632111885, 'l1_Layer_2': 0.004509516926158281, 'l1_Layer_3': 5.4716066176671154e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.43 | sMAPE for Validation Set is: 42.10% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 24.09 | sMAPE for Test Set is: 29.85% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:55:10,882]\u001b[0m Trial 455 finished with value: 9.374400973062109 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016695807089753699, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15613990899817734, 'dropout_rate_Layer_2': 0.14776950919305698, 'dropout_rate_Layer_3': 0.3362125751390802, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010973363326343636, 'l1_Layer_2': 0.0044846047292118225, 'l1_Layer_3': 5.4772319524322294e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.37 | sMAPE for Validation Set is: 42.03% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 25.10 | sMAPE for Test Set is: 30.94% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:55:25,179]\u001b[0m Trial 454 finished with value: 9.1160093167501 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007529651411882917, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023790296538705093, 'dropout_rate_Layer_2': 0.0007594501946409109, 'dropout_rate_Layer_3': 0.2671528532919588, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.018675488598702068, 'l1_Layer_2': 0.003376993601006188, 'l1_Layer_3': 0.00023734502931713983, 'n_units_Layer_1': 235, 'n_units_Layer_2': 60, 'n_units_Layer_3': 215}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.12 | sMAPE for Validation Set is: 40.24% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 24.01 | sMAPE for Test Set is: 28.42% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:55:37,282]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:55:44,680]\u001b[0m Trial 458 finished with value: 9.549624123078674 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017729753995410964, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12117684396740941, 'dropout_rate_Layer_2': 0.14480332009065633, 'dropout_rate_Layer_3': 0.33323763756629315, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010929542696395949, 'l1_Layer_2': 0.003978968265590279, 'l1_Layer_3': 4.4423735598132555e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 270, 'n_units_Layer_3': 145}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.55 | sMAPE for Validation Set is: 44.06% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 25.01 | sMAPE for Test Set is: 31.42% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:55:50,698]\u001b[0m Trial 456 finished with value: 9.008488178272545 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007099333620082814, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022199120352968976, 'dropout_rate_Layer_2': 0.01055106120186305, 'dropout_rate_Layer_3': 0.2679582863371667, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02083868740736276, 'l1_Layer_2': 0.003042543710383164, 'l1_Layer_3': 0.00016984389389161812, 'n_units_Layer_1': 210, 'n_units_Layer_2': 60, 'n_units_Layer_3': 220}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.01 | sMAPE for Validation Set is: 40.31% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.56 | sMAPE for Test Set is: 28.30% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:55:53,319]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:55:57,379]\u001b[0m Trial 459 finished with value: 9.58211597357357 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016907679881325275, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1252975252036115, 'dropout_rate_Layer_2': 0.14458356552150473, 'dropout_rate_Layer_3': 0.322536120864738, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010010567889054964, 'l1_Layer_2': 0.0029343121656821678, 'l1_Layer_3': 6.15111400004612e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 270, 'n_units_Layer_3': 150}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.58 | sMAPE for Validation Set is: 44.15% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 24.56 | sMAPE for Test Set is: 31.89% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:56:06,322]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:56:11,567]\u001b[0m Trial 461 finished with value: 9.321944453290689 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027438414073018558, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08563581759496044, 'dropout_rate_Layer_2': 0.12675616829401737, 'dropout_rate_Layer_3': 0.05708670440355892, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003928808265112259, 'l1_Layer_2': 0.010699035204791657, 'l1_Layer_3': 0.00013117477236478721, 'n_units_Layer_1': 100, 'n_units_Layer_2': 100, 'n_units_Layer_3': 235}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.32 | sMAPE for Validation Set is: 43.65% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 23.40 | sMAPE for Test Set is: 28.92% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:56:30,101]\u001b[0m Trial 464 finished with value: 9.37565584617488 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026265821908076025, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07917659433918783, 'dropout_rate_Layer_2': 0.12756869919250863, 'dropout_rate_Layer_3': 0.05662426823612815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004414569863135839, 'l1_Layer_2': 0.011129820138375717, 'l1_Layer_3': 0.00011919204383040313, 'n_units_Layer_1': 95, 'n_units_Layer_2': 95, 'n_units_Layer_3': 235}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.38 | sMAPE for Validation Set is: 44.84% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 22.74 | sMAPE for Test Set is: 28.65% | rMAE for Test Set is: 0.63\n",
      "MAE for Validation Set is: 9.32 | sMAPE for Validation Set is: 40.13% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 25.40 | sMAPE for Test Set is: 31.93% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:56:32,211]\u001b[0m Trial 466 finished with value: 9.323795006210979 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020631451658623527, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13049934002884195, 'dropout_rate_Layer_2': 0.1544918857678904, 'dropout_rate_Layer_3': 0.3316624932699213, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008039075455035623, 'l1_Layer_2': 0.0036811870802173864, 'l1_Layer_3': 4.155337572945994e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 260, 'n_units_Layer_3': 140}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.21 | sMAPE for Validation Set is: 41.70% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 23.73 | sMAPE for Test Set is: 28.42% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:56:34,153]\u001b[0m Trial 463 finished with value: 9.213115527386412 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011361132019868426, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0679051418772274, 'dropout_rate_Layer_2': 1.8916472467599664e-05, 'dropout_rate_Layer_3': 0.28360000354650583, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009688764340065107, 'l1_Layer_2': 0.011674664227047956, 'l1_Layer_3': 0.00017448390323274962, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 225}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:56:34,440]\u001b[0m Trial 465 finished with value: 9.33523417662653 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020642963594046057, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12096789446914344, 'dropout_rate_Layer_2': 0.15333036779923673, 'dropout_rate_Layer_3': 0.3325747164101878, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007098465621896693, 'l1_Layer_2': 0.0037695319527277925, 'l1_Layer_3': 4.637661346551152e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 260, 'n_units_Layer_3': 140}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.34 | sMAPE for Validation Set is: 41.51% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 23.95 | sMAPE for Test Set is: 30.08% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:56:36,968]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:56:47,193]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:57:00,464]\u001b[0m Trial 468 finished with value: 9.355249158725655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021705319001282916, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11947661074108995, 'dropout_rate_Layer_2': 0.15501115230804496, 'dropout_rate_Layer_3': 0.3088234033718771, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011011068296740531, 'l1_Layer_2': 0.0037342799716004126, 'l1_Layer_3': 4.3422248513264904e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.36 | sMAPE for Validation Set is: 41.15% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 24.66 | sMAPE for Test Set is: 30.61% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:57:05,516]\u001b[0m Trial 469 finished with value: 9.709538819586362 and parameters: {'n_hidden': 3, 'learning_rate': 0.002069551956324169, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11421917481219629, 'dropout_rate_Layer_2': 0.1546093216386456, 'dropout_rate_Layer_3': 0.3093545810460487, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011399979852909448, 'l1_Layer_2': 0.0024471796557799927, 'l1_Layer_3': 4.9104096013925884e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.71 | sMAPE for Validation Set is: 43.80% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 24.23 | sMAPE for Test Set is: 29.89% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:57:10,794]\u001b[0m Trial 470 finished with value: 9.392297662784628 and parameters: {'n_hidden': 3, 'learning_rate': 0.00402717003063137, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08991564890749157, 'dropout_rate_Layer_2': 0.15449075416746255, 'dropout_rate_Layer_3': 0.05317836550369987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00032835307940443683, 'l1_Layer_2': 0.011504591394416902, 'l1_Layer_3': 0.00017527352527019834, 'n_units_Layer_1': 100, 'n_units_Layer_2': 105, 'n_units_Layer_3': 235}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.39 | sMAPE for Validation Set is: 42.75% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 22.93 | sMAPE for Test Set is: 27.96% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:57:28,934]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.77 | sMAPE for Validation Set is: 46.23% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 24.23 | sMAPE for Test Set is: 30.60% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:57:30,502]\u001b[0m Trial 473 finished with value: 9.765415612350159 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022619349324862247, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1126219347807816, 'dropout_rate_Layer_2': 0.15294344434784649, 'dropout_rate_Layer_3': 0.30704128312835843, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010997953669905096, 'l1_Layer_2': 0.0026248013553029025, 'l1_Layer_3': 4.61883585932842e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.78 | sMAPE for Validation Set is: 45.03% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 26.86 | sMAPE for Test Set is: 34.59% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:57:32,288]\u001b[0m Trial 474 finished with value: 9.782856384386813 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023053712937074738, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11504686376412691, 'dropout_rate_Layer_2': 0.15382273548917924, 'dropout_rate_Layer_3': 0.31304997574244703, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011039120882867842, 'l1_Layer_2': 0.0024621351271328215, 'l1_Layer_3': 4.336833825455012e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.50 | sMAPE for Validation Set is: 43.18% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 24.57 | sMAPE for Test Set is: 29.86% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:57:38,054]\u001b[0m Trial 475 finished with value: 9.499084376223186 and parameters: {'n_hidden': 3, 'learning_rate': 0.002178252273745512, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11351913206948655, 'dropout_rate_Layer_2': 0.15811746410304214, 'dropout_rate_Layer_3': 0.3091962518791046, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011473089968334993, 'l1_Layer_2': 0.0025887260800548824, 'l1_Layer_3': 4.2806423312945586e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:57:42,870]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:57:43,739]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:57:52,826]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:58:02,836]\u001b[0m Trial 476 finished with value: 9.486810568088776 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022179391592778023, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11160592639307991, 'dropout_rate_Layer_2': 0.1628585633012583, 'dropout_rate_Layer_3': 0.32041352083114333, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00112473612608848, 'l1_Layer_2': 0.002780100823645022, 'l1_Layer_3': 4.386769039419313e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.49 | sMAPE for Validation Set is: 43.90% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 24.24 | sMAPE for Test Set is: 30.60% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:58:13,425]\u001b[0m Trial 481 finished with value: 9.48570482032711 and parameters: {'n_hidden': 3, 'learning_rate': 0.002241140821350027, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11662142284330758, 'dropout_rate_Layer_2': 0.1542137715838283, 'dropout_rate_Layer_3': 0.2928033819656644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011702827724055544, 'l1_Layer_2': 0.0029171935787960326, 'l1_Layer_3': 4.25485886722494e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 250, 'n_units_Layer_3': 145}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.49 | sMAPE for Validation Set is: 44.55% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 24.64 | sMAPE for Test Set is: 31.63% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:58:20,688]\u001b[0m Trial 482 finished with value: 9.274778752712153 and parameters: {'n_hidden': 3, 'learning_rate': 0.0057501424767904125, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10462588064070213, 'dropout_rate_Layer_2': 0.1625894414698799, 'dropout_rate_Layer_3': 0.05863645579488003, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004607524939760173, 'l1_Layer_2': 0.010877517642865337, 'l1_Layer_3': 0.0001256245972424257, 'n_units_Layer_1': 95, 'n_units_Layer_2': 105, 'n_units_Layer_3': 240}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.27 | sMAPE for Validation Set is: 41.48% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 23.21 | sMAPE for Test Set is: 28.30% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:58:34,136]\u001b[0m Trial 480 finished with value: 9.312196969894854 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007540901562138628, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07805049583208627, 'dropout_rate_Layer_2': 0.03366589302097596, 'dropout_rate_Layer_3': 0.27236567708555975, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.025811344250473617, 'l1_Layer_2': 0.0041503647911365505, 'l1_Layer_3': 9.125092908624493e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.31 | sMAPE for Validation Set is: 40.84% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 24.12 | sMAPE for Test Set is: 28.70% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:58:42,388]\u001b[0m Trial 484 finished with value: 9.37100805069383 and parameters: {'n_hidden': 3, 'learning_rate': 0.002720542390498041, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10774195218035627, 'dropout_rate_Layer_2': 0.151551225354696, 'dropout_rate_Layer_3': 0.29656439593663236, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011505496641256694, 'l1_Layer_2': 0.002884923228756685, 'l1_Layer_3': 4.7031861059917924e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 260, 'n_units_Layer_3': 145}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.37 | sMAPE for Validation Set is: 43.60% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 23.87 | sMAPE for Test Set is: 30.37% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:58:49,039]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:58:53,253]\u001b[0m Trial 485 finished with value: 9.441764355474804 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029223692930159533, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10247123051807783, 'dropout_rate_Layer_2': 0.15629299673250757, 'dropout_rate_Layer_3': 0.05106195945145666, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004312905025390608, 'l1_Layer_2': 0.010758914557331046, 'l1_Layer_3': 0.00015764801724986162, 'n_units_Layer_1': 95, 'n_units_Layer_2': 105, 'n_units_Layer_3': 240}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.44 | sMAPE for Validation Set is: 45.49% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 23.05 | sMAPE for Test Set is: 28.87% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:58:58,384]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:59:02,185]\u001b[0m Trial 483 finished with value: 9.149404759202412 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007870052612757595, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.038684034888826414, 'dropout_rate_Layer_2': 0.0005754936401957914, 'dropout_rate_Layer_3': 0.2701649560881419, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.019988166772847295, 'l1_Layer_2': 0.010460947378527125, 'l1_Layer_3': 9.929661466120178e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 55, 'n_units_Layer_3': 220}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.15 | sMAPE for Validation Set is: 39.72% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 24.03 | sMAPE for Test Set is: 28.73% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:59:04,210]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:59:11,707]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:59:15,230]\u001b[0m Trial 487 finished with value: 9.51068322160616 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027054613317496093, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11317826239244139, 'dropout_rate_Layer_2': 0.15208601718073908, 'dropout_rate_Layer_3': 0.28444943515472376, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001142444317952116, 'l1_Layer_2': 0.0025972564786489534, 'l1_Layer_3': 2.9353215295862205e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.51 | sMAPE for Validation Set is: 41.75% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 28.11 | sMAPE for Test Set is: 35.93% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:59:27,063]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:59:30,205]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 03:59:37,883]\u001b[0m Trial 492 finished with value: 9.717468257721587 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025492158087529475, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1123940792160536, 'dropout_rate_Layer_2': 0.15228923550968454, 'dropout_rate_Layer_3': 0.30744471193178835, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012389259310758077, 'l1_Layer_2': 0.0028608243856730903, 'l1_Layer_3': 4.421441816468047e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 260, 'n_units_Layer_3': 145}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.72 | sMAPE for Validation Set is: 44.02% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 26.09 | sMAPE for Test Set is: 33.41% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 03:59:43,935]\u001b[0m Trial 488 finished with value: 9.509988369873502 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010313732176923066, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08120397078686722, 'dropout_rate_Layer_2': 0.03539193589563514, 'dropout_rate_Layer_3': 0.2696076157282908, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.019756666768059695, 'l1_Layer_2': 0.003879800858629441, 'l1_Layer_3': 6.087801442594734e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 55, 'n_units_Layer_3': 225}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.51 | sMAPE for Validation Set is: 42.68% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 23.22 | sMAPE for Test Set is: 27.79% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:00:02,613]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:00:03,008]\u001b[0m Trial 498 finished with value: 9.461759567318161 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028719415577491856, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1146869431390709, 'dropout_rate_Layer_2': 0.14586897980105543, 'dropout_rate_Layer_3': 0.3049075152702381, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009933917930237187, 'l1_Layer_2': 0.0028453161178144076, 'l1_Layer_3': 3.247201681210872e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 135}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.46 | sMAPE for Validation Set is: 42.11% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 25.80 | sMAPE for Test Set is: 31.86% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:00:12,679]\u001b[0m Trial 496 finished with value: 9.056617961061727 and parameters: {'n_hidden': 3, 'learning_rate': 0.000970766505886775, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03502222617602479, 'dropout_rate_Layer_2': 0.01017525533982079, 'dropout_rate_Layer_3': 0.2670264842366865, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01880852423993595, 'l1_Layer_2': 0.010820138523701006, 'l1_Layer_3': 6.954395954945752e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 60, 'n_units_Layer_3': 260}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.06 | sMAPE for Validation Set is: 39.12% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 24.20 | sMAPE for Test Set is: 28.83% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:00:21,347]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:00:23,504]\u001b[0m Trial 497 finished with value: 9.39229500387791 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009476672057500971, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03673069599095328, 'dropout_rate_Layer_2': 0.013319112959721886, 'dropout_rate_Layer_3': 0.2854949168749183, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.019557993610349225, 'l1_Layer_2': 0.011350687644786375, 'l1_Layer_3': 5.570424135403797e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 60, 'n_units_Layer_3': 255}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.39 | sMAPE for Validation Set is: 42.04% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 24.45 | sMAPE for Test Set is: 29.20% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:00:29,380]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:00:37,376]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:00:38,072]\u001b[0m Trial 499 finished with value: 9.537906868620643 and parameters: {'n_hidden': 3, 'learning_rate': 0.00277158001029367, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10834650253654587, 'dropout_rate_Layer_2': 0.14600324715518762, 'dropout_rate_Layer_3': 0.3036823442513691, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009774415704649295, 'l1_Layer_2': 0.0026331111368259686, 'l1_Layer_3': 3.092564145884809e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 145}. Best is trial 444 with value: 8.942690972300833.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.54 | sMAPE for Validation Set is: 43.82% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 25.41 | sMAPE for Test Set is: 32.73% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:00:40,689]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:00:43,690]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:00:51,415]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:00:58,773]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:01:11,051]\u001b[0m Trial 506 finished with value: 8.844322035269485 and parameters: {'n_hidden': 3, 'learning_rate': 0.00642594871924963, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08010765084070945, 'dropout_rate_Layer_2': 0.14660953930800258, 'dropout_rate_Layer_3': 0.06061803730763834, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00038803604393840236, 'l1_Layer_2': 0.005770306988413397, 'l1_Layer_3': 0.0002594814104786049, 'n_units_Layer_1': 100, 'n_units_Layer_2': 115, 'n_units_Layer_3': 240}. Best is trial 506 with value: 8.844322035269485.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.84 | sMAPE for Validation Set is: 40.09% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.54 | sMAPE for Test Set is: 27.54% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:01:13,170]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:01:18,909]\u001b[0m Trial 504 finished with value: 8.612460782944105 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034452920892594305, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07913977473667402, 'dropout_rate_Layer_2': 0.14850471277744068, 'dropout_rate_Layer_3': 0.05979624790887723, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003996824162842666, 'l1_Layer_2': 0.010099439914118553, 'l1_Layer_3': 9.007821791394558e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 105, 'n_units_Layer_3': 240}. Best is trial 504 with value: 8.612460782944105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.61 | sMAPE for Validation Set is: 38.70% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.16 | sMAPE for Test Set is: 27.27% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:01:23,425]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:01:27,528]\u001b[0m Trial 509 finished with value: 9.251055305845338 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015155234933900343, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0012057118818651624, 'dropout_rate_Layer_2': 0.023445022797890847, 'dropout_rate_Layer_3': 0.2535250680404181, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007591884520693049, 'l1_Layer_2': 0.016611234993846355, 'l1_Layer_3': 0.00012083255599075804, 'n_units_Layer_1': 240, 'n_units_Layer_2': 65, 'n_units_Layer_3': 210}. Best is trial 504 with value: 8.612460782944105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.25 | sMAPE for Validation Set is: 40.64% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 23.99 | sMAPE for Test Set is: 28.72% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:01:27,832]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:01:28,447]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:01:43,337]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:01:50,608]\u001b[0m Trial 511 finished with value: 9.597612224480928 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022632201535354186, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1454166498275361, 'dropout_rate_Layer_2': 0.16871917987003524, 'dropout_rate_Layer_3': 0.3128465464420671, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011832766536423033, 'l1_Layer_2': 0.001543480620535675, 'l1_Layer_3': 2.631193133161722e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 255, 'n_units_Layer_3': 140}. Best is trial 504 with value: 8.612460782944105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.60 | sMAPE for Validation Set is: 46.15% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 24.08 | sMAPE for Test Set is: 30.28% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:01:54,888]\u001b[0m Trial 515 finished with value: 9.333842840018711 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020104274865771483, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11279743224736717, 'dropout_rate_Layer_2': 0.16113715689268884, 'dropout_rate_Layer_3': 0.31495112811333154, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012914853852930318, 'l1_Layer_2': 0.0024714525059767777, 'l1_Layer_3': 3.627485150070854e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 245, 'n_units_Layer_3': 135}. Best is trial 504 with value: 8.612460782944105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.33 | sMAPE for Validation Set is: 42.15% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 25.28 | sMAPE for Test Set is: 32.04% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:01:58,576]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:02:01,993]\u001b[0m Trial 517 finished with value: 9.464360918928849 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024352218035242606, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0868944157338778, 'dropout_rate_Layer_2': 0.16299681477508987, 'dropout_rate_Layer_3': 0.31582850604302887, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001300245924347285, 'l1_Layer_2': 0.002509300117215455, 'l1_Layer_3': 3.772597094553141e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 240, 'n_units_Layer_3': 135}. Best is trial 504 with value: 8.612460782944105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.46 | sMAPE for Validation Set is: 43.45% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 24.78 | sMAPE for Test Set is: 31.13% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:02:09,444]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:02:23,588]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:02:32,197]\u001b[0m Trial 522 finished with value: 9.527416202507865 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029114403384006976, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12443792811614311, 'dropout_rate_Layer_2': 0.17788648363444004, 'dropout_rate_Layer_3': 0.307303560549171, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009046048073135737, 'l1_Layer_2': 0.0028246104373842135, 'l1_Layer_3': 3.216448287581179e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 240, 'n_units_Layer_3': 135}. Best is trial 504 with value: 8.612460782944105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.53 | sMAPE for Validation Set is: 42.51% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 23.98 | sMAPE for Test Set is: 29.85% | rMAE for Test Set is: 0.67\n",
      "MAE for Validation Set is: 8.82 | sMAPE for Validation Set is: 39.15% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.60 | sMAPE for Test Set is: 27.64% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:02:32,397]\u001b[0m Trial 521 finished with value: 8.819919303307517 and parameters: {'n_hidden': 3, 'learning_rate': 0.006799727891682414, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09339047820749383, 'dropout_rate_Layer_2': 0.16770220693200813, 'dropout_rate_Layer_3': 0.05502779984895966, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003063546077258187, 'l1_Layer_2': 0.009201949618503616, 'l1_Layer_3': 0.00010558663398883386, 'n_units_Layer_1': 110, 'n_units_Layer_2': 95, 'n_units_Layer_3': 230}. Best is trial 504 with value: 8.612460782944105.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:02:39,207]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:02:41,427]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:02:46,035]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:02:48,606]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:02:56,804]\u001b[0m Trial 520 finished with value: 8.733400523958515 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025203855004924712, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08546127574567544, 'dropout_rate_Layer_2': 0.16812564561867274, 'dropout_rate_Layer_3': 0.05636997888615747, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005627455636378311, 'l1_Layer_2': 0.00980724539594978, 'l1_Layer_3': 0.00010690108439711112, 'n_units_Layer_1': 95, 'n_units_Layer_2': 95, 'n_units_Layer_3': 230}. Best is trial 504 with value: 8.612460782944105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.73 | sMAPE for Validation Set is: 39.41% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.60 | sMAPE for Test Set is: 27.52% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:02:57,983]\u001b[0m Trial 524 finished with value: 9.409688863130002 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025816234523776344, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12518996625867088, 'dropout_rate_Layer_2': 0.16699109803792123, 'dropout_rate_Layer_3': 0.3176794126998438, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009455652169122881, 'l1_Layer_2': 0.001576666838058455, 'l1_Layer_3': 2.9284730859349243e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 250, 'n_units_Layer_3': 140}. Best is trial 504 with value: 8.612460782944105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.41 | sMAPE for Validation Set is: 41.17% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 25.48 | sMAPE for Test Set is: 31.43% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:03:04,970]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:03:14,117]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:03:19,080]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:03:20,022]\u001b[0m Trial 531 finished with value: 9.499289521262147 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026121147658523663, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08508924779932749, 'dropout_rate_Layer_2': 0.16763956248894193, 'dropout_rate_Layer_3': 0.29860205814653146, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012675653292074656, 'l1_Layer_2': 0.003539991832099624, 'l1_Layer_3': 3.557117663935696e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 245, 'n_units_Layer_3': 135}. Best is trial 504 with value: 8.612460782944105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.50 | sMAPE for Validation Set is: 40.91% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 25.28 | sMAPE for Test Set is: 30.49% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:03:26,895]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:03:31,932]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:03:50,111]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:03:54,542]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:03:58,265]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:03:59,838]\u001b[0m Trial 538 finished with value: 8.677262418463952 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025798742825666084, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10319666512477066, 'dropout_rate_Layer_2': 0.1947265313779676, 'dropout_rate_Layer_3': 0.0628558086182279, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003266013475063609, 'l1_Layer_2': 0.007089196317576142, 'l1_Layer_3': 8.904688262872772e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 130, 'n_units_Layer_3': 220}. Best is trial 504 with value: 8.612460782944105.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.68 | sMAPE for Validation Set is: 38.85% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.01 | sMAPE for Test Set is: 28.39% | rMAE for Test Set is: 0.64\n",
      "MAE for Validation Set is: 8.60 | sMAPE for Validation Set is: 38.37% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.23 | sMAPE for Test Set is: 27.19% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:04:04,582]\u001b[0m Trial 535 finished with value: 8.600073709065509 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034718332438270763, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10488804894120639, 'dropout_rate_Layer_2': 0.17831382956016056, 'dropout_rate_Layer_3': 0.0809033665316237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005632968939222638, 'l1_Layer_2': 0.000730498151096022, 'l1_Layer_3': 8.683031682168959e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 95, 'n_units_Layer_3': 225}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:04:04,953]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:04:13,317]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:04:31,687]\u001b[0m Trial 540 finished with value: 8.69890958937499 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026066497880345824, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08041808600451951, 'dropout_rate_Layer_2': 0.16422378920016587, 'dropout_rate_Layer_3': 0.026737339548251065, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000303543461504752, 'l1_Layer_2': 0.0010975683611566436, 'l1_Layer_3': 9.091082220663314e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 105, 'n_units_Layer_3': 240}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.70 | sMAPE for Validation Set is: 38.48% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.25 | sMAPE for Test Set is: 26.92% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:04:56,494]\u001b[0m Trial 544 finished with value: 8.780003078224876 and parameters: {'n_hidden': 3, 'learning_rate': 0.003410258520125518, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10370843110693732, 'dropout_rate_Layer_2': 0.1926934882319111, 'dropout_rate_Layer_3': 0.06602020305141976, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003035646720747832, 'l1_Layer_2': 0.002917877449094549, 'l1_Layer_3': 0.0001330388280860406, 'n_units_Layer_1': 105, 'n_units_Layer_2': 105, 'n_units_Layer_3': 235}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.78 | sMAPE for Validation Set is: 39.52% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.04 | sMAPE for Test Set is: 27.50% | rMAE for Test Set is: 0.64\n",
      "MAE for Validation Set is: 8.76 | sMAPE for Validation Set is: 38.59% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.56 | sMAPE for Test Set is: 27.39% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:04:59,406]\u001b[0m Trial 542 finished with value: 8.758275745641942 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034054515139397092, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10401420359455679, 'dropout_rate_Layer_2': 0.20139978481530393, 'dropout_rate_Layer_3': 0.028136419064706545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00030429452602944996, 'l1_Layer_2': 0.006144082241299073, 'l1_Layer_3': 0.0001292752892494701, 'n_units_Layer_1': 95, 'n_units_Layer_2': 125, 'n_units_Layer_3': 235}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:05:04,986]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:05:05,804]\u001b[0m Trial 546 finished with value: 8.794381383229377 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034557657850129474, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1347481960189102, 'dropout_rate_Layer_2': 0.194481074970621, 'dropout_rate_Layer_3': 0.02603471305385209, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003014045543549416, 'l1_Layer_2': 0.006073973075900471, 'l1_Layer_3': 0.00012593190201599835, 'n_units_Layer_1': 90, 'n_units_Layer_2': 105, 'n_units_Layer_3': 235}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.79 | sMAPE for Validation Set is: 38.28% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.87 | sMAPE for Test Set is: 27.71% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:05:24,086]\u001b[0m Trial 547 finished with value: 9.462763459742929 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022360298652597055, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10184066917072195, 'dropout_rate_Layer_2': 0.16328402878033374, 'dropout_rate_Layer_3': 0.3227810905439022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001315346159439678, 'l1_Layer_2': 0.003958607516383725, 'l1_Layer_3': 3.6392891874843875e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 135}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.46 | sMAPE for Validation Set is: 40.86% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 26.85 | sMAPE for Test Set is: 32.80% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:05:29,552]\u001b[0m Trial 550 finished with value: 9.29534163361334 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023024467736454343, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10362537967688887, 'dropout_rate_Layer_2': 0.16369238489381513, 'dropout_rate_Layer_3': 0.3244782519900461, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013741951431222481, 'l1_Layer_2': 0.003823760298278806, 'l1_Layer_3': 3.7135515822265255e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 250, 'n_units_Layer_3': 135}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.30 | sMAPE for Validation Set is: 43.03% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 24.33 | sMAPE for Test Set is: 30.02% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:05:33,987]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.46 | sMAPE for Validation Set is: 40.93% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 25.06 | sMAPE for Test Set is: 31.04% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:05:38,365]\u001b[0m Trial 549 finished with value: 9.459666785173319 and parameters: {'n_hidden': 3, 'learning_rate': 0.002249328275636285, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10375458817675051, 'dropout_rate_Layer_2': 0.16259926123783253, 'dropout_rate_Layer_3': 0.32378494439238825, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013083729135114448, 'l1_Layer_2': 0.0036577132113558707, 'l1_Layer_3': 3.614898042663645e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 135}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:05:49,760]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:05:57,504]\u001b[0m Trial 551 finished with value: 9.229990610442675 and parameters: {'n_hidden': 3, 'learning_rate': 0.001878965476536279, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10410070126975793, 'dropout_rate_Layer_2': 0.20449957537766497, 'dropout_rate_Layer_3': 0.32360531901402007, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013650442283895618, 'l1_Layer_2': 0.0038524458478534805, 'l1_Layer_3': 3.86685014220309e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 230, 'n_units_Layer_3': 135}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.23 | sMAPE for Validation Set is: 41.00% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 24.49 | sMAPE for Test Set is: 30.09% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:06:08,262]\u001b[0m Trial 545 finished with value: 9.021501212479789 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005869211758823916, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025537394313391998, 'dropout_rate_Layer_2': 0.32725903821811064, 'dropout_rate_Layer_3': 0.22634529098944078, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011792499437397252, 'l1_Layer_2': 0.00820768810093261, 'l1_Layer_3': 0.0002647475700652941, 'n_units_Layer_1': 190, 'n_units_Layer_2': 60, 'n_units_Layer_3': 195}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.02 | sMAPE for Validation Set is: 39.05% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.83 | sMAPE for Test Set is: 28.57% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:06:12,787]\u001b[0m Trial 553 finished with value: 8.840901908045195 and parameters: {'n_hidden': 3, 'learning_rate': 0.00355345733809319, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10305582804526647, 'dropout_rate_Layer_2': 0.2064570919444833, 'dropout_rate_Layer_3': 0.008891475588513775, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00030247958175497083, 'l1_Layer_2': 0.0006142824935221052, 'l1_Layer_3': 9.00854454108736e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 135, 'n_units_Layer_3': 220}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.84 | sMAPE for Validation Set is: 39.46% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.75 | sMAPE for Test Set is: 29.34% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:06:35,078]\u001b[0m Trial 555 finished with value: 8.831298057062824 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024919918580074796, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10451710293116179, 'dropout_rate_Layer_2': 0.20159020389168328, 'dropout_rate_Layer_3': 0.039174122783098606, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022508699701306655, 'l1_Layer_2': 0.004628511869505897, 'l1_Layer_3': 0.00010236442933968246, 'n_units_Layer_1': 90, 'n_units_Layer_2': 125, 'n_units_Layer_3': 250}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.83 | sMAPE for Validation Set is: 38.68% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.72 | sMAPE for Test Set is: 27.87% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:06:39,179]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:06:40,066]\u001b[0m Trial 556 finished with value: 8.77927455254667 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025865856260386794, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10417962883198778, 'dropout_rate_Layer_2': 0.20039358408786961, 'dropout_rate_Layer_3': 0.012813642988424523, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019873051035120497, 'l1_Layer_2': 0.0006071245642511914, 'l1_Layer_3': 9.782595556370965e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 145, 'n_units_Layer_3': 235}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.78 | sMAPE for Validation Set is: 39.57% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.80 | sMAPE for Test Set is: 29.83% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:06:41,328]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:06:48,407]\u001b[0m Trial 557 finished with value: 9.83363043971339 and parameters: {'n_hidden': 3, 'learning_rate': 0.002149721942589693, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10305535742253143, 'dropout_rate_Layer_2': 0.20466677675113612, 'dropout_rate_Layer_3': 0.304107854529859, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001760835056224942, 'l1_Layer_2': 0.0032604275109220015, 'l1_Layer_3': 3.198886312142976e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 235, 'n_units_Layer_3': 130}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.83 | sMAPE for Validation Set is: 43.44% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 24.13 | sMAPE for Test Set is: 30.05% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:06:51,175]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:06:55,667]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:06:56,085]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:07:08,468]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:07:11,779]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:07:15,622]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:07:20,028]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:07:20,690]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:07:26,226]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:07:39,057]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:07:50,597]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:07:59,105]\u001b[0m Trial 573 finished with value: 8.846711831958473 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031186770165705703, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10048519818550669, 'dropout_rate_Layer_2': 0.18435476233378081, 'dropout_rate_Layer_3': 0.016974783327734805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020318480616882698, 'l1_Layer_2': 0.0006130200053866008, 'l1_Layer_3': 8.989484372567986e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 125, 'n_units_Layer_3': 225}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.85 | sMAPE for Validation Set is: 40.03% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.99 | sMAPE for Test Set is: 29.69% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:08:03,366]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:08:07,925]\u001b[0m Trial 574 finished with value: 8.875791056784857 and parameters: {'n_hidden': 3, 'learning_rate': 0.003607329743047195, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10766907939492393, 'dropout_rate_Layer_2': 0.18753663185801406, 'dropout_rate_Layer_3': 0.04338598306322052, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028155854311964605, 'l1_Layer_2': 0.0006923989761886845, 'l1_Layer_3': 9.339225307058378e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 135, 'n_units_Layer_3': 245}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.88 | sMAPE for Validation Set is: 39.83% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 24.31 | sMAPE for Test Set is: 29.64% | rMAE for Test Set is: 0.67\n",
      "MAE for Validation Set is: 8.87 | sMAPE for Validation Set is: 39.06% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.62 | sMAPE for Test Set is: 27.27% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:08:10,845]\u001b[0m Trial 567 finished with value: 8.867157714466531 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035950061287826295, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10547841039272189, 'dropout_rate_Layer_2': 0.22596759588706716, 'dropout_rate_Layer_3': 0.015942702090686923, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018424139030807842, 'l1_Layer_2': 0.0018361057140178164, 'l1_Layer_3': 0.00010179714167552488, 'n_units_Layer_1': 90, 'n_units_Layer_2': 125, 'n_units_Layer_3': 265}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:08:16,112]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:08:38,193]\u001b[0m Trial 576 finished with value: 9.479025861689392 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018824364535539317, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10949220945696851, 'dropout_rate_Layer_2': 0.14995437843048795, 'dropout_rate_Layer_3': 0.3090928330599452, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012608665358379513, 'l1_Layer_2': 0.002318256893379972, 'l1_Layer_3': 3.560099053765323e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 260, 'n_units_Layer_3': 130}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.48 | sMAPE for Validation Set is: 43.75% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 24.01 | sMAPE for Test Set is: 29.89% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:08:43,858]\u001b[0m Trial 579 finished with value: 8.941930411188908 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031156392181441645, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1301046012167997, 'dropout_rate_Layer_2': 0.23140777739455104, 'dropout_rate_Layer_3': 0.015996212780852302, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012693198535788247, 'l1_Layer_2': 0.0006192247030741018, 'l1_Layer_3': 0.00010072724248460453, 'n_units_Layer_1': 120, 'n_units_Layer_2': 140, 'n_units_Layer_3': 270}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.94 | sMAPE for Validation Set is: 41.89% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.86 | sMAPE for Test Set is: 27.72% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:08:53,222]\u001b[0m Trial 577 finished with value: 8.868847798813297 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034788794387879854, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1283724328656514, 'dropout_rate_Layer_2': 0.2308528802929661, 'dropout_rate_Layer_3': 0.01716895159518625, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001959808936330138, 'l1_Layer_2': 0.0006040312396928829, 'l1_Layer_3': 9.114456594985047e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 245}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.87 | sMAPE for Validation Set is: 39.22% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.80 | sMAPE for Test Set is: 27.71% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:08:58,797]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:09:12,071]\u001b[0m Trial 580 finished with value: 8.945824471700904 and parameters: {'n_hidden': 3, 'learning_rate': 0.004253151582276481, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1272650136515598, 'dropout_rate_Layer_2': 0.2041516715892052, 'dropout_rate_Layer_3': 0.01133598444264041, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014289172409918705, 'l1_Layer_2': 0.0003896056727441943, 'l1_Layer_3': 9.156006693627634e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 140, 'n_units_Layer_3': 270}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.95 | sMAPE for Validation Set is: 40.02% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.36 | sMAPE for Test Set is: 27.53% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:09:19,347]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:09:19,870]\u001b[0m Trial 582 finished with value: 8.876101194245459 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031704642684623687, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14549320788325168, 'dropout_rate_Layer_2': 0.23244292752597553, 'dropout_rate_Layer_3': 0.017247702366577425, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001386517215971703, 'l1_Layer_2': 0.0006277996211519285, 'l1_Layer_3': 9.624587288336777e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 280}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.88 | sMAPE for Validation Set is: 39.46% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 24.69 | sMAPE for Test Set is: 30.84% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:09:33,072]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:09:38,255]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:09:42,597]\u001b[0m Trial 583 finished with value: 9.017346048004088 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008834942323145981, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03654973179364935, 'dropout_rate_Layer_2': 0.20833603239061937, 'dropout_rate_Layer_3': 0.26382851249791683, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006322722183536993, 'l1_Layer_2': 0.002744510930913133, 'l1_Layer_3': 0.00039983715661384, 'n_units_Layer_1': 250, 'n_units_Layer_2': 50, 'n_units_Layer_3': 210}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.02 | sMAPE for Validation Set is: 40.06% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.84 | sMAPE for Test Set is: 28.76% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:09:49,625]\u001b[0m Trial 578 finished with value: 9.380560920595459 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007429993772995641, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03664449330511701, 'dropout_rate_Layer_2': 0.2770470191695279, 'dropout_rate_Layer_3': 0.2659597199472632, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01857655407104896, 'l1_Layer_2': 0.0028035711183041503, 'l1_Layer_3': 0.0002559305803851756, 'n_units_Layer_1': 250, 'n_units_Layer_2': 50, 'n_units_Layer_3': 215}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:09:49,756]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.38 | sMAPE for Validation Set is: 40.97% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 23.91 | sMAPE for Test Set is: 28.69% | rMAE for Test Set is: 0.66\n",
      "MAE for Validation Set is: 9.51 | sMAPE for Validation Set is: 44.46% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 24.02 | sMAPE for Test Set is: 29.89% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:09:55,911]\u001b[0m Trial 586 finished with value: 9.512757991968257 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022845799329504653, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09982144446359187, 'dropout_rate_Layer_2': 0.15216797232053927, 'dropout_rate_Layer_3': 0.32578843413930064, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015499457880816176, 'l1_Layer_2': 0.004447399820704232, 'l1_Layer_3': 5.2701947758696924e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 260, 'n_units_Layer_3': 125}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:09:58,819]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:10:00,235]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:10:07,171]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:10:07,991]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:10:22,224]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:10:30,121]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.84 | sMAPE for Validation Set is: 39.32% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.94 | sMAPE for Test Set is: 29.50% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:10:32,605]\u001b[0m Trial 592 finished with value: 8.83824964027786 and parameters: {'n_hidden': 3, 'learning_rate': 0.00441875395214465, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13939183627105997, 'dropout_rate_Layer_2': 0.2277411207265856, 'dropout_rate_Layer_3': 0.016706908064918563, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010397405645885708, 'l1_Layer_2': 0.0003945482108145879, 'l1_Layer_3': 8.742879166248276e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 155, 'n_units_Layer_3': 275}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:10:38,318]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:10:40,878]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:10:45,402]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:10:48,370]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:10:48,396]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:10:56,583]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:10:57,197]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:11:05,533]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:11:10,060]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:11:27,977]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:11:34,681]\u001b[0m Trial 605 finished with value: 9.527256796141687 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023488511587974248, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07903637269253619, 'dropout_rate_Layer_2': 0.16930124871247956, 'dropout_rate_Layer_3': 0.2976367379058778, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007528996306403248, 'l1_Layer_2': 0.004389491490401318, 'l1_Layer_3': 5.557674273408382e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 245, 'n_units_Layer_3': 140}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.53 | sMAPE for Validation Set is: 45.06% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 24.17 | sMAPE for Test Set is: 30.16% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:11:39,450]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:11:40,503]\u001b[0m Trial 608 finished with value: 8.996861976033964 and parameters: {'n_hidden': 3, 'learning_rate': 0.003535841197152636, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11095592397006146, 'dropout_rate_Layer_2': 0.24959939586557336, 'dropout_rate_Layer_3': 0.02942047839737464, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001725911375621539, 'l1_Layer_2': 0.001728004046776648, 'l1_Layer_3': 0.00010076423762795636, 'n_units_Layer_1': 115, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.00 | sMAPE for Validation Set is: 39.71% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.94 | sMAPE for Test Set is: 29.20% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:11:44,133]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:11:49,162]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:11:54,801]\u001b[0m Trial 588 finished with value: 9.185895285912848 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007551841928304624, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03688021598035401, 'dropout_rate_Layer_2': 0.27091439835418524, 'dropout_rate_Layer_3': 0.26335470759020935, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006199213647839981, 'l1_Layer_2': 0.015824956280419644, 'l1_Layer_3': 0.00025733864473477243, 'n_units_Layer_1': 235, 'n_units_Layer_2': 50, 'n_units_Layer_3': 235}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.19 | sMAPE for Validation Set is: 39.99% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 23.93 | sMAPE for Test Set is: 28.79% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:11:58,399]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:12:03,578]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:12:18,370]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:12:23,411]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:12:30,945]\u001b[0m Trial 615 finished with value: 9.533889857915229 and parameters: {'n_hidden': 3, 'learning_rate': 0.002324491271010168, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10124623918777426, 'dropout_rate_Layer_2': 0.14723808507276248, 'dropout_rate_Layer_3': 0.3108221898168612, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018063698784756767, 'l1_Layer_2': 0.0028228375162796197, 'l1_Layer_3': 4.3685095205080276e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 260, 'n_units_Layer_3': 145}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.53 | sMAPE for Validation Set is: 43.87% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 24.23 | sMAPE for Test Set is: 30.31% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:12:35,929]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:12:40,450]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:12:46,246]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:12:59,756]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:12:59,764]\u001b[0m Trial 620 finished with value: 9.477345193092649 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017840848271813796, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1205958095720734, 'dropout_rate_Layer_2': 0.1359567350817402, 'dropout_rate_Layer_3': 0.33302726981713615, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001292858578895779, 'l1_Layer_2': 0.0035946265260683565, 'l1_Layer_3': 3.425870750344868e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 245, 'n_units_Layer_3': 135}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.48 | sMAPE for Validation Set is: 40.69% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 29.65 | sMAPE for Test Set is: 37.02% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:13:00,264]\u001b[0m Trial 619 finished with value: 9.687693376087601 and parameters: {'n_hidden': 3, 'learning_rate': 0.001832691913601452, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12784893069954978, 'dropout_rate_Layer_2': 0.1373258814704884, 'dropout_rate_Layer_3': 0.3324404388097543, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001322623086982293, 'l1_Layer_2': 0.003577989886649625, 'l1_Layer_3': 3.698900906256198e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 245, 'n_units_Layer_3': 145}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.69 | sMAPE for Validation Set is: 45.37% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 23.93 | sMAPE for Test Set is: 30.01% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:13:10,767]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:13:11,163]\u001b[0m Trial 621 finished with value: 9.48893304568424 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017649059200299368, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12385972057891198, 'dropout_rate_Layer_2': 0.13690624754502728, 'dropout_rate_Layer_3': 0.33143026509955575, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013250517917658743, 'l1_Layer_2': 0.003826338863739962, 'l1_Layer_3': 3.6317696311679334e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 135}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.49 | sMAPE for Validation Set is: 42.91% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 23.91 | sMAPE for Test Set is: 29.50% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:13:40,115]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:13:46,228]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:13:46,240]\u001b[0m Trial 625 finished with value: 9.378195719341216 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017367827968067472, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12103979652740583, 'dropout_rate_Layer_2': 0.1359401586156566, 'dropout_rate_Layer_3': 0.2951343422181688, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009311097201293545, 'l1_Layer_2': 0.0015074812919063534, 'l1_Layer_3': 2.4017399900738816e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 240, 'n_units_Layer_3': 135}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.38 | sMAPE for Validation Set is: 41.95% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 24.20 | sMAPE for Test Set is: 30.90% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:13:53,423]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:14:02,264]\u001b[0m Trial 628 finished with value: 9.327693319236834 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016025334113881412, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12157057702474411, 'dropout_rate_Layer_2': 0.13443098424423708, 'dropout_rate_Layer_3': 0.3332775878863427, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00095235281566046, 'l1_Layer_2': 0.003796335985238981, 'l1_Layer_3': 3.3603299906747165e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 235, 'n_units_Layer_3': 135}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.33 | sMAPE for Validation Set is: 42.86% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 23.46 | sMAPE for Test Set is: 29.63% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:14:09,545]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:14:11,214]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.60 | sMAPE for Validation Set is: 43.09% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 24.75 | sMAPE for Test Set is: 30.55% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:14:14,813]\u001b[0m Trial 629 finished with value: 9.596988282719405 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005834826216326111, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.048650971024008574, 'dropout_rate_Layer_2': 0.15772039487354317, 'dropout_rate_Layer_3': 0.2266006883845503, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003644997473264162, 'l1_Layer_2': 0.0063163244418136845, 'l1_Layer_3': 4.036959023238622e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 55, 'n_units_Layer_3': 215}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:14:16,285]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:14:17,663]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:14:26,405]\u001b[0m Trial 630 finished with value: 8.841096906815565 and parameters: {'n_hidden': 3, 'learning_rate': 0.002527627236384424, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11788965144276632, 'dropout_rate_Layer_2': 0.1979246443576927, 'dropout_rate_Layer_3': 0.0010897704386161819, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.888220348048137e-05, 'l1_Layer_2': 0.00027581756854658555, 'l1_Layer_3': 6.54629233174213e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 150, 'n_units_Layer_3': 245}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.84 | sMAPE for Validation Set is: 39.12% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.95 | sMAPE for Test Set is: 27.84% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:14:36,023]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:14:40,162]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:14:41,030]\u001b[0m Trial 638 finished with value: 8.82239250077061 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026577875800193967, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1382529736277395, 'dropout_rate_Layer_2': 0.21642270248257245, 'dropout_rate_Layer_3': 0.019969864839706246, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002364278423007757, 'l1_Layer_2': 0.0002751055835237987, 'l1_Layer_3': 6.014572390133314e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 140, 'n_units_Layer_3': 260}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.82 | sMAPE for Validation Set is: 40.03% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.24 | sMAPE for Test Set is: 28.50% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:14:48,198]\u001b[0m Trial 637 finished with value: 9.600677397290008 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018406377016202586, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1190031599098308, 'dropout_rate_Layer_2': 0.14342730685235217, 'dropout_rate_Layer_3': 0.324609732930325, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009761970672767058, 'l1_Layer_2': 0.0030695639376469718, 'l1_Layer_3': 2.520564886291601e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 235, 'n_units_Layer_3': 135}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.60 | sMAPE for Validation Set is: 44.07% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 25.07 | sMAPE for Test Set is: 32.05% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:14:53,974]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:14:59,923]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:15:04,704]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:15:04,804]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:15:09,400]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:15:12,427]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:15:21,713]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:15:26,261]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.81 | sMAPE for Validation Set is: 38.88% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.57 | sMAPE for Test Set is: 27.60% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:15:28,358]\u001b[0m Trial 641 finished with value: 8.810390828048869 and parameters: {'n_hidden': 3, 'learning_rate': 0.003407235475336335, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14295952714573917, 'dropout_rate_Layer_2': 0.19795109884414097, 'dropout_rate_Layer_3': 0.0017402110121943612, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002630038566381303, 'l1_Layer_2': 0.00046924500880625675, 'l1_Layer_3': 7.385239262432667e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 150, 'n_units_Layer_3': 250}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:15:39,516]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:15:40,673]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:15:48,969]\u001b[0m Trial 649 finished with value: 9.255917087913721 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016494789685775335, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11109239732206846, 'dropout_rate_Layer_2': 0.1796971492454855, 'dropout_rate_Layer_3': 0.32885109405875834, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007486255043472512, 'l1_Layer_2': 0.0014432330388582805, 'l1_Layer_3': 3.0476689759321848e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 250, 'n_units_Layer_3': 140}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.26 | sMAPE for Validation Set is: 40.67% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 24.52 | sMAPE for Test Set is: 30.31% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:15:49,502]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:15:52,849]\u001b[0m Trial 647 finished with value: 9.098590257889493 and parameters: {'n_hidden': 3, 'learning_rate': 0.001065965043345854, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05655126356752401, 'dropout_rate_Layer_2': 0.010196406152439757, 'dropout_rate_Layer_3': 0.24658143831083906, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02227324225148243, 'l1_Layer_2': 0.00407440727233497, 'l1_Layer_3': 0.00013299430776121158, 'n_units_Layer_1': 225, 'n_units_Layer_2': 70, 'n_units_Layer_3': 185}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.10 | sMAPE for Validation Set is: 39.16% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.63 | sMAPE for Test Set is: 28.25% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:16:04,319]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:16:11,311]\u001b[0m Trial 653 finished with value: 8.783023086884782 and parameters: {'n_hidden': 3, 'learning_rate': 0.00239486274687924, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15185903641978776, 'dropout_rate_Layer_2': 0.18957092035498352, 'dropout_rate_Layer_3': 0.033223084281992124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002625666936737214, 'l1_Layer_2': 0.0004838382761480936, 'l1_Layer_3': 5.351298425846221e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 150, 'n_units_Layer_3': 255}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.78 | sMAPE for Validation Set is: 38.37% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.69 | sMAPE for Test Set is: 27.86% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:16:15,278]\u001b[0m Trial 657 finished with value: 8.889374517683033 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024072255323030626, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15242465234158056, 'dropout_rate_Layer_2': 0.21751091068505451, 'dropout_rate_Layer_3': 0.0002793859588763152, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028368159293049294, 'l1_Layer_2': 0.00030419567907520763, 'l1_Layer_3': 5.441351782501076e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 125, 'n_units_Layer_3': 260}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.89 | sMAPE for Validation Set is: 40.50% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 24.67 | sMAPE for Test Set is: 31.47% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:16:17,614]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:16:23,558]\u001b[0m Trial 658 finished with value: 8.889102880974667 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025523048003951547, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10914848390458949, 'dropout_rate_Layer_2': 0.2158845134552061, 'dropout_rate_Layer_3': 0.03320358839893933, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000195638630377278, 'l1_Layer_2': 0.00031255522701417065, 'l1_Layer_3': 6.032830742484542e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 125, 'n_units_Layer_3': 250}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.89 | sMAPE for Validation Set is: 40.39% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.18 | sMAPE for Test Set is: 28.44% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:16:28,023]\u001b[0m Trial 656 finished with value: 8.819647326525457 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024686487165260325, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15453694876201618, 'dropout_rate_Layer_2': 0.19025098554043357, 'dropout_rate_Layer_3': 0.031184345340474227, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025477880154676174, 'l1_Layer_2': 0.0005026870507498518, 'l1_Layer_3': 7.053443209620341e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 125, 'n_units_Layer_3': 255}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.82 | sMAPE for Validation Set is: 40.34% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.03 | sMAPE for Test Set is: 28.16% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:16:28,951]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:16:35,626]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:16:55,845]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:17:04,720]\u001b[0m Trial 664 finished with value: 9.121458926409233 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014564979655161017, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1077659865384569, 'dropout_rate_Layer_2': 0.18435110171919486, 'dropout_rate_Layer_3': 0.3110868138812728, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000501478295214727, 'l1_Layer_2': 0.001170197180998113, 'l1_Layer_3': 2.8635021971627327e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 265, 'n_units_Layer_3': 155}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.12 | sMAPE for Validation Set is: 42.20% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.24 | sMAPE for Test Set is: 28.69% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:17:05,487]\u001b[0m Trial 665 finished with value: 9.067549560624578 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015647753847158974, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10738208349358969, 'dropout_rate_Layer_2': 0.1766948627806368, 'dropout_rate_Layer_3': 0.32356355770453904, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005873491661066027, 'l1_Layer_2': 0.0010841862043292898, 'l1_Layer_3': 6.917905700293352e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 230, 'n_units_Layer_3': 155}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.07 | sMAPE for Validation Set is: 41.02% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.04 | sMAPE for Test Set is: 28.68% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:17:18,700]\u001b[0m Trial 663 finished with value: 9.235796001862767 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014343408216113294, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10483859049015626, 'dropout_rate_Layer_2': 0.17821782933107136, 'dropout_rate_Layer_3': 0.31031008972006446, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006970147738330857, 'l1_Layer_2': 0.0015240050744480804, 'l1_Layer_3': 2.8878463159730217e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 265, 'n_units_Layer_3': 160}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.24 | sMAPE for Validation Set is: 42.29% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 23.07 | sMAPE for Test Set is: 28.98% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:17:20,454]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:17:25,366]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:17:29,035]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:17:34,603]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:17:39,088]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:17:39,940]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:17:47,708]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:17:53,844]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:18:08,789]\u001b[0m Trial 670 finished with value: 8.921958523115686 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013784863220205532, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09550127475343927, 'dropout_rate_Layer_2': 0.18815314443954842, 'dropout_rate_Layer_3': 0.32562199193565683, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004317803235414911, 'l1_Layer_2': 0.0010296424609396706, 'l1_Layer_3': 1.8452970997354806e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 230, 'n_units_Layer_3': 160}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.92 | sMAPE for Validation Set is: 39.47% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.08 | sMAPE for Test Set is: 27.56% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:18:12,677]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:18:22,940]\u001b[0m Trial 672 finished with value: 9.123204577659552 and parameters: {'n_hidden': 3, 'learning_rate': 0.001349170235031475, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09512853443021205, 'dropout_rate_Layer_2': 0.18393060599123362, 'dropout_rate_Layer_3': 0.3271752799387942, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00046144111658818186, 'l1_Layer_2': 0.0006869263478668416, 'l1_Layer_3': 1.7665388518833317e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 220, 'n_units_Layer_3': 160}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.12 | sMAPE for Validation Set is: 40.58% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 22.59 | sMAPE for Test Set is: 27.69% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:18:37,136]\u001b[0m Trial 680 finished with value: 8.816439209114192 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024724633253999906, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10630712301359287, 'dropout_rate_Layer_2': 0.1702050197661572, 'dropout_rate_Layer_3': 0.008266302167081763, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023068552422494926, 'l1_Layer_2': 0.00037907060486267016, 'l1_Layer_3': 0.0001177881963864388, 'n_units_Layer_1': 110, 'n_units_Layer_2': 130, 'n_units_Layer_3': 255}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:18:37,142]\u001b[0m Trial 678 finished with value: 8.658376560481464 and parameters: {'n_hidden': 3, 'learning_rate': 0.002401701493651311, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10694659903733117, 'dropout_rate_Layer_2': 0.16721594376946752, 'dropout_rate_Layer_3': 0.009352326116913817, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002724185318508134, 'l1_Layer_2': 0.0011766175828070863, 'l1_Layer_3': 0.00011394833948467186, 'n_units_Layer_1': 110, 'n_units_Layer_2': 130, 'n_units_Layer_3': 255}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.66 | sMAPE for Validation Set is: 38.87% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.11 | sMAPE for Test Set is: 27.01% | rMAE for Test Set is: 0.61\n",
      "MAE for Validation Set is: 8.82 | sMAPE for Validation Set is: 38.61% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.03 | sMAPE for Test Set is: 27.81% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:18:37,516]\u001b[0m Trial 679 finished with value: 8.623336439645307 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023178405194249113, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10844613170226981, 'dropout_rate_Layer_2': 0.17031636520033133, 'dropout_rate_Layer_3': 0.00819933497657957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022976199736596655, 'l1_Layer_2': 0.001085865658439079, 'l1_Layer_3': 8.70329607564481e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 130, 'n_units_Layer_3': 255}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.62 | sMAPE for Validation Set is: 37.87% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.71 | sMAPE for Test Set is: 27.64% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:18:46,275]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:19:00,518]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:19:10,699]\u001b[0m Trial 677 finished with value: 8.633858976211666 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023612136388450502, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10489515734098404, 'dropout_rate_Layer_2': 0.17053658722293946, 'dropout_rate_Layer_3': 0.009632558997004555, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002404751620214233, 'l1_Layer_2': 0.0010862063552776549, 'l1_Layer_3': 8.755974595359292e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 130, 'n_units_Layer_3': 255}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.63 | sMAPE for Validation Set is: 37.99% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.89 | sMAPE for Test Set is: 27.81% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:19:14,295]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:19:22,677]\u001b[0m Trial 682 finished with value: 8.665570199540511 and parameters: {'n_hidden': 3, 'learning_rate': 0.002287945145530055, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10223842539030882, 'dropout_rate_Layer_2': 0.17018782837487495, 'dropout_rate_Layer_3': 0.006567363881723304, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022932622742795732, 'l1_Layer_2': 0.0011092717843112154, 'l1_Layer_3': 0.00011831820508012962, 'n_units_Layer_1': 110, 'n_units_Layer_2': 175, 'n_units_Layer_3': 255}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.67 | sMAPE for Validation Set is: 38.68% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.83 | sMAPE for Test Set is: 27.53% | rMAE for Test Set is: 0.63\n",
      "MAE for Validation Set is: 8.74 | sMAPE for Validation Set is: 39.31% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.60 | sMAPE for Test Set is: 27.37% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:19:24,284]\u001b[0m Trial 683 finished with value: 8.736091193876115 and parameters: {'n_hidden': 3, 'learning_rate': 0.002229570632606779, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10829265945257009, 'dropout_rate_Layer_2': 0.1689529757905653, 'dropout_rate_Layer_3': 0.011260723317081806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023553365445836848, 'l1_Layer_2': 0.0012115510501625175, 'l1_Layer_3': 0.00012446934077414533, 'n_units_Layer_1': 110, 'n_units_Layer_2': 130, 'n_units_Layer_3': 255}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:19:41,119]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:19:48,073]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:19:52,279]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:19:52,761]\u001b[0m Trial 689 finished with value: 8.778149153970826 and parameters: {'n_hidden': 3, 'learning_rate': 0.002295298254418177, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11247586482968769, 'dropout_rate_Layer_2': 0.16810610907435283, 'dropout_rate_Layer_3': 0.007287732376964873, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023759767864148156, 'l1_Layer_2': 0.0012549345750531343, 'l1_Layer_3': 0.00013856641807628343, 'n_units_Layer_1': 110, 'n_units_Layer_2': 185, 'n_units_Layer_3': 250}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:19:52,780]\u001b[0m Trial 687 finished with value: 8.625134232369641 and parameters: {'n_hidden': 3, 'learning_rate': 0.002253179863557635, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09323089173330684, 'dropout_rate_Layer_2': 0.16709843433201932, 'dropout_rate_Layer_3': 0.008192745163380288, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002327826500114413, 'l1_Layer_2': 0.0011550138720213701, 'l1_Layer_3': 0.00012343942841708483, 'n_units_Layer_1': 110, 'n_units_Layer_2': 175, 'n_units_Layer_3': 255}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.78 | sMAPE for Validation Set is: 39.05% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.87 | sMAPE for Test Set is: 28.86% | rMAE for Test Set is: 0.66\n",
      "MAE for Validation Set is: 8.63 | sMAPE for Validation Set is: 38.78% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.55 | sMAPE for Test Set is: 27.48% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:20:00,458]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:20:11,809]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:20:27,920]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:20:32,367]\u001b[0m Trial 691 finished with value: 9.0999137415537 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012603170253561986, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14115427622059248, 'dropout_rate_Layer_2': 0.17705509888832338, 'dropout_rate_Layer_3': 0.3400092510657304, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004989120082295017, 'l1_Layer_2': 0.0010987698218102625, 'l1_Layer_3': 1.2860425575835757e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.10 | sMAPE for Validation Set is: 41.15% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 22.42 | sMAPE for Test Set is: 28.16% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:20:39,314]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:20:39,935]\u001b[0m Trial 696 finished with value: 8.63506987062794 and parameters: {'n_hidden': 3, 'learning_rate': 0.002318242774346077, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11061604503451257, 'dropout_rate_Layer_2': 0.16889002678157441, 'dropout_rate_Layer_3': 0.00945034210183697, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000253132300425691, 'l1_Layer_2': 0.001166698480186173, 'l1_Layer_3': 0.0001231710366695898, 'n_units_Layer_1': 110, 'n_units_Layer_2': 170, 'n_units_Layer_3': 255}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.64 | sMAPE for Validation Set is: 40.00% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.78 | sMAPE for Test Set is: 26.64% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:20:50,660]\u001b[0m Trial 695 finished with value: 8.67732354258816 and parameters: {'n_hidden': 3, 'learning_rate': 0.00216424566079901, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17620004753804155, 'dropout_rate_Layer_2': 0.1710193729614062, 'dropout_rate_Layer_3': 0.00891234892192807, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025890471585050443, 'l1_Layer_2': 0.0011431139146767938, 'l1_Layer_3': 0.00012347315101090617, 'n_units_Layer_1': 125, 'n_units_Layer_2': 185, 'n_units_Layer_3': 255}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.68 | sMAPE for Validation Set is: 38.49% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.27 | sMAPE for Test Set is: 27.20% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:21:00,393]\u001b[0m Trial 697 finished with value: 9.33065613934326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014200237974554537, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09527830348115536, 'dropout_rate_Layer_2': 0.17928218423450917, 'dropout_rate_Layer_3': 0.314752894988212, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005538361370469273, 'l1_Layer_2': 0.0006937983468303863, 'l1_Layer_3': 2.459871023674008e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.33 | sMAPE for Validation Set is: 43.51% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 23.78 | sMAPE for Test Set is: 29.95% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:21:12,323]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:21:16,251]\u001b[0m Trial 699 finished with value: 9.609128776877744 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007014944712334233, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02283098399639974, 'dropout_rate_Layer_2': 0.00840052015143021, 'dropout_rate_Layer_3': 0.275597344922851, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011057669442539076, 'l1_Layer_2': 0.003632211465925719, 'l1_Layer_3': 4.572007019231813e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 55, 'n_units_Layer_3': 230}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.61 | sMAPE for Validation Set is: 44.52% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 24.08 | sMAPE for Test Set is: 29.14% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:21:20,619]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:21:30,089]\u001b[0m Trial 701 finished with value: 9.223293877587055 and parameters: {'n_hidden': 3, 'learning_rate': 0.000798207559183713, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02228325905933431, 'dropout_rate_Layer_2': 0.008434183261257186, 'dropout_rate_Layer_3': 0.27330704381846105, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010127279844402832, 'l1_Layer_2': 0.003406136367039386, 'l1_Layer_3': 0.0005480552790998411, 'n_units_Layer_1': 205, 'n_units_Layer_2': 55, 'n_units_Layer_3': 220}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.22 | sMAPE for Validation Set is: 41.45% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 24.23 | sMAPE for Test Set is: 29.52% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:21:33,848]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:21:34,537]\u001b[0m Trial 702 finished with value: 9.244472180633714 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008128372944103057, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03249782882703241, 'dropout_rate_Layer_2': 0.007140375694017522, 'dropout_rate_Layer_3': 0.2725397921529928, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010972224379286195, 'l1_Layer_2': 0.0033297597594378185, 'l1_Layer_3': 7.097516686647028e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 55, 'n_units_Layer_3': 220}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.24 | sMAPE for Validation Set is: 40.36% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 25.12 | sMAPE for Test Set is: 30.14% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:21:41,809]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:21:44,308]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:22:01,824]\u001b[0m Trial 703 finished with value: 8.604232705557996 and parameters: {'n_hidden': 3, 'learning_rate': 0.002187612192600344, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11143971540960425, 'dropout_rate_Layer_2': 0.16911711164642199, 'dropout_rate_Layer_3': 0.007408651282215091, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024086808263939268, 'l1_Layer_2': 0.0011079939466094979, 'l1_Layer_3': 0.000158377638112907, 'n_units_Layer_1': 130, 'n_units_Layer_2': 185, 'n_units_Layer_3': 260}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.60 | sMAPE for Validation Set is: 37.65% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.30 | sMAPE for Test Set is: 27.01% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:22:04,208]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:22:09,587]\u001b[0m Trial 707 finished with value: 9.129338388618846 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014371327605412526, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09066746441223694, 'dropout_rate_Layer_2': 0.17628866047260675, 'dropout_rate_Layer_3': 0.3327354425984132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005244212049886161, 'l1_Layer_2': 0.0010943637506263934, 'l1_Layer_3': 1.6544647235300673e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 270, 'n_units_Layer_3': 155}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.13 | sMAPE for Validation Set is: 42.36% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.68 | sMAPE for Test Set is: 29.46% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:22:15,322]\u001b[0m Trial 709 finished with value: 8.648162936124825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021497994593175714, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17670708869632534, 'dropout_rate_Layer_2': 0.16680597369655242, 'dropout_rate_Layer_3': 0.008852610851073858, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002641322499298001, 'l1_Layer_2': 0.0011083495481868009, 'l1_Layer_3': 0.00014624731033039084, 'n_units_Layer_1': 130, 'n_units_Layer_2': 185, 'n_units_Layer_3': 260}. Best is trial 535 with value: 8.600073709065509.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.65 | sMAPE for Validation Set is: 37.92% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.60 | sMAPE for Test Set is: 27.42% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:22:34,144]\u001b[0m Trial 711 finished with value: 8.58938378409589 and parameters: {'n_hidden': 3, 'learning_rate': 0.002161777433534933, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1865504040737398, 'dropout_rate_Layer_2': 0.17229025298428596, 'dropout_rate_Layer_3': 0.008501618493030962, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002591079176871986, 'l1_Layer_2': 0.0013899183743635655, 'l1_Layer_3': 0.00012807552665409312, 'n_units_Layer_1': 140, 'n_units_Layer_2': 170, 'n_units_Layer_3': 255}. Best is trial 711 with value: 8.58938378409589.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.59 | sMAPE for Validation Set is: 38.08% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.56 | sMAPE for Test Set is: 27.39% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:22:39,684]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:22:51,664]\u001b[0m Trial 714 finished with value: 8.532104665526745 and parameters: {'n_hidden': 3, 'learning_rate': 0.00215001345871053, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17375185001044646, 'dropout_rate_Layer_2': 0.17108853177164443, 'dropout_rate_Layer_3': 0.007126065763972878, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002704435195496511, 'l1_Layer_2': 0.0013665883480311525, 'l1_Layer_3': 0.00015983411288325597, 'n_units_Layer_1': 135, 'n_units_Layer_2': 175, 'n_units_Layer_3': 255}. Best is trial 714 with value: 8.532104665526745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.53 | sMAPE for Validation Set is: 38.93% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.87 | sMAPE for Test Set is: 26.60% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:23:01,099]\u001b[0m Trial 712 finished with value: 8.513585081999793 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022089511769974087, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1730839704119366, 'dropout_rate_Layer_2': 0.1704077910370241, 'dropout_rate_Layer_3': 0.00864391400278626, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025906093705255467, 'l1_Layer_2': 0.00133388962727791, 'l1_Layer_3': 0.00012897947255456404, 'n_units_Layer_1': 135, 'n_units_Layer_2': 175, 'n_units_Layer_3': 255}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.51 | sMAPE for Validation Set is: 38.41% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.69 | sMAPE for Test Set is: 26.81% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:23:06,216]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:23:11,258]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:23:11,509]\u001b[0m Trial 715 finished with value: 9.147250918024183 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011889729091408507, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08969972673469014, 'dropout_rate_Layer_2': 0.1896607012767452, 'dropout_rate_Layer_3': 0.34201903970629155, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003887881212277409, 'l1_Layer_2': 0.0011749527619798522, 'l1_Layer_3': 1.0944973287860375e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 270, 'n_units_Layer_3': 165}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.15 | sMAPE for Validation Set is: 42.47% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 22.78 | sMAPE for Test Set is: 28.71% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:23:13,253]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:23:30,358]\u001b[0m Trial 717 finished with value: 9.59622213355623 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009240362713408285, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008969396586353727, 'dropout_rate_Layer_2': 0.13352274643093304, 'dropout_rate_Layer_3': 0.32105042646421317, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.41083960580624e-05, 'l1_Layer_2': 0.004431416046294984, 'l1_Layer_3': 0.0001808694279111233, 'n_units_Layer_1': 215, 'n_units_Layer_2': 65, 'n_units_Layer_3': 185}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.60 | sMAPE for Validation Set is: 44.55% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 23.26 | sMAPE for Test Set is: 29.19% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:23:39,352]\u001b[0m Trial 722 finished with value: 9.124695017705001 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010945225271968742, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09031925859065576, 'dropout_rate_Layer_2': 0.18912771802244127, 'dropout_rate_Layer_3': 0.34033966219249157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004420754891138357, 'l1_Layer_2': 0.0004273194902590714, 'l1_Layer_3': 1.2393604107398311e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 265, 'n_units_Layer_3': 170}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.12 | sMAPE for Validation Set is: 42.20% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.56 | sMAPE for Test Set is: 29.72% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:23:44,789]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:23:50,821]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:23:55,478]\u001b[0m Trial 721 finished with value: 8.682725875667794 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022801417558698076, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1855519624241087, 'dropout_rate_Layer_2': 0.16182569635944513, 'dropout_rate_Layer_3': 0.006990677050284316, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003477223667938486, 'l1_Layer_2': 0.0013505935719416474, 'l1_Layer_3': 0.00014554932142893495, 'n_units_Layer_1': 140, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.68 | sMAPE for Validation Set is: 38.24% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.43 | sMAPE for Test Set is: 28.18% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:24:03,906]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:24:09,166]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:24:13,487]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:24:17,926]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:24:32,854]\u001b[0m Trial 726 finished with value: 9.123920183926268 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010106866745841392, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09259384405191737, 'dropout_rate_Layer_2': 0.1896164234066475, 'dropout_rate_Layer_3': 0.34937730149070245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004985310955044171, 'l1_Layer_2': 0.000515027485190864, 'l1_Layer_3': 1.2893150044382069e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 265, 'n_units_Layer_3': 175}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.12 | sMAPE for Validation Set is: 40.72% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 22.92 | sMAPE for Test Set is: 28.34% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:24:44,497]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:24:52,027]\u001b[0m Trial 731 finished with value: 8.625903360914913 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021137404381170815, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17578254942301344, 'dropout_rate_Layer_2': 0.16094819065123078, 'dropout_rate_Layer_3': 0.008510901411457925, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003422745266556167, 'l1_Layer_2': 0.0012294053851967372, 'l1_Layer_3': 0.00017650846112223035, 'n_units_Layer_1': 140, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.63 | sMAPE for Validation Set is: 38.46% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.43 | sMAPE for Test Set is: 27.42% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:24:57,242]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:25:05,990]\u001b[0m Trial 729 finished with value: 8.573480676094775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021661138340800606, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17435143169147926, 'dropout_rate_Layer_2': 0.16161486158298216, 'dropout_rate_Layer_3': 0.008353942078858942, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00034793601128943447, 'l1_Layer_2': 0.001338128822526101, 'l1_Layer_3': 0.0001643558559424898, 'n_units_Layer_1': 140, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.57 | sMAPE for Validation Set is: 38.27% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.04 | sMAPE for Test Set is: 27.02% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:25:10,105]\u001b[0m Trial 728 finished with value: 8.586413405014612 and parameters: {'n_hidden': 3, 'learning_rate': 0.002060073015887709, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18005908437642754, 'dropout_rate_Layer_2': 0.16158641983536828, 'dropout_rate_Layer_3': 0.009604170282358602, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003398523137936269, 'l1_Layer_2': 0.0013762178420683325, 'l1_Layer_3': 0.0001686667596612345, 'n_units_Layer_1': 140, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.59 | sMAPE for Validation Set is: 38.54% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.77 | sMAPE for Test Set is: 27.73% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:25:17,484]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:25:21,949]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:25:28,180]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:25:28,996]\u001b[0m Trial 733 finished with value: 8.729659612570495 and parameters: {'n_hidden': 3, 'learning_rate': 0.002075727576713167, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1816094633939539, 'dropout_rate_Layer_2': 0.1612018046057861, 'dropout_rate_Layer_3': 0.010230654952582376, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00034937934588885914, 'l1_Layer_2': 0.0013117617138997326, 'l1_Layer_3': 0.00016797063574792038, 'n_units_Layer_1': 130, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.73 | sMAPE for Validation Set is: 38.44% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.89 | sMAPE for Test Set is: 27.66% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:25:42,308]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:25:46,365]\u001b[0m Trial 737 finished with value: 8.609618533561518 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020996663973162286, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17577189249290082, 'dropout_rate_Layer_2': 0.16028326010028837, 'dropout_rate_Layer_3': 0.008867622832742035, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00036970247865621, 'l1_Layer_2': 0.0013270778793479656, 'l1_Layer_3': 0.00019376934973916224, 'n_units_Layer_1': 140, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.61 | sMAPE for Validation Set is: 38.55% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.60 | sMAPE for Test Set is: 27.40% | rMAE for Test Set is: 0.63\n",
      "MAE for Validation Set is: 8.57 | sMAPE for Validation Set is: 38.37% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.14 | sMAPE for Test Set is: 26.93% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:25:48,223]\u001b[0m Trial 735 finished with value: 8.568655675798102 and parameters: {'n_hidden': 3, 'learning_rate': 0.002095977177743758, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1808997964587184, 'dropout_rate_Layer_2': 0.15972794265605567, 'dropout_rate_Layer_3': 0.008830409192798337, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003499489413919333, 'l1_Layer_2': 0.0013283585620414591, 'l1_Layer_3': 0.0001749543819730837, 'n_units_Layer_1': 140, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:26:01,341]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:26:17,350]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.06 | sMAPE for Validation Set is: 42.88% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 22.50 | sMAPE for Test Set is: 27.97% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:26:20,506]\u001b[0m Trial 741 finished with value: 9.056081030920716 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013137486365807467, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08620804148202324, 'dropout_rate_Layer_2': 0.20921998761621047, 'dropout_rate_Layer_3': 0.31777569903603425, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00039550470952007233, 'l1_Layer_2': 0.0010541755434468755, 'l1_Layer_3': 1.869845354404535e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 225, 'n_units_Layer_3': 185}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:26:25,983]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:26:30,589]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:26:45,904]\u001b[0m Trial 745 finished with value: 8.98377801400221 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012029868536000143, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08259821168143357, 'dropout_rate_Layer_2': 0.17339929681443045, 'dropout_rate_Layer_3': 0.3177805061425569, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004079410166664024, 'l1_Layer_2': 0.00045389477395627406, 'l1_Layer_3': 1.187965983263468e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 225, 'n_units_Layer_3': 160}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.98 | sMAPE for Validation Set is: 40.74% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.59 | sMAPE for Test Set is: 27.58% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:27:01,562]\u001b[0m Trial 746 finished with value: 9.068084043659956 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015537921559072663, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16787664953363404, 'dropout_rate_Layer_2': 0.17670035317910374, 'dropout_rate_Layer_3': 0.34959595082421185, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005791512552224096, 'l1_Layer_2': 0.0005669733249505457, 'l1_Layer_3': 1.3530113046555614e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 225, 'n_units_Layer_3': 165}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.07 | sMAPE for Validation Set is: 40.17% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.95 | sMAPE for Test Set is: 30.40% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:27:08,334]\u001b[0m Trial 749 finished with value: 9.211449818063938 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010192812652836064, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08097284461011543, 'dropout_rate_Layer_2': 0.22580087739056287, 'dropout_rate_Layer_3': 0.3091716001620205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003151051438681168, 'l1_Layer_2': 0.000457118561510794, 'l1_Layer_3': 1.552877438731714e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 220, 'n_units_Layer_3': 185}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.21 | sMAPE for Validation Set is: 42.09% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 23.88 | sMAPE for Test Set is: 30.13% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:27:12,256]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:27:16,871]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:27:20,677]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:27:21,456]\u001b[0m Trial 742 finished with value: 9.23491141490417 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007622909023023009, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.036440796614059474, 'dropout_rate_Layer_2': 0.17455078373839386, 'dropout_rate_Layer_3': 0.2630127470599695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0053360417165301205, 'l1_Layer_2': 0.016471883203744687, 'l1_Layer_3': 0.00014049401449432662, 'n_units_Layer_1': 235, 'n_units_Layer_2': 50, 'n_units_Layer_3': 235}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.23 | sMAPE for Validation Set is: 39.91% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 24.47 | sMAPE for Test Set is: 29.17% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:27:28,198]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:27:32,521]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:27:36,179]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:27:36,951]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:27:43,508]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:27:50,922]\u001b[0m Trial 751 finished with value: 9.335140487102857 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008963770262694072, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06094509451320487, 'dropout_rate_Layer_2': 0.21615478743739044, 'dropout_rate_Layer_3': 0.3487546123395548, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002856448100034582, 'l1_Layer_2': 0.0005049391178641778, 'l1_Layer_3': 1.0130551656770382e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 225, 'n_units_Layer_3': 175}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.34 | sMAPE for Validation Set is: 43.60% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 23.10 | sMAPE for Test Set is: 29.28% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:27:56,031]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:28:11,722]\u001b[0m Trial 754 finished with value: 8.880229221384978 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009861716964302337, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07985053585231178, 'dropout_rate_Layer_2': 0.18871031482337233, 'dropout_rate_Layer_3': 0.34786893018103926, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00029486197499998444, 'l1_Layer_2': 0.0004255534389143615, 'l1_Layer_3': 1.0193343220776065e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 185}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.88 | sMAPE for Validation Set is: 40.51% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.05 | sMAPE for Test Set is: 28.28% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:28:17,862]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:28:25,130]\u001b[0m Trial 761 finished with value: 8.61336457652814 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018253203712743013, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18922525689917274, 'dropout_rate_Layer_2': 0.17209707064662258, 'dropout_rate_Layer_3': 0.020571965016034484, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003596084379547235, 'l1_Layer_2': 0.0010106723867871093, 'l1_Layer_3': 0.00022814238674132316, 'n_units_Layer_1': 150, 'n_units_Layer_2': 180, 'n_units_Layer_3': 260}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.61 | sMAPE for Validation Set is: 37.74% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.89 | sMAPE for Test Set is: 27.55% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:28:29,843]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:28:40,799]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:28:41,536]\u001b[0m Trial 760 finished with value: 9.099356907918816 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009704430774851177, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08403397124419948, 'dropout_rate_Layer_2': 0.2356593731693448, 'dropout_rate_Layer_3': 0.3256734047914197, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00027889236659545824, 'l1_Layer_2': 0.0007200346294621438, 'l1_Layer_3': 1.0026877587340751e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 210, 'n_units_Layer_3': 175}. Best is trial 712 with value: 8.513585081999793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.10 | sMAPE for Validation Set is: 40.82% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 22.81 | sMAPE for Test Set is: 28.32% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:28:41,693]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:28:49,354]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:28:58,294]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:29:08,952]\u001b[0m Trial 764 finished with value: 8.481023902385846 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018345575486142008, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19861081274610207, 'dropout_rate_Layer_2': 0.1706488673702715, 'dropout_rate_Layer_3': 0.02079848674963271, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003502989567989626, 'l1_Layer_2': 0.0009984192000202419, 'l1_Layer_3': 0.00022878120971225348, 'n_units_Layer_1': 150, 'n_units_Layer_2': 185, 'n_units_Layer_3': 260}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.48 | sMAPE for Validation Set is: 37.88% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.84 | sMAPE for Test Set is: 26.55% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:29:29,358]\u001b[0m Trial 772 finished with value: 8.624788227685233 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018081406141767682, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1890523712650992, 'dropout_rate_Layer_2': 0.17633799480979787, 'dropout_rate_Layer_3': 0.021165799161175704, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000369325897256311, 'l1_Layer_2': 0.0010024223619834408, 'l1_Layer_3': 0.00023275093120996213, 'n_units_Layer_1': 145, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.62 | sMAPE for Validation Set is: 38.61% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.25 | sMAPE for Test Set is: 26.92% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:29:30,298]\u001b[0m Trial 770 finished with value: 8.629449914870793 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017765844365946837, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19460425690416286, 'dropout_rate_Layer_2': 0.1778968665466727, 'dropout_rate_Layer_3': 0.021530258129815013, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00035732999385639744, 'l1_Layer_2': 0.0009042356416808195, 'l1_Layer_3': 0.00022636772527723199, 'n_units_Layer_1': 145, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.63 | sMAPE for Validation Set is: 39.46% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.38 | sMAPE for Test Set is: 27.33% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:29:44,090]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:29:46,828]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:29:51,850]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:29:56,535]\u001b[0m Trial 773 finished with value: 8.626036706995167 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017932946326209528, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1937204762244444, 'dropout_rate_Layer_2': 0.1777524174623391, 'dropout_rate_Layer_3': 0.02095452671281277, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003517320938456795, 'l1_Layer_2': 0.000954259176362341, 'l1_Layer_3': 0.00023372426630247125, 'n_units_Layer_1': 150, 'n_units_Layer_2': 185, 'n_units_Layer_3': 265}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.63 | sMAPE for Validation Set is: 38.35% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.41 | sMAPE for Test Set is: 27.18% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:30:04,424]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:30:09,597]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:30:15,708]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:30:19,934]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:30:24,482]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:30:29,322]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:30:35,092]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:30:35,227]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:30:42,086]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:30:42,445]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:30:48,236]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:30:50,632]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:30:51,562]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:30:52,978]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:31:00,091]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:31:03,874]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:31:06,091]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:31:11,533]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:31:16,355]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:31:35,496]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:31:39,868]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:31:48,158]\u001b[0m Trial 791 finished with value: 8.666815943229416 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017410505710697016, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2090256006128272, 'dropout_rate_Layer_2': 0.1542231750090032, 'dropout_rate_Layer_3': 0.015625538254816843, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002809788419795867, 'l1_Layer_2': 0.0016053590394599067, 'l1_Layer_3': 0.0003199516844969489, 'n_units_Layer_1': 145, 'n_units_Layer_2': 185, 'n_units_Layer_3': 275}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.67 | sMAPE for Validation Set is: 38.29% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.02 | sMAPE for Test Set is: 26.73% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:31:52,769]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:31:57,361]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:32:06,885]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:32:11,238]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:32:14,019]\u001b[0m Trial 776 finished with value: 9.132621240642132 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005458514358315036, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026874793355596626, 'dropout_rate_Layer_2': 0.32702059640729586, 'dropout_rate_Layer_3': 0.2914946399382524, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0090248940860223, 'l1_Layer_2': 0.01870003945892475, 'l1_Layer_3': 8.144469610687549e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 60, 'n_units_Layer_3': 265}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.13 | sMAPE for Validation Set is: 40.38% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 24.22 | sMAPE for Test Set is: 28.83% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:32:18,667]\u001b[0m Trial 798 finished with value: 8.63850201479904 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016793091374343084, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20618326084094823, 'dropout_rate_Layer_2': 0.15333026287225804, 'dropout_rate_Layer_3': 0.017586303865583436, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00035087620466774225, 'l1_Layer_2': 0.0008617963297577057, 'l1_Layer_3': 0.00030141126723473235, 'n_units_Layer_1': 150, 'n_units_Layer_2': 180, 'n_units_Layer_3': 275}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.64 | sMAPE for Validation Set is: 38.29% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.91 | sMAPE for Test Set is: 27.71% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:32:21,218]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:32:25,821]\u001b[0m Trial 800 finished with value: 9.198889200332381 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010155350104588056, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06596878805103563, 'dropout_rate_Layer_2': 0.21268175574001624, 'dropout_rate_Layer_3': 0.3579926627579159, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006390122989779324, 'l1_Layer_2': 0.0007784199950317542, 'l1_Layer_3': 1.1979090584168748e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 235, 'n_units_Layer_3': 160}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.20 | sMAPE for Validation Set is: 42.33% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 23.27 | sMAPE for Test Set is: 29.16% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:32:32,471]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:32:32,779]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:33:08,733]\u001b[0m Trial 810 finished with value: 8.562106091151277 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018253869815546301, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20228536731473193, 'dropout_rate_Layer_2': 0.15077095093978576, 'dropout_rate_Layer_3': 0.01748317728966641, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00034701321825674625, 'l1_Layer_2': 0.0008291985730924023, 'l1_Layer_3': 0.0003129823229043135, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 275}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.56 | sMAPE for Validation Set is: 38.16% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.51 | sMAPE for Test Set is: 27.29% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:33:09,277]\u001b[0m Trial 807 finished with value: 8.599202413307841 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018964755801618967, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2028669761115107, 'dropout_rate_Layer_2': 0.1486362247716997, 'dropout_rate_Layer_3': 0.016886327939684836, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00035291900786089747, 'l1_Layer_2': 0.0008482809592245878, 'l1_Layer_3': 0.0003341456195615651, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 275}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.60 | sMAPE for Validation Set is: 38.32% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.23 | sMAPE for Test Set is: 27.15% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:33:15,462]\u001b[0m Trial 808 finished with value: 8.594978313265488 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018302559905184327, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2184674557563804, 'dropout_rate_Layer_2': 0.15062966167831812, 'dropout_rate_Layer_3': 0.01618390849508603, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00034653872228317264, 'l1_Layer_2': 0.0008184625869358309, 'l1_Layer_3': 0.0003163976066546276, 'n_units_Layer_1': 145, 'n_units_Layer_2': 165, 'n_units_Layer_3': 275}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.59 | sMAPE for Validation Set is: 38.79% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.45 | sMAPE for Test Set is: 27.31% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:33:19,701]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:33:24,100]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:33:40,288]\u001b[0m Trial 811 finished with value: 8.614407002911209 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017749740622759573, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21904164218278196, 'dropout_rate_Layer_2': 0.14986470944988306, 'dropout_rate_Layer_3': 0.01642437011554147, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00037232763613897563, 'l1_Layer_2': 0.0008865676959722348, 'l1_Layer_3': 0.00031242698804543055, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 275}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.61 | sMAPE for Validation Set is: 38.73% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.05 | sMAPE for Test Set is: 26.82% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:33:53,327]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:33:58,649]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:34:03,169]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:34:07,757]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:34:20,886]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:34:25,160]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:34:29,165]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:34:29,874]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:34:38,614]\u001b[0m Trial 821 finished with value: 9.298500328491492 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015335343720804162, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0754431912942766, 'dropout_rate_Layer_2': 0.19683513816925302, 'dropout_rate_Layer_3': 0.32698878403437404, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002875216340227379, 'l1_Layer_2': 0.00025622749651874684, 'l1_Layer_3': 1.5732503956841218e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 230, 'n_units_Layer_3': 160}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.30 | sMAPE for Validation Set is: 40.76% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 23.55 | sMAPE for Test Set is: 29.49% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:34:42,604]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:34:47,977]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:34:52,699]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:35:09,924]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:35:13,605]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:35:13,778]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:35:20,577]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:35:23,169]\u001b[0m Trial 824 finished with value: 9.170417876295476 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015589416969959025, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10385108263049338, 'dropout_rate_Layer_2': 0.19816836005812852, 'dropout_rate_Layer_3': 0.31616575917603895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006198247254748472, 'l1_Layer_2': 0.0006115365514766429, 'l1_Layer_3': 2.0790551850701782e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 185, 'n_units_Layer_3': 165}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.17 | sMAPE for Validation Set is: 42.24% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 22.81 | sMAPE for Test Set is: 28.43% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:35:30,499]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:35:33,425]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:35:40,904]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:35:48,183]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:35:56,089]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:35:57,045]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:36:03,847]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:36:08,844]\u001b[0m Trial 833 finished with value: 8.658930458700425 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019931002899555975, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18900298942645893, 'dropout_rate_Layer_2': 0.15811175423932095, 'dropout_rate_Layer_3': 0.0240755989054555, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003882958600511164, 'l1_Layer_2': 0.0019435789493666646, 'l1_Layer_3': 0.0002431974624696487, 'n_units_Layer_1': 140, 'n_units_Layer_2': 195, 'n_units_Layer_3': 275}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.66 | sMAPE for Validation Set is: 38.45% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.86 | sMAPE for Test Set is: 27.70% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:36:12,976]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:36:25,566]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:36:29,865]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:36:34,230]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:36:41,529]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:36:50,440]\u001b[0m Trial 839 finished with value: 8.98214698698147 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006159291719287087, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04383162581334607, 'dropout_rate_Layer_2': 0.01450326129897757, 'dropout_rate_Layer_3': 0.2796616299975944, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007740547001662782, 'l1_Layer_2': 0.005452083179468578, 'l1_Layer_3': 0.0001539524420471901, 'n_units_Layer_1': 255, 'n_units_Layer_2': 80, 'n_units_Layer_3': 215}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.98 | sMAPE for Validation Set is: 40.33% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 24.19 | sMAPE for Test Set is: 29.10% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:36:52,812]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:36:57,721]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:37:03,539]\u001b[0m Trial 841 finished with value: 8.947062164212861 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015455319900192282, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07323916132002883, 'dropout_rate_Layer_2': 0.1963710498987904, 'dropout_rate_Layer_3': 0.3227497522759345, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00039617919196958186, 'l1_Layer_2': 0.00021075612790318496, 'l1_Layer_3': 1.4638719839829975e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 195}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.95 | sMAPE for Validation Set is: 39.77% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.05 | sMAPE for Test Set is: 28.67% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:37:21,894]\u001b[0m Trial 849 finished with value: 8.894830232923548 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013786916129308463, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08488194584609304, 'dropout_rate_Layer_2': 0.17519979578033665, 'dropout_rate_Layer_3': 0.16766575945914444, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005553971943496288, 'l1_Layer_2': 0.0003032646721613524, 'l1_Layer_3': 1.4293278638321063e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 220, 'n_units_Layer_3': 170}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.89 | sMAPE for Validation Set is: 40.15% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.05 | sMAPE for Test Set is: 28.30% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:37:26,557]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:37:29,933]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:37:34,412]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:37:38,616]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:37:38,933]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:37:46,652]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:37:47,163]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:37:53,837]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:37:54,178]\u001b[0m Trial 851 finished with value: 8.879966710051288 and parameters: {'n_hidden': 3, 'learning_rate': 0.00157525965973856, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07319348307261439, 'dropout_rate_Layer_2': 0.20656206961847257, 'dropout_rate_Layer_3': 0.33628003044197646, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00046352944831058447, 'l1_Layer_2': 0.00016861849551121733, 'l1_Layer_3': 1.4520357448182235e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 210, 'n_units_Layer_3': 195}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.88 | sMAPE for Validation Set is: 41.15% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.70 | sMAPE for Test Set is: 29.67% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:38:01,120]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:38:01,550]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:38:09,223]\u001b[0m Trial 829 finished with value: 9.04551032780878 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005491021436130063, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03736278179975007, 'dropout_rate_Layer_2': 8.855619020165222e-05, 'dropout_rate_Layer_3': 0.25877670630696914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.016995857960751298, 'l1_Layer_2': 0.02136227246292847, 'l1_Layer_3': 0.00036327004178675034, 'n_units_Layer_1': 230, 'n_units_Layer_2': 70, 'n_units_Layer_3': 270}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.05 | sMAPE for Validation Set is: 39.68% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.62 | sMAPE for Test Set is: 28.34% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:38:15,776]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:38:19,615]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:38:22,036]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:38:31,929]\u001b[0m Trial 862 finished with value: 9.041689556607409 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014229822836504499, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08156682891770935, 'dropout_rate_Layer_2': 0.20009079223299894, 'dropout_rate_Layer_3': 0.11847669623242418, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00025628760326895005, 'l1_Layer_2': 0.00020291110005223203, 'l1_Layer_3': 1.4889608111684509e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 210, 'n_units_Layer_3': 195}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.04 | sMAPE for Validation Set is: 41.48% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.04 | sMAPE for Test Set is: 29.09% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:38:38,519]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:38:43,665]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:38:46,631]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:38:50,978]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:38:55,439]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:38:55,919]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:39:05,395]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:39:11,851]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:39:17,664]\u001b[0m Trial 866 finished with value: 9.065594270220279 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006003962129102362, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.051050126154961496, 'dropout_rate_Layer_2': 0.01003596334359763, 'dropout_rate_Layer_3': 0.24259904181700032, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.022223178445514632, 'l1_Layer_2': 0.0029521558553250904, 'l1_Layer_3': 0.00020758411593222318, 'n_units_Layer_1': 225, 'n_units_Layer_2': 65, 'n_units_Layer_3': 200}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.07 | sMAPE for Validation Set is: 39.70% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.93 | sMAPE for Test Set is: 28.51% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:39:18,050]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:39:24,220]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:39:24,548]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:39:31,244]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:39:32,280]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:39:38,366]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:39:42,835]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:39:43,526]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:39:45,612]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:39:52,022]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:39:53,001]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:39:57,639]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:40:00,431]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:40:02,640]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:40:07,828]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:40:11,887]\u001b[0m Trial 879 finished with value: 8.588067784588455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020990049653813675, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2261354452710798, 'dropout_rate_Layer_2': 0.17241751354064466, 'dropout_rate_Layer_3': 0.013314887441390883, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002903137913656601, 'l1_Layer_2': 0.0009901242285858174, 'l1_Layer_3': 0.00024927078771577727, 'n_units_Layer_1': 155, 'n_units_Layer_2': 170, 'n_units_Layer_3': 260}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.59 | sMAPE for Validation Set is: 38.88% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.40 | sMAPE for Test Set is: 27.34% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:40:12,426]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:40:17,504]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:40:18,024]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:40:23,569]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:40:27,998]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:40:28,602]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:40:35,945]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:40:36,181]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:40:42,732]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:40:46,988]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:40:47,067]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:40:56,229]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:40:56,494]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:41:04,388]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:41:13,295]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:41:17,388]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:41:23,197]\u001b[0m Trial 900 finished with value: 9.299128444341731 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007178893311106394, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04484720102476995, 'dropout_rate_Layer_2': 0.03317063139047436, 'dropout_rate_Layer_3': 0.2101552957954859, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008625375563039588, 'l1_Layer_2': 0.0019659730835139486, 'l1_Layer_3': 0.0003030251220966099, 'n_units_Layer_1': 250, 'n_units_Layer_2': 70, 'n_units_Layer_3': 200}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.30 | sMAPE for Validation Set is: 43.57% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 23.80 | sMAPE for Test Set is: 29.00% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:41:23,522]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:41:29,800]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:41:32,293]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.99 | sMAPE for Validation Set is: 39.88% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 24.42 | sMAPE for Test Set is: 29.47% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:41:36,013]\u001b[0m Trial 903 finished with value: 8.993126938644322 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007144600619902329, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02204236631996748, 'dropout_rate_Layer_2': 0.03344293587040582, 'dropout_rate_Layer_3': 0.2536548662025672, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015212276805084463, 'l1_Layer_2': 0.0012995229427002106, 'l1_Layer_3': 0.0003085780886063497, 'n_units_Layer_1': 125, 'n_units_Layer_2': 65, 'n_units_Layer_3': 175}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:41:36,284]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:41:39,468]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:41:48,183]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:41:51,674]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:41:52,150]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:41:52,796]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:42:01,015]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:42:01,426]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:42:01,476]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:42:11,019]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:42:13,256]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:42:18,280]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:42:20,929]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:42:23,877]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:42:26,126]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:42:34,938]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:42:39,237]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:42:43,681]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:42:44,489]\u001b[0m Trial 915 finished with value: 9.077032500543636 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006212659926693123, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0003280876753656674, 'dropout_rate_Layer_2': 0.009919445686381404, 'dropout_rate_Layer_3': 0.2596331729245773, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011329197038243886, 'l1_Layer_2': 0.004778764745587346, 'l1_Layer_3': 0.0001940744527131456, 'n_units_Layer_1': 110, 'n_units_Layer_2': 65, 'n_units_Layer_3': 160}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.08 | sMAPE for Validation Set is: 41.71% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.35 | sMAPE for Test Set is: 28.29% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:42:51,551]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:42:55,939]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:42:59,098]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:43:01,375]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:43:05,632]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:43:06,167]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.04 | sMAPE for Validation Set is: 41.23% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 24.04 | sMAPE for Test Set is: 29.37% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:43:12,626]\u001b[0m Trial 928 finished with value: 9.036125970827891 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006144625606051561, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0023102515853032912, 'dropout_rate_Layer_2': 0.024061009507470064, 'dropout_rate_Layer_3': 0.23017455158224767, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011792439600961433, 'l1_Layer_2': 0.0008907695397800239, 'l1_Layer_3': 0.00015775633920100845, 'n_units_Layer_1': 255, 'n_units_Layer_2': 70, 'n_units_Layer_3': 165}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:43:16,968]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:43:22,054]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:43:26,124]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:43:30,304]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:43:38,154]\u001b[0m Trial 935 finished with value: 8.984418373738892 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009743408992224952, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014784411021906483, 'dropout_rate_Layer_2': 0.0077723766979688825, 'dropout_rate_Layer_3': 0.26033907995741346, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.017316539729382713, 'l1_Layer_2': 0.0037662949916843556, 'l1_Layer_3': 0.000212065104105345, 'n_units_Layer_1': 105, 'n_units_Layer_2': 90, 'n_units_Layer_3': 155}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.98 | sMAPE for Validation Set is: 40.45% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.91 | sMAPE for Test Set is: 28.89% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:43:42,636]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.23 | sMAPE for Validation Set is: 42.25% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 23.65 | sMAPE for Test Set is: 28.40% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:43:45,424]\u001b[0m Trial 938 finished with value: 9.22659124556552 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012238792617094282, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017874905885032592, 'dropout_rate_Layer_2': 0.00816542695582269, 'dropout_rate_Layer_3': 0.22883778657229542, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.017631203542335275, 'l1_Layer_2': 0.0039498078052309146, 'l1_Layer_3': 0.00017198378753232788, 'n_units_Layer_1': 110, 'n_units_Layer_2': 225, 'n_units_Layer_3': 165}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:43:46,154]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:43:47,168]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:43:52,386]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:43:53,013]\u001b[0m Trial 939 finished with value: 8.80182010382497 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009365881233689053, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013989343572992351, 'dropout_rate_Layer_2': 0.10473237494344842, 'dropout_rate_Layer_3': 0.23324735684724743, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015306921591777592, 'l1_Layer_2': 0.004204101297858515, 'l1_Layer_3': 0.00021316144790195184, 'n_units_Layer_1': 105, 'n_units_Layer_2': 90, 'n_units_Layer_3': 165}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.80 | sMAPE for Validation Set is: 38.46% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.89 | sMAPE for Test Set is: 28.74% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:43:55,550]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:43:59,350]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:44:26,667]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:44:30,547]\u001b[0m Trial 950 finished with value: 8.7158629376691 and parameters: {'n_hidden': 3, 'learning_rate': 0.002029341538258627, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20042774402226146, 'dropout_rate_Layer_2': 0.1736480405034716, 'dropout_rate_Layer_3': 0.00759601746003823, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021017434493694994, 'l1_Layer_2': 0.0016835802457397062, 'l1_Layer_3': 0.0001637632905043499, 'n_units_Layer_1': 145, 'n_units_Layer_2': 195, 'n_units_Layer_3': 265}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.72 | sMAPE for Validation Set is: 39.86% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.56 | sMAPE for Test Set is: 27.65% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:44:34,214]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:44:35,485]\u001b[0m Trial 953 finished with value: 8.713736443963585 and parameters: {'n_hidden': 3, 'learning_rate': 0.002004915157526906, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20068081506538038, 'dropout_rate_Layer_2': 0.17407166491301893, 'dropout_rate_Layer_3': 0.007380763362847157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022045587071956282, 'l1_Layer_2': 0.0018521789364467028, 'l1_Layer_3': 0.00016159990838342077, 'n_units_Layer_1': 145, 'n_units_Layer_2': 195, 'n_units_Layer_3': 265}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.71 | sMAPE for Validation Set is: 38.92% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.69 | sMAPE for Test Set is: 27.57% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:44:40,475]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:44:44,481]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:44:45,289]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:44:50,593]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:44:56,156]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:45:01,426]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:45:07,652]\u001b[0m Trial 951 finished with value: 9.223749128912429 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009255007515229835, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010904725866213497, 'dropout_rate_Layer_2': 0.051418296395400256, 'dropout_rate_Layer_3': 0.2598291887146646, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011279254840139474, 'l1_Layer_2': 0.0011024553757183198, 'l1_Layer_3': 0.0003557310655989784, 'n_units_Layer_1': 80, 'n_units_Layer_2': 90, 'n_units_Layer_3': 150}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.22 | sMAPE for Validation Set is: 43.60% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 22.78 | sMAPE for Test Set is: 27.75% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:45:12,091]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:45:16,204]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:45:21,558]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:45:21,908]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:45:29,236]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:45:32,153]\u001b[0m Trial 963 finished with value: 9.278387542029941 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009535973449867686, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012297039587417853, 'dropout_rate_Layer_2': 0.11796746719011998, 'dropout_rate_Layer_3': 0.21858177751856867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011269654256296767, 'l1_Layer_2': 0.0008986680703093275, 'l1_Layer_3': 0.0002165175134084514, 'n_units_Layer_1': 95, 'n_units_Layer_2': 90, 'n_units_Layer_3': 150}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.28 | sMAPE for Validation Set is: 41.25% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 25.04 | sMAPE for Test Set is: 30.86% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:45:36,262]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:45:39,518]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:45:56,276]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:45:57,211]\u001b[0m Trial 969 finished with value: 9.186162249229247 and parameters: {'n_hidden': 3, 'learning_rate': 0.000757181008476287, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0008691796906499724, 'dropout_rate_Layer_2': 0.02014481377468641, 'dropout_rate_Layer_3': 0.2519034337572122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.012805726024351951, 'l1_Layer_2': 0.0009034188059365208, 'l1_Layer_3': 1.733761450459576e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 90, 'n_units_Layer_3': 140}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.19 | sMAPE for Validation Set is: 41.24% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 24.95 | sMAPE for Test Set is: 30.66% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:46:00,035]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:46:05,193]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:46:09,434]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:46:12,908]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:46:15,526]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:46:18,558]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:46:22,056]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:46:22,182]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:46:23,318]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:46:30,832]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:46:34,532]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:46:39,601]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.54 | sMAPE for Validation Set is: 37.68% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.30 | sMAPE for Test Set is: 27.14% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:46:42,951]\u001b[0m Trial 972 finished with value: 8.544008858530828 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017494387181518085, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21962630890410945, 'dropout_rate_Layer_2': 0.15856136940964094, 'dropout_rate_Layer_3': 0.01936186337738547, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000610657436950117, 'l1_Layer_2': 0.0013386746759368713, 'l1_Layer_3': 0.00036787379864040013, 'n_units_Layer_1': 160, 'n_units_Layer_2': 180, 'n_units_Layer_3': 250}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:46:45,650]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:46:52,185]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:46:56,389]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:47:00,548]\u001b[0m Trial 983 finished with value: 9.143034541868401 and parameters: {'n_hidden': 3, 'learning_rate': 0.00171769556568116, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06260707463434458, 'dropout_rate_Layer_2': 0.19335688378700958, 'dropout_rate_Layer_3': 0.33635882261587285, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004893349603341314, 'l1_Layer_2': 0.0006866009303488284, 'l1_Layer_3': 2.0750017713303212e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 275, 'n_units_Layer_3': 170}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.14 | sMAPE for Validation Set is: 43.94% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.25 | sMAPE for Test Set is: 28.65% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:47:00,841]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:47:05,417]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:47:09,008]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:47:09,598]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:47:12,509]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:47:17,379]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:47:24,000]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:47:27,694]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:47:28,464]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:47:29,039]\u001b[0m Trial 988 finished with value: 9.155506480549606 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010968829135777766, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019132049003249378, 'dropout_rate_Layer_2': 0.007008414219452816, 'dropout_rate_Layer_3': 0.19885439819208903, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.022714529265285475, 'l1_Layer_2': 0.00400892497111129, 'l1_Layer_3': 0.00014280483977105845, 'n_units_Layer_1': 130, 'n_units_Layer_2': 75, 'n_units_Layer_3': 175}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.16 | sMAPE for Validation Set is: 40.78% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.32 | sMAPE for Test Set is: 28.00% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:47:36,548]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:47:36,770]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:47:43,164]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:47:47,753]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:47:48,472]\u001b[0m Trial 994 finished with value: 9.166196111693646 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010992643762816803, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018014303490602377, 'dropout_rate_Layer_2': 0.010032731040316545, 'dropout_rate_Layer_3': 0.2615085483036299, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.020532784468128278, 'l1_Layer_2': 0.0038374087088718385, 'l1_Layer_3': 0.00013594112935696594, 'n_units_Layer_1': 110, 'n_units_Layer_2': 70, 'n_units_Layer_3': 175}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.17 | sMAPE for Validation Set is: 41.81% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 24.06 | sMAPE for Test Set is: 29.02% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:47:54,079]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:47:55,172]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:48:00,992]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:48:05,900]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:48:09,489]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:48:10,405]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:48:15,392]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:48:20,117]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:48:33,344]\u001b[0m Trial 999 finished with value: 8.557122224821688 and parameters: {'n_hidden': 3, 'learning_rate': 0.001876254798180604, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17792509242104082, 'dropout_rate_Layer_2': 0.17762279168660858, 'dropout_rate_Layer_3': 0.025499719115050713, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006355363030328517, 'l1_Layer_2': 0.0010249469889222955, 'l1_Layer_3': 0.0004002808033893674, 'n_units_Layer_1': 155, 'n_units_Layer_2': 180, 'n_units_Layer_3': 275}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.56 | sMAPE for Validation Set is: 38.06% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.39 | sMAPE for Test Set is: 27.34% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:48:36,352]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:48:37,196]\u001b[0m Trial 1003 finished with value: 9.233027197976382 and parameters: {'n_hidden': 3, 'learning_rate': 0.001059436118093703, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0760014377227085, 'dropout_rate_Layer_2': 0.2121124313791847, 'dropout_rate_Layer_3': 0.340530601206281, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004134785221721685, 'l1_Layer_2': 0.00047682728830439694, 'l1_Layer_3': 1.5250122053217137e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 225, 'n_units_Layer_3': 160}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.23 | sMAPE for Validation Set is: 43.25% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 24.22 | sMAPE for Test Set is: 29.37% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:48:38,055]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:48:45,317]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:48:48,612]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:48:49,509]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:48:54,178]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:48:58,590]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:49:02,613]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:49:11,234]\u001b[0m Trial 1013 finished with value: 8.620757030743688 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019354378318926474, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21403911081924648, 'dropout_rate_Layer_2': 0.16502798640835065, 'dropout_rate_Layer_3': 0.012933024015825462, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003783920863400283, 'l1_Layer_2': 0.0008516460164531457, 'l1_Layer_3': 0.00028004508549341945, 'n_units_Layer_1': 155, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.62 | sMAPE for Validation Set is: 37.90% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.22 | sMAPE for Test Set is: 27.07% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:49:15,291]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:49:15,450]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.89 | sMAPE for Validation Set is: 40.38% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.48 | sMAPE for Test Set is: 27.91% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:49:18,758]\u001b[0m Trial 1017 finished with value: 8.889855216488955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010731350451924355, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.039074707108737124, 'dropout_rate_Layer_2': 0.2198368836155354, 'dropout_rate_Layer_3': 0.007526528340449853, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004283437798565848, 'l1_Layer_2': 0.00032085600760100105, 'l1_Layer_3': 1.542533246292055e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 225, 'n_units_Layer_3': 160}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:49:24,539]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:49:25,108]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:49:25,168]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:49:31,699]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:49:35,070]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:49:35,702]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:49:36,928]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:49:44,618]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:49:45,228]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:49:50,851]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:49:55,226]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:49:55,995]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:49:56,399]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:50:03,740]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:50:07,968]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:50:11,780]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:50:17,008]\u001b[0m Trial 1028 finished with value: 8.944943909064115 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007515385879830424, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0008802427723214707, 'dropout_rate_Layer_2': 0.01697086169462061, 'dropout_rate_Layer_3': 0.23661099369703822, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006788520755984097, 'l1_Layer_2': 0.002655313403295921, 'l1_Layer_3': 0.0004096290407089315, 'n_units_Layer_1': 255, 'n_units_Layer_2': 60, 'n_units_Layer_3': 190}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.94 | sMAPE for Validation Set is: 40.27% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 24.17 | sMAPE for Test Set is: 29.53% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:50:21,180]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:50:23,863]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:50:28,714]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:50:29,459]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:50:33,433]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:50:34,958]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:50:47,242]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:50:47,920]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:50:57,699]\u001b[0m Trial 1041 finished with value: 9.056287230770334 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007541873548791132, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027394672318196693, 'dropout_rate_Layer_2': 0.005442444535381731, 'dropout_rate_Layer_3': 0.26866386441892665, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.017843201488201614, 'l1_Layer_2': 0.002113252910497955, 'l1_Layer_3': 0.00036748550995727505, 'n_units_Layer_1': 240, 'n_units_Layer_2': 60, 'n_units_Layer_3': 210}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.06 | sMAPE for Validation Set is: 39.13% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 24.44 | sMAPE for Test Set is: 29.13% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:50:58,427]\u001b[0m Trial 1049 finished with value: 9.181641445213943 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008419849709681977, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09129505407249679, 'dropout_rate_Layer_2': 0.20083572557928406, 'dropout_rate_Layer_3': 0.3326403186115228, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00027213745051697896, 'l1_Layer_2': 0.00036461582631606716, 'l1_Layer_3': 1.886863146820369e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 210, 'n_units_Layer_3': 155}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.18 | sMAPE for Validation Set is: 42.51% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 23.24 | sMAPE for Test Set is: 28.61% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:50:58,564]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:51:07,158]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:51:07,485]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:51:15,129]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:51:15,773]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:51:21,147]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:51:27,599]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:51:32,510]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:51:33,038]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:51:44,565]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:51:47,234]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:51:50,233]\u001b[0m Trial 1056 finished with value: 9.002652772134907 and parameters: {'n_hidden': 3, 'learning_rate': 0.000847888293278539, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006398326841318665, 'dropout_rate_Layer_2': 0.0007997208003719786, 'dropout_rate_Layer_3': 0.2692537646521733, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009744576490123804, 'l1_Layer_2': 0.0020961157629393896, 'l1_Layer_3': 0.00037867558360815787, 'n_units_Layer_1': 260, 'n_units_Layer_2': 60, 'n_units_Layer_3': 210}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.00 | sMAPE for Validation Set is: 41.34% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.58 | sMAPE for Test Set is: 28.94% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:51:52,503]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:51:55,819]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:51:56,905]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:52:03,052]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:52:03,171]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:52:10,007]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:52:14,117]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:52:18,752]\u001b[0m Trial 1060 finished with value: 9.191201752129539 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008167483538980906, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00795062258938337, 'dropout_rate_Layer_2': 0.15598624228424285, 'dropout_rate_Layer_3': 0.25477494080759644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0047846557941211175, 'l1_Layer_2': 0.002211087540070959, 'l1_Layer_3': 0.0003853923457425085, 'n_units_Layer_1': 260, 'n_units_Layer_2': 60, 'n_units_Layer_3': 205}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.19 | sMAPE for Validation Set is: 43.00% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 23.99 | sMAPE for Test Set is: 29.44% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:52:26,339]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:52:29,877]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:52:30,289]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:52:30,496]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:52:43,265]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:52:49,439]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:52:51,881]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:52:55,540]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:53:00,683]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:53:07,990]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:53:12,592]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:53:17,351]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:53:18,133]\u001b[0m Trial 1077 finished with value: 8.69827558085184 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016914704966896799, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2768397054115095, 'dropout_rate_Layer_2': 0.18592103274741437, 'dropout_rate_Layer_3': 0.007637469773378767, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020153305855809375, 'l1_Layer_2': 0.0006070666867710076, 'l1_Layer_3': 0.0003768540700690657, 'n_units_Layer_1': 145, 'n_units_Layer_2': 190, 'n_units_Layer_3': 260}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.70 | sMAPE for Validation Set is: 39.13% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.98 | sMAPE for Test Set is: 27.72% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:53:25,428]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:53:30,683]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:53:42,745]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:53:49,661]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.11 | sMAPE for Validation Set is: 42.04% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.22 | sMAPE for Test Set is: 28.97% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:53:51,803]\u001b[0m Trial 1088 finished with value: 9.11108302434244 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013852106582994286, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.061069555296512236, 'dropout_rate_Layer_2': 0.1938667948918319, 'dropout_rate_Layer_3': 0.0007571418644481409, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.120475427369558e-05, 'l1_Layer_2': 0.0002584454899129267, 'l1_Layer_3': 1.3714267551548536e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 190, 'n_units_Layer_3': 160}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:53:55,904]\u001b[0m Trial 1085 finished with value: 9.152350620975719 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007089263144618868, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02611266532579769, 'dropout_rate_Layer_2': 0.006271953486071683, 'dropout_rate_Layer_3': 0.2643094809057319, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.016953597725479042, 'l1_Layer_2': 0.0014789625719484954, 'l1_Layer_3': 0.0006141393987389287, 'n_units_Layer_1': 250, 'n_units_Layer_2': 65, 'n_units_Layer_3': 155}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.15 | sMAPE for Validation Set is: 40.03% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.97 | sMAPE for Test Set is: 29.01% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:53:56,267]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:53:57,546]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:54:04,453]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:54:05,026]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:54:11,831]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:54:15,386]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:54:24,878]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:54:29,664]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:54:30,255]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:54:37,501]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:54:42,451]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:54:46,437]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:54:52,014]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:54:56,002]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:55:00,273]\u001b[0m Trial 1091 finished with value: 8.637633904629874 and parameters: {'n_hidden': 3, 'learning_rate': 0.001414463663291464, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16705057967758435, 'dropout_rate_Layer_2': 0.14162627349405799, 'dropout_rate_Layer_3': 0.015854361909939736, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002793611211908222, 'l1_Layer_2': 0.0009019219262052127, 'l1_Layer_3': 0.00023099987405340134, 'n_units_Layer_1': 135, 'n_units_Layer_2': 185, 'n_units_Layer_3': 255}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.64 | sMAPE for Validation Set is: 37.75% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.69 | sMAPE for Test Set is: 28.70% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:55:01,892]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:55:06,124]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:55:08,685]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:55:11,091]\u001b[0m Trial 1096 finished with value: 8.611655464469004 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023631633047376073, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17568989001144486, 'dropout_rate_Layer_2': 0.29193333924841824, 'dropout_rate_Layer_3': 0.01653029947684123, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000524354960434489, 'l1_Layer_2': 0.0014602662458938708, 'l1_Layer_3': 0.0002695405492715262, 'n_units_Layer_1': 175, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.61 | sMAPE for Validation Set is: 38.66% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.73 | sMAPE for Test Set is: 27.76% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:55:15,170]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:55:22,233]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:55:24,448]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:55:29,311]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:55:31,243]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:55:37,612]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:55:38,539]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:55:40,771]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:55:46,763]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:55:47,062]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:55:55,272]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:55:58,088]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:56:01,798]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:56:07,611]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:56:14,187]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:56:16,314]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:56:21,440]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:56:25,632]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:56:26,175]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:56:26,460]\u001b[0m Trial 1112 finished with value: 8.986018066014696 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012965200624640196, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07127285363433195, 'dropout_rate_Layer_2': 0.19469014894330078, 'dropout_rate_Layer_3': 0.0035418782609537226, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006087946275984367, 'l1_Layer_2': 0.00026482775082271854, 'l1_Layer_3': 1.540768012528914e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 175, 'n_units_Layer_3': 150}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.99 | sMAPE for Validation Set is: 41.05% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.25 | sMAPE for Test Set is: 28.17% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:56:35,659]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:56:36,638]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:56:37,147]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:57:05,340]\u001b[0m Trial 1133 finished with value: 9.05596516809742 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005398699544875089, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014127447325433216, 'dropout_rate_Layer_2': 0.021051478000797545, 'dropout_rate_Layer_3': 0.2658689641234075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010497568819825944, 'l1_Layer_2': 0.001261075963519616, 'l1_Layer_3': 0.00020444725859273595, 'n_units_Layer_1': 110, 'n_units_Layer_2': 80, 'n_units_Layer_3': 205}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.06 | sMAPE for Validation Set is: 41.83% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.70 | sMAPE for Test Set is: 28.91% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:57:06,421]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:57:11,993]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:57:16,840]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:57:22,889]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.68 | sMAPE for Validation Set is: 38.57% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.62 | sMAPE for Test Set is: 27.39% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:57:26,049]\u001b[0m Trial 1134 finished with value: 8.680865070621035 and parameters: {'n_hidden': 3, 'learning_rate': 0.002073273137302733, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1802861544420847, 'dropout_rate_Layer_2': 0.35153547036235744, 'dropout_rate_Layer_3': 7.02373104006903e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005417997055827166, 'l1_Layer_2': 0.001509556971146357, 'l1_Layer_3': 0.0002731261442050124, 'n_units_Layer_1': 130, 'n_units_Layer_2': 175, 'n_units_Layer_3': 275}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:57:29,225]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:57:32,929]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:57:37,252]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:57:41,722]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:57:45,722]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:57:51,551]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:57:57,099]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:58:00,571]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:58:04,041]\u001b[0m Trial 1135 finished with value: 9.062190454680277 and parameters: {'n_hidden': 3, 'learning_rate': 0.000560106915703311, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0003945563535469286, 'dropout_rate_Layer_2': 0.03465201417281715, 'dropout_rate_Layer_3': 0.26919075049139796, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009925671390975596, 'l1_Layer_2': 0.0020871613989484395, 'l1_Layer_3': 0.0008366591654468765, 'n_units_Layer_1': 110, 'n_units_Layer_2': 80, 'n_units_Layer_3': 205}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.06 | sMAPE for Validation Set is: 41.21% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.36 | sMAPE for Test Set is: 28.19% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:58:06,155]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:58:12,132]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:58:24,079]\u001b[0m Trial 1144 finished with value: 8.941564587526779 and parameters: {'n_hidden': 3, 'learning_rate': 0.001731880927666797, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10195444680396748, 'dropout_rate_Layer_2': 0.201068713457247, 'dropout_rate_Layer_3': 0.03218805618984705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005593864433975645, 'l1_Layer_2': 0.0002728376193174987, 'l1_Layer_3': 2.4814661630012997e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 170, 'n_units_Layer_3': 150}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.94 | sMAPE for Validation Set is: 40.52% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.43 | sMAPE for Test Set is: 28.06% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:58:29,896]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:58:40,124]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:58:46,846]\u001b[0m Trial 1152 finished with value: 9.047753856918304 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015487643944400481, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17997019572000725, 'dropout_rate_Layer_2': 0.17731040443792886, 'dropout_rate_Layer_3': 0.3466815162514243, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005043281490464458, 'l1_Layer_2': 0.0007916142381270659, 'l1_Layer_3': 1.1785818094046747e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 165, 'n_units_Layer_3': 160}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.05 | sMAPE for Validation Set is: 40.53% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.57 | sMAPE for Test Set is: 29.23% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:58:54,088]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:58:58,457]\u001b[0m Trial 1156 finished with value: 9.01727277116838 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018072631281167738, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10212810574898994, 'dropout_rate_Layer_2': 0.19507023354548986, 'dropout_rate_Layer_3': 0.028129730545487806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.613461051644747e-05, 'l1_Layer_2': 0.0002591360960235826, 'l1_Layer_3': 2.084331158834307e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 165, 'n_units_Layer_3': 150}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.02 | sMAPE for Validation Set is: 42.42% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.81 | sMAPE for Test Set is: 29.98% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:59:02,235]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:59:06,802]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:59:06,944]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:59:08,456]\u001b[0m Trial 1157 finished with value: 9.161519648554695 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018237260243350306, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10071603858423617, 'dropout_rate_Layer_2': 0.17621916074344585, 'dropout_rate_Layer_3': 0.04464132695712129, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00048407472775263623, 'l1_Layer_2': 0.00020892646171095924, 'l1_Layer_3': 2.669512324051924e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 160, 'n_units_Layer_3': 150}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.16 | sMAPE for Validation Set is: 42.37% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.32 | sMAPE for Test Set is: 28.92% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:59:16,143]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:59:21,236]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:59:26,532]\u001b[0m Trial 1158 finished with value: 8.906530514187219 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017755629436062308, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1857774606584388, 'dropout_rate_Layer_2': 0.16965536336581302, 'dropout_rate_Layer_3': 0.0279208455479742, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000522511522775493, 'l1_Layer_2': 0.00022122004108377654, 'l1_Layer_3': 2.5183532556510053e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 165, 'n_units_Layer_3': 170}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.91 | sMAPE for Validation Set is: 38.84% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.90 | sMAPE for Test Set is: 28.04% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:59:33,484]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:59:36,743]\u001b[0m Trial 1165 finished with value: 9.059535092885453 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016876439981386938, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16767248576004332, 'dropout_rate_Layer_2': 0.16774242646275941, 'dropout_rate_Layer_3': 0.0261793739671747, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.692300819485868e-05, 'l1_Layer_2': 0.00026834618308638967, 'l1_Layer_3': 1.1534323761759054e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 170, 'n_units_Layer_3': 150}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.06 | sMAPE for Validation Set is: 41.74% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.97 | sMAPE for Test Set is: 29.04% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:59:45,509]\u001b[0m Trial 1166 finished with value: 9.010051406652545 and parameters: {'n_hidden': 3, 'learning_rate': 0.001851464722733838, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19526460628574285, 'dropout_rate_Layer_2': 0.16699081544281663, 'dropout_rate_Layer_3': 0.028751681432578228, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.7578024492735785e-05, 'l1_Layer_2': 0.00026444795731007324, 'l1_Layer_3': 2.3368784873960177e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 165, 'n_units_Layer_3': 150}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.01 | sMAPE for Validation Set is: 40.17% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.43 | sMAPE for Test Set is: 27.79% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:59:46,397]\u001b[0m Trial 1167 finished with value: 9.126481468298818 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018825741782489828, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19323017510716126, 'dropout_rate_Layer_2': 0.16669022461234267, 'dropout_rate_Layer_3': 0.04402931978717894, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.4450355586709786e-05, 'l1_Layer_2': 0.0002677668314494919, 'l1_Layer_3': 2.569071149038454e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 165, 'n_units_Layer_3': 150}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.13 | sMAPE for Validation Set is: 40.11% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 25.37 | sMAPE for Test Set is: 30.65% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 04:59:48,622]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:59:56,489]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 04:59:57,208]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:00:01,776]\u001b[0m Trial 1169 finished with value: 9.370256867533483 and parameters: {'n_hidden': 3, 'learning_rate': 0.001859288130218652, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17808208046445104, 'dropout_rate_Layer_2': 0.16275593171224104, 'dropout_rate_Layer_3': 0.033677934207020116, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.814989671180632e-05, 'l1_Layer_2': 0.00024026575639307912, 'l1_Layer_3': 2.7694748301624393e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 160, 'n_units_Layer_3': 150}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.37 | sMAPE for Validation Set is: 40.82% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 25.13 | sMAPE for Test Set is: 30.02% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:00:05,908]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:00:06,226]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:00:14,397]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:00:14,576]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:00:15,332]\u001b[0m Trial 1163 finished with value: 8.593396443049722 and parameters: {'n_hidden': 3, 'learning_rate': 0.002137661530925953, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23472964942248797, 'dropout_rate_Layer_2': 0.2699592735728468, 'dropout_rate_Layer_3': 0.006603434728288437, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028104752034561, 'l1_Layer_2': 0.0006504432730594341, 'l1_Layer_3': 0.0002560231531971059, 'n_units_Layer_1': 185, 'n_units_Layer_2': 170, 'n_units_Layer_3': 270}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.59 | sMAPE for Validation Set is: 37.57% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.68 | sMAPE for Test Set is: 27.56% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:00:24,857]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:00:25,367]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:00:26,127]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:00:32,437]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:00:34,572]\u001b[0m Trial 1173 finished with value: 8.817257391728234 and parameters: {'n_hidden': 3, 'learning_rate': 0.001769314459557004, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2010809674778514, 'dropout_rate_Layer_2': 0.16540004869562752, 'dropout_rate_Layer_3': 0.020812149369845212, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.2319109526813256e-05, 'l1_Layer_2': 0.00024254193825029956, 'l1_Layer_3': 2.7601823893799507e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 160, 'n_units_Layer_3': 145}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.82 | sMAPE for Validation Set is: 41.21% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.49 | sMAPE for Test Set is: 27.81% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:00:35,435]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:00:38,759]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:00:40,416]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:00:42,517]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:00:50,635]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:00:53,607]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:00:57,097]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:00:57,795]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:00:58,956]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:01:04,188]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:01:10,999]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:01:11,171]\u001b[0m Trial 1187 finished with value: 8.790682634068142 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018762345996421296, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1878069007987759, 'dropout_rate_Layer_2': 0.1651774630839961, 'dropout_rate_Layer_3': 0.03681899756777183, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.003572340447045e-05, 'l1_Layer_2': 0.00019693781503217313, 'l1_Layer_3': 2.2235184720251136e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 165, 'n_units_Layer_3': 245}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.79 | sMAPE for Validation Set is: 39.96% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.60 | sMAPE for Test Set is: 28.17% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:01:12,135]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:01:13,226]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:01:23,741]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:01:23,800]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:01:31,108]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:01:35,494]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:01:39,879]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:01:48,871]\u001b[0m Trial 1200 finished with value: 8.76661165153734 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015681646102913766, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19273887026475334, 'dropout_rate_Layer_2': 0.16026580546073116, 'dropout_rate_Layer_3': 0.03462075559220067, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.852916410942498e-05, 'l1_Layer_2': 0.00016313892274236354, 'l1_Layer_3': 2.7582139232967103e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 170, 'n_units_Layer_3': 225}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.77 | sMAPE for Validation Set is: 39.00% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 24.98 | sMAPE for Test Set is: 30.03% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:01:55,058]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:01:55,588]\u001b[0m Trial 1198 finished with value: 8.952581935016616 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017241807184414358, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1894810543074978, 'dropout_rate_Layer_2': 0.16222335862120993, 'dropout_rate_Layer_3': 0.034030010245097345, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.83003879652821e-05, 'l1_Layer_2': 0.00013729508884142966, 'l1_Layer_3': 2.945341296708823e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 155, 'n_units_Layer_3': 235}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.95 | sMAPE for Validation Set is: 39.69% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.43 | sMAPE for Test Set is: 28.27% | rMAE for Test Set is: 0.62\n",
      "MAE for Validation Set is: 8.57 | sMAPE for Validation Set is: 38.42% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.20 | sMAPE for Test Set is: 28.01% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:01:59,105]\u001b[0m Trial 1199 finished with value: 8.57037560757668 and parameters: {'n_hidden': 3, 'learning_rate': 0.001716589597547907, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1959293610306057, 'dropout_rate_Layer_2': 0.15952309997103675, 'dropout_rate_Layer_3': 0.038822450941872116, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.3207592883117893e-05, 'l1_Layer_2': 0.00017547879225466526, 'l1_Layer_3': 2.967566236125436e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 170, 'n_units_Layer_3': 150}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:02:06,156]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:02:06,191]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:02:14,434]\u001b[0m Trial 1203 finished with value: 8.54567348618299 and parameters: {'n_hidden': 3, 'learning_rate': 0.001606319323369144, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18912518754109697, 'dropout_rate_Layer_2': 0.16350469917310084, 'dropout_rate_Layer_3': 0.00980435217355314, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.441298482534082e-05, 'l1_Layer_2': 0.00020442194032371891, 'l1_Layer_3': 2.786459545396385e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.55 | sMAPE for Validation Set is: 38.97% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.33 | sMAPE for Test Set is: 27.31% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:02:19,256]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:02:23,908]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:02:28,294]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:02:32,866]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:02:32,913]\u001b[0m Trial 1210 finished with value: 8.803247501669329 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018208324994752425, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19060344420447972, 'dropout_rate_Layer_2': 0.16291395984278662, 'dropout_rate_Layer_3': 0.04612935523356761, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.3055112710822216e-05, 'l1_Layer_2': 9.998073013575157e-05, 'l1_Layer_3': 2.7504230413021446e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 145, 'n_units_Layer_3': 250}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.80 | sMAPE for Validation Set is: 39.30% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.20 | sMAPE for Test Set is: 28.01% | rMAE for Test Set is: 0.64\n",
      "MAE for Validation Set is: 8.56 | sMAPE for Validation Set is: 39.35% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.82 | sMAPE for Test Set is: 27.84% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:02:36,553]\u001b[0m Trial 1206 finished with value: 8.559540753708106 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018714087409087508, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2114720633787579, 'dropout_rate_Layer_2': 0.1580423441620583, 'dropout_rate_Layer_3': 0.041981299616954446, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.187373322758117e-05, 'l1_Layer_2': 0.0001530534499834717, 'l1_Layer_3': 2.8863332676859223e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 170, 'n_units_Layer_3': 240}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:02:41,248]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:02:44,264]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:02:47,366]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:02:49,999]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:02:55,255]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:03:05,182]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:03:09,393]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:03:12,409]\u001b[0m Trial 1221 finished with value: 8.839479224411917 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017710017871913853, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18720983529527474, 'dropout_rate_Layer_2': 0.15671122511790164, 'dropout_rate_Layer_3': 0.033575145859738253, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2537531237479253e-05, 'l1_Layer_2': 8.50584979975841e-05, 'l1_Layer_3': 2.6631457507926878e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 150, 'n_units_Layer_3': 255}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.84 | sMAPE for Validation Set is: 38.92% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.20 | sMAPE for Test Set is: 27.85% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:03:12,790]\u001b[0m Trial 1219 finished with value: 8.72896337310148 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020557766263392223, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19156156363098925, 'dropout_rate_Layer_2': 0.1567249853322696, 'dropout_rate_Layer_3': 0.038507404700813194, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.482937223345451e-05, 'l1_Layer_2': 9.2053029427788e-05, 'l1_Layer_3': 2.7784665916273147e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 130, 'n_units_Layer_3': 240}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.73 | sMAPE for Validation Set is: 38.40% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.43 | sMAPE for Test Set is: 27.32% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:03:19,849]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:03:27,166]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:03:36,041]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:03:45,318]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:03:54,719]\u001b[0m Trial 1227 finished with value: 8.698699579970112 and parameters: {'n_hidden': 3, 'learning_rate': 0.002027669939896901, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19232991899185498, 'dropout_rate_Layer_2': 0.15601168888295264, 'dropout_rate_Layer_3': 0.051392069292607784, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3099772190495662e-05, 'l1_Layer_2': 8.497590874218596e-05, 'l1_Layer_3': 3.089288668622908e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 130, 'n_units_Layer_3': 240}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.70 | sMAPE for Validation Set is: 38.21% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.29 | sMAPE for Test Set is: 27.92% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:03:59,510]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:03:59,739]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:04:00,582]\u001b[0m Trial 1229 finished with value: 8.705843601118575 and parameters: {'n_hidden': 3, 'learning_rate': 0.002083726727253535, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1920085483143236, 'dropout_rate_Layer_2': 0.1570005981920945, 'dropout_rate_Layer_3': 0.04351097476892243, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5974857183895288e-05, 'l1_Layer_2': 8.5398125667266e-05, 'l1_Layer_3': 3.318787565385366e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 130, 'n_units_Layer_3': 240}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.71 | sMAPE for Validation Set is: 39.49% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.31 | sMAPE for Test Set is: 28.04% | rMAE for Test Set is: 0.65\n",
      "MAE for Validation Set is: 8.62 | sMAPE for Validation Set is: 38.12% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.99 | sMAPE for Test Set is: 26.57% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:04:07,037]\u001b[0m Trial 1214 finished with value: 8.615120573485324 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013308494781242408, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.205777078151316, 'dropout_rate_Layer_2': 0.27991919877894406, 'dropout_rate_Layer_3': 0.044698420863210644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004650862656810073, 'l1_Layer_2': 0.0012432255213895367, 'l1_Layer_3': 0.00017025037022501305, 'n_units_Layer_1': 150, 'n_units_Layer_2': 175, 'n_units_Layer_3': 285}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:04:08,834]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:04:15,882]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:04:19,141]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:04:24,317]\u001b[0m Trial 1232 finished with value: 8.811263089058308 and parameters: {'n_hidden': 3, 'learning_rate': 0.002045131769628247, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20159009373218215, 'dropout_rate_Layer_2': 0.15557748933419932, 'dropout_rate_Layer_3': 0.04911082326720846, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3033448859653528e-05, 'l1_Layer_2': 5.635522958810088e-05, 'l1_Layer_3': 3.33819494229053e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 125, 'n_units_Layer_3': 235}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.81 | sMAPE for Validation Set is: 39.25% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 24.11 | sMAPE for Test Set is: 28.80% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:04:24,679]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:04:32,276]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:04:36,993]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:04:40,569]\u001b[0m Trial 1237 finished with value: 8.688974832802346 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020560851357419884, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2071564680033165, 'dropout_rate_Layer_2': 0.1570789496278975, 'dropout_rate_Layer_3': 0.03994574400048622, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4822017483990456e-05, 'l1_Layer_2': 8.916719839496382e-05, 'l1_Layer_3': 2.7452030172389775e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 120, 'n_units_Layer_3': 230}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.69 | sMAPE for Validation Set is: 40.39% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 24.22 | sMAPE for Test Set is: 29.57% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:04:41,351]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:04:42,012]\u001b[0m Trial 1238 finished with value: 8.76583335426163 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019859350488664112, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.207386827244145, 'dropout_rate_Layer_2': 0.15708085875926062, 'dropout_rate_Layer_3': 0.039557836131135365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.4516479532649897e-05, 'l1_Layer_2': 8.763934469192566e-05, 'l1_Layer_3': 3.070937931379382e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 115, 'n_units_Layer_3': 235}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.77 | sMAPE for Validation Set is: 41.37% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.68 | sMAPE for Test Set is: 28.95% | rMAE for Test Set is: 0.66\n",
      "MAE for Validation Set is: 8.71 | sMAPE for Validation Set is: 39.95% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.91 | sMAPE for Test Set is: 27.97% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:04:49,135]\u001b[0m Trial 1233 finished with value: 8.705717939003653 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025863844009410635, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18144835149498173, 'dropout_rate_Layer_2': 0.18682883305642015, 'dropout_rate_Layer_3': 0.024997970314242824, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022788619054217506, 'l1_Layer_2': 0.0013736231606766493, 'l1_Layer_3': 0.0002743455942353952, 'n_units_Layer_1': 155, 'n_units_Layer_2': 180, 'n_units_Layer_3': 260}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:04:51,827]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:04:53,477]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:04:59,293]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:05:03,031]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:05:08,354]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:05:13,550]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:05:16,579]\u001b[0m Trial 1247 finished with value: 8.717350041072196 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021160238693713946, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20418339392262588, 'dropout_rate_Layer_2': 0.15392860650877566, 'dropout_rate_Layer_3': 0.04413583727426326, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1031425914649228e-05, 'l1_Layer_2': 5.208599256461014e-05, 'l1_Layer_3': 3.519160040079189e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 110, 'n_units_Layer_3': 235}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.72 | sMAPE for Validation Set is: 38.70% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.15 | sMAPE for Test Set is: 27.87% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:05:19,552]\u001b[0m Trial 1248 finished with value: 8.788747908435175 and parameters: {'n_hidden': 3, 'learning_rate': 0.002044260329701061, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20423964574146264, 'dropout_rate_Layer_2': 0.15618026600213314, 'dropout_rate_Layer_3': 0.0409352376867525, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5534037722560057e-05, 'l1_Layer_2': 8.701858079219086e-05, 'l1_Layer_3': 3.5455615475554364e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 130, 'n_units_Layer_3': 235}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.79 | sMAPE for Validation Set is: 39.70% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.56 | sMAPE for Test Set is: 28.67% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:05:22,943]\u001b[0m Trial 1242 finished with value: 8.659931954834938 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020859325014068657, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.216750648660592, 'dropout_rate_Layer_2': 0.1547944978951287, 'dropout_rate_Layer_3': 0.057453011711338785, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3338034079586368e-05, 'l1_Layer_2': 5.8822058536484525e-05, 'l1_Layer_3': 2.879771365463449e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 120, 'n_units_Layer_3': 230}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.66 | sMAPE for Validation Set is: 39.59% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.52 | sMAPE for Test Set is: 27.25% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:05:23,987]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:05:30,479]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:05:30,796]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:05:38,793]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:05:41,632]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:05:44,382]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:05:49,452]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:05:49,762]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:05:57,289]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:05:57,621]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:06:10,746]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:06:17,046]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:06:22,207]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:06:22,480]\u001b[0m Trial 1251 finished with value: 8.650008874765097 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017549613675712824, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1905030762200833, 'dropout_rate_Layer_2': 0.28050955559256263, 'dropout_rate_Layer_3': 0.021159234617497982, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004887554349600199, 'l1_Layer_2': 0.0016786318816746975, 'l1_Layer_3': 0.0002356073946770557, 'n_units_Layer_1': 165, 'n_units_Layer_2': 175, 'n_units_Layer_3': 300}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.65 | sMAPE for Validation Set is: 40.05% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.26 | sMAPE for Test Set is: 27.25% | rMAE for Test Set is: 0.62\n",
      "MAE for Validation Set is: 8.59 | sMAPE for Validation Set is: 38.80% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.93 | sMAPE for Test Set is: 27.89% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:06:26,327]\u001b[0m Trial 1263 finished with value: 8.592903318728773 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021631172655978835, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22578414773074953, 'dropout_rate_Layer_2': 0.15954293910353384, 'dropout_rate_Layer_3': 0.05308448919704181, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5590097441797193e-05, 'l1_Layer_2': 5.053471648843336e-05, 'l1_Layer_3': 2.796859388660277e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 130, 'n_units_Layer_3': 225}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:06:29,059]\u001b[0m Trial 1253 finished with value: 8.646419237153529 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017419092431050478, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1943700468269316, 'dropout_rate_Layer_2': 0.2702517054002282, 'dropout_rate_Layer_3': 0.0208049171041659, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005047897426606012, 'l1_Layer_2': 0.0005580251857228298, 'l1_Layer_3': 0.00022745403814540435, 'n_units_Layer_1': 165, 'n_units_Layer_2': 175, 'n_units_Layer_3': 290}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.65 | sMAPE for Validation Set is: 38.06% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.73 | sMAPE for Test Set is: 27.16% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:06:41,603]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:06:45,749]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:06:53,625]\u001b[0m Trial 1270 finished with value: 8.612689240760654 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022782781835248285, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22736347463641654, 'dropout_rate_Layer_2': 0.1568806409802219, 'dropout_rate_Layer_3': 0.06737602978904653, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.44025653006881e-05, 'l1_Layer_2': 6.773732535809919e-05, 'l1_Layer_3': 2.698095977993344e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 125, 'n_units_Layer_3': 220}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.61 | sMAPE for Validation Set is: 38.06% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.37 | sMAPE for Test Set is: 27.01% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:06:57,647]\u001b[0m Trial 1267 finished with value: 8.533360865982795 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019895582140960887, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22857437255235794, 'dropout_rate_Layer_2': 0.1576029129198831, 'dropout_rate_Layer_3': 0.05037286105009965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3881902227894723e-05, 'l1_Layer_2': 9.09051672366225e-05, 'l1_Layer_3': 2.8573624429318967e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 115, 'n_units_Layer_3': 240}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.53 | sMAPE for Validation Set is: 39.63% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.21 | sMAPE for Test Set is: 28.44% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:07:06,770]\u001b[0m Trial 1268 finished with value: 9.08014984911735 and parameters: {'n_hidden': 3, 'learning_rate': 0.001006740115786422, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007204365118090512, 'dropout_rate_Layer_2': 0.000775157009502583, 'dropout_rate_Layer_3': 0.23587627430300367, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02196716328929089, 'l1_Layer_2': 0.005234254734551883, 'l1_Layer_3': 0.00021146974267651124, 'n_units_Layer_1': 230, 'n_units_Layer_2': 55, 'n_units_Layer_3': 190}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.08 | sMAPE for Validation Set is: 40.99% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.73 | sMAPE for Test Set is: 28.46% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:07:11,909]\u001b[0m Trial 1274 finished with value: 8.814007782274643 and parameters: {'n_hidden': 3, 'learning_rate': 0.002351982302350364, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22636900116854625, 'dropout_rate_Layer_2': 0.15766745295088533, 'dropout_rate_Layer_3': 0.06793154627650662, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3180273926496113e-05, 'l1_Layer_2': 7.094135090993778e-05, 'l1_Layer_3': 3.436094249415296e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 120, 'n_units_Layer_3': 220}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.81 | sMAPE for Validation Set is: 39.06% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 24.03 | sMAPE for Test Set is: 29.15% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:07:16,937]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:07:17,694]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:07:25,929]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:07:35,794]\u001b[0m Trial 1272 finished with value: 8.62782422272691 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015182460715840245, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2325430399986049, 'dropout_rate_Layer_2': 0.1415493806658793, 'dropout_rate_Layer_3': 0.03191790305129901, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004011607436637898, 'l1_Layer_2': 0.0007798214075198597, 'l1_Layer_3': 0.00013896865864901884, 'n_units_Layer_1': 135, 'n_units_Layer_2': 230, 'n_units_Layer_3': 270}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.63 | sMAPE for Validation Set is: 38.03% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.84 | sMAPE for Test Set is: 27.44% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:07:40,969]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:07:44,219]\u001b[0m Trial 1277 finished with value: 8.679928003408657 and parameters: {'n_hidden': 3, 'learning_rate': 0.002296426277064606, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22538302530877977, 'dropout_rate_Layer_2': 0.15637269999451572, 'dropout_rate_Layer_3': 0.054293287705251866, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1775092278000389e-05, 'l1_Layer_2': 9.109480527616654e-05, 'l1_Layer_3': 3.1894189948764024e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 125, 'n_units_Layer_3': 220}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.68 | sMAPE for Validation Set is: 38.94% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.22 | sMAPE for Test Set is: 27.12% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:07:50,205]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.58 | sMAPE for Validation Set is: 39.24% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.86 | sMAPE for Test Set is: 27.84% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:07:52,591]\u001b[0m Trial 1279 finished with value: 8.5786800291805 and parameters: {'n_hidden': 3, 'learning_rate': 0.002329381802553125, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23202597448449808, 'dropout_rate_Layer_2': 0.15629830366732342, 'dropout_rate_Layer_3': 0.055598895926336205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4966434060802635e-05, 'l1_Layer_2': 9.876786361671534e-05, 'l1_Layer_3': 4.172488442480568e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 125, 'n_units_Layer_3': 220}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:07:54,259]\u001b[0m Trial 1273 finished with value: 8.930885402952825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009994698726898468, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015187444762421313, 'dropout_rate_Layer_2': 0.02235469960488163, 'dropout_rate_Layer_3': 0.27235691306335136, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02117096472149046, 'l1_Layer_2': 0.003120001370275675, 'l1_Layer_3': 0.0002341525317931432, 'n_units_Layer_1': 220, 'n_units_Layer_2': 75, 'n_units_Layer_3': 185}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.93 | sMAPE for Validation Set is: 38.56% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.91 | sMAPE for Test Set is: 28.37% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:07:55,691]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:08:01,843]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:08:06,062]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:08:09,979]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:08:10,601]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:08:16,752]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:08:18,327]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:08:24,049]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:08:29,136]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:08:33,841]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:08:37,281]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:08:37,501]\u001b[0m Trial 1286 finished with value: 9.124900287340983 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010066096283623302, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009006578475699065, 'dropout_rate_Layer_2': 0.029265559452223595, 'dropout_rate_Layer_3': 0.2765748735763981, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01551339755853309, 'l1_Layer_2': 0.0014493224704241767, 'l1_Layer_3': 0.00023618716284591918, 'n_units_Layer_1': 220, 'n_units_Layer_2': 75, 'n_units_Layer_3': 195}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.12 | sMAPE for Validation Set is: 40.29% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 24.61 | sMAPE for Test Set is: 29.56% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:08:38,404]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.64 | sMAPE for Validation Set is: 40.13% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.27 | sMAPE for Test Set is: 29.49% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:08:43,777]\u001b[0m Trial 1291 finished with value: 8.640113899067126 and parameters: {'n_hidden': 3, 'learning_rate': 0.002225841877019285, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21910215253014356, 'dropout_rate_Layer_2': 0.15310958263953328, 'dropout_rate_Layer_3': 0.05761355370043535, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.529122492130231e-05, 'l1_Layer_2': 0.0001018579450188351, 'l1_Layer_3': 3.998622647941932e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 130, 'n_units_Layer_3': 225}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:08:49,249]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:08:49,962]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:08:55,986]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:08:56,553]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:09:02,325]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:09:04,329]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:09:08,475]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:09:13,969]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:09:18,121]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:09:22,937]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:09:23,263]\u001b[0m Trial 1299 finished with value: 8.551350995780227 and parameters: {'n_hidden': 3, 'learning_rate': 0.002202489882663876, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23639997349270533, 'dropout_rate_Layer_2': 0.1404566454458869, 'dropout_rate_Layer_3': 0.04561629642273312, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5940299917435308e-05, 'l1_Layer_2': 8.920906014241742e-05, 'l1_Layer_3': 4.4195430588111986e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 140, 'n_units_Layer_3': 235}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.55 | sMAPE for Validation Set is: 38.72% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.25 | sMAPE for Test Set is: 28.77% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:09:29,977]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:09:30,442]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:09:31,894]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:09:39,423]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:09:40,706]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:09:42,236]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:09:43,275]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:09:52,698]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:09:53,339]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:10:02,712]\u001b[0m Trial 1316 finished with value: 8.823610967100256 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020108233530746686, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19649117850817857, 'dropout_rate_Layer_2': 0.15102065306256637, 'dropout_rate_Layer_3': 0.040813718404955096, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5292393568658504e-05, 'l1_Layer_2': 7.615033737683438e-05, 'l1_Layer_3': 2.7425281653404313e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 125, 'n_units_Layer_3': 230}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.82 | sMAPE for Validation Set is: 39.83% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.98 | sMAPE for Test Set is: 27.78% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:10:08,542]\u001b[0m Trial 1314 finished with value: 8.58196083990589 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020145704547498747, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20027917133966594, 'dropout_rate_Layer_2': 0.15857143803496562, 'dropout_rate_Layer_3': 0.04771167714299011, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5555973963379422e-05, 'l1_Layer_2': 4.2693091164979936e-05, 'l1_Layer_3': 2.8618040191883543e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 125, 'n_units_Layer_3': 230}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.58 | sMAPE for Validation Set is: 38.24% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.49 | sMAPE for Test Set is: 27.35% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:10:08,805]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:10:08,919]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:10:10,955]\u001b[0m Trial 1319 finished with value: 8.648380688689684 and parameters: {'n_hidden': 3, 'learning_rate': 0.002025403193850683, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1972836103349383, 'dropout_rate_Layer_2': 0.1490008193796852, 'dropout_rate_Layer_3': 0.04071027833450742, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0762764694120613e-05, 'l1_Layer_2': 4.236245561157543e-05, 'l1_Layer_3': 2.8667007732793367e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 125, 'n_units_Layer_3': 230}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.65 | sMAPE for Validation Set is: 38.45% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.68 | sMAPE for Test Set is: 28.82% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:10:15,946]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:10:25,724]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:10:29,349]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:10:30,078]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:10:30,221]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.70 | sMAPE for Validation Set is: 40.05% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.76 | sMAPE for Test Set is: 29.43% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:10:36,844]\u001b[0m Trial 1323 finished with value: 8.699967230632089 and parameters: {'n_hidden': 3, 'learning_rate': 0.002525146532808042, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2289957474931427, 'dropout_rate_Layer_2': 0.13080417827895718, 'dropout_rate_Layer_3': 0.060589254467947856, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0083531452409788e-05, 'l1_Layer_2': 3.2835464578485755e-05, 'l1_Layer_3': 3.352063443248522e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 120, 'n_units_Layer_3': 225}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:10:40,079]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:10:41,091]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:10:41,217]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:10:46,088]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:10:50,104]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:10:52,556]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:10:53,143]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:10:53,497]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:10:56,737]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:11:04,024]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:11:07,222]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:11:07,962]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:11:08,144]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:11:13,301]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:11:23,976]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:11:24,745]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:11:30,916]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:11:36,257]\u001b[0m Trial 1342 finished with value: 8.5801216224792 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022751396666951637, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2008380128328903, 'dropout_rate_Layer_2': 0.12677055076329233, 'dropout_rate_Layer_3': 0.040578309961772197, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0384030504142492e-05, 'l1_Layer_2': 6.190535026728818e-05, 'l1_Layer_3': 3.9250931018956555e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 130, 'n_units_Layer_3': 240}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.58 | sMAPE for Validation Set is: 38.60% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.61 | sMAPE for Test Set is: 28.85% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:11:43,554]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:11:44,067]\u001b[0m Trial 1346 finished with value: 8.675946852474326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036265937180654023, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20703249900169227, 'dropout_rate_Layer_2': 0.15044888013016386, 'dropout_rate_Layer_3': 0.04726674455744374, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4845238346981802e-05, 'l1_Layer_2': 5.626030510708407e-05, 'l1_Layer_3': 2.9108697103091435e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 115, 'n_units_Layer_3': 230}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.68 | sMAPE for Validation Set is: 39.12% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.58 | sMAPE for Test Set is: 27.34% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:11:51,293]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:11:51,969]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:11:52,891]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:11:57,594]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:12:02,737]\u001b[0m Trial 1347 finished with value: 8.522990076781054 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019476614412374312, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1937853990445366, 'dropout_rate_Layer_2': 0.1513772496585603, 'dropout_rate_Layer_3': 0.03831890112792062, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4742506233737181e-05, 'l1_Layer_2': 6.165963367037636e-05, 'l1_Layer_3': 2.7493183640808214e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 135, 'n_units_Layer_3': 240}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.52 | sMAPE for Validation Set is: 38.01% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.25 | sMAPE for Test Set is: 26.90% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:12:03,921]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:12:09,137]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:12:13,700]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:12:14,011]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:12:14,851]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:12:15,884]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:12:28,463]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:12:37,034]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:12:41,004]\u001b[0m Trial 1359 finished with value: 8.658817594816137 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022873199465884095, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19825041113820374, 'dropout_rate_Layer_2': 0.14181780149981912, 'dropout_rate_Layer_3': 0.07642026636152019, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3121960138027278e-05, 'l1_Layer_2': 7.426116268770622e-05, 'l1_Layer_3': 3.229106977379117e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 135, 'n_units_Layer_3': 215}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.66 | sMAPE for Validation Set is: 38.64% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.13 | sMAPE for Test Set is: 27.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:12:45,923]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:12:46,032]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:12:53,688]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:12:53,764]\u001b[0m Trial 1361 finished with value: 9.328235897277045 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012103116928497088, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05105821350726702, 'dropout_rate_Layer_2': 0.017407950273472923, 'dropout_rate_Layer_3': 0.2587051209226124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.021011201454869437, 'l1_Layer_2': 0.002926747665649225, 'l1_Layer_3': 0.00021240089275661154, 'n_units_Layer_1': 230, 'n_units_Layer_2': 70, 'n_units_Layer_3': 175}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.33 | sMAPE for Validation Set is: 42.14% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 24.23 | sMAPE for Test Set is: 28.93% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:13:02,037]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:13:02,137]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:13:10,985]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:13:14,670]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:13:19,431]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:13:24,919]\u001b[0m Trial 1360 finished with value: 8.61831501694346 and parameters: {'n_hidden': 3, 'learning_rate': 0.00175422319008967, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19247559024846148, 'dropout_rate_Layer_2': 0.16368176440240254, 'dropout_rate_Layer_3': 0.01639035845054781, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00032315692823856946, 'l1_Layer_2': 0.000973630806930442, 'l1_Layer_3': 0.0003168702926900277, 'n_units_Layer_1': 155, 'n_units_Layer_2': 170, 'n_units_Layer_3': 285}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.62 | sMAPE for Validation Set is: 39.77% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.13 | sMAPE for Test Set is: 27.31% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:13:29,949]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:13:30,110]\u001b[0m Trial 1371 finished with value: 8.734594232837049 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022970637000288984, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22379726685519133, 'dropout_rate_Layer_2': 0.1483769319226205, 'dropout_rate_Layer_3': 0.04690085918223463, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.600466958393592e-05, 'l1_Layer_2': 4.307739476811645e-05, 'l1_Layer_3': 4.343876472082708e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 115, 'n_units_Layer_3': 230}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.73 | sMAPE for Validation Set is: 38.81% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.05 | sMAPE for Test Set is: 27.95% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:13:36,244]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:13:39,271]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:13:42,459]\u001b[0m Trial 1374 finished with value: 8.780299653259169 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022628789195753996, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1798881819295456, 'dropout_rate_Layer_2': 0.1506270593891403, 'dropout_rate_Layer_3': 0.04814171136698638, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4425064244248076e-05, 'l1_Layer_2': 4.4450787164401454e-05, 'l1_Layer_3': 3.9998466012176024e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 125, 'n_units_Layer_3': 220}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.78 | sMAPE for Validation Set is: 41.03% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.36 | sMAPE for Test Set is: 28.23% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:13:45,128]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:13:45,711]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:13:47,707]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:13:53,003]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:13:57,374]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:13:58,172]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:13:59,025]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:13:59,288]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:14:07,928]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:14:11,665]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:14:11,749]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:14:22,586]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:14:31,938]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:14:32,873]\u001b[0m Trial 1388 finished with value: 8.696549965938209 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022942071479237344, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2075012328218908, 'dropout_rate_Layer_2': 0.13780352917006713, 'dropout_rate_Layer_3': 0.058149451641174354, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1146903017748665e-05, 'l1_Layer_2': 7.941334692697213e-05, 'l1_Layer_3': 3.322974316419573e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 135, 'n_units_Layer_3': 245}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.70 | sMAPE for Validation Set is: 39.29% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.62 | sMAPE for Test Set is: 27.52% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:14:39,941]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:14:40,415]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:14:41,207]\u001b[0m Trial 1389 finished with value: 8.517622405766556 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022620132613258665, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20032331902166914, 'dropout_rate_Layer_2': 0.14901653059854195, 'dropout_rate_Layer_3': 0.04010670544180041, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7219184435626716e-05, 'l1_Layer_2': 5.504510852136039e-05, 'l1_Layer_3': 3.709952445546261e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 125, 'n_units_Layer_3': 215}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.52 | sMAPE for Validation Set is: 39.14% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.29 | sMAPE for Test Set is: 27.26% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:14:48,507]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:14:51,338]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:14:52,176]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:14:59,470]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:15:00,300]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:15:05,817]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:15:08,520]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:15:13,022]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:15:16,187]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:15:18,869]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:15:22,238]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:15:27,324]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:15:28,097]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:15:33,649]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:15:43,174]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:15:44,051]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:15:50,915]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:15:54,872]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:15:59,620]\u001b[0m Trial 1402 finished with value: 8.553331961437106 and parameters: {'n_hidden': 3, 'learning_rate': 0.002174520535396416, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20318969419839228, 'dropout_rate_Layer_2': 0.15011186596249043, 'dropout_rate_Layer_3': 0.03292673242375725, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8128712604397754e-05, 'l1_Layer_2': 8.39197033730131e-05, 'l1_Layer_3': 3.212610246185839e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 125, 'n_units_Layer_3': 260}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.55 | sMAPE for Validation Set is: 37.68% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.61 | sMAPE for Test Set is: 28.42% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:16:00,038]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.91 | sMAPE for Validation Set is: 39.77% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.82 | sMAPE for Test Set is: 28.58% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:16:05,097]\u001b[0m Trial 1397 finished with value: 8.912243921043649 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005974372455667273, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06543372924951081, 'dropout_rate_Layer_2': 0.007437787343549645, 'dropout_rate_Layer_3': 0.2360729404374795, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006924478310317376, 'l1_Layer_2': 0.002410281698831946, 'l1_Layer_3': 0.0007555947704470401, 'n_units_Layer_1': 235, 'n_units_Layer_2': 245, 'n_units_Layer_3': 270}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:16:08,670]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:16:09,623]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:16:17,272]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:16:17,385]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.65 | sMAPE for Validation Set is: 39.98% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.41 | sMAPE for Test Set is: 28.44% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:16:21,186]\u001b[0m Trial 1414 finished with value: 8.65208062494096 and parameters: {'n_hidden': 3, 'learning_rate': 0.002124769553100015, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20029261030596102, 'dropout_rate_Layer_2': 0.15052007949809412, 'dropout_rate_Layer_3': 0.05227816760304456, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7224362551431473e-05, 'l1_Layer_2': 0.0001209659838115127, 'l1_Layer_3': 3.839728191444668e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 140, 'n_units_Layer_3': 225}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:16:27,094]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:16:31,474]\u001b[0m Trial 1417 finished with value: 8.628163217055848 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024363156652525805, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21612753365933193, 'dropout_rate_Layer_2': 0.12709199823228154, 'dropout_rate_Layer_3': 0.053436246125860336, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2317780253162784e-05, 'l1_Layer_2': 0.00012064994576561097, 'l1_Layer_3': 6.248094561584607e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 120, 'n_units_Layer_3': 255}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.63 | sMAPE for Validation Set is: 38.43% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.83 | sMAPE for Test Set is: 28.85% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:16:34,141]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:16:36,045]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:16:40,857]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:17:04,418]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:17:04,610]\u001b[0m Trial 1427 finished with value: 8.600273867495146 and parameters: {'n_hidden': 3, 'learning_rate': 0.002007241664234175, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23976069406454686, 'dropout_rate_Layer_2': 0.17874489008648664, 'dropout_rate_Layer_3': 0.021283964267947132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016088249922183327, 'l1_Layer_2': 0.0005117461342089099, 'l1_Layer_3': 0.00047499895923099874, 'n_units_Layer_1': 130, 'n_units_Layer_2': 160, 'n_units_Layer_3': 275}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.60 | sMAPE for Validation Set is: 38.79% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.93 | sMAPE for Test Set is: 26.94% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:17:12,668]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:17:17,286]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:17:22,023]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:17:28,612]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:17:33,199]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:17:35,024]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:17:39,367]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:17:44,478]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:17:47,497]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:17:51,731]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:17:54,012]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:17:59,943]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:04,231]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:05,006]\u001b[0m Trial 1424 finished with value: 9.123743489568044 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006095457157310365, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012040215182983963, 'dropout_rate_Layer_2': 0.0062422094236311895, 'dropout_rate_Layer_3': 0.27714503536649304, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006718284692937316, 'l1_Layer_2': 0.0017905488380060522, 'l1_Layer_3': 0.0007425926696035606, 'n_units_Layer_1': 240, 'n_units_Layer_2': 50, 'n_units_Layer_3': 275}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:05,028]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.12 | sMAPE for Validation Set is: 40.54% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 24.15 | sMAPE for Test Set is: 29.22% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:18:13,818]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:13,988]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:14,527]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:23,640]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:25,244]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:29,240]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:30,512]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:33,786]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:34,649]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:37,259]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:38,129]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:42,741]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:45,973]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:50,579]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:57,123]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:18:57,977]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:19:04,297]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:19:05,758]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:19:10,812]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:19:15,265]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:19:17,968]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:19:20,960]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:19:25,998]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:19:31,496]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:19:35,983]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:19:41,446]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:19:47,970]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:19:53,074]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:19:57,972]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:19:58,622]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:20:04,313]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:20:05,288]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:20:13,195]\u001b[0m Trial 1466 finished with value: 8.556476656164605 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024544406007470628, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1883499820777367, 'dropout_rate_Layer_2': 0.13832579866397432, 'dropout_rate_Layer_3': 0.007756402553350059, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001738571072115247, 'l1_Layer_2': 0.000990131394017549, 'l1_Layer_3': 0.0002088338715118751, 'n_units_Layer_1': 120, 'n_units_Layer_2': 175, 'n_units_Layer_3': 260}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.56 | sMAPE for Validation Set is: 38.47% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.22 | sMAPE for Test Set is: 27.18% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:20:18,619]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:20:19,610]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:20:27,290]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:20:28,604]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:20:33,513]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:20:36,734]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.67 | sMAPE for Validation Set is: 39.44% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.97 | sMAPE for Test Set is: 27.58% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:20:40,396]\u001b[0m Trial 1475 finished with value: 8.671975194896497 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032486522608325486, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23266606582252952, 'dropout_rate_Layer_2': 0.16141292531794796, 'dropout_rate_Layer_3': 0.0640469819548867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.645356875016309e-05, 'l1_Layer_2': 4.959417988430546e-05, 'l1_Layer_3': 4.7391826101702304e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 145, 'n_units_Layer_3': 225}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:20:41,947]\u001b[0m Trial 1457 finished with value: 9.332428457755924 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005453154328927634, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04429796218737773, 'dropout_rate_Layer_2': 0.01737133620136799, 'dropout_rate_Layer_3': 0.2555724600252362, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005023659517897126, 'l1_Layer_2': 0.0031600131124965673, 'l1_Layer_3': 0.00031613578256464497, 'n_units_Layer_1': 235, 'n_units_Layer_2': 260, 'n_units_Layer_3': 220}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.33 | sMAPE for Validation Set is: 43.05% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 23.55 | sMAPE for Test Set is: 28.75% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 05:20:43,415]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:20:43,689]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:20:48,184]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:20:49,628]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:20:54,400]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:20:59,750]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:21:02,217]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:21:08,904]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:21:09,301]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:21:09,556]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:21:17,546]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:21:19,973]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:21:20,901]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:21:22,246]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:21:30,000]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:21:32,712]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:21:32,968]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 05:21:36,968]\u001b[0m Trial 1490 finished with value: 8.640395235427716 and parameters: {'n_hidden': 3, 'learning_rate': 0.002753665553005687, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17141195693383915, 'dropout_rate_Layer_2': 0.12724423361792328, 'dropout_rate_Layer_3': 0.017596421687848626, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014493112568847216, 'l1_Layer_2': 0.0019688102207832004, 'l1_Layer_3': 0.0001867906815336055, 'n_units_Layer_1': 135, 'n_units_Layer_2': 190, 'n_units_Layer_3': 255}. Best is trial 764 with value: 8.481023902385846.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.64 | sMAPE for Validation Set is: 37.85% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.34 | sMAPE for Test Set is: 27.10% | rMAE for Test Set is: 0.62\n",
      "for 2021-01-01, MAE is:7.30 & sMAPE is:15.57% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 15.57% & 0.52\n",
      "for 2021-01-02, MAE is:7.14 & sMAPE is:14.36% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 14.97% & 0.37\n",
      "for 2021-01-03, MAE is:14.81 & sMAPE is:41.14% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :9.75 & 23.69% & 0.45\n",
      "for 2021-01-04, MAE is:10.05 & sMAPE is:23.65% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :9.82 & 23.68% & 0.57\n",
      "for 2021-01-05, MAE is:11.60 & sMAPE is:25.89% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :10.18 & 24.12% & 0.77\n",
      "for 2021-01-06, MAE is:5.89 & sMAPE is:12.59% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :9.46 & 22.20% & 0.79\n",
      "for 2021-01-07, MAE is:27.69 & sMAPE is:49.16% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :12.07 & 26.05% & 0.83\n",
      "for 2021-01-08, MAE is:22.36 & sMAPE is:29.58% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :13.36 & 26.49% & 0.83\n",
      "for 2021-01-09, MAE is:5.42 & sMAPE is:9.53% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :12.47 & 24.61% & 0.81\n",
      "for 2021-01-10, MAE is:4.10 & sMAPE is:8.65% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :11.64 & 23.01% & 0.76\n",
      "for 2021-01-11, MAE is:9.34 & sMAPE is:20.66% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :11.43 & 22.80% & 0.76\n",
      "for 2021-01-12, MAE is:10.23 & sMAPE is:24.56% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :11.33 & 22.95% & 0.87\n",
      "for 2021-01-13, MAE is:4.55 & sMAPE is:11.14% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :10.81 & 22.04% & 0.86\n",
      "for 2021-01-14, MAE is:25.71 & sMAPE is:39.53% & rMAE is:5.19 ||| daily mean of MAE & sMAPE & rMAE till now are :11.87 & 23.29% & 1.17\n",
      "for 2021-01-15, MAE is:14.16 & sMAPE is:18.85% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :12.02 & 22.99% & 1.22\n",
      "for 2021-01-16, MAE is:3.35 & sMAPE is:5.89% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :11.48 & 21.92% & 1.19\n",
      "for 2021-01-17, MAE is:6.49 & sMAPE is:12.31% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 21.36% & 1.16\n",
      "for 2021-01-18, MAE is:6.19 & sMAPE is:11.24% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :10.91 & 20.79% & 1.12\n",
      "for 2021-01-19, MAE is:2.71 & sMAPE is:5.88% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :10.48 & 20.01% & 1.08\n",
      "for 2021-01-20, MAE is:4.56 & sMAPE is:11.83% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :10.18 & 19.60% & 1.07\n",
      "for 2021-01-21, MAE is:10.05 & sMAPE is:26.74% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :10.18 & 19.94% & 1.03\n",
      "for 2021-01-22, MAE is:9.19 & sMAPE is:29.40% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :10.13 & 20.37% & 0.99\n",
      "for 2021-01-23, MAE is:22.89 & sMAPE is:58.72% & rMAE is:3.04 ||| daily mean of MAE & sMAPE & rMAE till now are :10.69 & 22.04% & 1.08\n",
      "for 2021-01-24, MAE is:7.60 & sMAPE is:15.87% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :10.56 & 21.78% & 1.11\n",
      "for 2021-01-25, MAE is:8.46 & sMAPE is:14.60% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :10.47 & 21.49% & 1.11\n",
      "for 2021-01-26, MAE is:13.05 & sMAPE is:23.69% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :10.57 & 21.58% & 1.10\n",
      "for 2021-01-27, MAE is:6.07 & sMAPE is:10.77% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.41 & 21.18% & 1.07\n",
      "for 2021-01-28, MAE is:5.77 & sMAPE is:9.88% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :10.24 & 20.77% & 1.04\n",
      "for 2021-01-29, MAE is:7.92 & sMAPE is:14.30% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :10.16 & 20.55% & 1.02\n",
      "for 2021-01-30, MAE is:8.35 & sMAPE is:17.95% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :10.10 & 20.46% & 1.04\n",
      "for 2021-01-31, MAE is:10.56 & sMAPE is:24.23% & rMAE is:6.66 ||| daily mean of MAE & sMAPE & rMAE till now are :10.11 & 20.59% & 1.22\n",
      "for 2021-02-01, MAE is:38.04 & sMAPE is:42.44% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :10.99 & 21.27% & 1.23\n",
      "for 2021-02-02, MAE is:17.19 & sMAPE is:23.61% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :11.17 & 21.34% & 1.23\n",
      "for 2021-02-03, MAE is:10.43 & sMAPE is:18.95% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :11.15 & 21.27% & 1.23\n",
      "for 2021-02-04, MAE is:14.21 & sMAPE is:24.30% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 21.36% & 1.25\n",
      "for 2021-02-05, MAE is:29.15 & sMAPE is:30.66% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :11.74 & 21.61% & 1.25\n",
      "for 2021-02-06, MAE is:6.87 & sMAPE is:15.14% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :11.61 & 21.44% & 1.26\n",
      "for 2021-02-07, MAE is:7.28 & sMAPE is:16.39% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :11.49 & 21.31% & 1.26\n",
      "for 2021-02-08, MAE is:4.58 & sMAPE is:7.76% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :11.32 & 20.96% & 1.23\n",
      "for 2021-02-09, MAE is:14.07 & sMAPE is:20.30% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :11.38 & 20.94% & 1.22\n",
      "for 2021-02-10, MAE is:10.04 & sMAPE is:13.13% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :11.35 & 20.75% & 1.21\n",
      "for 2021-02-11, MAE is:31.34 & sMAPE is:27.12% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :11.83 & 20.90% & 1.20\n",
      "for 2021-02-12, MAE is:26.68 & sMAPE is:28.24% & rMAE is:2.60 ||| daily mean of MAE & sMAPE & rMAE till now are :12.17 & 21.07% & 1.23\n",
      "for 2021-02-13, MAE is:13.20 & sMAPE is:27.33% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :12.20 & 21.22% & 1.24\n",
      "for 2021-02-14, MAE is:4.12 & sMAPE is:8.34% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :12.02 & 20.93% & 1.23\n",
      "for 2021-02-15, MAE is:14.35 & sMAPE is:17.53% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :12.07 & 20.86% & 1.23\n",
      "for 2021-02-16, MAE is:11.09 & sMAPE is:17.76% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :12.05 & 20.79% & 1.23\n",
      "for 2021-02-17, MAE is:5.69 & sMAPE is:10.71% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :11.91 & 20.58% & 1.21\n",
      "for 2021-02-18, MAE is:14.32 & sMAPE is:26.44% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :11.96 & 20.70% & 1.19\n",
      "for 2021-02-19, MAE is:5.27 & sMAPE is:10.24% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :11.83 & 20.49% & 1.17\n",
      "for 2021-02-20, MAE is:2.95 & sMAPE is:7.78% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :11.65 & 20.24% & 1.15\n",
      "for 2021-02-21, MAE is:6.00 & sMAPE is:15.06% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :11.55 & 20.14% & 1.14\n",
      "for 2021-02-22, MAE is:6.04 & sMAPE is:11.92% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :11.44 & 19.99% & 1.13\n",
      "for 2021-02-23, MAE is:4.48 & sMAPE is:9.79% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :11.31 & 19.80% & 1.11\n",
      "for 2021-02-24, MAE is:6.85 & sMAPE is:18.64% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :11.23 & 19.78% & 1.10\n",
      "for 2021-02-25, MAE is:2.39 & sMAPE is:7.08% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :11.07 & 19.55% & 1.08\n",
      "for 2021-02-26, MAE is:7.24 & sMAPE is:20.91% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :11.01 & 19.57% & 1.07\n",
      "for 2021-02-27, MAE is:13.97 & sMAPE is:35.70% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :11.06 & 19.85% & 1.08\n",
      "for 2021-02-28, MAE is:5.36 & sMAPE is:12.91% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :10.96 & 19.73% & 1.08\n",
      "for 2021-03-01, MAE is:6.34 & sMAPE is:13.02% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.88 & 19.62% & 1.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-03-02, MAE is:10.82 & sMAPE is:21.68% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :10.88 & 19.66% & 1.09\n",
      "for 2021-03-03, MAE is:5.05 & sMAPE is:9.36% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :10.79 & 19.49% & 1.07\n",
      "for 2021-03-04, MAE is:14.33 & sMAPE is:30.69% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :10.85 & 19.67% & 1.07\n",
      "for 2021-03-05, MAE is:8.03 & sMAPE is:15.55% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.80 & 19.60% & 1.06\n",
      "for 2021-03-06, MAE is:10.11 & sMAPE is:30.00% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :10.79 & 19.76% & 1.05\n",
      "for 2021-03-07, MAE is:12.41 & sMAPE is:35.36% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :10.82 & 20.00% & 1.06\n",
      "for 2021-03-08, MAE is:14.44 & sMAPE is:24.90% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :10.87 & 20.07% & 1.06\n",
      "for 2021-03-09, MAE is:7.87 & sMAPE is:12.24% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :10.83 & 19.96% & 1.06\n",
      "for 2021-03-10, MAE is:13.38 & sMAPE is:20.96% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :10.86 & 19.97% & 1.06\n",
      "for 2021-03-11, MAE is:4.77 & sMAPE is:17.16% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :10.78 & 19.93% & 1.05\n",
      "for 2021-03-12, MAE is:6.53 & sMAPE is:24.13% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.72 & 19.99% & 1.03\n",
      "for 2021-03-13, MAE is:3.69 & sMAPE is:12.14% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :10.62 & 19.88% & 1.03\n",
      "for 2021-03-14, MAE is:5.92 & sMAPE is:18.01% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :10.55 & 19.86% & 1.02\n",
      "for 2021-03-15, MAE is:7.11 & sMAPE is:15.44% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :10.51 & 19.80% & 1.01\n",
      "for 2021-03-16, MAE is:6.25 & sMAPE is:11.30% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 19.68% & 1.01\n",
      "for 2021-03-17, MAE is:6.63 & sMAPE is:11.12% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :10.40 & 19.57% & 1.01\n",
      "for 2021-03-18, MAE is:11.08 & sMAPE is:17.32% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :10.41 & 19.54% & 1.00\n",
      "for 2021-03-19, MAE is:9.05 & sMAPE is:16.39% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.39 & 19.50% & 0.99\n",
      "for 2021-03-20, MAE is:7.94 & sMAPE is:21.09% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 19.52% & 0.98\n",
      "for 2021-03-21, MAE is:11.19 & sMAPE is:35.98% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :10.37 & 19.73% & 0.98\n",
      "for 2021-03-22, MAE is:13.72 & sMAPE is:27.23% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.41 & 19.82% & 0.99\n",
      "for 2021-03-23, MAE is:14.49 & sMAPE is:27.34% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 19.91% & 1.00\n",
      "for 2021-03-24, MAE is:11.62 & sMAPE is:22.74% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :10.48 & 19.95% & 1.01\n",
      "for 2021-03-25, MAE is:6.27 & sMAPE is:10.59% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 19.83% & 1.01\n",
      "for 2021-03-26, MAE is:8.64 & sMAPE is:18.57% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :10.40 & 19.82% & 1.01\n",
      "for 2021-03-27, MAE is:10.12 & sMAPE is:35.27% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :10.40 & 20.00% & 1.00\n",
      "for 2021-03-28, MAE is:8.92 & sMAPE is:36.36% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :10.38 & 20.19% & 1.00\n",
      "for 2021-03-29, MAE is:7.22 & sMAPE is:30.18% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 20.30% & 0.99\n",
      "for 2021-03-30, MAE is:11.67 & sMAPE is:30.96% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 20.42% & 0.98\n",
      "for 2021-03-31, MAE is:9.89 & sMAPE is:17.37% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :10.36 & 20.39% & 0.99\n",
      "for 2021-04-01, MAE is:6.38 & sMAPE is:13.38% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :10.31 & 20.31% & 0.98\n",
      "for 2021-04-02, MAE is:13.36 & sMAPE is:41.49% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 20.54% & 0.98\n",
      "for 2021-04-03, MAE is:10.49 & sMAPE is:32.36% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 20.67% & 0.98\n",
      "for 2021-04-04, MAE is:22.32 & sMAPE is:88.21% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :10.48 & 21.39% & 0.99\n",
      "for 2021-04-05, MAE is:10.67 & sMAPE is:148.33% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :10.48 & 22.72% & 0.98\n",
      "for 2021-04-06, MAE is:12.03 & sMAPE is:68.37% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :10.49 & 23.20% & 0.98\n",
      "for 2021-04-07, MAE is:12.07 & sMAPE is:31.46% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :10.51 & 23.28% & 0.98\n",
      "for 2021-04-08, MAE is:12.20 & sMAPE is:26.05% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :10.53 & 23.31% & 0.98\n",
      "for 2021-04-09, MAE is:4.12 & sMAPE is:16.40% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 23.24% & 0.97\n",
      "for 2021-04-10, MAE is:22.67 & sMAPE is:52.61% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.59 & 23.53% & 0.97\n",
      "for 2021-04-11, MAE is:9.25 & sMAPE is:20.48% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.57 & 23.50% & 0.97\n",
      "for 2021-04-12, MAE is:10.29 & sMAPE is:26.21% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :10.57 & 23.53% & 0.96\n",
      "for 2021-04-13, MAE is:11.99 & sMAPE is:25.84% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :10.58 & 23.55% & 0.96\n",
      "for 2021-04-14, MAE is:22.33 & sMAPE is:36.59% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :10.70 & 23.68% & 0.96\n",
      "for 2021-04-15, MAE is:10.35 & sMAPE is:15.32% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :10.69 & 23.60% & 0.95\n",
      "for 2021-04-16, MAE is:14.80 & sMAPE is:30.34% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :10.73 & 23.66% & 0.95\n",
      "for 2021-04-17, MAE is:19.14 & sMAPE is:38.69% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :10.81 & 23.80% & 0.96\n",
      "for 2021-04-18, MAE is:6.76 & sMAPE is:11.78% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :10.77 & 23.69% & 0.96\n",
      "for 2021-04-19, MAE is:16.96 & sMAPE is:25.00% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :10.83 & 23.70% & 0.95\n",
      "for 2021-04-20, MAE is:19.26 & sMAPE is:28.30% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :10.91 & 23.75% & 0.95\n",
      "for 2021-04-21, MAE is:18.75 & sMAPE is:32.04% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :10.98 & 23.82% & 0.95\n",
      "for 2021-04-22, MAE is:14.56 & sMAPE is:51.10% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :11.01 & 24.06% & 0.95\n",
      "for 2021-04-23, MAE is:15.05 & sMAPE is:40.50% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :11.04 & 24.21% & 0.95\n",
      "for 2021-04-24, MAE is:12.03 & sMAPE is:27.69% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :11.05 & 24.24% & 0.95\n",
      "for 2021-04-25, MAE is:17.16 & sMAPE is:57.77% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 24.53% & 0.95\n",
      "for 2021-04-26, MAE is:7.99 & sMAPE is:13.83% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :11.08 & 24.44% & 0.95\n",
      "for 2021-04-27, MAE is:6.66 & sMAPE is:10.78% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :11.04 & 24.32% & 0.94\n",
      "for 2021-04-28, MAE is:9.97 & sMAPE is:17.40% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :11.03 & 24.26% & 0.94\n",
      "for 2021-04-29, MAE is:6.06 & sMAPE is:11.29% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.99 & 24.15% & 0.94\n",
      "for 2021-04-30, MAE is:26.73 & sMAPE is:51.40% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :11.12 & 24.38% & 0.94\n",
      "for 2021-05-01, MAE is:4.06 & sMAPE is:7.12% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :11.06 & 24.24% & 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-05-02, MAE is:8.80 & sMAPE is:18.97% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :11.05 & 24.20% & 0.94\n",
      "for 2021-05-03, MAE is:12.11 & sMAPE is:21.21% & rMAE is:3.85 ||| daily mean of MAE & sMAPE & rMAE till now are :11.05 & 24.17% & 0.96\n",
      "for 2021-05-04, MAE is:10.60 & sMAPE is:23.48% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :11.05 & 24.17% & 0.96\n",
      "for 2021-05-05, MAE is:6.22 & sMAPE is:16.42% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :11.01 & 24.10% & 0.95\n",
      "for 2021-05-06, MAE is:18.01 & sMAPE is:34.67% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :11.07 & 24.19% & 0.95\n",
      "for 2021-05-07, MAE is:7.08 & sMAPE is:10.42% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :11.04 & 24.08% & 0.95\n",
      "for 2021-05-08, MAE is:7.96 & sMAPE is:17.82% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :11.01 & 24.03% & 0.95\n",
      "for 2021-05-09, MAE is:15.82 & sMAPE is:76.75% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :11.05 & 24.44% & 0.95\n",
      "for 2021-05-10, MAE is:24.21 & sMAPE is:56.72% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :11.15 & 24.69% & 0.95\n",
      "for 2021-05-11, MAE is:7.81 & sMAPE is:11.18% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :11.12 & 24.58% & 0.95\n",
      "for 2021-05-12, MAE is:5.34 & sMAPE is:7.92% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :11.08 & 24.46% & 0.94\n",
      "for 2021-05-13, MAE is:5.17 & sMAPE is:8.33% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :11.04 & 24.34% & 0.94\n",
      "for 2021-05-14, MAE is:7.23 & sMAPE is:10.42% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :11.01 & 24.23% & 0.94\n",
      "for 2021-05-15, MAE is:13.50 & sMAPE is:27.68% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :11.03 & 24.26% & 0.94\n",
      "for 2021-05-16, MAE is:18.16 & sMAPE is:44.73% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :11.08 & 24.41% & 0.94\n",
      "for 2021-05-17, MAE is:14.13 & sMAPE is:21.37% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :11.10 & 24.39% & 0.94\n",
      "for 2021-05-18, MAE is:8.15 & sMAPE is:11.28% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :11.08 & 24.29% & 0.95\n",
      "for 2021-05-19, MAE is:8.46 & sMAPE is:10.98% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :11.06 & 24.20% & 0.95\n",
      "for 2021-05-20, MAE is:9.70 & sMAPE is:15.28% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :11.05 & 24.13% & 0.95\n",
      "for 2021-05-21, MAE is:22.77 & sMAPE is:62.73% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 24.41% & 0.95\n",
      "for 2021-05-22, MAE is:14.96 & sMAPE is:89.78% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 24.87% & 0.95\n",
      "for 2021-05-23, MAE is:15.69 & sMAPE is:68.59% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 25.17% & 0.95\n",
      "for 2021-05-24, MAE is:9.70 & sMAPE is:26.21% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :11.18 & 25.18% & 0.94\n",
      "for 2021-05-25, MAE is:12.42 & sMAPE is:23.88% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 25.17% & 0.94\n",
      "for 2021-05-26, MAE is:6.91 & sMAPE is:11.33% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 25.08% & 0.94\n",
      "for 2021-05-27, MAE is:16.68 & sMAPE is:26.14% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :11.20 & 25.08% & 0.94\n",
      "for 2021-05-28, MAE is:9.87 & sMAPE is:14.12% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 25.01% & 0.94\n",
      "for 2021-05-29, MAE is:9.38 & sMAPE is:18.56% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :11.18 & 24.97% & 0.93\n",
      "for 2021-05-30, MAE is:12.28 & sMAPE is:33.33% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 25.02% & 0.93\n",
      "for 2021-05-31, MAE is:20.17 & sMAPE is:35.50% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :11.25 & 25.09% & 0.93\n",
      "for 2021-06-01, MAE is:6.18 & sMAPE is:8.95% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :11.21 & 24.98% & 0.93\n",
      "for 2021-06-02, MAE is:8.25 & sMAPE is:12.78% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 24.90% & 0.93\n",
      "for 2021-06-03, MAE is:5.47 & sMAPE is:9.13% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 24.80% & 0.93\n",
      "for 2021-06-04, MAE is:17.14 & sMAPE is:28.02% & rMAE is:2.88 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 24.82% & 0.94\n",
      "for 2021-06-05, MAE is:4.65 & sMAPE is:7.42% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :11.15 & 24.71% & 0.94\n",
      "for 2021-06-06, MAE is:4.77 & sMAPE is:7.97% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 24.61% & 0.93\n",
      "for 2021-06-07, MAE is:13.76 & sMAPE is:19.62% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 24.57% & 0.93\n",
      "for 2021-06-08, MAE is:10.42 & sMAPE is:13.65% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :11.12 & 24.50% & 0.94\n",
      "for 2021-06-09, MAE is:9.25 & sMAPE is:12.59% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 24.43% & 0.94\n",
      "for 2021-06-10, MAE is:13.86 & sMAPE is:18.86% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :11.13 & 24.40% & 0.93\n",
      "for 2021-06-11, MAE is:7.32 & sMAPE is:9.63% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 24.30% & 0.93\n",
      "for 2021-06-12, MAE is:25.14 & sMAPE is:65.82% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 24.56% & 0.93\n",
      "for 2021-06-13, MAE is:19.64 & sMAPE is:109.45% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 25.08% & 0.93\n",
      "for 2021-06-14, MAE is:19.65 & sMAPE is:30.00% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :11.29 & 25.11% & 0.94\n",
      "for 2021-06-15, MAE is:15.20 & sMAPE is:20.38% & rMAE is:2.72 ||| daily mean of MAE & sMAPE & rMAE till now are :11.32 & 25.08% & 0.95\n",
      "for 2021-06-16, MAE is:11.62 & sMAPE is:13.80% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :11.32 & 25.01% & 0.95\n",
      "for 2021-06-17, MAE is:11.93 & sMAPE is:16.49% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :11.32 & 24.96% & 0.95\n",
      "for 2021-06-18, MAE is:20.63 & sMAPE is:30.40% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :11.38 & 24.99% & 0.96\n",
      "for 2021-06-19, MAE is:11.59 & sMAPE is:17.37% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :11.38 & 24.95% & 0.96\n",
      "for 2021-06-20, MAE is:11.19 & sMAPE is:21.05% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :11.38 & 24.92% & 0.95\n",
      "for 2021-06-21, MAE is:10.65 & sMAPE is:14.68% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :11.37 & 24.87% & 0.96\n",
      "for 2021-06-22, MAE is:12.57 & sMAPE is:15.89% & rMAE is:3.06 ||| daily mean of MAE & sMAPE & rMAE till now are :11.38 & 24.81% & 0.97\n",
      "for 2021-06-23, MAE is:14.63 & sMAPE is:15.82% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :11.40 & 24.76% & 0.97\n",
      "for 2021-06-24, MAE is:17.35 & sMAPE is:20.24% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :11.43 & 24.74% & 0.97\n",
      "for 2021-06-25, MAE is:6.75 & sMAPE is:7.76% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :11.41 & 24.64% & 0.97\n",
      "for 2021-06-26, MAE is:6.57 & sMAPE is:8.27% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :11.38 & 24.55% & 0.97\n",
      "for 2021-06-27, MAE is:11.75 & sMAPE is:19.71% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :11.38 & 24.52% & 0.97\n",
      "for 2021-06-28, MAE is:15.22 & sMAPE is:18.35% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :11.40 & 24.49% & 0.97\n",
      "for 2021-06-29, MAE is:13.95 & sMAPE is:16.07% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :11.42 & 24.44% & 0.98\n",
      "for 2021-06-30, MAE is:9.50 & sMAPE is:11.02% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :11.41 & 24.36% & 0.98\n",
      "for 2021-07-01, MAE is:8.57 & sMAPE is:10.01% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :11.39 & 24.29% & 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-07-02, MAE is:11.78 & sMAPE is:12.95% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :11.39 & 24.22% & 0.98\n",
      "for 2021-07-03, MAE is:9.25 & sMAPE is:10.85% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :11.38 & 24.15% & 0.99\n",
      "for 2021-07-04, MAE is:6.34 & sMAPE is:7.40% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :11.35 & 24.06% & 0.98\n",
      "for 2021-07-05, MAE is:8.95 & sMAPE is:9.52% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :11.34 & 23.98% & 0.99\n",
      "for 2021-07-06, MAE is:10.71 & sMAPE is:13.41% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :11.34 & 23.93% & 0.98\n",
      "for 2021-07-07, MAE is:24.40 & sMAPE is:27.19% & rMAE is:2.99 ||| daily mean of MAE & sMAPE & rMAE till now are :11.41 & 23.94% & 0.99\n",
      "for 2021-07-08, MAE is:17.91 & sMAPE is:16.67% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :11.44 & 23.90% & 0.99\n",
      "for 2021-07-09, MAE is:4.32 & sMAPE is:4.74% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :11.40 & 23.80% & 0.99\n",
      "for 2021-07-10, MAE is:7.73 & sMAPE is:9.61% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :11.39 & 23.73% & 1.00\n",
      "for 2021-07-11, MAE is:9.44 & sMAPE is:11.91% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :11.38 & 23.67% & 1.00\n",
      "for 2021-07-12, MAE is:10.94 & sMAPE is:11.95% & rMAE is:3.48 ||| daily mean of MAE & sMAPE & rMAE till now are :11.37 & 23.61% & 1.02\n",
      "for 2021-07-13, MAE is:9.02 & sMAPE is:10.07% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :11.36 & 23.54% & 1.01\n",
      "for 2021-07-14, MAE is:7.12 & sMAPE is:8.17% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :11.34 & 23.46% & 1.01\n",
      "for 2021-07-15, MAE is:17.49 & sMAPE is:20.72% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :11.37 & 23.44% & 1.01\n",
      "for 2021-07-16, MAE is:5.83 & sMAPE is:7.00% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :11.34 & 23.36% & 1.01\n",
      "for 2021-07-17, MAE is:12.87 & sMAPE is:22.81% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :11.35 & 23.36% & 1.01\n",
      "for 2021-07-18, MAE is:17.49 & sMAPE is:55.90% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :11.38 & 23.52% & 1.01\n",
      "for 2021-07-19, MAE is:20.06 & sMAPE is:25.04% & rMAE is:3.21 ||| daily mean of MAE & sMAPE & rMAE till now are :11.42 & 23.53% & 1.02\n",
      "for 2021-07-20, MAE is:10.80 & sMAPE is:12.04% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :11.42 & 23.47% & 1.02\n",
      "for 2021-07-21, MAE is:10.61 & sMAPE is:12.02% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :11.42 & 23.42% & 1.02\n",
      "for 2021-07-22, MAE is:6.78 & sMAPE is:7.74% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :11.39 & 23.34% & 1.02\n",
      "for 2021-07-23, MAE is:14.17 & sMAPE is:16.95% & rMAE is:3.56 ||| daily mean of MAE & sMAPE & rMAE till now are :11.41 & 23.31% & 1.03\n",
      "for 2021-07-24, MAE is:6.47 & sMAPE is:8.85% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :11.38 & 23.24% & 1.03\n",
      "for 2021-07-25, MAE is:8.58 & sMAPE is:12.88% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :11.37 & 23.19% & 1.02\n",
      "for 2021-07-26, MAE is:12.49 & sMAPE is:15.40% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :11.38 & 23.15% & 1.03\n",
      "for 2021-07-27, MAE is:9.32 & sMAPE is:10.93% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :11.37 & 23.09% & 1.03\n",
      "for 2021-07-28, MAE is:11.24 & sMAPE is:14.39% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :11.36 & 23.05% & 1.03\n",
      "for 2021-07-29, MAE is:23.13 & sMAPE is:66.63% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :11.42 & 23.26% & 1.03\n",
      "for 2021-07-30, MAE is:11.25 & sMAPE is:18.55% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :11.42 & 23.23% & 1.03\n",
      "for 2021-07-31, MAE is:18.64 & sMAPE is:34.89% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :11.45 & 23.29% & 1.03\n",
      "for 2021-08-01, MAE is:6.65 & sMAPE is:12.05% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :11.43 & 23.24% & 1.03\n",
      "for 2021-08-02, MAE is:15.51 & sMAPE is:19.89% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :11.45 & 23.22% & 1.03\n",
      "for 2021-08-03, MAE is:14.06 & sMAPE is:15.25% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :11.46 & 23.18% & 1.03\n",
      "for 2021-08-04, MAE is:15.26 & sMAPE is:16.25% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :11.48 & 23.15% & 1.03\n",
      "for 2021-08-05, MAE is:18.06 & sMAPE is:20.40% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :11.51 & 23.14% & 1.02\n",
      "for 2021-08-06, MAE is:6.60 & sMAPE is:9.48% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :11.49 & 23.08% & 1.02\n",
      "for 2021-08-07, MAE is:6.09 & sMAPE is:10.10% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :11.46 & 23.02% & 1.02\n",
      "for 2021-08-08, MAE is:28.60 & sMAPE is:96.38% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :11.54 & 23.35% & 1.02\n",
      "for 2021-08-09, MAE is:13.06 & sMAPE is:19.00% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :11.55 & 23.33% & 1.02\n",
      "for 2021-08-10, MAE is:13.44 & sMAPE is:14.90% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :11.56 & 23.29% & 1.02\n",
      "for 2021-08-11, MAE is:15.17 & sMAPE is:15.33% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :11.57 & 23.26% & 1.02\n",
      "for 2021-08-12, MAE is:13.70 & sMAPE is:12.86% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :11.58 & 23.21% & 1.02\n",
      "for 2021-08-13, MAE is:10.80 & sMAPE is:11.19% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :11.58 & 23.16% & 1.02\n",
      "for 2021-08-14, MAE is:8.71 & sMAPE is:13.19% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :11.57 & 23.11% & 1.02\n",
      "for 2021-08-15, MAE is:9.25 & sMAPE is:13.92% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :11.56 & 23.07% & 1.02\n",
      "for 2021-08-16, MAE is:13.05 & sMAPE is:16.82% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :11.56 & 23.04% & 1.02\n",
      "for 2021-08-17, MAE is:7.97 & sMAPE is:12.29% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :11.55 & 23.00% & 1.01\n",
      "for 2021-08-18, MAE is:6.47 & sMAPE is:8.72% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :11.53 & 22.94% & 1.01\n",
      "for 2021-08-19, MAE is:18.07 & sMAPE is:20.36% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :11.55 & 22.92% & 1.01\n",
      "for 2021-08-20, MAE is:11.42 & sMAPE is:11.43% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :11.55 & 22.87% & 1.01\n",
      "for 2021-08-21, MAE is:7.34 & sMAPE is:7.88% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :11.53 & 22.81% & 1.01\n",
      "for 2021-08-22, MAE is:8.80 & sMAPE is:10.87% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :11.52 & 22.76% & 1.01\n",
      "for 2021-08-23, MAE is:11.16 & sMAPE is:12.35% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :11.52 & 22.72% & 1.01\n",
      "for 2021-08-24, MAE is:24.34 & sMAPE is:26.00% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :11.58 & 22.73% & 1.00\n",
      "for 2021-08-25, MAE is:10.06 & sMAPE is:11.73% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :11.57 & 22.68% & 1.01\n",
      "for 2021-08-26, MAE is:14.08 & sMAPE is:15.87% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :11.58 & 22.65% & 1.01\n",
      "for 2021-08-27, MAE is:13.68 & sMAPE is:15.40% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :11.59 & 22.62% & 1.01\n",
      "for 2021-08-28, MAE is:5.75 & sMAPE is:6.98% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :11.56 & 22.56% & 1.01\n",
      "for 2021-08-29, MAE is:5.99 & sMAPE is:7.28% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :11.54 & 22.49% & 1.01\n",
      "for 2021-08-30, MAE is:20.82 & sMAPE is:20.73% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :11.58 & 22.49% & 1.01\n",
      "for 2021-08-31, MAE is:14.21 & sMAPE is:13.61% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :11.59 & 22.45% & 1.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-09-01, MAE is:17.13 & sMAPE is:15.80% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :11.61 & 22.42% & 1.01\n",
      "for 2021-09-02, MAE is:16.23 & sMAPE is:14.05% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :11.63 & 22.39% & 1.01\n",
      "for 2021-09-03, MAE is:17.36 & sMAPE is:16.40% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :11.66 & 22.37% & 1.01\n",
      "for 2021-09-04, MAE is:11.84 & sMAPE is:10.76% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :11.66 & 22.32% & 1.01\n",
      "for 2021-09-05, MAE is:15.86 & sMAPE is:16.36% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :11.67 & 22.29% & 1.01\n",
      "for 2021-09-06, MAE is:24.61 & sMAPE is:19.92% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :11.72 & 22.28% & 1.01\n",
      "for 2021-09-07, MAE is:15.92 & sMAPE is:12.63% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :11.74 & 22.25% & 1.01\n",
      "for 2021-09-08, MAE is:18.91 & sMAPE is:16.03% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :11.77 & 22.22% & 1.01\n",
      "for 2021-09-09, MAE is:20.75 & sMAPE is:16.54% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :11.81 & 22.20% & 1.01\n",
      "for 2021-09-10, MAE is:18.63 & sMAPE is:14.21% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :11.83 & 22.17% & 1.01\n",
      "for 2021-09-11, MAE is:11.60 & sMAPE is:8.98% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :11.83 & 22.12% & 1.01\n",
      "for 2021-09-12, MAE is:13.69 & sMAPE is:12.78% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :11.84 & 22.08% & 1.01\n",
      "for 2021-09-13, MAE is:26.29 & sMAPE is:19.79% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :11.90 & 22.07% & 1.02\n",
      "for 2021-09-14, MAE is:16.66 & sMAPE is:11.49% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :11.91 & 22.03% & 1.02\n",
      "for 2021-09-15, MAE is:44.71 & sMAPE is:30.08% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :12.04 & 22.06% & 1.02\n",
      "for 2021-09-16, MAE is:16.72 & sMAPE is:10.54% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :12.06 & 22.02% & 1.01\n",
      "for 2021-09-17, MAE is:23.47 & sMAPE is:17.40% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :12.10 & 22.00% & 1.01\n",
      "for 2021-09-18, MAE is:23.62 & sMAPE is:19.85% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :12.15 & 21.99% & 1.02\n",
      "for 2021-09-19, MAE is:20.90 & sMAPE is:20.34% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :12.18 & 21.98% & 1.02\n",
      "for 2021-09-20, MAE is:40.93 & sMAPE is:30.82% & rMAE is:3.07 ||| daily mean of MAE & sMAPE & rMAE till now are :12.29 & 22.02% & 1.02\n",
      "for 2021-09-21, MAE is:14.87 & sMAPE is:9.96% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :12.30 & 21.97% & 1.03\n",
      "for 2021-09-22, MAE is:20.91 & sMAPE is:14.92% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :12.33 & 21.94% & 1.02\n",
      "for 2021-09-23, MAE is:50.06 & sMAPE is:56.01% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :12.47 & 22.07% & 1.02\n",
      "for 2021-09-24, MAE is:18.87 & sMAPE is:25.46% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :12.50 & 22.09% & 1.02\n",
      "for 2021-09-25, MAE is:41.43 & sMAPE is:37.73% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :12.61 & 22.14% & 1.02\n",
      "for 2021-09-26, MAE is:23.31 & sMAPE is:18.30% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :12.65 & 22.13% & 1.02\n",
      "for 2021-09-27, MAE is:28.27 & sMAPE is:21.64% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :12.70 & 22.13% & 1.02\n",
      "for 2021-09-28, MAE is:39.67 & sMAPE is:27.20% & rMAE is:2.52 ||| daily mean of MAE & sMAPE & rMAE till now are :12.80 & 22.15% & 1.03\n",
      "for 2021-09-29, MAE is:28.74 & sMAPE is:23.10% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :12.86 & 22.15% & 1.03\n",
      "for 2021-09-30, MAE is:20.36 & sMAPE is:22.29% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :12.89 & 22.15% & 1.03\n",
      "for 2021-10-01, MAE is:12.34 & sMAPE is:24.14% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :12.89 & 22.16% & 1.03\n",
      "for 2021-10-02, MAE is:48.38 & sMAPE is:64.16% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :13.02 & 22.31% & 1.03\n",
      "for 2021-10-03, MAE is:35.36 & sMAPE is:142.64% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :13.10 & 22.75% & 1.02\n",
      "for 2021-10-04, MAE is:91.45 & sMAPE is:83.85% & rMAE is:2.37 ||| daily mean of MAE & sMAPE & rMAE till now are :13.38 & 22.97% & 1.03\n",
      "for 2021-10-05, MAE is:38.03 & sMAPE is:24.24% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :13.47 & 22.97% & 1.03\n",
      "for 2021-10-06, MAE is:74.35 & sMAPE is:45.70% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :13.69 & 23.05% & 1.03\n",
      "for 2021-10-07, MAE is:124.60 & sMAPE is:51.56% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :14.08 & 23.15% & 1.03\n",
      "for 2021-10-08, MAE is:49.98 & sMAPE is:23.26% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :14.21 & 23.16% & 1.03\n",
      "for 2021-10-09, MAE is:33.48 & sMAPE is:24.23% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :14.28 & 23.16% & 1.03\n",
      "for 2021-10-10, MAE is:41.62 & sMAPE is:33.30% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :14.38 & 23.19% & 1.02\n",
      "for 2021-10-11, MAE is:25.04 & sMAPE is:24.51% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :14.41 & 23.20% & 1.02\n",
      "for 2021-10-12, MAE is:64.44 & sMAPE is:54.29% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :14.59 & 23.31% & 1.02\n",
      "for 2021-10-13, MAE is:28.26 & sMAPE is:16.31% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :14.64 & 23.28% & 1.02\n",
      "for 2021-10-14, MAE is:77.42 & sMAPE is:64.14% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :14.86 & 23.43% & 1.02\n",
      "for 2021-10-15, MAE is:29.10 & sMAPE is:87.48% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :14.91 & 23.65% & 1.02\n",
      "for 2021-10-16, MAE is:17.70 & sMAPE is:82.39% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :14.91 & 23.85% & 1.01\n",
      "for 2021-10-17, MAE is:78.35 & sMAPE is:93.87% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :15.13 & 24.09% & 1.02\n",
      "for 2021-10-18, MAE is:51.23 & sMAPE is:30.39% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :15.26 & 24.12% & 1.01\n",
      "for 2021-10-19, MAE is:33.39 & sMAPE is:25.71% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :15.32 & 24.12% & 1.01\n",
      "for 2021-10-20, MAE is:50.94 & sMAPE is:99.44% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :15.44 & 24.38% & 1.01\n",
      "for 2021-10-21, MAE is:20.67 & sMAPE is:46.60% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :15.46 & 24.45% & 1.01\n",
      "for 2021-10-22, MAE is:18.21 & sMAPE is:63.33% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :15.47 & 24.58% & 1.01\n",
      "for 2021-10-23, MAE is:81.25 & sMAPE is:128.65% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :15.69 & 24.94% & 1.01\n",
      "for 2021-10-24, MAE is:67.83 & sMAPE is:59.84% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :15.87 & 25.05% & 1.01\n",
      "for 2021-10-25, MAE is:36.98 & sMAPE is:43.87% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :15.94 & 25.12% & 1.01\n",
      "for 2021-10-26, MAE is:41.89 & sMAPE is:27.83% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :16.02 & 25.13% & 1.01\n",
      "for 2021-10-27, MAE is:52.95 & sMAPE is:107.70% & rMAE is:3.63 ||| daily mean of MAE & sMAPE & rMAE till now are :16.15 & 25.40% & 1.02\n",
      "for 2021-10-28, MAE is:32.47 & sMAPE is:63.04% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :16.20 & 25.53% & 1.02\n",
      "for 2021-10-29, MAE is:19.04 & sMAPE is:32.67% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :16.21 & 25.55% & 1.02\n",
      "for 2021-10-30, MAE is:18.34 & sMAPE is:23.99% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :16.22 & 25.55% & 1.02\n",
      "for 2021-10-31, MAE is:21.27 & sMAPE is:54.23% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :16.23 & 25.64% & 1.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-11-01, MAE is:17.50 & sMAPE is:30.22% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :16.24 & 25.65% & 1.01\n",
      "for 2021-11-02, MAE is:108.26 & sMAPE is:71.83% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :16.54 & 25.81% & 1.02\n",
      "for 2021-11-03, MAE is:22.33 & sMAPE is:12.11% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :16.56 & 25.76% & 1.01\n",
      "for 2021-11-04, MAE is:26.69 & sMAPE is:17.40% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :16.59 & 25.73% & 1.01\n",
      "for 2021-11-05, MAE is:62.41 & sMAPE is:85.52% & rMAE is:3.09 ||| daily mean of MAE & sMAPE & rMAE till now are :16.74 & 25.93% & 1.02\n",
      "for 2021-11-06, MAE is:21.86 & sMAPE is:111.75% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :16.76 & 26.20% & 1.01\n",
      "for 2021-11-07, MAE is:20.39 & sMAPE is:71.00% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :16.77 & 26.35% & 1.01\n",
      "for 2021-11-08, MAE is:103.41 & sMAPE is:73.71% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :17.04 & 26.50% & 1.01\n",
      "for 2021-11-09, MAE is:88.75 & sMAPE is:76.53% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :17.27 & 26.66% & 1.01\n",
      "for 2021-11-10, MAE is:106.12 & sMAPE is:117.58% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :17.56 & 26.95% & 1.01\n",
      "for 2021-11-11, MAE is:31.09 & sMAPE is:17.69% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :17.60 & 26.92% & 1.01\n",
      "for 2021-11-12, MAE is:33.88 & sMAPE is:23.61% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :17.65 & 26.91% & 1.01\n",
      "for 2021-11-13, MAE is:60.94 & sMAPE is:46.85% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :17.79 & 26.97% & 1.01\n",
      "for 2021-11-14, MAE is:24.94 & sMAPE is:17.89% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :17.81 & 26.94% & 1.01\n",
      "for 2021-11-15, MAE is:83.93 & sMAPE is:45.03% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :18.02 & 27.00% & 1.01\n",
      "for 2021-11-16, MAE is:62.86 & sMAPE is:29.34% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :18.16 & 27.01% & 1.01\n",
      "for 2021-11-17, MAE is:87.65 & sMAPE is:66.70% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :18.37 & 27.13% & 1.01\n",
      "for 2021-11-18, MAE is:34.09 & sMAPE is:74.73% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :18.42 & 27.28% & 1.01\n",
      "for 2021-11-19, MAE is:33.07 & sMAPE is:106.47% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :18.47 & 27.52% & 1.00\n",
      "for 2021-11-20, MAE is:23.84 & sMAPE is:66.24% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :18.49 & 27.64% & 1.00\n",
      "for 2021-11-21, MAE is:29.30 & sMAPE is:51.51% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :18.52 & 27.72% & 1.00\n",
      "for 2021-11-22, MAE is:102.55 & sMAPE is:60.77% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :18.78 & 27.82% & 1.00\n",
      "for 2021-11-23, MAE is:64.89 & sMAPE is:57.20% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :18.92 & 27.91% & 1.00\n",
      "for 2021-11-24, MAE is:127.11 & sMAPE is:87.59% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :19.25 & 28.09% & 1.00\n",
      "for 2021-11-25, MAE is:28.78 & sMAPE is:34.34% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :19.28 & 28.11% & 1.00\n",
      "for 2021-11-26, MAE is:81.06 & sMAPE is:55.78% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :19.46 & 28.19% & 1.00\n",
      "for 2021-11-27, MAE is:67.54 & sMAPE is:43.78% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :19.61 & 28.24% & 1.00\n",
      "for 2021-11-28, MAE is:49.29 & sMAPE is:29.37% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :19.70 & 28.24% & 1.00\n",
      "for 2021-11-29, MAE is:85.96 & sMAPE is:33.35% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :19.90 & 28.26% & 1.00\n",
      "for 2021-11-30, MAE is:50.70 & sMAPE is:29.91% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :19.99 & 28.26% & 1.00\n",
      "for 2021-12-01, MAE is:56.46 & sMAPE is:35.28% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :20.10 & 28.28% & 1.00\n",
      "for 2021-12-02, MAE is:90.14 & sMAPE is:60.39% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :20.31 & 28.38% & 1.00\n",
      "for 2021-12-03, MAE is:33.94 & sMAPE is:20.34% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :20.35 & 28.36% & 1.00\n",
      "for 2021-12-04, MAE is:45.77 & sMAPE is:25.77% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :20.42 & 28.35% & 1.00\n",
      "for 2021-12-05, MAE is:41.53 & sMAPE is:29.83% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :20.48 & 28.35% & 1.00\n",
      "for 2021-12-06, MAE is:104.89 & sMAPE is:36.88% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :20.73 & 28.38% & 1.00\n",
      "for 2021-12-07, MAE is:44.21 & sMAPE is:21.17% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :20.80 & 28.36% & 1.00\n",
      "for 2021-12-08, MAE is:37.01 & sMAPE is:22.53% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :20.85 & 28.34% & 1.00\n",
      "for 2021-12-09, MAE is:86.24 & sMAPE is:34.89% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :21.04 & 28.36% & 1.00\n",
      "for 2021-12-10, MAE is:48.61 & sMAPE is:22.04% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :21.12 & 28.34% & 1.00\n",
      "for 2021-12-11, MAE is:35.36 & sMAPE is:16.72% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :21.16 & 28.31% & 1.00\n",
      "for 2021-12-12, MAE is:43.45 & sMAPE is:24.03% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :21.23 & 28.29% & 1.00\n",
      "for 2021-12-13, MAE is:49.56 & sMAPE is:24.56% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :21.31 & 28.28% & 1.00\n",
      "for 2021-12-14, MAE is:89.72 & sMAPE is:52.06% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :21.50 & 28.35% & 1.00\n",
      "for 2021-12-15, MAE is:86.77 & sMAPE is:83.32% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :21.69 & 28.51% & 1.00\n",
      "for 2021-12-16, MAE is:58.13 & sMAPE is:55.43% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :21.79 & 28.59% & 1.00\n",
      "for 2021-12-17, MAE is:97.35 & sMAPE is:70.02% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :22.01 & 28.70% & 1.00\n",
      "for 2021-12-18, MAE is:54.83 & sMAPE is:41.98% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :22.10 & 28.74% & 1.00\n",
      "for 2021-12-19, MAE is:45.64 & sMAPE is:74.45% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :22.17 & 28.87% & 0.99\n",
      "for 2021-12-20, MAE is:199.37 & sMAPE is:86.82% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :22.67 & 29.04% & 1.00\n",
      "for 2021-12-21, MAE is:133.85 & sMAPE is:36.23% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :22.98 & 29.06% & 1.00\n",
      "for 2021-12-22, MAE is:88.14 & sMAPE is:23.32% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :23.17 & 29.04% & 0.99\n",
      "for 2021-12-23, MAE is:53.87 & sMAPE is:21.03% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :23.25 & 29.02% & 0.99\n",
      "for 2021-12-24, MAE is:37.48 & sMAPE is:22.25% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :23.29 & 29.00% & 0.99\n",
      "for 2021-12-25, MAE is:20.71 & sMAPE is:11.25% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :23.29 & 28.95% & 0.99\n",
      "for 2021-12-26, MAE is:22.52 & sMAPE is:13.69% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :23.28 & 28.91% & 0.99\n",
      "for 2021-12-27, MAE is:49.95 & sMAPE is:31.31% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :23.36 & 28.91% & 0.98\n",
      "for 2021-12-28, MAE is:64.54 & sMAPE is:49.11% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :23.47 & 28.97% & 0.98\n",
      "for 2021-12-29, MAE is:22.74 & sMAPE is:15.54% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :23.47 & 28.93% & 0.98\n",
      "for 2021-12-30, MAE is:63.68 & sMAPE is:65.93% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :23.58 & 29.03% & 0.98\n",
      "for 2021-12-31, MAE is:36.14 & sMAPE is:64.28% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :23.61 & 29.13% & 0.98\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:40:29,766]\u001b[0m A new study created in RDB with name: DK_2_2022\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:40:48,558]\u001b[0m Trial 3 finished with value: 45.348959974985114 and parameters: {'n_hidden': 3, 'learning_rate': 0.011441007377225277, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011585875493753717, 'dropout_rate_Layer_2': 0.28448142322345304, 'dropout_rate_Layer_3': 0.027489222435972984, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5802445680836723e-05, 'l1_Layer_2': 1.5445410973756114e-05, 'l1_Layer_3': 0.00019541824214569596, 'n_units_Layer_1': 250, 'n_units_Layer_2': 110, 'n_units_Layer_3': 115}. Best is trial 3 with value: 45.348959974985114.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.35 | sMAPE for Validation Set is: 53.34% | rMAE for Validation Set is: 1.26\n",
      "MAE for Test Set is: 169.48 | sMAPE for Test Set is: 112.48% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:40:49,015]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 32.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:40:56,421]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:01,179]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:03,939]\u001b[0m Trial 0 finished with value: 22.444812100286594 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011137598388442703, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05752024905973996, 'dropout_rate_Layer_2': 0.32610106989082, 'dropout_rate_Layer_3': 0.24245308364529447, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02047413255594605, 'l1_Layer_2': 9.373581459531996e-05, 'l1_Layer_3': 1.052533922340148e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 170, 'n_units_Layer_3': 290}. Best is trial 0 with value: 22.444812100286594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.44 | sMAPE for Validation Set is: 27.08% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 60.44 | sMAPE for Test Set is: 41.11% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:41:06,862]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:10,104]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:10,450]\u001b[0m Trial 1 finished with value: 46.43130091887169 and parameters: {'n_hidden': 4, 'learning_rate': 0.04694829896272035, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03115243642878589, 'dropout_rate_Layer_2': 0.17784699086048106, 'dropout_rate_Layer_3': 0.053390688440967705, 'dropout_rate_Layer_4': 0.3713188402043762, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 4.444358160802773e-05, 'l1_Layer_2': 0.0018256032556092966, 'l1_Layer_3': 0.06732844023530006, 'l1_Layer_4': 0.0009875311534729844, 'n_units_Layer_1': 165, 'n_units_Layer_2': 175, 'n_units_Layer_3': 245, 'n_units_Layer_4': 195}. Best is trial 0 with value: 22.444812100286594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.43 | sMAPE for Validation Set is: 55.29% | rMAE for Validation Set is: 1.29\n",
      "MAE for Test Set is: 169.06 | sMAPE for Test Set is: 112.54% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:41:14,560]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:14,723]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:15,902]\u001b[0m Trial 7 finished with value: 44.145461980066706 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021336516610793933, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04189346753745409, 'dropout_rate_Layer_2': 0.2976992238549636, 'dropout_rate_Layer_3': 0.02510415465457454, 'dropout_rate_Layer_4': 0.24140523045975282, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.7992357427973834e-05, 'l1_Layer_2': 0.00042269264552463587, 'l1_Layer_3': 4.1372080904779624e-05, 'l1_Layer_4': 1.8898340687023088e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 85, 'n_units_Layer_3': 125, 'n_units_Layer_4': 55}. Best is trial 0 with value: 22.444812100286594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.15 | sMAPE for Validation Set is: 51.55% | rMAE for Validation Set is: 1.23\n",
      "MAE for Test Set is: 165.09 | sMAPE for Test Set is: 108.37% | rMAE for Test Set is: 1.60\n",
      "MAE for Validation Set is: 26.01 | sMAPE for Validation Set is: 30.90% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 69.16 | sMAPE for Test Set is: 45.34% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:41:19,570]\u001b[0m Trial 4 finished with value: 26.01097311177956 and parameters: {'n_hidden': 3, 'learning_rate': 0.08492200351163663, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04433416093008322, 'dropout_rate_Layer_2': 0.044527502712094824, 'dropout_rate_Layer_3': 0.3006624038117858, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07168913062117718, 'l1_Layer_2': 0.010241836239386981, 'l1_Layer_3': 1.0655449769214255e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 215, 'n_units_Layer_3': 265}. Best is trial 0 with value: 22.444812100286594.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:23,239]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:26,405]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:28,956]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:33,207]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:34,864]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:38,469]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:39,740]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:40,616]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:46,270]\u001b[0m Trial 13 finished with value: 49.3962333208489 and parameters: {'n_hidden': 3, 'learning_rate': 0.06920280001176678, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17204096883388298, 'dropout_rate_Layer_2': 0.34683130410478324, 'dropout_rate_Layer_3': 0.29384688415977483, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.011438393454195655, 'l1_Layer_2': 7.176926883223864e-05, 'l1_Layer_3': 0.03926089889490354, 'n_units_Layer_1': 95, 'n_units_Layer_2': 300, 'n_units_Layer_3': 75}. Best is trial 0 with value: 22.444812100286594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.40 | sMAPE for Validation Set is: 60.16% | rMAE for Validation Set is: 1.37\n",
      "MAE for Test Set is: 173.15 | sMAPE for Test Set is: 117.49% | rMAE for Test Set is: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:41:46,613]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:48,096]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:48,135]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:52,554]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:55,817]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:57,602]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:41:58,013]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:02,928]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:06,361]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:07,345]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:07,843]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:15,722]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:19,198]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:20,428]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:25,016]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:28,086]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:28,380]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:32,587]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:35,385]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:41,357]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:44,437]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:44,841]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:45,931]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:51,404]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:51,882]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:51,978]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.81 | sMAPE for Validation Set is: 46.29% | rMAE for Validation Set is: 1.13\n",
      "MAE for Test Set is: 160.69 | sMAPE for Test Set is: 103.08% | rMAE for Test Set is: 1.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:42:55,592]\u001b[0m Trial 34 finished with value: 40.80888319940873 and parameters: {'n_hidden': 3, 'learning_rate': 0.010841618349212243, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1465972443819951, 'dropout_rate_Layer_2': 0.22036270223602458, 'dropout_rate_Layer_3': 0.17363090813228954, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 6.866222375421565e-05, 'l1_Layer_2': 0.0007956226569267587, 'l1_Layer_3': 0.0010988212617922739, 'n_units_Layer_1': 140, 'n_units_Layer_2': 280, 'n_units_Layer_3': 160}. Best is trial 0 with value: 22.444812100286594.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:42:58,761]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:02,195]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:04,275]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:07,079]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:07,358]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:07,582]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:08,438]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:15,783]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:17,406]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:21,567]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:26,372]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:26,808]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:30,559]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:31,247]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:33,373]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:37,817]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:39,050]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:40,797]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:47,637]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:48,513]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:43:51,099]\u001b[0m Trial 65 finished with value: 40.24003087358185 and parameters: {'n_hidden': 3, 'learning_rate': 0.03341995438615033, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24965087123062812, 'dropout_rate_Layer_2': 0.3449922661164602, 'dropout_rate_Layer_3': 0.22428586338951076, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010693350405635765, 'l1_Layer_2': 0.0014712075906485765, 'l1_Layer_3': 0.00022289280999805816, 'n_units_Layer_1': 115, 'n_units_Layer_2': 115, 'n_units_Layer_3': 85}. Best is trial 0 with value: 22.444812100286594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.24 | sMAPE for Validation Set is: 45.93% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 158.24 | sMAPE for Test Set is: 100.52% | rMAE for Test Set is: 1.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:43:58,787]\u001b[0m Trial 68 finished with value: 42.68696846311985 and parameters: {'n_hidden': 3, 'learning_rate': 0.02318750726455919, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0025669053495382538, 'dropout_rate_Layer_2': 0.28619737201481094, 'dropout_rate_Layer_3': 0.018050548061014537, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2032234011491595e-05, 'l1_Layer_2': 1.4696561854451512e-05, 'l1_Layer_3': 0.00015686622350531067, 'n_units_Layer_1': 300, 'n_units_Layer_2': 50, 'n_units_Layer_3': 50}. Best is trial 0 with value: 22.444812100286594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.69 | sMAPE for Validation Set is: 49.08% | rMAE for Validation Set is: 1.18\n",
      "MAE for Test Set is: 161.83 | sMAPE for Test Set is: 104.32% | rMAE for Test Set is: 1.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:43:59,518]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.16 | sMAPE for Validation Set is: 40.46% | rMAE for Validation Set is: 1.00\n",
      "MAE for Test Set is: 146.31 | sMAPE for Test Set is: 89.33% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:44:02,711]\u001b[0m Trial 70 finished with value: 36.156541692295995 and parameters: {'n_hidden': 3, 'learning_rate': 0.017619795886597456, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009952900394335237, 'dropout_rate_Layer_2': 0.2533286718707061, 'dropout_rate_Layer_3': 0.0036460679192294454, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2241494910132733e-05, 'l1_Layer_2': 1.1806536444433798e-05, 'l1_Layer_3': 9.084363755561264e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 180, 'n_units_Layer_3': 135}. Best is trial 0 with value: 22.444812100286594.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:44:05,729]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:44:10,795]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:44:12,141]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:44:16,638]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:44:19,675]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:44:19,809]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:44:20,078]\u001b[0m Trial 72 finished with value: 33.90643490643475 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017956908890977828, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08999373874312902, 'dropout_rate_Layer_2': 0.23916757377261455, 'dropout_rate_Layer_3': 0.06098151490502403, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.978864126216368e-05, 'l1_Layer_2': 0.0001289047334182999, 'l1_Layer_3': 7.14427146464595e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 195}. Best is trial 0 with value: 22.444812100286594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.91 | sMAPE for Validation Set is: 37.95% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 143.49 | sMAPE for Test Set is: 87.24% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:44:27,007]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:44:30,880]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:44:34,493]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:44:38,347]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:44:46,799]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:44:56,670]\u001b[0m Trial 74 finished with value: 30.943323657184113 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007064457209822838, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23852809310378253, 'dropout_rate_Layer_2': 0.07512542806719487, 'dropout_rate_Layer_3': 0.10073308419706391, 'dropout_rate_Layer_4': 0.17742437919901835, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.07508720017595505, 'l1_Layer_2': 0.0013599437515095989, 'l1_Layer_3': 7.346980800429681e-05, 'l1_Layer_4': 0.019799200408593974, 'n_units_Layer_1': 275, 'n_units_Layer_2': 235, 'n_units_Layer_3': 275, 'n_units_Layer_4': 290}. Best is trial 0 with value: 22.444812100286594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.94 | sMAPE for Validation Set is: 35.51% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 129.33 | sMAPE for Test Set is: 76.14% | rMAE for Test Set is: 1.26\n",
      "MAE for Validation Set is: 35.13 | sMAPE for Validation Set is: 39.44% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 145.51 | sMAPE for Test Set is: 88.11% | rMAE for Test Set is: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:44:58,284]\u001b[0m Trial 87 finished with value: 35.12802796315797 and parameters: {'n_hidden': 3, 'learning_rate': 0.044342573532099964, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26141253931530023, 'dropout_rate_Layer_2': 0.12470055066951916, 'dropout_rate_Layer_3': 0.06789901559863391, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.430483772943767e-05, 'l1_Layer_2': 4.122494044832934e-05, 'l1_Layer_3': 7.61459203317642e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 165, 'n_units_Layer_3': 185}. Best is trial 0 with value: 22.444812100286594.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:45:00,416]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:45:03,180]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:45:07,586]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:45:09,861]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:45:10,210]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:45:10,308]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:45:15,684]\u001b[0m Trial 86 finished with value: 33.005932048090784 and parameters: {'n_hidden': 3, 'learning_rate': 0.001023845639001158, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0853735241463264, 'dropout_rate_Layer_2': 0.23931476252853523, 'dropout_rate_Layer_3': 0.07741300704833978, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004479937634244231, 'l1_Layer_2': 0.00024612493368665996, 'l1_Layer_3': 5.807860817714716e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 215, 'n_units_Layer_3': 250}. Best is trial 0 with value: 22.444812100286594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.01 | sMAPE for Validation Set is: 36.46% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 141.24 | sMAPE for Test Set is: 85.30% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:45:19,536]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:45:23,764]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:45:24,178]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:45:29,787]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:45:29,965]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:45:38,475]\u001b[0m Trial 93 finished with value: 36.90046924583517 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021579446922977575, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07071661721485335, 'dropout_rate_Layer_2': 0.12730388272473547, 'dropout_rate_Layer_3': 0.2297621559645608, 'dropout_rate_Layer_4': 0.3968694762175704, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01408543516611107, 'l1_Layer_2': 0.019258109591584697, 'l1_Layer_3': 0.0010539751191881207, 'l1_Layer_4': 0.00016601457511982373, 'n_units_Layer_1': 160, 'n_units_Layer_2': 225, 'n_units_Layer_3': 195, 'n_units_Layer_4': 165}. Best is trial 0 with value: 22.444812100286594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.90 | sMAPE for Validation Set is: 41.39% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 149.30 | sMAPE for Test Set is: 92.12% | rMAE for Test Set is: 1.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:45:41,312]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:45:44,135]\u001b[0m Trial 100 finished with value: 35.63260348331329 and parameters: {'n_hidden': 3, 'learning_rate': 0.04409272307070076, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2967192239545598, 'dropout_rate_Layer_2': 0.12057748086603588, 'dropout_rate_Layer_3': 0.05185207744205442, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.217848474430363e-05, 'l1_Layer_2': 0.00026203805296988545, 'l1_Layer_3': 2.7471467902811957e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 160, 'n_units_Layer_3': 185}. Best is trial 0 with value: 22.444812100286594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.63 | sMAPE for Validation Set is: 40.16% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 144.67 | sMAPE for Test Set is: 87.65% | rMAE for Test Set is: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:45:44,684]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:45:50,752]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:45:52,651]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:45:56,904]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:45:57,472]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.32 | sMAPE for Validation Set is: 41.11% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 143.67 | sMAPE for Test Set is: 86.60% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:45:58,769]\u001b[0m Trial 103 finished with value: 36.323122185848284 and parameters: {'n_hidden': 3, 'learning_rate': 0.04581270444495249, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2742041653106786, 'dropout_rate_Layer_2': 0.009509403902907124, 'dropout_rate_Layer_3': 0.10392813308578253, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.587355755880174e-05, 'l1_Layer_2': 0.00027714877589255497, 'l1_Layer_3': 3.505158733616804e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 160, 'n_units_Layer_3': 190}. Best is trial 0 with value: 22.444812100286594.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:02,602]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:04,912]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:07,911]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:08,053]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:08,403]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:15,532]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:16,319]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:19,110]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:22,740]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:24,886]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:27,910]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:28,548]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:30,403]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:34,536]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:34,999]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:39,614]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:39,962]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:41,817]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:44,973]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:47,363]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:48,750]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:54,157]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:54,343]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:46:59,767]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:00,168]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:04,623]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:04,723]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:10,960]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:11,818]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:12,984]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:18,351]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:23,523]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 36.46 | sMAPE for Validation Set is: 41.02% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 148.32 | sMAPE for Test Set is: 90.42% | rMAE for Test Set is: 1.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:47:24,948]\u001b[0m Trial 138 finished with value: 36.46069349143092 and parameters: {'n_hidden': 3, 'learning_rate': 0.04948910680836305, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.323385055844323, 'dropout_rate_Layer_2': 0.10968566743322121, 'dropout_rate_Layer_3': 0.04015183307154166, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.12472904094061e-05, 'l1_Layer_2': 0.00019878420390523872, 'l1_Layer_3': 2.268964344739346e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 170, 'n_units_Layer_3': 175}. Best is trial 0 with value: 22.444812100286594.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:25,194]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:29,136]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:30,334]\u001b[0m Trial 137 finished with value: 22.408175691278235 and parameters: {'n_hidden': 3, 'learning_rate': 0.015364263337536129, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.049043811467437436, 'dropout_rate_Layer_2': 0.13032431932791907, 'dropout_rate_Layer_3': 0.06050819670074402, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00765365227595275, 'l1_Layer_2': 2.223507892322773e-05, 'l1_Layer_3': 1.8531989356056023e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 125, 'n_units_Layer_3': 250}. Best is trial 137 with value: 22.408175691278235.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.41 | sMAPE for Validation Set is: 27.35% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 60.39 | sMAPE for Test Set is: 41.66% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:47:33,331]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:38,862]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:39,213]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:39,267]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:44,939]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:47,777]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:50,152]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:51,732]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:54,957]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:55,338]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:57,190]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:47:59,491]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:05,408]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:05,922]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 37.87 | sMAPE for Validation Set is: 42.33% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 155.97 | sMAPE for Test Set is: 98.54% | rMAE for Test Set is: 1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:48:07,603]\u001b[0m Trial 149 finished with value: 37.87100155420587 and parameters: {'n_hidden': 4, 'learning_rate': 0.010556254962445116, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24766534340463586, 'dropout_rate_Layer_2': 0.13814737066168023, 'dropout_rate_Layer_3': 0.3711076266285822, 'dropout_rate_Layer_4': 0.15155740214960411, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009277158213843414, 'l1_Layer_2': 0.00028192278909294245, 'l1_Layer_3': 0.0050015264747814295, 'l1_Layer_4': 1.1112439729685532e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 300, 'n_units_Layer_3': 80, 'n_units_Layer_4': 245}. Best is trial 137 with value: 22.408175691278235.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:09,465]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:09,785]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:11,095]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:15,556]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:17,851]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:19,637]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:22,455]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:26,182]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:28,023]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:30,726]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:33,616]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:33,851]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:34,188]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:37,018]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:40,721]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:42,896]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:44,595]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:45,006]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:49,427]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:50,607]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:55,248]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:48:58,789]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:49:02,891]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:49:03,472]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:49:07,586]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:49:12,419]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:49:15,639]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:49:21,059]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:49:24,392]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:49:28,103]\u001b[0m Trial 183 finished with value: 22.144885173616462 and parameters: {'n_hidden': 3, 'learning_rate': 0.05076382053283345, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0018889776034440343, 'dropout_rate_Layer_2': 0.16405148184837717, 'dropout_rate_Layer_3': 0.1943969020053691, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005822538762368706, 'l1_Layer_2': 0.008755484579638723, 'l1_Layer_3': 0.00038387765635220015, 'n_units_Layer_1': 110, 'n_units_Layer_2': 180, 'n_units_Layer_3': 170}. Best is trial 183 with value: 22.144885173616462.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.14 | sMAPE for Validation Set is: 26.80% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 59.04 | sMAPE for Test Set is: 41.02% | rMAE for Test Set is: 0.57\n",
      "MAE for Validation Set is: 24.21 | sMAPE for Validation Set is: 29.78% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 62.38 | sMAPE for Test Set is: 42.32% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:49:28,267]\u001b[0m Trial 184 finished with value: 24.213031825131328 and parameters: {'n_hidden': 3, 'learning_rate': 0.022131458494900162, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03275715108824967, 'dropout_rate_Layer_2': 0.17910039690152296, 'dropout_rate_Layer_3': 0.015277766721723651, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.4560137604313145e-05, 'l1_Layer_2': 3.851505385075985e-05, 'l1_Layer_3': 6.362014354725128e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 250, 'n_units_Layer_3': 165}. Best is trial 183 with value: 22.144885173616462.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:49:28,765]\u001b[0m Trial 185 finished with value: 22.069752172986444 and parameters: {'n_hidden': 3, 'learning_rate': 0.060653898829792066, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18202540881480062, 'dropout_rate_Layer_2': 0.2092249004261898, 'dropout_rate_Layer_3': 0.19722775374642462, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007579445147430944, 'l1_Layer_2': 0.009972013739089867, 'l1_Layer_3': 0.0003617100507312527, 'n_units_Layer_1': 110, 'n_units_Layer_2': 175, 'n_units_Layer_3': 185}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.07 | sMAPE for Validation Set is: 26.70% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 58.93 | sMAPE for Test Set is: 40.84% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:49:35,125]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:49:36,103]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:49:37,956]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:49:39,639]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:49:42,190]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:49:46,104]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:49:50,012]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:49:53,798]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:49:54,093]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:50:00,628]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:50:03,730]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:50:03,942]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:50:04,885]\u001b[0m Trial 197 finished with value: 22.33365412287706 and parameters: {'n_hidden': 3, 'learning_rate': 0.005730234820460002, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.045623165797029616, 'dropout_rate_Layer_2': 0.047244242487052515, 'dropout_rate_Layer_3': 0.11852303720356358, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0026362834085767745, 'l1_Layer_2': 1.6996570591403666e-05, 'l1_Layer_3': 0.002310747211448483, 'n_units_Layer_1': 100, 'n_units_Layer_2': 215, 'n_units_Layer_3': 220}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.33 | sMAPE for Validation Set is: 27.94% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 64.60 | sMAPE for Test Set is: 41.76% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:50:12,109]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:50:17,200]\u001b[0m Trial 204 finished with value: 23.564481087574524 and parameters: {'n_hidden': 3, 'learning_rate': 0.024730480986488713, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02178515879296386, 'dropout_rate_Layer_2': 0.2711480479125314, 'dropout_rate_Layer_3': 0.017315769890213127, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4838384146281629e-05, 'l1_Layer_2': 0.00010023577049201203, 'l1_Layer_3': 0.00013408856447584143, 'n_units_Layer_1': 235, 'n_units_Layer_2': 205, 'n_units_Layer_3': 125}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.56 | sMAPE for Validation Set is: 28.85% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 61.04 | sMAPE for Test Set is: 41.92% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:50:18,072]\u001b[0m Trial 205 finished with value: 23.593319289698726 and parameters: {'n_hidden': 3, 'learning_rate': 0.025670905186186716, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019005819943528693, 'dropout_rate_Layer_2': 0.21711576432895893, 'dropout_rate_Layer_3': 0.0028798590064099613, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2535730118711757e-05, 'l1_Layer_2': 0.00010616577720931474, 'l1_Layer_3': 0.00015640253834306507, 'n_units_Layer_1': 235, 'n_units_Layer_2': 205, 'n_units_Layer_3': 110}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.59 | sMAPE for Validation Set is: 28.32% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.94 | sMAPE for Test Set is: 41.17% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:50:24,225]\u001b[0m Trial 190 finished with value: 25.93333108402081 and parameters: {'n_hidden': 4, 'learning_rate': 0.000554839773049097, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2649197853074274, 'dropout_rate_Layer_2': 0.1239299859378493, 'dropout_rate_Layer_3': 0.0016389159386358404, 'dropout_rate_Layer_4': 0.15711705055051078, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0839074221405675, 'l1_Layer_2': 0.00664794727599735, 'l1_Layer_3': 8.081756103486179e-05, 'l1_Layer_4': 1.1067491488860902e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 255, 'n_units_Layer_3': 300, 'n_units_Layer_4': 285}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.93 | sMAPE for Validation Set is: 29.66% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 112.93 | sMAPE for Test Set is: 64.72% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:50:27,281]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:50:33,688]\u001b[0m Trial 208 finished with value: 23.898053677116476 and parameters: {'n_hidden': 3, 'learning_rate': 0.02496870178882555, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030975180427056034, 'dropout_rate_Layer_2': 0.30924298537329253, 'dropout_rate_Layer_3': 0.030286695556255433, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.41494240828184e-05, 'l1_Layer_2': 0.00010468616444899092, 'l1_Layer_3': 0.00014350023912340485, 'n_units_Layer_1': 240, 'n_units_Layer_2': 215, 'n_units_Layer_3': 115}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.90 | sMAPE for Validation Set is: 29.18% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.11 | sMAPE for Test Set is: 41.00% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:50:37,447]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:50:38,117]\u001b[0m Trial 207 finished with value: 22.447330696351372 and parameters: {'n_hidden': 3, 'learning_rate': 0.004208587582204721, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22788330782787247, 'dropout_rate_Layer_2': 0.03423977237111735, 'dropout_rate_Layer_3': 0.09703237542870363, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004185596605374679, 'l1_Layer_2': 0.0012275822571641633, 'l1_Layer_3': 0.002946279380159988, 'n_units_Layer_1': 100, 'n_units_Layer_2': 210, 'n_units_Layer_3': 240}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.45 | sMAPE for Validation Set is: 27.34% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 60.76 | sMAPE for Test Set is: 40.85% | rMAE for Test Set is: 0.59\n",
      "MAE for Validation Set is: 23.11 | sMAPE for Validation Set is: 28.33% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.46 | sMAPE for Test Set is: 41.19% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:50:43,284]\u001b[0m Trial 211 finished with value: 23.1111119167565 and parameters: {'n_hidden': 3, 'learning_rate': 0.02433522770252607, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026374283940874932, 'dropout_rate_Layer_2': 0.21971647044978604, 'dropout_rate_Layer_3': 0.020781887087535936, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0211429412954623e-05, 'l1_Layer_2': 0.00010150688725722292, 'l1_Layer_3': 0.00017446587944210275, 'n_units_Layer_1': 240, 'n_units_Layer_2': 205, 'n_units_Layer_3': 115}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.28 | sMAPE for Validation Set is: 27.11% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.01 | sMAPE for Test Set is: 40.71% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:50:44,722]\u001b[0m Trial 209 finished with value: 22.277156702957118 and parameters: {'n_hidden': 3, 'learning_rate': 0.024710940983197427, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025567093316334676, 'dropout_rate_Layer_2': 0.2186147188412995, 'dropout_rate_Layer_3': 0.03198523493798665, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0888384474772314e-05, 'l1_Layer_2': 0.00010503448175466646, 'l1_Layer_3': 0.0001433807653221234, 'n_units_Layer_1': 240, 'n_units_Layer_2': 220, 'n_units_Layer_3': 120}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:50:49,521]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:50:52,564]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:50:54,836]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:50:55,824]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:50:56,442]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:51:00,907]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:51:01,398]\u001b[0m Trial 214 finished with value: 23.35855753495513 and parameters: {'n_hidden': 3, 'learning_rate': 0.026295024976399167, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024409150789875426, 'dropout_rate_Layer_2': 0.3191329183773948, 'dropout_rate_Layer_3': 0.02789018716523102, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4614057270788448e-05, 'l1_Layer_2': 9.803139357145365e-05, 'l1_Layer_3': 0.00014438804956376985, 'n_units_Layer_1': 240, 'n_units_Layer_2': 220, 'n_units_Layer_3': 115}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.36 | sMAPE for Validation Set is: 29.04% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 57.17 | sMAPE for Test Set is: 40.39% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:51:03,967]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:51:06,729]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:51:08,237]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:51:12,113]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:51:13,677]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:51:14,331]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:51:17,077]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:51:23,063]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:51:32,676]\u001b[0m Trial 229 finished with value: 22.32403735128972 and parameters: {'n_hidden': 3, 'learning_rate': 0.018175501204122296, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022260216905181845, 'dropout_rate_Layer_2': 0.27340267432450355, 'dropout_rate_Layer_3': 0.030251761753665868, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6258664025896652e-05, 'l1_Layer_2': 0.0004146784826785473, 'l1_Layer_3': 0.00042521669405823424, 'n_units_Layer_1': 215, 'n_units_Layer_2': 215, 'n_units_Layer_3': 100}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.32 | sMAPE for Validation Set is: 27.26% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 55.68 | sMAPE for Test Set is: 39.71% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:51:33,281]\u001b[0m Trial 227 finished with value: 22.569161050374344 and parameters: {'n_hidden': 3, 'learning_rate': 0.009879990730493303, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04811382610690547, 'dropout_rate_Layer_2': 0.27469125262753874, 'dropout_rate_Layer_3': 0.03152949568236131, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5233296890804121e-05, 'l1_Layer_2': 0.0003556439903407791, 'l1_Layer_3': 0.0004137078149585348, 'n_units_Layer_1': 210, 'n_units_Layer_2': 220, 'n_units_Layer_3': 125}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.57 | sMAPE for Validation Set is: 27.43% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.69 | sMAPE for Test Set is: 40.41% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:51:41,424]\u001b[0m Trial 228 finished with value: 23.325886922598553 and parameters: {'n_hidden': 3, 'learning_rate': 0.018498729115128225, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019355184069337797, 'dropout_rate_Layer_2': 0.27207084231784207, 'dropout_rate_Layer_3': 0.0356886552304519, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.56024726996543e-05, 'l1_Layer_2': 0.0003577925294368737, 'l1_Layer_3': 0.0004034165053029319, 'n_units_Layer_1': 215, 'n_units_Layer_2': 220, 'n_units_Layer_3': 105}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.33 | sMAPE for Validation Set is: 28.07% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 61.74 | sMAPE for Test Set is: 41.57% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:51:53,421]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:52:06,888]\u001b[0m Trial 232 finished with value: 22.767226625547732 and parameters: {'n_hidden': 3, 'learning_rate': 0.01916955794899871, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.047730730746012195, 'dropout_rate_Layer_2': 0.2701298759917611, 'dropout_rate_Layer_3': 0.0040338617459786084, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0096390473261782e-05, 'l1_Layer_2': 0.0004907714520378633, 'l1_Layer_3': 0.00040306901614151, 'n_units_Layer_1': 215, 'n_units_Layer_2': 220, 'n_units_Layer_3': 100}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.77 | sMAPE for Validation Set is: 27.77% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.11 | sMAPE for Test Set is: 40.38% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:52:13,107]\u001b[0m Trial 235 finished with value: 22.289580670409816 and parameters: {'n_hidden': 3, 'learning_rate': 0.013344857204324184, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.002121218961037008, 'dropout_rate_Layer_2': 0.15925065437227592, 'dropout_rate_Layer_3': 0.21431695719691413, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005005960973849282, 'l1_Layer_2': 0.043026778104882236, 'l1_Layer_3': 0.001980257663168882, 'n_units_Layer_1': 120, 'n_units_Layer_2': 250, 'n_units_Layer_3': 195}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.29 | sMAPE for Validation Set is: 27.17% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.21 | sMAPE for Test Set is: 40.59% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:52:21,969]\u001b[0m Trial 231 finished with value: 26.99015586030106 and parameters: {'n_hidden': 4, 'learning_rate': 0.000530172662567262, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2757038463314947, 'dropout_rate_Layer_2': 0.006169002023366288, 'dropout_rate_Layer_3': 0.0012911916763441282, 'dropout_rate_Layer_4': 0.17628156024360508, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09954622581567159, 'l1_Layer_2': 0.006507801001841614, 'l1_Layer_3': 6.173629742236716e-05, 'l1_Layer_4': 1.1442800783825053e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 240, 'n_units_Layer_3': 280, 'n_units_Layer_4': 300}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.99 | sMAPE for Validation Set is: 30.70% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 121.13 | sMAPE for Test Set is: 70.03% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:52:25,328]\u001b[0m Trial 233 finished with value: 25.740909056563623 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005281888568101024, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3943937892548084, 'dropout_rate_Layer_2': 0.011434233606402694, 'dropout_rate_Layer_3': 0.004099689062510544, 'dropout_rate_Layer_4': 0.17770706441002504, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09636392147102264, 'l1_Layer_2': 0.007966269144048818, 'l1_Layer_3': 0.00012968644076366572, 'l1_Layer_4': 2.6512532224378494e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 280, 'n_units_Layer_4': 300}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.74 | sMAPE for Validation Set is: 30.69% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 102.40 | sMAPE for Test Set is: 59.17% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:52:28,132]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:52:31,398]\u001b[0m Trial 236 finished with value: 22.221092196202367 and parameters: {'n_hidden': 3, 'learning_rate': 0.005802553570764269, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05741447677202002, 'dropout_rate_Layer_2': 0.29749939211490584, 'dropout_rate_Layer_3': 0.04114900153583986, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0000149819735923e-05, 'l1_Layer_2': 0.0006208196735873282, 'l1_Layer_3': 0.0004847553517815795, 'n_units_Layer_1': 205, 'n_units_Layer_2': 195, 'n_units_Layer_3': 80}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.22 | sMAPE for Validation Set is: 27.19% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.10 | sMAPE for Test Set is: 39.59% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:52:31,680]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:52:41,663]\u001b[0m Trial 238 finished with value: 23.14105223523838 and parameters: {'n_hidden': 3, 'learning_rate': 0.010273628075898817, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.001028230492747119, 'dropout_rate_Layer_2': 0.2962042663259867, 'dropout_rate_Layer_3': 0.037069284468622066, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8956362580571346e-05, 'l1_Layer_2': 0.0006750103114488641, 'l1_Layer_3': 0.0005525096868728675, 'n_units_Layer_1': 215, 'n_units_Layer_2': 225, 'n_units_Layer_3': 100}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.14 | sMAPE for Validation Set is: 27.93% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.53 | sMAPE for Test Set is: 41.63% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:52:47,943]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:52:50,107]\u001b[0m Trial 242 finished with value: 22.376349909255623 and parameters: {'n_hidden': 3, 'learning_rate': 0.013569527194403892, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0007249025362491487, 'dropout_rate_Layer_2': 0.14659302680972638, 'dropout_rate_Layer_3': 0.17116837480374392, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000519375315229889, 'l1_Layer_2': 0.04853580201665069, 'l1_Layer_3': 0.002662428707090074, 'n_units_Layer_1': 120, 'n_units_Layer_2': 260, 'n_units_Layer_3': 185}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.38 | sMAPE for Validation Set is: 27.17% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 60.65 | sMAPE for Test Set is: 41.69% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:52:52,717]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:52:55,235]\u001b[0m Trial 243 finished with value: 22.47531357254174 and parameters: {'n_hidden': 3, 'learning_rate': 0.013026252088426829, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.000679637017530836, 'dropout_rate_Layer_2': 0.15712945912777077, 'dropout_rate_Layer_3': 0.17294143517840804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004382731679418742, 'l1_Layer_2': 0.03997995543105342, 'l1_Layer_3': 0.002451685111345584, 'n_units_Layer_1': 120, 'n_units_Layer_2': 255, 'n_units_Layer_3': 175}. Best is trial 185 with value: 22.069752172986444.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.48 | sMAPE for Validation Set is: 27.27% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.67 | sMAPE for Test Set is: 41.18% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:52:58,967]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:53:00,947]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:53:01,399]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:53:02,282]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:53:07,682]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:53:09,160]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:53:24,381]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:53:28,979]\u001b[0m Trial 253 finished with value: 21.883625268587775 and parameters: {'n_hidden': 3, 'learning_rate': 0.004735933026632964, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02840175430396562, 'dropout_rate_Layer_2': 0.197372014137879, 'dropout_rate_Layer_3': 0.2080547764873178, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005592961705895398, 'l1_Layer_2': 0.03992292065753429, 'l1_Layer_3': 0.0005335725542208391, 'n_units_Layer_1': 60, 'n_units_Layer_2': 290, 'n_units_Layer_3': 185}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.88 | sMAPE for Validation Set is: 26.69% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.39 | sMAPE for Test Set is: 39.91% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:53:29,706]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:53:31,270]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:53:34,360]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:53:35,193]\u001b[0m Trial 250 finished with value: 22.266685432989288 and parameters: {'n_hidden': 3, 'learning_rate': 0.004366548687322273, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02757059659689326, 'dropout_rate_Layer_2': 0.19328489141144156, 'dropout_rate_Layer_3': 0.19823459882284444, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007143394463784635, 'l1_Layer_2': 0.043164834141183564, 'l1_Layer_3': 0.0021215242145254764, 'n_units_Layer_1': 60, 'n_units_Layer_2': 300, 'n_units_Layer_3': 185}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.27 | sMAPE for Validation Set is: 27.05% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 59.45 | sMAPE for Test Set is: 41.08% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:53:36,189]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:53:43,589]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:53:46,364]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:53:48,946]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:53:49,168]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:53:57,721]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:54:01,430]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:54:03,899]\u001b[0m Trial 258 finished with value: 23.073864411113153 and parameters: {'n_hidden': 3, 'learning_rate': 0.008063893757627266, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04813538036999084, 'dropout_rate_Layer_2': 0.33946838914025507, 'dropout_rate_Layer_3': 0.04974354056582192, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.680537732917053e-05, 'l1_Layer_2': 0.0012564721035220028, 'l1_Layer_3': 0.0006772065125221226, 'n_units_Layer_1': 195, 'n_units_Layer_2': 190, 'n_units_Layer_3': 125}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.07 | sMAPE for Validation Set is: 27.73% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.31 | sMAPE for Test Set is: 40.89% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:54:04,459]\u001b[0m Trial 260 finished with value: 22.670047175723578 and parameters: {'n_hidden': 3, 'learning_rate': 0.008899763708860314, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04831330240982189, 'dropout_rate_Layer_2': 0.25916498716307085, 'dropout_rate_Layer_3': 0.046195497725892654, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0082334301124407e-05, 'l1_Layer_2': 0.0011579360721359333, 'l1_Layer_3': 0.0007682256087153162, 'n_units_Layer_1': 205, 'n_units_Layer_2': 190, 'n_units_Layer_3': 125}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:54:04,565]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.67 | sMAPE for Validation Set is: 27.88% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 60.16 | sMAPE for Test Set is: 41.16% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:54:12,064]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:54:25,760]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:54:32,110]\u001b[0m Trial 270 finished with value: 22.92763893071111 and parameters: {'n_hidden': 3, 'learning_rate': 0.007061353424717153, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0653535917765483, 'dropout_rate_Layer_2': 0.2570364268000506, 'dropout_rate_Layer_3': 0.05533836612152147, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7966360395511788e-05, 'l1_Layer_2': 0.0019492016983799134, 'l1_Layer_3': 0.00183505535017912, 'n_units_Layer_1': 205, 'n_units_Layer_2': 210, 'n_units_Layer_3': 85}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.93 | sMAPE for Validation Set is: 28.28% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.23 | sMAPE for Test Set is: 41.38% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:54:34,681]\u001b[0m Trial 264 finished with value: 34.700611095230066 and parameters: {'n_hidden': 4, 'learning_rate': 0.00130863010269703, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33440482381473996, 'dropout_rate_Layer_2': 0.021287254151284508, 'dropout_rate_Layer_3': 0.057614181366238734, 'dropout_rate_Layer_4': 0.29016984115801864, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.027914481870813534, 'l1_Layer_2': 0.011720817450485118, 'l1_Layer_3': 0.0004273664875627555, 'l1_Layer_4': 8.133715959487601e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 55, 'n_units_Layer_3': 300, 'n_units_Layer_4': 100}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.70 | sMAPE for Validation Set is: 39.47% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 142.39 | sMAPE for Test Set is: 86.17% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:54:35,128]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:54:42,962]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:54:53,064]\u001b[0m Trial 269 finished with value: 22.538763191865367 and parameters: {'n_hidden': 3, 'learning_rate': 0.006786734471664954, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.065365109140781, 'dropout_rate_Layer_2': 0.33350014575963055, 'dropout_rate_Layer_3': 0.05227931461322662, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.797105907514169e-05, 'l1_Layer_2': 0.001823344965998851, 'l1_Layer_3': 0.0024214875595203016, 'n_units_Layer_1': 185, 'n_units_Layer_2': 190, 'n_units_Layer_3': 80}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:54:53,201]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.54 | sMAPE for Validation Set is: 27.81% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 60.76 | sMAPE for Test Set is: 41.57% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:54:59,649]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:55:03,722]\u001b[0m Trial 271 finished with value: 22.81475748032498 and parameters: {'n_hidden': 3, 'learning_rate': 0.012767469422860701, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09320063015049637, 'dropout_rate_Layer_2': 0.23427936936459792, 'dropout_rate_Layer_3': 0.05233483273780946, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.204752987109637e-05, 'l1_Layer_2': 0.004712857828269282, 'l1_Layer_3': 0.00023141680276156243, 'n_units_Layer_1': 205, 'n_units_Layer_2': 205, 'n_units_Layer_3': 85}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.81 | sMAPE for Validation Set is: 27.63% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.26 | sMAPE for Test Set is: 40.70% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:55:07,117]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:55:14,740]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:55:30,590]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:55:31,500]\u001b[0m Trial 281 finished with value: 22.027814518596205 and parameters: {'n_hidden': 3, 'learning_rate': 0.004353113008496445, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03095791139326514, 'dropout_rate_Layer_2': 0.27160367122700085, 'dropout_rate_Layer_3': 0.2646299677525299, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002118117432672348, 'l1_Layer_2': 0.0137312098573301, 'l1_Layer_3': 0.00046990305720468514, 'n_units_Layer_1': 65, 'n_units_Layer_2': 295, 'n_units_Layer_3': 155}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.03 | sMAPE for Validation Set is: 26.93% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.21 | sMAPE for Test Set is: 40.20% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:55:39,862]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:55:43,613]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:55:44,022]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:55:50,559]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:55:50,917]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:55:55,127]\u001b[0m Trial 278 finished with value: 30.305718008300335 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005693260304192767, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.311574999210844, 'dropout_rate_Layer_2': 0.09796572080836903, 'dropout_rate_Layer_3': 0.04724317141397913, 'dropout_rate_Layer_4': 0.26483444487095686, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003264772856953598, 'l1_Layer_2': 0.019270950642007213, 'l1_Layer_3': 0.0018687715739998314, 'l1_Layer_4': 0.0006365651376296607, 'n_units_Layer_1': 265, 'n_units_Layer_2': 250, 'n_units_Layer_3': 255, 'n_units_Layer_4': 145}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.31 | sMAPE for Validation Set is: 34.05% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 133.76 | sMAPE for Test Set is: 78.70% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:55:57,204]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:55:58,992]\u001b[0m Trial 273 finished with value: 32.37094016585215 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005081454830072817, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29515126599002484, 'dropout_rate_Layer_2': 0.3935820811539458, 'dropout_rate_Layer_3': 0.047071638024476004, 'dropout_rate_Layer_4': 0.26204958741855505, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004578484464294339, 'l1_Layer_2': 0.0038355448862125983, 'l1_Layer_3': 0.001983031970281757, 'l1_Layer_4': 0.0006181549186113932, 'n_units_Layer_1': 265, 'n_units_Layer_2': 250, 'n_units_Layer_3': 255, 'n_units_Layer_4': 150}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.37 | sMAPE for Validation Set is: 36.03% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 141.91 | sMAPE for Test Set is: 85.49% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:56:04,340]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:56:04,730]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:56:08,934]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:56:10,204]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:56:14,567]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:56:18,284]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:56:23,822]\u001b[0m Trial 289 finished with value: 23.204495582420737 and parameters: {'n_hidden': 3, 'learning_rate': 0.016336455895334594, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.036088217368589325, 'dropout_rate_Layer_2': 0.281353431789101, 'dropout_rate_Layer_3': 0.054658013319155575, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3108029724099359e-05, 'l1_Layer_2': 0.010266265528095108, 'l1_Layer_3': 0.001091609486109723, 'n_units_Layer_1': 205, 'n_units_Layer_2': 215, 'n_units_Layer_3': 55}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.20 | sMAPE for Validation Set is: 28.39% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.50 | sMAPE for Test Set is: 40.78% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:56:28,398]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:56:30,023]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:56:32,097]\u001b[0m Trial 295 finished with value: 22.531173410346835 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037602818420171503, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09173726481361545, 'dropout_rate_Layer_2': 0.3156932705721422, 'dropout_rate_Layer_3': 0.1526479328714977, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013845562789383803, 'l1_Layer_2': 0.014708059434706267, 'l1_Layer_3': 0.00036056283234075045, 'n_units_Layer_1': 65, 'n_units_Layer_2': 280, 'n_units_Layer_3': 150}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.53 | sMAPE for Validation Set is: 27.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.22 | sMAPE for Test Set is: 40.34% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:56:36,590]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:56:39,421]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:56:42,588]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:56:45,614]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:56:48,734]\u001b[0m Trial 299 finished with value: 23.447160105374774 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032496124602451677, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2449944894976785, 'dropout_rate_Layer_2': 0.21773571971620337, 'dropout_rate_Layer_3': 0.2763669941146435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011632300182175579, 'l1_Layer_2': 0.004427504945528819, 'l1_Layer_3': 0.00047254123792420935, 'n_units_Layer_1': 70, 'n_units_Layer_2': 70, 'n_units_Layer_3': 150}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.45 | sMAPE for Validation Set is: 28.90% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 62.70 | sMAPE for Test Set is: 42.20% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:56:54,404]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:56:55,026]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:56:58,324]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:56:59,046]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:57:03,271]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:57:08,535]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:57:14,943]\u001b[0m Trial 302 finished with value: 23.209705619286453 and parameters: {'n_hidden': 3, 'learning_rate': 0.011927270461698102, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10165233359247365, 'dropout_rate_Layer_2': 0.2613219143779058, 'dropout_rate_Layer_3': 0.09160624213094772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.983707026705819e-05, 'l1_Layer_2': 0.0004723602156423394, 'l1_Layer_3': 0.002236395149848637, 'n_units_Layer_1': 190, 'n_units_Layer_2': 200, 'n_units_Layer_3': 95}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.21 | sMAPE for Validation Set is: 28.96% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.43 | sMAPE for Test Set is: 40.70% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:57:23,308]\u001b[0m Trial 312 finished with value: 24.04740327994473 and parameters: {'n_hidden': 3, 'learning_rate': 0.007672642160776193, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03247241189352764, 'dropout_rate_Layer_2': 0.22175707561783373, 'dropout_rate_Layer_3': 0.10838280454225503, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003468601724294318, 'l1_Layer_2': 0.03383738626971797, 'l1_Layer_3': 0.0070505200271753065, 'n_units_Layer_1': 95, 'n_units_Layer_2': 285, 'n_units_Layer_3': 115}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.05 | sMAPE for Validation Set is: 29.40% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 62.96 | sMAPE for Test Set is: 43.10% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:57:25,487]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:57:29,442]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:57:32,150]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:57:34,706]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:57:36,588]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:57:40,130]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:57:49,327]\u001b[0m Trial 310 finished with value: 27.97879009914007 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009112066785962888, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2639272886110533, 'dropout_rate_Layer_2': 0.006973288271494564, 'dropout_rate_Layer_3': 0.002624544853520912, 'dropout_rate_Layer_4': 0.15290160656964696, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03288126452601277, 'l1_Layer_2': 0.00776702671928038, 'l1_Layer_3': 2.8580290674617897e-05, 'l1_Layer_4': 1.0097519261869563e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 220, 'n_units_Layer_3': 280, 'n_units_Layer_4': 260}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.98 | sMAPE for Validation Set is: 32.13% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 123.06 | sMAPE for Test Set is: 71.83% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:57:49,877]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:57:51,179]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:57:55,277]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:57:55,445]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:57:59,268]\u001b[0m Trial 301 finished with value: 29.27947927033213 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009457724126094395, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26617803136926593, 'dropout_rate_Layer_2': 0.003839842506733551, 'dropout_rate_Layer_3': 0.1496155753068615, 'dropout_rate_Layer_4': 0.14649504484692608, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.08866398019451814, 'l1_Layer_2': 0.00878256883665498, 'l1_Layer_3': 3.732663018730404e-05, 'l1_Layer_4': 1.1015606223684818e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 225, 'n_units_Layer_3': 280, 'n_units_Layer_4': 260}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.28 | sMAPE for Validation Set is: 32.62% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 125.97 | sMAPE for Test Set is: 73.78% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:58:02,329]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:58:08,986]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:58:12,055]\u001b[0m Trial 324 finished with value: 22.79881965941391 and parameters: {'n_hidden': 3, 'learning_rate': 0.006390911121104581, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0511858002076412, 'dropout_rate_Layer_2': 0.010795030985308261, 'dropout_rate_Layer_3': 0.09108533736701101, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02735633623112839, 'l1_Layer_2': 4.8336713645675126e-05, 'l1_Layer_3': 1.3243465771060862e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 240, 'n_units_Layer_3': 240}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:58:12,079]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.80 | sMAPE for Validation Set is: 27.42% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.48 | sMAPE for Test Set is: 40.41% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:58:12,615]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:58:18,827]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:58:19,110]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:58:19,194]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:58:20,471]\u001b[0m Trial 323 finished with value: 22.56092156087942 and parameters: {'n_hidden': 3, 'learning_rate': 0.008570693496437458, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06897895929774345, 'dropout_rate_Layer_2': 0.3493979839530148, 'dropout_rate_Layer_3': 0.047461514514488407, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6889756876980087e-05, 'l1_Layer_2': 0.0021443303270865404, 'l1_Layer_3': 0.000727491609672915, 'n_units_Layer_1': 195, 'n_units_Layer_2': 210, 'n_units_Layer_3': 105}. Best is trial 253 with value: 21.883625268587775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.56 | sMAPE for Validation Set is: 27.78% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.63 | sMAPE for Test Set is: 40.47% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:58:29,291]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:58:32,705]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:58:34,880]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:58:35,379]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:58:39,691]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:58:42,009]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:58:44,587]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:58:49,150]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:58:54,119]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:59:11,690]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:59:12,441]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:59:16,224]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:59:19,337]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:59:19,943]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.43 | sMAPE for Validation Set is: 26.38% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 55.51 | sMAPE for Test Set is: 39.71% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:59:23,863]\u001b[0m Trial 341 finished with value: 21.4285008467856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013107553610467732, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10895763106198303, 'dropout_rate_Layer_2': 0.17537854448275117, 'dropout_rate_Layer_3': 0.2508436682465624, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.537551658931033e-05, 'l1_Layer_2': 0.004602561005362171, 'l1_Layer_3': 0.0015323267139302733, 'n_units_Layer_1': 145, 'n_units_Layer_2': 120, 'n_units_Layer_3': 135}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:59:29,473]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:59:34,603]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:59:37,812]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:59:41,289]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:59:43,292]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:59:44,144]\u001b[0m Trial 349 finished with value: 21.44346006897575 and parameters: {'n_hidden': 3, 'learning_rate': 0.00475127051725031, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10211211379424688, 'dropout_rate_Layer_2': 0.17718457602150264, 'dropout_rate_Layer_3': 0.2491592218464763, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008309021632329917, 'l1_Layer_2': 0.0008152439237641031, 'l1_Layer_3': 9.012565253993739e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 115, 'n_units_Layer_3': 135}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.44 | sMAPE for Validation Set is: 26.66% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.75 | sMAPE for Test Set is: 39.53% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 06:59:46,782]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:59:51,775]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:59:54,102]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 06:59:59,621]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:00:04,108]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:00:04,512]\u001b[0m Trial 357 finished with value: 22.871291554609048 and parameters: {'n_hidden': 3, 'learning_rate': 0.005565559540231525, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06731695166900427, 'dropout_rate_Layer_2': 0.007881237010131327, 'dropout_rate_Layer_3': 0.10053570268348987, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01933365282328257, 'l1_Layer_2': 2.5760290009995145e-05, 'l1_Layer_3': 0.00012607696566111209, 'n_units_Layer_1': 100, 'n_units_Layer_2': 210, 'n_units_Layer_3': 225}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.87 | sMAPE for Validation Set is: 27.84% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 59.81 | sMAPE for Test Set is: 41.13% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:00:09,379]\u001b[0m Trial 356 finished with value: 22.85149094121194 and parameters: {'n_hidden': 3, 'learning_rate': 0.005419532549539803, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07407640045117661, 'dropout_rate_Layer_2': 0.048939265236179745, 'dropout_rate_Layer_3': 0.13282729179492098, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018059111453348993, 'l1_Layer_2': 2.7176076737487355e-05, 'l1_Layer_3': 0.00013143225240686671, 'n_units_Layer_1': 100, 'n_units_Layer_2': 220, 'n_units_Layer_3': 230}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.85 | sMAPE for Validation Set is: 27.45% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 63.64 | sMAPE for Test Set is: 42.21% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:00:11,866]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:00:27,270]\u001b[0m Trial 363 finished with value: 21.905099176806118 and parameters: {'n_hidden': 3, 'learning_rate': 0.004628716312660259, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07424245979789737, 'dropout_rate_Layer_2': 0.009426666535329314, 'dropout_rate_Layer_3': 0.11696675399028593, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014391607011514934, 'l1_Layer_2': 1.8809827746283726e-05, 'l1_Layer_3': 0.00013242107392395, 'n_units_Layer_1': 90, 'n_units_Layer_2': 220, 'n_units_Layer_3': 230}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.91 | sMAPE for Validation Set is: 26.74% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 58.26 | sMAPE for Test Set is: 40.57% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:00:29,427]\u001b[0m Trial 360 finished with value: 35.53392302545887 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007700298663398524, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2195314679540545, 'dropout_rate_Layer_2': 0.17789526239376463, 'dropout_rate_Layer_3': 0.03162726076889731, 'dropout_rate_Layer_4': 0.11328025954629954, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00044526125411996, 'l1_Layer_2': 0.0018031898127882754, 'l1_Layer_3': 0.00011144410858519529, 'l1_Layer_4': 0.0002180715801710331, 'n_units_Layer_1': 250, 'n_units_Layer_2': 280, 'n_units_Layer_3': 265, 'n_units_Layer_4': 270}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 35.53 | sMAPE for Validation Set is: 39.79% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 149.86 | sMAPE for Test Set is: 92.75% | rMAE for Test Set is: 1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:00:31,579]\u001b[0m Trial 362 finished with value: 22.731238565373086 and parameters: {'n_hidden': 3, 'learning_rate': 0.004728538947873088, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06128092599181471, 'dropout_rate_Layer_2': 0.009822289591716764, 'dropout_rate_Layer_3': 0.09594516097302791, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.017861470513028978, 'l1_Layer_2': 2.379528863345418e-05, 'l1_Layer_3': 0.0003637868322782512, 'n_units_Layer_1': 90, 'n_units_Layer_2': 220, 'n_units_Layer_3': 215}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.73 | sMAPE for Validation Set is: 27.81% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 60.05 | sMAPE for Test Set is: 41.31% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:00:35,546]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:00:39,508]\u001b[0m Trial 364 finished with value: 22.531046885947664 and parameters: {'n_hidden': 3, 'learning_rate': 0.004630012742485495, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06076101724186117, 'dropout_rate_Layer_2': 0.003231213185656546, 'dropout_rate_Layer_3': 0.10589034290417648, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010789679959737926, 'l1_Layer_2': 1.556157170903613e-05, 'l1_Layer_3': 6.158018772524413e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 220, 'n_units_Layer_3': 215}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.53 | sMAPE for Validation Set is: 26.85% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 62.75 | sMAPE for Test Set is: 41.75% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:00:43,761]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:00:49,982]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:00:53,904]\u001b[0m Trial 367 finished with value: 22.63703261764356 and parameters: {'n_hidden': 3, 'learning_rate': 0.0045931509416610936, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07157965661466895, 'dropout_rate_Layer_2': 0.001506615683263492, 'dropout_rate_Layer_3': 0.10461256931812246, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0138989595345258, 'l1_Layer_2': 1.7701009674703057e-05, 'l1_Layer_3': 0.00021489881877503994, 'n_units_Layer_1': 85, 'n_units_Layer_2': 220, 'n_units_Layer_3': 215}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.64 | sMAPE for Validation Set is: 27.61% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.97 | sMAPE for Test Set is: 40.33% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:00:54,170]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:00:59,575]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:01:01,437]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:01:05,565]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:01:05,614]\u001b[0m Trial 368 finished with value: 22.02249331849373 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033066506431899457, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07409471183969328, 'dropout_rate_Layer_2': 0.000998683396438698, 'dropout_rate_Layer_3': 0.10303233743117401, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014108872920005674, 'l1_Layer_2': 1.798071284261573e-05, 'l1_Layer_3': 0.00012698930117407213, 'n_units_Layer_1': 85, 'n_units_Layer_2': 220, 'n_units_Layer_3': 215}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.02 | sMAPE for Validation Set is: 26.92% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.63 | sMAPE for Test Set is: 39.65% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:01:10,200]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:01:15,495]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:01:18,780]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:01:21,630]\u001b[0m Trial 375 finished with value: 22.043395877294035 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034232490451797976, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05443541980788402, 'dropout_rate_Layer_2': 0.0004621356923565148, 'dropout_rate_Layer_3': 0.08744155894077321, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013164103551034093, 'l1_Layer_2': 1.0561892925824715e-05, 'l1_Layer_3': 0.00018880927962896808, 'n_units_Layer_1': 85, 'n_units_Layer_2': 230, 'n_units_Layer_3': 200}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.04 | sMAPE for Validation Set is: 27.10% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.71 | sMAPE for Test Set is: 39.75% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:01:25,681]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:01:41,261]\u001b[0m Trial 381 finished with value: 22.02877213277686 and parameters: {'n_hidden': 3, 'learning_rate': 0.003067402033899394, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05400789888254355, 'dropout_rate_Layer_2': 0.008671031353219474, 'dropout_rate_Layer_3': 0.09455706741495651, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011476292278003364, 'l1_Layer_2': 1.5064985743612042e-05, 'l1_Layer_3': 0.00013254522664878137, 'n_units_Layer_1': 80, 'n_units_Layer_2': 235, 'n_units_Layer_3': 210}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.03 | sMAPE for Validation Set is: 27.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.59 | sMAPE for Test Set is: 39.23% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:01:42,121]\u001b[0m Trial 382 finished with value: 22.41038103485019 and parameters: {'n_hidden': 3, 'learning_rate': 0.002650184539830291, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05607186624265505, 'dropout_rate_Layer_2': 0.00820120427802739, 'dropout_rate_Layer_3': 0.07825414976400599, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01538315377471188, 'l1_Layer_2': 1.0037665790369416e-05, 'l1_Layer_3': 0.000182696462234462, 'n_units_Layer_1': 90, 'n_units_Layer_2': 220, 'n_units_Layer_3': 210}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.41 | sMAPE for Validation Set is: 27.39% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.45 | sMAPE for Test Set is: 40.02% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:01:47,463]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:01:48,113]\u001b[0m Trial 371 finished with value: 23.261209279280468 and parameters: {'n_hidden': 3, 'learning_rate': 0.003986505640581134, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030791087931580606, 'dropout_rate_Layer_2': 0.2519092454706179, 'dropout_rate_Layer_3': 0.2724826607003137, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.99580370103467e-05, 'l1_Layer_2': 0.00016958137867796358, 'l1_Layer_3': 0.0002701536187695692, 'n_units_Layer_1': 230, 'n_units_Layer_2': 220, 'n_units_Layer_3': 100}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.26 | sMAPE for Validation Set is: 27.82% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.88 | sMAPE for Test Set is: 41.10% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:01:51,057]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:01:52,930]\u001b[0m Trial 378 finished with value: 33.304775401329415 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007555950007738898, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28749321293278196, 'dropout_rate_Layer_2': 0.09854804715297194, 'dropout_rate_Layer_3': 0.19636008771975647, 'dropout_rate_Layer_4': 0.2208892467421155, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01612128504387827, 'l1_Layer_2': 0.00608315211718675, 'l1_Layer_3': 2.960447718218081e-05, 'l1_Layer_4': 0.002750927191546097, 'n_units_Layer_1': 190, 'n_units_Layer_2': 205, 'n_units_Layer_3': 235, 'n_units_Layer_4': 210}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 33.30 | sMAPE for Validation Set is: 37.04% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 143.66 | sMAPE for Test Set is: 87.01% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:01:57,236]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:01,332]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:02,726]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:04,491]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:05,800]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:07,402]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:09,671]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:14,010]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:18,107]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:18,706]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:23,483]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:23,836]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:24,026]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:30,310]\u001b[0m Trial 389 finished with value: 21.564231719759192 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016300085028723437, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08599729637000524, 'dropout_rate_Layer_2': 0.17978459158539875, 'dropout_rate_Layer_3': 0.22464663931148499, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.160866993584002e-05, 'l1_Layer_2': 0.0010465385348476166, 'l1_Layer_3': 0.0007497678426628613, 'n_units_Layer_1': 145, 'n_units_Layer_2': 95, 'n_units_Layer_3': 125}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.56 | sMAPE for Validation Set is: 26.47% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.13 | sMAPE for Test Set is: 39.79% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:02:31,139]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:36,947]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:38,687]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:39,270]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:40,538]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:44,790]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:45,215]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:45,378]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:54,228]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:02:57,854]\u001b[0m Trial 399 finished with value: 22.88351032904406 and parameters: {'n_hidden': 3, 'learning_rate': 0.013807774602771172, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03982844806249012, 'dropout_rate_Layer_2': 0.3535346086938169, 'dropout_rate_Layer_3': 0.008139454561056046, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6117508668349722e-05, 'l1_Layer_2': 0.0005423029719408162, 'l1_Layer_3': 0.009430778067294539, 'n_units_Layer_1': 200, 'n_units_Layer_2': 165, 'n_units_Layer_3': 80}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.88 | sMAPE for Validation Set is: 27.35% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.59 | sMAPE for Test Set is: 40.78% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:02:58,074]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:04,509]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:05,226]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:06,434]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:07,323]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:11,549]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:15,172]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:15,209]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:16,152]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:19,288]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:24,423]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:25,156]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:31,768]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:38,600]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:39,193]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:44,245]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:47,959]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:51,961]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:52,474]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:03:56,680]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:04:00,414]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:04:00,664]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:04:06,689]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:04:10,095]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:04:16,701]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:04:27,431]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:04:30,234]\u001b[0m Trial 435 finished with value: 22.61440430088666 and parameters: {'n_hidden': 3, 'learning_rate': 0.005042452874222501, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08222306573472113, 'dropout_rate_Layer_2': 0.3265930251796239, 'dropout_rate_Layer_3': 0.06432005932965335, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00030139858681326717, 'l1_Layer_2': 0.001424473725613133, 'l1_Layer_3': 0.0014756141342422778, 'n_units_Layer_1': 205, 'n_units_Layer_2': 185, 'n_units_Layer_3': 70}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.61 | sMAPE for Validation Set is: 27.58% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.36 | sMAPE for Test Set is: 40.06% | rMAE for Test Set is: 0.57\n",
      "MAE for Validation Set is: 22.26 | sMAPE for Validation Set is: 27.06% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.41 | sMAPE for Test Set is: 40.04% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:04:31,428]\u001b[0m Trial 434 finished with value: 22.262766192575683 and parameters: {'n_hidden': 3, 'learning_rate': 0.00280488713796759, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08189752854086847, 'dropout_rate_Layer_2': 0.3712698048616617, 'dropout_rate_Layer_3': 0.06178295880354888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9316827336084366e-05, 'l1_Layer_2': 0.0016460509560651153, 'l1_Layer_3': 0.0022293570118831455, 'n_units_Layer_1': 205, 'n_units_Layer_2': 190, 'n_units_Layer_3': 70}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:04:34,992]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:04:45,678]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:04:52,222]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:04:52,661]\u001b[0m Trial 439 finished with value: 22.62036392825387 and parameters: {'n_hidden': 3, 'learning_rate': 0.0040596570023960134, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06393398759981107, 'dropout_rate_Layer_2': 0.009225245039924224, 'dropout_rate_Layer_3': 0.1033838687646901, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011581608449739015, 'l1_Layer_2': 1.0161875070656437e-05, 'l1_Layer_3': 0.00017448813117512853, 'n_units_Layer_1': 80, 'n_units_Layer_2': 235, 'n_units_Layer_3': 230}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.62 | sMAPE for Validation Set is: 27.35% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.78 | sMAPE for Test Set is: 40.62% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:04:56,821]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:04:57,177]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:05:04,985]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:05:10,431]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:05:14,925]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:05:18,063]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:05:24,517]\u001b[0m Trial 447 finished with value: 21.79272728045414 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011827528446854765, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06506757341427993, 'dropout_rate_Layer_2': 0.18617237974627093, 'dropout_rate_Layer_3': 0.31180608192585546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.012558509738448e-05, 'l1_Layer_2': 7.110447167916432e-05, 'l1_Layer_3': 0.0005573871093277567, 'n_units_Layer_1': 210, 'n_units_Layer_2': 100, 'n_units_Layer_3': 205}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.79 | sMAPE for Validation Set is: 26.63% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.39 | sMAPE for Test Set is: 39.87% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:05:27,864]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:05:35,033]\u001b[0m Trial 445 finished with value: 30.97514882774104 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008533065098196356, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27246510524316103, 'dropout_rate_Layer_2': 0.026595564685358564, 'dropout_rate_Layer_3': 0.00036812022217900956, 'dropout_rate_Layer_4': 0.1736960581588854, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.046526365583255326, 'l1_Layer_2': 0.007894717620249335, 'l1_Layer_3': 2.0004465430806357e-05, 'l1_Layer_4': 1.173194195379252e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 225, 'n_units_Layer_3': 280, 'n_units_Layer_4': 265}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.98 | sMAPE for Validation Set is: 34.56% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 133.02 | sMAPE for Test Set is: 78.40% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:05:41,402]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:05:44,615]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:05:51,238]\u001b[0m Trial 452 finished with value: 22.426848448568432 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026232478986191617, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028363119881755435, 'dropout_rate_Layer_2': 0.3127466456803247, 'dropout_rate_Layer_3': 0.07170341087417792, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0133473152179213e-05, 'l1_Layer_2': 0.0007222333342871586, 'l1_Layer_3': 0.000890071198399013, 'n_units_Layer_1': 170, 'n_units_Layer_2': 195, 'n_units_Layer_3': 80}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.43 | sMAPE for Validation Set is: 27.24% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.06 | sMAPE for Test Set is: 39.75% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:05:53,131]\u001b[0m Trial 450 finished with value: 22.438755869575584 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016521012385315303, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09572443959660994, 'dropout_rate_Layer_2': 0.3116090632878562, 'dropout_rate_Layer_3': 0.0707449637383861, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0116838226290915e-05, 'l1_Layer_2': 0.0008367683073659586, 'l1_Layer_3': 0.0009012967672177326, 'n_units_Layer_1': 215, 'n_units_Layer_2': 170, 'n_units_Layer_3': 80}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.44 | sMAPE for Validation Set is: 27.13% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.92 | sMAPE for Test Set is: 40.03% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:05:57,763]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:05:58,623]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:05:59,409]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:06:02,025]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:06:07,872]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:06:14,766]\u001b[0m Trial 459 finished with value: 22.875365121173687 and parameters: {'n_hidden': 3, 'learning_rate': 0.002445956170172337, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11690090187848032, 'dropout_rate_Layer_2': 0.2983309531110069, 'dropout_rate_Layer_3': 0.072197595762484, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.19240061332254e-05, 'l1_Layer_2': 0.00041229432903799884, 'l1_Layer_3': 0.0005556013065741385, 'n_units_Layer_1': 230, 'n_units_Layer_2': 190, 'n_units_Layer_3': 75}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.88 | sMAPE for Validation Set is: 27.73% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.25 | sMAPE for Test Set is: 40.81% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:06:17,804]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:06:23,519]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:06:28,883]\u001b[0m Trial 460 finished with value: 22.382004715078818 and parameters: {'n_hidden': 3, 'learning_rate': 0.002775956230843055, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12034059947399597, 'dropout_rate_Layer_2': 0.3013102727835146, 'dropout_rate_Layer_3': 0.07310559218119424, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003084248867154131, 'l1_Layer_2': 0.0017868719559831177, 'l1_Layer_3': 0.0005776449867329908, 'n_units_Layer_1': 230, 'n_units_Layer_2': 200, 'n_units_Layer_3': 70}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.38 | sMAPE for Validation Set is: 27.07% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.16 | sMAPE for Test Set is: 39.94% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:06:32,064]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:06:35,714]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:06:39,115]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:06:42,917]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:06:52,012]\u001b[0m Trial 462 finished with value: 28.37232614650573 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006754307055793039, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3327393483738967, 'dropout_rate_Layer_2': 0.05895390236364593, 'dropout_rate_Layer_3': 0.02621162610457124, 'dropout_rate_Layer_4': 0.17266756688925822, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.017207794390235415, 'l1_Layer_2': 1.5735453334573454e-05, 'l1_Layer_3': 0.00014658927435367306, 'l1_Layer_4': 1.845551744303066e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 225, 'n_units_Layer_3': 270, 'n_units_Layer_4': 280}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.37 | sMAPE for Validation Set is: 32.77% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 118.98 | sMAPE for Test Set is: 68.56% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:06:55,513]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:06:57,657]\u001b[0m Trial 455 finished with value: 30.250470394768524 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006629094388426941, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33212066325014356, 'dropout_rate_Layer_2': 0.001214635578483233, 'dropout_rate_Layer_3': 0.001379836259122691, 'dropout_rate_Layer_4': 0.16494888438549654, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01628064901247335, 'l1_Layer_2': 0.010293841052048466, 'l1_Layer_3': 0.00014887158058953233, 'l1_Layer_4': 2.2545817635474685e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270, 'n_units_Layer_4': 275}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.25 | sMAPE for Validation Set is: 33.69% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 132.97 | sMAPE for Test Set is: 78.37% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:07:04,324]\u001b[0m Trial 465 finished with value: 22.30317370506874 and parameters: {'n_hidden': 3, 'learning_rate': 0.00419968804521854, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.057711155337415616, 'dropout_rate_Layer_2': 0.042745023744549186, 'dropout_rate_Layer_3': 0.08974961121293917, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008580967101398298, 'l1_Layer_2': 1.4447045173845746e-05, 'l1_Layer_3': 0.00011254767340832946, 'n_units_Layer_1': 80, 'n_units_Layer_2': 230, 'n_units_Layer_3': 225}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.30 | sMAPE for Validation Set is: 27.12% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 60.28 | sMAPE for Test Set is: 41.01% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:07:24,076]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:07:24,480]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:07:25,327]\u001b[0m Trial 470 finished with value: 29.011358032509047 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005405596451942143, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27118800353476546, 'dropout_rate_Layer_2': 0.0660296191402255, 'dropout_rate_Layer_3': 0.00014221908958944943, 'dropout_rate_Layer_4': 0.15829583651716292, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.017993698144273887, 'l1_Layer_2': 0.012849118305242714, 'l1_Layer_3': 0.00014590477264980306, 'l1_Layer_4': 1.023090290881555e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 225, 'n_units_Layer_3': 270, 'n_units_Layer_4': 280}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.01 | sMAPE for Validation Set is: 32.52% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 128.72 | sMAPE for Test Set is: 75.42% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:07:32,948]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:07:33,865]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:07:34,901]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:07:36,356]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:07:40,208]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:07:40,950]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:07:42,263]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:07:44,350]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:07:58,006]\u001b[0m Trial 472 finished with value: 22.172058907642384 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007653593551118664, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.062366647608431414, 'dropout_rate_Layer_2': 0.1832861069457242, 'dropout_rate_Layer_3': 0.3677098743385865, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0180329932388548e-05, 'l1_Layer_2': 0.00022454484917435564, 'l1_Layer_3': 0.000500641469214427, 'n_units_Layer_1': 210, 'n_units_Layer_2': 50, 'n_units_Layer_3': 205}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.17 | sMAPE for Validation Set is: 27.00% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.95 | sMAPE for Test Set is: 39.82% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:08:00,387]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:01,096]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:03,061]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:06,853]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:07,507]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.92 | sMAPE for Validation Set is: 26.54% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.47 | sMAPE for Test Set is: 39.97% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:08:11,557]\u001b[0m Trial 485 finished with value: 21.924062890531413 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028516169157755712, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.106341122732799, 'dropout_rate_Layer_2': 0.31118455714212256, 'dropout_rate_Layer_3': 0.12828734576027984, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0059122698366962136, 'l1_Layer_2': 0.001381015355223541, 'l1_Layer_3': 0.001897920275367818, 'n_units_Layer_1': 235, 'n_units_Layer_2': 170, 'n_units_Layer_3': 70}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:12,169]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:14,226]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:18,427]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:21,225]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:23,067]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:23,681]\u001b[0m Trial 489 finished with value: 21.964142144060727 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012933248940155421, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08573882173091847, 'dropout_rate_Layer_2': 0.20352369949841956, 'dropout_rate_Layer_3': 0.21670959008908797, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2087853683923388e-05, 'l1_Layer_2': 5.7981851689212746e-05, 'l1_Layer_3': 0.00031588430083318735, 'n_units_Layer_1': 175, 'n_units_Layer_2': 105, 'n_units_Layer_3': 160}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.96 | sMAPE for Validation Set is: 26.88% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.42 | sMAPE for Test Set is: 40.14% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:08:24,422]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:29,154]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:29,591]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:30,474]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:35,755]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:39,113]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:42,644]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:48,084]\u001b[0m Trial 503 finished with value: 22.438369656557892 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013813239470994317, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08812514448218785, 'dropout_rate_Layer_2': 0.14724774689539352, 'dropout_rate_Layer_3': 0.2581744742467122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3411491492628094e-05, 'l1_Layer_2': 3.411355934895081e-05, 'l1_Layer_3': 0.0008520489847560998, 'n_units_Layer_1': 185, 'n_units_Layer_2': 65, 'n_units_Layer_3': 125}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.44 | sMAPE for Validation Set is: 27.56% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.98 | sMAPE for Test Set is: 40.72% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:08:49,065]\u001b[0m Trial 498 finished with value: 22.666639171601233 and parameters: {'n_hidden': 3, 'learning_rate': 0.002795999686242829, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09918859161539131, 'dropout_rate_Layer_2': 0.32672382068450884, 'dropout_rate_Layer_3': 0.19145995607225957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01854337174142581, 'l1_Layer_2': 0.0009286107178865206, 'l1_Layer_3': 0.0015439490697699272, 'n_units_Layer_1': 225, 'n_units_Layer_2': 200, 'n_units_Layer_3': 80}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.67 | sMAPE for Validation Set is: 27.46% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.33 | sMAPE for Test Set is: 40.82% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:08:52,511]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:55,634]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:08:56,105]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:09:00,957]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:09:06,791]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:09:07,310]\u001b[0m Trial 500 finished with value: 22.45413569813445 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012484358056654961, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07345943694401393, 'dropout_rate_Layer_2': 0.3257538953743449, 'dropout_rate_Layer_3': 0.1033589086494139, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006605508806687195, 'l1_Layer_2': 0.0009753612936172227, 'l1_Layer_3': 0.0024944162643746296, 'n_units_Layer_1': 235, 'n_units_Layer_2': 200, 'n_units_Layer_3': 80}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.45 | sMAPE for Validation Set is: 27.06% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.89 | sMAPE for Test Set is: 40.38% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:09:07,796]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:09:14,237]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:09:19,868]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:09:20,324]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:09:24,908]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:09:25,425]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:09:28,992]\u001b[0m Trial 513 finished with value: 21.98883040180225 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019143157117494935, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04636316881051296, 'dropout_rate_Layer_2': 0.22735803501568544, 'dropout_rate_Layer_3': 0.27607127595005715, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.828891865109657e-05, 'l1_Layer_2': 0.00011749674506136921, 'l1_Layer_3': 0.000577436053111996, 'n_units_Layer_1': 275, 'n_units_Layer_2': 120, 'n_units_Layer_3': 175}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.99 | sMAPE for Validation Set is: 26.83% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.16 | sMAPE for Test Set is: 39.60% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:09:29,505]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:09:30,028]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:09:34,056]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:09:37,415]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:09:42,775]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:09:54,157]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:09:59,876]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:10:00,682]\u001b[0m Trial 523 finished with value: 22.267164157509352 and parameters: {'n_hidden': 4, 'learning_rate': 0.0044820933070546295, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04943163869772954, 'dropout_rate_Layer_2': 0.00032684623028322683, 'dropout_rate_Layer_3': 0.19795940148556476, 'dropout_rate_Layer_4': 0.21160816760946882, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.01921130948069854, 'l1_Layer_2': 1.947246837742969e-05, 'l1_Layer_3': 0.00013995540434716072, 'l1_Layer_4': 0.0003685322532176318, 'n_units_Layer_1': 80, 'n_units_Layer_2': 240, 'n_units_Layer_3': 205, 'n_units_Layer_4': 290}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.27 | sMAPE for Validation Set is: 27.04% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 61.73 | sMAPE for Test Set is: 41.31% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:10:04,648]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:10:05,769]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:10:10,706]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:10:14,547]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:10:17,677]\u001b[0m Trial 520 finished with value: 28.24169405606428 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006662859557097945, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32683057054076836, 'dropout_rate_Layer_2': 0.05407554544392812, 'dropout_rate_Layer_3': 0.027487515958048138, 'dropout_rate_Layer_4': 0.17407780443211177, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.019648820147206297, 'l1_Layer_2': 1.1474924128300626e-05, 'l1_Layer_3': 0.00027758475243742085, 'l1_Layer_4': 2.024674107548606e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 265, 'n_units_Layer_4': 285}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.24 | sMAPE for Validation Set is: 32.98% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 118.32 | sMAPE for Test Set is: 67.89% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:10:18,356]\u001b[0m Trial 522 finished with value: 27.802883713936893 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007174855615615136, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3336701688663074, 'dropout_rate_Layer_2': 0.056488419935397334, 'dropout_rate_Layer_3': 0.03106403232164314, 'dropout_rate_Layer_4': 0.18400131002568604, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.021487852849321195, 'l1_Layer_2': 2.2784541331168856e-05, 'l1_Layer_3': 9.524913143592337e-05, 'l1_Layer_4': 1.859641054313024e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 290, 'n_units_Layer_4': 285}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.80 | sMAPE for Validation Set is: 32.53% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 117.09 | sMAPE for Test Set is: 67.09% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:10:20,429]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:10:21,137]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:10:26,902]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:10:29,385]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:10:29,573]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:10:29,696]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:10:30,577]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:10:40,347]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:10:42,381]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:10:45,862]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:10:49,487]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:10:52,490]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:10:57,131]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:11:01,631]\u001b[0m Trial 540 finished with value: 22.63761355012045 and parameters: {'n_hidden': 3, 'learning_rate': 0.001739606005354035, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08189618555677422, 'dropout_rate_Layer_2': 0.3090229509522363, 'dropout_rate_Layer_3': 0.2177914348487727, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006198412231203147, 'l1_Layer_2': 0.0020289563060279414, 'l1_Layer_3': 0.0009224043978850075, 'n_units_Layer_1': 210, 'n_units_Layer_2': 195, 'n_units_Layer_3': 85}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.64 | sMAPE for Validation Set is: 27.28% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 59.86 | sMAPE for Test Set is: 41.03% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:11:04,198]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:11:07,816]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:11:11,912]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:11:14,638]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:11:19,621]\u001b[0m Trial 539 finished with value: 30.39518233504819 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006284883682485955, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.375103131401069, 'dropout_rate_Layer_2': 0.07196891467042354, 'dropout_rate_Layer_3': 0.04091207690077805, 'dropout_rate_Layer_4': 0.19693336044702203, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0348735304318582, 'l1_Layer_2': 5.772744557644223e-05, 'l1_Layer_3': 3.6910942458158455e-05, 'l1_Layer_4': 1.858001710738174e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 190, 'n_units_Layer_3': 55, 'n_units_Layer_4': 285}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.40 | sMAPE for Validation Set is: 33.54% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 133.07 | sMAPE for Test Set is: 78.14% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:11:22,198]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:11:22,544]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:11:22,563]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:11:32,487]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:11:39,241]\u001b[0m Trial 554 finished with value: 21.748016551790254 and parameters: {'n_hidden': 3, 'learning_rate': 0.002137378913326194, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03663720470076373, 'dropout_rate_Layer_2': 0.24784699164790372, 'dropout_rate_Layer_3': 0.272518931116524, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.487005052396445e-05, 'l1_Layer_2': 2.0841120984472833e-05, 'l1_Layer_3': 0.0006079773506659837, 'n_units_Layer_1': 165, 'n_units_Layer_2': 110, 'n_units_Layer_3': 155}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.75 | sMAPE for Validation Set is: 26.50% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.35 | sMAPE for Test Set is: 39.67% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:11:43,179]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:11:56,753]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:11:57,821]\u001b[0m Trial 556 finished with value: 32.816258239094275 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010974810577854433, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24718615991429926, 'dropout_rate_Layer_2': 0.04245768189733824, 'dropout_rate_Layer_3': 0.01558099436902755, 'dropout_rate_Layer_4': 0.1446944369655724, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011059674736946514, 'l1_Layer_2': 0.00015724087996681405, 'l1_Layer_3': 1.0749362853597473e-05, 'l1_Layer_4': 0.011773878551592449, 'n_units_Layer_1': 290, 'n_units_Layer_2': 260, 'n_units_Layer_3': 290, 'n_units_Layer_4': 60}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.82 | sMAPE for Validation Set is: 36.85% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 139.05 | sMAPE for Test Set is: 83.05% | rMAE for Test Set is: 1.35\n",
      "MAE for Validation Set is: 25.72 | sMAPE for Validation Set is: 29.97% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 108.44 | sMAPE for Test Set is: 61.96% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:11:58,758]\u001b[0m Trial 549 finished with value: 25.721856080114886 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006224057867585783, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3725509253619121, 'dropout_rate_Layer_2': 0.07569289236561418, 'dropout_rate_Layer_3': 0.0430633197071131, 'dropout_rate_Layer_4': 0.18848518408641152, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03598132523544357, 'l1_Layer_2': 0.0001506479164370536, 'l1_Layer_3': 2.4371594309958574e-05, 'l1_Layer_4': 0.0029893215504202767, 'n_units_Layer_1': 285, 'n_units_Layer_2': 260, 'n_units_Layer_3': 290, 'n_units_Layer_4': 285}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:04,529]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:06,698]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:07,315]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:08,041]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:11,311]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:14,364]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:15,588]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:17,927]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:22,905]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:25,838]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:26,339]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:26,425]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.07 | sMAPE for Validation Set is: 26.54% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 59.42 | sMAPE for Test Set is: 40.56% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:12:30,144]\u001b[0m Trial 557 finished with value: 22.06939111418343 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011113557818032526, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10508528193360064, 'dropout_rate_Layer_2': 0.30978204274765364, 'dropout_rate_Layer_3': 0.2101544979009318, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004282795585583929, 'l1_Layer_2': 0.001821538591488547, 'l1_Layer_3': 0.0007336073840330548, 'n_units_Layer_1': 240, 'n_units_Layer_2': 200, 'n_units_Layer_3': 95}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:34,515]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:34,663]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:35,349]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:42,330]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:45,761]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:50,523]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:53,857]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:53,938]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:56,685]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:12:59,792]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:13:03,460]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:13:06,308]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:13:09,503]\u001b[0m Trial 579 finished with value: 22.672967300561556 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014424999283630408, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10522389063544914, 'dropout_rate_Layer_2': 0.3197387691355529, 'dropout_rate_Layer_3': 0.17768398372930785, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008912047673840752, 'l1_Layer_2': 0.002569452145285271, 'l1_Layer_3': 0.0007130576091536984, 'n_units_Layer_1': 230, 'n_units_Layer_2': 205, 'n_units_Layer_3': 80}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.67 | sMAPE for Validation Set is: 27.93% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.17 | sMAPE for Test Set is: 41.12% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:13:12,255]\u001b[0m Trial 584 finished with value: 22.22014068604834 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020450266786559883, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015479479242810845, 'dropout_rate_Layer_2': 0.24624105738694715, 'dropout_rate_Layer_3': 0.20922585635891744, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2533707683006346e-05, 'l1_Layer_2': 1.2441876751239179e-05, 'l1_Layer_3': 0.0005858018944623311, 'n_units_Layer_1': 165, 'n_units_Layer_2': 105, 'n_units_Layer_3': 130}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.22 | sMAPE for Validation Set is: 27.41% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.82 | sMAPE for Test Set is: 40.38% | rMAE for Test Set is: 0.55\n",
      "MAE for Validation Set is: 21.91 | sMAPE for Validation Set is: 26.80% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.40 | sMAPE for Test Set is: 40.11% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:13:14,783]\u001b[0m Trial 583 finished with value: 21.91132788634667 and parameters: {'n_hidden': 3, 'learning_rate': 0.002130209019168443, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05289675031167335, 'dropout_rate_Layer_2': 0.22802956297796745, 'dropout_rate_Layer_3': 0.2100386147233497, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3571690712898941e-05, 'l1_Layer_2': 1.588293093595582e-05, 'l1_Layer_3': 0.00025032032118739493, 'n_units_Layer_1': 165, 'n_units_Layer_2': 110, 'n_units_Layer_3': 130}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:13:18,023]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:13:19,859]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:13:25,391]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:13:29,078]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:13:33,234]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:13:36,781]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:13:39,682]\u001b[0m Trial 588 finished with value: 22.241375167756107 and parameters: {'n_hidden': 3, 'learning_rate': 0.001988519757526773, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21261220840035483, 'dropout_rate_Layer_2': 0.330150951364082, 'dropout_rate_Layer_3': 0.20472855554948607, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003245304620453087, 'l1_Layer_2': 0.0013133444318199911, 'l1_Layer_3': 0.0008577003544199368, 'n_units_Layer_1': 245, 'n_units_Layer_2': 210, 'n_units_Layer_3': 75}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.24 | sMAPE for Validation Set is: 27.07% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 59.49 | sMAPE for Test Set is: 40.88% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:13:44,655]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:13:51,214]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:13:54,438]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:13:57,441]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:02,633]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:08,377]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:08,773]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:14,125]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:14,392]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:18,782]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:21,992]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:24,541]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:26,784]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:29,902]\u001b[0m Trial 587 finished with value: 27.20885738095536 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007803731208231901, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35599096255480117, 'dropout_rate_Layer_2': 0.02074601736964003, 'dropout_rate_Layer_3': 0.015801073657068766, 'dropout_rate_Layer_4': 0.18859698456617427, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.06326670459964344, 'l1_Layer_2': 0.0036585910625453093, 'l1_Layer_3': 2.2470151867982718e-05, 'l1_Layer_4': 0.0046140485890857385, 'n_units_Layer_1': 290, 'n_units_Layer_2': 235, 'n_units_Layer_3': 280, 'n_units_Layer_4': 290}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.21 | sMAPE for Validation Set is: 31.04% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 120.84 | sMAPE for Test Set is: 70.19% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:14:30,050]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:34,607]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:37,563]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:38,392]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:40,505]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:45,070]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:47,261]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:48,353]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:50,137]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:52,761]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:14:58,121]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:03,686]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:04,652]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:09,003]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:10,886]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:13,643]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:16,119]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:18,316]\u001b[0m Trial 606 finished with value: 32.168580482117065 and parameters: {'n_hidden': 4, 'learning_rate': 0.001197684392805718, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3011629599550603, 'dropout_rate_Layer_2': 0.014207088129514479, 'dropout_rate_Layer_3': 0.01703239064717693, 'dropout_rate_Layer_4': 0.18700340566983856, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05711086875790646, 'l1_Layer_2': 0.0012446434632731533, 'l1_Layer_3': 4.721777466774724e-05, 'l1_Layer_4': 1.5164397889980203e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 235, 'n_units_Layer_3': 280, 'n_units_Layer_4': 290}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.17 | sMAPE for Validation Set is: 36.13% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 136.19 | sMAPE for Test Set is: 81.16% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:15:18,786]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:20,902]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:24,734]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:27,028]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:27,444]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:29,469]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:32,552]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:35,393]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:37,237]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:39,449]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:42,934]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:45,666]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:49,728]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.00 | sMAPE for Validation Set is: 26.93% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.02 | sMAPE for Test Set is: 39.76% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:15:51,082]\u001b[0m Trial 633 finished with value: 21.998531603694335 and parameters: {'n_hidden': 3, 'learning_rate': 0.00228739257359357, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011437481329571689, 'dropout_rate_Layer_2': 0.2603947571855368, 'dropout_rate_Layer_3': 0.18300733415600307, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5592387956210255e-05, 'l1_Layer_2': 1.5756580047245065e-05, 'l1_Layer_3': 0.001293253216117335, 'n_units_Layer_1': 155, 'n_units_Layer_2': 160, 'n_units_Layer_3': 195}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:54,608]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:54,766]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:15:58,732]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:01,865]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:05,569]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:07,713]\u001b[0m Trial 641 finished with value: 22.23901249549465 and parameters: {'n_hidden': 3, 'learning_rate': 0.0064153261603210315, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06469350632541776, 'dropout_rate_Layer_2': 0.1820932071483265, 'dropout_rate_Layer_3': 0.09748823753997972, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026286340568574245, 'l1_Layer_2': 1.9859601520212652e-05, 'l1_Layer_3': 1.0145773915661933e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 100, 'n_units_Layer_3': 220}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.24 | sMAPE for Validation Set is: 26.82% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.93 | sMAPE for Test Set is: 40.37% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:16:08,983]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:10,403]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:12,422]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:16,490]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:21,959]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:22,028]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:25,721]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:31,971]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:33,958]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:37,667]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:41,529]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:44,915]\u001b[0m Trial 657 finished with value: 21.991503673548323 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034883014792581506, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0969730337869512, 'dropout_rate_Layer_2': 0.22419868358413464, 'dropout_rate_Layer_3': 0.2566783293080701, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.6438406808550365e-05, 'l1_Layer_2': 6.699909038826668e-05, 'l1_Layer_3': 0.0007182651228684399, 'n_units_Layer_1': 175, 'n_units_Layer_2': 80, 'n_units_Layer_3': 180}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.99 | sMAPE for Validation Set is: 27.14% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.51 | sMAPE for Test Set is: 40.25% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:16:46,704]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:49,865]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:53,345]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:53,915]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:16:53,944]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:17:01,429]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:17:01,799]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:17:07,552]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:17:07,746]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:17:12,355]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:17:15,541]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:17:16,528]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:17:20,239]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:17:23,070]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:17:24,143]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:17:24,769]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:17:25,928]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:17:32,073]\u001b[0m Trial 669 finished with value: 23.164095748238946 and parameters: {'n_hidden': 3, 'learning_rate': 0.00723594001604487, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0068464701896105845, 'dropout_rate_Layer_2': 0.3330432879674654, 'dropout_rate_Layer_3': 0.11586038806768274, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013005391652129937, 'l1_Layer_2': 0.0015528039734348646, 'l1_Layer_3': 0.0005012508944536203, 'n_units_Layer_1': 235, 'n_units_Layer_2': 195, 'n_units_Layer_3': 75}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.16 | sMAPE for Validation Set is: 28.41% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 56.66 | sMAPE for Test Set is: 40.07% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:17:33,795]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:17:35,280]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:17:39,603]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:17:48,254]\u001b[0m Trial 681 finished with value: 21.599485840130203 and parameters: {'n_hidden': 3, 'learning_rate': 0.002790850101636726, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03582239546782018, 'dropout_rate_Layer_2': 0.1904095962868763, 'dropout_rate_Layer_3': 0.2676541701169567, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1211830884538733e-05, 'l1_Layer_2': 8.795224781729415e-05, 'l1_Layer_3': 0.0004960288372500148, 'n_units_Layer_1': 135, 'n_units_Layer_2': 100, 'n_units_Layer_3': 170}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.60 | sMAPE for Validation Set is: 26.32% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 57.30 | sMAPE for Test Set is: 40.26% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:17:51,587]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:17:59,291]\u001b[0m Trial 679 finished with value: 22.014045974600027 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015968096063691387, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10712568739259255, 'dropout_rate_Layer_2': 0.30222000999979715, 'dropout_rate_Layer_3': 0.1746602222332761, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007539793579465471, 'l1_Layer_2': 0.002701216282656514, 'l1_Layer_3': 0.0007599895958106967, 'n_units_Layer_1': 230, 'n_units_Layer_2': 205, 'n_units_Layer_3': 80}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.01 | sMAPE for Validation Set is: 27.17% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.15 | sMAPE for Test Set is: 40.65% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:18:00,374]\u001b[0m Trial 682 finished with value: 22.568261796329 and parameters: {'n_hidden': 3, 'learning_rate': 0.00593025596720105, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08619271692288706, 'dropout_rate_Layer_2': 0.3043835517629223, 'dropout_rate_Layer_3': 0.16687452369831493, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5024329252404375e-05, 'l1_Layer_2': 0.003953922898194633, 'l1_Layer_3': 0.0008235040027428362, 'n_units_Layer_1': 230, 'n_units_Layer_2': 205, 'n_units_Layer_3': 95}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.57 | sMAPE for Validation Set is: 27.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.49 | sMAPE for Test Set is: 40.58% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:18:05,638]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:18:05,833]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.56 | sMAPE for Validation Set is: 27.64% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 56.92 | sMAPE for Test Set is: 40.79% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:18:08,302]\u001b[0m Trial 684 finished with value: 22.561032214475528 and parameters: {'n_hidden': 3, 'learning_rate': 0.005893770345379899, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09172767316400506, 'dropout_rate_Layer_2': 0.3391468455115523, 'dropout_rate_Layer_3': 0.046668981549890506, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00796978498002742, 'l1_Layer_2': 0.002651497447888607, 'l1_Layer_3': 0.000774956367598073, 'n_units_Layer_1': 220, 'n_units_Layer_2': 205, 'n_units_Layer_3': 70}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:18:13,030]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:18:14,743]\u001b[0m Trial 683 finished with value: 22.285721603207975 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015333213396681402, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09783357036161817, 'dropout_rate_Layer_2': 0.3419125656624444, 'dropout_rate_Layer_3': 0.1790028073090113, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007783499180343922, 'l1_Layer_2': 0.003060118206945145, 'l1_Layer_3': 0.000782199106969865, 'n_units_Layer_1': 220, 'n_units_Layer_2': 205, 'n_units_Layer_3': 95}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.29 | sMAPE for Validation Set is: 27.26% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.23 | sMAPE for Test Set is: 40.36% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:18:15,177]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:18:18,994]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:18:24,818]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:18:29,035]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:18:32,397]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:18:36,775]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:18:39,970]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:18:44,903]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:18:47,653]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:18:50,806]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:18:51,327]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:18:55,318]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:18:58,095]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:19:01,549]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:19:05,675]\u001b[0m Trial 699 finished with value: 21.580906144116266 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026819126422233473, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03606081813353643, 'dropout_rate_Layer_2': 0.1384253072352237, 'dropout_rate_Layer_3': 0.20684086020945008, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2187157028077268e-05, 'l1_Layer_2': 0.0013628352376713027, 'l1_Layer_3': 0.0010579714489092349, 'n_units_Layer_1': 195, 'n_units_Layer_2': 60, 'n_units_Layer_3': 165}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.58 | sMAPE for Validation Set is: 26.32% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.27 | sMAPE for Test Set is: 39.38% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:19:09,724]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:19:15,854]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:19:36,062]\u001b[0m Trial 687 finished with value: 43.808348414143154 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007895940009911691, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3692640609112294, 'dropout_rate_Layer_2': 0.3899821118459589, 'dropout_rate_Layer_3': 0.07929699861187259, 'dropout_rate_Layer_4': 0.16171990953336274, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012498220611312403, 'l1_Layer_2': 7.398909567798153e-05, 'l1_Layer_3': 7.012869680930011e-05, 'l1_Layer_4': 0.0003684400150208433, 'n_units_Layer_1': 270, 'n_units_Layer_2': 245, 'n_units_Layer_3': 275, 'n_units_Layer_4': 300}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.81 | sMAPE for Validation Set is: 50.82% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 165.10 | sMAPE for Test Set is: 107.84% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:19:42,169]\u001b[0m Trial 708 finished with value: 22.81502315984314 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016130810454532665, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08126260954095935, 'dropout_rate_Layer_2': 0.29748894228075495, 'dropout_rate_Layer_3': 0.174012700911438, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004538414391049951, 'l1_Layer_2': 0.003401476574976058, 'l1_Layer_3': 0.0009147412573038885, 'n_units_Layer_1': 230, 'n_units_Layer_2': 215, 'n_units_Layer_3': 95}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.82 | sMAPE for Validation Set is: 27.63% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 59.56 | sMAPE for Test Set is: 41.36% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:19:45,750]\u001b[0m Trial 704 finished with value: 29.320274675420762 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009176483764955376, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37978478519705405, 'dropout_rate_Layer_2': 0.01630336142524892, 'dropout_rate_Layer_3': 0.00981532217428196, 'dropout_rate_Layer_4': 0.15736100704081768, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02491689046108551, 'l1_Layer_2': 0.007756611828530474, 'l1_Layer_3': 2.3640401819726754e-05, 'l1_Layer_4': 2.8765112211814317e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 220, 'n_units_Layer_3': 275, 'n_units_Layer_4': 265}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.32 | sMAPE for Validation Set is: 32.94% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 129.97 | sMAPE for Test Set is: 76.45% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:19:46,203]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.66 | sMAPE for Validation Set is: 34.33% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 134.45 | sMAPE for Test Set is: 79.59% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:19:49,161]\u001b[0m Trial 706 finished with value: 30.66324479630317 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008983949221214154, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2549372878942359, 'dropout_rate_Layer_2': 0.06265267557023489, 'dropout_rate_Layer_3': 0.008484023063217185, 'dropout_rate_Layer_4': 0.15398128070527659, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02454882655018434, 'l1_Layer_2': 0.006726921235484257, 'l1_Layer_3': 2.5037222501869723e-05, 'l1_Layer_4': 2.8708029636256364e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 220, 'n_units_Layer_3': 275, 'n_units_Layer_4': 265}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:19:53,773]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:19:54,392]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:19:55,394]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:19:55,518]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:01,832]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:02,579]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:03,519]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:03,832]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:09,226]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:13,079]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:16,171]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:20,127]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:20,615]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:25,343]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:25,512]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:30,993]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:32,823]\u001b[0m Trial 720 finished with value: 21.8660687982556 and parameters: {'n_hidden': 3, 'learning_rate': 0.002934199802663345, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04885378458240022, 'dropout_rate_Layer_2': 0.05024736936187836, 'dropout_rate_Layer_3': 0.08662219883991427, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0076006929537458115, 'l1_Layer_2': 1.365561937466723e-05, 'l1_Layer_3': 0.00019833519172356381, 'n_units_Layer_1': 100, 'n_units_Layer_2': 280, 'n_units_Layer_3': 200}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.87 | sMAPE for Validation Set is: 26.22% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.88 | sMAPE for Test Set is: 39.62% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:20:34,776]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:38,243]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:38,703]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:43,409]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:47,844]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:51,657]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:20:58,032]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:00,315]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:05,816]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:09,354]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:12,780]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:13,365]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:14,439]\u001b[0m Trial 722 finished with value: 26.881035179727792 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006087229719013555, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34658367961364195, 'dropout_rate_Layer_2': 0.014612366747196922, 'dropout_rate_Layer_3': 0.023990903291768867, 'dropout_rate_Layer_4': 0.20615530606582552, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0357447605014054, 'l1_Layer_2': 0.008865548421949688, 'l1_Layer_3': 1.0741938051920459e-05, 'l1_Layer_4': 1.4586431562860576e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 245, 'n_units_Layer_3': 290, 'n_units_Layer_4': 275}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.88 | sMAPE for Validation Set is: 30.69% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 115.44 | sMAPE for Test Set is: 66.38% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:21:16,338]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:18,568]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:25,365]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:28,511]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:29,194]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:35,925]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:36,077]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:37,071]\u001b[0m Trial 742 finished with value: 22.79111601461246 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030309916021188602, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09354485781415772, 'dropout_rate_Layer_2': 0.32661043952192564, 'dropout_rate_Layer_3': 0.18471691868146087, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4370880114887653e-05, 'l1_Layer_2': 2.324283632497816e-05, 'l1_Layer_3': 0.0023541888559159684, 'n_units_Layer_1': 235, 'n_units_Layer_2': 200, 'n_units_Layer_3': 70}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.79 | sMAPE for Validation Set is: 27.67% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 60.27 | sMAPE for Test Set is: 41.53% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:21:37,637]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:45,252]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:48,362]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:48,618]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:54,598]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:21:55,241]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:00,337]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:03,725]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:07,606]\u001b[0m Trial 753 finished with value: 22.074730909424563 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018578601469973035, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06859590379638805, 'dropout_rate_Layer_2': 0.18808457320306812, 'dropout_rate_Layer_3': 0.20306749574764232, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6952561179512892e-05, 'l1_Layer_2': 2.7257715534689283e-05, 'l1_Layer_3': 0.00044454411470588016, 'n_units_Layer_1': 195, 'n_units_Layer_2': 110, 'n_units_Layer_3': 140}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.07 | sMAPE for Validation Set is: 26.98% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.73 | sMAPE for Test Set is: 39.59% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:22:09,452]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:13,194]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:15,131]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:17,976]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:20,010]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:22,676]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:24,255]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:29,871]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:34,958]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:38,990]\u001b[0m Trial 750 finished with value: 27.29157575446356 and parameters: {'n_hidden': 4, 'learning_rate': 0.000566713371485705, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34391078083621557, 'dropout_rate_Layer_2': 0.033517180163916895, 'dropout_rate_Layer_3': 0.0538192284911675, 'dropout_rate_Layer_4': 0.20538396078372265, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.03964165142691038, 'l1_Layer_2': 0.0018904180088821368, 'l1_Layer_3': 1.2583253508438711e-05, 'l1_Layer_4': 1.4609872527941498e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 250, 'n_units_Layer_3': 265, 'n_units_Layer_4': 290}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.29 | sMAPE for Validation Set is: 30.96% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 116.43 | sMAPE for Test Set is: 67.45% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:22:39,407]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:39,616]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:45,398]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:47,353]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:47,727]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:49,150]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:22:56,643]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:00,212]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:00,245]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:00,780]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:00,961]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:07,320]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:09,101]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:09,802]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:10,472]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:17,476]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:21,391]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:21,716]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:27,005]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:27,319]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:27,680]\u001b[0m Trial 780 finished with value: 21.953528458659765 and parameters: {'n_hidden': 3, 'learning_rate': 0.001133350903390158, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008269472512779343, 'dropout_rate_Layer_2': 0.15200988252614436, 'dropout_rate_Layer_3': 0.18894390239639233, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.1679184839889066e-05, 'l1_Layer_2': 1.0238091409611796e-05, 'l1_Layer_3': 0.0016578059892485707, 'n_units_Layer_1': 160, 'n_units_Layer_2': 100, 'n_units_Layer_3': 160}. Best is trial 341 with value: 21.4285008467856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.95 | sMAPE for Validation Set is: 26.85% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.34 | sMAPE for Test Set is: 39.34% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:23:33,462]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:33,989]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:34,041]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:34,598]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:43,401]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:44,612]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:46,436]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:49,769]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:51,217]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:52,130]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:53,141]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:58,561]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:59,217]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:23:59,430]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:24:06,371]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:24:06,826]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:24:07,616]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:24:10,354]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:24:13,250]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:24:16,036]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:24:16,884]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:24:20,319]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:24:22,126]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:24:24,894]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:24:28,229]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:24:40,768]\u001b[0m Trial 815 finished with value: 21.332792004487814 and parameters: {'n_hidden': 3, 'learning_rate': 0.0041312015278854594, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02143758810721845, 'dropout_rate_Layer_2': 0.2159864050357828, 'dropout_rate_Layer_3': 0.23878781264729995, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016654570746247612, 'l1_Layer_2': 2.12210495275472e-05, 'l1_Layer_3': 0.001338388614018527, 'n_units_Layer_1': 150, 'n_units_Layer_2': 95, 'n_units_Layer_3': 110}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.33 | sMAPE for Validation Set is: 26.17% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 55.88 | sMAPE for Test Set is: 39.28% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:24:51,601]\u001b[0m Trial 816 finished with value: 22.624166239187037 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005042817262261692, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35994606461862927, 'dropout_rate_Layer_2': 0.012972699585974965, 'dropout_rate_Layer_3': 0.04686157657547892, 'dropout_rate_Layer_4': 0.22430230233653836, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001595923747467687, 'l1_Layer_2': 0.0017015991370288046, 'l1_Layer_3': 1.3623293247975868e-05, 'l1_Layer_4': 1.4062934147397721e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 250, 'n_units_Layer_3': 190, 'n_units_Layer_4': 295}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.62 | sMAPE for Validation Set is: 27.33% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 60.89 | sMAPE for Test Set is: 41.80% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:24:51,990]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:24:53,079]\u001b[0m Trial 812 finished with value: 22.495996056588677 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013938534894272956, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11305575767423175, 'dropout_rate_Layer_2': 0.31953925453861753, 'dropout_rate_Layer_3': 0.16978448675698182, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01198973527766589, 'l1_Layer_2': 0.003876532879609959, 'l1_Layer_3': 0.000520589043167569, 'n_units_Layer_1': 225, 'n_units_Layer_2': 210, 'n_units_Layer_3': 80}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.50 | sMAPE for Validation Set is: 27.39% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 55.68 | sMAPE for Test Set is: 40.16% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:24:56,655]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:24:58,454]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:01,203]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:06,343]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:06,944]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:07,566]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:09,659]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:14,427]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:17,756]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:17,913]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:18,843]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.13 | sMAPE for Validation Set is: 29.52% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 61.48 | sMAPE for Test Set is: 42.56% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:25:23,026]\u001b[0m Trial 817 finished with value: 24.130733680578583 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005020009198285092, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3552167413357309, 'dropout_rate_Layer_2': 0.01029242217417813, 'dropout_rate_Layer_3': 0.2968387586026429, 'dropout_rate_Layer_4': 0.22201924402620965, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.08157877448715598, 'l1_Layer_2': 0.0025965538660719786, 'l1_Layer_3': 1.3610419980823363e-05, 'l1_Layer_4': 1.4134891375833976e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 255, 'n_units_Layer_3': 285, 'n_units_Layer_4': 295}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:28,346]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:29,228]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:29,961]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:33,865]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:38,375]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:39,025]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:43,408]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:43,637]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:43,771]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:50,900]\u001b[0m Trial 831 finished with value: 25.23326275793534 and parameters: {'n_hidden': 4, 'learning_rate': 0.01647819916560015, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3589597869725924, 'dropout_rate_Layer_2': 0.20666686576399684, 'dropout_rate_Layer_3': 0.06684929009920419, 'dropout_rate_Layer_4': 0.21431612250839177, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00020521397608579532, 'l1_Layer_2': 0.002745615846015219, 'l1_Layer_3': 1.41008328271509e-05, 'l1_Layer_4': 7.511369575133434e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 270, 'n_units_Layer_3': 180, 'n_units_Layer_4': 295}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:50,971]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.23 | sMAPE for Validation Set is: 31.27% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 70.10 | sMAPE for Test Set is: 44.61% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:25:51,066]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:57,835]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:25:58,535]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:02,479]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:02,617]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:07,326]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:09,156]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:09,867]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:14,851]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:16,616]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:17,523]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:20,514]\u001b[0m Trial 839 finished with value: 25.777089103782203 and parameters: {'n_hidden': 4, 'learning_rate': 0.016427648321223686, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38193439212714725, 'dropout_rate_Layer_2': 0.011637784258296289, 'dropout_rate_Layer_3': 0.3402231705059374, 'dropout_rate_Layer_4': 0.26605993163885094, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010342685948507142, 'l1_Layer_2': 0.010910680308069527, 'l1_Layer_3': 1.5328060329142614e-05, 'l1_Layer_4': 1.42828579517023e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 270, 'n_units_Layer_3': 190, 'n_units_Layer_4': 275}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.78 | sMAPE for Validation Set is: 31.50% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 79.87 | sMAPE for Test Set is: 46.74% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:26:24,043]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:25,161]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:30,497]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:30,622]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:36,714]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:40,096]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:43,499]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:44,331]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:46,213]\u001b[0m Trial 856 finished with value: 25.03719107905802 and parameters: {'n_hidden': 4, 'learning_rate': 0.00802076790542468, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36151065349835343, 'dropout_rate_Layer_2': 0.20360971041619863, 'dropout_rate_Layer_3': 0.34767957619104906, 'dropout_rate_Layer_4': 0.2911644399240014, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00019078617713108305, 'l1_Layer_2': 0.0008780660493516868, 'l1_Layer_3': 1.4910340951794952e-05, 'l1_Layer_4': 6.778815534725428e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 290, 'n_units_Layer_3': 180, 'n_units_Layer_4': 275}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.04 | sMAPE for Validation Set is: 31.26% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 66.13 | sMAPE for Test Set is: 43.46% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:26:49,433]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:53,614]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:54,574]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:26:57,034]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:01,652]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:02,038]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:12,971]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:17,639]\u001b[0m Trial 861 finished with value: 22.255301431447435 and parameters: {'n_hidden': 3, 'learning_rate': 0.001981098163217128, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0968681395443277, 'dropout_rate_Layer_2': 0.3013363819204952, 'dropout_rate_Layer_3': 0.18988149828721682, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009955372650173535, 'l1_Layer_2': 0.002102946139225951, 'l1_Layer_3': 0.0008218431927855998, 'n_units_Layer_1': 245, 'n_units_Layer_2': 200, 'n_units_Layer_3': 125}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.26 | sMAPE for Validation Set is: 26.98% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.04 | sMAPE for Test Set is: 40.03% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:27:19,969]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:20,145]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:20,718]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:22,326]\u001b[0m Trial 868 finished with value: 24.411747310991842 and parameters: {'n_hidden': 4, 'learning_rate': 0.012087894975192139, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3660357745346475, 'dropout_rate_Layer_2': 0.2057274953867212, 'dropout_rate_Layer_3': 0.34084112375041375, 'dropout_rate_Layer_4': 0.29870561870931867, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00016105121633693407, 'l1_Layer_2': 0.0008647957610995323, 'l1_Layer_3': 1.6567340672540446e-05, 'l1_Layer_4': 5.941400489397025e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 300, 'n_units_Layer_3': 190, 'n_units_Layer_4': 265}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.41 | sMAPE for Validation Set is: 29.47% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 77.54 | sMAPE for Test Set is: 45.35% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:27:26,953]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:27,133]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:29,384]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:33,368]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:37,603]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:38,267]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:42,716]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:42,917]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:47,619]\u001b[0m Trial 878 finished with value: 25.90698219303756 and parameters: {'n_hidden': 4, 'learning_rate': 0.010340750162012694, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36325899684161067, 'dropout_rate_Layer_2': 0.20094094876174223, 'dropout_rate_Layer_3': 0.33607692082488905, 'dropout_rate_Layer_4': 0.2758574294425125, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001611101008131807, 'l1_Layer_2': 0.0007616658702525481, 'l1_Layer_3': 1.6719696799030554e-05, 'l1_Layer_4': 9.227902999602643e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 300, 'n_units_Layer_3': 190, 'n_units_Layer_4': 260}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.91 | sMAPE for Validation Set is: 30.87% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 95.26 | sMAPE for Test Set is: 50.25% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:27:48,813]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:49,099]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:55,696]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:27:55,974]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:28:01,542]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:28:04,855]\u001b[0m Trial 882 finished with value: 25.319784430091165 and parameters: {'n_hidden': 4, 'learning_rate': 0.009880947095050113, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36312384176687723, 'dropout_rate_Layer_2': 0.20875873498212405, 'dropout_rate_Layer_3': 0.340755847213744, 'dropout_rate_Layer_4': 0.3237969618898196, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00017653171638099468, 'l1_Layer_2': 0.000874408189930734, 'l1_Layer_3': 1.8417248769948482e-05, 'l1_Layer_4': 0.0001845819243135704, 'n_units_Layer_1': 280, 'n_units_Layer_2': 295, 'n_units_Layer_3': 190, 'n_units_Layer_4': 260}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.32 | sMAPE for Validation Set is: 30.15% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 84.03 | sMAPE for Test Set is: 47.39% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:28:05,922]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:28:08,924]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:28:18,543]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.43 | sMAPE for Validation Set is: 29.53% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 62.08 | sMAPE for Test Set is: 43.03% | rMAE for Test Set is: 0.60\n",
      "MAE for Validation Set is: 23.62 | sMAPE for Validation Set is: 28.78% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.85 | sMAPE for Test Set is: 41.39% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:28:21,268]\u001b[0m Trial 885 finished with value: 23.42978514302987 and parameters: {'n_hidden': 4, 'learning_rate': 0.007404772457663861, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38437175998170703, 'dropout_rate_Layer_2': 0.2430900803981047, 'dropout_rate_Layer_3': 0.37174291772501417, 'dropout_rate_Layer_4': 0.3044837269296016, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.39492316597677e-05, 'l1_Layer_2': 0.0005205171943100363, 'l1_Layer_3': 1.454065929606878e-05, 'l1_Layer_4': 0.00016544090452602368, 'n_units_Layer_1': 245, 'n_units_Layer_2': 285, 'n_units_Layer_3': 155, 'n_units_Layer_4': 275}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:28:21,279]\u001b[0m Trial 889 finished with value: 23.62135774350921 and parameters: {'n_hidden': 4, 'learning_rate': 0.007911154669121158, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37682705042067094, 'dropout_rate_Layer_2': 0.18913154701040652, 'dropout_rate_Layer_3': 0.36843587417485435, 'dropout_rate_Layer_4': 0.29955959296962087, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.740788971087495e-05, 'l1_Layer_2': 0.0004614733833577776, 'l1_Layer_3': 1.4635780375091063e-05, 'l1_Layer_4': 6.704062536854213e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 290, 'n_units_Layer_3': 195, 'n_units_Layer_4': 270}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:28:25,941]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:28:28,133]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:28:31,391]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:28:34,695]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:28:39,148]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:28:42,258]\u001b[0m Trial 893 finished with value: 21.92061173868801 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016271599719714233, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09998288775470286, 'dropout_rate_Layer_2': 0.31123577010329107, 'dropout_rate_Layer_3': 0.17267837275227382, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0090300613732153, 'l1_Layer_2': 0.002046810354078296, 'l1_Layer_3': 0.0006657541041989143, 'n_units_Layer_1': 250, 'n_units_Layer_2': 205, 'n_units_Layer_3': 120}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.92 | sMAPE for Validation Set is: 26.54% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.62 | sMAPE for Test Set is: 39.25% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:28:42,716]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:28:48,197]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:28:51,367]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:28:53,836]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:28:57,848]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:29:01,334]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:29:05,203]\u001b[0m Trial 900 finished with value: 24.591487751748534 and parameters: {'n_hidden': 4, 'learning_rate': 0.01206522637044353, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3241107616079215, 'dropout_rate_Layer_2': 0.18137979064042364, 'dropout_rate_Layer_3': 0.3622760300253337, 'dropout_rate_Layer_4': 0.32448609839950604, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00023566360288629977, 'l1_Layer_2': 0.0004399086749829427, 'l1_Layer_3': 1.368774998940488e-05, 'l1_Layer_4': 0.00017422164728377471, 'n_units_Layer_1': 245, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175, 'n_units_Layer_4': 240}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.59 | sMAPE for Validation Set is: 30.13% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 71.83 | sMAPE for Test Set is: 47.07% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:29:09,035]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:29:09,924]\u001b[0m Trial 905 finished with value: 24.460481885287574 and parameters: {'n_hidden': 3, 'learning_rate': 0.012937583249657877, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31944653765026826, 'dropout_rate_Layer_2': 0.1894887584663302, 'dropout_rate_Layer_3': 0.3680577560847716, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023323119756165305, 'l1_Layer_2': 0.0009740519587699314, 'l1_Layer_3': 1.4634493938014973e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 300, 'n_units_Layer_3': 180}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.46 | sMAPE for Validation Set is: 29.96% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 74.74 | sMAPE for Test Set is: 48.48% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:29:14,200]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:29:16,599]\u001b[0m Trial 908 finished with value: 24.625056415723027 and parameters: {'n_hidden': 3, 'learning_rate': 0.008357341475189425, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3366062821754378, 'dropout_rate_Layer_2': 0.18795077402957405, 'dropout_rate_Layer_3': 0.36988599245455595, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024839866226530633, 'l1_Layer_2': 0.0009569681884912844, 'l1_Layer_3': 1.3828682648830988e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 300, 'n_units_Layer_3': 160}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.63 | sMAPE for Validation Set is: 29.79% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 76.13 | sMAPE for Test Set is: 46.15% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:29:16,952]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:29:17,539]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:29:23,818]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:29:41,179]\u001b[0m Trial 916 finished with value: 23.985709415023223 and parameters: {'n_hidden': 3, 'learning_rate': 0.012539618240042837, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32432233368709273, 'dropout_rate_Layer_2': 0.18893285613445124, 'dropout_rate_Layer_3': 0.36921375107822896, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024437700499019944, 'l1_Layer_2': 0.00036588015058290326, 'l1_Layer_3': 1.3289041772911017e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 300, 'n_units_Layer_3': 160}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.99 | sMAPE for Validation Set is: 29.35% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 68.07 | sMAPE for Test Set is: 45.62% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:29:45,484]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:29:48,309]\u001b[0m Trial 914 finished with value: 22.122388697374248 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016791015510928097, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09856708890786497, 'dropout_rate_Layer_2': 0.3057830286786417, 'dropout_rate_Layer_3': 0.06340345192131246, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009893725288946243, 'l1_Layer_2': 0.0012219221535946002, 'l1_Layer_3': 0.0009079694729707214, 'n_units_Layer_1': 245, 'n_units_Layer_2': 215, 'n_units_Layer_3': 115}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.12 | sMAPE for Validation Set is: 26.54% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 59.06 | sMAPE for Test Set is: 40.21% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:29:49,943]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:29:53,834]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:29:58,951]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:29:59,923]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:30:03,167]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:30:06,551]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:30:09,391]\u001b[0m Trial 918 finished with value: 21.775630448090723 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015868073747841744, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07928557137376219, 'dropout_rate_Layer_2': 0.2077987450300266, 'dropout_rate_Layer_3': 0.21637366658252966, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5135700187002825e-05, 'l1_Layer_2': 4.6957993501623456e-05, 'l1_Layer_3': 0.0012077806508238858, 'n_units_Layer_1': 180, 'n_units_Layer_2': 105, 'n_units_Layer_3': 165}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.78 | sMAPE for Validation Set is: 26.71% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.61 | sMAPE for Test Set is: 39.86% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:30:11,384]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:30:13,585]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:30:15,612]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:30:18,825]\u001b[0m Trial 901 finished with value: 22.226031962551 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016417109923942321, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11474712994371598, 'dropout_rate_Layer_2': 0.307953829148202, 'dropout_rate_Layer_3': 0.027839351286296072, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008809202053692664, 'l1_Layer_2': 0.0021978798324358713, 'l1_Layer_3': 0.0007818305285390441, 'n_units_Layer_1': 230, 'n_units_Layer_2': 215, 'n_units_Layer_3': 120}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.23 | sMAPE for Validation Set is: 26.98% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.79 | sMAPE for Test Set is: 40.64% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:30:19,984]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:30:25,482]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:30:26,478]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:30:30,083]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:30:31,115]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:30:35,259]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:30:39,020]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:30:39,073]\u001b[0m Trial 925 finished with value: 22.095713186510448 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025153218278081662, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09474725057293731, 'dropout_rate_Layer_2': 0.3238323589023957, 'dropout_rate_Layer_3': 0.0639215017033011, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005977422558688438, 'l1_Layer_2': 0.0012581426425763266, 'l1_Layer_3': 0.0030971903241085335, 'n_units_Layer_1': 235, 'n_units_Layer_2': 205, 'n_units_Layer_3': 100}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.10 | sMAPE for Validation Set is: 26.74% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 58.07 | sMAPE for Test Set is: 40.15% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:30:47,011]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:30:48,888]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:30:53,482]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:30:55,075]\u001b[0m Trial 935 finished with value: 24.04334364768958 and parameters: {'n_hidden': 3, 'learning_rate': 0.013346228029587506, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31782756402128254, 'dropout_rate_Layer_2': 0.18315519640238065, 'dropout_rate_Layer_3': 0.3834817872244049, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002788299541025122, 'l1_Layer_2': 0.00039891669245543677, 'l1_Layer_3': 1.921404276518972e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 300, 'n_units_Layer_3': 160}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.04 | sMAPE for Validation Set is: 29.31% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 66.97 | sMAPE for Test Set is: 43.71% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:31:01,290]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:31:02,233]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:31:03,625]\u001b[0m Trial 937 finished with value: 22.931002174669143 and parameters: {'n_hidden': 3, 'learning_rate': 0.005206027623249887, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.317419618189251, 'dropout_rate_Layer_2': 0.18327902574966784, 'dropout_rate_Layer_3': 0.38578503643407386, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002933450810818082, 'l1_Layer_2': 0.0003876882941996247, 'l1_Layer_3': 1.8465528889931556e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 300, 'n_units_Layer_3': 160}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.93 | sMAPE for Validation Set is: 27.81% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 64.83 | sMAPE for Test Set is: 42.44% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:31:03,979]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:31:04,992]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:31:12,736]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:31:13,146]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:31:18,490]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:31:18,951]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:31:23,239]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:31:24,955]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:31:28,532]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:31:31,631]\u001b[0m Trial 949 finished with value: 23.933111056273656 and parameters: {'n_hidden': 3, 'learning_rate': 0.011816096295180932, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30715978408574834, 'dropout_rate_Layer_2': 0.24150513759949502, 'dropout_rate_Layer_3': 0.3979863055182455, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.433041836972127e-05, 'l1_Layer_2': 0.00034830264199255237, 'l1_Layer_3': 2.0705884197018255e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 285, 'n_units_Layer_3': 135}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.93 | sMAPE for Validation Set is: 29.45% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 69.25 | sMAPE for Test Set is: 44.99% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:31:34,128]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:31:34,290]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:31:43,216]\u001b[0m Trial 955 finished with value: 22.517905958402537 and parameters: {'n_hidden': 3, 'learning_rate': 0.005725134147071569, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06549576855550643, 'dropout_rate_Layer_2': 0.2708970832957832, 'dropout_rate_Layer_3': 0.3889125803881319, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00031522381885623385, 'l1_Layer_2': 0.00035883290917281885, 'l1_Layer_3': 3.152338714212651e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 285, 'n_units_Layer_3': 160}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.52 | sMAPE for Validation Set is: 27.20% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 60.90 | sMAPE for Test Set is: 41.36% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:31:43,576]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:31:43,707]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:31:51,477]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:31:52,709]\u001b[0m Trial 956 finished with value: 21.748251780231442 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014452528707433181, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07434361414261116, 'dropout_rate_Layer_2': 0.2082543784685414, 'dropout_rate_Layer_3': 0.19348337472556254, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.461348224144107e-05, 'l1_Layer_2': 4.3333445595666e-05, 'l1_Layer_3': 0.0013503090477376897, 'n_units_Layer_1': 165, 'n_units_Layer_2': 100, 'n_units_Layer_3': 180}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.75 | sMAPE for Validation Set is: 26.56% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.33 | sMAPE for Test Set is: 39.61% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:31:57,837]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:31:59,599]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:03,264]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:04,302]\u001b[0m Trial 958 finished with value: 23.78807925704166 and parameters: {'n_hidden': 3, 'learning_rate': 0.005185063987523155, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2982562992558357, 'dropout_rate_Layer_2': 0.28640861342677826, 'dropout_rate_Layer_3': 0.3812654378122122, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007757006170704478, 'l1_Layer_2': 0.00035170601652217547, 'l1_Layer_3': 3.027116510302147e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 285, 'n_units_Layer_3': 155}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.79 | sMAPE for Validation Set is: 30.19% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 71.02 | sMAPE for Test Set is: 43.83% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:32:08,025]\u001b[0m Trial 962 finished with value: 24.122834061405296 and parameters: {'n_hidden': 3, 'learning_rate': 0.004615983278374876, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13318968696877498, 'dropout_rate_Layer_2': 0.29103192745814055, 'dropout_rate_Layer_3': 0.383149518962356, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00031471448330484375, 'l1_Layer_2': 0.00021558338279217547, 'l1_Layer_3': 2.8845849453413784e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 280, 'n_units_Layer_3': 155}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.12 | sMAPE for Validation Set is: 29.51% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 68.99 | sMAPE for Test Set is: 43.68% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:32:10,793]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:11,523]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:15,250]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:17,381]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:18,689]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.03 | sMAPE for Validation Set is: 27.08% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.98 | sMAPE for Test Set is: 40.04% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:32:22,970]\u001b[0m Trial 963 finished with value: 22.031011652239226 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021351768845842473, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10232968178205809, 'dropout_rate_Layer_2': 0.21307441851975467, 'dropout_rate_Layer_3': 0.25023151499467666, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.503118391358729e-05, 'l1_Layer_2': 5.001811113208847e-05, 'l1_Layer_3': 0.0008030430266276313, 'n_units_Layer_1': 180, 'n_units_Layer_2': 70, 'n_units_Layer_3': 190}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:23,184]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:24,280]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:24,407]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:29,972]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:30,598]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:35,247]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:36,773]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:38,412]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:44,099]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:44,399]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:44,399]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:52,570]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:52,813]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:56,769]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:32:57,052]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.76 | sMAPE for Validation Set is: 29.54% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 73.76 | sMAPE for Test Set is: 45.15% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:33:01,675]\u001b[0m Trial 983 finished with value: 24.756409166052773 and parameters: {'n_hidden': 3, 'learning_rate': 0.005113955621214029, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.060616875761160066, 'dropout_rate_Layer_2': 0.2922583095937311, 'dropout_rate_Layer_3': 0.38092150134991926, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003502224971655602, 'l1_Layer_2': 0.00022856022815226736, 'l1_Layer_3': 3.092741749246576e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 285, 'n_units_Layer_3': 155}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:33:05,432]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:33:08,150]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:33:08,831]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:33:13,042]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:33:17,120]\u001b[0m Trial 981 finished with value: 22.509818264510155 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031270102689997625, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08544474850354722, 'dropout_rate_Layer_2': 0.2876225121090631, 'dropout_rate_Layer_3': 0.06683973818766095, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.030928076226952e-05, 'l1_Layer_2': 0.0036960637048232396, 'l1_Layer_3': 0.0009489149883580105, 'n_units_Layer_1': 235, 'n_units_Layer_2': 210, 'n_units_Layer_3': 60}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.51 | sMAPE for Validation Set is: 27.18% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 61.82 | sMAPE for Test Set is: 41.82% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:33:17,670]\u001b[0m Trial 987 finished with value: 23.6771537423872 and parameters: {'n_hidden': 3, 'learning_rate': 0.005023083628624508, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14815653008057103, 'dropout_rate_Layer_2': 0.3004711349501927, 'dropout_rate_Layer_3': 0.38457638193556404, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00032637390543944887, 'l1_Layer_2': 0.00020993503565461147, 'l1_Layer_3': 2.920573516514472e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 285, 'n_units_Layer_3': 155}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.68 | sMAPE for Validation Set is: 28.39% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 76.59 | sMAPE for Test Set is: 45.40% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:33:21,896]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:33:22,760]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:33:26,350]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:33:29,946]\u001b[0m Trial 993 finished with value: 21.815818225452762 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016800384559489448, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12003759262870747, 'dropout_rate_Layer_2': 0.1892947619937495, 'dropout_rate_Layer_3': 0.2030021380726271, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0128455168686322e-05, 'l1_Layer_2': 3.233038374088653e-05, 'l1_Layer_3': 0.000984676581793536, 'n_units_Layer_1': 155, 'n_units_Layer_2': 135, 'n_units_Layer_3': 145}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.82 | sMAPE for Validation Set is: 26.68% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.29 | sMAPE for Test Set is: 39.70% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:33:34,103]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:33:36,471]\u001b[0m Trial 992 finished with value: 22.254896659644626 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032766810030281286, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08511981086200547, 'dropout_rate_Layer_2': 0.3535290712830672, 'dropout_rate_Layer_3': 0.15135326987269013, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005039645787663735, 'l1_Layer_2': 0.0018798852182476812, 'l1_Layer_3': 0.0008026636765931323, 'n_units_Layer_1': 180, 'n_units_Layer_2': 205, 'n_units_Layer_3': 55}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.25 | sMAPE for Validation Set is: 26.98% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.76 | sMAPE for Test Set is: 40.26% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:33:37,527]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:33:42,365]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:33:42,871]\u001b[0m Trial 997 finished with value: 21.74940925374447 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017296586155379713, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11869732146414073, 'dropout_rate_Layer_2': 0.20819516257526094, 'dropout_rate_Layer_3': 0.27153650126247963, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5648813714074898e-05, 'l1_Layer_2': 0.0001808836366451038, 'l1_Layer_3': 0.0009833951075153124, 'n_units_Layer_1': 185, 'n_units_Layer_2': 95, 'n_units_Layer_3': 145}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.75 | sMAPE for Validation Set is: 26.74% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.52 | sMAPE for Test Set is: 39.68% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:33:46,380]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:33:50,537]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:33:52,241]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:33:54,324]\u001b[0m Trial 999 finished with value: 22.324697497889986 and parameters: {'n_hidden': 3, 'learning_rate': 0.002859297316549159, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0886974460569351, 'dropout_rate_Layer_2': 0.28538244425785375, 'dropout_rate_Layer_3': 0.07229107492487175, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0868023977380612e-05, 'l1_Layer_2': 0.003891186888553698, 'l1_Layer_3': 0.0007392851657407146, 'n_units_Layer_1': 240, 'n_units_Layer_2': 210, 'n_units_Layer_3': 55}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.32 | sMAPE for Validation Set is: 27.03% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 59.72 | sMAPE for Test Set is: 41.16% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:33:55,128]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:34:02,658]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:34:02,808]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:34:08,228]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:34:11,450]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:34:15,374]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:34:20,964]\u001b[0m Trial 1006 finished with value: 21.884885928976583 and parameters: {'n_hidden': 3, 'learning_rate': 0.004590138300310485, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03428400847312279, 'dropout_rate_Layer_2': 0.054805909270313195, 'dropout_rate_Layer_3': 0.0995267725417398, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008785180988162203, 'l1_Layer_2': 0.0005716098003787119, 'l1_Layer_3': 0.0001217436589865701, 'n_units_Layer_1': 85, 'n_units_Layer_2': 210, 'n_units_Layer_3': 215}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.88 | sMAPE for Validation Set is: 26.45% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.28 | sMAPE for Test Set is: 39.56% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:34:22,443]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:34:26,843]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:34:27,695]\u001b[0m Trial 1010 finished with value: 22.211676036636703 and parameters: {'n_hidden': 3, 'learning_rate': 0.003046096880206725, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07616273837239206, 'dropout_rate_Layer_2': 0.36526936108586233, 'dropout_rate_Layer_3': 0.07176033674246898, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0051686346386775415, 'l1_Layer_2': 0.003305237899034739, 'l1_Layer_3': 0.000739583890483037, 'n_units_Layer_1': 165, 'n_units_Layer_2': 210, 'n_units_Layer_3': 60}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.21 | sMAPE for Validation Set is: 27.09% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.40 | sMAPE for Test Set is: 40.42% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:34:32,933]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:34:38,709]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:34:39,683]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:34:44,098]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:34:45,268]\u001b[0m Trial 1016 finished with value: 21.559600449927235 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015766642745141065, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12261724290702986, 'dropout_rate_Layer_2': 0.19719410941085014, 'dropout_rate_Layer_3': 0.2860711283044222, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006114413262315101, 'l1_Layer_2': 2.9911516216420913e-05, 'l1_Layer_3': 0.00097433864634238, 'n_units_Layer_1': 155, 'n_units_Layer_2': 190, 'n_units_Layer_3': 155}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.56 | sMAPE for Validation Set is: 26.46% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 54.35 | sMAPE for Test Set is: 38.82% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:34:50,493]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:34:54,185]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:34:55,474]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:35:02,467]\u001b[0m Trial 1021 finished with value: 21.69110663148174 and parameters: {'n_hidden': 3, 'learning_rate': 0.001519357909549108, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16081747621744408, 'dropout_rate_Layer_2': 0.19722110703074164, 'dropout_rate_Layer_3': 0.004666328821544552, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7837272048324645e-05, 'l1_Layer_2': 2.9252717579749514e-05, 'l1_Layer_3': 0.0009969847726397528, 'n_units_Layer_1': 155, 'n_units_Layer_2': 190, 'n_units_Layer_3': 155}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.69 | sMAPE for Validation Set is: 26.57% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.05 | sMAPE for Test Set is: 39.24% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:35:03,079]\u001b[0m Trial 1018 finished with value: 21.919644885797965 and parameters: {'n_hidden': 3, 'learning_rate': 0.003267471632286085, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0784587137528657, 'dropout_rate_Layer_2': 0.3648841106395807, 'dropout_rate_Layer_3': 0.0745184243807562, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004917627512327231, 'l1_Layer_2': 0.004819594297472907, 'l1_Layer_3': 0.0006987807803715053, 'n_units_Layer_1': 170, 'n_units_Layer_2': 215, 'n_units_Layer_3': 55}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.92 | sMAPE for Validation Set is: 26.67% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.85 | sMAPE for Test Set is: 40.22% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:35:08,645]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:35:13,440]\u001b[0m Trial 1025 finished with value: 24.103313021966343 and parameters: {'n_hidden': 3, 'learning_rate': 0.006304301583270432, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18686317752710502, 'dropout_rate_Layer_2': 0.2703979349994142, 'dropout_rate_Layer_3': 0.35367118834808153, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006570954126238778, 'l1_Layer_2': 0.0003662291595230485, 'l1_Layer_3': 1.83174790330216e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 275, 'n_units_Layer_3': 130}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.10 | sMAPE for Validation Set is: 29.34% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 71.67 | sMAPE for Test Set is: 44.28% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:35:14,132]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:35:20,818]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:35:24,885]\u001b[0m Trial 1026 finished with value: 21.970350909397368 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028629162768635886, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07066218701643558, 'dropout_rate_Layer_2': 0.3660060216356341, 'dropout_rate_Layer_3': 0.08627821525392594, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005408573813050371, 'l1_Layer_2': 0.003625577065276993, 'l1_Layer_3': 0.0009123661988030357, 'n_units_Layer_1': 240, 'n_units_Layer_2': 210, 'n_units_Layer_3': 60}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.97 | sMAPE for Validation Set is: 27.04% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 54.24 | sMAPE for Test Set is: 39.18% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:35:28,926]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:35:29,457]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:35:34,813]\u001b[0m Trial 1029 finished with value: 22.479966676177487 and parameters: {'n_hidden': 3, 'learning_rate': 0.00326369457853626, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08045823522678812, 'dropout_rate_Layer_2': 0.3777507547384804, 'dropout_rate_Layer_3': 0.08755137009827575, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0029689915497956706, 'l1_Layer_2': 0.004604246042642842, 'l1_Layer_3': 0.0009115693980762035, 'n_units_Layer_1': 165, 'n_units_Layer_2': 215, 'n_units_Layer_3': 50}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.48 | sMAPE for Validation Set is: 27.42% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.92 | sMAPE for Test Set is: 40.68% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:35:37,542]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:35:42,189]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:35:42,847]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:35:43,289]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:35:49,199]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:35:51,733]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:35:52,923]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:35:59,946]\u001b[0m Trial 1039 finished with value: 24.132672797812763 and parameters: {'n_hidden': 3, 'learning_rate': 0.0063837895491248966, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11272254461596218, 'dropout_rate_Layer_2': 0.2461179648591022, 'dropout_rate_Layer_3': 0.3236451156237309, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5494659727354604e-05, 'l1_Layer_2': 0.00011631891600118114, 'l1_Layer_3': 0.0013894459654196886, 'n_units_Layer_1': 215, 'n_units_Layer_2': 285, 'n_units_Layer_3': 120}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:36:00,000]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.13 | sMAPE for Validation Set is: 29.98% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 73.38 | sMAPE for Test Set is: 44.90% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:36:00,398]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:36:06,786]\u001b[0m Trial 1043 finished with value: 25.161430726957054 and parameters: {'n_hidden': 3, 'learning_rate': 0.006312115915205608, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08561855728198194, 'dropout_rate_Layer_2': 0.25301136134429036, 'dropout_rate_Layer_3': 0.39066303043566103, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.1914900371290646e-05, 'l1_Layer_2': 0.00019153395269061197, 'l1_Layer_3': 2.2920520141261606e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 275, 'n_units_Layer_3': 120}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.16 | sMAPE for Validation Set is: 31.27% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 69.72 | sMAPE for Test Set is: 44.41% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:36:07,499]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:36:07,643]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:36:13,554]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:36:15,868]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:36:18,506]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:36:21,159]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:36:21,308]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:36:21,990]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:36:29,203]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:36:35,037]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:36:35,339]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:36:36,225]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:36:36,918]\u001b[0m Trial 1055 finished with value: 44.485868954622994 and parameters: {'n_hidden': 3, 'learning_rate': 0.008940973601639191, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3388767598674911, 'dropout_rate_Layer_2': 0.14952751032880246, 'dropout_rate_Layer_3': 0.37840478723165216, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006605253129971831, 'l1_Layer_2': 0.00039610066386844804, 'l1_Layer_3': 5.2467241483687834e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 295, 'n_units_Layer_3': 145}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.49 | sMAPE for Validation Set is: 52.07% | rMAE for Validation Set is: 1.23\n",
      "MAE for Test Set is: 165.68 | sMAPE for Test Set is: 108.57% | rMAE for Test Set is: 1.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:36:46,893]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:36:49,505]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:36:50,008]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:36:56,727]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:37:02,211]\u001b[0m Trial 1060 finished with value: 23.476271939903665 and parameters: {'n_hidden': 3, 'learning_rate': 0.004153039880921153, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32742691413881886, 'dropout_rate_Layer_2': 0.21709463379910005, 'dropout_rate_Layer_3': 0.38853580238681457, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012460196679605006, 'l1_Layer_2': 0.0006243015603014619, 'l1_Layer_3': 2.0061204427010327e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 280, 'n_units_Layer_3': 170}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.48 | sMAPE for Validation Set is: 28.97% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 67.04 | sMAPE for Test Set is: 42.81% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:37:05,974]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:37:06,295]\u001b[0m Trial 1062 finished with value: 24.504302645491048 and parameters: {'n_hidden': 3, 'learning_rate': 0.0041080233150001455, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2949149290210178, 'dropout_rate_Layer_2': 0.26554133920937395, 'dropout_rate_Layer_3': 0.3579229575256885, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012843327065085316, 'l1_Layer_2': 0.0015002299852833845, 'l1_Layer_3': 2.0568960361800247e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 275, 'n_units_Layer_3': 150}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.50 | sMAPE for Validation Set is: 30.62% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 75.28 | sMAPE for Test Set is: 45.05% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:37:11,017]\u001b[0m Trial 1064 finished with value: 23.902572350477598 and parameters: {'n_hidden': 3, 'learning_rate': 0.0039429525372083225, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15032362910714192, 'dropout_rate_Layer_2': 0.21768059190286024, 'dropout_rate_Layer_3': 0.3571792099894648, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003399180481100934, 'l1_Layer_2': 0.0005817819070048632, 'l1_Layer_3': 2.022625302400303e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 275, 'n_units_Layer_3': 150}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.90 | sMAPE for Validation Set is: 29.58% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 68.28 | sMAPE for Test Set is: 43.58% | rMAE for Test Set is: 0.66\n",
      "MAE for Validation Set is: 24.86 | sMAPE for Validation Set is: 30.62% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 84.34 | sMAPE for Test Set is: 47.06% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:37:11,895]\u001b[0m Trial 1063 finished with value: 24.864572645814146 and parameters: {'n_hidden': 3, 'learning_rate': 0.004169079646469639, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18014882435309537, 'dropout_rate_Layer_2': 0.26546361907150423, 'dropout_rate_Layer_3': 0.3600280743137157, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001219537964528515, 'l1_Layer_2': 0.0006717101106788806, 'l1_Layer_3': 2.0800702782009112e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 275, 'n_units_Layer_3': 150}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:37:13,409]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:37:14,375]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:37:19,679]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:37:21,885]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:37:22,928]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:37:26,949]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:37:30,460]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:37:35,676]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:37:36,379]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:37:41,711]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:37:46,581]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:37:49,187]\u001b[0m Trial 1071 finished with value: 24.148763276787278 and parameters: {'n_hidden': 3, 'learning_rate': 0.003150877947856822, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2072964432422691, 'dropout_rate_Layer_2': 0.217671425634908, 'dropout_rate_Layer_3': 0.3905349384954842, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00038163260010660863, 'l1_Layer_2': 0.0005821781694107056, 'l1_Layer_3': 2.7766347580158027e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 285, 'n_units_Layer_3': 170}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.15 | sMAPE for Validation Set is: 30.35% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 74.91 | sMAPE for Test Set is: 44.18% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:37:51,581]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.14 | sMAPE for Validation Set is: 26.81% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.42 | sMAPE for Test Set is: 40.14% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:37:54,764]\u001b[0m Trial 1074 finished with value: 22.142925481170256 and parameters: {'n_hidden': 3, 'learning_rate': 0.002933208568414135, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09558015406891357, 'dropout_rate_Layer_2': 0.3839106411485714, 'dropout_rate_Layer_3': 0.07015118144850159, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004669979752851973, 'l1_Layer_2': 0.00391789447604177, 'l1_Layer_3': 0.0007962154686046243, 'n_units_Layer_1': 165, 'n_units_Layer_2': 205, 'n_units_Layer_3': 65}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:37:58,850]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:38:02,133]\u001b[0m Trial 1079 finished with value: 23.87339047339376 and parameters: {'n_hidden': 3, 'learning_rate': 0.003140845630469437, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12917829881592854, 'dropout_rate_Layer_2': 0.21349342737472018, 'dropout_rate_Layer_3': 0.3907969145868677, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003653382963524032, 'l1_Layer_2': 0.00026565087929989486, 'l1_Layer_3': 2.5353597374556993e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 285, 'n_units_Layer_3': 200}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.87 | sMAPE for Validation Set is: 29.77% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 69.99 | sMAPE for Test Set is: 43.77% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:38:04,835]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:38:08,655]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:38:15,127]\u001b[0m Trial 1081 finished with value: 23.21594382559121 and parameters: {'n_hidden': 3, 'learning_rate': 0.00523555708938225, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1527042948108627, 'dropout_rate_Layer_2': 0.23771041176643573, 'dropout_rate_Layer_3': 0.3711652463974583, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008244718607153807, 'l1_Layer_2': 0.00026505945605832115, 'l1_Layer_3': 1.1725320500458913e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 265, 'n_units_Layer_3': 205}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.22 | sMAPE for Validation Set is: 28.96% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 61.60 | sMAPE for Test Set is: 41.18% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:38:18,880]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.05 | sMAPE for Validation Set is: 26.91% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.47 | sMAPE for Test Set is: 39.88% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:38:21,306]\u001b[0m Trial 1082 finished with value: 22.0471317656169 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028104715301376457, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01188546603275082, 'dropout_rate_Layer_2': 0.38488860704199246, 'dropout_rate_Layer_3': 0.07499678372302505, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004843483256494097, 'l1_Layer_2': 0.003699777968155884, 'l1_Layer_3': 0.0008254672369885197, 'n_units_Layer_1': 165, 'n_units_Layer_2': 280, 'n_units_Layer_3': 60}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:38:23,593]\u001b[0m Trial 1087 finished with value: 24.189075687450238 and parameters: {'n_hidden': 3, 'learning_rate': 0.005464201909605184, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1522575929998696, 'dropout_rate_Layer_2': 0.23493331961083921, 'dropout_rate_Layer_3': 0.3272942480044843, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005585514229441004, 'l1_Layer_2': 0.00026143900711943663, 'l1_Layer_3': 3.9572151553155543e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 265, 'n_units_Layer_3': 205}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.19 | sMAPE for Validation Set is: 30.08% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 71.43 | sMAPE for Test Set is: 44.13% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:38:28,953]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:38:29,264]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:38:29,362]\u001b[0m Trial 1085 finished with value: 22.2513202539325 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029356587329081043, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22321720035989231, 'dropout_rate_Layer_2': 0.39608872086306557, 'dropout_rate_Layer_3': 0.07389144803591713, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004647165582611726, 'l1_Layer_2': 0.0028233134420287457, 'l1_Layer_3': 0.0011417565940483872, 'n_units_Layer_1': 150, 'n_units_Layer_2': 205, 'n_units_Layer_3': 60}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.25 | sMAPE for Validation Set is: 27.15% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 59.70 | sMAPE for Test Set is: 41.35% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:38:29,926]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:38:41,369]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:38:43,402]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:38:43,474]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:38:45,329]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:38:48,388]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:38:49,281]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:38:49,924]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:38:52,819]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:38:58,151]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:38:59,732]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:39:00,946]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:39:01,119]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:39:04,485]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:39:08,881]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:39:12,629]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:39:12,764]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:39:14,768]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:39:23,556]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:39:26,770]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:39:27,393]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:39:32,097]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:39:38,053]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:39:41,875]\u001b[0m Trial 1109 finished with value: 22.427922824592343 and parameters: {'n_hidden': 3, 'learning_rate': 0.00227689707252625, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008963004458192474, 'dropout_rate_Layer_2': 0.39502270275322315, 'dropout_rate_Layer_3': 0.06893470365195659, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0037896896205454832, 'l1_Layer_2': 0.0028721132754289027, 'l1_Layer_3': 0.0008178617610917856, 'n_units_Layer_1': 165, 'n_units_Layer_2': 260, 'n_units_Layer_3': 65}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.43 | sMAPE for Validation Set is: 27.30% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.30 | sMAPE for Test Set is: 40.71% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:39:42,601]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:39:48,023]\u001b[0m Trial 1111 finished with value: 22.78067818293803 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029874220642930743, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24571012260941336, 'dropout_rate_Layer_2': 0.39655820096279326, 'dropout_rate_Layer_3': 0.07423389243069511, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0037780386837409138, 'l1_Layer_2': 0.002794021609804753, 'l1_Layer_3': 0.0007717038411826314, 'n_units_Layer_1': 145, 'n_units_Layer_2': 205, 'n_units_Layer_3': 65}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.78 | sMAPE for Validation Set is: 27.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.61 | sMAPE for Test Set is: 40.62% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:39:48,822]\u001b[0m Trial 1114 finished with value: 21.65497623049916 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017117234517542612, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14542817999252555, 'dropout_rate_Layer_2': 0.19453926682242606, 'dropout_rate_Layer_3': 0.2342652875350414, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0127295905768804e-05, 'l1_Layer_2': 2.6544702016034692e-05, 'l1_Layer_3': 0.0012912945542402638, 'n_units_Layer_1': 155, 'n_units_Layer_2': 120, 'n_units_Layer_3': 135}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.65 | sMAPE for Validation Set is: 26.64% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.96 | sMAPE for Test Set is: 39.64% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:39:54,475]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:39:56,572]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:01,419]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:05,144]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:07,805]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:11,171]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:17,991]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:18,970]\u001b[0m Trial 1118 finished with value: 22.338844679520367 and parameters: {'n_hidden': 3, 'learning_rate': 0.002223156899125692, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006588548318849793, 'dropout_rate_Layer_2': 0.39851793060659235, 'dropout_rate_Layer_3': 0.07738884740659197, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0035446085155504377, 'l1_Layer_2': 0.003878205973642299, 'l1_Layer_3': 6.656722456223558e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 285, 'n_units_Layer_3': 60}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.34 | sMAPE for Validation Set is: 27.25% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.35 | sMAPE for Test Set is: 40.21% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:40:19,333]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:24,317]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:25,716]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:26,882]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:27,574]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:36,258]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:37,593]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:42,806]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:43,849]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:50,314]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:50,700]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:50,825]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:40:51,080]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:41:01,579]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:41:02,047]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.40 | sMAPE for Validation Set is: 29.08% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 63.62 | sMAPE for Test Set is: 42.26% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:41:06,489]\u001b[0m Trial 1139 finished with value: 23.39978651731818 and parameters: {'n_hidden': 3, 'learning_rate': 0.004534318791401845, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14763528679259869, 'dropout_rate_Layer_2': 0.30526978858550075, 'dropout_rate_Layer_3': 0.3915169290410647, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008739707989073516, 'l1_Layer_2': 0.0006898074470110779, 'l1_Layer_3': 2.6334121497749086e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 280, 'n_units_Layer_3': 140}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:41:09,941]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:41:13,958]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:41:14,346]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:41:19,556]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:41:19,994]\u001b[0m Trial 1143 finished with value: 24.35862573707681 and parameters: {'n_hidden': 3, 'learning_rate': 0.0047084225323139085, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11208236422673656, 'dropout_rate_Layer_2': 0.2550659809747768, 'dropout_rate_Layer_3': 0.38983515060579443, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009640019538471645, 'l1_Layer_2': 0.00029083024461383554, 'l1_Layer_3': 2.703806353114743e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 280, 'n_units_Layer_3': 175}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.36 | sMAPE for Validation Set is: 30.99% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 62.50 | sMAPE for Test Set is: 41.58% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:41:20,490]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:41:28,275]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:41:28,479]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.92 | sMAPE for Validation Set is: 26.53% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.67 | sMAPE for Test Set is: 39.93% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:41:32,538]\u001b[0m Trial 1140 finished with value: 21.91904542465908 and parameters: {'n_hidden': 3, 'learning_rate': 0.002634647279946833, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21561846652531347, 'dropout_rate_Layer_2': 0.3873638516108413, 'dropout_rate_Layer_3': 0.05735533646343388, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004249811233017129, 'l1_Layer_2': 0.0032751650529324597, 'l1_Layer_3': 0.00010401155918846882, 'n_units_Layer_1': 245, 'n_units_Layer_2': 300, 'n_units_Layer_3': 160}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:41:36,535]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:41:39,810]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:41:43,276]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:41:44,376]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:41:49,090]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:41:50,248]\u001b[0m Trial 1150 finished with value: 21.73386851015478 and parameters: {'n_hidden': 3, 'learning_rate': 0.002031560795478951, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022223404368571276, 'dropout_rate_Layer_2': 0.3821740318889246, 'dropout_rate_Layer_3': 0.05738561401714782, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0039053735505203903, 'l1_Layer_2': 3.2613047806605674e-05, 'l1_Layer_3': 0.0006096941919603586, 'n_units_Layer_1': 150, 'n_units_Layer_2': 205, 'n_units_Layer_3': 55}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.73 | sMAPE for Validation Set is: 26.50% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 59.36 | sMAPE for Test Set is: 40.34% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:41:55,425]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:41:59,714]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:02,292]\u001b[0m Trial 1152 finished with value: 23.025368319603874 and parameters: {'n_hidden': 3, 'learning_rate': 0.005600065822903743, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16161472903266222, 'dropout_rate_Layer_2': 0.311308307568129, 'dropout_rate_Layer_3': 0.3612525477729563, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005294001601332842, 'l1_Layer_2': 0.0007073616249219085, 'l1_Layer_3': 2.3725745750126725e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 260, 'n_units_Layer_3': 215}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.03 | sMAPE for Validation Set is: 29.30% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 60.62 | sMAPE for Test Set is: 41.64% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:42:04,868]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:07,765]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:10,019]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:16,309]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:19,463]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:19,534]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:21,611]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:28,885]\u001b[0m Trial 1161 finished with value: 21.970061964661827 and parameters: {'n_hidden': 3, 'learning_rate': 0.002028105690857138, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20825213582249702, 'dropout_rate_Layer_2': 0.3880493233167562, 'dropout_rate_Layer_3': 0.05655506377735646, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003998558603897451, 'l1_Layer_2': 2.1614656119529493e-05, 'l1_Layer_3': 0.000171573085254724, 'n_units_Layer_1': 140, 'n_units_Layer_2': 285, 'n_units_Layer_3': 50}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.97 | sMAPE for Validation Set is: 26.79% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 58.83 | sMAPE for Test Set is: 40.17% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:42:30,335]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:30,604]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:31,142]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:32,093]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:41,597]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:42,108]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:43,250]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:43,294]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:49,822]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:51,771]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:53,259]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:55,993]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:58,219]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:42:58,678]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:43:02,304]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:43:06,906]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:43:11,059]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:43:11,816]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:43:11,995]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:43:12,522]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:43:22,648]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:43:25,730]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:43:30,021]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:43:35,331]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:43:35,404]\u001b[0m Trial 1192 finished with value: 21.902103129734517 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030382870222015377, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08303672966583636, 'dropout_rate_Layer_2': 0.17485730566769786, 'dropout_rate_Layer_3': 0.27609052464641387, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9452523225599507e-05, 'l1_Layer_2': 9.301376560324165e-05, 'l1_Layer_3': 0.0005186812406754258, 'n_units_Layer_1': 200, 'n_units_Layer_2': 170, 'n_units_Layer_3': 120}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.90 | sMAPE for Validation Set is: 26.83% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.79 | sMAPE for Test Set is: 39.52% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:43:37,321]\u001b[0m Trial 1188 finished with value: 22.46455173150565 and parameters: {'n_hidden': 3, 'learning_rate': 0.004862441714808289, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07631987254335283, 'dropout_rate_Layer_2': 0.2396348125106647, 'dropout_rate_Layer_3': 0.11994699217584233, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01268058331362198, 'l1_Layer_2': 1.0222854953364194e-05, 'l1_Layer_3': 0.00016609182567031895, 'n_units_Layer_1': 80, 'n_units_Layer_2': 215, 'n_units_Layer_3': 225}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.46 | sMAPE for Validation Set is: 27.28% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 60.41 | sMAPE for Test Set is: 41.16% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:43:43,276]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:43:43,347]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:43:44,612]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:43:45,142]\u001b[0m Trial 1191 finished with value: 21.991300878423772 and parameters: {'n_hidden': 3, 'learning_rate': 0.002771628496349102, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015816009168750516, 'dropout_rate_Layer_2': 0.3820136181281664, 'dropout_rate_Layer_3': 0.05825265147872618, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004005665051491191, 'l1_Layer_2': 1.6350617786296987e-05, 'l1_Layer_3': 0.0006223964887212426, 'n_units_Layer_1': 140, 'n_units_Layer_2': 115, 'n_units_Layer_3': 55}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.99 | sMAPE for Validation Set is: 26.69% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 60.59 | sMAPE for Test Set is: 40.60% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:43:50,352]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:43:51,937]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:00,045]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:00,240]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:01,398]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:02,080]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:08,403]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:11,249]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:11,464]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:13,375]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:14,441]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:23,334]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:24,335]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:28,729]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:29,751]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:35,975]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:36,424]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:39,706]\u001b[0m Trial 1212 finished with value: 24.011148201226913 and parameters: {'n_hidden': 3, 'learning_rate': 0.006802198141732721, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1252361308914187, 'dropout_rate_Layer_2': 0.30611844010134964, 'dropout_rate_Layer_3': 0.2543336782713479, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005578284840290397, 'l1_Layer_2': 0.00046529396325545384, 'l1_Layer_3': 1.7503127841296504e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 270, 'n_units_Layer_3': 195}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.01 | sMAPE for Validation Set is: 30.08% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 66.55 | sMAPE for Test Set is: 42.58% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:44:43,168]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:43,407]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:49,979]\u001b[0m Trial 1209 finished with value: 21.881109257854344 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020352037649279836, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015072302562710593, 'dropout_rate_Layer_2': 0.3892792170497896, 'dropout_rate_Layer_3': 0.37927158778852843, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008051270734144163, 'l1_Layer_2': 8.766297206259512e-05, 'l1_Layer_3': 0.00013035154499363796, 'n_units_Layer_1': 140, 'n_units_Layer_2': 205, 'n_units_Layer_3': 60}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.88 | sMAPE for Validation Set is: 26.58% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 58.26 | sMAPE for Test Set is: 40.43% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:44:50,473]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:51,290]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:51,640]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:58,325]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:44:58,819]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:45:01,725]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:45:06,127]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:45:11,532]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:45:12,111]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:45:17,136]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:45:17,953]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:45:24,792]\u001b[0m Trial 1228 finished with value: 23.163415498387213 and parameters: {'n_hidden': 3, 'learning_rate': 0.00436564492905913, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17582308838281469, 'dropout_rate_Layer_2': 0.3303937188914024, 'dropout_rate_Layer_3': 0.3880033133592811, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004039511340393789, 'l1_Layer_2': 0.0014121741698467469, 'l1_Layer_3': 3.3344325818147606e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 260, 'n_units_Layer_3': 225}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.16 | sMAPE for Validation Set is: 28.73% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 66.22 | sMAPE for Test Set is: 42.28% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:45:31,288]\u001b[0m Trial 1231 finished with value: 23.399448926945524 and parameters: {'n_hidden': 3, 'learning_rate': 0.005051050154721961, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17130444063948347, 'dropout_rate_Layer_2': 0.33747656280213373, 'dropout_rate_Layer_3': 0.31292423655133583, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022107821351215165, 'l1_Layer_2': 0.00020342981594367645, 'l1_Layer_3': 3.1729709092039664e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 295, 'n_units_Layer_3': 165}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.40 | sMAPE for Validation Set is: 28.21% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 70.66 | sMAPE for Test Set is: 43.46% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:45:32,205]\u001b[0m Trial 1232 finished with value: 23.04951221294965 and parameters: {'n_hidden': 3, 'learning_rate': 0.004587257231591426, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18435262348291565, 'dropout_rate_Layer_2': 0.3363331378839954, 'dropout_rate_Layer_3': 0.19817400772631943, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011389693784354398, 'l1_Layer_2': 0.00013856217494061574, 'l1_Layer_3': 2.943633304176176e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 135, 'n_units_Layer_3': 220}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.05 | sMAPE for Validation Set is: 29.23% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.60 | sMAPE for Test Set is: 40.56% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:45:36,920]\u001b[0m Trial 1233 finished with value: 22.715353143392775 and parameters: {'n_hidden': 3, 'learning_rate': 0.003426081738589686, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17298537247704218, 'dropout_rate_Layer_2': 0.3309738219238118, 'dropout_rate_Layer_3': 0.20006208961298708, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020559152554391683, 'l1_Layer_2': 0.0014858607193436297, 'l1_Layer_3': 3.968945049828542e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 260, 'n_units_Layer_3': 215}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.72 | sMAPE for Validation Set is: 27.82% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 63.18 | sMAPE for Test Set is: 41.38% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:45:40,921]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:45:41,045]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:45:47,492]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:45:50,510]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:45:54,719]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:45:59,536]\u001b[0m Trial 1234 finished with value: 22.12920410515432 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022213005105634074, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015459404887429386, 'dropout_rate_Layer_2': 0.39361118687385377, 'dropout_rate_Layer_3': 0.3733806249902246, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009788169112822582, 'l1_Layer_2': 1.7432526473907555e-05, 'l1_Layer_3': 0.00013394040345815215, 'n_units_Layer_1': 130, 'n_units_Layer_2': 205, 'n_units_Layer_3': 60}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.13 | sMAPE for Validation Set is: 26.94% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 58.80 | sMAPE for Test Set is: 40.20% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:46:03,164]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:46:06,785]\u001b[0m Trial 1240 finished with value: 23.162120371692897 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034185115397066057, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17323183233688438, 'dropout_rate_Layer_2': 0.34810911965239477, 'dropout_rate_Layer_3': 0.2732187829917341, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025011700355727843, 'l1_Layer_2': 0.0015702672202260917, 'l1_Layer_3': 4.3934834970703286e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 255, 'n_units_Layer_3': 225}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.16 | sMAPE for Validation Set is: 28.55% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 63.17 | sMAPE for Test Set is: 41.44% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:46:07,471]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:46:07,851]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:46:08,173]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:46:15,829]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:46:16,236]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:46:24,356]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:46:24,605]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:46:25,233]\u001b[0m Trial 1246 finished with value: 21.648530940451213 and parameters: {'n_hidden': 3, 'learning_rate': 0.002263312633990444, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1100297418535274, 'dropout_rate_Layer_2': 0.2028109439862058, 'dropout_rate_Layer_3': 0.034240671742390136, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0428701623505093e-05, 'l1_Layer_2': 2.739238184850792e-05, 'l1_Layer_3': 0.0009553791332597975, 'n_units_Layer_1': 170, 'n_units_Layer_2': 115, 'n_units_Layer_3': 125}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.65 | sMAPE for Validation Set is: 26.33% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 54.57 | sMAPE for Test Set is: 38.85% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:46:26,057]\u001b[0m Trial 1248 finished with value: 21.763135963822027 and parameters: {'n_hidden': 3, 'learning_rate': 0.002363328216613457, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14611693968408018, 'dropout_rate_Layer_2': 0.20044019481807268, 'dropout_rate_Layer_3': 0.038545913864669906, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0748883767619981e-05, 'l1_Layer_2': 4.13374676615116e-05, 'l1_Layer_3': 0.001034621304207291, 'n_units_Layer_1': 165, 'n_units_Layer_2': 115, 'n_units_Layer_3': 150}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.76 | sMAPE for Validation Set is: 26.64% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.40 | sMAPE for Test Set is: 39.38% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:46:33,272]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:46:35,480]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:46:36,438]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:46:37,057]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:46:37,973]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:46:49,661]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:46:50,486]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:46:50,743]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:46:57,869]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:46:59,879]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:02,092]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:02,990]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:09,774]\u001b[0m Trial 1259 finished with value: 22.538472150894407 and parameters: {'n_hidden': 3, 'learning_rate': 0.004437610161737274, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17672858526930427, 'dropout_rate_Layer_2': 0.3503186373527712, 'dropout_rate_Layer_3': 0.19006828748914123, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002423931213414907, 'l1_Layer_2': 0.0014755910629832764, 'l1_Layer_3': 7.515699038349865e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 125, 'n_units_Layer_3': 225}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.54 | sMAPE for Validation Set is: 27.62% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 60.74 | sMAPE for Test Set is: 40.60% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:47:15,076]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:20,870]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:22,064]\u001b[0m Trial 1265 finished with value: 23.207946863152245 and parameters: {'n_hidden': 3, 'learning_rate': 0.004499191177671079, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17542904837138165, 'dropout_rate_Layer_2': 0.34199686514365496, 'dropout_rate_Layer_3': 0.2749093607585675, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002303982626885177, 'l1_Layer_2': 0.001429587524294964, 'l1_Layer_3': 6.161966731029085e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 135, 'n_units_Layer_3': 225}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.21 | sMAPE for Validation Set is: 28.62% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 63.08 | sMAPE for Test Set is: 41.80% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:47:26,948]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:28,010]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.61 | sMAPE for Validation Set is: 27.77% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 59.57 | sMAPE for Test Set is: 40.21% | rMAE for Test Set is: 0.58\n",
      "MAE for Validation Set is: 22.06 | sMAPE for Validation Set is: 26.57% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 58.06 | sMAPE for Test Set is: 39.90% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:47:31,692]\u001b[0m Trial 1266 finished with value: 22.61028063517487 and parameters: {'n_hidden': 3, 'learning_rate': 0.004395122487793638, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1816550444193358, 'dropout_rate_Layer_2': 0.35326049862259, 'dropout_rate_Layer_3': 0.28609198128003765, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025484029986204944, 'l1_Layer_2': 0.0016110485373143266, 'l1_Layer_3': 3.975932577946498e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 120, 'n_units_Layer_3': 220}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:32,350]\u001b[0m Trial 1264 finished with value: 22.064239430513016 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022258455007719133, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05467213788754882, 'dropout_rate_Layer_2': 0.16738417422890475, 'dropout_rate_Layer_3': 0.11358180988181474, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009598878694590732, 'l1_Layer_2': 1.7812703100401947e-05, 'l1_Layer_3': 7.953926151527967e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 225, 'n_units_Layer_3': 255}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:32,471]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:33,988]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:40,341]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:42,485]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:42,536]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:43,949]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:48,296]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:49,166]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:54,417]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:54,574]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:47:55,779]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:48:02,205]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:48:02,697]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:48:03,254]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:48:11,464]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:48:11,472]\u001b[0m Trial 1282 finished with value: 21.80654571729811 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027988492996741435, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14292908927999723, 'dropout_rate_Layer_2': 0.2117244461963818, 'dropout_rate_Layer_3': 0.00736877734233057, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.340372465181961e-05, 'l1_Layer_2': 4.1519326908382526e-05, 'l1_Layer_3': 0.002164143594237399, 'n_units_Layer_1': 165, 'n_units_Layer_2': 110, 'n_units_Layer_3': 125}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.81 | sMAPE for Validation Set is: 26.70% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.48 | sMAPE for Test Set is: 39.41% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:48:18,336]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:48:18,530]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:48:25,240]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:48:25,285]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:48:31,222]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:48:31,456]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:48:36,563]\u001b[0m Trial 1286 finished with value: 22.548260840681042 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025130690122358613, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014992224184863165, 'dropout_rate_Layer_2': 0.36494194034561156, 'dropout_rate_Layer_3': 0.06764228232784943, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0032388758599351283, 'l1_Layer_2': 0.00010842256244850896, 'l1_Layer_3': 0.00018839735657921042, 'n_units_Layer_1': 175, 'n_units_Layer_2': 280, 'n_units_Layer_3': 65}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.55 | sMAPE for Validation Set is: 27.04% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 63.48 | sMAPE for Test Set is: 41.28% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:48:37,750]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:48:38,666]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.73 | sMAPE for Validation Set is: 26.45% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.89 | sMAPE for Test Set is: 39.66% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:48:42,694]\u001b[0m Trial 1287 finished with value: 21.72978985442685 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033752813840728603, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17839636239332737, 'dropout_rate_Layer_2': 0.3538885847933626, 'dropout_rate_Layer_3': 0.27336468532025704, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00250781760031762, 'l1_Layer_2': 0.001700510024418438, 'l1_Layer_3': 5.6312106469460044e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 130, 'n_units_Layer_3': 225}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:48:45,699]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:48:48,898]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:48:53,517]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:48:54,255]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:48:54,731]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:01,657]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:02,455]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:03,127]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:09,895]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:10,328]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:13,500]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:18,712]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:19,897]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:20,342]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:23,012]\u001b[0m Trial 1300 finished with value: 21.61548779192584 and parameters: {'n_hidden': 3, 'learning_rate': 0.003442610892052924, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18122840038302745, 'dropout_rate_Layer_2': 0.35095278553575626, 'dropout_rate_Layer_3': 0.27726441194014606, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002687194406708415, 'l1_Layer_2': 0.001585747448157865, 'l1_Layer_3': 6.820110358302785e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 125, 'n_units_Layer_3': 225}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.62 | sMAPE for Validation Set is: 26.38% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.61 | sMAPE for Test Set is: 39.21% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:49:23,560]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:29,792]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:33,561]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:39,132]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:39,966]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:46,182]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:49,749]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:53,116]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:55,494]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:49:56,592]\u001b[0m Trial 1314 finished with value: 22.24357482750968 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020598225786966416, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07102395524702469, 'dropout_rate_Layer_2': 0.39081538817486194, 'dropout_rate_Layer_3': 0.04751168228587562, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00508195972145277, 'l1_Layer_2': 3.183555407660974e-05, 'l1_Layer_3': 0.0006978095455148033, 'n_units_Layer_1': 165, 'n_units_Layer_2': 205, 'n_units_Layer_3': 55}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.24 | sMAPE for Validation Set is: 26.94% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 59.14 | sMAPE for Test Set is: 40.20% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:50:01,548]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:50:05,403]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:50:08,579]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:50:09,536]\u001b[0m Trial 1319 finished with value: 21.913235321468928 and parameters: {'n_hidden': 3, 'learning_rate': 0.001992791391640161, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18692902268322406, 'dropout_rate_Layer_2': 0.39031517919446773, 'dropout_rate_Layer_3': 0.04755677824969716, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005615871785646274, 'l1_Layer_2': 1.3108286286184885e-05, 'l1_Layer_3': 0.0006714314232782675, 'n_units_Layer_1': 155, 'n_units_Layer_2': 205, 'n_units_Layer_3': 55}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.91 | sMAPE for Validation Set is: 26.25% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.77 | sMAPE for Test Set is: 39.97% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:50:12,212]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:50:17,725]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:50:18,061]\u001b[0m Trial 1324 finished with value: 21.830858073228388 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023205505283079935, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1465899083399993, 'dropout_rate_Layer_2': 0.17949213217657695, 'dropout_rate_Layer_3': 0.0528980198973298, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.741761057331388e-05, 'l1_Layer_2': 4.6674071799595235e-05, 'l1_Layer_3': 0.001465944898360214, 'n_units_Layer_1': 150, 'n_units_Layer_2': 95, 'n_units_Layer_3': 135}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.83 | sMAPE for Validation Set is: 27.04% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.35 | sMAPE for Test Set is: 39.66% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:50:18,968]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:50:25,731]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:50:26,011]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:50:32,599]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:50:33,325]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:50:41,557]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:50:45,700]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:50:46,705]\u001b[0m Trial 1330 finished with value: 21.945217162887506 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019269959801346517, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25678155269259445, 'dropout_rate_Layer_2': 0.3908044318270024, 'dropout_rate_Layer_3': 0.04503147647414813, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00589491807224829, 'l1_Layer_2': 1.0707243681041082e-05, 'l1_Layer_3': 0.0005176056560671604, 'n_units_Layer_1': 155, 'n_units_Layer_2': 210, 'n_units_Layer_3': 55}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.95 | sMAPE for Validation Set is: 26.60% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.47 | sMAPE for Test Set is: 39.64% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:50:47,232]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:50:54,429]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:50:54,619]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:50:57,844]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:51:02,095]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:51:06,499]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:51:08,565]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:51:13,735]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:51:20,647]\u001b[0m Trial 1333 finished with value: 21.689925065997375 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014270922325302676, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.032670662560411734, 'dropout_rate_Layer_2': 8.230860893820163e-05, 'dropout_rate_Layer_3': 0.13275694482542047, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008239685556205956, 'l1_Layer_2': 1.7300426380480243e-05, 'l1_Layer_3': 0.00015413013415740886, 'n_units_Layer_1': 90, 'n_units_Layer_2': 130, 'n_units_Layer_3': 230}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.69 | sMAPE for Validation Set is: 26.13% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 58.67 | sMAPE for Test Set is: 40.39% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:51:25,944]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:51:27,475]\u001b[0m Trial 1344 finished with value: 21.96522341297104 and parameters: {'n_hidden': 3, 'learning_rate': 0.001788042119907624, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26716161443501585, 'dropout_rate_Layer_2': 0.38280310332795614, 'dropout_rate_Layer_3': 0.11982054554694874, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004981687441645128, 'l1_Layer_2': 1.0246275467912173e-05, 'l1_Layer_3': 0.00039192871950525924, 'n_units_Layer_1': 145, 'n_units_Layer_2': 220, 'n_units_Layer_3': 60}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.97 | sMAPE for Validation Set is: 26.59% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.25 | sMAPE for Test Set is: 39.92% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:51:27,623]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:51:35,065]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:51:35,283]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:51:36,113]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:51:42,269]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:51:43,655]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:51:44,872]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:51:46,217]\u001b[0m Trial 1351 finished with value: 21.680272408494073 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015695710910863172, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09249915660470845, 'dropout_rate_Layer_2': 0.20536209279861223, 'dropout_rate_Layer_3': 0.038010716730079136, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.411023309358688e-05, 'l1_Layer_2': 3.8131327594142214e-05, 'l1_Layer_3': 0.0005635905256488467, 'n_units_Layer_1': 165, 'n_units_Layer_2': 105, 'n_units_Layer_3': 140}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.68 | sMAPE for Validation Set is: 26.61% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.57 | sMAPE for Test Set is: 39.89% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:51:53,298]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:51:54,333]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:51:54,479]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:00,106]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:03,809]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:07,785]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:07,961]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:08,999]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:17,028]\u001b[0m Trial 1360 finished with value: 22.21362634118348 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034086702289956076, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21745458672910692, 'dropout_rate_Layer_2': 0.34175718566854996, 'dropout_rate_Layer_3': 0.2861780499092939, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001776310867791083, 'l1_Layer_2': 0.001347896081415911, 'l1_Layer_3': 7.644717882879657e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 150, 'n_units_Layer_3': 215}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.21 | sMAPE for Validation Set is: 27.58% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 55.92 | sMAPE for Test Set is: 39.41% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:52:17,360]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:18,060]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:18,240]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:24,938]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:26,241]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:29,699]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:30,774]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:31,528]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:32,692]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:38,644]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:40,832]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:42,781]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:45,457]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:52,807]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:53,706]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:58,768]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:59,185]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:52:59,396]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:53:07,532]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:53:08,606]\u001b[0m Trial 1380 finished with value: 21.545925387035314 and parameters: {'n_hidden': 3, 'learning_rate': 0.003711000998624102, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2203708554914743, 'dropout_rate_Layer_2': 0.3389338543915169, 'dropout_rate_Layer_3': 0.2577600536266395, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018805811930253373, 'l1_Layer_2': 0.0013411303546688547, 'l1_Layer_3': 0.00012443617212046218, 'n_units_Layer_1': 135, 'n_units_Layer_2': 150, 'n_units_Layer_3': 235}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.55 | sMAPE for Validation Set is: 26.32% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.51 | sMAPE for Test Set is: 39.36% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:53:09,928]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:53:11,367]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:53:12,340]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:53:17,627]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:53:19,033]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:53:20,384]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:53:28,829]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:53:30,300]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:53:31,648]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:53:37,700]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:53:38,060]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:53:44,349]\u001b[0m Trial 1391 finished with value: 22.41664120400668 and parameters: {'n_hidden': 3, 'learning_rate': 0.009116185719014057, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06709944598727835, 'dropout_rate_Layer_2': 0.02037779677905235, 'dropout_rate_Layer_3': 0.07144839936248212, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006022495952801152, 'l1_Layer_2': 1.4434466961851303e-05, 'l1_Layer_3': 0.000167531068285215, 'n_units_Layer_1': 95, 'n_units_Layer_2': 215, 'n_units_Layer_3': 205}. Best is trial 815 with value: 21.332792004487814.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:53:44,431]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.42 | sMAPE for Validation Set is: 27.34% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 55.99 | sMAPE for Test Set is: 39.68% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:53:51,961]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.33 | sMAPE for Validation Set is: 26.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 55.00 | sMAPE for Test Set is: 38.97% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:53:54,261]\u001b[0m Trial 1397 finished with value: 21.331670834012538 and parameters: {'n_hidden': 3, 'learning_rate': 0.003519529085929327, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19959510564699506, 'dropout_rate_Layer_2': 0.37729838651640796, 'dropout_rate_Layer_3': 0.26230925510177905, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001725386006857635, 'l1_Layer_2': 0.0022473332830907737, 'l1_Layer_3': 5.1999507459801076e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 165, 'n_units_Layer_3': 240}. Best is trial 1397 with value: 21.331670834012538.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:00,598]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:02,095]\u001b[0m Trial 1398 finished with value: 21.925894493480076 and parameters: {'n_hidden': 3, 'learning_rate': 0.002593979525439906, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25951256609102463, 'dropout_rate_Layer_2': 0.38184902227043954, 'dropout_rate_Layer_3': 0.052847197487390314, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004419940218724096, 'l1_Layer_2': 1.8431167326165415e-05, 'l1_Layer_3': 0.0006556918012580943, 'n_units_Layer_1': 135, 'n_units_Layer_2': 200, 'n_units_Layer_3': 60}. Best is trial 1397 with value: 21.331670834012538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.93 | sMAPE for Validation Set is: 26.46% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.36 | sMAPE for Test Set is: 39.78% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:54:03,704]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:10,864]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:11,237]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:17,808]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:18,031]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:18,458]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:18,891]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:28,313]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:29,151]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:29,559]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:37,294]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:40,959]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:43,079]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:46,790]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:47,108]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:50,374]\u001b[0m Trial 1409 finished with value: 22.144220903674817 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021007060557147106, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2768193341437579, 'dropout_rate_Layer_2': 0.3820369671994997, 'dropout_rate_Layer_3': 0.30981670088663416, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0027208180066489287, 'l1_Layer_2': 1.796886024917933e-05, 'l1_Layer_3': 0.0005978708536675128, 'n_units_Layer_1': 130, 'n_units_Layer_2': 220, 'n_units_Layer_3': 65}. Best is trial 1397 with value: 21.331670834012538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.14 | sMAPE for Validation Set is: 26.90% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 60.80 | sMAPE for Test Set is: 40.57% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:54:53,505]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:54:54,323]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:55:02,424]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:55:03,281]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:55:03,733]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:55:12,197]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:55:12,438]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:55:16,754]\u001b[0m Trial 1417 finished with value: 21.580947566901926 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021375078917622967, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09635289186855002, 'dropout_rate_Layer_2': 0.2016497550420746, 'dropout_rate_Layer_3': 0.03295942937892071, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010802873853180974, 'l1_Layer_2': 5.518197769890483e-05, 'l1_Layer_3': 0.0004967536280995984, 'n_units_Layer_1': 180, 'n_units_Layer_2': 120, 'n_units_Layer_3': 125}. Best is trial 1397 with value: 21.331670834012538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.58 | sMAPE for Validation Set is: 26.17% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.22 | sMAPE for Test Set is: 38.93% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:55:17,620]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:55:20,908]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:55:24,321]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:55:25,746]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:55:31,113]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:55:39,405]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:55:43,295]\u001b[0m Trial 1433 finished with value: 21.984339841604307 and parameters: {'n_hidden': 3, 'learning_rate': 0.002199897050361554, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09753876612296411, 'dropout_rate_Layer_2': 0.22509345714486168, 'dropout_rate_Layer_3': 0.059629368259476734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007927912666384657, 'l1_Layer_2': 3.3927705878639796e-05, 'l1_Layer_3': 0.0005127598232766743, 'n_units_Layer_1': 150, 'n_units_Layer_2': 120, 'n_units_Layer_3': 105}. Best is trial 1397 with value: 21.331670834012538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.98 | sMAPE for Validation Set is: 27.38% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.89 | sMAPE for Test Set is: 39.33% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:55:45,868]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:55:47,521]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:55:49,575]\u001b[0m Trial 1434 finished with value: 21.717018531187986 and parameters: {'n_hidden': 3, 'learning_rate': 0.002173402917623563, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09602864621083587, 'dropout_rate_Layer_2': 0.17969698264476838, 'dropout_rate_Layer_3': 0.06177298749260027, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005755234178592096, 'l1_Layer_2': 3.6286125128240625e-05, 'l1_Layer_3': 0.000642877011251, 'n_units_Layer_1': 150, 'n_units_Layer_2': 120, 'n_units_Layer_3': 115}. Best is trial 1397 with value: 21.331670834012538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.72 | sMAPE for Validation Set is: 26.55% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.45 | sMAPE for Test Set is: 39.64% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:55:50,834]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:55:54,936]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:55:58,985]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:02,262]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:02,319]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:09,803]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:10,059]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:17,143]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.58 | sMAPE for Validation Set is: 26.33% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.97 | sMAPE for Test Set is: 39.12% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:56:19,524]\u001b[0m Trial 1431 finished with value: 21.575418509587063 and parameters: {'n_hidden': 3, 'learning_rate': 0.002352515892550806, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1978222951285864, 'dropout_rate_Layer_2': 0.3801475638778757, 'dropout_rate_Layer_3': 0.25873333232846196, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00403314305436979, 'l1_Layer_2': 0.002405905861813081, 'l1_Layer_3': 0.00021005774980998947, 'n_units_Layer_1': 135, 'n_units_Layer_2': 155, 'n_units_Layer_3': 215}. Best is trial 1397 with value: 21.331670834012538.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:21,836]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:24,619]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:27,131]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:32,039]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:33,852]\u001b[0m Trial 1446 finished with value: 22.33850546907405 and parameters: {'n_hidden': 3, 'learning_rate': 0.005150909444126613, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08295595178279076, 'dropout_rate_Layer_2': 0.1579156558661211, 'dropout_rate_Layer_3': 0.09653257000029956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01536297124093669, 'l1_Layer_2': 1.0130675969530585e-05, 'l1_Layer_3': 0.00014156751978132133, 'n_units_Layer_1': 110, 'n_units_Layer_2': 105, 'n_units_Layer_3': 225}. Best is trial 1397 with value: 21.331670834012538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.34 | sMAPE for Validation Set is: 27.37% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 59.72 | sMAPE for Test Set is: 40.99% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:56:37,858]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:38,094]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:38,432]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:41,389]\u001b[0m Trial 1442 finished with value: 21.75325157835719 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031651800388438705, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22567449986744878, 'dropout_rate_Layer_2': 0.3579955365961072, 'dropout_rate_Layer_3': 0.23715536524683264, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003800204896441298, 'l1_Layer_2': 0.0024186835381084584, 'l1_Layer_3': 8.751819184351907e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 150, 'n_units_Layer_3': 215}. Best is trial 1397 with value: 21.331670834012538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.75 | sMAPE for Validation Set is: 26.43% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 57.11 | sMAPE for Test Set is: 39.86% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:56:45,432]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:47,385]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:51,094]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:52,207]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:56,573]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:56:58,311]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:57:04,150]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:57:06,425]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:57:07,469]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:57:13,365]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:57:13,769]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:57:21,550]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:57:25,126]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:57:27,900]\u001b[0m Trial 1464 finished with value: 21.774682071417004 and parameters: {'n_hidden': 3, 'learning_rate': 0.00242383406342994, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10709793771004102, 'dropout_rate_Layer_2': 0.09069955654894797, 'dropout_rate_Layer_3': 0.03488478379345091, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006032868596524647, 'l1_Layer_2': 3.6707666796893945e-05, 'l1_Layer_3': 0.0007415857771201247, 'n_units_Layer_1': 160, 'n_units_Layer_2': 120, 'n_units_Layer_3': 130}. Best is trial 1397 with value: 21.331670834012538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.77 | sMAPE for Validation Set is: 26.34% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 58.08 | sMAPE for Test Set is: 40.00% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:57:30,668]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:57:31,710]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.53 | sMAPE for Validation Set is: 26.22% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.54 | sMAPE for Test Set is: 39.31% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:57:36,545]\u001b[0m Trial 1467 finished with value: 21.529025425915393 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030263988996413606, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2416587330431177, 'dropout_rate_Layer_2': 0.37503892500211616, 'dropout_rate_Layer_3': 0.2395682368498122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003748121544426203, 'l1_Layer_2': 0.002504781428438961, 'l1_Layer_3': 0.00016289855185222247, 'n_units_Layer_1': 130, 'n_units_Layer_2': 170, 'n_units_Layer_3': 215}. Best is trial 1397 with value: 21.331670834012538.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:57:40,227]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:57:40,733]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:57:46,268]\u001b[0m Trial 1465 finished with value: 21.687487921783603 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028789915335123493, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22362321256825968, 'dropout_rate_Layer_2': 0.3569812415159801, 'dropout_rate_Layer_3': 0.24355190719650413, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006655334386308814, 'l1_Layer_2': 0.0031559208673265595, 'l1_Layer_3': 0.00020282010821238706, 'n_units_Layer_1': 110, 'n_units_Layer_2': 170, 'n_units_Layer_3': 210}. Best is trial 1397 with value: 21.331670834012538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.69 | sMAPE for Validation Set is: 26.41% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.74 | sMAPE for Test Set is: 39.52% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:57:46,581]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:57:47,090]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:57:54,428]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:57:54,701]\u001b[0m Trial 1472 finished with value: 21.89314871908344 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030338250948283925, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2257085653149723, 'dropout_rate_Layer_2': 0.3588004768014348, 'dropout_rate_Layer_3': 0.2617917307728039, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0039441671737752, 'l1_Layer_2': 0.0025480839456323567, 'l1_Layer_3': 0.00011564814917192508, 'n_units_Layer_1': 110, 'n_units_Layer_2': 170, 'n_units_Layer_3': 215}. Best is trial 1397 with value: 21.331670834012538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.89 | sMAPE for Validation Set is: 26.63% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.93 | sMAPE for Test Set is: 39.39% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:57:54,827]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:57:56,185]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:58:01,588]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:58:05,409]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:58:06,101]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:58:06,687]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:58:14,958]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:58:17,311]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:58:18,123]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:58:25,937]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:58:29,660]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:58:29,870]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:58:35,466]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:58:36,344]\u001b[0m Trial 1486 finished with value: 21.499815062136083 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021237693196221727, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11851466183333077, 'dropout_rate_Layer_2': 0.2139510287458679, 'dropout_rate_Layer_3': 0.020969977018899664, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011242012844422274, 'l1_Layer_2': 2.8459668793934583e-05, 'l1_Layer_3': 0.0003578099727825065, 'n_units_Layer_1': 145, 'n_units_Layer_2': 125, 'n_units_Layer_3': 150}. Best is trial 1397 with value: 21.331670834012538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.50 | sMAPE for Validation Set is: 26.26% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 54.16 | sMAPE for Test Set is: 38.74% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:58:37,515]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:58:41,987]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:58:46,818]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:58:55,101]\u001b[0m Trial 1490 finished with value: 21.46062398237147 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020804298557564214, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11528946107505206, 'dropout_rate_Layer_2': 0.21412591093260536, 'dropout_rate_Layer_3': 0.016327590925019172, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012258564392545019, 'l1_Layer_2': 0.001448305085791984, 'l1_Layer_3': 0.0003478155935702506, 'n_units_Layer_1': 145, 'n_units_Layer_2': 85, 'n_units_Layer_3': 135}. Best is trial 1397 with value: 21.331670834012538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.46 | sMAPE for Validation Set is: 26.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.36 | sMAPE for Test Set is: 39.25% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 07:58:59,835]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:59:01,286]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:59:04,846]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 07:59:08,877]\u001b[0m Trial 1498 finished with value: 22.428206657670728 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014220877555950952, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25788066251405256, 'dropout_rate_Layer_2': 0.3929222590304131, 'dropout_rate_Layer_3': 0.06018776797354335, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0020731390932172775, 'l1_Layer_2': 0.006473759846630945, 'l1_Layer_3': 7.981832174650101e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 195, 'n_units_Layer_3': 55}. Best is trial 1397 with value: 21.331670834012538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.43 | sMAPE for Validation Set is: 27.28% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 59.13 | sMAPE for Test Set is: 41.15% | rMAE for Test Set is: 0.57\n",
      "for 2022-01-01, MAE is:27.30 & sMAPE is:33.64% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :27.30 & 33.64% & 0.24\n",
      "for 2022-01-02, MAE is:27.49 & sMAPE is:43.18% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :27.40 & 38.41% & 0.24\n",
      "for 2022-01-03, MAE is:15.62 & sMAPE is:30.09% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :23.47 & 35.63% & 0.23\n",
      "for 2022-01-04, MAE is:64.48 & sMAPE is:61.41% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :33.72 & 42.08% & 0.67\n",
      "for 2022-01-05, MAE is:15.18 & sMAPE is:15.64% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :30.01 & 36.79% & 0.60\n",
      "for 2022-01-06, MAE is:75.13 & sMAPE is:47.59% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :37.53 & 38.59% & 0.61\n",
      "for 2022-01-07, MAE is:18.21 & sMAPE is:11.47% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :34.77 & 34.72% & 0.55\n",
      "for 2022-01-08, MAE is:25.35 & sMAPE is:19.84% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :33.59 & 32.86% & 0.53\n",
      "for 2022-01-09, MAE is:37.09 & sMAPE is:28.56% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :33.98 & 32.38% & 0.52\n",
      "for 2022-01-10, MAE is:95.98 & sMAPE is:45.11% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :40.18 & 33.65% & 0.52\n",
      "for 2022-01-11, MAE is:38.47 & sMAPE is:16.95% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :40.03 & 32.13% & 0.52\n",
      "for 2022-01-12, MAE is:65.22 & sMAPE is:50.49% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :42.13 & 33.66% & 0.54\n",
      "for 2022-01-13, MAE is:54.52 & sMAPE is:118.17% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :43.08 & 40.16% & 0.53\n",
      "for 2022-01-14, MAE is:30.11 & sMAPE is:34.29% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :42.15 & 39.74% & 0.52\n",
      "for 2022-01-15, MAE is:75.60 & sMAPE is:57.22% & rMAE is:3.03 ||| daily mean of MAE & sMAPE & rMAE till now are :44.38 & 40.91% & 0.68\n",
      "for 2022-01-16, MAE is:98.31 & sMAPE is:123.38% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :47.75 & 46.06% & 0.69\n",
      "for 2022-01-17, MAE is:33.48 & sMAPE is:51.81% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :46.91 & 46.40% & 0.67\n",
      "for 2022-01-18, MAE is:44.01 & sMAPE is:33.04% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :46.75 & 45.66% & 0.66\n",
      "for 2022-01-19, MAE is:49.03 & sMAPE is:95.81% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :46.87 & 48.30% & 0.65\n",
      "for 2022-01-20, MAE is:48.13 & sMAPE is:122.40% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :46.94 & 52.00% & 0.67\n",
      "for 2022-01-21, MAE is:50.92 & sMAPE is:61.57% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :47.13 & 52.46% & 0.70\n",
      "for 2022-01-22, MAE is:47.72 & sMAPE is:32.83% & rMAE is:2.69 ||| daily mean of MAE & sMAPE & rMAE till now are :47.15 & 51.57% & 0.79\n",
      "for 2022-01-23, MAE is:17.95 & sMAPE is:14.19% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :45.88 & 49.94% & 0.76\n",
      "for 2022-01-24, MAE is:66.16 & sMAPE is:90.40% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :46.73 & 51.63% & 0.81\n",
      "for 2022-01-25, MAE is:94.02 & sMAPE is:79.23% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :48.62 & 52.73% & 0.83\n",
      "for 2022-01-26, MAE is:38.49 & sMAPE is:44.13% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :48.23 & 52.40% & 0.82\n",
      "for 2022-01-27, MAE is:22.96 & sMAPE is:51.28% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :47.29 & 52.36% & 0.82\n",
      "for 2022-01-28, MAE is:74.85 & sMAPE is:101.28% & rMAE is:3.54 ||| daily mean of MAE & sMAPE & rMAE till now are :48.28 & 54.11% & 0.91\n",
      "for 2022-01-29, MAE is:77.40 & sMAPE is:113.07% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :49.28 & 56.14% & 0.90\n",
      "for 2022-01-30, MAE is:37.42 & sMAPE is:99.08% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :48.89 & 57.57% & 0.89\n",
      "for 2022-01-31, MAE is:109.70 & sMAPE is:75.77% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :50.85 & 58.16% & 0.88\n",
      "for 2022-02-01, MAE is:44.85 & sMAPE is:30.47% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :50.66 & 57.29% & 0.87\n",
      "for 2022-02-02, MAE is:67.09 & sMAPE is:65.18% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :51.16 & 57.53% & 0.88\n",
      "for 2022-02-03, MAE is:36.48 & sMAPE is:21.99% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :50.73 & 56.49% & 0.86\n",
      "for 2022-02-04, MAE is:29.11 & sMAPE is:22.07% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :50.11 & 55.50% & 0.85\n",
      "for 2022-02-05, MAE is:65.93 & sMAPE is:111.24% & rMAE is:2.52 ||| daily mean of MAE & sMAPE & rMAE till now are :50.55 & 57.05% & 0.90\n",
      "for 2022-02-06, MAE is:30.15 & sMAPE is:81.03% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :50.00 & 57.70% & 0.91\n",
      "for 2022-02-07, MAE is:29.39 & sMAPE is:49.24% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :49.46 & 57.48% & 0.89\n",
      "for 2022-02-08, MAE is:27.12 & sMAPE is:46.20% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :48.88 & 57.19% & 0.88\n",
      "for 2022-02-09, MAE is:29.78 & sMAPE is:37.78% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :48.41 & 56.70% & 0.87\n",
      "for 2022-02-10, MAE is:27.14 & sMAPE is:25.11% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :47.89 & 55.93% & 0.86\n",
      "for 2022-02-11, MAE is:60.36 & sMAPE is:39.36% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :48.18 & 55.54% & 0.87\n",
      "for 2022-02-12, MAE is:46.04 & sMAPE is:39.81% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :48.13 & 55.17% & 0.86\n",
      "for 2022-02-13, MAE is:36.50 & sMAPE is:89.38% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :47.87 & 55.95% & 0.88\n",
      "for 2022-02-14, MAE is:29.39 & sMAPE is:50.24% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :47.46 & 55.82% & 0.88\n",
      "for 2022-02-15, MAE is:23.51 & sMAPE is:48.38% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :46.94 & 55.66% & 0.88\n",
      "for 2022-02-16, MAE is:31.81 & sMAPE is:50.50% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :46.62 & 55.55% & 0.88\n",
      "for 2022-02-17, MAE is:19.57 & sMAPE is:38.84% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :46.05 & 55.20% & 0.87\n",
      "for 2022-02-18, MAE is:24.03 & sMAPE is:43.24% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :45.60 & 54.96% & 0.86\n",
      "for 2022-02-19, MAE is:53.71 & sMAPE is:115.53% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :45.77 & 56.17% & 0.85\n",
      "for 2022-02-20, MAE is:25.19 & sMAPE is:50.86% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :45.36 & 56.07% & 0.85\n",
      "for 2022-02-21, MAE is:27.72 & sMAPE is:54.20% & rMAE is:3.46 ||| daily mean of MAE & sMAPE & rMAE till now are :45.02 & 56.03% & 0.90\n",
      "for 2022-02-22, MAE is:58.04 & sMAPE is:65.50% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :45.27 & 56.21% & 0.90\n",
      "for 2022-02-23, MAE is:23.66 & sMAPE is:31.61% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :44.87 & 55.75% & 0.90\n",
      "for 2022-02-24, MAE is:29.51 & sMAPE is:54.87% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :44.59 & 55.74% & 0.90\n",
      "for 2022-02-25, MAE is:27.01 & sMAPE is:40.20% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :44.27 & 55.46% & 0.91\n",
      "for 2022-02-26, MAE is:127.17 & sMAPE is:79.34% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :45.73 & 55.88% & 0.91\n",
      "for 2022-02-27, MAE is:35.54 & sMAPE is:20.14% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :45.55 & 55.26% & 0.90\n",
      "for 2022-02-28, MAE is:42.46 & sMAPE is:23.66% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :45.50 & 54.73% & 0.89\n",
      "for 2022-03-01, MAE is:108.51 & sMAPE is:74.26% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :46.55 & 55.05% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-03-02, MAE is:74.01 & sMAPE is:30.58% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :47.00 & 54.65% & 0.88\n",
      "for 2022-03-03, MAE is:114.16 & sMAPE is:40.29% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :48.08 & 54.42% & 0.88\n",
      "for 2022-03-04, MAE is:81.81 & sMAPE is:25.67% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :48.62 & 53.96% & 0.87\n",
      "for 2022-03-05, MAE is:50.19 & sMAPE is:15.27% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :48.64 & 53.36% & 0.86\n",
      "for 2022-03-06, MAE is:77.85 & sMAPE is:24.33% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :49.09 & 52.91% & 0.85\n",
      "for 2022-03-07, MAE is:81.93 & sMAPE is:21.76% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :49.59 & 52.44% & 0.85\n",
      "for 2022-03-08, MAE is:158.11 & sMAPE is:37.63% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :51.21 & 52.22% & 0.84\n",
      "for 2022-03-09, MAE is:70.16 & sMAPE is:15.96% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :51.49 & 51.69% & 0.84\n",
      "for 2022-03-10, MAE is:155.23 & sMAPE is:55.48% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :52.99 & 51.74% & 0.85\n",
      "for 2022-03-11, MAE is:79.83 & sMAPE is:92.39% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :53.38 & 52.32% & 0.84\n",
      "for 2022-03-12, MAE is:33.23 & sMAPE is:29.68% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :53.09 & 52.00% & 0.83\n",
      "for 2022-03-13, MAE is:92.74 & sMAPE is:84.37% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :53.64 & 52.45% & 0.82\n",
      "for 2022-03-14, MAE is:128.27 & sMAPE is:71.42% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :54.67 & 52.71% & 0.82\n",
      "for 2022-03-15, MAE is:48.76 & sMAPE is:16.71% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :54.59 & 52.23% & 0.81\n",
      "for 2022-03-16, MAE is:71.97 & sMAPE is:30.43% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :54.82 & 51.93% & 0.81\n",
      "for 2022-03-17, MAE is:44.41 & sMAPE is:33.44% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :54.68 & 51.69% & 0.80\n",
      "for 2022-03-18, MAE is:66.82 & sMAPE is:35.37% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :54.84 & 51.48% & 0.80\n",
      "for 2022-03-19, MAE is:69.93 & sMAPE is:57.81% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :55.03 & 51.56% & 0.80\n",
      "for 2022-03-20, MAE is:40.00 & sMAPE is:84.14% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :54.84 & 51.97% & 0.80\n",
      "for 2022-03-21, MAE is:97.39 & sMAPE is:78.60% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :55.37 & 52.31% & 0.81\n",
      "for 2022-03-22, MAE is:52.76 & sMAPE is:24.74% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :55.34 & 51.97% & 0.82\n",
      "for 2022-03-23, MAE is:44.35 & sMAPE is:18.97% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :55.21 & 51.56% & 0.82\n",
      "for 2022-03-24, MAE is:49.24 & sMAPE is:21.63% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :55.14 & 51.20% & 0.81\n",
      "for 2022-03-25, MAE is:65.47 & sMAPE is:35.23% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :55.26 & 51.01% & 0.82\n",
      "for 2022-03-26, MAE is:83.09 & sMAPE is:93.56% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :55.59 & 51.51% & 0.82\n",
      "for 2022-03-27, MAE is:43.48 & sMAPE is:26.90% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :55.45 & 51.23% & 0.81\n",
      "for 2022-03-28, MAE is:71.88 & sMAPE is:79.45% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :55.63 & 51.55% & 0.81\n",
      "for 2022-03-29, MAE is:132.27 & sMAPE is:93.57% & rMAE is:4.20 ||| daily mean of MAE & sMAPE & rMAE till now are :56.50 & 52.03% & 0.85\n",
      "for 2022-03-30, MAE is:43.46 & sMAPE is:18.44% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :56.36 & 51.65% & 0.85\n",
      "for 2022-03-31, MAE is:27.77 & sMAPE is:13.74% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :56.04 & 51.23% & 0.85\n",
      "for 2022-04-01, MAE is:18.47 & sMAPE is:12.51% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :55.63 & 50.80% & 0.84\n",
      "for 2022-04-02, MAE is:22.25 & sMAPE is:13.21% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :55.26 & 50.40% & 0.84\n",
      "for 2022-04-03, MAE is:56.89 & sMAPE is:42.09% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :55.28 & 50.31% & 0.84\n",
      "for 2022-04-04, MAE is:25.63 & sMAPE is:38.34% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :54.97 & 50.18% & 0.84\n",
      "for 2022-04-05, MAE is:54.86 & sMAPE is:63.25% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :54.97 & 50.32% & 0.84\n",
      "for 2022-04-06, MAE is:42.27 & sMAPE is:33.50% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :54.83 & 50.14% & 0.83\n",
      "for 2022-04-07, MAE is:25.03 & sMAPE is:28.18% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :54.53 & 49.92% & 0.83\n",
      "for 2022-04-08, MAE is:35.03 & sMAPE is:68.03% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :54.33 & 50.10% & 0.82\n",
      "for 2022-04-09, MAE is:40.99 & sMAPE is:87.07% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :54.19 & 50.47% & 0.82\n",
      "for 2022-04-10, MAE is:24.29 & sMAPE is:83.85% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :53.89 & 50.81% & 0.81\n",
      "for 2022-04-11, MAE is:139.65 & sMAPE is:107.56% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :54.74 & 51.37% & 0.81\n",
      "for 2022-04-12, MAE is:40.84 & sMAPE is:23.38% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :54.61 & 51.09% & 0.81\n",
      "for 2022-04-13, MAE is:71.22 & sMAPE is:43.02% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :54.77 & 51.02% & 0.81\n",
      "for 2022-04-14, MAE is:32.65 & sMAPE is:15.83% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :54.56 & 50.68% & 0.80\n",
      "for 2022-04-15, MAE is:26.31 & sMAPE is:17.36% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :54.29 & 50.36% & 0.80\n",
      "for 2022-04-16, MAE is:41.03 & sMAPE is:33.20% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :54.16 & 50.20% & 0.79\n",
      "for 2022-04-17, MAE is:40.07 & sMAPE is:48.96% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :54.03 & 50.19% & 0.79\n",
      "for 2022-04-18, MAE is:44.81 & sMAPE is:36.23% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :53.94 & 50.06% & 0.79\n",
      "for 2022-04-19, MAE is:54.67 & sMAPE is:29.54% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :53.95 & 49.87% & 0.80\n",
      "for 2022-04-20, MAE is:20.33 & sMAPE is:10.31% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :53.64 & 49.51% & 0.79\n",
      "for 2022-04-21, MAE is:22.35 & sMAPE is:11.82% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :53.36 & 49.17% & 0.79\n",
      "for 2022-04-22, MAE is:41.30 & sMAPE is:26.81% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :53.26 & 48.97% & 0.79\n",
      "for 2022-04-23, MAE is:49.55 & sMAPE is:68.28% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :53.22 & 49.14% & 0.79\n",
      "for 2022-04-24, MAE is:34.66 & sMAPE is:31.77% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :53.06 & 48.99% & 0.80\n",
      "for 2022-04-25, MAE is:79.20 & sMAPE is:43.25% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :53.29 & 48.94% & 0.80\n",
      "for 2022-04-26, MAE is:30.38 & sMAPE is:13.60% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :53.09 & 48.63% & 0.80\n",
      "for 2022-04-27, MAE is:17.80 & sMAPE is:8.24% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :52.79 & 48.29% & 0.80\n",
      "for 2022-04-28, MAE is:36.50 & sMAPE is:16.87% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :52.65 & 48.02% & 0.80\n",
      "for 2022-04-29, MAE is:20.97 & sMAPE is:9.57% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :52.38 & 47.70% & 0.80\n",
      "for 2022-04-30, MAE is:21.38 & sMAPE is:11.03% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :52.13 & 47.39% & 0.80\n",
      "for 2022-05-01, MAE is:21.22 & sMAPE is:11.24% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :51.87 & 47.10% & 0.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-05-02, MAE is:41.42 & sMAPE is:23.66% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :51.78 & 46.90% & 0.79\n",
      "for 2022-05-03, MAE is:59.26 & sMAPE is:32.12% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :51.84 & 46.78% & 0.80\n",
      "for 2022-05-04, MAE is:35.82 & sMAPE is:16.99% & rMAE is:3.66 ||| daily mean of MAE & sMAPE & rMAE till now are :51.72 & 46.54% & 0.82\n",
      "for 2022-05-05, MAE is:25.67 & sMAPE is:11.98% & rMAE is:2.69 ||| daily mean of MAE & sMAPE & rMAE till now are :51.51 & 46.27% & 0.84\n",
      "for 2022-05-06, MAE is:23.96 & sMAPE is:11.54% & rMAE is:3.37 ||| daily mean of MAE & sMAPE & rMAE till now are :51.29 & 45.99% & 0.86\n",
      "for 2022-05-07, MAE is:19.17 & sMAPE is:10.03% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :51.04 & 45.71% & 0.86\n",
      "for 2022-05-08, MAE is:35.03 & sMAPE is:22.54% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :50.91 & 45.53% & 0.87\n",
      "for 2022-05-09, MAE is:30.70 & sMAPE is:15.22% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :50.75 & 45.29% & 0.87\n",
      "for 2022-05-10, MAE is:63.20 & sMAPE is:59.04% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :50.85 & 45.40% & 0.87\n",
      "for 2022-05-11, MAE is:52.60 & sMAPE is:43.52% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :50.86 & 45.38% & 0.87\n",
      "for 2022-05-12, MAE is:55.96 & sMAPE is:56.73% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :50.90 & 45.47% & 0.87\n",
      "for 2022-05-13, MAE is:61.36 & sMAPE is:55.27% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :50.98 & 45.54% & 0.87\n",
      "for 2022-05-14, MAE is:72.10 & sMAPE is:131.26% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :51.14 & 46.18% & 0.87\n",
      "for 2022-05-15, MAE is:43.75 & sMAPE is:36.16% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :51.08 & 46.11% & 0.87\n",
      "for 2022-05-16, MAE is:44.51 & sMAPE is:23.32% & rMAE is:3.88 ||| daily mean of MAE & sMAPE & rMAE till now are :51.03 & 45.94% & 0.89\n",
      "for 2022-05-17, MAE is:38.76 & sMAPE is:18.92% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :50.95 & 45.74% & 0.89\n",
      "for 2022-05-18, MAE is:23.88 & sMAPE is:12.27% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :50.75 & 45.50% & 0.89\n",
      "for 2022-05-19, MAE is:33.77 & sMAPE is:18.94% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :50.63 & 45.31% & 0.88\n",
      "for 2022-05-20, MAE is:37.20 & sMAPE is:26.15% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :50.53 & 45.17% & 0.88\n",
      "for 2022-05-21, MAE is:59.73 & sMAPE is:54.50% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :50.60 & 45.24% & 0.88\n",
      "for 2022-05-22, MAE is:21.94 & sMAPE is:14.19% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :50.39 & 45.02% & 0.88\n",
      "for 2022-05-23, MAE is:28.38 & sMAPE is:17.96% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :50.24 & 44.83% & 0.88\n",
      "for 2022-05-24, MAE is:37.24 & sMAPE is:39.91% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :50.15 & 44.80% & 0.88\n",
      "for 2022-05-25, MAE is:30.69 & sMAPE is:20.65% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :50.02 & 44.63% & 0.88\n",
      "for 2022-05-26, MAE is:99.91 & sMAPE is:132.80% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :50.36 & 45.23% & 0.87\n",
      "for 2022-05-27, MAE is:64.10 & sMAPE is:133.11% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :50.45 & 45.83% & 0.87\n",
      "for 2022-05-28, MAE is:30.24 & sMAPE is:108.99% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :50.31 & 46.26% & 0.87\n",
      "for 2022-05-29, MAE is:54.04 & sMAPE is:41.50% & rMAE is:2.81 ||| daily mean of MAE & sMAPE & rMAE till now are :50.34 & 46.23% & 0.88\n",
      "for 2022-05-30, MAE is:56.80 & sMAPE is:28.72% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :50.38 & 46.11% & 0.88\n",
      "for 2022-05-31, MAE is:19.74 & sMAPE is:9.59% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :50.18 & 45.87% & 0.88\n",
      "for 2022-06-01, MAE is:31.19 & sMAPE is:15.83% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :50.06 & 45.67% & 0.88\n",
      "for 2022-06-02, MAE is:23.05 & sMAPE is:12.56% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :49.88 & 45.45% & 0.87\n",
      "for 2022-06-03, MAE is:51.57 & sMAPE is:32.76% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :49.89 & 45.37% & 0.87\n",
      "for 2022-06-04, MAE is:22.47 & sMAPE is:14.61% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :49.71 & 45.17% & 0.86\n",
      "for 2022-06-05, MAE is:21.20 & sMAPE is:14.06% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :49.53 & 44.97% & 0.87\n",
      "for 2022-06-06, MAE is:67.77 & sMAPE is:72.39% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :49.65 & 45.15% & 0.86\n",
      "for 2022-06-07, MAE is:14.10 & sMAPE is:8.16% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :49.42 & 44.91% & 0.86\n",
      "for 2022-06-08, MAE is:16.13 & sMAPE is:8.58% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :49.21 & 44.69% & 0.86\n",
      "for 2022-06-09, MAE is:19.16 & sMAPE is:11.21% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :49.02 & 44.48% & 0.86\n",
      "for 2022-06-10, MAE is:23.25 & sMAPE is:13.40% & rMAE is:3.16 ||| daily mean of MAE & sMAPE & rMAE till now are :48.86 & 44.28% & 0.88\n",
      "for 2022-06-11, MAE is:47.48 & sMAPE is:43.09% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :48.86 & 44.28% & 0.88\n",
      "for 2022-06-12, MAE is:45.76 & sMAPE is:52.85% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :48.84 & 44.33% & 0.88\n",
      "for 2022-06-13, MAE is:25.53 & sMAPE is:17.05% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :48.69 & 44.16% & 0.88\n",
      "for 2022-06-14, MAE is:59.63 & sMAPE is:54.30% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :48.76 & 44.22% & 0.88\n",
      "for 2022-06-15, MAE is:37.04 & sMAPE is:17.98% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :48.69 & 44.07% & 0.88\n",
      "for 2022-06-16, MAE is:42.16 & sMAPE is:23.20% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :48.65 & 43.94% & 0.88\n",
      "for 2022-06-17, MAE is:55.00 & sMAPE is:22.59% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :48.69 & 43.81% & 0.88\n",
      "for 2022-06-18, MAE is:44.95 & sMAPE is:25.39% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :48.67 & 43.71% & 0.88\n",
      "for 2022-06-19, MAE is:72.42 & sMAPE is:46.35% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :48.81 & 43.72% & 0.89\n",
      "for 2022-06-20, MAE is:43.97 & sMAPE is:15.90% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :48.78 & 43.56% & 0.88\n",
      "for 2022-06-21, MAE is:59.02 & sMAPE is:20.36% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :48.84 & 43.42% & 0.88\n",
      "for 2022-06-22, MAE is:44.94 & sMAPE is:13.46% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :48.81 & 43.25% & 0.88\n",
      "for 2022-06-23, MAE is:38.45 & sMAPE is:12.89% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :48.76 & 43.08% & 0.88\n",
      "for 2022-06-24, MAE is:54.16 & sMAPE is:29.70% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :48.79 & 43.00% & 0.88\n",
      "for 2022-06-25, MAE is:43.80 & sMAPE is:19.33% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :48.76 & 42.86% & 0.88\n",
      "for 2022-06-26, MAE is:64.91 & sMAPE is:35.02% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :48.85 & 42.82% & 0.88\n",
      "for 2022-06-27, MAE is:34.45 & sMAPE is:11.20% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :48.77 & 42.64% & 0.88\n",
      "for 2022-06-28, MAE is:49.18 & sMAPE is:14.85% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :48.77 & 42.49% & 0.88\n",
      "for 2022-06-29, MAE is:26.40 & sMAPE is:8.54% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :48.65 & 42.30% & 0.88\n",
      "for 2022-06-30, MAE is:52.38 & sMAPE is:16.80% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :48.67 & 42.16% & 0.88\n",
      "for 2022-07-01, MAE is:33.25 & sMAPE is:10.80% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :48.58 & 41.99% & 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-07-02, MAE is:69.45 & sMAPE is:34.40% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :48.70 & 41.94% & 0.88\n",
      "for 2022-07-03, MAE is:69.26 & sMAPE is:37.33% & rMAE is:3.48 ||| daily mean of MAE & sMAPE & rMAE till now are :48.81 & 41.92% & 0.90\n",
      "for 2022-07-04, MAE is:48.42 & sMAPE is:18.60% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :48.81 & 41.79% & 0.90\n",
      "for 2022-07-05, MAE is:32.03 & sMAPE is:11.77% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :48.72 & 41.63% & 0.89\n",
      "for 2022-07-06, MAE is:65.19 & sMAPE is:28.36% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :48.80 & 41.56% & 0.89\n",
      "for 2022-07-07, MAE is:53.95 & sMAPE is:53.67% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :48.83 & 41.63% & 0.89\n",
      "for 2022-07-08, MAE is:17.07 & sMAPE is:9.26% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :48.66 & 41.45% & 0.89\n",
      "for 2022-07-09, MAE is:173.61 & sMAPE is:191.12% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :49.32 & 42.24% & 0.89\n",
      "for 2022-07-10, MAE is:83.99 & sMAPE is:121.51% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :49.50 & 42.66% & 0.88\n",
      "for 2022-07-11, MAE is:113.79 & sMAPE is:35.89% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :49.84 & 42.62% & 0.89\n",
      "for 2022-07-12, MAE is:71.40 & sMAPE is:23.24% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :49.95 & 42.52% & 0.88\n",
      "for 2022-07-13, MAE is:182.34 & sMAPE is:144.92% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :50.63 & 43.05% & 0.89\n",
      "for 2022-07-14, MAE is:19.59 & sMAPE is:156.22% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :50.47 & 43.63% & 0.88\n",
      "for 2022-07-15, MAE is:63.69 & sMAPE is:140.46% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :50.54 & 44.12% & 0.88\n",
      "for 2022-07-16, MAE is:111.27 & sMAPE is:115.34% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :50.85 & 44.48% & 0.88\n",
      "for 2022-07-17, MAE is:82.65 & sMAPE is:41.52% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :51.01 & 44.47% & 0.88\n",
      "for 2022-07-18, MAE is:55.95 & sMAPE is:15.55% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :51.03 & 44.32% & 0.88\n",
      "for 2022-07-19, MAE is:67.78 & sMAPE is:17.55% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :51.12 & 44.19% & 0.88\n",
      "for 2022-07-20, MAE is:84.37 & sMAPE is:38.79% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :51.28 & 44.16% & 0.88\n",
      "for 2022-07-21, MAE is:232.97 & sMAPE is:102.13% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :52.18 & 44.45% & 0.88\n",
      "for 2022-07-22, MAE is:48.14 & sMAPE is:17.27% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :52.16 & 44.32% & 0.88\n",
      "for 2022-07-23, MAE is:80.18 & sMAPE is:31.66% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :52.30 & 44.25% & 0.88\n",
      "for 2022-07-24, MAE is:103.19 & sMAPE is:50.56% & rMAE is:2.70 ||| daily mean of MAE & sMAPE & rMAE till now are :52.55 & 44.29% & 0.88\n",
      "for 2022-07-25, MAE is:97.78 & sMAPE is:41.06% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :52.77 & 44.27% & 0.88\n",
      "for 2022-07-26, MAE is:152.15 & sMAPE is:102.27% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :53.25 & 44.55% & 0.88\n",
      "for 2022-07-27, MAE is:115.43 & sMAPE is:124.03% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :53.55 & 44.93% & 0.88\n",
      "for 2022-07-28, MAE is:153.08 & sMAPE is:39.46% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :54.02 & 44.91% & 0.88\n",
      "for 2022-07-29, MAE is:27.45 & sMAPE is:6.37% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :53.90 & 44.72% & 0.88\n",
      "for 2022-07-30, MAE is:67.25 & sMAPE is:21.22% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :53.96 & 44.61% & 0.88\n",
      "for 2022-07-31, MAE is:51.79 & sMAPE is:16.38% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :53.95 & 44.48% & 0.87\n",
      "for 2022-08-01, MAE is:43.68 & sMAPE is:12.15% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :53.90 & 44.33% & 0.87\n",
      "for 2022-08-02, MAE is:105.76 & sMAPE is:37.75% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :54.14 & 44.30% & 0.87\n",
      "for 2022-08-03, MAE is:104.40 & sMAPE is:38.15% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :54.38 & 44.27% & 0.87\n",
      "for 2022-08-04, MAE is:98.69 & sMAPE is:30.16% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :54.58 & 44.20% & 0.87\n",
      "for 2022-08-05, MAE is:67.06 & sMAPE is:20.47% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :54.64 & 44.09% & 0.87\n",
      "for 2022-08-06, MAE is:82.66 & sMAPE is:40.13% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :54.77 & 44.07% & 0.87\n",
      "for 2022-08-07, MAE is:95.72 & sMAPE is:46.42% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :54.95 & 44.08% & 0.87\n",
      "for 2022-08-08, MAE is:45.16 & sMAPE is:12.51% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :54.91 & 43.94% & 0.87\n",
      "for 2022-08-09, MAE is:38.23 & sMAPE is:11.08% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :54.83 & 43.79% & 0.87\n",
      "for 2022-08-10, MAE is:40.61 & sMAPE is:12.30% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :54.77 & 43.65% & 0.86\n",
      "for 2022-08-11, MAE is:56.08 & sMAPE is:15.43% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :54.78 & 43.52% & 0.86\n",
      "for 2022-08-12, MAE is:86.54 & sMAPE is:21.80% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :54.92 & 43.43% & 0.86\n",
      "for 2022-08-13, MAE is:58.73 & sMAPE is:16.93% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :54.94 & 43.31% & 0.86\n",
      "for 2022-08-14, MAE is:68.02 & sMAPE is:25.72% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :54.99 & 43.23% & 0.86\n",
      "for 2022-08-15, MAE is:79.90 & sMAPE is:22.58% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :55.10 & 43.14% & 0.86\n",
      "for 2022-08-16, MAE is:88.62 & sMAPE is:19.35% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :55.25 & 43.04% & 0.86\n",
      "for 2022-08-17, MAE is:98.72 & sMAPE is:19.70% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :55.44 & 42.93% & 0.86\n",
      "for 2022-08-18, MAE is:89.69 & sMAPE is:17.64% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :55.59 & 42.82% & 0.86\n",
      "for 2022-08-19, MAE is:32.78 & sMAPE is:6.79% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :55.49 & 42.67% & 0.86\n",
      "for 2022-08-20, MAE is:43.98 & sMAPE is:9.99% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :55.44 & 42.53% & 0.85\n",
      "for 2022-08-21, MAE is:115.02 & sMAPE is:35.29% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :55.70 & 42.50% & 0.86\n",
      "for 2022-08-22, MAE is:94.52 & sMAPE is:18.69% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :55.86 & 42.39% & 0.86\n",
      "for 2022-08-23, MAE is:89.72 & sMAPE is:16.15% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :56.01 & 42.28% & 0.86\n",
      "for 2022-08-24, MAE is:91.59 & sMAPE is:15.67% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :56.16 & 42.17% & 0.86\n",
      "for 2022-08-25, MAE is:79.08 & sMAPE is:13.97% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :56.25 & 42.05% & 0.86\n",
      "for 2022-08-26, MAE is:134.29 & sMAPE is:21.63% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :56.58 & 41.97% & 0.86\n",
      "for 2022-08-27, MAE is:54.87 & sMAPE is:9.75% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :56.57 & 41.83% & 0.86\n",
      "for 2022-08-28, MAE is:159.18 & sMAPE is:46.53% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :57.00 & 41.85% & 0.86\n",
      "for 2022-08-29, MAE is:152.34 & sMAPE is:26.64% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :57.40 & 41.79% & 0.87\n",
      "for 2022-08-30, MAE is:63.05 & sMAPE is:9.54% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :57.42 & 41.65% & 0.87\n",
      "for 2022-08-31, MAE is:53.94 & sMAPE is:9.27% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :57.41 & 41.52% & 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-09-01, MAE is:69.46 & sMAPE is:13.13% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :57.46 & 41.40% & 0.87\n",
      "for 2022-09-02, MAE is:122.38 & sMAPE is:27.15% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :57.72 & 41.35% & 0.87\n",
      "for 2022-09-03, MAE is:114.33 & sMAPE is:48.03% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :57.95 & 41.37% & 0.87\n",
      "for 2022-09-04, MAE is:114.82 & sMAPE is:66.18% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :58.18 & 41.47% & 0.87\n",
      "for 2022-09-05, MAE is:94.34 & sMAPE is:29.17% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :58.33 & 41.42% & 0.86\n",
      "for 2022-09-06, MAE is:122.93 & sMAPE is:46.92% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :58.59 & 41.45% & 0.86\n",
      "for 2022-09-07, MAE is:95.36 & sMAPE is:27.26% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :58.73 & 41.39% & 0.86\n",
      "for 2022-09-08, MAE is:88.87 & sMAPE is:35.27% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :58.85 & 41.36% & 0.86\n",
      "for 2022-09-09, MAE is:107.72 & sMAPE is:40.89% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :59.05 & 41.36% & 0.86\n",
      "for 2022-09-10, MAE is:87.93 & sMAPE is:25.19% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :59.16 & 41.30% & 0.86\n",
      "for 2022-09-11, MAE is:58.81 & sMAPE is:16.57% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :59.16 & 41.20% & 0.86\n",
      "for 2022-09-12, MAE is:54.33 & sMAPE is:13.93% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :59.14 & 41.09% & 0.85\n",
      "for 2022-09-13, MAE is:47.96 & sMAPE is:13.51% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :59.10 & 40.99% & 0.85\n",
      "for 2022-09-14, MAE is:93.91 & sMAPE is:24.45% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :59.23 & 40.92% & 0.86\n",
      "for 2022-09-15, MAE is:43.02 & sMAPE is:13.08% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :59.17 & 40.81% & 0.85\n",
      "for 2022-09-16, MAE is:127.66 & sMAPE is:59.38% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :59.43 & 40.89% & 0.85\n",
      "for 2022-09-17, MAE is:123.85 & sMAPE is:93.86% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :59.68 & 41.09% & 0.85\n",
      "for 2022-09-18, MAE is:37.93 & sMAPE is:52.45% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :59.60 & 41.13% & 0.85\n",
      "for 2022-09-19, MAE is:109.13 & sMAPE is:44.07% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :59.79 & 41.14% & 0.85\n",
      "for 2022-09-20, MAE is:89.33 & sMAPE is:27.12% & rMAE is:2.75 ||| daily mean of MAE & sMAPE & rMAE till now are :59.90 & 41.09% & 0.86\n",
      "for 2022-09-21, MAE is:72.09 & sMAPE is:19.90% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :59.95 & 41.01% & 0.86\n",
      "for 2022-09-22, MAE is:75.78 & sMAPE is:20.17% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :60.01 & 40.93% & 0.86\n",
      "for 2022-09-23, MAE is:54.54 & sMAPE is:15.71% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :59.99 & 40.84% & 0.86\n",
      "for 2022-09-24, MAE is:69.39 & sMAPE is:22.05% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :60.02 & 40.77% & 0.85\n",
      "for 2022-09-25, MAE is:32.51 & sMAPE is:11.05% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :59.92 & 40.66% & 0.85\n",
      "for 2022-09-26, MAE is:58.40 & sMAPE is:25.48% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :59.91 & 40.60% & 0.85\n",
      "for 2022-09-27, MAE is:48.42 & sMAPE is:16.19% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :59.87 & 40.51% & 0.85\n",
      "for 2022-09-28, MAE is:90.76 & sMAPE is:25.75% & rMAE is:2.70 ||| daily mean of MAE & sMAPE & rMAE till now are :59.98 & 40.46% & 0.86\n",
      "for 2022-09-29, MAE is:75.07 & sMAPE is:18.83% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :60.04 & 40.38% & 0.86\n",
      "for 2022-09-30, MAE is:102.28 & sMAPE is:33.67% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :60.19 & 40.35% & 0.87\n",
      "for 2022-10-01, MAE is:104.10 & sMAPE is:88.78% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :60.35 & 40.53% & 0.86\n",
      "for 2022-10-02, MAE is:43.22 & sMAPE is:32.47% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :60.29 & 40.50% & 0.86\n",
      "for 2022-10-03, MAE is:78.27 & sMAPE is:37.81% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :60.36 & 40.49% & 0.87\n",
      "for 2022-10-04, MAE is:73.51 & sMAPE is:29.67% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :60.41 & 40.45% & 0.87\n",
      "for 2022-10-05, MAE is:135.73 & sMAPE is:119.90% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :60.68 & 40.74% & 0.86\n",
      "for 2022-10-06, MAE is:30.72 & sMAPE is:117.73% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :60.57 & 41.01% & 0.86\n",
      "for 2022-10-07, MAE is:20.14 & sMAPE is:88.73% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :60.42 & 41.18% & 0.86\n",
      "for 2022-10-08, MAE is:33.43 & sMAPE is:111.16% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :60.33 & 41.43% & 0.86\n",
      "for 2022-10-09, MAE is:99.16 & sMAPE is:140.94% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :60.47 & 41.78% & 0.86\n",
      "for 2022-10-10, MAE is:64.70 & sMAPE is:63.27% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :60.48 & 41.86% & 0.86\n",
      "for 2022-10-11, MAE is:111.57 & sMAPE is:55.75% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :60.66 & 41.91% & 0.86\n",
      "for 2022-10-12, MAE is:65.77 & sMAPE is:23.12% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :60.68 & 41.84% & 0.86\n",
      "for 2022-10-13, MAE is:56.93 & sMAPE is:24.35% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :60.67 & 41.78% & 0.86\n",
      "for 2022-10-14, MAE is:72.07 & sMAPE is:31.83% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :60.71 & 41.75% & 0.86\n",
      "for 2022-10-15, MAE is:20.04 & sMAPE is:12.45% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :60.56 & 41.65% & 0.85\n",
      "for 2022-10-16, MAE is:54.10 & sMAPE is:81.37% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :60.54 & 41.78% & 0.85\n",
      "for 2022-10-17, MAE is:47.34 & sMAPE is:33.82% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :60.50 & 41.76% & 0.86\n",
      "for 2022-10-18, MAE is:44.55 & sMAPE is:28.20% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :60.44 & 41.71% & 0.85\n",
      "for 2022-10-19, MAE is:34.61 & sMAPE is:22.72% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :60.35 & 41.64% & 0.85\n",
      "for 2022-10-20, MAE is:24.24 & sMAPE is:18.64% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :60.23 & 41.57% & 0.85\n",
      "for 2022-10-21, MAE is:48.84 & sMAPE is:37.64% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :60.19 & 41.55% & 0.85\n",
      "for 2022-10-22, MAE is:33.50 & sMAPE is:27.79% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :60.10 & 41.51% & 0.85\n",
      "for 2022-10-23, MAE is:13.14 & sMAPE is:13.50% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :59.94 & 41.41% & 0.85\n",
      "for 2022-10-24, MAE is:15.79 & sMAPE is:20.38% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :59.79 & 41.34% & 0.85\n",
      "for 2022-10-25, MAE is:43.63 & sMAPE is:52.57% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :59.74 & 41.38% & 0.85\n",
      "for 2022-10-26, MAE is:39.68 & sMAPE is:40.34% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :59.67 & 41.37% & 0.85\n",
      "for 2022-10-27, MAE is:57.65 & sMAPE is:60.96% & rMAE is:2.87 ||| daily mean of MAE & sMAPE & rMAE till now are :59.67 & 41.44% & 0.85\n",
      "for 2022-10-28, MAE is:19.71 & sMAPE is:22.69% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :59.53 & 41.38% & 0.85\n",
      "for 2022-10-29, MAE is:38.40 & sMAPE is:55.60% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :59.46 & 41.42% & 0.85\n",
      "for 2022-10-30, MAE is:39.04 & sMAPE is:39.58% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :59.40 & 41.42% & 0.85\n",
      "for 2022-10-31, MAE is:55.97 & sMAPE is:48.12% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :59.38 & 41.44% & 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-11-01, MAE is:18.84 & sMAPE is:27.60% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :59.25 & 41.39% & 0.85\n",
      "for 2022-11-02, MAE is:44.82 & sMAPE is:111.01% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :59.20 & 41.62% & 0.85\n",
      "for 2022-11-03, MAE is:42.80 & sMAPE is:63.08% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :59.15 & 41.69% & 0.85\n",
      "for 2022-11-04, MAE is:120.98 & sMAPE is:119.52% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :59.35 & 41.94% & 0.86\n",
      "for 2022-11-05, MAE is:48.72 & sMAPE is:54.92% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :59.32 & 41.99% & 0.86\n",
      "for 2022-11-06, MAE is:22.52 & sMAPE is:99.66% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :59.20 & 42.17% & 0.86\n",
      "for 2022-11-07, MAE is:34.91 & sMAPE is:105.53% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :59.12 & 42.38% & 0.85\n",
      "for 2022-11-08, MAE is:30.56 & sMAPE is:91.83% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :59.03 & 42.54% & 0.86\n",
      "for 2022-11-09, MAE is:96.99 & sMAPE is:164.42% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :59.15 & 42.92% & 0.86\n",
      "for 2022-11-10, MAE is:53.37 & sMAPE is:76.80% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :59.13 & 43.03% & 0.86\n",
      "for 2022-11-11, MAE is:21.08 & sMAPE is:150.61% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :59.01 & 43.37% & 0.86\n",
      "for 2022-11-12, MAE is:151.93 & sMAPE is:195.33% & rMAE is:2.28 ||| daily mean of MAE & sMAPE & rMAE till now are :59.30 & 43.85% & 0.86\n",
      "for 2022-11-13, MAE is:45.13 & sMAPE is:36.71% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :59.26 & 43.83% & 0.86\n",
      "for 2022-11-14, MAE is:60.03 & sMAPE is:46.34% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :59.26 & 43.84% & 0.86\n",
      "for 2022-11-15, MAE is:78.37 & sMAPE is:71.14% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :59.32 & 43.93% & 0.86\n",
      "for 2022-11-16, MAE is:24.28 & sMAPE is:103.24% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :59.21 & 44.11% & 0.86\n",
      "for 2022-11-17, MAE is:37.02 & sMAPE is:119.15% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :59.14 & 44.34% & 0.86\n",
      "for 2022-11-18, MAE is:93.55 & sMAPE is:151.00% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :59.25 & 44.68% & 0.86\n",
      "for 2022-11-19, MAE is:102.88 & sMAPE is:72.17% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :59.39 & 44.76% & 0.86\n",
      "for 2022-11-20, MAE is:55.43 & sMAPE is:30.31% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :59.37 & 44.72% & 0.86\n",
      "for 2022-11-21, MAE is:82.99 & sMAPE is:36.24% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :59.45 & 44.69% & 0.86\n",
      "for 2022-11-22, MAE is:23.34 & sMAPE is:13.37% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :59.33 & 44.59% & 0.86\n",
      "for 2022-11-23, MAE is:43.87 & sMAPE is:36.14% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :59.29 & 44.57% & 0.86\n",
      "for 2022-11-24, MAE is:150.04 & sMAPE is:92.11% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :59.56 & 44.71% & 0.86\n",
      "for 2022-11-25, MAE is:90.66 & sMAPE is:41.33% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :59.66 & 44.70% & 0.86\n",
      "for 2022-11-26, MAE is:34.71 & sMAPE is:16.19% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :59.58 & 44.62% & 0.86\n",
      "for 2022-11-27, MAE is:31.05 & sMAPE is:20.02% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :59.50 & 44.54% & 0.86\n",
      "for 2022-11-28, MAE is:85.04 & sMAPE is:66.45% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :59.57 & 44.61% & 0.86\n",
      "for 2022-11-29, MAE is:230.16 & sMAPE is:93.27% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :60.09 & 44.75% & 0.86\n",
      "for 2022-11-30, MAE is:143.50 & sMAPE is:43.34% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :60.34 & 44.75% & 0.86\n",
      "for 2022-12-01, MAE is:123.65 & sMAPE is:37.87% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :60.53 & 44.73% & 0.86\n",
      "for 2022-12-02, MAE is:64.69 & sMAPE is:20.81% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :60.54 & 44.66% & 0.86\n",
      "for 2022-12-03, MAE is:44.24 & sMAPE is:19.76% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :60.49 & 44.58% & 0.86\n",
      "for 2022-12-04, MAE is:75.64 & sMAPE is:33.78% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :60.53 & 44.55% & 0.86\n",
      "for 2022-12-05, MAE is:82.90 & sMAPE is:29.46% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :60.60 & 44.51% & 0.86\n",
      "for 2022-12-06, MAE is:112.80 & sMAPE is:34.77% & rMAE is:3.03 ||| daily mean of MAE & sMAPE & rMAE till now are :60.75 & 44.48% & 0.86\n",
      "for 2022-12-07, MAE is:64.93 & sMAPE is:21.04% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :60.77 & 44.41% & 0.86\n",
      "for 2022-12-08, MAE is:131.05 & sMAPE is:41.27% & rMAE is:12.51 ||| daily mean of MAE & sMAPE & rMAE till now are :60.97 & 44.40% & 0.90\n",
      "for 2022-12-09, MAE is:138.78 & sMAPE is:40.80% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :61.20 & 44.39% & 0.90\n",
      "for 2022-12-10, MAE is:91.07 & sMAPE is:29.72% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :61.28 & 44.35% & 0.90\n",
      "for 2022-12-11, MAE is:60.60 & sMAPE is:21.16% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :61.28 & 44.28% & 0.90\n",
      "for 2022-12-12, MAE is:151.57 & sMAPE is:40.63% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :61.54 & 44.27% & 0.90\n",
      "for 2022-12-13, MAE is:123.51 & sMAPE is:30.55% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :61.72 & 44.23% & 0.91\n",
      "for 2022-12-14, MAE is:154.45 & sMAPE is:41.10% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :61.99 & 44.22% & 0.91\n",
      "for 2022-12-15, MAE is:92.58 & sMAPE is:27.32% & rMAE is:5.21 ||| daily mean of MAE & sMAPE & rMAE till now are :62.08 & 44.17% & 0.92\n",
      "for 2022-12-16, MAE is:79.24 & sMAPE is:21.44% & rMAE is:2.94 ||| daily mean of MAE & sMAPE & rMAE till now are :62.13 & 44.11% & 0.93\n",
      "for 2022-12-17, MAE is:52.76 & sMAPE is:19.52% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :62.10 & 44.04% & 0.92\n",
      "for 2022-12-18, MAE is:37.35 & sMAPE is:21.23% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :62.03 & 43.97% & 0.92\n",
      "for 2022-12-19, MAE is:49.97 & sMAPE is:32.03% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :61.99 & 43.94% & 0.92\n",
      "for 2022-12-20, MAE is:18.42 & sMAPE is:10.74% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :61.87 & 43.85% & 0.92\n",
      "for 2022-12-21, MAE is:39.32 & sMAPE is:23.19% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :61.81 & 43.79% & 0.92\n",
      "for 2022-12-22, MAE is:30.24 & sMAPE is:20.77% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :61.72 & 43.72% & 0.91\n",
      "for 2022-12-23, MAE is:36.60 & sMAPE is:24.53% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :61.65 & 43.67% & 0.91\n",
      "for 2022-12-24, MAE is:18.28 & sMAPE is:18.39% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :61.53 & 43.60% & 0.91\n",
      "for 2022-12-25, MAE is:21.21 & sMAPE is:24.96% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :61.42 & 43.55% & 0.91\n",
      "for 2022-12-26, MAE is:44.33 & sMAPE is:71.95% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :61.37 & 43.63% & 0.91\n",
      "for 2022-12-27, MAE is:60.80 & sMAPE is:134.18% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :61.37 & 43.88% & 0.91\n",
      "for 2022-12-28, MAE is:15.96 & sMAPE is:46.41% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :61.24 & 43.88% & 0.90\n",
      "for 2022-12-29, MAE is:18.02 & sMAPE is:96.58% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :61.12 & 44.03% & 0.90\n",
      "for 2022-12-30, MAE is:14.25 & sMAPE is:104.19% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :60.99 & 44.19% & 0.90\n",
      "for 2022-12-31, MAE is:20.42 & sMAPE is:146.92% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :60.88 & 44.48% & 0.90\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 08:59:21,850]\u001b[0m A new study created in RDB with name: DK_2_2023\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 125.13 | sMAPE for Validation Set is: 72.59% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 32.13 | sMAPE for Test Set is: 45.07% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 08:59:37,605]\u001b[0m Trial 1 finished with value: 125.13322355564303 and parameters: {'n_hidden': 4, 'learning_rate': 0.06308809105151324, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1388404687774732, 'dropout_rate_Layer_2': 0.06373496762752269, 'dropout_rate_Layer_3': 0.3923242598781038, 'dropout_rate_Layer_4': 0.2757286669038081, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00296205283774186, 'l1_Layer_2': 1.1683428423494158e-05, 'l1_Layer_3': 0.007529148843005659, 'l1_Layer_4': 0.04225394960827774, 'n_units_Layer_1': 95, 'n_units_Layer_2': 90, 'n_units_Layer_3': 80, 'n_units_Layer_4': 50}. Best is trial 1 with value: 125.13322355564303.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 08:59:41,093]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 08:59:44,200]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 08:59:49,414]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 08:59:54,920]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:00:04,602]\u001b[0m Trial 0 finished with value: 109.58669411873684 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018564095606159047, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38528236368841223, 'dropout_rate_Layer_2': 0.2664891156331703, 'dropout_rate_Layer_3': 0.14805202632716838, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0003023993514996829, 'l1_Layer_2': 0.000811659967867785, 'l1_Layer_3': 0.0007634492938751588, 'n_units_Layer_1': 260, 'n_units_Layer_2': 80, 'n_units_Layer_3': 260}. Best is trial 0 with value: 109.58669411873684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 109.59 | sMAPE for Validation Set is: 62.39% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 28.98 | sMAPE for Test Set is: 42.15% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:00:09,050]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:00:18,737]\u001b[0m Trial 10 finished with value: 126.22365186749 and parameters: {'n_hidden': 4, 'learning_rate': 0.061397692040739485, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.060494878214057524, 'dropout_rate_Layer_2': 0.04377245816087747, 'dropout_rate_Layer_3': 0.11127922417053387, 'dropout_rate_Layer_4': 0.196847334240786, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.03077982329820321, 'l1_Layer_2': 0.005776310710942007, 'l1_Layer_3': 0.0004275873014659569, 'l1_Layer_4': 0.005742679832026609, 'n_units_Layer_1': 90, 'n_units_Layer_2': 160, 'n_units_Layer_3': 280, 'n_units_Layer_4': 110}. Best is trial 0 with value: 109.58669411873684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 126.22 | sMAPE for Validation Set is: 73.81% | rMAE for Validation Set is: 1.23\n",
      "MAE for Test Set is: 38.28 | sMAPE for Test Set is: 55.38% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:00:21,372]\u001b[0m Trial 3 finished with value: 106.02608838686733 and parameters: {'n_hidden': 4, 'learning_rate': 0.002008645818152116, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13085517526153034, 'dropout_rate_Layer_2': 0.04514505639956168, 'dropout_rate_Layer_3': 0.32110636776630436, 'dropout_rate_Layer_4': 0.2651568253585412, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00030138987339965793, 'l1_Layer_2': 0.005726536361497014, 'l1_Layer_3': 0.04811438105230747, 'l1_Layer_4': 0.05691187255178671, 'n_units_Layer_1': 235, 'n_units_Layer_2': 180, 'n_units_Layer_3': 215, 'n_units_Layer_4': 260}. Best is trial 3 with value: 106.02608838686733.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 106.03 | sMAPE for Validation Set is: 60.41% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 28.55 | sMAPE for Test Set is: 41.88% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:00:25,268]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:00:25,575]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 103.50 | sMAPE for Validation Set is: 59.06% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 37.65 | sMAPE for Test Set is: 47.37% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:00:30,509]\u001b[0m Trial 2 finished with value: 103.50464180225322 and parameters: {'n_hidden': 3, 'learning_rate': 0.03864209957632054, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1730473301399545, 'dropout_rate_Layer_2': 0.020360408000477028, 'dropout_rate_Layer_3': 0.31069998077063815, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0008062539062024438, 'l1_Layer_2': 0.00010812393752813131, 'l1_Layer_3': 0.0007968752613655119, 'n_units_Layer_1': 135, 'n_units_Layer_2': 100, 'n_units_Layer_3': 220}. Best is trial 2 with value: 103.50464180225322.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:00:31,946]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:00:37,063]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:00:37,500]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:00:37,626]\u001b[0m Trial 8 finished with value: 100.3876720402716 and parameters: {'n_hidden': 4, 'learning_rate': 0.002316407131927808, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17804863593692768, 'dropout_rate_Layer_2': 0.2833881430083116, 'dropout_rate_Layer_3': 0.24152593756581575, 'dropout_rate_Layer_4': 0.3775054760393287, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009723726291477771, 'l1_Layer_2': 0.0343590853003818, 'l1_Layer_3': 4.899049482486343e-05, 'l1_Layer_4': 0.004722164935973411, 'n_units_Layer_1': 190, 'n_units_Layer_2': 130, 'n_units_Layer_3': 55, 'n_units_Layer_4': 260}. Best is trial 8 with value: 100.3876720402716.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 100.39 | sMAPE for Validation Set is: 57.02% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 29.73 | sMAPE for Test Set is: 41.89% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:00:54,556]\u001b[0m Trial 16 finished with value: 87.79532210497439 and parameters: {'n_hidden': 4, 'learning_rate': 0.07319211732512426, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03167048820576648, 'dropout_rate_Layer_2': 0.21012153396304561, 'dropout_rate_Layer_3': 0.365459679907087, 'dropout_rate_Layer_4': 0.37780410603407844, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02690890335454898, 'l1_Layer_2': 3.438031118484154e-05, 'l1_Layer_3': 0.04019870790890396, 'l1_Layer_4': 8.497391588342065e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 280, 'n_units_Layer_3': 220, 'n_units_Layer_4': 105}. Best is trial 16 with value: 87.79532210497439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 87.80 | sMAPE for Validation Set is: 52.05% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 36.63 | sMAPE for Test Set is: 50.51% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:00:57,452]\u001b[0m Trial 19 finished with value: 89.08410721208797 and parameters: {'n_hidden': 3, 'learning_rate': 0.01223370020506865, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04512008077520684, 'dropout_rate_Layer_2': 0.20211737328480248, 'dropout_rate_Layer_3': 0.26071438081263154, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9812745778932748e-05, 'l1_Layer_2': 0.00021465035944314407, 'l1_Layer_3': 3.593369402776004e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 75, 'n_units_Layer_3': 260}. Best is trial 16 with value: 87.79532210497439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 89.08 | sMAPE for Validation Set is: 52.30% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 48.73 | sMAPE for Test Set is: 52.35% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:01:01,008]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:01:02,616]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:01:07,270]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:01:07,326]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:01:07,489]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 100.26 | sMAPE for Validation Set is: 56.73% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 40.26 | sMAPE for Test Set is: 49.14% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:01:11,287]\u001b[0m Trial 18 finished with value: 100.2608423047625 and parameters: {'n_hidden': 4, 'learning_rate': 0.04669811670084749, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3371940970394125, 'dropout_rate_Layer_2': 0.31459411404135984, 'dropout_rate_Layer_3': 0.09779856374487489, 'dropout_rate_Layer_4': 0.2649858436715995, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00039242574158327825, 'l1_Layer_2': 0.0029183760306680487, 'l1_Layer_3': 2.295175967908086e-05, 'l1_Layer_4': 0.010939026681174838, 'n_units_Layer_1': 240, 'n_units_Layer_2': 230, 'n_units_Layer_3': 300, 'n_units_Layer_4': 70}. Best is trial 16 with value: 87.79532210497439.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:01:18,871]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:01:19,193]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:01:19,395]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:01:19,415]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:01:29,387]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:01:29,647]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:01:35,875]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:01:37,240]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:01:38,414]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:01:51,220]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:01:55,313]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:02:07,452]\u001b[0m Trial 34 finished with value: 104.95699700510924 and parameters: {'n_hidden': 3, 'learning_rate': 0.013040441129990952, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18280259161764875, 'dropout_rate_Layer_2': 0.3580815961349208, 'dropout_rate_Layer_3': 0.024002139177569593, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.005664655722480509, 'l1_Layer_2': 0.0002445462334516914, 'l1_Layer_3': 0.0011569630388114506, 'n_units_Layer_1': 145, 'n_units_Layer_2': 60, 'n_units_Layer_3': 195}. Best is trial 16 with value: 87.79532210497439.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 104.96 | sMAPE for Validation Set is: 60.90% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 30.58 | sMAPE for Test Set is: 42.36% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:02:11,048]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:02:16,024]\u001b[0m Trial 38 finished with value: 78.57264492635066 and parameters: {'n_hidden': 3, 'learning_rate': 0.006536354328290078, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39542582236060503, 'dropout_rate_Layer_2': 0.2640326117561418, 'dropout_rate_Layer_3': 0.003888249877079669, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005268264226229864, 'l1_Layer_2': 0.00012837141855775975, 'l1_Layer_3': 1.1022021955481574e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 180, 'n_units_Layer_3': 225}. Best is trial 38 with value: 78.57264492635066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 78.57 | sMAPE for Validation Set is: 47.86% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 24.64 | sMAPE for Test Set is: 36.55% | rMAE for Test Set is: 0.55\n",
      "MAE for Validation Set is: 94.06 | sMAPE for Validation Set is: 54.63% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 31.41 | sMAPE for Test Set is: 43.31% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:02:18,718]\u001b[0m Trial 28 finished with value: 94.05842345736768 and parameters: {'n_hidden': 4, 'learning_rate': 0.002610831829378666, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29408644587469335, 'dropout_rate_Layer_2': 0.27964469125812896, 'dropout_rate_Layer_3': 0.14351969210104484, 'dropout_rate_Layer_4': 0.22919325919253986, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.004244990308321994, 'l1_Layer_2': 1.551020402689169e-05, 'l1_Layer_3': 0.09077537394504423, 'l1_Layer_4': 4.397265161653183e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 265, 'n_units_Layer_3': 80, 'n_units_Layer_4': 120}. Best is trial 38 with value: 78.57264492635066.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:02:21,849]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:02:25,036]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:02:28,746]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:02:30,495]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:02:32,990]\u001b[0m Trial 40 finished with value: 54.17100481256287 and parameters: {'n_hidden': 3, 'learning_rate': 0.007405014249607501, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3965136308842892, 'dropout_rate_Layer_2': 0.25352732743502404, 'dropout_rate_Layer_3': 0.07165398665478909, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06119055461969113, 'l1_Layer_2': 0.0010032552954352234, 'l1_Layer_3': 1.2135320695467818e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 175, 'n_units_Layer_3': 210}. Best is trial 40 with value: 54.17100481256287.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.17 | sMAPE for Validation Set is: 39.12% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 26.03 | sMAPE for Test Set is: 40.59% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:02:33,435]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:02:37,787]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:02:38,477]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:02:43,079]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:02:43,690]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:02:47,824]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:02:58,077]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:02:58,271]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:02:58,838]\u001b[0m Trial 52 finished with value: 57.33617503763465 and parameters: {'n_hidden': 3, 'learning_rate': 0.03172964231614236, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3563647211626422, 'dropout_rate_Layer_2': 0.2818619080506174, 'dropout_rate_Layer_3': 0.07350807935935041, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.888213183501734e-05, 'l1_Layer_2': 3.664488309076981e-05, 'l1_Layer_3': 0.00017133829225330198, 'n_units_Layer_1': 250, 'n_units_Layer_2': 230, 'n_units_Layer_3': 280}. Best is trial 40 with value: 54.17100481256287.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.34 | sMAPE for Validation Set is: 40.35% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 27.28 | sMAPE for Test Set is: 39.34% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:03:04,548]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:03:05,187]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:03:06,065]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:03:12,838]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:03:19,269]\u001b[0m Trial 41 finished with value: 86.25578616320281 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031000210447714397, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08734832539912625, 'dropout_rate_Layer_2': 0.294726798728883, 'dropout_rate_Layer_3': 0.10517303417314716, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005776119328364345, 'l1_Layer_2': 3.0254602714313397e-05, 'l1_Layer_3': 9.323117858725294e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 280, 'n_units_Layer_3': 265}. Best is trial 40 with value: 54.17100481256287.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 86.26 | sMAPE for Validation Set is: 51.17% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 32.55 | sMAPE for Test Set is: 44.30% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:03:20,853]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:03:21,840]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:03:25,832]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:03:29,058]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:03:31,003]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:03:33,592]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:03:35,421]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:03:38,080]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:03:47,210]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:03:47,425]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:03:52,871]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:03:55,815]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:04:00,186]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:04:05,247]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:05:04,420]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 91.99 | sMAPE for Validation Set is: 54.27% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 32.39 | sMAPE for Test Set is: 45.79% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:05:06,098]\u001b[0m Trial 57 finished with value: 91.99355239212844 and parameters: {'n_hidden': 3, 'learning_rate': 0.006179930489655099, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25638772707208085, 'dropout_rate_Layer_2': 0.16247105501802633, 'dropout_rate_Layer_3': 0.23666343590404013, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004909674169551995, 'l1_Layer_2': 0.0016730303502971802, 'l1_Layer_3': 8.055767595260885e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 150, 'n_units_Layer_3': 285}. Best is trial 40 with value: 54.17100481256287.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:05:11,031]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:05:14,424]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:05:17,881]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:05:21,924]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:05:26,061]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:05:33,891]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:05:47,421]\u001b[0m Trial 76 finished with value: 89.0857623736996 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012303476603383015, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3846894093961509, 'dropout_rate_Layer_2': 0.10228639936531236, 'dropout_rate_Layer_3': 0.17408088617132128, 'dropout_rate_Layer_4': 0.02935199350068235, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011445173713866478, 'l1_Layer_2': 0.00047262020269881914, 'l1_Layer_3': 0.003523238437119683, 'l1_Layer_4': 0.004292378910047879, 'n_units_Layer_1': 210, 'n_units_Layer_2': 255, 'n_units_Layer_3': 170, 'n_units_Layer_4': 155}. Best is trial 40 with value: 54.17100481256287.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 89.09 | sMAPE for Validation Set is: 51.56% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 30.76 | sMAPE for Test Set is: 41.46% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:05:51,835]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:05:55,859]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:05:56,378]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:06:02,433]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:06:13,011]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:06:39,512]\u001b[0m Trial 89 finished with value: 51.32015720630158 and parameters: {'n_hidden': 3, 'learning_rate': 0.001256450316253298, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3550555548300718, 'dropout_rate_Layer_2': 0.31683866088645024, 'dropout_rate_Layer_3': 0.18128065776271468, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012693035649182205, 'l1_Layer_2': 0.00044103495415847183, 'l1_Layer_3': 0.0005820155846464377, 'n_units_Layer_1': 300, 'n_units_Layer_2': 255, 'n_units_Layer_3': 245}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.32 | sMAPE for Validation Set is: 37.50% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 24.63 | sMAPE for Test Set is: 37.61% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:06:45,818]\u001b[0m Trial 75 finished with value: 79.93446429588525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005609579915160237, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14033006683508287, 'dropout_rate_Layer_2': 0.11371539134543107, 'dropout_rate_Layer_3': 0.305972692434053, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025750860373257, 'l1_Layer_2': 0.0031446832615271434, 'l1_Layer_3': 0.0001161153821864376, 'n_units_Layer_1': 215, 'n_units_Layer_2': 155, 'n_units_Layer_3': 295}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 79.93 | sMAPE for Validation Set is: 48.84% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 32.22 | sMAPE for Test Set is: 44.39% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:06:56,471]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:07:01,223]\u001b[0m Trial 86 finished with value: 76.01364534794699 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012494508682758991, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33425437585152523, 'dropout_rate_Layer_2': 0.010050823179863638, 'dropout_rate_Layer_3': 0.06663318455761455, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0322631669888616e-05, 'l1_Layer_2': 0.00048006552663146484, 'l1_Layer_3': 0.00360334620821572, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 180}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 76.01 | sMAPE for Validation Set is: 46.51% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 62.59 | sMAPE for Test Set is: 57.92% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:07:04,009]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:07:06,428]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:07:25,831]\u001b[0m Trial 94 finished with value: 87.30716413464044 and parameters: {'n_hidden': 3, 'learning_rate': 0.02795309740000284, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38006285580745297, 'dropout_rate_Layer_2': 0.2111388265065585, 'dropout_rate_Layer_3': 0.06477622683213138, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017943062380428106, 'l1_Layer_2': 3.300800018002237e-05, 'l1_Layer_3': 0.0066022436497691715, 'n_units_Layer_1': 295, 'n_units_Layer_2': 185, 'n_units_Layer_3': 180}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 87.31 | sMAPE for Validation Set is: 53.68% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 42.61 | sMAPE for Test Set is: 69.23% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:07:39,428]\u001b[0m Trial 90 finished with value: 72.98129987051311 and parameters: {'n_hidden': 3, 'learning_rate': 0.001257448591981916, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3528909564338352, 'dropout_rate_Layer_2': 0.005002235807622879, 'dropout_rate_Layer_3': 0.06367042047300338, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8487867904630177e-05, 'l1_Layer_2': 0.0004447109685798709, 'l1_Layer_3': 0.0021940800178202866, 'n_units_Layer_1': 215, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.98 | sMAPE for Validation Set is: 45.22% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 57.05 | sMAPE for Test Set is: 55.41% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:07:45,427]\u001b[0m Trial 95 finished with value: 76.79730926994047 and parameters: {'n_hidden': 4, 'learning_rate': 0.004413745470904332, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07975076265464152, 'dropout_rate_Layer_2': 0.046675219304012396, 'dropout_rate_Layer_3': 0.3583117474241057, 'dropout_rate_Layer_4': 0.13101811156677176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.9456508217525905e-05, 'l1_Layer_2': 8.455264000939166e-05, 'l1_Layer_3': 0.003200039131358241, 'l1_Layer_4': 0.06565869203499024, 'n_units_Layer_1': 270, 'n_units_Layer_2': 125, 'n_units_Layer_3': 115, 'n_units_Layer_4': 255}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 76.80 | sMAPE for Validation Set is: 47.82% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 30.54 | sMAPE for Test Set is: 47.84% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:07:45,917]\u001b[0m Trial 72 finished with value: 76.70308736413328 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005107347863082467, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13528826573508945, 'dropout_rate_Layer_2': 0.07701772973710111, 'dropout_rate_Layer_3': 0.3277420183777602, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027262302241402457, 'l1_Layer_2': 0.0029687329959302124, 'l1_Layer_3': 8.163231717485227e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 165, 'n_units_Layer_3': 295}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 76.70 | sMAPE for Validation Set is: 46.98% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 33.85 | sMAPE for Test Set is: 44.12% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:07:50,044]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:07:51,945]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:07:54,044]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:07:55,920]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:08:00,279]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:08:03,481]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:08:06,702]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:08:09,294]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:08:14,194]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:08:18,233]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:08:22,684]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:08:33,232]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:08:36,606]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:08:40,057]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:08:49,557]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:09:04,663]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:09:08,828]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:09:12,858]\u001b[0m Trial 113 finished with value: 100.191703217811 and parameters: {'n_hidden': 3, 'learning_rate': 0.012028300849304948, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39628536968087813, 'dropout_rate_Layer_2': 0.2647547211202972, 'dropout_rate_Layer_3': 0.015417033145654221, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0004811601333746638, 'l1_Layer_2': 0.06160779774085682, 'l1_Layer_3': 0.010958158260244724, 'n_units_Layer_1': 300, 'n_units_Layer_2': 55, 'n_units_Layer_3': 140}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 100.19 | sMAPE for Validation Set is: 57.91% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 32.44 | sMAPE for Test Set is: 45.40% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:09:14,829]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:09:17,794]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:09:20,275]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:09:23,595]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:09:24,641]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:09:29,111]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:09:29,537]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:09:35,007]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:09:36,190]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:09:39,651]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:09:43,236]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:09:44,645]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:09:51,332]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:09:55,778]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:03,612]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.52 | sMAPE for Validation Set is: 39.57% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 26.97 | sMAPE for Test Set is: 39.47% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:10:05,250]\u001b[0m Trial 117 finished with value: 55.523362367566214 and parameters: {'n_hidden': 3, 'learning_rate': 0.004515311261870892, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12556521530619708, 'dropout_rate_Layer_2': 0.3921160657538264, 'dropout_rate_Layer_3': 0.12647682113101447, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0036584638246184736, 'l1_Layer_2': 1.116030122418926e-05, 'l1_Layer_3': 1.0680161372434712e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 200, 'n_units_Layer_3': 110}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:06,080]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:08,183]\u001b[0m Trial 129 finished with value: 95.49938602617999 and parameters: {'n_hidden': 3, 'learning_rate': 0.006921189229846044, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.213636694370141, 'dropout_rate_Layer_2': 0.06200381504972529, 'dropout_rate_Layer_3': 0.2941252426985771, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1324841239970418e-05, 'l1_Layer_2': 0.0009929681191173855, 'l1_Layer_3': 3.105527909206046e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 210, 'n_units_Layer_3': 230}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 95.50 | sMAPE for Validation Set is: 55.40% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 42.35 | sMAPE for Test Set is: 50.12% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:10:10,976]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:13,355]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:14,527]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:15,913]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:17,601]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:19,610]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:20,314]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:21,995]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:25,654]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:27,718]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:32,407]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:33,826]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:37,631]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:39,226]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:40,569]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:51,706]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:51,907]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:10:59,416]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:11:05,344]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:11:05,668]\u001b[0m Trial 147 finished with value: 83.0047575952458 and parameters: {'n_hidden': 4, 'learning_rate': 0.00264653434728081, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38132498238572443, 'dropout_rate_Layer_2': 0.202252540100943, 'dropout_rate_Layer_3': 0.2646222550056549, 'dropout_rate_Layer_4': 0.09340216654680696, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.030196204598268363, 'l1_Layer_2': 4.896653796163961e-05, 'l1_Layer_3': 0.0007678424348432583, 'l1_Layer_4': 1.3844481922062916e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 290, 'n_units_Layer_3': 190, 'n_units_Layer_4': 185}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 83.00 | sMAPE for Validation Set is: 51.97% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 44.88 | sMAPE for Test Set is: 66.84% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:11:10,543]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:11:15,185]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.14 | sMAPE for Validation Set is: 38.39% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 25.59 | sMAPE for Test Set is: 37.68% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:11:16,862]\u001b[0m Trial 148 finished with value: 53.140618359813914 and parameters: {'n_hidden': 3, 'learning_rate': 0.001342305317757664, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35019909422755935, 'dropout_rate_Layer_2': 0.3600951962515187, 'dropout_rate_Layer_3': 0.10904404735513729, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03382249813929767, 'l1_Layer_2': 0.0012231314804794764, 'l1_Layer_3': 0.0004938072993777172, 'n_units_Layer_1': 300, 'n_units_Layer_2': 235, 'n_units_Layer_3': 245}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:11:23,974]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:11:25,582]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:11:30,452]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:11:32,137]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:11:33,221]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:11:38,444]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:11:46,865]\u001b[0m Trial 156 finished with value: 59.07192904361633 and parameters: {'n_hidden': 3, 'learning_rate': 0.004447457003874525, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12017441811654299, 'dropout_rate_Layer_2': 0.10607692184080575, 'dropout_rate_Layer_3': 0.16919725574018696, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006452499566520329, 'l1_Layer_2': 1.1201625092106335e-05, 'l1_Layer_3': 1.2233339990342028e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 210, 'n_units_Layer_3': 105}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.07 | sMAPE for Validation Set is: 41.34% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.77 | sMAPE for Test Set is: 42.47% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:11:47,367]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:11:53,292]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:11:54,989]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:00,735]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:05,058]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:07,552]\u001b[0m Trial 161 finished with value: 52.78682298167263 and parameters: {'n_hidden': 3, 'learning_rate': 0.002917854370931618, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3730633934565163, 'dropout_rate_Layer_2': 0.27727663896662913, 'dropout_rate_Layer_3': 0.12413981727048909, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012819873275821122, 'l1_Layer_2': 0.0014571602578096188, 'l1_Layer_3': 0.00048398767822123255, 'n_units_Layer_1': 280, 'n_units_Layer_2': 210, 'n_units_Layer_3': 295}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.79 | sMAPE for Validation Set is: 38.14% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.25 | sMAPE for Test Set is: 38.47% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:12:08,019]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.30 | sMAPE for Validation Set is: 41.70% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.95 | sMAPE for Test Set is: 39.55% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:12:13,034]\u001b[0m Trial 163 finished with value: 60.29846648725939 and parameters: {'n_hidden': 3, 'learning_rate': 0.004388794919582573, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11665897629395411, 'dropout_rate_Layer_2': 0.3721796945187835, 'dropout_rate_Layer_3': 0.16938143460609004, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007899939939667817, 'l1_Layer_2': 1.1534291776339247e-05, 'l1_Layer_3': 1.8389703053419887e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 60, 'n_units_Layer_3': 105}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:17,135]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:19,894]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:24,199]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:26,482]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:30,596]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:30,674]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:37,507]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:37,977]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:43,114]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:43,607]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:43,777]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:51,809]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:56,077]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:57,381]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:12:59,231]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:13:03,592]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:13:07,654]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:13:09,826]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:13:13,063]\u001b[0m Trial 170 finished with value: 60.35293242622354 and parameters: {'n_hidden': 3, 'learning_rate': 0.000549975557307348, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12940293738137337, 'dropout_rate_Layer_2': 0.39466366645214834, 'dropout_rate_Layer_3': 0.15395146280946392, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006505245200209827, 'l1_Layer_2': 1.0332607523288275e-05, 'l1_Layer_3': 1.8843567656694124e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 225, 'n_units_Layer_3': 105}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.35 | sMAPE for Validation Set is: 42.21% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.18 | sMAPE for Test Set is: 40.02% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:13:20,521]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:13:28,102]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:13:46,607]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:13:49,591]\u001b[0m Trial 188 finished with value: 60.6225462670695 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005462058709420759, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013952890276874408, 'dropout_rate_Layer_2': 0.3963675491209562, 'dropout_rate_Layer_3': 0.1770620676320412, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006359639716775653, 'l1_Layer_2': 1.1435326756767573e-05, 'l1_Layer_3': 1.0664174338958209e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 230, 'n_units_Layer_3': 165}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.62 | sMAPE for Validation Set is: 42.56% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.84 | sMAPE for Test Set is: 43.62% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:13:51,890]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:13:55,057]\u001b[0m Trial 190 finished with value: 56.10008852449126 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008152443264744721, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1437971367093884, 'dropout_rate_Layer_2': 0.399450135900868, 'dropout_rate_Layer_3': 0.16972765706499898, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00713456502710781, 'l1_Layer_2': 1.2174973958535406e-05, 'l1_Layer_3': 1.1301856718526201e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 230, 'n_units_Layer_3': 165}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.10 | sMAPE for Validation Set is: 40.12% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 26.30 | sMAPE for Test Set is: 39.66% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:13:55,572]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:00,562]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:02,431]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:07,483]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:09,978]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:12,410]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:13,896]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:15,307]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:19,596]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:27,452]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:31,431]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:31,747]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:32,068]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:39,489]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:39,701]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:40,110]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:40,264]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:49,680]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:55,192]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:57,761]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:14:58,338]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:00,475]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:02,669]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:03,765]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:04,613]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:06,459]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:12,952]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:13,202]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:13,628]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:17,222]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:21,296]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:23,278]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:23,527]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:25,216]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:29,105]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:33,507]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:37,474]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:39,825]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:44,754]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:45,688]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:52,570]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:54,475]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:15:57,727]\u001b[0m Trial 232 finished with value: 56.50518825810811 and parameters: {'n_hidden': 3, 'learning_rate': 0.0115647602079022, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10565123621909875, 'dropout_rate_Layer_2': 0.32421829870143243, 'dropout_rate_Layer_3': 0.21074460145047846, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0023843209430609216, 'l1_Layer_2': 3.421355448116907e-05, 'l1_Layer_3': 2.8752617528307656e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 250, 'n_units_Layer_3': 125}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.51 | sMAPE for Validation Set is: 39.56% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 27.65 | sMAPE for Test Set is: 40.03% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:16:00,512]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:16:04,512]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:16:07,372]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:16:14,066]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:16:23,121]\u001b[0m Trial 239 finished with value: 56.23167753196267 and parameters: {'n_hidden': 3, 'learning_rate': 0.011500321336048114, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10326096580778213, 'dropout_rate_Layer_2': 0.3142717493892864, 'dropout_rate_Layer_3': 0.06078079845003308, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0033040073205073484, 'l1_Layer_2': 2.77913769892462e-05, 'l1_Layer_3': 0.0003230437751349026, 'n_units_Layer_1': 240, 'n_units_Layer_2': 250, 'n_units_Layer_3': 120}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.23 | sMAPE for Validation Set is: 40.98% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 27.92 | sMAPE for Test Set is: 44.01% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:16:27,498]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:16:31,068]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:16:31,818]\u001b[0m Trial 241 finished with value: 57.916091413606146 and parameters: {'n_hidden': 3, 'learning_rate': 0.012943417784895177, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16327529943075847, 'dropout_rate_Layer_2': 0.3195008510244442, 'dropout_rate_Layer_3': 0.21292384566278394, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002086512417236629, 'l1_Layer_2': 4.032787524378036e-05, 'l1_Layer_3': 0.00021970614248602915, 'n_units_Layer_1': 250, 'n_units_Layer_2': 260, 'n_units_Layer_3': 160}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.92 | sMAPE for Validation Set is: 40.73% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.99 | sMAPE for Test Set is: 41.74% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:16:36,032]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:16:36,654]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.41 | sMAPE for Validation Set is: 40.10% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 26.33 | sMAPE for Test Set is: 39.10% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:16:40,301]\u001b[0m Trial 243 finished with value: 56.41302265122922 and parameters: {'n_hidden': 3, 'learning_rate': 0.014413212532559914, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1673599848532982, 'dropout_rate_Layer_2': 0.32210374595768504, 'dropout_rate_Layer_3': 0.07061725253082375, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026086875330252786, 'l1_Layer_2': 4.170149510620056e-05, 'l1_Layer_3': 0.0002296057110425166, 'n_units_Layer_1': 255, 'n_units_Layer_2': 255, 'n_units_Layer_3': 150}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:16:41,537]\u001b[0m Trial 245 finished with value: 56.76238495240997 and parameters: {'n_hidden': 3, 'learning_rate': 0.014170713072357927, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09395493882590569, 'dropout_rate_Layer_2': 0.3269634481916404, 'dropout_rate_Layer_3': 0.06533073253520055, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029173124562188375, 'l1_Layer_2': 4.502755094602984e-05, 'l1_Layer_3': 3.488420736191602e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.76 | sMAPE for Validation Set is: 40.21% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 27.24 | sMAPE for Test Set is: 41.93% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:16:43,444]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:16:43,623]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:16:49,223]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:16:53,512]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:16:54,181]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:16:56,468]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:00,269]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:05,230]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:05,630]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:08,262]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:10,647]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:13,817]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:15,320]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:15,405]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:15,553]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:17,935]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:26,364]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:26,753]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:29,302]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:30,015]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:38,775]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:39,254]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:43,929]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:50,997]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:17:59,195]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:18:02,850]\u001b[0m Trial 276 finished with value: 87.37701155103728 and parameters: {'n_hidden': 4, 'learning_rate': 0.010666856508287796, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05738883606577806, 'dropout_rate_Layer_2': 0.3947607388734256, 'dropout_rate_Layer_3': 0.17190227168868077, 'dropout_rate_Layer_4': 0.12377970913429125, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0009520898944442477, 'l1_Layer_2': 4.4924372849914055e-05, 'l1_Layer_3': 0.0005527224001014502, 'l1_Layer_4': 0.00023176506574233756, 'n_units_Layer_1': 300, 'n_units_Layer_2': 55, 'n_units_Layer_3': 185, 'n_units_Layer_4': 125}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 87.38 | sMAPE for Validation Set is: 52.37% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 35.85 | sMAPE for Test Set is: 49.14% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:18:04,777]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:18:09,165]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:18:18,900]\u001b[0m Trial 279 finished with value: 55.292724131143245 and parameters: {'n_hidden': 3, 'learning_rate': 0.006329375380828321, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14599778562725216, 'dropout_rate_Layer_2': 0.2829737297953689, 'dropout_rate_Layer_3': 0.12907611867468433, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000995060428054257, 'l1_Layer_2': 2.035087465746912e-05, 'l1_Layer_3': 4.434480518384059e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 205, 'n_units_Layer_3': 90}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.29 | sMAPE for Validation Set is: 39.97% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 28.26 | sMAPE for Test Set is: 43.73% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:18:22,786]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:18:31,431]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:18:34,595]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:18:46,189]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:18:56,937]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:19:01,467]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:19:08,596]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:19:11,622]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:19:16,145]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:19:18,181]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:19:22,167]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:19:24,945]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:19:27,391]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:19:29,752]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:19:33,050]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:19:37,171]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:19:39,823]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:19:55,568]\u001b[0m Trial 299 finished with value: 59.16354769040752 and parameters: {'n_hidden': 3, 'learning_rate': 0.021437403440000946, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20063552689241282, 'dropout_rate_Layer_2': 0.3986591813078523, 'dropout_rate_Layer_3': 0.08988021787083834, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010602707953370279, 'l1_Layer_2': 1.8513990945525534e-05, 'l1_Layer_3': 0.0006269263788670975, 'n_units_Layer_1': 225, 'n_units_Layer_2': 240, 'n_units_Layer_3': 125}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.16 | sMAPE for Validation Set is: 43.14% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 33.35 | sMAPE for Test Set is: 49.40% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:20:04,143]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:20:07,840]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:20:24,743]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:20:27,142]\u001b[0m Trial 281 finished with value: 59.693900832726825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022827794766463756, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3588241984030209, 'dropout_rate_Layer_2': 0.15604378208195382, 'dropout_rate_Layer_3': 0.09688144354128608, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003615442308738633, 'l1_Layer_2': 0.00016277770317894087, 'l1_Layer_3': 3.337789242552393e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 130, 'n_units_Layer_3': 70}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.69 | sMAPE for Validation Set is: 41.82% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.01 | sMAPE for Test Set is: 39.76% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:20:30,448]\u001b[0m Trial 302 finished with value: 54.589168717019824 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033786531165180163, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3469455218129891, 'dropout_rate_Layer_2': 0.3109671125298863, 'dropout_rate_Layer_3': 0.09086451205477875, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.031171218349371043, 'l1_Layer_2': 0.0011131194471629194, 'l1_Layer_3': 0.0007435467749873763, 'n_units_Layer_1': 300, 'n_units_Layer_2': 230, 'n_units_Layer_3': 125}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.59 | sMAPE for Validation Set is: 38.94% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 25.42 | sMAPE for Test Set is: 37.69% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:20:31,161]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:20:40,241]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:20:42,006]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:20:45,254]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:20:50,536]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:20:52,002]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:20:54,106]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:21:01,028]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:21:01,459]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:21:12,283]\u001b[0m Trial 312 finished with value: 58.91519649668112 and parameters: {'n_hidden': 3, 'learning_rate': 0.04292711414046574, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08648965165769784, 'dropout_rate_Layer_2': 0.2952103302389297, 'dropout_rate_Layer_3': 0.1914309283853851, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0047584436000584745, 'l1_Layer_2': 6.738602986971084e-05, 'l1_Layer_3': 0.00015249786276945026, 'n_units_Layer_1': 200, 'n_units_Layer_2': 210, 'n_units_Layer_3': 295}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.92 | sMAPE for Validation Set is: 41.55% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 32.01 | sMAPE for Test Set is: 46.69% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:21:28,017]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:21:30,125]\u001b[0m Trial 314 finished with value: 51.38053319085228 and parameters: {'n_hidden': 3, 'learning_rate': 0.002815736916378304, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22992741630420566, 'dropout_rate_Layer_2': 0.08479546592154819, 'dropout_rate_Layer_3': 0.09479584716743714, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005408928441609571, 'l1_Layer_2': 0.0006837132174893561, 'l1_Layer_3': 1.466265253414987e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 120}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.38 | sMAPE for Validation Set is: 37.23% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 25.01 | sMAPE for Test Set is: 39.08% | rMAE for Test Set is: 0.56\n",
      "MAE for Validation Set is: 53.85 | sMAPE for Validation Set is: 39.24% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 27.67 | sMAPE for Test Set is: 41.23% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:21:32,649]\u001b[0m Trial 315 finished with value: 53.84661619753368 and parameters: {'n_hidden': 3, 'learning_rate': 0.0083801472846619, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14509390087978474, 'dropout_rate_Layer_2': 0.1752764002557397, 'dropout_rate_Layer_3': 0.3982696908490841, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.017250039986544827, 'l1_Layer_2': 1.6968644922516437e-05, 'l1_Layer_3': 0.0003731297809681284, 'n_units_Layer_1': 175, 'n_units_Layer_2': 270, 'n_units_Layer_3': 70}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:21:46,575]\u001b[0m Trial 271 finished with value: 56.27866463060165 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015364587985588942, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3648463173531254, 'dropout_rate_Layer_2': 0.15297832866186836, 'dropout_rate_Layer_3': 0.2673678646892106, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9846728244175685e-05, 'l1_Layer_2': 0.0001952709176623332, 'l1_Layer_3': 0.0026112380550011136, 'n_units_Layer_1': 205, 'n_units_Layer_2': 280, 'n_units_Layer_3': 135}. Best is trial 89 with value: 51.32015720630158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.28 | sMAPE for Validation Set is: 40.27% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 27.72 | sMAPE for Test Set is: 39.39% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:21:57,750]\u001b[0m Trial 316 finished with value: 50.48443708645869 and parameters: {'n_hidden': 3, 'learning_rate': 0.0039301966204361395, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2024769587987398, 'dropout_rate_Layer_2': 0.2847315320770141, 'dropout_rate_Layer_3': 0.06631570606088058, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007493716618290754, 'l1_Layer_2': 6.866150961864832e-05, 'l1_Layer_3': 2.610671538557291e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 70, 'n_units_Layer_3': 90}. Best is trial 316 with value: 50.48443708645869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.48 | sMAPE for Validation Set is: 37.16% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 25.19 | sMAPE for Test Set is: 37.98% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:22:03,962]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:22:15,523]\u001b[0m Trial 320 finished with value: 53.15954566751287 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038006050605122192, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2273638467143158, 'dropout_rate_Layer_2': 0.28877081916956227, 'dropout_rate_Layer_3': 0.04888390635419737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005783674938329062, 'l1_Layer_2': 6.57982611212031e-05, 'l1_Layer_3': 1.8388308576380584e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 70, 'n_units_Layer_3': 85}. Best is trial 316 with value: 50.48443708645869.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.16 | sMAPE for Validation Set is: 38.34% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 26.62 | sMAPE for Test Set is: 39.50% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:22:37,773]\u001b[0m Trial 321 finished with value: 49.859640975492255 and parameters: {'n_hidden': 3, 'learning_rate': 0.003974828748081166, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2042371766221834, 'dropout_rate_Layer_2': 0.02735779709387052, 'dropout_rate_Layer_3': 0.06480930193259524, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003953010490199778, 'l1_Layer_2': 7.469394331929952e-05, 'l1_Layer_3': 1.75709709169983e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 75, 'n_units_Layer_3': 85}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.86 | sMAPE for Validation Set is: 36.73% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 25.26 | sMAPE for Test Set is: 38.39% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:22:42,442]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:22:55,861]\u001b[0m Trial 322 finished with value: 51.111762662648154 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038350210030240295, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20638411561831224, 'dropout_rate_Layer_2': 0.09196217907871387, 'dropout_rate_Layer_3': 0.04778187792965145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005510378267334033, 'l1_Layer_2': 6.141742019744761e-05, 'l1_Layer_3': 1.9136281849681043e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 55, 'n_units_Layer_3': 90}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.11 | sMAPE for Validation Set is: 37.07% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 25.10 | sMAPE for Test Set is: 37.03% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:23:32,964]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:23:52,931]\u001b[0m Trial 318 finished with value: 61.64459572223089 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029374301720667497, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36680104920762285, 'dropout_rate_Layer_2': 0.18294600256888613, 'dropout_rate_Layer_3': 0.07238617304618322, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001866139726676577, 'l1_Layer_2': 0.0004110004144105255, 'l1_Layer_3': 0.004479018357634863, 'n_units_Layer_1': 215, 'n_units_Layer_2': 275, 'n_units_Layer_3': 70}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.64 | sMAPE for Validation Set is: 42.84% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.11 | sMAPE for Test Set is: 41.21% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:24:28,535]\u001b[0m Trial 327 finished with value: 50.11069869941506 and parameters: {'n_hidden': 3, 'learning_rate': 0.003930070663695921, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19668535219664296, 'dropout_rate_Layer_2': 0.07822819913918772, 'dropout_rate_Layer_3': 0.04723414570739398, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003442925467725817, 'l1_Layer_2': 5.737842374567517e-05, 'l1_Layer_3': 2.5486453543380925e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 70, 'n_units_Layer_3': 90}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.11 | sMAPE for Validation Set is: 37.19% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 26.15 | sMAPE for Test Set is: 40.20% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:24:45,093]\u001b[0m Trial 328 finished with value: 52.50271070990101 and parameters: {'n_hidden': 3, 'learning_rate': 0.004040414836962164, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2038173742068397, 'dropout_rate_Layer_2': 0.07747122472453474, 'dropout_rate_Layer_3': 0.04855574306502365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004686125984566692, 'l1_Layer_2': 5.753931681565672e-05, 'l1_Layer_3': 2.657730297038976e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 70, 'n_units_Layer_3': 90}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.50 | sMAPE for Validation Set is: 37.88% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 26.70 | sMAPE for Test Set is: 38.61% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:24:59,214]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:25:03,271]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:25:06,610]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:25:38,853]\u001b[0m Trial 323 finished with value: 58.194712685925445 and parameters: {'n_hidden': 3, 'learning_rate': 0.001411934894277647, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3679260182024249, 'dropout_rate_Layer_2': 0.18425414850815616, 'dropout_rate_Layer_3': 0.09252163305352658, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016555308334605353, 'l1_Layer_2': 0.00010025581815068901, 'l1_Layer_3': 0.004994156111964228, 'n_units_Layer_1': 220, 'n_units_Layer_2': 275, 'n_units_Layer_3': 200}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.19 | sMAPE for Validation Set is: 40.98% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.56 | sMAPE for Test Set is: 39.05% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:25:45,898]\u001b[0m Trial 326 finished with value: 63.593876629141015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022250447134110254, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3542363827450218, 'dropout_rate_Layer_2': 0.18585803402528933, 'dropout_rate_Layer_3': 0.09469679098722916, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.283814338573273e-05, 'l1_Layer_2': 0.0002124081924619683, 'l1_Layer_3': 0.004328029633685621, 'n_units_Layer_1': 215, 'n_units_Layer_2': 275, 'n_units_Layer_3': 165}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 63.59 | sMAPE for Validation Set is: 43.59% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 32.06 | sMAPE for Test Set is: 42.65% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:25:51,070]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:26:11,004]\u001b[0m Trial 334 finished with value: 51.68236388377219 and parameters: {'n_hidden': 3, 'learning_rate': 0.005751990770520523, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20811823995325265, 'dropout_rate_Layer_2': 0.06638057344772899, 'dropout_rate_Layer_3': 0.03263678086390362, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0027630334406642003, 'l1_Layer_2': 9.192782147291831e-05, 'l1_Layer_3': 1.3845767873845879e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 80, 'n_units_Layer_3': 85}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.68 | sMAPE for Validation Set is: 37.64% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 27.44 | sMAPE for Test Set is: 38.75% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:26:27,829]\u001b[0m Trial 324 finished with value: 55.07320669604786 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014470531022889675, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35503768149581943, 'dropout_rate_Layer_2': 0.1850576277728147, 'dropout_rate_Layer_3': 0.0696130858508274, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.0482740674952994e-05, 'l1_Layer_2': 0.00023781141396079253, 'l1_Layer_3': 0.003938489331446473, 'n_units_Layer_1': 220, 'n_units_Layer_2': 275, 'n_units_Layer_3': 200}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.07 | sMAPE for Validation Set is: 39.59% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 28.14 | sMAPE for Test Set is: 39.93% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:26:46,411]\u001b[0m Trial 336 finished with value: 50.083650593320584 and parameters: {'n_hidden': 3, 'learning_rate': 0.0055732535196088995, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21042869186513963, 'dropout_rate_Layer_2': 0.06903136057512925, 'dropout_rate_Layer_3': 0.022612498385800896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0030004892536768884, 'l1_Layer_2': 9.90350843160384e-05, 'l1_Layer_3': 1.862423227836237e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 80, 'n_units_Layer_3': 85}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.08 | sMAPE for Validation Set is: 37.03% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 25.69 | sMAPE for Test Set is: 39.39% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:26:50,756]\u001b[0m Trial 337 finished with value: 51.6504361522045 and parameters: {'n_hidden': 3, 'learning_rate': 0.005961129386424524, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21508309351376098, 'dropout_rate_Layer_2': 0.10865064603522884, 'dropout_rate_Layer_3': 0.04803599350449887, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002719422589562211, 'l1_Layer_2': 9.868587601996227e-05, 'l1_Layer_3': 1.813877003962494e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 80, 'n_units_Layer_3': 85}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.65 | sMAPE for Validation Set is: 37.74% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 25.81 | sMAPE for Test Set is: 38.85% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:27:14,864]\u001b[0m Trial 338 finished with value: 52.28718000861186 and parameters: {'n_hidden': 3, 'learning_rate': 0.006135863238284495, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2100457374418896, 'dropout_rate_Layer_2': 0.07505714270704793, 'dropout_rate_Layer_3': 0.038099473379473205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028275201619967264, 'l1_Layer_2': 9.87171028593482e-05, 'l1_Layer_3': 1.9064726646144656e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 80, 'n_units_Layer_3': 85}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.29 | sMAPE for Validation Set is: 37.56% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 27.18 | sMAPE for Test Set is: 39.90% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:27:18,735]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:27:35,672]\u001b[0m Trial 332 finished with value: 62.08003661336624 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022308078349594983, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38941040303691354, 'dropout_rate_Layer_2': 0.18158863499348388, 'dropout_rate_Layer_3': 0.06680875571487131, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012619444839529425, 'l1_Layer_2': 0.00020733635040576652, 'l1_Layer_3': 0.004349638127280976, 'n_units_Layer_1': 220, 'n_units_Layer_2': 275, 'n_units_Layer_3': 80}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.08 | sMAPE for Validation Set is: 42.93% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 32.67 | sMAPE for Test Set is: 42.93% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:27:51,549]\u001b[0m Trial 335 finished with value: 60.59444317937521 and parameters: {'n_hidden': 3, 'learning_rate': 0.002093613726104821, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3563117212669682, 'dropout_rate_Layer_2': 0.1853648297521262, 'dropout_rate_Layer_3': 0.06927862492503879, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006660421810036724, 'l1_Layer_2': 7.066260712603411e-05, 'l1_Layer_3': 0.005662912979976802, 'n_units_Layer_1': 220, 'n_units_Layer_2': 275, 'n_units_Layer_3': 200}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.59 | sMAPE for Validation Set is: 42.23% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 30.09 | sMAPE for Test Set is: 41.41% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:28:00,636]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:28:01,012]\u001b[0m Trial 342 finished with value: 51.294468640799124 and parameters: {'n_hidden': 3, 'learning_rate': 0.005823427869860587, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20592786987253608, 'dropout_rate_Layer_2': 0.09926654665128475, 'dropout_rate_Layer_3': 0.018791784814454298, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003397419856256036, 'l1_Layer_2': 8.328316418310611e-05, 'l1_Layer_3': 1.2610494825681165e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 85, 'n_units_Layer_3': 95}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.29 | sMAPE for Validation Set is: 37.65% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 25.14 | sMAPE for Test Set is: 37.50% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:28:18,178]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:29:14,893]\u001b[0m Trial 341 finished with value: 61.4794114929582 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022187929759866533, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3487551636779717, 'dropout_rate_Layer_2': 0.1799626639021211, 'dropout_rate_Layer_3': 0.09498517090879088, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011487324534986952, 'l1_Layer_2': 0.00023053114867763774, 'l1_Layer_3': 0.005598888446924519, 'n_units_Layer_1': 220, 'n_units_Layer_2': 275, 'n_units_Layer_3': 185}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.48 | sMAPE for Validation Set is: 43.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.82 | sMAPE for Test Set is: 41.60% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:29:21,227]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:29:31,543]\u001b[0m Trial 339 finished with value: 61.786589859926046 and parameters: {'n_hidden': 3, 'learning_rate': 0.002163408185802875, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35344703641915953, 'dropout_rate_Layer_2': 0.18348306872391032, 'dropout_rate_Layer_3': 0.0695388314076213, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013206686357345645, 'l1_Layer_2': 7.041917374312016e-05, 'l1_Layer_3': 0.0058206928089210635, 'n_units_Layer_1': 220, 'n_units_Layer_2': 275, 'n_units_Layer_3': 200}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.79 | sMAPE for Validation Set is: 42.80% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 30.12 | sMAPE for Test Set is: 41.63% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:29:37,538]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:29:42,028]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:30:17,290]\u001b[0m Trial 346 finished with value: 61.53736510559167 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021175041964938495, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35649862710328556, 'dropout_rate_Layer_2': 0.1807611114576734, 'dropout_rate_Layer_3': 0.09865189205659466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011454754958646935, 'l1_Layer_2': 7.467309889864656e-05, 'l1_Layer_3': 0.005980772560061987, 'n_units_Layer_1': 215, 'n_units_Layer_2': 275, 'n_units_Layer_3': 75}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.54 | sMAPE for Validation Set is: 43.01% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 30.73 | sMAPE for Test Set is: 41.51% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:30:21,573]\u001b[0m Trial 351 finished with value: 59.7095945054215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007116365717472771, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39083730315961446, 'dropout_rate_Layer_2': 0.12982230021703067, 'dropout_rate_Layer_3': 0.16707753739704054, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0023815072340116136, 'l1_Layer_2': 1.3886661161403551e-05, 'l1_Layer_3': 1.5238196096426968e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 165, 'n_units_Layer_3': 300}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.71 | sMAPE for Validation Set is: 42.03% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 30.25 | sMAPE for Test Set is: 45.48% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:30:37,110]\u001b[0m Trial 352 finished with value: 52.76553694418272 and parameters: {'n_hidden': 3, 'learning_rate': 0.008344514929606391, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14881406740930994, 'dropout_rate_Layer_2': 0.18381368232977865, 'dropout_rate_Layer_3': 0.11224057355204275, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009946456289056329, 'l1_Layer_2': 0.00017757630291845172, 'l1_Layer_3': 6.338131624697039e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 225, 'n_units_Layer_3': 50}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.77 | sMAPE for Validation Set is: 38.17% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.37 | sMAPE for Test Set is: 37.62% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:30:41,395]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:30:44,412]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:30:54,252]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:30:57,652]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:30:58,827]\u001b[0m Trial 353 finished with value: 50.32624046261236 and parameters: {'n_hidden': 3, 'learning_rate': 0.004890673562545782, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.209986550863074, 'dropout_rate_Layer_2': 0.04970291662479201, 'dropout_rate_Layer_3': 0.04132891747645831, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00471539135968213, 'l1_Layer_2': 9.205326988454636e-05, 'l1_Layer_3': 1.5396491655548227e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 55, 'n_units_Layer_3': 75}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.33 | sMAPE for Validation Set is: 36.91% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 26.19 | sMAPE for Test Set is: 38.96% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:31:05,734]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:31:25,930]\u001b[0m Trial 359 finished with value: 53.02688373847699 and parameters: {'n_hidden': 3, 'learning_rate': 0.006167100290664911, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19685165933861487, 'dropout_rate_Layer_2': 0.043084932375311503, 'dropout_rate_Layer_3': 0.05853670946494441, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00833293094678966, 'l1_Layer_2': 0.0001419585061134675, 'l1_Layer_3': 1.7962591606057564e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 60, 'n_units_Layer_3': 95}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.03 | sMAPE for Validation Set is: 38.37% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 26.12 | sMAPE for Test Set is: 40.03% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:31:28,043]\u001b[0m Trial 360 finished with value: 52.658028213682975 and parameters: {'n_hidden': 3, 'learning_rate': 0.005481831949460353, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19732618173014713, 'dropout_rate_Layer_2': 0.06828757593097838, 'dropout_rate_Layer_3': 0.059449898709643054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008581734775157397, 'l1_Layer_2': 5.659048424396655e-05, 'l1_Layer_3': 1.786077507040582e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 50, 'n_units_Layer_3': 95}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.66 | sMAPE for Validation Set is: 37.87% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 26.48 | sMAPE for Test Set is: 38.97% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:31:34,524]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:31:46,217]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:31:51,582]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:32:11,428]\u001b[0m Trial 365 finished with value: 52.964789459677604 and parameters: {'n_hidden': 3, 'learning_rate': 0.007020645992844395, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22586499868290943, 'dropout_rate_Layer_2': 0.017188666068718314, 'dropout_rate_Layer_3': 0.045231347327167035, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003376111397416783, 'l1_Layer_2': 7.643585328163618e-05, 'l1_Layer_3': 2.2850446428526782e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 70, 'n_units_Layer_3': 65}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.96 | sMAPE for Validation Set is: 38.39% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 29.61 | sMAPE for Test Set is: 40.68% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:32:11,886]\u001b[0m Trial 363 finished with value: 59.052122421693916 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007031401968344568, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06684441942429198, 'dropout_rate_Layer_2': 0.07662819089503392, 'dropout_rate_Layer_3': 0.22076078640128882, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024073949361461756, 'l1_Layer_2': 1.0706704299298304e-05, 'l1_Layer_3': 1.352245779222671e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 170, 'n_units_Layer_3': 295}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.05 | sMAPE for Validation Set is: 41.46% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 29.04 | sMAPE for Test Set is: 42.51% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:32:18,961]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:32:19,290]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:32:27,613]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:32:27,910]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:32:32,738]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:32:39,034]\u001b[0m Trial 358 finished with value: 60.82498732581484 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018548012241997158, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31314529713209305, 'dropout_rate_Layer_2': 0.14862596654651822, 'dropout_rate_Layer_3': 0.11714223870621729, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006597277903719145, 'l1_Layer_2': 5.3583850812383123e-05, 'l1_Layer_3': 0.01663133256879132, 'n_units_Layer_1': 205, 'n_units_Layer_2': 260, 'n_units_Layer_3': 70}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.82 | sMAPE for Validation Set is: 42.29% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.43 | sMAPE for Test Set is: 40.90% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:32:42,277]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:32:42,921]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:32:51,126]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:32:53,169]\u001b[0m Trial 370 finished with value: 51.75654299719207 and parameters: {'n_hidden': 3, 'learning_rate': 0.004820783197419786, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2358170822419931, 'dropout_rate_Layer_2': 0.04791336278252606, 'dropout_rate_Layer_3': 0.06553325817536125, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005722642346256006, 'l1_Layer_2': 5.839304223952108e-05, 'l1_Layer_3': 1.5538347633077594e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 50, 'n_units_Layer_3': 75}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.76 | sMAPE for Validation Set is: 37.52% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 27.71 | sMAPE for Test Set is: 39.32% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:32:56,340]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:33:00,558]\u001b[0m Trial 347 finished with value: 59.920727229158295 and parameters: {'n_hidden': 3, 'learning_rate': 0.002213315426163798, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36483894158378816, 'dropout_rate_Layer_2': 0.18589110824524926, 'dropout_rate_Layer_3': 0.10028547345852475, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001162295349098654, 'l1_Layer_2': 8.055784923174045e-05, 'l1_Layer_3': 0.0059672951613040336, 'n_units_Layer_1': 215, 'n_units_Layer_2': 275, 'n_units_Layer_3': 80}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.92 | sMAPE for Validation Set is: 41.78% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 29.47 | sMAPE for Test Set is: 40.83% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:33:06,864]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:33:12,265]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:33:12,581]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:33:20,728]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:33:24,299]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:33:30,807]\u001b[0m Trial 379 finished with value: 52.660147239656034 and parameters: {'n_hidden': 3, 'learning_rate': 0.004224946314239346, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23594905243105854, 'dropout_rate_Layer_2': 0.07239023788862337, 'dropout_rate_Layer_3': 0.05087245188299019, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010540859788328664, 'l1_Layer_2': 4.2597934954305795e-05, 'l1_Layer_3': 2.6247943706042525e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 80, 'n_units_Layer_3': 70}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.66 | sMAPE for Validation Set is: 38.26% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 26.94 | sMAPE for Test Set is: 41.54% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:33:31,282]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:33:38,172]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:33:46,500]\u001b[0m Trial 381 finished with value: 51.417243434837985 and parameters: {'n_hidden': 3, 'learning_rate': 0.003818682697995104, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1874363023326442, 'dropout_rate_Layer_2': 0.060695999626137455, 'dropout_rate_Layer_3': 0.06569353984449831, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005725311323168475, 'l1_Layer_2': 6.705588618781019e-05, 'l1_Layer_3': 1.5983780866524164e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 75, 'n_units_Layer_3': 75}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.42 | sMAPE for Validation Set is: 37.40% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 26.11 | sMAPE for Test Set is: 37.73% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:33:51,834]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:34:03,074]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:34:04,078]\u001b[0m Trial 385 finished with value: 52.73147246092819 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007904588381638782, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0923145007231828, 'dropout_rate_Layer_2': 0.08035433569539015, 'dropout_rate_Layer_3': 0.26893470381255613, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026227330411757963, 'l1_Layer_2': 1.2430230016150544e-05, 'l1_Layer_3': 1.7614895313118278e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.73 | sMAPE for Validation Set is: 38.42% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.18 | sMAPE for Test Set is: 38.14% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:34:08,973]\u001b[0m Trial 384 finished with value: 51.120850705770515 and parameters: {'n_hidden': 3, 'learning_rate': 0.003793262083961217, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1874228433333484, 'dropout_rate_Layer_2': 0.050810539746643665, 'dropout_rate_Layer_3': 0.062427639506300044, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005487380541003404, 'l1_Layer_2': 0.00011323474299908096, 'l1_Layer_3': 1.6490906845856288e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 75, 'n_units_Layer_3': 75}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.12 | sMAPE for Validation Set is: 37.13% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 25.72 | sMAPE for Test Set is: 38.09% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:34:14,283]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:34:23,751]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:34:29,422]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:34:36,169]\u001b[0m Trial 390 finished with value: 51.29348613172257 and parameters: {'n_hidden': 3, 'learning_rate': 0.004458685490772406, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1663596066426607, 'dropout_rate_Layer_2': 0.027623061871607405, 'dropout_rate_Layer_3': 0.03876704924693722, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004549150613717236, 'l1_Layer_2': 8.050378522573575e-05, 'l1_Layer_3': 1.0393569088083915e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 80, 'n_units_Layer_3': 95}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.29 | sMAPE for Validation Set is: 37.40% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 26.23 | sMAPE for Test Set is: 38.15% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:34:38,921]\u001b[0m Trial 391 finished with value: 51.010147471011955 and parameters: {'n_hidden': 3, 'learning_rate': 0.004649671594615548, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1649555668471232, 'dropout_rate_Layer_2': 0.028128255824220117, 'dropout_rate_Layer_3': 0.03698151033245495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003991461983823246, 'l1_Layer_2': 3.7501703340455707e-05, 'l1_Layer_3': 1.014302378761942e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 80, 'n_units_Layer_3': 95}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.01 | sMAPE for Validation Set is: 37.39% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 25.24 | sMAPE for Test Set is: 37.38% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:34:44,314]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:34:47,314]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:34:50,843]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:34:57,666]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:35:02,051]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:35:05,586]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:35:09,206]\u001b[0m Trial 398 finished with value: 52.171706545706314 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036953996486451543, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1551874986766057, 'dropout_rate_Layer_2': 0.030096952557249205, 'dropout_rate_Layer_3': 0.011390140229192915, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003975568422062343, 'l1_Layer_2': 3.1225933677505245e-05, 'l1_Layer_3': 1.1886924960858135e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 90, 'n_units_Layer_3': 100}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.17 | sMAPE for Validation Set is: 37.72% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 26.51 | sMAPE for Test Set is: 38.43% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:35:33,291]\u001b[0m Trial 401 finished with value: 52.09187190774016 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007195758099011807, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09252810076839552, 'dropout_rate_Layer_2': 0.12437719323311588, 'dropout_rate_Layer_3': 0.27201319242450506, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026600246146901057, 'l1_Layer_2': 1.2387487899358098e-05, 'l1_Layer_3': 1.846771241969761e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.09 | sMAPE for Validation Set is: 38.27% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.37 | sMAPE for Test Set is: 38.28% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:35:38,867]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:35:41,035]\u001b[0m Trial 403 finished with value: 51.11042724715487 and parameters: {'n_hidden': 3, 'learning_rate': 0.005459990013165772, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17593386628197702, 'dropout_rate_Layer_2': 0.029808474396273214, 'dropout_rate_Layer_3': 0.025707430593982887, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005358471238177455, 'l1_Layer_2': 8.674708450687906e-05, 'l1_Layer_3': 1.6051819001091022e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 90, 'n_units_Layer_3': 70}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.11 | sMAPE for Validation Set is: 37.33% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 28.10 | sMAPE for Test Set is: 39.60% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:35:47,541]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:36:07,235]\u001b[0m Trial 406 finished with value: 51.02992175519528 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037174513371613467, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15656520215524325, 'dropout_rate_Layer_2': 0.03018307427341801, 'dropout_rate_Layer_3': 0.028616379429718286, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004797846379019936, 'l1_Layer_2': 2.4400671670430673e-05, 'l1_Layer_3': 1.4967456198096727e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 90, 'n_units_Layer_3': 90}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.03 | sMAPE for Validation Set is: 37.47% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 27.41 | sMAPE for Test Set is: 39.74% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:36:11,436]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:36:12,130]\u001b[0m Trial 407 finished with value: 53.94369298787549 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007868457928019748, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027424819067421835, 'dropout_rate_Layer_2': 0.12736171270859187, 'dropout_rate_Layer_3': 0.26931287457080116, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020385575151252158, 'l1_Layer_2': 2.1074454639584957e-05, 'l1_Layer_3': 1.699798072561343e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 145, 'n_units_Layer_3': 290}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.94 | sMAPE for Validation Set is: 39.03% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 25.69 | sMAPE for Test Set is: 39.20% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:36:24,664]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:36:30,070]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:36:33,618]\u001b[0m Trial 392 finished with value: 60.30924149193354 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015295742238847754, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3383607795465269, 'dropout_rate_Layer_2': 0.19598357970176555, 'dropout_rate_Layer_3': 0.08360950332919807, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002513893756811283, 'l1_Layer_2': 3.4423478233699575e-05, 'l1_Layer_3': 0.009070922310585438, 'n_units_Layer_1': 200, 'n_units_Layer_2': 265, 'n_units_Layer_3': 100}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.31 | sMAPE for Validation Set is: 42.20% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.21 | sMAPE for Test Set is: 43.64% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:36:43,280]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:36:56,582]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:37:29,092]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:37:33,163]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:37:40,695]\u001b[0m Trial 408 finished with value: 60.53740471567077 and parameters: {'n_hidden': 3, 'learning_rate': 0.001385560728308007, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3910694117550734, 'dropout_rate_Layer_2': 0.21496516341020258, 'dropout_rate_Layer_3': 0.059102837781417186, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004839945430898371, 'l1_Layer_2': 0.0002827967572220984, 'l1_Layer_3': 0.005053181887929504, 'n_units_Layer_1': 220, 'n_units_Layer_2': 280, 'n_units_Layer_3': 105}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.54 | sMAPE for Validation Set is: 41.94% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 33.12 | sMAPE for Test Set is: 43.50% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:37:51,156]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:37:56,924]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:38:25,445]\u001b[0m Trial 421 finished with value: 50.58599810564166 and parameters: {'n_hidden': 3, 'learning_rate': 0.004257693938602424, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1710013259973602, 'dropout_rate_Layer_2': 0.07782903185564957, 'dropout_rate_Layer_3': 0.04069905142458578, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00493935097570193, 'l1_Layer_2': 5.858915382517659e-05, 'l1_Layer_3': 1.9439991395374413e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 90, 'n_units_Layer_3': 85}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.59 | sMAPE for Validation Set is: 37.18% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 28.55 | sMAPE for Test Set is: 40.55% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:38:31,463]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:39:03,246]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:39:15,506]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:39:20,131]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:39:54,506]\u001b[0m Trial 418 finished with value: 59.01481293742258 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024997873731457325, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35120569205336327, 'dropout_rate_Layer_2': 0.17300035127005325, 'dropout_rate_Layer_3': 0.08576257634435533, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015963395132972025, 'l1_Layer_2': 8.978565580210374e-05, 'l1_Layer_3': 0.005195465391932915, 'n_units_Layer_1': 215, 'n_units_Layer_2': 270, 'n_units_Layer_3': 90}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.01 | sMAPE for Validation Set is: 41.72% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 30.02 | sMAPE for Test Set is: 41.29% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:39:58,419]\u001b[0m Trial 426 finished with value: 51.86411322366424 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008247858555105551, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025426465598341455, 'dropout_rate_Layer_2': 0.1294738184029746, 'dropout_rate_Layer_3': 0.26841692956366525, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025786437467671707, 'l1_Layer_2': 1.363284945157987e-05, 'l1_Layer_3': 1.669052196130583e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 115, 'n_units_Layer_3': 290}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.86 | sMAPE for Validation Set is: 38.25% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 26.68 | sMAPE for Test Set is: 38.87% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:40:03,375]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:40:07,573]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:40:23,640]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:40:31,776]\u001b[0m Trial 413 finished with value: 60.83713029096469 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013849264753546732, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3236773716773127, 'dropout_rate_Layer_2': 0.1238070245447951, 'dropout_rate_Layer_3': 0.040759567668674154, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016387170326809882, 'l1_Layer_2': 0.00031662846919461703, 'l1_Layer_3': 0.005335624503979037, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 100}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.84 | sMAPE for Validation Set is: 42.29% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.91 | sMAPE for Test Set is: 41.65% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:40:32,317]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:40:37,677]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:40:38,110]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:40:51,726]\u001b[0m Trial 434 finished with value: 53.819174126062535 and parameters: {'n_hidden': 3, 'learning_rate': 0.019803916412739295, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2187570025676865, 'dropout_rate_Layer_2': 0.2380838045523284, 'dropout_rate_Layer_3': 0.10513731196880033, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014331044173629937, 'l1_Layer_2': 0.0017175710239690082, 'l1_Layer_3': 0.0009558490763996966, 'n_units_Layer_1': 80, 'n_units_Layer_2': 220, 'n_units_Layer_3': 255}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.82 | sMAPE for Validation Set is: 39.17% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 30.04 | sMAPE for Test Set is: 40.98% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:40:58,684]\u001b[0m Trial 432 finished with value: 52.90958291004241 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007830081165200757, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.036005067342836025, 'dropout_rate_Layer_2': 0.12382813611915917, 'dropout_rate_Layer_3': 0.272204102451035, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.107106651797324e-05, 'l1_Layer_2': 1.1705130121635953e-05, 'l1_Layer_3': 1.671754582126725e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.91 | sMAPE for Validation Set is: 38.57% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.47 | sMAPE for Test Set is: 37.98% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:40:59,308]\u001b[0m Trial 435 finished with value: 51.72713126216354 and parameters: {'n_hidden': 3, 'learning_rate': 0.004563177621050492, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20749597885638074, 'dropout_rate_Layer_2': 0.09710991931651729, 'dropout_rate_Layer_3': 0.04054015470745875, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004429885521585168, 'l1_Layer_2': 7.563361078848468e-05, 'l1_Layer_3': 1.200978143542236e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 85, 'n_units_Layer_3': 100}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.73 | sMAPE for Validation Set is: 37.98% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 27.04 | sMAPE for Test Set is: 41.05% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:41:13,884]\u001b[0m Trial 429 finished with value: 60.77504358721844 and parameters: {'n_hidden': 3, 'learning_rate': 0.0046796633044997775, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33320121801338065, 'dropout_rate_Layer_2': 0.21363087329961097, 'dropout_rate_Layer_3': 0.050529215444063115, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008492287769571881, 'l1_Layer_2': 0.00017233659237548768, 'l1_Layer_3': 0.0017447650867767335, 'n_units_Layer_1': 235, 'n_units_Layer_2': 295, 'n_units_Layer_3': 110}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.78 | sMAPE for Validation Set is: 42.32% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.93 | sMAPE for Test Set is: 40.98% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:41:14,337]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:41:24,413]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:41:40,531]\u001b[0m Trial 440 finished with value: 54.066793179696255 and parameters: {'n_hidden': 3, 'learning_rate': 0.018372450602792252, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21616150994197425, 'dropout_rate_Layer_2': 0.233951231644561, 'dropout_rate_Layer_3': 0.1480080143862092, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014523432798952893, 'l1_Layer_2': 0.002151658892925629, 'l1_Layer_3': 0.001287856658129321, 'n_units_Layer_1': 80, 'n_units_Layer_2': 220, 'n_units_Layer_3': 250}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.07 | sMAPE for Validation Set is: 38.86% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 25.86 | sMAPE for Test Set is: 38.67% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:41:41,428]\u001b[0m Trial 441 finished with value: 51.8597564172753 and parameters: {'n_hidden': 3, 'learning_rate': 0.003837024946304153, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16074748249660484, 'dropout_rate_Layer_2': 0.08539295668508236, 'dropout_rate_Layer_3': 0.03354732358392919, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0029913458053919015, 'l1_Layer_2': 0.00011215234948258731, 'l1_Layer_3': 1.1593492701821991e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 105, 'n_units_Layer_3': 85}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.86 | sMAPE for Validation Set is: 37.99% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 26.83 | sMAPE for Test Set is: 38.96% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:41:46,479]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:41:59,407]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:42:06,149]\u001b[0m Trial 443 finished with value: 51.349658770613935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031785287211113316, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.162781850370217, 'dropout_rate_Layer_2': 0.016049535123586978, 'dropout_rate_Layer_3': 0.022100286302395997, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003112890958531697, 'l1_Layer_2': 0.00010445490511537223, 'l1_Layer_3': 1.0730723784793547e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 105, 'n_units_Layer_3': 85}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.35 | sMAPE for Validation Set is: 37.90% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 27.83 | sMAPE for Test Set is: 38.84% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:42:09,460]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:42:18,485]\u001b[0m Trial 445 finished with value: 53.576597122480074 and parameters: {'n_hidden': 3, 'learning_rate': 0.019346313973010783, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2181004668155062, 'dropout_rate_Layer_2': 0.2313356827345354, 'dropout_rate_Layer_3': 0.10377150023827514, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016039300205577213, 'l1_Layer_2': 0.002636981101046619, 'l1_Layer_3': 0.0018572881580654265, 'n_units_Layer_1': 85, 'n_units_Layer_2': 220, 'n_units_Layer_3': 255}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.58 | sMAPE for Validation Set is: 38.87% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 25.91 | sMAPE for Test Set is: 38.06% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:42:22,760]\u001b[0m Trial 446 finished with value: 51.371573083415704 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031999948769653127, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14986185557716733, 'dropout_rate_Layer_2': 0.017578384345233244, 'dropout_rate_Layer_3': 0.028890145633887823, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003050110627609842, 'l1_Layer_2': 8.641198565031852e-05, 'l1_Layer_3': 1.0584487663663375e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 110, 'n_units_Layer_3': 80}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.37 | sMAPE for Validation Set is: 38.04% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 29.43 | sMAPE for Test Set is: 40.49% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:42:35,596]\u001b[0m Trial 447 finished with value: 51.001579737122164 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031606538110768552, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16399264125765114, 'dropout_rate_Layer_2': 0.018899878510974653, 'dropout_rate_Layer_3': 0.005931524362340949, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0031285376596864446, 'l1_Layer_2': 0.00017671182146835674, 'l1_Layer_3': 1.0244329042006765e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 110, 'n_units_Layer_3': 80}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.00 | sMAPE for Validation Set is: 37.51% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 26.84 | sMAPE for Test Set is: 38.89% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:42:40,095]\u001b[0m Trial 448 finished with value: 51.41173419730789 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033367366669875493, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16328516167200838, 'dropout_rate_Layer_2': 0.021069913782607187, 'dropout_rate_Layer_3': 0.005954239181201464, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00307164823265577, 'l1_Layer_2': 0.00012045481869337825, 'l1_Layer_3': 1.0088897086431955e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 110, 'n_units_Layer_3': 80}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.41 | sMAPE for Validation Set is: 37.69% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 26.92 | sMAPE for Test Set is: 38.64% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:42:47,610]\u001b[0m Trial 449 finished with value: 55.01797722670036 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012067644807318076, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.030364895648542802, 'dropout_rate_Layer_2': 0.16464995023464782, 'dropout_rate_Layer_3': 0.26401284015281945, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.0168662711806255e-05, 'l1_Layer_2': 1.2947514121553505e-05, 'l1_Layer_3': 2.029741285014215e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 145, 'n_units_Layer_3': 240}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.02 | sMAPE for Validation Set is: 39.53% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 26.49 | sMAPE for Test Set is: 38.97% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:42:52,510]\u001b[0m Trial 438 finished with value: 61.1543021406408 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012808240228400743, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3416420759667905, 'dropout_rate_Layer_2': 0.13923259770590526, 'dropout_rate_Layer_3': 0.03744531824953908, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008771167886389809, 'l1_Layer_2': 0.000250386818304015, 'l1_Layer_3': 0.01741136813081139, 'n_units_Layer_1': 210, 'n_units_Layer_2': 285, 'n_units_Layer_3': 100}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.15 | sMAPE for Validation Set is: 42.66% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 31.26 | sMAPE for Test Set is: 42.38% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:42:53,473]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:42:59,928]\u001b[0m Trial 451 finished with value: 50.5557595958945 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031143650059669544, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14778192358731493, 'dropout_rate_Layer_2': 0.013776962076284194, 'dropout_rate_Layer_3': 0.001841240794938831, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023136978792918776, 'l1_Layer_2': 0.00018745079608965942, 'l1_Layer_3': 1.1490749010808534e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 115, 'n_units_Layer_3': 75}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.56 | sMAPE for Validation Set is: 37.55% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 28.92 | sMAPE for Test Set is: 39.94% | rMAE for Test Set is: 0.64\n",
      "MAE for Validation Set is: 50.71 | sMAPE for Validation Set is: 37.29% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 28.48 | sMAPE for Test Set is: 40.24% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:43:02,259]\u001b[0m Trial 450 finished with value: 50.70669464429458 and parameters: {'n_hidden': 3, 'learning_rate': 0.002903060889707944, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17140174751178092, 'dropout_rate_Layer_2': 0.022965263523563848, 'dropout_rate_Layer_3': 0.006821179071589443, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0031271391926568364, 'l1_Layer_2': 0.00019040198954638538, 'l1_Layer_3': 1.0311490493704451e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 115, 'n_units_Layer_3': 75}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:43:03,378]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:43:13,726]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:43:24,655]\u001b[0m Trial 455 finished with value: 53.96628346059908 and parameters: {'n_hidden': 3, 'learning_rate': 0.01936570464450123, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2787816298135118, 'dropout_rate_Layer_2': 0.241038846295341, 'dropout_rate_Layer_3': 0.08903505095866461, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001399904385183108, 'l1_Layer_2': 0.0031308778104772042, 'l1_Layer_3': 0.0013080430765532022, 'n_units_Layer_1': 80, 'n_units_Layer_2': 225, 'n_units_Layer_3': 250}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.97 | sMAPE for Validation Set is: 39.43% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 25.77 | sMAPE for Test Set is: 39.76% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:43:25,675]\u001b[0m Trial 454 finished with value: 50.964884719026564 and parameters: {'n_hidden': 3, 'learning_rate': 0.003028024311022725, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1679173749929281, 'dropout_rate_Layer_2': 0.0028386829484023796, 'dropout_rate_Layer_3': 0.004247500276517055, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022571784943028177, 'l1_Layer_2': 7.941019858544267e-05, 'l1_Layer_3': 1.0021114018379447e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 120, 'n_units_Layer_3': 70}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.96 | sMAPE for Validation Set is: 37.11% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 30.78 | sMAPE for Test Set is: 41.46% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:43:33,131]\u001b[0m Trial 457 finished with value: 51.55165487018183 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028639704664277983, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16667342960722129, 'dropout_rate_Layer_2': 0.01417750698202643, 'dropout_rate_Layer_3': 0.0049951487894915915, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021247431233553443, 'l1_Layer_2': 0.00013831382808598627, 'l1_Layer_3': 1.0436675869084946e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 115, 'n_units_Layer_3': 70}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.55 | sMAPE for Validation Set is: 37.82% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 28.57 | sMAPE for Test Set is: 39.88% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:43:46,712]\u001b[0m Trial 460 finished with value: 51.79449479290643 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028152433088356474, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17026099980452333, 'dropout_rate_Layer_2': 0.004035574506592136, 'dropout_rate_Layer_3': 0.005165710173414568, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001608297207796928, 'l1_Layer_2': 0.0002127483650435468, 'l1_Layer_3': 1.0307120818677531e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 120, 'n_units_Layer_3': 70}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.79 | sMAPE for Validation Set is: 37.99% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 29.17 | sMAPE for Test Set is: 40.00% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:43:52,614]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:43:57,277]\u001b[0m Trial 461 finished with value: 51.18612943130359 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026944572696649335, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1693957047648706, 'dropout_rate_Layer_2': 0.0039446665923457795, 'dropout_rate_Layer_3': 0.0015391546108896345, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001754301800294744, 'l1_Layer_2': 0.0002169955955636014, 'l1_Layer_3': 1.0156322821393876e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 125, 'n_units_Layer_3': 70}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.19 | sMAPE for Validation Set is: 37.83% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 26.59 | sMAPE for Test Set is: 39.33% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:44:05,431]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:44:10,768]\u001b[0m Trial 463 finished with value: 51.60226014386384 and parameters: {'n_hidden': 3, 'learning_rate': 0.002463569564281445, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15033031838894528, 'dropout_rate_Layer_2': 0.015912123998008933, 'dropout_rate_Layer_3': 0.0011787351572429055, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002106472856379556, 'l1_Layer_2': 0.00014392911510515208, 'l1_Layer_3': 1.0226771172577024e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 115, 'n_units_Layer_3': 75}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.60 | sMAPE for Validation Set is: 37.88% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 27.13 | sMAPE for Test Set is: 40.25% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:44:10,964]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:44:32,067]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:44:36,015]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:44:43,659]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:44:48,254]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:44:52,722]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:44:58,966]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:45:08,067]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:45:08,907]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:45:13,743]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:45:17,646]\u001b[0m Trial 458 finished with value: 59.35942016950977 and parameters: {'n_hidden': 3, 'learning_rate': 0.001546491164304685, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3836578131370071, 'dropout_rate_Layer_2': 0.2359903590864194, 'dropout_rate_Layer_3': 0.028111523433593837, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002689954460940143, 'l1_Layer_2': 0.0001340317432868875, 'l1_Layer_3': 0.0114296179180591, 'n_units_Layer_1': 235, 'n_units_Layer_2': 290, 'n_units_Layer_3': 115}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.36 | sMAPE for Validation Set is: 41.58% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 30.21 | sMAPE for Test Set is: 42.05% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:45:31,026]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:45:34,358]\u001b[0m Trial 474 finished with value: 51.612221206246254 and parameters: {'n_hidden': 3, 'learning_rate': 0.00328624781074885, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15519456444323038, 'dropout_rate_Layer_2': 0.01422896068949443, 'dropout_rate_Layer_3': 0.015151805134759904, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002467095846389014, 'l1_Layer_2': 0.00015767074030473798, 'l1_Layer_3': 1.2098453230813569e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 110, 'n_units_Layer_3': 55}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.61 | sMAPE for Validation Set is: 37.82% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 28.05 | sMAPE for Test Set is: 39.23% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:45:34,658]\u001b[0m Trial 477 finished with value: 51.23449505008464 and parameters: {'n_hidden': 3, 'learning_rate': 0.00248839372484451, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16463009686393282, 'dropout_rate_Layer_2': 0.03466833397263246, 'dropout_rate_Layer_3': 0.010255559696457294, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022258434871491556, 'l1_Layer_2': 8.354115928201308e-05, 'l1_Layer_3': 1.4540603834122125e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 110, 'n_units_Layer_3': 80}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.23 | sMAPE for Validation Set is: 37.94% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 29.24 | sMAPE for Test Set is: 40.34% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:45:40,522]\u001b[0m Trial 476 finished with value: 50.57374964486369 and parameters: {'n_hidden': 3, 'learning_rate': 0.003456008283229742, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16775351551512727, 'dropout_rate_Layer_2': 0.018738277895634745, 'dropout_rate_Layer_3': 0.019536205481904684, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003365171383204938, 'l1_Layer_2': 0.00019292715498259863, 'l1_Layer_3': 1.4403347104356956e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 120, 'n_units_Layer_3': 80}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.57 | sMAPE for Validation Set is: 37.23% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 29.04 | sMAPE for Test Set is: 40.30% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:45:45,957]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:45:50,862]\u001b[0m Trial 480 finished with value: 51.87472727891412 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034865561105902588, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1855535914169281, 'dropout_rate_Layer_2': 0.036910984876229305, 'dropout_rate_Layer_3': 0.023771490084237, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003282767200518231, 'l1_Layer_2': 7.960140049627513e-05, 'l1_Layer_3': 1.5241412679639307e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 105, 'n_units_Layer_3': 80}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.87 | sMAPE for Validation Set is: 38.16% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 25.92 | sMAPE for Test Set is: 38.19% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:45:51,929]\u001b[0m Trial 478 finished with value: 51.06273268572167 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034423824863933287, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16493814753428504, 'dropout_rate_Layer_2': 0.018806764731815175, 'dropout_rate_Layer_3': 0.00961357544842923, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002362721846789743, 'l1_Layer_2': 0.00020518615182179317, 'l1_Layer_3': 1.4421419971911553e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 120, 'n_units_Layer_3': 80}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.06 | sMAPE for Validation Set is: 37.65% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 29.63 | sMAPE for Test Set is: 40.10% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:45:56,023]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:46:01,777]\u001b[0m Trial 479 finished with value: 50.47115614914021 and parameters: {'n_hidden': 3, 'learning_rate': 0.002700515245857328, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1876900243092824, 'dropout_rate_Layer_2': 0.03885223100029549, 'dropout_rate_Layer_3': 0.021285269486969766, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0033622736151921757, 'l1_Layer_2': 8.049017500657695e-05, 'l1_Layer_3': 1.481270546090018e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 120, 'n_units_Layer_3': 80}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.47 | sMAPE for Validation Set is: 37.04% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 29.35 | sMAPE for Test Set is: 40.96% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:46:05,080]\u001b[0m Trial 483 finished with value: 54.02796128059621 and parameters: {'n_hidden': 3, 'learning_rate': 0.03136447465339174, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2859963508365819, 'dropout_rate_Layer_2': 0.19566240232957657, 'dropout_rate_Layer_3': 0.08376421654310293, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002401126342687774, 'l1_Layer_2': 0.003791602251784327, 'l1_Layer_3': 0.002506652931749019, 'n_units_Layer_1': 50, 'n_units_Layer_2': 270, 'n_units_Layer_3': 265}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.03 | sMAPE for Validation Set is: 39.43% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 26.16 | sMAPE for Test Set is: 38.20% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:46:05,431]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:46:15,151]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:46:16,232]\u001b[0m Trial 482 finished with value: 51.19844344350861 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035461035299973374, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17673842992215563, 'dropout_rate_Layer_2': 0.029446162722971275, 'dropout_rate_Layer_3': 0.011975471751130668, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003537496519077476, 'l1_Layer_2': 0.0002360275297159441, 'l1_Layer_3': 1.4620780403854284e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 125, 'n_units_Layer_3': 80}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.20 | sMAPE for Validation Set is: 37.75% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 27.20 | sMAPE for Test Set is: 38.75% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:46:20,452]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:46:24,542]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:46:24,991]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:46:25,650]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:46:31,007]\u001b[0m Trial 486 finished with value: 51.51522116585962 and parameters: {'n_hidden': 3, 'learning_rate': 0.00233121288733715, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17188623212664147, 'dropout_rate_Layer_2': 0.03307732232887896, 'dropout_rate_Layer_3': 0.010761058012302283, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023375144784153006, 'l1_Layer_2': 0.00023342604512197407, 'l1_Layer_3': 2.1873504396096348e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 125, 'n_units_Layer_3': 90}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.52 | sMAPE for Validation Set is: 37.72% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 27.74 | sMAPE for Test Set is: 39.01% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:46:31,748]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:46:34,546]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:46:38,344]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:46:40,253]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:46:42,591]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:46:44,493]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:46:53,507]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:46:54,364]\u001b[0m Trial 493 finished with value: 51.25936554306073 and parameters: {'n_hidden': 3, 'learning_rate': 0.002541756265512918, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16201932514802528, 'dropout_rate_Layer_2': 0.02690112215927075, 'dropout_rate_Layer_3': 0.01673844811863066, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0037406996791858266, 'l1_Layer_2': 0.00022989858929786314, 'l1_Layer_3': 1.377111889280665e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 125, 'n_units_Layer_3': 90}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.26 | sMAPE for Validation Set is: 37.57% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 29.35 | sMAPE for Test Set is: 40.71% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:47:08,150]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:47:13,168]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:47:13,771]\u001b[0m Trial 500 finished with value: 52.90896269455323 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008325656816839481, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02630443424665071, 'dropout_rate_Layer_2': 0.12827731484222019, 'dropout_rate_Layer_3': 0.2560571738923212, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.039158446769431e-05, 'l1_Layer_2': 2.1999313362543732e-05, 'l1_Layer_3': 3.4468464870345644e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 120, 'n_units_Layer_3': 270}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.91 | sMAPE for Validation Set is: 38.44% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.40 | sMAPE for Test Set is: 38.19% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:47:14,447]\u001b[0m Trial 499 finished with value: 51.10068125136863 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008643461540272397, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02179380102718345, 'dropout_rate_Layer_2': 0.12754748554529122, 'dropout_rate_Layer_3': 0.28022927731927894, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.7441745990897855e-05, 'l1_Layer_2': 2.183609676019925e-05, 'l1_Layer_3': 3.108350014058787e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 120, 'n_units_Layer_3': 265}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.10 | sMAPE for Validation Set is: 37.96% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 25.54 | sMAPE for Test Set is: 38.40% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:47:20,677]\u001b[0m Trial 502 finished with value: 51.03484759901446 and parameters: {'n_hidden': 3, 'learning_rate': 0.002621860130766467, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17877577655423776, 'dropout_rate_Layer_2': 0.03655548357468288, 'dropout_rate_Layer_3': 0.012280877145469934, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003709954962093876, 'l1_Layer_2': 0.0003215783390758314, 'l1_Layer_3': 1.6118653318966736e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 120, 'n_units_Layer_3': 95}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.03 | sMAPE for Validation Set is: 37.27% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 31.02 | sMAPE for Test Set is: 41.65% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:47:26,307]\u001b[0m Trial 505 finished with value: 154.56292320469015 and parameters: {'n_hidden': 4, 'learning_rate': 0.01947153362557967, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3340881568083206, 'dropout_rate_Layer_2': 0.14832643864231548, 'dropout_rate_Layer_3': 0.10833333402568364, 'dropout_rate_Layer_4': 0.27130491684860486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0014018008301643573, 'l1_Layer_2': 0.012652827201721416, 'l1_Layer_3': 0.004289368158011011, 'l1_Layer_4': 0.0010236462728828314, 'n_units_Layer_1': 115, 'n_units_Layer_2': 220, 'n_units_Layer_3': 230, 'n_units_Layer_4': 160}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 154.56 | sMAPE for Validation Set is: 96.81% | rMAE for Validation Set is: 1.50\n",
      "MAE for Test Set is: 39.55 | sMAPE for Test Set is: 52.43% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:47:31,134]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:47:39,161]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:47:39,452]\u001b[0m Trial 506 finished with value: 51.278938541472364 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026040373012579782, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13287498923237312, 'dropout_rate_Layer_2': 0.03453618442960322, 'dropout_rate_Layer_3': 0.010502915233995568, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019873887332919954, 'l1_Layer_2': 8.379030224397792e-05, 'l1_Layer_3': 1.704248108916151e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 125, 'n_units_Layer_3': 65}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.28 | sMAPE for Validation Set is: 37.65% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 30.73 | sMAPE for Test Set is: 41.16% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:48:02,688]\u001b[0m Trial 511 finished with value: 51.06493558624436 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025161904433927997, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15335264987763922, 'dropout_rate_Layer_2': 0.022884273710136877, 'dropout_rate_Layer_3': 0.00017456087709179224, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0025933515973429124, 'l1_Layer_2': 0.00017614581712255574, 'l1_Layer_3': 2.1322449983317572e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 125, 'n_units_Layer_3': 85}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.06 | sMAPE for Validation Set is: 37.56% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 27.97 | sMAPE for Test Set is: 39.09% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:48:13,188]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:48:29,526]\u001b[0m Trial 508 finished with value: 61.546373442875364 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020099934777033862, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39262985228771835, 'dropout_rate_Layer_2': 0.26583280130064013, 'dropout_rate_Layer_3': 0.021201698328434077, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0028662398380775813, 'l1_Layer_2': 7.448212137709747e-05, 'l1_Layer_3': 0.004001683392188215, 'n_units_Layer_1': 225, 'n_units_Layer_2': 265, 'n_units_Layer_3': 95}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.55 | sMAPE for Validation Set is: 42.48% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.29 | sMAPE for Test Set is: 41.02% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:48:32,421]\u001b[0m Trial 514 finished with value: 51.75124276908027 and parameters: {'n_hidden': 3, 'learning_rate': 0.002521749463850215, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14305178037855998, 'dropout_rate_Layer_2': 0.021795639259906352, 'dropout_rate_Layer_3': 0.0005795194676171409, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002460452679200839, 'l1_Layer_2': 0.00018720369410746794, 'l1_Layer_3': 2.1219673119415534e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 125, 'n_units_Layer_3': 85}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.75 | sMAPE for Validation Set is: 37.82% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 26.74 | sMAPE for Test Set is: 38.32% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:48:36,198]\u001b[0m Trial 512 finished with value: 53.45723894128582 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009101823975245432, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005355398176809134, 'dropout_rate_Layer_2': 0.14405764687625244, 'dropout_rate_Layer_3': 0.2808911703552252, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.441913272270642e-05, 'l1_Layer_2': 2.4833487421083927e-05, 'l1_Layer_3': 3.305517517127809e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 115, 'n_units_Layer_3': 265}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.46 | sMAPE for Validation Set is: 38.87% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 25.83 | sMAPE for Test Set is: 38.94% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:48:39,521]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:48:42,847]\u001b[0m Trial 510 finished with value: 61.144761942751565 and parameters: {'n_hidden': 3, 'learning_rate': 0.001603886697503253, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35044894141183525, 'dropout_rate_Layer_2': 0.15059592023917975, 'dropout_rate_Layer_3': 0.044767566230380765, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002912789438984743, 'l1_Layer_2': 4.943399247301785e-05, 'l1_Layer_3': 0.003807641912829338, 'n_units_Layer_1': 225, 'n_units_Layer_2': 265, 'n_units_Layer_3': 100}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.14 | sMAPE for Validation Set is: 42.46% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.14 | sMAPE for Test Set is: 41.49% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:48:45,064]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:48:47,120]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:48:49,501]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:48:54,331]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:48:57,670]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:49:04,310]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:49:07,525]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.17 | sMAPE for Validation Set is: 37.32% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 29.25 | sMAPE for Test Set is: 40.19% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:49:09,306]\u001b[0m Trial 516 finished with value: 51.1703598650764 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022644246472400533, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15252568893911309, 'dropout_rate_Layer_2': 0.05073786261121439, 'dropout_rate_Layer_3': 0.009001111534333727, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0027701562323726443, 'l1_Layer_2': 0.00025947253788910545, 'l1_Layer_3': 2.4110455602241312e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 140, 'n_units_Layer_3': 55}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:49:12,012]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:49:14,200]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:49:15,058]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:49:23,058]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:49:26,953]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:49:33,690]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:49:54,627]\u001b[0m Trial 532 finished with value: 51.5022658633338 and parameters: {'n_hidden': 3, 'learning_rate': 0.002900080188237219, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1561936213992515, 'dropout_rate_Layer_2': 0.017367048543383366, 'dropout_rate_Layer_3': 0.029151696350191443, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004036714075980613, 'l1_Layer_2': 0.00015646833393209044, 'l1_Layer_3': 3.3726099735904304e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 120, 'n_units_Layer_3': 80}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.50 | sMAPE for Validation Set is: 37.93% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 26.91 | sMAPE for Test Set is: 39.09% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:49:59,292]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:50:27,431]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:50:31,248]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:50:34,217]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:50:41,641]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:50:53,481]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:50:58,714]\u001b[0m Trial 538 finished with value: 51.13613540987128 and parameters: {'n_hidden': 3, 'learning_rate': 0.002556071564402335, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14600961908821752, 'dropout_rate_Layer_2': 0.030299619448864952, 'dropout_rate_Layer_3': 0.026050486682912776, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003397257847882206, 'l1_Layer_2': 0.0003379781307935906, 'l1_Layer_3': 1.2444403469967122e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 100, 'n_units_Layer_3': 95}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.14 | sMAPE for Validation Set is: 37.24% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 30.10 | sMAPE for Test Set is: 41.00% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:51:02,070]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:51:02,586]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:51:06,792]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:51:06,803]\u001b[0m Trial 539 finished with value: 50.7171675575118 and parameters: {'n_hidden': 3, 'learning_rate': 0.00263296756411265, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1447730109815087, 'dropout_rate_Layer_2': 0.0077043517883284215, 'dropout_rate_Layer_3': 0.02877550522540793, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003434714973911315, 'l1_Layer_2': 0.0002362196390574384, 'l1_Layer_3': 1.2658832355135074e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 100, 'n_units_Layer_3': 95}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.72 | sMAPE for Validation Set is: 37.12% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 27.20 | sMAPE for Test Set is: 39.99% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:51:07,853]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:51:14,027]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:51:15,181]\u001b[0m Trial 535 finished with value: 62.13949951389204 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037577945557795405, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3476021264422614, 'dropout_rate_Layer_2': 0.13032224116881833, 'dropout_rate_Layer_3': 0.07524473954758631, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004191157740798819, 'l1_Layer_2': 8.950597635078553e-05, 'l1_Layer_3': 0.006372754592103314, 'n_units_Layer_1': 205, 'n_units_Layer_2': 280, 'n_units_Layer_3': 100}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.14 | sMAPE for Validation Set is: 42.52% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 36.75 | sMAPE for Test Set is: 45.92% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:51:21,795]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:51:24,454]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:51:29,656]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:51:31,228]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:51:33,434]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:51:40,987]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:51:47,536]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:51:59,807]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:52:00,287]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:52:16,757]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:52:20,018]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:52:44,682]\u001b[0m Trial 559 finished with value: 54.22805101375685 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015318130761943732, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04871648642678558, 'dropout_rate_Layer_2': 0.19053721786108635, 'dropout_rate_Layer_3': 0.25354230944876655, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.072241895643903e-05, 'l1_Layer_2': 3.940132916615789e-05, 'l1_Layer_3': 2.5085166435527484e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 100, 'n_units_Layer_3': 250}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.23 | sMAPE for Validation Set is: 38.98% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 26.04 | sMAPE for Test Set is: 38.40% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:52:48,105]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:52:55,071]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:52:59,037]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:53:01,812]\u001b[0m Trial 556 finished with value: 53.18596293823873 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008763606085915117, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008497290401770927, 'dropout_rate_Layer_2': 0.09918766764420572, 'dropout_rate_Layer_3': 0.2846092214769414, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.967428790549443e-05, 'l1_Layer_2': 1.0077766329932615e-05, 'l1_Layer_3': 4.114463885032764e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 105, 'n_units_Layer_3': 255}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.19 | sMAPE for Validation Set is: 38.60% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 25.53 | sMAPE for Test Set is: 38.26% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:53:06,055]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:53:08,103]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:53:19,144]\u001b[0m Trial 565 finished with value: 56.59536793878623 and parameters: {'n_hidden': 3, 'learning_rate': 0.0352022120835592, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22616016768700783, 'dropout_rate_Layer_2': 0.21518482546922554, 'dropout_rate_Layer_3': 0.019924272651120067, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.496883183196275e-05, 'l1_Layer_2': 0.009853491200677128, 'l1_Layer_3': 0.016601010927781327, 'n_units_Layer_1': 65, 'n_units_Layer_2': 235, 'n_units_Layer_3': 275}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.60 | sMAPE for Validation Set is: 40.63% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 26.32 | sMAPE for Test Set is: 39.38% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:53:33,111]\u001b[0m Trial 563 finished with value: 50.31676142432025 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020439208695564783, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18059225654286276, 'dropout_rate_Layer_2': 0.026507019919093103, 'dropout_rate_Layer_3': 0.05473199688507204, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004067588660282847, 'l1_Layer_2': 0.0002003597580560643, 'l1_Layer_3': 1.2354858794932887e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 70, 'n_units_Layer_3': 75}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.32 | sMAPE for Validation Set is: 36.95% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 26.57 | sMAPE for Test Set is: 39.82% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:53:48,805]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:53:59,153]\u001b[0m Trial 557 finished with value: 59.60164692404479 and parameters: {'n_hidden': 3, 'learning_rate': 0.001357264124131026, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3375901728679655, 'dropout_rate_Layer_2': 0.1404222228431464, 'dropout_rate_Layer_3': 0.013781145660457305, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010366168910203903, 'l1_Layer_2': 0.0002602605409250014, 'l1_Layer_3': 0.015535153767227142, 'n_units_Layer_1': 210, 'n_units_Layer_2': 285, 'n_units_Layer_3': 105}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.60 | sMAPE for Validation Set is: 41.94% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 29.48 | sMAPE for Test Set is: 41.38% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:54:02,670]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:54:02,814]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:54:14,049]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:54:17,852]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:54:22,159]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:54:28,389]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:54:47,853]\u001b[0m Trial 574 finished with value: 51.612813998485116 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030609126458121727, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20015608418081304, 'dropout_rate_Layer_2': 0.013311817227073326, 'dropout_rate_Layer_3': 0.0391740348529475, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004405021508544535, 'l1_Layer_2': 0.00020484482372899566, 'l1_Layer_3': 1.4828732772728908e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 90, 'n_units_Layer_3': 85}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.61 | sMAPE for Validation Set is: 37.55% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 27.30 | sMAPE for Test Set is: 39.12% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:54:48,505]\u001b[0m Trial 571 finished with value: 53.914877034809784 and parameters: {'n_hidden': 3, 'learning_rate': 0.000583256912911844, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03711929300020783, 'dropout_rate_Layer_2': 0.09006818289737054, 'dropout_rate_Layer_3': 0.321311460727337, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.035562620998594e-05, 'l1_Layer_2': 1.0539642234472474e-05, 'l1_Layer_3': 6.961424613842049e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 90, 'n_units_Layer_3': 280}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.91 | sMAPE for Validation Set is: 39.00% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 25.43 | sMAPE for Test Set is: 38.30% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:54:52,973]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:54:53,572]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:54:58,337]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:55:01,315]\u001b[0m Trial 575 finished with value: 50.448134958404125 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023870409839273346, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19787607084000133, 'dropout_rate_Layer_2': 0.013432472111445819, 'dropout_rate_Layer_3': 0.030079716064016333, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004123144823823211, 'l1_Layer_2': 0.00020050097862115172, 'l1_Layer_3': 1.4675941675905944e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 65, 'n_units_Layer_3': 85}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:55:01,459]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.45 | sMAPE for Validation Set is: 36.96% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 31.66 | sMAPE for Test Set is: 41.53% | rMAE for Test Set is: 0.70\n",
      "MAE for Validation Set is: 52.99 | sMAPE for Validation Set is: 38.66% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.97 | sMAPE for Test Set is: 38.52% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:55:04,142]\u001b[0m Trial 576 finished with value: 52.99420916519157 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005643337136846656, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03569237045359279, 'dropout_rate_Layer_2': 0.08843376384693516, 'dropout_rate_Layer_3': 0.3118491921294786, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.574710688015266e-05, 'l1_Layer_2': 1.0700842345339736e-05, 'l1_Layer_3': 6.998312349652198e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 85, 'n_units_Layer_3': 225}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:55:07,251]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:55:10,826]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:55:11,624]\u001b[0m Trial 579 finished with value: 60.650015878760605 and parameters: {'n_hidden': 3, 'learning_rate': 0.024876806300138832, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2660219603605176, 'dropout_rate_Layer_2': 0.2430713691516678, 'dropout_rate_Layer_3': 0.07700527339263175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005514894903574146, 'l1_Layer_2': 0.0022847462574082504, 'l1_Layer_3': 0.00040923026024012357, 'n_units_Layer_1': 105, 'n_units_Layer_2': 270, 'n_units_Layer_3': 235}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.65 | sMAPE for Validation Set is: 41.92% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.97 | sMAPE for Test Set is: 41.34% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:55:16,015]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:55:20,138]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:55:23,196]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:55:35,309]\u001b[0m Trial 588 finished with value: 53.47761528901325 and parameters: {'n_hidden': 3, 'learning_rate': 0.03600405753844371, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28674299043117835, 'dropout_rate_Layer_2': 0.19834813210512464, 'dropout_rate_Layer_3': 0.08376776253983814, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022801730219373126, 'l1_Layer_2': 0.003922439672034551, 'l1_Layer_3': 0.0022339077183733892, 'n_units_Layer_1': 65, 'n_units_Layer_2': 270, 'n_units_Layer_3': 255}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.48 | sMAPE for Validation Set is: 38.91% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 25.43 | sMAPE for Test Set is: 38.12% | rMAE for Test Set is: 0.57\n",
      "MAE for Validation Set is: 50.58 | sMAPE for Validation Set is: 37.44% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 25.98 | sMAPE for Test Set is: 38.31% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:55:38,498]\u001b[0m Trial 585 finished with value: 50.5774504825769 and parameters: {'n_hidden': 3, 'learning_rate': 0.00230763350689405, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20150040405632466, 'dropout_rate_Layer_2': 0.026740104673068567, 'dropout_rate_Layer_3': 0.024468449213214456, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0042451932774571904, 'l1_Layer_2': 0.00016829242758286658, 'l1_Layer_3': 1.5075190472558025e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 155, 'n_units_Layer_3': 80}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:55:43,564]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:55:46,119]\u001b[0m Trial 587 finished with value: 51.707022574435456 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006002897777387231, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06306836169264547, 'dropout_rate_Layer_2': 0.08622027357486352, 'dropout_rate_Layer_3': 0.30231935601732823, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014245436195045298, 'l1_Layer_2': 1.5179207712621857e-05, 'l1_Layer_3': 1.0150787497864036e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 80, 'n_units_Layer_3': 220}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.71 | sMAPE for Validation Set is: 38.08% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 25.14 | sMAPE for Test Set is: 38.20% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:55:48,028]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:55:50,627]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:55:55,363]\u001b[0m Trial 590 finished with value: 52.98546558832768 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005923603931902347, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08658335524951298, 'dropout_rate_Layer_2': 0.08462001480420987, 'dropout_rate_Layer_3': 0.3038529250505454, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014144699610722607, 'l1_Layer_2': 1.8649582508455683e-05, 'l1_Layer_3': 1.000107821085898e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 80, 'n_units_Layer_3': 225}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.99 | sMAPE for Validation Set is: 38.66% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.65 | sMAPE for Test Set is: 39.00% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:55:59,505]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:56:05,457]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:56:08,589]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:56:29,337]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:56:43,974]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:56:49,730]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:56:52,987]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:57:02,953]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:57:06,316]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:57:11,138]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:57:15,063]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:57:18,787]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:57:28,371]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:57:33,067]\u001b[0m Trial 607 finished with value: 53.8370063323909 and parameters: {'n_hidden': 3, 'learning_rate': 0.001035876250405143, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06052315531118983, 'dropout_rate_Layer_2': 0.10950984353835959, 'dropout_rate_Layer_3': 0.2531921912916701, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.59790876795247e-05, 'l1_Layer_2': 3.2583432174839375e-05, 'l1_Layer_3': 1.695391860371203e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 130, 'n_units_Layer_3': 275}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.84 | sMAPE for Validation Set is: 38.84% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 25.79 | sMAPE for Test Set is: 38.09% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:57:36,056]\u001b[0m Trial 606 finished with value: 53.501820889588174 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005026867898995875, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06197715633222739, 'dropout_rate_Layer_2': 0.10640499773868108, 'dropout_rate_Layer_3': 0.2574029799958037, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010468090104187362, 'l1_Layer_2': 7.785909201647713e-05, 'l1_Layer_3': 2.5974622822342883e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.50 | sMAPE for Validation Set is: 38.69% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 25.07 | sMAPE for Test Set is: 38.03% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:57:36,610]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:57:41,079]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:57:48,001]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:57:51,493]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:57:53,906]\u001b[0m Trial 610 finished with value: 51.92536348688549 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010219934979291817, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05694925080124914, 'dropout_rate_Layer_2': 0.109941138039891, 'dropout_rate_Layer_3': 0.342696059062165, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.255913218275718e-05, 'l1_Layer_2': 3.1531456002321474e-05, 'l1_Layer_3': 1.7648705435361623e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 130, 'n_units_Layer_3': 280}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.93 | sMAPE for Validation Set is: 38.29% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 25.60 | sMAPE for Test Set is: 38.67% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:57:57,137]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:57:57,895]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:58:15,679]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.00 | sMAPE for Validation Set is: 40.70% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 32.69 | sMAPE for Test Set is: 42.96% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:58:17,591]\u001b[0m Trial 599 finished with value: 57.00482875790967 and parameters: {'n_hidden': 3, 'learning_rate': 0.002006397550681858, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35346666584099, 'dropout_rate_Layer_2': 0.18956274059493988, 'dropout_rate_Layer_3': 0.02349882972702603, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.438777218700621e-05, 'l1_Layer_2': 0.0002129937058719424, 'l1_Layer_3': 0.0042003042619664895, 'n_units_Layer_1': 210, 'n_units_Layer_2': 285, 'n_units_Layer_3': 205}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:58:19,602]\u001b[0m Trial 614 finished with value: 53.226366548811804 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006638116346864905, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09197685949533932, 'dropout_rate_Layer_2': 0.060579780583471306, 'dropout_rate_Layer_3': 0.30415300461747846, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001530428153616591, 'l1_Layer_2': 1.691377438907006e-05, 'l1_Layer_3': 1.1041641487661713e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.23 | sMAPE for Validation Set is: 38.83% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 26.04 | sMAPE for Test Set is: 39.42% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:58:25,173]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:58:34,589]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:58:44,137]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:58:48,124]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:58:51,412]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:58:52,059]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:58:57,294]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:58:59,427]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:59:10,990]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:59:16,933]\u001b[0m Trial 629 finished with value: 52.262298290059654 and parameters: {'n_hidden': 3, 'learning_rate': 0.005145219778579985, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22201358934238496, 'dropout_rate_Layer_2': 0.015117316244369839, 'dropout_rate_Layer_3': 0.011683455464625394, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004395559652984907, 'l1_Layer_2': 0.00020364395332441546, 'l1_Layer_3': 2.1073367634509406e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 100, 'n_units_Layer_3': 105}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.26 | sMAPE for Validation Set is: 37.77% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 34.63 | sMAPE for Test Set is: 44.19% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:59:17,170]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:59:18,330]\u001b[0m Trial 628 finished with value: 50.76841512436889 and parameters: {'n_hidden': 3, 'learning_rate': 0.002553053599022698, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22013403993816963, 'dropout_rate_Layer_2': 0.00011431843330956615, 'dropout_rate_Layer_3': 0.012680354572266492, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004418806285548729, 'l1_Layer_2': 8.857244165928935e-05, 'l1_Layer_3': 2.0367772566899777e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 150, 'n_units_Layer_3': 85}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.77 | sMAPE for Validation Set is: 37.41% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 27.49 | sMAPE for Test Set is: 39.07% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:59:18,838]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:59:23,864]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:59:25,428]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:59:26,695]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:59:32,719]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:59:35,770]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:59:37,420]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:59:40,458]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:59:42,131]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 09:59:56,018]\u001b[0m Trial 639 finished with value: 53.26590724359428 and parameters: {'n_hidden': 3, 'learning_rate': 0.008997296173374752, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32353326033109747, 'dropout_rate_Layer_2': 0.24933762912027624, 'dropout_rate_Layer_3': 0.09360736489820783, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0042532435566430766, 'l1_Layer_2': 0.005301657104870847, 'l1_Layer_3': 0.0020900244975812603, 'n_units_Layer_1': 75, 'n_units_Layer_2': 70, 'n_units_Layer_3': 245}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.27 | sMAPE for Validation Set is: 38.32% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 26.90 | sMAPE for Test Set is: 38.51% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 09:59:58,443]\u001b[0m Trial 634 finished with value: 52.88456587176415 and parameters: {'n_hidden': 3, 'learning_rate': 0.009415369956447456, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31531147845374696, 'dropout_rate_Layer_2': 0.25173441382868095, 'dropout_rate_Layer_3': 0.08345400533263522, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004266357621469724, 'l1_Layer_2': 0.006060312572530865, 'l1_Layer_3': 0.0009806582411026358, 'n_units_Layer_1': 75, 'n_units_Layer_2': 265, 'n_units_Layer_3': 250}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.88 | sMAPE for Validation Set is: 38.43% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 27.45 | sMAPE for Test Set is: 43.57% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:00:00,357]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:00:02,752]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:00:05,707]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:00:06,333]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:00:10,996]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:00:14,752]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:00:17,674]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:00:22,479]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:00:38,354]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:00:41,892]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:00:44,318]\u001b[0m Trial 652 finished with value: 51.58149772803946 and parameters: {'n_hidden': 3, 'learning_rate': 0.002770986795538106, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1757856384256167, 'dropout_rate_Layer_2': 0.03821691228616518, 'dropout_rate_Layer_3': 0.022439633133104268, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0034852619151874856, 'l1_Layer_2': 0.00016311657607305058, 'l1_Layer_3': 1.5875203424944888e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 165, 'n_units_Layer_3': 85}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.58 | sMAPE for Validation Set is: 37.64% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 26.33 | sMAPE for Test Set is: 38.95% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:00:48,096]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:00:56,683]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:00,745]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:05,556]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:08,429]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:08,770]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:15,177]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:21,161]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:24,883]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:25,739]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:28,938]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:29,214]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:29,752]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:35,383]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:35,638]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:40,344]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:40,584]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:41,141]\u001b[0m Trial 653 finished with value: 64.43973529269574 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015066730237516333, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38105086883620237, 'dropout_rate_Layer_2': 0.19060563512204481, 'dropout_rate_Layer_3': 0.06902115458161373, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019527952343249802, 'l1_Layer_2': 5.7241077515570375e-05, 'l1_Layer_3': 0.007035677465820447, 'n_units_Layer_1': 205, 'n_units_Layer_2': 220, 'n_units_Layer_3': 85}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 64.44 | sMAPE for Validation Set is: 44.02% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 31.07 | sMAPE for Test Set is: 42.40% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:01:48,183]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:48,417]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:54,549]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:55,263]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:01:59,334]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:02:04,476]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:02:06,820]\u001b[0m Trial 676 finished with value: 55.77567571295705 and parameters: {'n_hidden': 3, 'learning_rate': 0.015855150015629125, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32936251160157975, 'dropout_rate_Layer_2': 0.24793592094277775, 'dropout_rate_Layer_3': 0.11600504192959973, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0049774674920214255, 'l1_Layer_2': 0.025310627219419995, 'l1_Layer_3': 0.005963204368197436, 'n_units_Layer_1': 135, 'n_units_Layer_2': 75, 'n_units_Layer_3': 240}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.78 | sMAPE for Validation Set is: 39.83% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 25.82 | sMAPE for Test Set is: 38.04% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:02:08,805]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:02:11,438]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:02:13,660]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:02:17,720]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:02:17,829]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:02:23,991]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:02:26,870]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:02:33,377]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:02:37,013]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:02:42,735]\u001b[0m Trial 687 finished with value: 53.26615749934865 and parameters: {'n_hidden': 3, 'learning_rate': 0.024081979143567248, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31163833447858397, 'dropout_rate_Layer_2': 0.27864484899945174, 'dropout_rate_Layer_3': 0.07655585570605786, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017714035749609876, 'l1_Layer_2': 0.00887387794301269, 'l1_Layer_3': 0.002087973859421374, 'n_units_Layer_1': 70, 'n_units_Layer_2': 110, 'n_units_Layer_3': 265}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.27 | sMAPE for Validation Set is: 38.74% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 25.78 | sMAPE for Test Set is: 38.92% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:02:57,717]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:03:18,331]\u001b[0m Trial 692 finished with value: 54.37917075056824 and parameters: {'n_hidden': 3, 'learning_rate': 0.005103783389244519, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3131858991829608, 'dropout_rate_Layer_2': 0.284122772251798, 'dropout_rate_Layer_3': 0.059178042069886964, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008561444764550365, 'l1_Layer_2': 0.008728397920974353, 'l1_Layer_3': 0.009716054253729655, 'n_units_Layer_1': 70, 'n_units_Layer_2': 95, 'n_units_Layer_3': 265}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.38 | sMAPE for Validation Set is: 39.25% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 26.14 | sMAPE for Test Set is: 37.95% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:03:21,435]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:03:25,010]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:03:33,116]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:03:36,638]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:03:40,702]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:03:46,923]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:03:50,145]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:03:50,436]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:03:55,484]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:04:01,191]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:04:08,652]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:04:12,567]\u001b[0m Trial 700 finished with value: 54.599807625831396 and parameters: {'n_hidden': 3, 'learning_rate': 0.024290253538212545, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3490011747465662, 'dropout_rate_Layer_2': 0.2533299691728243, 'dropout_rate_Layer_3': 0.08051540350183267, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001840124869945901, 'l1_Layer_2': 0.004918157265752327, 'l1_Layer_3': 0.0020043469435677705, 'n_units_Layer_1': 60, 'n_units_Layer_2': 165, 'n_units_Layer_3': 275}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.60 | sMAPE for Validation Set is: 39.16% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 25.64 | sMAPE for Test Set is: 39.14% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:04:12,960]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:04:28,611]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:04:44,022]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:04:55,804]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:05:00,231]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:05:18,254]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:05:24,901]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:05:28,114]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:05:28,759]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:05:37,533]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:05:41,421]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:05:44,611]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:05:49,029]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:05:51,990]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:05:54,026]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:05:55,050]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:05:57,354]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:05:58,157]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:06:03,974]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:06:06,196]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:06:06,197]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:06:08,046]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:06:08,064]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:06:14,660]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:06:15,462]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:06:19,211]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:06:19,553]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:06:20,473]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:06:26,588]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:06:31,131]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:06:34,617]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:06:35,201]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:06:44,486]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:06:54,243]\u001b[0m Trial 737 finished with value: 52.71049168408555 and parameters: {'n_hidden': 3, 'learning_rate': 0.00997584562712726, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2975336532004696, 'dropout_rate_Layer_2': 0.20438479390108025, 'dropout_rate_Layer_3': 0.13781465617246932, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007236960503163304, 'l1_Layer_2': 0.013095625613632804, 'l1_Layer_3': 0.0009754391806330747, 'n_units_Layer_1': 85, 'n_units_Layer_2': 95, 'n_units_Layer_3': 245}. Best is trial 321 with value: 49.859640975492255.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.71 | sMAPE for Validation Set is: 38.48% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.57 | sMAPE for Test Set is: 39.02% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:06:57,554]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:07:00,642]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:07:04,776]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:07:08,241]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:07:11,541]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:07:14,693]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:07:18,223]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:07:21,322]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:07:25,194]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:07:28,801]\u001b[0m Trial 734 finished with value: 49.54610283504429 and parameters: {'n_hidden': 3, 'learning_rate': 0.000629432562416257, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07070583759044942, 'dropout_rate_Layer_2': 0.13433327176898824, 'dropout_rate_Layer_3': 0.34138097807176315, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017740958936953623, 'l1_Layer_2': 4.7448605596661086e-05, 'l1_Layer_3': 1.4874454339259847e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 95, 'n_units_Layer_3': 250}. Best is trial 734 with value: 49.54610283504429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.55 | sMAPE for Validation Set is: 37.17% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 24.76 | sMAPE for Test Set is: 38.57% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:07:33,052]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:07:36,264]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:07:42,688]\u001b[0m Trial 729 finished with value: 49.56587302177763 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006421402488063777, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023167836381748255, 'dropout_rate_Layer_2': 0.179086404588137, 'dropout_rate_Layer_3': 0.3221128793130106, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016157564621970764, 'l1_Layer_2': 4.8151552243685345e-05, 'l1_Layer_3': 4.882203891525316e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 95, 'n_units_Layer_3': 270}. Best is trial 734 with value: 49.54610283504429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.57 | sMAPE for Validation Set is: 37.26% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 24.49 | sMAPE for Test Set is: 37.36% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:07:46,921]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:07:50,802]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:08:00,240]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:08:02,308]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:08:05,734]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:08:15,936]\u001b[0m Trial 738 finished with value: 49.51648963231503 and parameters: {'n_hidden': 3, 'learning_rate': 0.001619400508544777, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07742934455159368, 'dropout_rate_Layer_2': 0.1363867831194772, 'dropout_rate_Layer_3': 0.33832983969111735, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005755400301126781, 'l1_Layer_2': 4.7715708239811205e-05, 'l1_Layer_3': 5.240528917131539e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 125, 'n_units_Layer_3': 275}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.52 | sMAPE for Validation Set is: 36.65% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 24.59 | sMAPE for Test Set is: 37.90% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:08:19,745]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:08:27,450]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:08:30,675]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:08:31,407]\u001b[0m Trial 748 finished with value: 49.80258335111333 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006186686041139482, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10611960416392835, 'dropout_rate_Layer_2': 0.13062049477653914, 'dropout_rate_Layer_3': 0.3459637128803378, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016049977945718454, 'l1_Layer_2': 4.803128720174782e-05, 'l1_Layer_3': 5.630598648395482e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 125, 'n_units_Layer_3': 270}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.80 | sMAPE for Validation Set is: 37.54% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 25.19 | sMAPE for Test Set is: 39.50% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:08:35,948]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:08:39,370]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:08:39,812]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:08:44,091]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:08:44,454]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:08:51,773]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:08:55,381]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:08:57,601]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:09:01,709]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:09:05,194]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:09:10,148]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:09:11,122]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:09:15,361]\u001b[0m Trial 765 finished with value: 54.11794090049782 and parameters: {'n_hidden': 3, 'learning_rate': 0.007179482073041013, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3043197494891246, 'dropout_rate_Layer_2': 0.1478936084804933, 'dropout_rate_Layer_3': 0.05583311339217336, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009902024373613209, 'l1_Layer_2': 0.032592279171800215, 'l1_Layer_3': 0.000581454584650551, 'n_units_Layer_1': 100, 'n_units_Layer_2': 115, 'n_units_Layer_3': 265}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.12 | sMAPE for Validation Set is: 39.04% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 26.72 | sMAPE for Test Set is: 40.50% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:09:21,739]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:09:26,407]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:09:31,690]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:09:35,435]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:09:37,599]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:09:41,574]\u001b[0m Trial 773 finished with value: 54.22001509606616 and parameters: {'n_hidden': 3, 'learning_rate': 0.005360484298490279, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3436490201862627, 'dropout_rate_Layer_2': 0.14734194120065544, 'dropout_rate_Layer_3': 0.15740669831268056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008936070258387116, 'l1_Layer_2': 0.03388196428176391, 'l1_Layer_3': 0.0005679631389599215, 'n_units_Layer_1': 100, 'n_units_Layer_2': 110, 'n_units_Layer_3': 240}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.22 | sMAPE for Validation Set is: 38.84% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 27.18 | sMAPE for Test Set is: 39.07% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:09:48,264]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:09:57,027]\u001b[0m Trial 780 finished with value: 54.85638687260323 and parameters: {'n_hidden': 3, 'learning_rate': 0.02226803780593566, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.261484365600362, 'dropout_rate_Layer_2': 0.2767312514627056, 'dropout_rate_Layer_3': 0.10785650044651783, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003912953180634687, 'l1_Layer_2': 0.0016673138476094329, 'l1_Layer_3': 0.0008811037976217736, 'n_units_Layer_1': 70, 'n_units_Layer_2': 65, 'n_units_Layer_3': 255}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.86 | sMAPE for Validation Set is: 39.49% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 25.30 | sMAPE for Test Set is: 37.98% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:10:06,183]\u001b[0m Trial 766 finished with value: 61.07111206652732 and parameters: {'n_hidden': 3, 'learning_rate': 0.002090883188593475, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3513862792125771, 'dropout_rate_Layer_2': 0.24325347893959962, 'dropout_rate_Layer_3': 0.01925980380559114, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003187218532417929, 'l1_Layer_2': 7.864222957773358e-05, 'l1_Layer_3': 0.004083593692935138, 'n_units_Layer_1': 225, 'n_units_Layer_2': 260, 'n_units_Layer_3': 90}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.07 | sMAPE for Validation Set is: 42.53% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.55 | sMAPE for Test Set is: 43.90% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:10:06,606]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:10:12,150]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:10:13,013]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:10:17,824]\u001b[0m Trial 782 finished with value: 51.245606185666226 and parameters: {'n_hidden': 3, 'learning_rate': 0.003084466294001153, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19083688124848044, 'dropout_rate_Layer_2': 0.02017582302221369, 'dropout_rate_Layer_3': 0.04339435944662447, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006085995964873282, 'l1_Layer_2': 0.00025266311490675466, 'l1_Layer_3': 1.3429704278568142e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 95, 'n_units_Layer_3': 75}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.25 | sMAPE for Validation Set is: 37.83% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 26.63 | sMAPE for Test Set is: 38.81% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:10:18,728]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:10:22,959]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:10:23,265]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:10:23,740]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:10:26,421]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:10:34,155]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:10:34,595]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:10:34,709]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:10:43,737]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:10:47,574]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:10:47,850]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:10:48,364]\u001b[0m Trial 790 finished with value: 52.47118358276139 and parameters: {'n_hidden': 3, 'learning_rate': 0.004829146174826888, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.221758705224135, 'dropout_rate_Layer_2': 0.031144919563186952, 'dropout_rate_Layer_3': 0.024661867299616655, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0034288391536398816, 'l1_Layer_2': 5.483164799943806e-05, 'l1_Layer_3': 2.1339694442786414e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 120, 'n_units_Layer_3': 85}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.47 | sMAPE for Validation Set is: 37.67% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 29.81 | sMAPE for Test Set is: 41.72% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:10:48,706]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:11:00,365]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:11:00,456]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:11:06,462]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:11:11,898]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:11:34,212]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:11:37,747]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:11:38,022]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:11:44,589]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:11:44,701]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:11:52,996]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:11:57,611]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:12:00,979]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:12:03,672]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:12:06,113]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:12:12,918]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:12:13,445]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:12:23,199]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:12:23,796]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:12:28,220]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:12:31,051]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:12:31,824]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:12:36,687]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:12:37,402]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:12:37,847]\u001b[0m Trial 815 finished with value: 51.62263957233014 and parameters: {'n_hidden': 3, 'learning_rate': 0.002190055462362436, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2139394423588553, 'dropout_rate_Layer_2': 0.026610614585884595, 'dropout_rate_Layer_3': 0.005375459069351895, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006625196153588065, 'l1_Layer_2': 0.00011923944594303378, 'l1_Layer_3': 1.3199194526770697e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 70, 'n_units_Layer_3': 80}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.62 | sMAPE for Validation Set is: 37.92% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 26.56 | sMAPE for Test Set is: 40.40% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:12:40,848]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:12:45,397]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:12:45,901]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:12:51,954]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:12:55,504]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:13:16,976]\u001b[0m Trial 830 finished with value: 52.835209517886575 and parameters: {'n_hidden': 3, 'learning_rate': 0.006919309361057779, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24078344305404326, 'dropout_rate_Layer_2': 0.26953518816541433, 'dropout_rate_Layer_3': 0.043021422323095006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004189041987884371, 'l1_Layer_2': 0.004408017356864684, 'l1_Layer_3': 0.0007614352703434745, 'n_units_Layer_1': 55, 'n_units_Layer_2': 260, 'n_units_Layer_3': 270}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.84 | sMAPE for Validation Set is: 38.42% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.14 | sMAPE for Test Set is: 39.25% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:13:20,530]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:13:36,435]\u001b[0m Trial 807 finished with value: 49.65412088661761 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005925440044763701, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10583475711484334, 'dropout_rate_Layer_2': 0.18621981431517037, 'dropout_rate_Layer_3': 0.3734740176568922, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000182207009344483, 'l1_Layer_2': 0.00012200009089713467, 'l1_Layer_3': 6.250399596903432e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 95, 'n_units_Layer_3': 250}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.65 | sMAPE for Validation Set is: 37.26% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 24.68 | sMAPE for Test Set is: 37.97% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:13:43,087]\u001b[0m Trial 826 finished with value: 50.01633832521736 and parameters: {'n_hidden': 3, 'learning_rate': 0.000627926545899679, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1051410123565936, 'dropout_rate_Layer_2': 0.17332854295681954, 'dropout_rate_Layer_3': 0.34672094424369154, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017396578896904897, 'l1_Layer_2': 9.516797989927356e-05, 'l1_Layer_3': 2.6041356555838264e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 95, 'n_units_Layer_3': 250}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.02 | sMAPE for Validation Set is: 37.42% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 24.94 | sMAPE for Test Set is: 38.79% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:13:46,062]\u001b[0m Trial 832 finished with value: 52.64089774559497 and parameters: {'n_hidden': 3, 'learning_rate': 0.006895481490955091, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2556671523308473, 'dropout_rate_Layer_2': 0.16434207538739126, 'dropout_rate_Layer_3': 0.04066822309754031, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004063904223132909, 'l1_Layer_2': 0.0047036537722121045, 'l1_Layer_3': 0.0007492832448222072, 'n_units_Layer_1': 50, 'n_units_Layer_2': 260, 'n_units_Layer_3': 270}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.64 | sMAPE for Validation Set is: 38.11% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 26.55 | sMAPE for Test Set is: 38.40% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:13:54,932]\u001b[0m Trial 827 finished with value: 50.33688060542863 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005964107147169256, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09886143715950757, 'dropout_rate_Layer_2': 0.2081064396486176, 'dropout_rate_Layer_3': 0.34494675721230106, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005513244509875164, 'l1_Layer_2': 0.00013252545759414992, 'l1_Layer_3': 5.8044472074508934e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 95, 'n_units_Layer_3': 255}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.34 | sMAPE for Validation Set is: 37.60% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 24.71 | sMAPE for Test Set is: 37.96% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:13:59,414]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:04,154]\u001b[0m Trial 834 finished with value: 52.716785449971006 and parameters: {'n_hidden': 3, 'learning_rate': 0.007149120379481935, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.259711371256016, 'dropout_rate_Layer_2': 0.26851298527297757, 'dropout_rate_Layer_3': 0.047362308841738074, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004304826988258321, 'l1_Layer_2': 0.005237063045977558, 'l1_Layer_3': 0.0007231895501664241, 'n_units_Layer_1': 60, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.72 | sMAPE for Validation Set is: 38.49% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 26.04 | sMAPE for Test Set is: 40.84% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:14:08,373]\u001b[0m Trial 833 finished with value: 50.35739204446987 and parameters: {'n_hidden': 3, 'learning_rate': 0.003159553188857358, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16098142555960265, 'dropout_rate_Layer_2': 0.011998382079830871, 'dropout_rate_Layer_3': 0.027262905442130895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00044268317552935497, 'l1_Layer_2': 0.00016677542404797046, 'l1_Layer_3': 1.8813007553708263e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 55, 'n_units_Layer_3': 95}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.36 | sMAPE for Validation Set is: 37.23% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 25.35 | sMAPE for Test Set is: 37.27% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:14:09,218]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:11,728]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:13,363]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:14,973]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:18,020]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:19,995]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:22,206]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:32,038]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:35,541]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:36,312]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:40,297]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:41,285]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:45,268]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:46,268]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:50,413]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:51,025]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:55,363]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:14:57,459]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:15:00,746]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:15:03,386]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:15:06,684]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:15:08,601]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:15:16,302]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:15:29,307]\u001b[0m Trial 861 finished with value: 53.970521156466255 and parameters: {'n_hidden': 3, 'learning_rate': 0.006767502055147454, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23951450852649325, 'dropout_rate_Layer_2': 0.3067598038046359, 'dropout_rate_Layer_3': 0.030567218178881594, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00042072441587449747, 'l1_Layer_2': 0.004739206782295479, 'l1_Layer_3': 0.0007452129257905548, 'n_units_Layer_1': 55, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.97 | sMAPE for Validation Set is: 38.61% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 25.20 | sMAPE for Test Set is: 38.54% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:15:54,767]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:15:55,547]\u001b[0m Trial 863 finished with value: 52.30682028036961 and parameters: {'n_hidden': 3, 'learning_rate': 0.004000351733553456, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25483445006259053, 'dropout_rate_Layer_2': 0.10558687740973018, 'dropout_rate_Layer_3': 0.04007574040238126, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00029173791734738206, 'l1_Layer_2': 0.014955227997164259, 'l1_Layer_3': 0.00046959155066670624, 'n_units_Layer_1': 50, 'n_units_Layer_2': 280, 'n_units_Layer_3': 285}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.31 | sMAPE for Validation Set is: 38.17% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.24 | sMAPE for Test Set is: 38.80% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:16:02,718]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:16:05,735]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:16:08,901]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:16:47,356]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:16:50,646]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:16:54,366]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:16:55,963]\u001b[0m Trial 856 finished with value: 49.743100201790554 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006132553439728076, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07828771415998409, 'dropout_rate_Layer_2': 0.17825580187272017, 'dropout_rate_Layer_3': 0.3566117149578973, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017676521302722084, 'l1_Layer_2': 0.00017648699611813132, 'l1_Layer_3': 0.00011419500223232606, 'n_units_Layer_1': 90, 'n_units_Layer_2': 95, 'n_units_Layer_3': 215}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.74 | sMAPE for Validation Set is: 37.26% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 24.45 | sMAPE for Test Set is: 37.91% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:17:03,123]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:17:08,712]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:17:14,615]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:17:21,313]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:17:24,212]\u001b[0m Trial 862 finished with value: 50.118877933601 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006358166140662066, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11541320497616597, 'dropout_rate_Layer_2': 0.17665418968046903, 'dropout_rate_Layer_3': 0.3576751560270857, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001767874124122894, 'l1_Layer_2': 0.000274597476545491, 'l1_Layer_3': 0.00013292264087399943, 'n_units_Layer_1': 90, 'n_units_Layer_2': 100, 'n_units_Layer_3': 210}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.12 | sMAPE for Validation Set is: 37.34% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 24.64 | sMAPE for Test Set is: 37.46% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:17:24,439]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:17:29,101]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:17:29,645]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:17:34,586]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:17:35,297]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:17:39,719]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:17:40,530]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:17:40,593]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:17:46,776]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:17:46,962]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:17:52,499]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:18:02,098]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:18:06,366]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:18:06,659]\u001b[0m Trial 864 finished with value: 62.66565130922825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013886350690299326, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36005753917932776, 'dropout_rate_Layer_2': 0.18261028667745094, 'dropout_rate_Layer_3': 0.03637596093550117, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004517478758902896, 'l1_Layer_2': 0.00011102331620044676, 'l1_Layer_3': 0.0037615275048088507, 'n_units_Layer_1': 225, 'n_units_Layer_2': 270, 'n_units_Layer_3': 95}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.67 | sMAPE for Validation Set is: 43.39% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 29.04 | sMAPE for Test Set is: 41.48% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:18:21,565]\u001b[0m Trial 887 finished with value: 52.71280818599229 and parameters: {'n_hidden': 3, 'learning_rate': 0.005309583650929774, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25897268526063066, 'dropout_rate_Layer_2': 0.13021831890282232, 'dropout_rate_Layer_3': 0.03898405938335608, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014473616362209002, 'l1_Layer_2': 0.012822824558858961, 'l1_Layer_3': 0.0003288451958250743, 'n_units_Layer_1': 55, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.71 | sMAPE for Validation Set is: 38.44% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.34 | sMAPE for Test Set is: 40.04% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:18:26,962]\u001b[0m Trial 884 finished with value: 52.17763617674703 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016893939925001363, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2712306007457384, 'dropout_rate_Layer_2': 0.0689991098064568, 'dropout_rate_Layer_3': 0.03551569969598047, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005297993466476165, 'l1_Layer_2': 0.013329385707980625, 'l1_Layer_3': 0.00045317132206193055, 'n_units_Layer_1': 50, 'n_units_Layer_2': 300, 'n_units_Layer_3': 300}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.18 | sMAPE for Validation Set is: 38.01% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.56 | sMAPE for Test Set is: 37.86% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:18:32,348]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:18:34,631]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:18:40,396]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:18:44,866]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:19:53,197]\u001b[0m Trial 890 finished with value: 50.52995009610634 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006582598816247127, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11791516579780678, 'dropout_rate_Layer_2': 0.18987609896745838, 'dropout_rate_Layer_3': 0.3555119366918443, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002115273227390037, 'l1_Layer_2': 0.00034066822879126526, 'l1_Layer_3': 0.00010557545246946174, 'n_units_Layer_1': 65, 'n_units_Layer_2': 100, 'n_units_Layer_3': 205}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.53 | sMAPE for Validation Set is: 37.44% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 24.85 | sMAPE for Test Set is: 38.42% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:19:57,732]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:19:57,971]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:20:03,115]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:20:04,807]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:20:46,594]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:20:49,941]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:20:54,955]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:21:02,439]\u001b[0m Trial 902 finished with value: 68.00776311841089 and parameters: {'n_hidden': 3, 'learning_rate': 0.002868218828125199, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3671998372288833, 'dropout_rate_Layer_2': 0.188487872447279, 'dropout_rate_Layer_3': 0.34792501961286504, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025112123538617117, 'l1_Layer_2': 0.0003396648830490227, 'l1_Layer_3': 0.004623821815181735, 'n_units_Layer_1': 215, 'n_units_Layer_2': 275, 'n_units_Layer_3': 60}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 68.01 | sMAPE for Validation Set is: 45.31% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 36.28 | sMAPE for Test Set is: 46.21% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:21:19,360]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:21:21,508]\u001b[0m Trial 900 finished with value: 51.45130319553797 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006489558714628192, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11951912652063643, 'dropout_rate_Layer_2': 0.19309870533667836, 'dropout_rate_Layer_3': 0.3554323738854365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00038029050704350823, 'l1_Layer_2': 0.00015267635123148915, 'l1_Layer_3': 0.00010951150707305706, 'n_units_Layer_1': 50, 'n_units_Layer_2': 100, 'n_units_Layer_3': 200}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.45 | sMAPE for Validation Set is: 38.05% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 25.47 | sMAPE for Test Set is: 39.26% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:21:23,550]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:21:37,147]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:21:40,631]\u001b[0m Trial 908 finished with value: 51.917049448974076 and parameters: {'n_hidden': 3, 'learning_rate': 0.003528476330215135, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1870339249362846, 'dropout_rate_Layer_2': 0.0177943722093771, 'dropout_rate_Layer_3': 0.02470814405505888, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028389991383716714, 'l1_Layer_2': 7.480065311058444e-05, 'l1_Layer_3': 1.5800942228184606e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 120, 'n_units_Layer_3': 65}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.92 | sMAPE for Validation Set is: 38.21% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 29.15 | sMAPE for Test Set is: 40.44% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:21:41,471]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:21:45,879]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:21:46,997]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:21:50,115]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:21:53,370]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:22:18,987]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:22:22,243]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:22:25,829]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:22:29,954]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:22:33,575]\u001b[0m Trial 901 finished with value: 50.003369482100084 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006571032982779247, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11763199154685683, 'dropout_rate_Layer_2': 0.18777250664758718, 'dropout_rate_Layer_3': 0.3534350062960647, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021317060445297226, 'l1_Layer_2': 0.0003460372787198229, 'l1_Layer_3': 8.143167805206899e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 100, 'n_units_Layer_3': 205}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.00 | sMAPE for Validation Set is: 37.48% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 24.61 | sMAPE for Test Set is: 37.33% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:22:37,218]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:22:37,773]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:23:03,461]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:23:07,123]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:23:10,841]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:23:21,655]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:23:32,616]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:23:33,155]\u001b[0m Trial 923 finished with value: 51.956999637141706 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015415355913923133, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26161709730156674, 'dropout_rate_Layer_2': 0.07184146486964024, 'dropout_rate_Layer_3': 0.03923155194496702, 'dropout_rate_Layer_4': 0.023832434819027193, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00014225305250166386, 'l1_Layer_2': 0.017148234951850225, 'l1_Layer_3': 0.0004740517907070076, 'l1_Layer_4': 0.0006717157704319931, 'n_units_Layer_1': 50, 'n_units_Layer_2': 295, 'n_units_Layer_3': 300, 'n_units_Layer_4': 170}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.96 | sMAPE for Validation Set is: 37.87% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 24.82 | sMAPE for Test Set is: 38.36% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:23:35,687]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:23:38,102]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:23:43,038]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:23:43,179]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:23:44,000]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:23:50,820]\u001b[0m Trial 914 finished with value: 50.23536882905361 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005618124181440572, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09973275051349759, 'dropout_rate_Layer_2': 0.17309855191149512, 'dropout_rate_Layer_3': 0.34214044999200893, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001656550848172717, 'l1_Layer_2': 6.883294867855457e-05, 'l1_Layer_3': 0.00023056168070300818, 'n_units_Layer_1': 100, 'n_units_Layer_2': 85, 'n_units_Layer_3': 185}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.24 | sMAPE for Validation Set is: 37.24% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 24.75 | sMAPE for Test Set is: 38.13% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:23:51,432]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:23:51,461]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:23:57,059]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:24:00,835]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:24:01,677]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:24:07,771]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:24:11,475]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:24:28,470]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:24:59,404]\u001b[0m Trial 943 finished with value: 50.47882347754662 and parameters: {'n_hidden': 3, 'learning_rate': 0.00318232392892528, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16884057647905623, 'dropout_rate_Layer_2': 0.026952968337697468, 'dropout_rate_Layer_3': 0.007269830284072198, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008709551280765601, 'l1_Layer_2': 5.128224305843816e-05, 'l1_Layer_3': 2.0585867415433786e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 65, 'n_units_Layer_3': 80}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.48 | sMAPE for Validation Set is: 37.31% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 25.52 | sMAPE for Test Set is: 38.49% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:25:26,770]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:25:28,966]\u001b[0m Trial 936 finished with value: 50.458742142434005 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007250669886577982, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14436372957348353, 'dropout_rate_Layer_2': 0.15668986914493377, 'dropout_rate_Layer_3': 0.33808949874712085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017197986068959807, 'l1_Layer_2': 5.991405093015951e-05, 'l1_Layer_3': 0.00022931168799387547, 'n_units_Layer_1': 85, 'n_units_Layer_2': 65, 'n_units_Layer_3': 190}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.46 | sMAPE for Validation Set is: 37.53% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 26.10 | sMAPE for Test Set is: 41.03% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:25:29,639]\u001b[0m Trial 942 finished with value: 50.811788299980066 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007427845349499888, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07744599726447737, 'dropout_rate_Layer_2': 0.15550214966111053, 'dropout_rate_Layer_3': 0.33809609505649346, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015896314942227477, 'l1_Layer_2': 6.190369292761475e-05, 'l1_Layer_3': 0.000261594269297754, 'n_units_Layer_1': 85, 'n_units_Layer_2': 105, 'n_units_Layer_3': 170}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.81 | sMAPE for Validation Set is: 37.78% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 26.37 | sMAPE for Test Set is: 41.28% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:25:35,191]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:25:38,925]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:26:05,162]\u001b[0m Trial 940 finished with value: 50.16221669029187 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007303841939439961, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14564308691517594, 'dropout_rate_Layer_2': 0.16297198886611264, 'dropout_rate_Layer_3': 0.3677011855918961, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012992336132274166, 'l1_Layer_2': 6.221692167298953e-05, 'l1_Layer_3': 0.00033181601426167053, 'n_units_Layer_1': 85, 'n_units_Layer_2': 65, 'n_units_Layer_3': 195}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.16 | sMAPE for Validation Set is: 37.39% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 25.98 | sMAPE for Test Set is: 41.00% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:26:05,839]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:26:12,766]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:26:22,201]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:26:27,888]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:26:32,159]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:26:38,455]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:26:47,310]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:26:48,042]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.95 | sMAPE for Validation Set is: 37.16% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 24.36 | sMAPE for Test Set is: 36.95% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:26:50,627]\u001b[0m Trial 947 finished with value: 49.947271274414874 and parameters: {'n_hidden': 3, 'learning_rate': 0.00098947315122354, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09980979257277803, 'dropout_rate_Layer_2': 0.1755291394898708, 'dropout_rate_Layer_3': 0.3714309264139208, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012807587716009747, 'l1_Layer_2': 8.717374029010168e-05, 'l1_Layer_3': 5.7407144904770564e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 90, 'n_units_Layer_3': 240}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:26:57,556]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:27:01,397]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:27:05,252]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:27:08,999]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:28:08,043]\u001b[0m Trial 945 finished with value: 50.27165212910477 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007289682617740657, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1482774960015855, 'dropout_rate_Layer_2': 0.15268923798479875, 'dropout_rate_Layer_3': 0.37242267023508024, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001708637923375735, 'l1_Layer_2': 6.501217957397699e-05, 'l1_Layer_3': 0.00024553787327131885, 'n_units_Layer_1': 90, 'n_units_Layer_2': 65, 'n_units_Layer_3': 195}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.27 | sMAPE for Validation Set is: 37.63% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 25.69 | sMAPE for Test Set is: 40.05% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:28:12,335]\u001b[0m Trial 958 finished with value: 60.77368715015037 and parameters: {'n_hidden': 3, 'learning_rate': 0.002067684425072229, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3546994631811367, 'dropout_rate_Layer_2': 0.1873388075435575, 'dropout_rate_Layer_3': 0.07005054846873782, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013884353468089673, 'l1_Layer_2': 5.315554713059432e-05, 'l1_Layer_3': 0.005169848286570257, 'n_units_Layer_1': 205, 'n_units_Layer_2': 270, 'n_units_Layer_3': 195}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.77 | sMAPE for Validation Set is: 42.35% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 30.72 | sMAPE for Test Set is: 42.05% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:28:17,277]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:28:20,624]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:28:26,273]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:28:44,301]\u001b[0m Trial 966 finished with value: 59.18313104246359 and parameters: {'n_hidden': 4, 'learning_rate': 0.002518213128228338, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23826231146748622, 'dropout_rate_Layer_2': 0.09248219186421892, 'dropout_rate_Layer_3': 0.04101891579306709, 'dropout_rate_Layer_4': 0.2822807039585404, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005854095121662232, 'l1_Layer_2': 0.055258577775811946, 'l1_Layer_3': 0.00026525895921460183, 'l1_Layer_4': 0.008451216459661058, 'n_units_Layer_1': 60, 'n_units_Layer_2': 295, 'n_units_Layer_3': 290, 'n_units_Layer_4': 75}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.18 | sMAPE for Validation Set is: 41.49% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 28.37 | sMAPE for Test Set is: 41.62% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:28:48,648]\u001b[0m Trial 967 finished with value: 59.399069075695394 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028505249977980583, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23475290094782095, 'dropout_rate_Layer_2': 0.08609107101846322, 'dropout_rate_Layer_3': 0.03944458741294961, 'dropout_rate_Layer_4': 0.31798424224736266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005865733367555194, 'l1_Layer_2': 0.04633008842064466, 'l1_Layer_3': 0.0002876601299078489, 'l1_Layer_4': 0.005414586169098336, 'n_units_Layer_1': 60, 'n_units_Layer_2': 295, 'n_units_Layer_3': 290, 'n_units_Layer_4': 55}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.40 | sMAPE for Validation Set is: 41.80% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 28.97 | sMAPE for Test Set is: 41.62% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:28:52,642]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:28:53,587]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:28:55,919]\u001b[0m Trial 957 finished with value: 50.946893059012076 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005005546500880687, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15569694468551198, 'dropout_rate_Layer_2': 0.17424952778179162, 'dropout_rate_Layer_3': 0.37105237304470734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013184162927205956, 'l1_Layer_2': 8.120862495369494e-05, 'l1_Layer_3': 0.00017555196914573282, 'n_units_Layer_1': 75, 'n_units_Layer_2': 80, 'n_units_Layer_3': 200}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.95 | sMAPE for Validation Set is: 37.74% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 25.37 | sMAPE for Test Set is: 39.20% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:29:00,578]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:29:01,096]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:29:01,978]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:29:14,841]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:29:18,613]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:29:30,808]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:29:35,394]\u001b[0m Trial 976 finished with value: 53.61428678166766 and parameters: {'n_hidden': 4, 'learning_rate': 0.005538035710981091, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27553513762379805, 'dropout_rate_Layer_2': 0.12208364262125466, 'dropout_rate_Layer_3': 0.05332699098867754, 'dropout_rate_Layer_4': 0.0592803798202231, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00026738217967278076, 'l1_Layer_2': 0.014900896378789141, 'l1_Layer_3': 0.00032762200503463825, 'l1_Layer_4': 1.7210994143827335e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 285, 'n_units_Layer_3': 280, 'n_units_Layer_4': 180}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.61 | sMAPE for Validation Set is: 39.08% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 25.62 | sMAPE for Test Set is: 38.11% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:29:39,998]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:29:44,843]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:29:52,265]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:29:52,755]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:29:57,597]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:30:05,362]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:30:08,088]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:30:16,253]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:30:17,304]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:30:19,339]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:30:25,676]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:30:32,273]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:30:33,782]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:30:39,023]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:30:39,196]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:30:47,369]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:30:48,237]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:30:54,405]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:30:56,784]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:31:00,656]\u001b[0m Trial 990 finished with value: 52.384715171165375 and parameters: {'n_hidden': 3, 'learning_rate': 0.00472102692641613, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25810014570245, 'dropout_rate_Layer_2': 0.06011447178365828, 'dropout_rate_Layer_3': 0.0674628989663297, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001551379970668027, 'l1_Layer_2': 0.010657938642718103, 'l1_Layer_3': 0.00019390622947365176, 'n_units_Layer_1': 60, 'n_units_Layer_2': 280, 'n_units_Layer_3': 300}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.38 | sMAPE for Validation Set is: 38.43% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.67 | sMAPE for Test Set is: 40.68% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:31:04,099]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:31:04,418]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:31:10,680]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:31:11,285]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:31:17,268]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:31:17,892]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:31:22,938]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:31:23,903]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:31:30,565]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:31:41,627]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:31:46,287]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:32:01,691]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:32:06,122]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:33:03,012]\u001b[0m Trial 1006 finished with value: 62.39423154703064 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014701405976947411, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.357609098872128, 'dropout_rate_Layer_2': 0.2037910083698832, 'dropout_rate_Layer_3': 0.08224919197934227, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016747402092387132, 'l1_Layer_2': 2.888632974854583e-05, 'l1_Layer_3': 0.006139890571155255, 'n_units_Layer_1': 205, 'n_units_Layer_2': 175, 'n_units_Layer_3': 85}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.39 | sMAPE for Validation Set is: 42.90% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 33.71 | sMAPE for Test Set is: 44.29% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:33:06,115]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:33:06,884]\u001b[0m Trial 1011 finished with value: 50.981877472666916 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007902195848626211, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06739038718167167, 'dropout_rate_Layer_2': 0.16561548021306854, 'dropout_rate_Layer_3': 0.3915854854970223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.813149347429531e-05, 'l1_Layer_2': 0.0002514847358102403, 'l1_Layer_3': 0.0003402153288932132, 'n_units_Layer_1': 90, 'n_units_Layer_2': 90, 'n_units_Layer_3': 210}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.98 | sMAPE for Validation Set is: 37.81% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 25.34 | sMAPE for Test Set is: 38.99% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:33:15,700]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:33:33,508]\u001b[0m Trial 1013 finished with value: 51.049387478710635 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007876730498025428, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06929202548627988, 'dropout_rate_Layer_2': 0.1623341428425172, 'dropout_rate_Layer_3': 0.32305721555292205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.330313211167995e-05, 'l1_Layer_2': 0.00010031232154847655, 'l1_Layer_3': 6.35106298219165e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 90, 'n_units_Layer_3': 245}. Best is trial 738 with value: 49.51648963231503.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.05 | sMAPE for Validation Set is: 37.97% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 25.14 | sMAPE for Test Set is: 38.59% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:33:33,815]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:33:45,384]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:33:48,635]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:33:50,737]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:33:54,135]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:33:55,359]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:34:00,623]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:34:04,321]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:34:10,497]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:34:14,802]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:34:29,958]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:34:32,724]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:34:37,617]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:34:41,857]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:34:47,518]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:34:48,415]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:34:55,528]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:34:56,218]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:35:11,773]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:35:15,336]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:35:19,152]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:35:22,921]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:35:29,069]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:35:33,497]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:35:38,037]\u001b[0m Trial 1016 finished with value: 49.46655102596844 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005421238828147047, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10762903998290803, 'dropout_rate_Layer_2': 0.17176502371305907, 'dropout_rate_Layer_3': 0.32118520188545224, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010149363019378531, 'l1_Layer_2': 4.489162312294724e-05, 'l1_Layer_3': 0.00013688975363659037, 'n_units_Layer_1': 95, 'n_units_Layer_2': 85, 'n_units_Layer_3': 260}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:35:38,111]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.47 | sMAPE for Validation Set is: 37.20% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 24.35 | sMAPE for Test Set is: 37.40% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:35:43,927]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:35:50,693]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:35:58,406]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:36:02,308]\u001b[0m Trial 1033 finished with value: 61.72339844484346 and parameters: {'n_hidden': 3, 'learning_rate': 0.002811847168382792, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34483039665100174, 'dropout_rate_Layer_2': 0.12705952169945656, 'dropout_rate_Layer_3': 0.010376029751096161, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0033961150941790685, 'l1_Layer_2': 0.0001539287456005697, 'l1_Layer_3': 0.0073749526901972385, 'n_units_Layer_1': 215, 'n_units_Layer_2': 280, 'n_units_Layer_3': 105}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.72 | sMAPE for Validation Set is: 42.74% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.10 | sMAPE for Test Set is: 41.55% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:36:06,092]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:36:10,615]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:36:15,526]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:36:22,006]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:36:31,751]\u001b[0m Trial 1043 finished with value: 50.68588975342056 and parameters: {'n_hidden': 3, 'learning_rate': 0.000645385570422714, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08723496973360746, 'dropout_rate_Layer_2': 0.14942304956696673, 'dropout_rate_Layer_3': 0.3992894758450634, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010221346737442781, 'l1_Layer_2': 0.00012425526199163562, 'l1_Layer_3': 8.479732059997366e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 95, 'n_units_Layer_3': 260}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:36:31,768]\u001b[0m Trial 1047 finished with value: 51.571407659000386 and parameters: {'n_hidden': 3, 'learning_rate': 0.004113204188207718, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2219225581726166, 'dropout_rate_Layer_2': 0.06914853818177848, 'dropout_rate_Layer_3': 0.012224548660630212, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.85496125894284e-05, 'l1_Layer_2': 0.024329540674264634, 'l1_Layer_3': 0.00022797422357116967, 'n_units_Layer_1': 65, 'n_units_Layer_2': 280, 'n_units_Layer_3': 290}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.69 | sMAPE for Validation Set is: 37.62% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 25.59 | sMAPE for Test Set is: 39.15% | rMAE for Test Set is: 0.57\n",
      "MAE for Validation Set is: 51.57 | sMAPE for Validation Set is: 37.69% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 24.88 | sMAPE for Test Set is: 38.19% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:36:38,276]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:36:46,431]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:36:47,307]\u001b[0m Trial 1052 finished with value: 52.189842137645236 and parameters: {'n_hidden': 3, 'learning_rate': 0.00799466261785027, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2012463387106675, 'dropout_rate_Layer_2': 0.028247978447124907, 'dropout_rate_Layer_3': 0.006576180619711346, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.867346388556713e-05, 'l1_Layer_2': 0.023725458906265724, 'l1_Layer_3': 0.0003530350624217482, 'n_units_Layer_1': 280, 'n_units_Layer_2': 280, 'n_units_Layer_3': 285}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.19 | sMAPE for Validation Set is: 37.99% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 26.39 | sMAPE for Test Set is: 38.35% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:36:54,180]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:37:03,097]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:37:07,030]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:37:12,189]\u001b[0m Trial 1046 finished with value: 51.4909157724469 and parameters: {'n_hidden': 3, 'learning_rate': 0.002393008367576556, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19102898202607532, 'dropout_rate_Layer_2': 0.03725121233058529, 'dropout_rate_Layer_3': 0.019978929262274896, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004986752448261384, 'l1_Layer_2': 0.00020277245133719772, 'l1_Layer_3': 3.28973422915209e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 60, 'n_units_Layer_3': 95}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.49 | sMAPE for Validation Set is: 37.41% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 25.83 | sMAPE for Test Set is: 39.55% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:37:21,606]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:37:26,864]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:37:37,094]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:37:41,061]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:37:54,005]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:37:59,048]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:38:03,219]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:38:08,217]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:38:13,077]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:38:18,074]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:38:44,945]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:38:51,468]\u001b[0m Trial 1058 finished with value: 50.80467988375304 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009237372630390253, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1254745138126187, 'dropout_rate_Layer_2': 0.1857900831635182, 'dropout_rate_Layer_3': 0.3334724475813435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.592813373839444e-05, 'l1_Layer_2': 4.3758034622620014e-05, 'l1_Layer_3': 4.568219263291556e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 105, 'n_units_Layer_3': 250}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.80 | sMAPE for Validation Set is: 37.70% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 24.51 | sMAPE for Test Set is: 37.61% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:38:54,898]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:38:57,483]\u001b[0m Trial 1071 finished with value: 50.85593411589855 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030350512885123663, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22558354688748267, 'dropout_rate_Layer_2': 0.027866049305681047, 'dropout_rate_Layer_3': 0.005011184842836219, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.817845532237536e-05, 'l1_Layer_2': 0.011623929230295772, 'l1_Layer_3': 8.32047761198392e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 290, 'n_units_Layer_3': 295}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.86 | sMAPE for Validation Set is: 37.31% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 24.19 | sMAPE for Test Set is: 37.68% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:39:00,103]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:39:03,207]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:39:04,086]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:39:15,509]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:39:16,169]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:39:27,200]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:39:28,123]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:39:37,521]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:39:39,810]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:39:39,847]\u001b[0m Trial 1077 finished with value: 52.21490993476863 and parameters: {'n_hidden': 3, 'learning_rate': 0.004852662593958755, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22925802013711802, 'dropout_rate_Layer_2': 0.03350619203164418, 'dropout_rate_Layer_3': 0.006969591389212112, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.6219711974877974e-05, 'l1_Layer_2': 0.033331527273744346, 'l1_Layer_3': 0.00035189988571438034, 'n_units_Layer_1': 275, 'n_units_Layer_2': 290, 'n_units_Layer_3': 295}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.21 | sMAPE for Validation Set is: 38.51% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.33 | sMAPE for Test Set is: 38.97% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:39:46,341]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:39:53,611]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:39:54,208]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:39:59,721]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:40:08,765]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:40:20,360]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:40:21,393]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:40:26,505]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:40:30,764]\u001b[0m Trial 1087 finished with value: 52.20519447589942 and parameters: {'n_hidden': 3, 'learning_rate': 0.004862224979655054, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22648458365951468, 'dropout_rate_Layer_2': 0.0340927729277591, 'dropout_rate_Layer_3': 0.001476127704865068, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.818588807737303e-05, 'l1_Layer_2': 0.029497819570072335, 'l1_Layer_3': 0.00035125479197077445, 'n_units_Layer_1': 270, 'n_units_Layer_2': 290, 'n_units_Layer_3': 295}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.21 | sMAPE for Validation Set is: 38.27% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.50 | sMAPE for Test Set is: 39.28% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:40:34,081]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:40:42,035]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:40:48,711]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:40:52,235]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:41:01,554]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:41:05,579]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:41:09,160]\u001b[0m Trial 1096 finished with value: 52.07566391068796 and parameters: {'n_hidden': 3, 'learning_rate': 0.002926874406951714, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22634058559288245, 'dropout_rate_Layer_2': 0.02831462568409225, 'dropout_rate_Layer_3': 0.0071687266757456914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5486047925640696e-05, 'l1_Layer_2': 0.04141347555553411, 'l1_Layer_3': 8.274215481892392e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 290, 'n_units_Layer_3': 290}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.08 | sMAPE for Validation Set is: 37.96% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.58 | sMAPE for Test Set is: 40.08% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:41:16,091]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:41:23,535]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:41:27,260]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:41:30,451]\u001b[0m Trial 1097 finished with value: 52.16349325315343 and parameters: {'n_hidden': 3, 'learning_rate': 0.003208865030246216, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22778785788168762, 'dropout_rate_Layer_2': 0.03454871238747734, 'dropout_rate_Layer_3': 0.010160112558387925, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7127715674086206e-05, 'l1_Layer_2': 0.08214084909713161, 'l1_Layer_3': 0.00020309030052363916, 'n_units_Layer_1': 275, 'n_units_Layer_2': 290, 'n_units_Layer_3': 290}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.16 | sMAPE for Validation Set is: 38.22% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 26.19 | sMAPE for Test Set is: 38.35% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:41:30,648]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:41:38,029]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:41:38,452]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:41:50,468]\u001b[0m Trial 1100 finished with value: 51.47791961268596 and parameters: {'n_hidden': 3, 'learning_rate': 0.002295017598062041, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.221835947261306, 'dropout_rate_Layer_2': 0.022895396789905244, 'dropout_rate_Layer_3': 0.005787436290653092, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.631097094869265e-05, 'l1_Layer_2': 0.030546789716433834, 'l1_Layer_3': 0.00018583661060206087, 'n_units_Layer_1': 275, 'n_units_Layer_2': 280, 'n_units_Layer_3': 290}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.48 | sMAPE for Validation Set is: 37.87% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 25.52 | sMAPE for Test Set is: 38.52% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:41:50,712]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:41:51,431]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:42:01,279]\u001b[0m Trial 1104 finished with value: 53.09333107592769 and parameters: {'n_hidden': 3, 'learning_rate': 0.002959176008444746, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22797134429203808, 'dropout_rate_Layer_2': 0.027607607093813085, 'dropout_rate_Layer_3': 0.0068040369549444415, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.2073332059630227e-05, 'l1_Layer_2': 0.09241017295645601, 'l1_Layer_3': 0.0001807885236504867, 'n_units_Layer_1': 270, 'n_units_Layer_2': 290, 'n_units_Layer_3': 290}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.09 | sMAPE for Validation Set is: 38.74% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 25.96 | sMAPE for Test Set is: 38.22% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:42:04,649]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:42:06,016]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:42:11,109]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:42:11,379]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:42:17,527]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:42:21,731]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:42:26,475]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:42:31,556]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:42:36,060]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:42:40,165]\u001b[0m Trial 1110 finished with value: 52.47607936441218 and parameters: {'n_hidden': 3, 'learning_rate': 0.002865716150242297, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22060923127095314, 'dropout_rate_Layer_2': 0.028769984085742294, 'dropout_rate_Layer_3': 0.006846248879636047, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0057512266994602e-05, 'l1_Layer_2': 0.0738020343182133, 'l1_Layer_3': 8.556499107769049e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 290, 'n_units_Layer_3': 290}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.48 | sMAPE for Validation Set is: 38.42% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.44 | sMAPE for Test Set is: 39.58% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:42:40,845]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:42:46,347]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:42:50,332]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:42:54,734]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:43:11,395]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:43:15,888]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:43:27,235]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:43:31,975]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:43:34,479]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:43:40,310]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:43:45,098]\u001b[0m Trial 1122 finished with value: 50.67460102174974 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005476259838705095, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1406500134768972, 'dropout_rate_Layer_2': 0.16981110001996108, 'dropout_rate_Layer_3': 0.339694766218798, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000450835561892955, 'l1_Layer_2': 5.446937703968052e-05, 'l1_Layer_3': 3.909555135995684e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 95, 'n_units_Layer_3': 175}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.67 | sMAPE for Validation Set is: 37.69% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 25.49 | sMAPE for Test Set is: 39.70% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:43:45,338]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:43:46,087]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:43:46,481]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:43:54,045]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:43:56,190]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:43:58,050]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:44:01,000]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:44:04,341]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:44:07,992]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:44:13,347]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:44:17,639]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:44:21,086]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:44:21,306]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:44:27,859]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:44:28,127]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:44:33,996]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:44:35,828]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:44:40,109]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:44:55,485]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:45:04,533]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:45:06,632]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:45:11,747]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:45:15,499]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:45:17,315]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:45:22,817]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:45:23,088]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:45:29,190]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:45:35,768]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:45:39,630]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:45:43,225]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:45:44,018]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:45:50,480]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:45:54,512]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:45:59,692]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:46:03,579]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:46:17,167]\u001b[0m Trial 1139 finished with value: 50.924768156848664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006046867007839941, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12917169614025312, 'dropout_rate_Layer_2': 0.19368012243766683, 'dropout_rate_Layer_3': 0.39019480155143604, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028961265213263226, 'l1_Layer_2': 0.00010675627480347863, 'l1_Layer_3': 0.00010223369962249673, 'n_units_Layer_1': 95, 'n_units_Layer_2': 80, 'n_units_Layer_3': 245}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.92 | sMAPE for Validation Set is: 37.69% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 24.96 | sMAPE for Test Set is: 39.07% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:46:24,052]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:46:32,220]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:46:32,330]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:46:38,077]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:46:38,236]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:46:43,633]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:47:15,558]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:47:25,293]\u001b[0m Trial 1175 finished with value: 53.33017408509355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0047235227852842725, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22711417836946907, 'dropout_rate_Layer_2': 0.013440407794846562, 'dropout_rate_Layer_3': 0.028667379322563774, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.080219435763701e-05, 'l1_Layer_2': 0.04876644235757003, 'l1_Layer_3': 0.00013702046272111835, 'n_units_Layer_1': 260, 'n_units_Layer_2': 285, 'n_units_Layer_3': 300}. Best is trial 1016 with value: 49.46655102596844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.33 | sMAPE for Validation Set is: 38.90% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 25.48 | sMAPE for Test Set is: 39.27% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:47:30,034]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:47:32,545]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.38 | sMAPE for Validation Set is: 37.11% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 25.47 | sMAPE for Test Set is: 40.83% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:47:35,106]\u001b[0m Trial 1158 finished with value: 49.37653458167804 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008326345552606738, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1943633763668886, 'dropout_rate_Layer_2': 0.14996070464627456, 'dropout_rate_Layer_3': 0.3707593430888674, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001763206797028081, 'l1_Layer_2': 7.642692583627791e-05, 'l1_Layer_3': 0.00025274217321833407, 'n_units_Layer_1': 100, 'n_units_Layer_2': 65, 'n_units_Layer_3': 195}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:47:38,483]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:47:42,484]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:47:53,731]\u001b[0m Trial 1173 finished with value: 50.88706209359484 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007480398408307097, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10497419870368836, 'dropout_rate_Layer_2': 0.17595264832178384, 'dropout_rate_Layer_3': 0.3759362418311524, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022524117578861115, 'l1_Layer_2': 3.723628872609924e-05, 'l1_Layer_3': 0.0006596645417444082, 'n_units_Layer_1': 100, 'n_units_Layer_2': 50, 'n_units_Layer_3': 195}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.89 | sMAPE for Validation Set is: 37.83% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 26.11 | sMAPE for Test Set is: 40.61% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:48:04,180]\u001b[0m Trial 1178 finished with value: 52.59418786063734 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032539587240387026, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19642026805932203, 'dropout_rate_Layer_2': 0.05687029706761777, 'dropout_rate_Layer_3': 0.012132801055769615, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5701591689954307e-05, 'l1_Layer_2': 0.05920433658054899, 'l1_Layer_3': 7.740368333557971e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 295, 'n_units_Layer_3': 285}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.59 | sMAPE for Validation Set is: 38.49% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.32 | sMAPE for Test Set is: 38.60% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:48:07,766]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:48:08,011]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:48:44,840]\u001b[0m Trial 1185 finished with value: 50.521102320369 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012994172781499178, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22901982294325665, 'dropout_rate_Layer_2': 0.13892643538265675, 'dropout_rate_Layer_3': 0.35729051881423235, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026468935710305023, 'l1_Layer_2': 0.00026875312860387326, 'l1_Layer_3': 2.8652183996788715e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 85, 'n_units_Layer_3': 270}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.52 | sMAPE for Validation Set is: 37.67% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 26.36 | sMAPE for Test Set is: 41.83% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:48:48,498]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:48:52,490]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:48:52,964]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:49:01,428]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:49:14,443]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:49:15,335]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:49:26,023]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:49:26,794]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:49:28,838]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:49:29,485]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:49:36,681]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:49:41,686]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:49:51,214]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:50:00,384]\u001b[0m Trial 1196 finished with value: 52.501541631025866 and parameters: {'n_hidden': 3, 'learning_rate': 0.003866235048127506, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17743216126550262, 'dropout_rate_Layer_2': 0.06630305397051445, 'dropout_rate_Layer_3': 0.019423317802031288, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.1329649277164005e-05, 'l1_Layer_2': 0.03960461982286532, 'l1_Layer_3': 0.00011606369068737463, 'n_units_Layer_1': 265, 'n_units_Layer_2': 275, 'n_units_Layer_3': 290}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.50 | sMAPE for Validation Set is: 38.20% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 25.20 | sMAPE for Test Set is: 38.65% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:50:09,074]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:50:11,540]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:50:15,955]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:50:25,461]\u001b[0m Trial 1200 finished with value: 51.919965651954215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037781130192240265, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22142065962540738, 'dropout_rate_Layer_2': 0.06641255765150568, 'dropout_rate_Layer_3': 0.020614059948754714, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.3753229055156344e-05, 'l1_Layer_2': 0.04272195149675824, 'l1_Layer_3': 5.602183280128958e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 275, 'n_units_Layer_3': 290}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.92 | sMAPE for Validation Set is: 38.38% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 25.47 | sMAPE for Test Set is: 40.71% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:50:25,830]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:50:41,842]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:50:42,829]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:50:49,310]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:50:50,454]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:50:54,033]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:50:54,949]\u001b[0m Trial 1195 finished with value: 51.23008328389279 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005866514278811923, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12001792975734286, 'dropout_rate_Layer_2': 0.15127748355484133, 'dropout_rate_Layer_3': 0.3673482872763421, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001690993772510881, 'l1_Layer_2': 7.16816015963186e-05, 'l1_Layer_3': 0.0002451168066415245, 'n_units_Layer_1': 90, 'n_units_Layer_2': 60, 'n_units_Layer_3': 180}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.23 | sMAPE for Validation Set is: 37.82% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 26.23 | sMAPE for Test Set is: 41.16% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:50:58,476]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:51:05,522]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:51:06,041]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:51:06,211]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:51:16,126]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:51:16,595]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:51:24,050]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:51:50,855]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:51:54,710]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:52:03,334]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:52:17,848]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:52:22,192]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:52:26,021]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:52:35,498]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:52:38,628]\u001b[0m Trial 1217 finished with value: 50.67801519933969 and parameters: {'n_hidden': 3, 'learning_rate': 0.000679076528079602, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14123591034562227, 'dropout_rate_Layer_2': 0.14813499108646272, 'dropout_rate_Layer_3': 0.35193076591753164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001497212906674276, 'l1_Layer_2': 6.270386301625323e-05, 'l1_Layer_3': 8.61822850669032e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 70, 'n_units_Layer_3': 185}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.68 | sMAPE for Validation Set is: 37.65% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 25.30 | sMAPE for Test Set is: 39.19% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:52:43,637]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:52:50,929]\u001b[0m Trial 1210 finished with value: 50.34580946309912 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005962224225874144, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11783909581546048, 'dropout_rate_Layer_2': 0.14945721362794204, 'dropout_rate_Layer_3': 0.36735630470370256, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015993870966807887, 'l1_Layer_2': 6.34210362648639e-05, 'l1_Layer_3': 7.863873996014427e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 65, 'n_units_Layer_3': 200}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.35 | sMAPE for Validation Set is: 37.40% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 24.98 | sMAPE for Test Set is: 38.31% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:53:05,334]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:53:08,641]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:53:12,618]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:53:16,948]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:53:17,543]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:53:18,458]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:53:28,079]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:53:35,244]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:53:40,182]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:53:40,967]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:53:46,909]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:53:49,265]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:53:55,141]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:53:59,068]\u001b[0m Trial 1230 finished with value: 50.76649056174873 and parameters: {'n_hidden': 3, 'learning_rate': 0.000986421702105743, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14938202959923638, 'dropout_rate_Layer_2': 0.17091411123322614, 'dropout_rate_Layer_3': 0.32282984038168444, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022635915424677332, 'l1_Layer_2': 8.674640332098686e-05, 'l1_Layer_3': 5.830189120119619e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 90, 'n_units_Layer_3': 190}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.77 | sMAPE for Validation Set is: 37.73% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 27.11 | sMAPE for Test Set is: 43.13% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:53:59,348]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:54:06,284]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:54:06,507]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:54:31,868]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:54:32,008]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:54:48,785]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:54:53,423]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:54:57,548]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:55:18,731]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:55:23,137]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:55:27,312]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:55:32,568]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:55:36,619]\u001b[0m Trial 1235 finished with value: 53.43288842929627 and parameters: {'n_hidden': 3, 'learning_rate': 0.001355379588646878, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3739117648627792, 'dropout_rate_Layer_2': 0.24881899171733957, 'dropout_rate_Layer_3': 0.013535063404709835, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.1465278328925164e-05, 'l1_Layer_2': 0.00015422385319527343, 'l1_Layer_3': 0.0036112704291344252, 'n_units_Layer_1': 240, 'n_units_Layer_2': 290, 'n_units_Layer_3': 125}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.43 | sMAPE for Validation Set is: 38.72% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 26.04 | sMAPE for Test Set is: 38.19% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:55:48,772]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:55:52,265]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:55:58,277]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:56:03,614]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:56:13,713]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:56:21,897]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:56:26,085]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:56:30,407]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:56:34,783]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:56:39,880]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:56:43,510]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.00 | sMAPE for Validation Set is: 39.10% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 25.31 | sMAPE for Test Set is: 38.13% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:56:46,172]\u001b[0m Trial 1240 finished with value: 54.00384268172987 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013523186922972258, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3757235850645472, 'dropout_rate_Layer_2': 0.21088779189511944, 'dropout_rate_Layer_3': 0.10713487783978831, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.822467508750805e-05, 'l1_Layer_2': 6.0164601019088436e-05, 'l1_Layer_3': 0.003174358210492152, 'n_units_Layer_1': 210, 'n_units_Layer_2': 290, 'n_units_Layer_3': 205}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:56:50,834]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:56:54,379]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:56:54,644]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:56:55,556]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:57:03,743]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:57:06,297]\u001b[0m Trial 1255 finished with value: 51.01294682231556 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017093941192592972, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2320296065668111, 'dropout_rate_Layer_2': 0.018141941285624047, 'dropout_rate_Layer_3': 0.02597716777882314, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.404856531079349e-05, 'l1_Layer_2': 0.01999533398544666, 'l1_Layer_3': 0.0005049198564535585, 'n_units_Layer_1': 275, 'n_units_Layer_2': 300, 'n_units_Layer_3': 295}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.01 | sMAPE for Validation Set is: 37.49% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 24.20 | sMAPE for Test Set is: 37.71% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:57:06,945]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:57:11,700]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:57:12,266]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:57:18,773]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:57:19,147]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:57:26,639]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:57:30,919]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:57:35,307]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:57:37,755]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:57:39,838]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:57:45,472]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:57:48,921]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:57:49,741]\u001b[0m Trial 1276 finished with value: 50.784921497177585 and parameters: {'n_hidden': 3, 'learning_rate': 0.003605982488938928, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.204294647666386, 'dropout_rate_Layer_2': 0.022326571490545236, 'dropout_rate_Layer_3': 0.05197861451618253, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003642191969767459, 'l1_Layer_2': 9.806496485893391e-05, 'l1_Layer_3': 1.9404392775533905e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 60, 'n_units_Layer_3': 95}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.78 | sMAPE for Validation Set is: 37.61% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 26.46 | sMAPE for Test Set is: 40.54% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:57:56,191]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:57:56,898]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:57:58,791]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:58:05,892]\u001b[0m Trial 1273 finished with value: 51.772747465245544 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033746652600795605, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2336151738379621, 'dropout_rate_Layer_2': 0.020505925751359438, 'dropout_rate_Layer_3': 0.024715564790170307, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6547771915662923e-05, 'l1_Layer_2': 0.06600426283386024, 'l1_Layer_3': 5.36902052821288e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 300, 'n_units_Layer_3': 295}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.77 | sMAPE for Validation Set is: 37.69% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 24.58 | sMAPE for Test Set is: 37.89% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:58:21,371]\u001b[0m Trial 1290 finished with value: 51.745783899656224 and parameters: {'n_hidden': 3, 'learning_rate': 0.00325677972791354, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20604715307838162, 'dropout_rate_Layer_2': 0.0210209348860427, 'dropout_rate_Layer_3': 0.056014824789678924, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003327819436872242, 'l1_Layer_2': 0.000128831286105669, 'l1_Layer_3': 3.0709867380449624e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 65, 'n_units_Layer_3': 95}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.75 | sMAPE for Validation Set is: 37.53% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 25.17 | sMAPE for Test Set is: 38.57% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 10:58:23,328]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:58:27,065]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:58:32,571]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:58:33,847]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:58:37,774]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:58:42,199]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:58:46,496]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:58:49,565]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:58:56,365]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:58:59,431]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:59:04,319]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:59:07,074]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:59:09,395]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:59:10,299]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:59:13,762]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:59:22,510]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:59:23,449]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:59:29,491]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:59:30,665]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:59:37,251]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:59:37,578]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:59:44,328]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:59:48,634]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 10:59:56,050]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:00:00,594]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:00:14,658]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:00:18,936]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:00:24,540]\u001b[0m Trial 1288 finished with value: 50.726299051090905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011925358084146262, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2316964630963238, 'dropout_rate_Layer_2': 0.017964557832621384, 'dropout_rate_Layer_3': 0.009417025337417933, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3706075219272518e-05, 'l1_Layer_2': 0.01989539039730679, 'l1_Layer_3': 5.064518466975483e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 300, 'n_units_Layer_3': 295}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.73 | sMAPE for Validation Set is: 37.74% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 25.23 | sMAPE for Test Set is: 38.68% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:00:32,993]\u001b[0m Trial 1307 finished with value: 51.017500891064884 and parameters: {'n_hidden': 3, 'learning_rate': 0.002362768456432434, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23192485622452635, 'dropout_rate_Layer_2': 0.0032208972386775173, 'dropout_rate_Layer_3': 0.010338324276281945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.479201411055133e-05, 'l1_Layer_2': 0.020341996406879077, 'l1_Layer_3': 4.084344428953222e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.02 | sMAPE for Validation Set is: 37.61% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 24.63 | sMAPE for Test Set is: 38.31% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:00:41,430]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:00:46,143]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:00:50,088]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:00:57,984]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:00:59,607]\u001b[0m Trial 1319 finished with value: 52.35247119990051 and parameters: {'n_hidden': 3, 'learning_rate': 0.003228726680059471, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2315302794884767, 'dropout_rate_Layer_2': 0.0009447853632362432, 'dropout_rate_Layer_3': 0.012760716043613153, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.2930702385909625e-05, 'l1_Layer_2': 0.019767340333774565, 'l1_Layer_3': 5.634855284009965e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.35 | sMAPE for Validation Set is: 38.17% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 24.94 | sMAPE for Test Set is: 38.78% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:01:04,491]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:01:07,337]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:01:12,260]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:01:17,183]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:01:19,895]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:01:26,965]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:01:29,506]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:01:33,851]\u001b[0m Trial 1320 finished with value: 51.13084171024226 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031775508787950657, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2140437415844977, 'dropout_rate_Layer_2': 0.00021738880676646505, 'dropout_rate_Layer_3': 7.571371412164185e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0550467810195494e-05, 'l1_Layer_2': 0.020301308228798207, 'l1_Layer_3': 5.542908284766783e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.13 | sMAPE for Validation Set is: 37.80% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 24.97 | sMAPE for Test Set is: 39.16% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:01:48,155]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:01:52,375]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:02:01,439]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:02:16,322]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:02:20,201]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:02:20,926]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:02:27,450]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:02:31,538]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:02:31,838]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:02:38,706]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:02:39,485]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:02:46,983]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:02:47,891]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:02:53,633]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:02:58,486]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:03:00,517]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:03:04,808]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:03:08,900]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:03:12,094]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:03:12,511]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:03:25,964]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:03:29,937]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:03:34,289]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:03:38,306]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:03:49,649]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:04:02,052]\u001b[0m Trial 1346 finished with value: 51.75044920636941 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011852793238427582, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2149275061505127, 'dropout_rate_Layer_2': 0.019796455468085523, 'dropout_rate_Layer_3': 0.02259384521654986, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0848074879930488e-05, 'l1_Layer_2': 0.07577958987321952, 'l1_Layer_3': 4.882066949295585e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 300, 'n_units_Layer_3': 275}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.75 | sMAPE for Validation Set is: 38.13% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 24.94 | sMAPE for Test Set is: 38.28% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:04:13,926]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:04:19,806]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:04:32,805]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:04:33,033]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:04:40,418]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:04:45,409]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:04:47,432]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:04:56,246]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:04:59,456]\u001b[0m Trial 1358 finished with value: 66.12386858820692 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014401412501301276, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34945000584501695, 'dropout_rate_Layer_2': 0.2332066456238374, 'dropout_rate_Layer_3': 0.38363340309635546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008175164309665706, 'l1_Layer_2': 3.3575414715065826e-05, 'l1_Layer_3': 0.026090589135427632, 'n_units_Layer_1': 280, 'n_units_Layer_2': 265, 'n_units_Layer_3': 100}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 66.12 | sMAPE for Validation Set is: 44.84% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 31.12 | sMAPE for Test Set is: 42.46% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:05:00,793]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:05:04,188]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:05:19,180]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:05:38,496]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:05:48,150]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:05:52,448]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:05:52,710]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:05:59,088]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:06:04,171]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:07:01,095]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:07:08,263]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:07:12,995]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:07:16,990]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:07:22,842]\u001b[0m Trial 1372 finished with value: 62.19095905413396 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020906058366241464, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3274491462800984, 'dropout_rate_Layer_2': 0.34356008938107074, 'dropout_rate_Layer_3': 0.03607022519203521, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.686170153016159e-05, 'l1_Layer_2': 0.00012294488873956883, 'l1_Layer_3': 0.004360162749007005, 'n_units_Layer_1': 210, 'n_units_Layer_2': 225, 'n_units_Layer_3': 55}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.19 | sMAPE for Validation Set is: 43.22% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.19 | sMAPE for Test Set is: 41.10% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:07:27,112]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:07:33,427]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:07:42,437]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:07:58,341]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:08:02,855]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:08:06,570]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:08:10,421]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:08:12,386]\u001b[0m Trial 1378 finished with value: 61.98576877781798 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016159474750809591, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3694479640875659, 'dropout_rate_Layer_2': 0.19155724033614857, 'dropout_rate_Layer_3': 0.054026160937415794, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012786356505196908, 'l1_Layer_2': 7.726557752698968e-05, 'l1_Layer_3': 0.004549773658846565, 'n_units_Layer_1': 215, 'n_units_Layer_2': 290, 'n_units_Layer_3': 180}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.99 | sMAPE for Validation Set is: 43.00% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.71 | sMAPE for Test Set is: 42.00% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:08:15,586]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:08:19,691]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:08:24,555]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:08:27,953]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:08:28,573]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:08:34,374]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:08:35,750]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:08:40,165]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:08:45,294]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:08:46,812]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:08:48,053]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:08:52,958]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:08:53,000]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:09:04,965]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:09:08,502]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:09:14,513]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:09:16,366]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:09:21,599]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:09:25,127]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:09:25,699]\u001b[0m Trial 1386 finished with value: 51.10552965718558 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011700469823390763, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19254782562792355, 'dropout_rate_Layer_2': 0.006306697818310277, 'dropout_rate_Layer_3': 0.015444191161972643, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.289597990417504e-05, 'l1_Layer_2': 0.06660438736059207, 'l1_Layer_3': 2.051092593603676e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 285, 'n_units_Layer_3': 280}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.11 | sMAPE for Validation Set is: 37.81% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 24.61 | sMAPE for Test Set is: 37.82% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:09:35,425]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:09:39,413]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:09:39,822]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:09:45,627]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:09:48,482]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:09:51,929]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:09:53,587]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:10:00,135]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:10:04,706]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:10:14,109]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:10:30,070]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:10:31,424]\u001b[0m Trial 1417 finished with value: 51.16319600069142 and parameters: {'n_hidden': 3, 'learning_rate': 0.00229474224060516, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.170602047270696, 'dropout_rate_Layer_2': 0.02989104318957544, 'dropout_rate_Layer_3': 5.558663701194823e-06, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0035875303993292366, 'l1_Layer_2': 0.00010207562201572949, 'l1_Layer_3': 2.5903581666793977e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 105, 'n_units_Layer_3': 70}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.16 | sMAPE for Validation Set is: 37.29% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 27.33 | sMAPE for Test Set is: 38.53% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:10:36,803]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:10:38,341]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:10:44,039]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:10:45,010]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:10:55,838]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:10:59,280]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:11:04,350]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:11:07,798]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:11:12,652]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:11:16,535]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:11:42,879]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:11:51,414]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:11:55,150]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:12:02,628]\u001b[0m Trial 1411 finished with value: 50.73525207959503 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011223187978401435, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19529884886375715, 'dropout_rate_Layer_2': 0.0011606424452894094, 'dropout_rate_Layer_3': 0.02470830951771847, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0041349829539276e-05, 'l1_Layer_2': 0.06363711975370823, 'l1_Layer_3': 2.3431162765392984e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 270, 'n_units_Layer_3': 275}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.74 | sMAPE for Validation Set is: 37.55% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 24.15 | sMAPE for Test Set is: 37.63% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:12:07,838]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:12:07,880]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:12:23,698]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:12:53,148]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:13:07,058]\u001b[0m Trial 1437 finished with value: 60.69964003177994 and parameters: {'n_hidden': 3, 'learning_rate': 0.0062110056334394245, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3504174579601505, 'dropout_rate_Layer_2': 0.24204746652874395, 'dropout_rate_Layer_3': 0.08482135945276223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001567939483386802, 'l1_Layer_2': 0.00011253472319947435, 'l1_Layer_3': 0.0036967569905056456, 'n_units_Layer_1': 210, 'n_units_Layer_2': 270, 'n_units_Layer_3': 95}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.70 | sMAPE for Validation Set is: 42.43% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.32 | sMAPE for Test Set is: 41.29% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:13:07,704]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:13:16,683]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:13:21,629]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:13:27,565]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:13:31,240]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:13:34,161]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:13:38,796]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:13:39,443]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:13:44,995]\u001b[0m Trial 1435 finished with value: 55.45479222014074 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017810198488291164, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34557515922648635, 'dropout_rate_Layer_2': 0.25615429683236624, 'dropout_rate_Layer_3': 0.08532306920989086, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014621859013069101, 'l1_Layer_2': 9.714688849360843e-05, 'l1_Layer_3': 1.7304856262193137e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 270, 'n_units_Layer_3': 90}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.45 | sMAPE for Validation Set is: 39.73% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 28.35 | sMAPE for Test Set is: 40.15% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:13:53,655]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:14:00,451]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:14:04,908]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:14:18,155]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:14:22,181]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:14:25,754]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:14:32,184]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:14:36,220]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:14:40,201]\u001b[0m Trial 1454 finished with value: 50.7565478554232 and parameters: {'n_hidden': 3, 'learning_rate': 0.002478431063504182, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1935001323969194, 'dropout_rate_Layer_2': 0.041137969247786906, 'dropout_rate_Layer_3': 0.011731950805241474, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003435194982626899, 'l1_Layer_2': 0.00031253349757190846, 'l1_Layer_3': 2.9146894262272304e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 65, 'n_units_Layer_3': 80}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.76 | sMAPE for Validation Set is: 37.28% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 28.36 | sMAPE for Test Set is: 39.54% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:14:45,059]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:14:47,281]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:14:53,946]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:15:32,038]\u001b[0m Trial 1461 finished with value: 52.295926181585344 and parameters: {'n_hidden': 3, 'learning_rate': 0.001765560459017903, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3402341064207922, 'dropout_rate_Layer_2': 0.25435865799041474, 'dropout_rate_Layer_3': 0.08238110328616202, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009536235341162064, 'l1_Layer_2': 9.398720852660879e-05, 'l1_Layer_3': 0.013087481286154199, 'n_units_Layer_1': 200, 'n_units_Layer_2': 280, 'n_units_Layer_3': 100}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.30 | sMAPE for Validation Set is: 38.11% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 27.01 | sMAPE for Test Set is: 38.29% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:15:36,389]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:15:41,855]\u001b[0m Trial 1441 finished with value: 51.325177198996556 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007398894401889703, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21192197558922363, 'dropout_rate_Layer_2': 0.0020187620743096803, 'dropout_rate_Layer_3': 0.051493751614674385, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2677710600498043e-05, 'l1_Layer_2': 0.0386183951779154, 'l1_Layer_3': 2.602937650665696e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 270, 'n_units_Layer_3': 295}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.33 | sMAPE for Validation Set is: 37.74% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 24.21 | sMAPE for Test Set is: 37.68% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:15:48,647]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:15:52,336]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:16:01,794]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:16:16,437]\u001b[0m Trial 1450 finished with value: 49.81474642487046 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008268627342320335, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1567137047954264, 'dropout_rate_Layer_2': 0.1423157623819347, 'dropout_rate_Layer_3': 0.35273054012001304, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010074050842703473, 'l1_Layer_2': 4.1395458764905146e-05, 'l1_Layer_3': 0.0002446271949055023, 'n_units_Layer_1': 105, 'n_units_Layer_2': 200, 'n_units_Layer_3': 205}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.81 | sMAPE for Validation Set is: 37.74% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 25.80 | sMAPE for Test Set is: 40.89% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:16:23,440]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:16:27,812]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:16:49,060]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:16:55,617]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:16:59,916]\u001b[0m Trial 1463 finished with value: 49.8960289048108 and parameters: {'n_hidden': 3, 'learning_rate': 0.00084391515798018, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12766777412391223, 'dropout_rate_Layer_2': 0.13823619904088638, 'dropout_rate_Layer_3': 0.3482778999707573, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010152181091331675, 'l1_Layer_2': 6.813452471824294e-05, 'l1_Layer_3': 0.00021845921142185613, 'n_units_Layer_1': 105, 'n_units_Layer_2': 55, 'n_units_Layer_3': 180}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.90 | sMAPE for Validation Set is: 37.30% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 25.16 | sMAPE for Test Set is: 38.84% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:17:16,876]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:17:30,899]\u001b[0m Trial 1475 finished with value: 50.863381747400325 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025033413792376258, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1890050371336292, 'dropout_rate_Layer_2': 0.03825407506119579, 'dropout_rate_Layer_3': 0.015168728352647924, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003177627584976934, 'l1_Layer_2': 0.0007407501643619882, 'l1_Layer_3': 1.4099421404592326e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 70, 'n_units_Layer_3': 85}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.86 | sMAPE for Validation Set is: 37.67% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 26.37 | sMAPE for Test Set is: 38.29% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:17:41,354]\u001b[0m Trial 1474 finished with value: 52.22593144578911 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011842301387885005, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029730780268005907, 'dropout_rate_Layer_2': 0.24141572641966505, 'dropout_rate_Layer_3': 0.0712815492857024, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008995895898005069, 'l1_Layer_2': 8.097501670900048e-05, 'l1_Layer_3': 1.0588318905448015e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 60, 'n_units_Layer_3': 100}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.23 | sMAPE for Validation Set is: 37.95% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 27.57 | sMAPE for Test Set is: 39.14% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:17:43,710]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:17:53,801]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:18:09,320]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:18:40,670]\u001b[0m Trial 1481 finished with value: 51.40930340157541 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010980169214135983, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1871793632493109, 'dropout_rate_Layer_2': 0.24427945006605023, 'dropout_rate_Layer_3': 0.3329424218302832, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000471013336197851, 'l1_Layer_2': 9.523971544242641e-05, 'l1_Layer_3': 1.1771861742896477e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 260, 'n_units_Layer_3': 110}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.41 | sMAPE for Validation Set is: 37.76% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 24.79 | sMAPE for Test Set is: 37.74% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:19:12,196]\u001b[0m Trial 1465 finished with value: 50.71382033119958 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007693570300398209, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18739967044450792, 'dropout_rate_Layer_2': 0.0028850202270687512, 'dropout_rate_Layer_3': 0.02238012181940416, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0262433270905376e-05, 'l1_Layer_2': 0.050262828019617574, 'l1_Layer_3': 2.3736979466140797e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 270, 'n_units_Layer_3': 280}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.71 | sMAPE for Validation Set is: 37.30% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 23.70 | sMAPE for Test Set is: 37.09% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:19:16,834]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:19:22,791]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:19:27,999]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:19:33,442]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:19:34,575]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:19:43,029]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:19:43,648]\u001b[0m Trial 1482 finished with value: 50.65696725506084 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008966262290903221, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010085620191158079, 'dropout_rate_Layer_2': 0.24783210234701467, 'dropout_rate_Layer_3': 0.3468317257631984, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003975303462806858, 'l1_Layer_2': 9.069926169559994e-05, 'l1_Layer_3': 1.440174905599368e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 255, 'n_units_Layer_3': 110}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.66 | sMAPE for Validation Set is: 37.30% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 27.09 | sMAPE for Test Set is: 38.58% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:19:54,514]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:19:57,141]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:19:58,395]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:20:05,610]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:20:06,232]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:20:13,106]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:20:24,866]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:20:33,308]\u001b[0m Trial 1491 finished with value: 50.94340915491849 and parameters: {'n_hidden': 3, 'learning_rate': 0.000920083903612449, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02155561820405985, 'dropout_rate_Layer_2': 0.2441794237683451, 'dropout_rate_Layer_3': 0.0745584815912947, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00039935363361128824, 'l1_Layer_2': 9.197927222930507e-05, 'l1_Layer_3': 1.0548415015345027e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 245, 'n_units_Layer_3': 110}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.94 | sMAPE for Validation Set is: 37.35% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 26.13 | sMAPE for Test Set is: 38.30% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:20:34,245]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:20:34,687]\u001b[0m Trial 1496 finished with value: 52.173683487851186 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009181308883910027, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_Woff_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026437467179529384, 'dropout_rate_Layer_2': 0.24883887261820087, 'dropout_rate_Layer_3': 0.36093733694896574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00040690198861088043, 'l1_Layer_2': 9.914221778111224e-05, 'l1_Layer_3': 1.5493185287690765e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 250, 'n_units_Layer_3': 115}. Best is trial 1158 with value: 49.37653458167804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.17 | sMAPE for Validation Set is: 38.23% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 38.65 | sMAPE for Test Set is: 47.14% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-07 11:20:38,713]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:20:42,309]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-07 11:21:03,068]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-01-01, MAE is:14.65 & sMAPE is:111.14% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :14.65 & 111.14% & 0.17\n",
      "for 2023-01-02, MAE is:93.10 & sMAPE is:124.50% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :53.87 & 117.82% & 0.63\n",
      "for 2023-01-03, MAE is:42.29 & sMAPE is:40.79% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :50.01 & 92.14% & 0.68\n",
      "for 2023-01-04, MAE is:22.66 & sMAPE is:33.40% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :43.17 & 77.46% & 0.69\n",
      "for 2023-01-05, MAE is:92.44 & sMAPE is:132.85% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :53.03 & 88.53% & 0.75\n",
      "for 2023-01-06, MAE is:19.51 & sMAPE is:17.69% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :47.44 & 76.73% & 0.66\n",
      "for 2023-01-07, MAE is:22.24 & sMAPE is:31.03% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :43.84 & 70.20% & 0.61\n",
      "for 2023-01-08, MAE is:21.19 & sMAPE is:55.53% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :41.01 & 68.36% & 0.63\n",
      "for 2023-01-09, MAE is:46.32 & sMAPE is:62.08% & rMAE is:3.68 ||| daily mean of MAE & sMAPE & rMAE till now are :41.60 & 67.67% & 0.97\n",
      "for 2023-01-10, MAE is:45.99 & sMAPE is:57.27% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :42.04 & 66.63% & 1.05\n",
      "for 2023-01-11, MAE is:13.48 & sMAPE is:22.47% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :39.44 & 62.61% & 1.01\n",
      "for 2023-01-12, MAE is:15.10 & sMAPE is:41.88% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :37.41 & 60.88% & 0.95\n",
      "for 2023-01-13, MAE is:33.21 & sMAPE is:71.73% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :37.09 & 61.72% & 0.94\n",
      "for 2023-01-14, MAE is:25.48 & sMAPE is:63.76% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :36.26 & 61.87% & 0.94\n",
      "for 2023-01-15, MAE is:17.85 & sMAPE is:73.62% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :35.03 & 62.65% & 0.92\n",
      "for 2023-01-16, MAE is:43.47 & sMAPE is:78.17% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :35.56 & 63.62% & 0.94\n",
      "for 2023-01-17, MAE is:27.60 & sMAPE is:49.38% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :35.09 & 62.78% & 0.91\n",
      "for 2023-01-18, MAE is:87.22 & sMAPE is:131.81% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :37.99 & 66.62% & 0.95\n",
      "for 2023-01-19, MAE is:42.51 & sMAPE is:38.96% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :38.23 & 65.16% & 0.93\n",
      "for 2023-01-20, MAE is:105.75 & sMAPE is:85.83% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :41.60 & 66.19% & 0.93\n",
      "for 2023-01-21, MAE is:26.65 & sMAPE is:21.61% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :40.89 & 64.07% & 0.90\n",
      "for 2023-01-22, MAE is:26.87 & sMAPE is:21.13% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :40.25 & 62.12% & 0.87\n",
      "for 2023-01-23, MAE is:92.52 & sMAPE is:60.97% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :42.53 & 62.07% & 0.87\n",
      "for 2023-01-24, MAE is:71.99 & sMAPE is:44.88% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :43.75 & 61.35% & 0.86\n",
      "for 2023-01-25, MAE is:32.05 & sMAPE is:30.35% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :43.29 & 60.11% & 0.87\n",
      "for 2023-01-26, MAE is:68.45 & sMAPE is:72.21% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :44.25 & 60.58% & 0.92\n",
      "for 2023-01-27, MAE is:96.31 & sMAPE is:100.06% & rMAE is:4.59 ||| daily mean of MAE & sMAPE & rMAE till now are :46.18 & 62.04% & 1.06\n",
      "for 2023-01-28, MAE is:52.21 & sMAPE is:58.61% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :46.40 & 61.92% & 1.05\n",
      "for 2023-01-29, MAE is:13.07 & sMAPE is:46.67% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :45.25 & 61.39% & 1.02\n",
      "for 2023-01-30, MAE is:52.24 & sMAPE is:116.00% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :45.48 & 63.21% & 1.00\n",
      "for 2023-01-31, MAE is:18.52 & sMAPE is:47.42% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :44.61 & 62.70% & 0.97\n",
      "for 2023-02-01, MAE is:53.69 & sMAPE is:93.28% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :44.89 & 63.66% & 0.98\n",
      "for 2023-02-02, MAE is:94.49 & sMAPE is:114.59% & rMAE is:3.24 ||| daily mean of MAE & sMAPE & rMAE till now are :46.40 & 65.20% & 1.05\n",
      "for 2023-02-03, MAE is:27.54 & sMAPE is:32.15% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :45.84 & 64.23% & 1.03\n",
      "for 2023-02-04, MAE is:93.49 & sMAPE is:98.32% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :47.20 & 65.20% & 1.04\n",
      "for 2023-02-05, MAE is:14.24 & sMAPE is:13.73% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :46.29 & 63.77% & 1.02\n",
      "for 2023-02-06, MAE is:72.02 & sMAPE is:54.74% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :46.98 & 63.53% & 1.00\n",
      "for 2023-02-07, MAE is:65.55 & sMAPE is:48.07% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :47.47 & 63.12% & 1.00\n",
      "for 2023-02-08, MAE is:50.54 & sMAPE is:48.40% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :47.55 & 62.75% & 0.99\n",
      "for 2023-02-09, MAE is:18.94 & sMAPE is:92.00% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :46.84 & 63.48% & 0.97\n",
      "for 2023-02-10, MAE is:33.80 & sMAPE is:102.23% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :46.52 & 64.42% & 0.97\n",
      "for 2023-02-11, MAE is:30.72 & sMAPE is:80.55% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :46.14 & 64.81% & 0.95\n",
      "for 2023-02-12, MAE is:58.98 & sMAPE is:81.96% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :46.44 & 65.21% & 0.96\n",
      "for 2023-02-13, MAE is:64.59 & sMAPE is:110.76% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :46.85 & 66.24% & 0.96\n",
      "for 2023-02-14, MAE is:39.19 & sMAPE is:30.85% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :46.68 & 65.45% & 0.99\n",
      "for 2023-02-15, MAE is:45.13 & sMAPE is:38.43% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :46.65 & 64.87% & 1.00\n",
      "for 2023-02-16, MAE is:54.14 & sMAPE is:52.87% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :46.81 & 64.61% & 0.99\n",
      "for 2023-02-17, MAE is:23.11 & sMAPE is:47.56% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :46.31 & 64.26% & 0.99\n",
      "for 2023-02-18, MAE is:21.56 & sMAPE is:89.99% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :45.81 & 64.78% & 0.99\n",
      "for 2023-02-19, MAE is:43.07 & sMAPE is:112.40% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :45.75 & 65.73% & 0.98\n",
      "for 2023-02-20, MAE is:29.10 & sMAPE is:55.73% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :45.43 & 65.54% & 0.97\n",
      "for 2023-02-21, MAE is:67.73 & sMAPE is:96.12% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :45.86 & 66.13% & 0.98\n",
      "for 2023-02-22, MAE is:40.55 & sMAPE is:40.08% & rMAE is:2.72 ||| daily mean of MAE & sMAPE & rMAE till now are :45.76 & 65.63% & 1.01\n",
      "for 2023-02-23, MAE is:70.92 & sMAPE is:114.33% & rMAE is:3.48 ||| daily mean of MAE & sMAPE & rMAE till now are :46.22 & 66.54% & 1.06\n",
      "for 2023-02-24, MAE is:35.51 & sMAPE is:61.33% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :46.03 & 66.44% & 1.06\n",
      "for 2023-02-25, MAE is:6.18 & sMAPE is:25.07% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :45.32 & 65.70% & 1.06\n",
      "for 2023-02-26, MAE is:65.93 & sMAPE is:127.67% & rMAE is:2.48 ||| daily mean of MAE & sMAPE & rMAE till now are :45.68 & 66.79% & 1.09\n",
      "for 2023-02-27, MAE is:46.95 & sMAPE is:38.46% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :45.70 & 66.30% & 1.08\n",
      "for 2023-02-28, MAE is:45.79 & sMAPE is:37.64% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :45.70 & 65.82% & 1.08\n",
      "for 2023-03-01, MAE is:62.28 & sMAPE is:56.69% & rMAE is:2.44 ||| daily mean of MAE & sMAPE & rMAE till now are :45.98 & 65.66% & 1.10\n",
      "for 2023-03-02, MAE is:58.04 & sMAPE is:52.52% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :46.18 & 65.45% & 1.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-03-03, MAE is:56.82 & sMAPE is:69.05% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :46.35 & 65.51% & 1.11\n",
      "for 2023-03-04, MAE is:58.52 & sMAPE is:103.16% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :46.54 & 66.10% & 1.11\n",
      "for 2023-03-05, MAE is:68.17 & sMAPE is:79.26% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :46.88 & 66.31% & 1.12\n",
      "for 2023-03-06, MAE is:54.21 & sMAPE is:46.26% & rMAE is:3.48 ||| daily mean of MAE & sMAPE & rMAE till now are :46.99 & 66.00% & 1.16\n",
      "for 2023-03-07, MAE is:25.50 & sMAPE is:31.83% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :46.67 & 65.48% & 1.15\n",
      "for 2023-03-08, MAE is:92.02 & sMAPE is:113.72% & rMAE is:3.97 ||| daily mean of MAE & sMAPE & rMAE till now are :47.34 & 66.20% & 1.19\n",
      "for 2023-03-09, MAE is:41.41 & sMAPE is:41.61% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :47.26 & 65.84% & 1.20\n",
      "for 2023-03-10, MAE is:48.89 & sMAPE is:56.52% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :47.28 & 65.71% & 1.20\n",
      "for 2023-03-11, MAE is:36.76 & sMAPE is:50.41% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :47.13 & 65.49% & 1.20\n",
      "for 2023-03-12, MAE is:36.37 & sMAPE is:60.02% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :46.98 & 65.41% & 1.20\n",
      "for 2023-03-13, MAE is:23.84 & sMAPE is:67.60% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :46.66 & 65.44% & 1.19\n",
      "for 2023-03-14, MAE is:25.32 & sMAPE is:52.87% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :46.36 & 65.27% & 1.18\n",
      "for 2023-03-15, MAE is:39.67 & sMAPE is:67.36% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :46.27 & 65.30% & 1.17\n",
      "for 2023-03-16, MAE is:63.48 & sMAPE is:111.54% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :46.50 & 65.91% & 1.18\n",
      "for 2023-03-17, MAE is:17.11 & sMAPE is:72.12% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :46.12 & 66.00% & 1.17\n",
      "for 2023-03-18, MAE is:84.90 & sMAPE is:155.07% & rMAE is:3.38 ||| daily mean of MAE & sMAPE & rMAE till now are :46.62 & 67.15% & 1.20\n",
      "for 2023-03-19, MAE is:42.96 & sMAPE is:47.04% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :46.57 & 66.89% & 1.20\n",
      "for 2023-03-20, MAE is:30.96 & sMAPE is:30.46% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :46.37 & 66.43% & 1.19\n",
      "for 2023-03-21, MAE is:49.95 & sMAPE is:62.30% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :46.42 & 66.38% & 1.18\n",
      "for 2023-03-22, MAE is:22.13 & sMAPE is:75.20% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :46.12 & 66.49% & 1.18\n",
      "for 2023-03-23, MAE is:27.37 & sMAPE is:85.94% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :45.89 & 66.73% & 1.17\n",
      "for 2023-03-24, MAE is:9.41 & sMAPE is:26.65% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :45.45 & 66.24% & 1.16\n",
      "for 2023-03-25, MAE is:13.54 & sMAPE is:88.64% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :45.07 & 66.51% & 1.15\n",
      "for 2023-03-26, MAE is:33.63 & sMAPE is:108.23% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :44.94 & 67.00% & 1.15\n",
      "for 2023-03-27, MAE is:36.82 & sMAPE is:69.33% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :44.84 & 67.03% & 1.14\n",
      "for 2023-03-28, MAE is:51.11 & sMAPE is:70.76% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :44.91 & 67.07% & 1.14\n",
      "for 2023-03-29, MAE is:58.43 & sMAPE is:67.68% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :45.07 & 67.08% & 1.14\n",
      "for 2023-03-30, MAE is:32.91 & sMAPE is:47.00% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :44.93 & 66.85% & 1.13\n",
      "for 2023-03-31, MAE is:51.83 & sMAPE is:81.50% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :45.01 & 67.02% & 1.13\n",
      "for 2023-04-01, MAE is:19.02 & sMAPE is:62.53% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :44.72 & 66.97% & 1.13\n",
      "for 2023-04-02, MAE is:49.24 & sMAPE is:126.95% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :44.77 & 67.62% & 1.15\n",
      "for 2023-04-03, MAE is:31.91 & sMAPE is:31.79% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :44.63 & 67.23% & 1.15\n",
      "for 2023-04-04, MAE is:61.26 & sMAPE is:59.85% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :44.81 & 67.16% & 1.15\n",
      "for 2023-04-05, MAE is:54.90 & sMAPE is:47.36% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :44.92 & 66.95% & 1.16\n",
      "for 2023-04-06, MAE is:28.48 & sMAPE is:27.18% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :44.75 & 66.53% & 1.16\n",
      "for 2023-04-07, MAE is:52.74 & sMAPE is:67.65% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :44.83 & 66.54% & 1.16\n",
      "for 2023-04-08, MAE is:30.08 & sMAPE is:34.85% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :44.68 & 66.22% & 1.16\n",
      "for 2023-04-09, MAE is:43.57 & sMAPE is:52.07% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :44.67 & 66.08% & 1.16\n",
      "for 2023-04-10, MAE is:29.37 & sMAPE is:79.23% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :44.51 & 66.21% & 1.15\n",
      "for 2023-04-11, MAE is:40.11 & sMAPE is:79.54% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :44.47 & 66.34% & 1.14\n",
      "for 2023-04-12, MAE is:38.94 & sMAPE is:55.31% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :44.42 & 66.23% & 1.14\n",
      "for 2023-04-13, MAE is:67.95 & sMAPE is:129.98% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :44.64 & 66.85% & 1.14\n",
      "for 2023-04-14, MAE is:64.37 & sMAPE is:67.30% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :44.83 & 66.86% & 1.15\n",
      "for 2023-04-15, MAE is:19.92 & sMAPE is:32.63% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :44.60 & 66.53% & 1.14\n",
      "for 2023-04-16, MAE is:84.71 & sMAPE is:159.03% & rMAE is:2.88 ||| daily mean of MAE & sMAPE & rMAE till now are :44.97 & 67.40% & 1.16\n",
      "for 2023-04-17, MAE is:44.04 & sMAPE is:42.02% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :44.97 & 67.17% & 1.16\n",
      "for 2023-04-18, MAE is:20.28 & sMAPE is:22.65% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :44.74 & 66.75% & 1.15\n",
      "for 2023-04-19, MAE is:43.39 & sMAPE is:133.43% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :44.72 & 67.37% & 1.15\n",
      "for 2023-04-20, MAE is:21.74 & sMAPE is:63.90% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :44.52 & 67.33% & 1.14\n",
      "for 2023-04-21, MAE is:67.77 & sMAPE is:159.11% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :44.73 & 68.16% & 1.14\n",
      "for 2023-04-22, MAE is:35.49 & sMAPE is:70.98% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :44.64 & 68.19% & 1.15\n",
      "for 2023-04-23, MAE is:59.85 & sMAPE is:134.44% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :44.78 & 68.77% & 1.16\n",
      "for 2023-04-24, MAE is:23.46 & sMAPE is:27.33% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :44.59 & 68.41% & 1.15\n",
      "for 2023-04-25, MAE is:24.05 & sMAPE is:69.23% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :44.41 & 68.42% & 1.15\n",
      "for 2023-04-26, MAE is:50.66 & sMAPE is:163.10% & rMAE is:2.89 ||| daily mean of MAE & sMAPE & rMAE till now are :44.47 & 69.23% & 1.16\n",
      "for 2023-04-27, MAE is:90.13 & sMAPE is:150.37% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :44.86 & 69.93% & 1.17\n",
      "for 2023-04-28, MAE is:29.95 & sMAPE is:34.84% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :44.73 & 69.63% & 1.16\n",
      "for 2023-04-29, MAE is:28.28 & sMAPE is:43.76% & rMAE is:2.48 ||| daily mean of MAE & sMAPE & rMAE till now are :44.59 & 69.41% & 1.17\n",
      "for 2023-04-30, MAE is:39.01 & sMAPE is:129.46% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :44.55 & 69.91% & 1.18\n",
      "for 2023-05-01, MAE is:28.19 & sMAPE is:41.00% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :44.41 & 69.67% & 1.17\n",
      "for 2023-05-02, MAE is:33.75 & sMAPE is:40.70% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :44.32 & 69.43% & 1.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-05-03, MAE is:49.24 & sMAPE is:73.20% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :44.36 & 69.47% & 1.17\n",
      "for 2023-05-04, MAE is:24.56 & sMAPE is:28.90% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :44.20 & 69.14% & 1.18\n",
      "for 2023-05-05, MAE is:39.51 & sMAPE is:88.40% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :44.17 & 69.29% & 1.17\n",
      "for 2023-05-06, MAE is:43.56 & sMAPE is:87.70% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :44.16 & 69.44% & 1.18\n",
      "for 2023-05-07, MAE is:35.00 & sMAPE is:103.32% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :44.09 & 69.71% & 1.18\n",
      "for 2023-05-08, MAE is:41.09 & sMAPE is:85.86% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :44.07 & 69.83% & 1.18\n",
      "for 2023-05-09, MAE is:22.13 & sMAPE is:120.89% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :43.89 & 70.23% & 1.17\n",
      "for 2023-05-10, MAE is:12.29 & sMAPE is:131.74% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :43.65 & 70.70% & 1.16\n",
      "for 2023-05-11, MAE is:49.47 & sMAPE is:99.47% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :43.70 & 70.92% & 1.16\n",
      "for 2023-05-12, MAE is:48.09 & sMAPE is:76.57% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :43.73 & 70.96% & 1.17\n",
      "for 2023-05-13, MAE is:39.59 & sMAPE is:70.43% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :43.70 & 70.96% & 1.17\n",
      "for 2023-05-14, MAE is:33.04 & sMAPE is:67.97% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :43.62 & 70.94% & 1.17\n",
      "for 2023-05-15, MAE is:40.20 & sMAPE is:43.14% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :43.59 & 70.73% & 1.17\n",
      "for 2023-05-16, MAE is:18.78 & sMAPE is:42.16% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :43.41 & 70.52% & 1.16\n",
      "for 2023-05-17, MAE is:29.53 & sMAPE is:166.08% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :43.31 & 71.22% & 1.16\n",
      "for 2023-05-18, MAE is:44.03 & sMAPE is:65.56% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :43.32 & 71.18% & 1.16\n",
      "for 2023-05-19, MAE is:20.94 & sMAPE is:27.36% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :43.15 & 70.86% & 1.16\n",
      "for 2023-05-20, MAE is:18.86 & sMAPE is:69.42% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :42.98 & 70.85% & 1.16\n",
      "for 2023-05-21, MAE is:18.08 & sMAPE is:87.55% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :42.80 & 70.97% & 1.16\n",
      "for 2023-05-22, MAE is:19.39 & sMAPE is:27.36% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :42.64 & 70.66% & 1.15\n",
      "for 2023-05-23, MAE is:35.30 & sMAPE is:68.41% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :42.59 & 70.65% & 1.16\n",
      "for 2023-05-24, MAE is:58.46 & sMAPE is:80.97% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :42.70 & 70.72% & 1.15\n",
      "for 2023-05-25, MAE is:20.86 & sMAPE is:47.00% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :42.55 & 70.56% & 1.15\n",
      "for 2023-05-26, MAE is:33.36 & sMAPE is:96.24% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :42.48 & 70.73% & 1.15\n",
      "for 2023-05-27, MAE is:34.01 & sMAPE is:88.41% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :42.43 & 70.85% & 1.16\n",
      "for 2023-05-28, MAE is:28.02 & sMAPE is:90.84% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :42.33 & 70.99% & 1.16\n",
      "for 2023-05-29, MAE is:22.11 & sMAPE is:88.76% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :42.19 & 71.11% & 1.15\n",
      "for 2023-05-30, MAE is:40.48 & sMAPE is:59.48% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :42.18 & 71.03% & 1.16\n",
      "for 2023-05-31, MAE is:41.81 & sMAPE is:73.94% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :42.18 & 71.05% & 1.16\n",
      "for 2023-06-01, MAE is:50.22 & sMAPE is:114.53% & rMAE is:3.29 ||| daily mean of MAE & sMAPE & rMAE till now are :42.23 & 71.33% & 1.17\n",
      "for 2023-06-02, MAE is:34.12 & sMAPE is:51.11% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :42.18 & 71.20% & 1.17\n",
      "for 2023-06-03, MAE is:26.22 & sMAPE is:71.14% & rMAE is:3.02 ||| daily mean of MAE & sMAPE & rMAE till now are :42.08 & 71.20% & 1.18\n",
      "for 2023-06-04, MAE is:21.56 & sMAPE is:65.27% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :41.94 & 71.16% & 1.18\n",
      "for 2023-06-05, MAE is:32.48 & sMAPE is:43.32% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :41.88 & 70.98% & 1.18\n",
      "for 2023-06-06, MAE is:21.18 & sMAPE is:23.67% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :41.75 & 70.68% & 1.19\n",
      "for 2023-06-07, MAE is:44.00 & sMAPE is:55.08% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :41.77 & 70.58% & 1.18\n",
      "for 2023-06-08, MAE is:21.89 & sMAPE is:29.47% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :41.64 & 70.33% & 1.18\n",
      "for 2023-06-09, MAE is:25.98 & sMAPE is:43.41% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :41.54 & 70.16% & 1.18\n",
      "for 2023-06-10, MAE is:11.51 & sMAPE is:62.32% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :41.36 & 70.11% & 1.18\n",
      "for 2023-06-11, MAE is:28.29 & sMAPE is:131.21% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :41.28 & 70.49% & 1.18\n",
      "for 2023-06-12, MAE is:39.11 & sMAPE is:54.23% & rMAE is:4.34 ||| daily mean of MAE & sMAPE & rMAE till now are :41.26 & 70.39% & 1.20\n",
      "for 2023-06-13, MAE is:25.93 & sMAPE is:33.33% & rMAE is:2.44 ||| daily mean of MAE & sMAPE & rMAE till now are :41.17 & 70.16% & 1.21\n",
      "for 2023-06-14, MAE is:33.16 & sMAPE is:37.54% & rMAE is:5.80 ||| daily mean of MAE & sMAPE & rMAE till now are :41.12 & 69.96% & 1.24\n",
      "for 2023-06-15, MAE is:21.29 & sMAPE is:17.58% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :41.00 & 69.65% & 1.23\n",
      "for 2023-06-16, MAE is:40.30 & sMAPE is:36.92% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :41.00 & 69.45% & 1.23\n",
      "for 2023-06-17, MAE is:24.31 & sMAPE is:25.49% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :40.90 & 69.19% & 1.22\n",
      "for 2023-06-18, MAE is:19.84 & sMAPE is:25.60% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :40.77 & 68.93% & 1.22\n",
      "for 2023-06-19, MAE is:19.70 & sMAPE is:16.89% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :40.65 & 68.62% & 1.22\n",
      "for 2023-06-20, MAE is:15.00 & sMAPE is:12.73% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :40.50 & 68.30% & 1.21\n",
      "for 2023-06-21, MAE is:26.69 & sMAPE is:23.11% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :40.42 & 68.04% & 1.21\n",
      "for 2023-06-22, MAE is:14.73 & sMAPE is:12.55% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :40.27 & 67.71% & 1.21\n",
      "for 2023-06-23, MAE is:16.59 & sMAPE is:16.92% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :40.13 & 67.42% & 1.21\n",
      "for 2023-06-24, MAE is:26.80 & sMAPE is:49.54% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :40.06 & 67.32% & 1.21\n",
      "for 2023-06-25, MAE is:36.59 & sMAPE is:69.82% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :40.04 & 67.33% & 1.21\n",
      "for 2023-06-26, MAE is:25.55 & sMAPE is:27.14% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :39.96 & 67.11% & 1.21\n",
      "for 2023-06-27, MAE is:52.41 & sMAPE is:93.98% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :40.03 & 67.26% & 1.21\n",
      "for 2023-06-28, MAE is:14.64 & sMAPE is:13.19% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :39.88 & 66.96% & 1.21\n",
      "for 2023-06-29, MAE is:18.71 & sMAPE is:16.76% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :39.77 & 66.68% & 1.21\n",
      "for 2023-06-30, MAE is:13.89 & sMAPE is:13.53% & rMAE is:2.65 ||| daily mean of MAE & sMAPE & rMAE till now are :39.62 & 66.38% & 1.22\n",
      "CPU times: total: 1d 20h 26s\n",
      "Wall time: 19h 34min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for zone in zones:\n",
    "    large_scale_predictor(zone, first_year=2018, last_year=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
